presenting okay share your screen that's what I'm doing oh you are okay hopefully it is yeah stop sharing yeah you should be sharing my screen under your camera until I can decide if I click on slideshow this is still show my camera uh it does I guess I can minimize it do screen sharing are you recording tooYeah great baseball back yeah I mean it's my first time giving my lecture so I'm as good as I can be do you want that cheers I mean I have to write something to hear me okay okay you know that it works. this week will probably go live tomorrow uh not quite sure yet but you'll try to get it up as soon as possible so I guess like without further Ado let's Jump Right In. I'm gonna go somewhat into detail into what representation learning is and I think this should sort of cap out the last few weeks of deep learning um and probably give you a more comprehensive understanding of what deep learning actually is doing. We'll talk a little bit about what learning transfer is and what the benefits might be when we train a model from scratch which we don't usually do. The machine learning pipeline you start with an input X you extract all the relevant features from it and then you push those into a machine learning algorithm should get an output Y and you sort of optimize based on that. There are special feature extractors for images so this is sort of what classical machine classical CV look like. We will have an entire lecture dedicated to self-supervised learning for Envision Envision might actually be trying to predict the hidden part or property of the input from any observed or unhidden part of the image. but luckily huge models have already been trained before so the sort of question is can we leverage them in some way and the answer is yes absolutely so you might have heard of what we've called pre-trained models. Many of these pre- trained models are frequently used all the time and so we can take a look at how and why we might want to use them so if we train a model from scratch our model parameters or our weights are randomly initialized in the beginning and then we update them gradually through an optimization algorithm such as stochastic radio descent. um and the similarity of the new data set to the original data set so for example in the case one where you have um a small small data set or a lot a large data set. Since it's larger we have more confidence that we won't overfit if we fine-tune. On the other hand if we have a smaller data set even though it's similar to theOriginal model it's not a good idea sometimes to fine tune because you can definitely overfit. And then in the third case in which you have like a smallsmall data set and then it's pretty different from the first task um. to embeddings to something called a latent space so we often prefer to work with lower dimensional data. The idea is that if we can directly work with the significant somehow find a way to represent this line using just one variable instead of three and so here's let's say the XYZ coordinates that's going to be better. This also provides learning algorithms are trying to learn something much more Beyond supervised training turns out that this example is not constrained to just CV you can also do SSL with NLP. as a 70 784 dimensional Vector plus 25 to 784. so what you can do is you can train a model that would classify um what digit the image contains. Your goal is to optimize the network such that this error decreases and your model is trying to output something that is very close to the actual labels y . so in a sense your training process is receiving supervision from the labels your super your labels are guiding what the model must learn and and this whole process is called supervised learning like the name suggests. any labels into that algorithm you just feed in the data Matrix. There was there were no labeling involved you just took each audio signal um projected it down to two dimensions and clustered them with other points so yeah it turns out that dimensional eruption with PCA clustering etc etc are common examples of unsupervised learning and this is sort of. uh hopefully it will give you a clearer picture of what's going on so in the first picture your different points and they have plot labels associated with them so in a classification task you're going to predict what the labels are. anymore but it's also trying to understand what's going on in the image it's it's going to learn that an image can be made up of different parts and those parts are going to be related to each other. There are some more technical details on the slides um I won't go into those but something that the authors actually did I actually go mention this is when they sample the patches and they divide it into a grid instead of taking the grid directly they actually generate each patch a bit.  SSL can also be applied to audio it's a very broad sort of paradigm and I think the currency of the art and audio classification is Wave 2 Vector Q which I think came out a few years ago okay so what if we go back to this idea of where to work we are predicting a single word from some surrounding context. What if you predict a word from the entire sentence that it is a part of and as I think I think you might imagine that this white this might work better because the sentence will give you more context. the slide is it turns out that the current state of the art for CV is actually very similar to Burke so that's a teaser for the lecture that we discuss Advanced Techniques and as software CV. There is a homework for this entire cluster which is the high Crush notebook that should be due next Tuesday even though this lecture doesn't have homework I mentioned before that there will be a lecture on on Advanced SSL for CV and that will have a homework so to work on that homework this slide deck should be up on the website again if you feel free to do that that is it for today a second pause.