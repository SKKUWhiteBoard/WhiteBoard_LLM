==================== [1/100] ====================
Summary:
John ESSIGMANN: I measure my blood sugar at different times during the day. Gluconeogenesis technically means new synthesis of glucose from non-carbohydrate precursors. The medicine I take is called Metformin. It has a number of targets, but one of them is one of the enzymes, called PEPCK, Pyruvate Carboxykinase, that's in the gluconeogenic pathway. The liver provides a constant stream of glucose to these organs that absolutely require it, like our brain. the night, is to take this drug that will prevent the switch to produce more and more sugar by gluconeogenesis. The drug will stop the switch from producing more sugar to producing less sugar. It will also prevent the production of more sugar from the body's own production of sugar. This is called the 'gluconeogenesis inhibitor' and is used in the treatment of diabetes and obesity. It is a drug that stops the switch between the two processes from occurring. It also prevents the body from producing too much sugar.

ROUGE-1: 45.30, ROUGE-2: 30.98, ROUGE-L: 31.54
BERTScore: 67.45

==============================================
==================== [2/100] ====================
Summary:
In this lecture, we introduce and develop the concept of independence between events. If I tell you that a certain event A has occurred, this will generally change the probability of some other event B. In such a case, we say that events A and B are independent. We will then proceed to define the independence of a collection of more than two events. Finally, we will close with an application in reliability analysis and with a nice puzzle that will serve as a word of caution about putting together such a collection. probabilistic models. Probabilism models are models based on a set of assumptions about the future of the economy. The models are based on the assumption that the economy will continue to grow in the future. They can be used to make predictions about future growth. For more information, visit: http://www.cnn.com/2013/01/29/30/science/features/top-10-most-futile-probabilities-in-the-world/story/story.html.

ROUGE-1: 63.01, ROUGE-2: 50.14, ROUGE-L: 50.41
BERTScore: 70.32

==============================================
==================== [3/100] ====================
Summary:
As the dough ferments it fills up with carbon dioxide expelled by the yeast which is feeding on simple sugars. The gas accumulates in pockets inside the dough held together by the gluten structure. We want the dough to rise up and become nice and light bread so why would we want to punch the gas out it seems that it would defeat the purpose of fermentation normally punching down is performed halfway through bulk fermentation and the punching down or degassing can be accompanied by folding in fact both are done in the kitchen. same step and these two actions go hand in hand not only during folding but also when dividing pre-shaping and final shaping the dough. No matter how gentle you try to handle your dough you will always de-gas it if only a little bit. In today's comparison video we'll make 4 breads they will be made from the same dough but they will all be treated differently. The first one of the four breads will be left alone from the beginning of fermentation until it's baked. The final one will be folded shaped and degassed three times and we won't be fermenting them for the same amount of time. You would almost never make a bread like the one on the left and there's a good reason for it that's why first we're going to talk about folding. folding achieves a couple of things first off it degasses the dough secondly it builds tension into the dough if the dough is weak and loose by folding it we can tighten it this makes it rise higher vertically instead of spreading out sideways. A stronger dough will also be able to hold more gas and take more fermentation before deflating and falling flat and what you're seeing here on the screen is the first fold halfway to bulk fermentation. why are you punching it punching is actually quite aggressive and you should never punch your dough the best thing to do is deflate it by pressing it gently as the dough ferments the gas pockets inside the grow larger and larger and the membrane of dough between those pockets can tear and the pockets of gas can fuse into larger pockets. If this process keeps going undisturbed the crumb of the bread can end up with large bubbles surrounded by denser areas of dough this of course not always a bad thing some high hydration breads are specifically made to have that texture as we punch down or deflate the dough the Gas pockets break down and split up resulting in a more tightly packed and even chrome structure. proof i tried to shape them similarly as i could so that the main difference between these breads would be the steps that we took or skipped now degassing folding and shaping is not just about what the crumb will be like it's also a way of controlling fermentation the loft on the left is almost ready to be baked while the other three they still need about an hour until they go in the oven as we know fermentation builds flavor and it helps develop texture of the crumbs and the crust by degassing the dough we are forcing it to rise back up again it basically has to start over. for one the crust on this loaf separated that could be all those gas bubbles fusing together and finding the path of least resistance and we see a good progression of oven spring the more the dough was shaped de-gassed and handled the highest rows that may seem quite counter-intuitive but as i mentioned earlier tension is what makes the oven spring happen and the dough on the right was the tightest one because we folded it pre-shaped it and final shaped it now let's have a look at the crumb and of course as i explained earlier if the dough is left undisturbed it will result in a crumb with large holes surrounded by denser dough that's exactly what we're seeing here on the bread that wasn't de-Gassed at all. worst and you should not be making bread like that if you want to use this method it should be fermented for much longer and perhaps go in a higher tin at the end of the day it's all up to you make your bread the way you like it make it fit your style and taste experiment try different methods don't just follow recipes ask questions and if you ever get stuck check out more videos in the principles of baking playlists you might find some answers there so what do you think of degas thing do you degas your bread though let me know down in the comments and don't forget to read the blog post linked in the video description.

ROUGE-1: 62.50, ROUGE-2: 61.65, ROUGE-L: 62.43
BERTScore: 72.60

==============================================
==================== [4/100] ====================
Summary:
When it was ratified in 1789, the U.S. Constitution provided a way for the people to alter the constitution itself. Of the nearly 11,000 amendments proposed in the centuries since, only 27 have succeeded. For an amendment to even be proposed, it must receive a two-thirds vote of approval in both houses of Congress. To actually change the Constitution, the amendment must be ratified by three-quarters of all states. To do this, each state can either have its legislature vote on the amendment, or it can hold a separate ratification convention. The U.S. hasn't passed an amendment since 1992. The Bill of Rights includes some of America's most well-known freedoms. The first ever proposed amendment was on the verge of ratification in the 1790s. Today, there are many suggested amendments, including outlawing the burning of the flag, limiting congressional terms, or even repealing the Second Amendment. While many enjoy strong support, their likelihood of passing is slim. Americans today are the most politically polarized since the Civil War, making it difficult to pass amendments. nearly impossible to reach a broad consensus. The late Supreme Court Justice Antonin Scalia once calculated that due to America's representative system of government, it could take as little as 2% of the total population to block an amendment. Interestingly, the founders themselves may have foreseen this problem early on. In a letter to James Madison, Thomas Jefferson wrote that laws should expire every 19 years rather than having to be changed or repealed. Although he believed that the basic principles of the Constitution would endure, he stressed that the Earth belongs to the living, and not to the dead.

ROUGE-1: 62.93, ROUGE-2: 59.03, ROUGE-L: 62.04
BERTScore: 73.15

==============================================
==================== [5/100] ====================
Summary:
50 years ago, John McCarthy and Marvin Minsky coined the term artificial intelligence. Progress has been made, especially in the last 20 years. But it was obvious that we needed different expertises. Not all in computer science, but in other ones. And so, this was the people that we put on the team. The team was made up of computer scientists, mathematicians, physicists, and other experts in different fields of study. The group was put together by MIT OpenCourseWare, a collaboration between MIT and several universities. together from different labs, from neuroscience, from computer science, from cognitive science, and from a number of institutions in the US. Let me tell you a bit more about the background here. This idea of merging brain research and computer science in the quest to understand intelligence. Part of the reason for this was progress and convergence we saw between different disciplines. And one of them was progress in AI. And this started, really, with Deep Blue, I guess it was called at the time. And then, of course, there was Watson beating champions in Jeopardy. cover of a Nature supplement, on artificial intelligence and machine learning. I think it's a golden age for intelligent applications. We are still very far from understanding how people can answer questions about images. And we would like to know to have a system that does that. But also, to know how our brain does it. So that's the science part. It's not enough to pass the Turing Test. In In Nature, David Wheeler looks at the future of artificial intelligence, and how it will affect our lives. this case, to have a system that does it. And we want to compare your model, our system, with measurements on the brain of people, or monkeys, also during the same task. So that's what we call Turing plus, plus questions. And part of the rationale about it is, this is kind of a more philosophical discussion. I personally think that it's very difficult tohave a definition of intelligence, in general. There are many different forms of intelligence. What we can ask is questions about, what is human intelligence? Because we can study that. able to answer how people do understand images. We start with vision. We are not limited, eventually, to vision. But in the first five years of the center, that's the main focus. And answer the question about images. And we want to understand how the answers are produced by our brain at the computational, psychophysical, and neural level. It's ambitious. And I think there are probably, in terms of having all these different levels, levels of really understanding from the what, where, the neuroscience, to the behavior. looking at the face. And make models of what's going on. And, of course, we want these models to respect the neural data, ideally the MRI data. And do the job of recognizing faces as well as human do. So we are getting there. I'm not saying we have the answers, but we have at least models that can be tested at all these different levels. So that's kind of the ideal situation, from the point of view of what we want to do in the center.

ROUGE-1: 60.30, ROUGE-2: 55.67, ROUGE-L: 56.41
BERTScore: 68.37

==============================================
==================== [6/100] ====================
Summary:
Chef Todd Moore shares the seven basic skills that everyone should have to cook food consistently in the kitchen and be proud of the results. If you already have all seven of these skills and cooking techniques great you can work for me on the other hand if you only have one or two ofthese skills that's still fantastic why because I know you'll want to add other skills and learn to cook basic methods. Chef Todd Moore: My chef test highlights the skills thateveryone should possess if they want to learn to Cook anything at any time. know the methods behind all written recipes then you'll be making your cooking a winner every single time so here are my seven Chef tests to reveal their knowledge of basic cooking methods. Use a chef knife correctly and cut vegetables into three specific sizes number two anticipate when oil is about to reach the smoke point number three develop color during sauté number four thicken a liquid to make a sauce number five softly poach an egg number six roast a delicate item like fish and number seven tell when a grilled steak is done. The Magician's hands the way that he wants you to. Once you've been shown the misdirection how the trick works you start looking for this redirection. You can also cook chicken fish steak vegetables pork in the same repetitive method and and the magic will then appear for you so here are the answers to my chef test number one using a chef's knife correctly. The first indicator of an experienced cook from a novice is the way they handle the most used tool in the kitchen it's the chef's knives. Cube It's a tiny little cut that you'd find in chicken salad or soup batonette is a 2in stick that's a/4 in on all sides small dice is a/ quin Cube small dice comes from batonettes as the cubes are always cut from sticks so to pass this test well the result should be three items that are precisely twice or half the size of the others. consistency of cut is consistency of cook so knife skills are very important for excellence results you have failed this test if you give me items of a wide variety of shapes and sizes are all the items cut into the same size. like to cut things up you'll be using fresh vegetables uh anyway uh second in my chef test to anticipate when oil is about to smoke now the skill here is understanding the convective cooking process. When the chef notices the oil starting to change from being perfectly smooth to beginning a convection process then adds the protein product to the pan just before there's visible smoke this is where you get the splattering reaction in the pan. If you give me a chicken breast with a beautiful brown plate appeal that shows your ability to control heat so that the item develops color but doesn't lose moisture or burn you fail this test. one that's lost moisture one that's burned one that shows the lack of involvement in the preliminary steps of the sauté process Chef test number four here's the answer thicken a liquid to make a sauce. Without an understanding of how starches thicken it's difficult to make consistently great sauces this is a skill of someone that really knows how to cook number five Chef test softly poach an. If you give me a cup of milk that looks like mashed potato Poes or cottage cheese you failed this test. egg well this shows the moist convective process and it means that the Chef should have an understanding of the difference between boil simmer and poach a common mistake of Home cooks and chefs alike is always boiling items boiling is not a cooking method once you understand how to control the reaction of liquid in a pan you'll be able to perform a poach of a very delicate item like eggs without making all busted up egg drop soup. When you give me a nicely poached egg one that looks like it should be in a magazine beautiful yoke bright yellow sitting up high on the albumin should be fully intact and look great. a chicken most people can put a piece of meat in for a while and I don't have 3 hours to wait on the chef test anyway but roasting something delicate like fish now this shows the ability to show to control dry convective heat dry versus Mo moist in controlling dry heat. There's a very fine line between the coagulation of proteins the stiffening and shrinking of what you're cooking at 165° F and the 212° fah when moisture starts evaporating the key to cooking with dry heat is being able to live in this temperature zone between 165 and 212 where the food Cooks for drying out. and it's dry it's much smaller in its uh cooked State than it was in its raw State because of the drying effect of the oven this Chef doesn't know how to retain moisture in a dry cooking process Chef test number seven how to tell when a grilled steak is done I mean the best test that I can think of for this is to hand a chef three steaks ask them to cook them to order cook me one rare one medium one well done a lot of people can't do this how you do this. every single time because understanding these methods will allow you to make sense out of any recipe or not even use a recipe. Your increased understanding of how different cooking techniques work not what to cook but how the techniques work and then you'll be creating the things that you want you want them to be. Make sure you get a seed at my webinar [Music] and then come back again and again to try and create the things you want to create. You'll be able to create them again andagain and again.

ROUGE-1: 60.87, ROUGE-2: 58.38, ROUGE-L: 56.99
BERTScore: 69.56

==============================================
==================== [7/100] ====================
Summary:
Third degree heart blocks also known as a complete heart block this type of heart block is the worst of all blocks. Electrical signal from the atria isn't making it to the ventricles. The person could be born with it so it could be congenital or the person has severe heart disease or they have a myocardial infarction or they're taking some type of medication that they become toxic on like digoxin. What is the treatment for a heart valve problem now what is the treating for a third degree heart block? third degree heart block well with this your patient's usually going to have some signs and symptoms because whenever the heart is beating like this it's not going to perfuse your body. Some treatment that can be given to that patient is that atropine can be administered to help that heart pump more efficiently. The patient could be connected to a temporary pacemaker which will again get that heart beating correctly so we can maintain cardiac output and then eventually the patient will need a permanent pacemaker implanted. block and if you'd like to watch more videos about heart blocks in this series you can access the link in the youtube description below. Click here to read the first video in the series about a heart block. Read the second video to learn more about the heart block and how to block it. Click the third video to see the next video about the block and learn about the different types of block that can be used to block a person's heart. The third video is the final video of the series and is about the blocking of a heart valve.

ROUGE-1: 54.43, ROUGE-2: 43.85, ROUGE-L: 42.90
BERTScore: 64.90

==============================================
==================== [8/100] ====================
Summary:
The final contest, which is due tonight, is to design an agent that plays together with another agent to try to collect food pellets while not getting eaten by ghosts. submissions for that, your last chance to submit are tonight at midnight. And on Thursday in lecture, we'll discuss the results. What else is left? I think there is a project due next week. There is still a section this week. And I think that homework is all wrapped up, but you would still have a self-assessment of your last homework that will be due next. And then there's a final exam the week after that. be mostly on advanced applications. The idea behind these two lectures is to look at advanced applications, where we have covered a good amount of the material in the ideas behind those applications. We will not quiz you on these application lectures, on the final exam, or anything like that. It's more meant to give you more perspective rather than extra study materials for the final. So far, I've looked at foundational methods for search, for acting adversarial environments, for learning to do new things, and for dealing with uncertainty. Today's state-of-the-art in Go is that there are computer players better than the best human players. But actually, if you went back to March 2016, that was not the case yet. So how do you make an AI for Go? Let's go back to what we were looking at in lecture on games, MiniMax. MiniMax is about solving games in adversarial environments. And you reason about it. And in what it did, we had to update this graph that you see at the very beginning of the course, where we had already checkers fully solved. For a game like Tic-Tac-Toe, you will find out that you can force a draw, and that means fully solving the game. For Go, this is actually pretty hard to do, and it's even much harder than chess. And why? Let's take a look at chess. It's a 19 by 19 board, so there's 19 times 19 positions to choose from in the first move. And then one less, of course, next move. But the branching factor is enormous. So if you tried to run an exhaustive search through this kind of game tree, it's not going to work. The evaluation function was learned. A deep neural network was trained to provide a good evaluation function at various stages of the game. But even then, because the branching factor is so large, the evaluation function, sure, if you want to look one step ahead, no problem. But many of the moves are not that useful. So the question you can ask, can we learn another neural network that can tell us how to reduce which moves to consider when we do our depth-limited search? And so policy network can be trained, which assigns probabilities to all possible moves. And then you might only consider the moves with high probability when running your search. DeepMind's AlphaGo is a computer program that can learn to play the game of Go without the help of humans. It uses deep neural networks and tree search, combined, to bring together two topics we've covered in this class. AlphaGo Zero has also been used to learn chess and, I believe, Shogi, or some other board game that's strategically similar to chess, but a little more complicated. Any questions about this? We'll cover a sequence of different applications one after the other, and this is the part for Go. When you play against yourself, initially, you're playing pretty poorly, of course, because you don't know how to play it. It's a random neural network, or a network that's randomly initialized, making decisions. And so it turns out that in terms of reinforcement learning problem, problems you can phrase as you playing against a version of yourself, and that kind of problem is much easier to learn than most other things. And the longer it keeps playing itself, the better it keeps getting. might overfit to your exact current way of playing. Sometimes the human knowledge put into it is looking at past games of humans, and training a value network and a pulse network to predict what happened in there. But maybe if you learn from scratch, you can find something even way better? I don't know the answer to that. But empirically, it seems that learning from scratch reaches levels beyond the levels reached with the previous methods. But yeah, who knows? There is no final answer yet. moment, ?] another [INAUDIBLE] PROFESSOR: There is something called fictitious play. In fictitious play, you kind of play against yourself in a slightly more complicated setting than this. So I believe it includes this, the result. By playing yourself, you're guaranteed to reach an equilibrium. Actually, what reaches the equilibrium is the average version of all your past selves. So rather than your actual current network being the equilibrium solution, it's the average of all past. AlphaGo Zero is compared with AlphaGo Lee, which is the version that played Lee Sedol. So AlphaGo Zero has no prior knowledge. It starts at a pretty, actually, negative elo rating. Loses all the time initially. It's playing itself, but then gets tested against a set of players to calibrate its elo. And the green line is we're Alpha go Lee. The blue line is Alpha go Zero. The red line isAlpha go Master. The yellow line isalpha go master. Sedol was. that blue dotted line, after 21 days, it goes past where AlphaGo Master, was which was an improved version of AlphaGo Lee Sedol. And then it was still creeping up after 40 days. Once you reach that level, essentially, there's no further to go, because you solved the game. And I don't know what elo rating would correspond to that. Any other questions about Go? Yes? STUDENT: [INAUDIBLE] PROFESSOR: Well, that's a good question. The question was, do we think we can solve the game with enough compute power? With reasonable compute power, it traverses the whole tree. Even with alpha beta pruning, I don't think that'll happen anytime soon. It's a really big tree. If you do a more kind of brute force style approach-- not 100% brute force. It might be. But pretty much no one would say less than 20, and most people would say 50 or more. And that's maybe when we reach human level play. But that's a given. Now, with infinite computing power, for sure. Then you can definitely solve it. even longer. But the more brute force style approach, where you don't have good value functions, you don’t have good policy functions, was expected to take decades before we reached compute levels that can do that. It could be that by using human knowledge, you're in some kind of based enough attraction. For a local [? optim, ?] that maybe not as good as another one that might be out there. I don't know if that would be the case or not, but that's a possibility. Some examples in a few other problems settings soon. And then the reinforced learning on top of that to further improve. That's kind of the standard way to solve a problem. From a research point of view, it's very interesting to see where you can get from scratch. OK, switching gears to helicopters. Here's a motivating example. How do you get a helicopter to do this autonomously? And by the way, this is done autonomously here, but how do we get to something like this? like this? Well, what does it mean to fly a helicopter? What are the challenges? There's two key challenges. One is tracking where the helicopter is at any given time, because if you don't know where it is, you'll not be able to control it very reliably. And then the other thing is to decide what to do, what controls is sent to the helicopter. Typically, have a remote control, which has two joysticks. You send controls from that to the helicopters. We have four control channels, two in each joystick. A collective is the action for the main rotor collective page. It's the average angle of attack as the blade goes through the air. So that way, you can generate a torque that allows your helicopter to roll or pitch based on how much differential thrust you have from back, left to right. The tail rotor has a variable pitch also, and that pitch allows you to modulate how much thrust you get from the tail rotor. That's how you control a helicopter. You cannot directly ask it to fly forward or sideways. in a helicopter frame. vertically, the helicopter frame will now be partially forward and partially up, and up compensates for gravity and the forward is what lets you fly forward. So you can build a model for this from collecting data from your helicopter, let's say, and learning a bunch of parameters that predict the next state, given current state and action. For hover, we saw this. You can have a reward based on distance to target location, x star, y star, z star. And maybe penalizing for non-zero velocity, so you want it to hold still. not possible because when you are spinning and you're not able to generate direct vertical thrust, if you generate that vertical thrust in your helicopter frame, you move forward or backwards in some way. So maybe we decide as a target, for this helicopter, to do this kind of maneuver. But exactly what will be the details? It's not easy. Exactly how much do you push up? How fast do you spin? Difficult things to decide. And so we designed a trajectory. This is me, together with Adam Coates and Morgan Quigley. And then had reinforcement learning, learn a controller to follow the trajectory that we design. pretty good. And then we run it on our helicopter. So this is our helicopter, indeed, flipping, which is great. It's moving more than we want it to move. And it went into the trees. So let's think about what happened here. What happened in the real world is we're trying to follow this path that we design where the maximal reward is. And so we had asked it to fly a path that's not flyable. So it starts deviating from that path. As it deviates, what it learned in the simulator becomes less and less relevant. saw it making these wild motions, overcompensating. It pushed the controls so hard that the engine died. At that moment, the blades stopped spinning, or they slowed down. You lose control over your helicopter, more or less, at that point. Then what happened is our human pilot took back control to try to save the helicopter. And believe it or not, they actually saved this. Helicopter incredible. But he knew from past experience. His dynamics model was pretty good, I guess. was just phenomenal. It's behind the trees. He doesn't see it. He knows kind of what's happening. And right before he lands, he changes the collective control to not absorb energy into blades anymore, but to push it all back out. That kinetic energy that's in the spinning blades now goes into pushing air down to slow down the helicopter. It landed a little harder than you want to land, but it landed on its feet. So clearly, human level control, at that point, was much better than our autonomous controller. the helicopter to follow a path that's not flyable. So how do we get a specification of what we should be flying? Well, we could learn the trajectory from these as noisy observations. What methodology do we have for that? Hidden Markov models. If we collect paths from a human pilot and then ask the helicopter to fly those paths, they tend to be noisy. But if we collect many demonstrations, we figured, then, this set of demonstrations captures the essence of what it means. have something we don't know that evolves over time, but we have some noisy measurements of it, we can run an HMM to recover what we actually want. We use something called dynamic time warping. So what does that do? You can align two trajectories. After you do that, then you can run the inference and hidden Markov model, just standard based net inference, which, in this case, was just a guess. Then you run dynamic time Warping, which aligns each trajectory with the hidden one. But in the process, also aligns all the demonstrations, because they're all aligned with this one reference. is an extended common filter/smoother, which is a forward/backward path, similar to what we covered, but done for continuous variables rather than for discrete variables. Let's then re-infer, through probabilistic inference, what the hidden state might be. Keep repeating this till we reach some fixed point, and that will be our target for our helicopter to fly. What does this look like? Here is, in white, the target found through the hidden Markov model inference, and in color, still the demonstrations. We have collected data to learn a dynamics model for the helicopter. We can now penalize our award, penalized for deviating from the target. And then we can run reinforcement learning in simulation, let's say, in this learn simulator to find a good controller and run it on the real helicopter. The controller we learn in simulation is still a little optimistic about really following that path. So while we fly the helicopter, we'll do depth-limited search to improve what we have. able to look ahead only two seconds, rather than needing to look Ahead much further. A value function tells us, OK, how good is it to end up here? We also have a reward at each time tick. And our search over those two seconds is what results in the control we apply. Here's what we get. So fully autonomous. Takeoff, flipping over during takeoff. Hover. So this method can also learn to hover, no problem. Then it goes into forward flight and it's going to do something called split [? us, ?] where you do a half roll, half loop. The fastest we flew this helicopter was close to 55 miles per hour, so almost highway speeds. The algorithm's only this big, so it's pretty fast for something of this size. Inverted flight. Knife edge fall. Stall turn again, coming out tail first. Hurricanes are fast backward flying circles. And then now are actually some of the hardest maneuvers to execute on. Why is flying 55 miles an hour not harder than this? Well, when you do something like this and hear the tick tock, the hardest maneuver in this air show. Berkeley PhD student Woody Hoburg set up the helicopter to learn from scratch. Hoburg shut it off whenever it starts tilting itself, so it lands on some pretty wide landing gear so it's more stable. He was able to have it learn to hover reliably with the only human input being shut off when it looks like it might start doing something dangerous. But that was the onlyHuman input required. We did not push that further to flying those maneuvers. There is some work to be done. at OpenEye, there's been some work on robots learning to do back flips. And that was kind of one step further. It wasn't just shutting it off. You would watch your robot try things. And human input would be not specifying a reward function, which is very hard to do for things like back flips, just like it was hard here. But what they did is they said, the human watches it and says, which one is better or worse among a set of them? it has more time, and if it already has a recovery controller, then you can imagine that. And Claire Tomlin's group here at Berkeley has done some work in that direction, where they have a safe controller and a learned controller. And the learning controller is learning on its own while the safe controller keeps things in check so the helicopter doesn't crash. Yeah, the mass properties change a little bit. So it actually more power, until the very end, of course, when it has no power left. gets a little more power. Maybe a question related to that is, how much power does this thing actually have? This helicopter had inverted slide, where it has more power, 3 Gs. So it can generate three times the power of gravity. Of course, you need to generate one of them to even stay up in the air, but it still had two G's left to do other things with. And regular flight had about 2.5 G's maximum acceleration. OK, let's take a short break here. And after the break,let's do legged locomotion and manipulation. is a separate linear feedback controller for each time slice. And the way you learn that feedback controller is by doing a forward pass to see what your current sequence of controllers achieves. And then you can do a backward pass, which is, essentially, a value attrition pass over that same trajectory to find the optimal sequence of feedback controllers. So essentially, value iteration, but in a continuous space. A continuous space is always harder to represent things, so that's why you make a simplifying assumption. We assume that we are just going to use a sequence of linear controllers. follow a new path. Along that new path, we linear the dynamics, because dynamics' not really linear. We approximate it linearly. We do another backward pass along that, and keep repeating this until it's converged. Once we've done that, we have value functions everywhere and we have linear feedback controllers everywhere. If there is no wind, you can actually just run the linear feedback control. It will be fine. But if there's some wind gusts that could throw you off, you want to use the value functions and the two second look ahead against those value functions. Walking tends to be harder than flying for robotic control. If you're flying, you're up in the air. Everything is the same. Unless there's some weird air flows, that's the only thing that really changes. When you're walking, the surface could change all the time. A lot more change in your environment. Here's an example of how hard this can be. This is a video from 2015, there was the Doppler Robotics Challenge, which was held in Pomona, just east of Los Angeles. of Los Angeles. People had two years to work on this. And what did the robot have to do? It had to, essentially, drive a car or walk, but driving the car was recommended. Then get out of the car, walk a little bit, open a door, grab a drill, drill a hole, walk some more. So doesn't sound that complicated. But actually, it turned it's very complex to get a robot to do that. And here's some footage from the competition. very funny to watch the video, but it turns out at the competition, everybody was really sad for the robots when the robot fell. It was very interesting to see how people really connected with these robots and really felt for them and wanted them to succeed. Now, this is indicative of how hard this can be. And why is this so hard? Why did this not just work? Well, if you look underneath of a lot of what was going on in these approaches is they would build a model of the world. or not you're already making contact, and making contact or not. You can be very close, but not have contact. It's a very subtle thing. You don't have contact, you don't get to apply any forces. So it's very hard to do this. Now, what's changed recently in the past few years is that through advances in deep learning, it's been possible to better map from raw sensory information to controls you might want to apply. And ultimately, it learns to walk. Reinforcement learning algorithm can be reused directly onto other robots and can learn to control these other robots. The reward function is the closer your head is to standing head height, the better. So sitting is better than lying on the ground and standing is even better. At this point, it is possible. You run enough simulation to train up a very wide range of skills. So these are results from Jason Pang. He's the founder and CEO of reinforcement learning company, Pang Robotics. a student here at Berkeley. And at this point, if you have a motion you want a robot to master, Jason's methodology can pretty much make it happen. So this can work directly for building video games. You build video games, you want your main character to move in a realistic way. You can have it sequence together motions like these and dynamically simulate how they interact with the world. Same for animated movies. How about real robots? Let's say you want to get this robot across this terrain. And once I find a good path, I want to control the robot to follow that path. High level control problem, that's actually a star search. If you have a cost function for this terrain, what would the cost function be? Where do you want to place your feet? Well, you maybe don't want to be next to a big cliff. The three on the ground-- the support triangle of that-- if you project down the center of mass of the robot, she'll maybe fall within that support triangle, because then it won't fall over. So there's a bunch of considerations you might have. When we thought about this problem, we had 25 features we came up with that we thought matter. When you run the search, or the value iteration, which is, more or less, equivalent to find a path across this terrain. But if you choose the trade-off between the features differently, you'll find different paths. So reward learning. How you do reward learning, you demonstrate a path. Demonstrating doesn't mean just drawing a line. It actually means choosing a sequence of footsteps that it executes on, and assuming it does well. It assumes you have a low level controller, but that's well understood how to do that. First time it's ever been done, autonomous vehicles. During the first eight miles of the race, Highlander gains two minutes on Stanley. After months of tireless effort, there's a lot at stake. Each one leaves the chute with confidence, a far cry from the first Grand Challenge, where many faltered within sight of the start. No robot went beyond seven miles in last year's race, and no robot has ever gone further than three miles in the history of autonomous cars. Stanford robot becomes first vehicle in history to drive 132 miles by itself. Five hours after leaving the starting line, Stanley now leads the pack, and just five robots remain on the course. To finish, they must wind through a treacherous mountain pass. After driving six hours and 53 minutes at an average speed of 90 miles an hour, Stanley is about to become the first vehicle to drive all 132 miles in a single trip. It will take Stanley six hours to complete the 132-mile journey. work, and was very impressive that, in fact, four cars finished the 150 miles. That's a Berkeley entry. Only motorcycle in the race. Now, what goes onto those cars? There's a few different things. There is IMU, like right on a helicopter, a lot of computers. The GPS compass. Regular GPS to get position. Lasers, where you shoot out laser beams. And based on how long it takes them to get back, you know how far away the nearest obstacle is in that direction. An urban environment will have a lot more obstacles. With HMM, you get 0.02% false positives of where there might be obstacles. Cameras are important, too, of course. With a camera, you can often look further ahead. You might wonder, why do we need cameras if we have already have LIDAR? LIDar sends out a laser beam, measures how long it takes to get back. But usually, it doesn't work beyond 50 meters. You don't get enough signal back. A camera will be better at that than a LIDAR. Somebody needs to tell you what is road, what is not road. Self-supervision is a trick that's very widely used to reduce labeling efforts. So the camera now knows all the red here is road. In urban environments, there's even more need to recognize. A lot of progress has been made this is video from 2013. So after 2005, 2005 was a desert race,2005 was a Desert race, 2005. The Google Self-driving Car Project has been working on self-driving cars for a few years. This was before deep neural networks were heavily used for this kind of thing. It's only getting better to recognize what's in scenes, thanks toDeep neural networks. So what does it tell us? Well, the devil is really in the details, in the long term. The future is very bright for self- driving cars, but we have a long way to go before they're ready for prime time. tail of special events that can happen when you're driving. You can measure progress by just demo videos, which is one way, and it gives you some kind of feel for what's going on. But the 2013 video is already very impressive. So another way to measure progress is to see how are these cars doing relative to human drivers. So left and right are the same plots, but the ride is on a log scale so you can see more detail. It's a number of events per 1,000 miles driven. Red there is human fatalities. Then yellow is human injuries. is between 10 and negative 2 and 10 negative 3 per 1,000 miles of human driving. In green is the Google slash [? wave ?] mode disengagement. It's when the driver decides they want to take control because they don't trust the autonomous system right now to avoid an accident. And we see that it's going down how often that needs to happen, but still a bit removed from where humans are at. Where does this data come from? If you test in California, you have to report this data to the DMV. so many decisions. If they're gigantic, use a lot of power. That's a problem. Let's see what we can do to build smaller networks to make decisions. What else did we not cover yet? Personal robotics. I want to spend a little more than two minutes on that, so let's keep that for Thursday. that's it for today. Bye. [SIDE CONVERSATIONS] [Side CONversation] [sideconversation.com: Do you know more about this topic? Email us at jennifer.smith@cnn.com].

ROUGE-1: 56.82, ROUGE-2: 54.06, ROUGE-L: 53.34
BERTScore: 72.30

==============================================
==================== [9/100] ====================
Summary:
So let me say here just the repetition, normal, inferior. Let us say we are talking about price of good 1 has gone up substitution, income these are the effects and overall. When P 1 goes up subs because of substitution effect x 1 will. Come down. And for income also because of income effect it will come down. So, overall it comes down. While inferior goods substitution effect quantity demanded would come down while income effect is Up. Up. Can you give me an example its very very difficult to find Giffen good in real life why? Sir, like if Gucci is a brand and it is. Prices comes down by significant amount. No one could buy a Gucci, it is at that level. only because of it is prices. I am not certain about this statement then when price of these goods would come down then people would not buy what you are saying. No, no if some purse is very expensive like 10 lakh rupees and it symbolizes your status. And other day it comes down to 1 lakh rupee. Then there is no point that the set of people who were consuming that purse that good for 10 lakhRupees to show their status would buy the same purse at 1 lakh Rupees because it will become more common. The consumption of these goods will go up because price has come down, maybe not same set of people would buy, but when we are talking about from for the market. And also see this is the another requirement here that income effect has to be larger than substitution effect it means significant portion of your income is gone in buying these items so that is not true. So, these luxury goods are not Giffen goods fine, it is clear? Let me give you just an example typically it is very very difficult to find GIFFen goods. You know if you take an example of potato that I gave you earlier and it was it was talked about for a very long time in economic discipline that during Irish famine the potato was Giffan good. for meat and other food products. To get enough calorie; they had to increase the consumption of potato. So, in that case if this story is true then potato is Giffen good ok, but the problem is with this the second requirement that income effect is larger than the substitution effect. Typically this is not fulfilled that is why we have very-very hard time getting finding out, figuring out Giffsen good in an economy. It's very hard to find out what's good.

ROUGE-1: 65.96, ROUGE-2: 63.63, ROUGE-L: 65.05
BERTScore: 76.10

==============================================
==================== [10/100] ====================
Summary:
which we are to for next week and here and I'll talk about that actually week from today because it's callay on Monday so it will get behind but if we get any further behind I'll have to make it up sometime the but if you don't have that you be copies available upstairs is it c um come to my office okay to dany's office he doesn't have copies of it there that's six six upstairs in the first floor immediately after CL and then on the next Friday I will talk about the parts in the in the inquiry that were assigned and also a that essay of of the oral concept. and the compact of government and I'll talk about that in a moment and the latter is actually is a compact which I'll mention but it's a Act of fiduciary Trust on the part of the people now the idea is that for a regime to be legitimate LX view has to be such that beginning in this state of equal right which is to state ofequal political jurisdiction now and that you have to keep in mind because it allows for a society and various forms like families and tribes and so on and even tribal band it's not about political jurisdiction. The way in which he described absolutism of the kind of he's objecting to is going to be thrown out um and the has if his premises are correct more arguments than he needs. If you're rational you're not going to agree to submit yourself to an abolute monarchy or any form of abute arbitary power and then and there other restrictions so if we go through it will turn out that aism in the form which he's attacking it gets thrown out by these restrictions. Mo's view is that although of course one is bound I'm sorry one is Born Into into society as a matter of social fact biological fact and so on one is not obligated through the political institutions until one gives at least some consent to a regime. He's here opposing filmer who believe that people are born into a society and that they are naturally subjected to it as a result of growing up in it. He argues that people have as were no choice they are bound to a particular regime. the Age of Reason some form of consent now it's unclear the form in which is tast whether it's an oath of fidelity to the crown upon inher say the family property or whatever it's not expressly said. There's a distinction between express consent and P consent Express consent incorporates us into society as full member and as a Perpetual or presumably taxic consent does not do this. The point for us that's important is that when you read hum's account of the original contract he gives arguments against unlocks View and you have to ask yourself how effective is K's argument against each of these two parts. legitimate form of regime and the other is the conditions under which. particular individuals become bound to say the regime of England as opposed to the. regime of France. How does that happen and you want to ask in H's case which of these two and possibly both are his or effed okay then I will go on with this other question. I want to talk a bit of uh today and it may seem as if I'm getting bogged down in some points of n only theory of constitutions and so on but pension history. exclusion crisis of 1679 and 81 um the original part of the second CH was written it believe about 79 and 880 and then other chapters that were were added in 81 83 and two chapters added after. Now by definition a mixed Constitution is a constitution in which two or more constitutionally defined agents let's say share in and each have a part in What L calls the legislative power that is the supreme power in the constitution is the Legislative power. In the English case of course it's the crown and Parliament so we're only actually dealing with two agents in this case and neither is supreme so we want to say that they are coordinate powers. In mock terminology the crown and the whole combines within itself in this one constitutional agent what call the executive and and Federated power now. In the English case they essentially just these of two agents and we can then we only have to call that two we don't have an independent perhaps in our case a coordinate power of the Judiciary that's the key reality of our system now consequence of there being two coordinate powers and both in a way equal. The crown cannot govern without Parliament is depending it depends on that in general the tax monies and is to enforce and has the duty to enforce the laws. means that is there's no legal framework within which that is within the Constitution for settling the conflict there is no way to do it at law. In paragraph 168 he says if there is a conflict of the sort then the people have the right to appeal to Heaven which is a euphemism for for go to war that is Civil War and uh the power then refs to them and they have theright of resistance I'll come for that the moment now I might mention that in our constitution there are devices that tend to prevent this sort of conflict from happening. of Andrew Johnson although didn't past and it tends to make it politically impossible for president to persist over a period of time and a long drawn that conflict of with Congress so I might say that today checks then has this effect and comparable things were not available in the 17th century you had not yet institutionalized these various devices. Mar's problem is to justify existence of the crown in this kind of situ situation now now the source of Lock's constitutional Doctrine the source and thought is a book where at least is belied to be. the political Community as a whole and the people are then free uh to exercise their Liberty and to establish a new and different form of government with the different powers assigned to various coordinate con constitutional agents or else if they don't do that they can take necessary steps to restore what they believe is the a traditional form of the Constitution which has been violated by conduct of one of the Pres Powers so it was laon's view in this book that actually the English government was dissolved in 1642 so what Mark is saying something analogous to that that it was again dissolved in the course of the exclusion crisis in 798. before the view of next con Constitution and he says that the crown is in a powerful sense uh Supreme 151 now so much for Lock's problem and an indication how he attempts to answer it View and then I'll go into this in some more details now the significance of this for us is the following which I will go on some that later namely that we want to make a distinction implicit in in Lock's View and in aon's view between constituent power and ordinary power. Now by constituent power I mean the power of the people to determine the form of the Constitution oh it is the power that is exercised by the making of the or placing the political Authority in a certain form of regime. This is a compact between the members of the political Community to do something they need to establish political Authority. It is not the contact and not a contract is another term not favor term with the government or with the Agents of the government. We want to think St from the establishing of political Authority in whatever form the majority shall decide it shall take unless within the social contact with some Proviso that it has to be greater or other than a majority so that action that takes place in the second part will be a fedu will be the exercise of this fiduciary power U. it doesn't make the king for example the compact citizens with each other and there is in fact no such contract contacted government in LW and there isn't in h either but other contract doctrines some sometimes as a talk with a both but here there's only the one contact. The concept of Mages power as a fiduciary power the point of that I think is to emphasize the constituent power of the people. The people always had this right had this constituent power it isn't and cannot be alienated and that in the case of a conflict between the various coordinate agents that it establishes in the form of theim. power as a p power it connects up with the idea that political Authority is the right of making laws only for the public good says that the very beginning in three since given all of the constraints on parties to the social compact it can not be given uh for any other purpose now I don't know whether I ought to do this I might Ting out kind of what the form of thesocial compact might be. We think it just as AAL and express uh consent we hereby compact with one another each with all and all each it's better to unite into more non political Community or political society. to comply with the loss of political power as defined say in section three political power of the purose of community. We cannot act irrationally so this has to be rational agreement it doesn't violate any any Clauses of or duties that are consequence of fundamental law of Nature and so on. I think I'll skip over that um but it's sort of an exercise I believe to try to uh write it down now I'm want to say where two about mck's view was not accepted by the other wigs. changed his mind he thought perhaps it was not all together safe never knew in England the English were regarded in those days as very unstable people uh and not now we think of them as how and settled down or any rate 200 years after that they we regard as a model and longer of stability and and political common sense. Mark was afraid well who knows uh may be different I don't want people know what I said in the past it might be unsafe. He didn't want to have to flee to Holland again but his view was that Charles II then had violated his trust. government is dissolved people are now free to establish a new Constitution and to change the powers of government. Mark says nothing about the details of of this process that is how does he Enis that this constition power is actually to take place he doesn't give any institutional account of how he supposes actually might be done laon is also vague on this he says something has the idea that it would begin in the county courts and they organized there and would then they presented Des sent from there to a parliament. in that case but the implications are quite are quite uh obvious in some sense this is inly radical U Democratic Doctrine or it could be although I don't pain that either of them or actually what we would think of today is either Republicans Or democrats of come to that in in a moment. The point is is not surprising those that the wigs rejected this do and no doubt they did so partly because of the radical implications if thought through of L's View and it might have been a politically unappealing Doctrine so far as in might estimate. Nation than the other now why did L refuse to alter his view I think we have to assume that he didn't change his mind and he persisted in the doctrine that he formed earlier in 79 and 880. I think partly because his views are more radical than the standard view of his college that that would be one reason but also because he felt I think that it was inconsistent now there isn't this view in the trus but if one sort of HS it through perhaps one can see that it is any rate in danger of being insistent. he found in lawon and of which he gave a very clear and re statement is consistent and it presents he thought a more or less adequate account of the basis of sovereignty in a constitutional regime. What is important I say is the not formulates or we can find in this view this the distinction between constituent and and ordinary power and the idea of power is is connected with the motion of aary trust now the this distinction between this difference andordinary power raises the question. What I did was to see the importance of this view formulate in a very brief and readable clear manner I think. of how this constition power gets expressed in institutions and may effective you see it's all very well to talk about power and say that there is such a thing and talk about it uh coming into play when there's this kind of a conflict but if you don't have some kind of ideas how to be expressed in institution and how it can be made effective then it's always some extent this problematical. We may want to think of certain basic rights of the people as protected by the Constitution as also institutionalizing the basis through which and institutions through which this constituent power can be expressed. protected it's the importance of this notion now I'm not I want to mention at the end I gu about the last for some minutes um I'm going on to mention a witness in lock view from from our standpoint. The fact that is clear from paragraphs say 138 to 40 particularly 40 and 157 to8 that Mark is presupposing and taking for granted that only a few people vote. Mark is not arguing that point one way or the other taking it for granted and also when he talks about property he's not attempting to justify property in the sense of explaining it and justifying it. about an institution which is politically Tak from point of view everyone accepts D's argument had been that MOX or any social compact view or contract view the earlier agreements could not account for prodate property. "In that sense it's not a justification but attempt to explain how property could arise within the social contract cont well there are has it ought to distinguish three kinds of inequalities" "The right to vote is only shared by a few people now the question is that L lawr to argue that beginning with a state of equal" Right and going through all these agreements the contact of society would take place consistent all these other constraints and and yet the form of regime would be one in which most people did not have the right to vote and how could that come about. We don't have a clear explanation in L of how that might come about also we don't know who is included among the people uh when M talks about it excludes a lot of people excludes those that are dependent or some kind of servant it includes women. certainly thought that everyone those most people had what we might call Freedom of opportunity had some opportunity to accumulate the amount of of land and me tackle in order to be able to vote so it was not let's say cast system which was uh one could not by social institutions cross from one to to the other. But it would probably hard for most people um and what I'm looking at it from the standpoint of those who are born into a family that say doesn't have a right to vote how can one account for that on this scheme? form of a regime that excludes most people from actually voting I we might say adding on the condition provided that everyone has or most people have the opportunity to mer and gain and to acquire that amount. I believe that Mark more or less achieve his objective in this book which is to give an argument per it's easy to argue against but to give a coherent argument for the right of resistance in mixed Constitution. It isn't a criticism of what M does in terms of his aim but from another point of view we want to free the notion of constition power from being exercise subject to historical conditions. and who does not have the right to vote and what the conditions on it are maybe we want to free it from that of course what I'm thinking of eventually um is that that that would be one motivation for introducing an idea like the origal position that say it's a way of conceiving how con power might be exercised. No point in criticizing someone for something they didn't intend to do okay well I think it's stop so remember there's no class here Monday so the next class here will be next Friday.

ROUGE-1: 64.47, ROUGE-2: 62.96, ROUGE-L: 61.85
BERTScore: 77.22

==============================================
==================== [11/100] ====================
Summary:
David Kaiser: Today we're going to be talking about the kind of invention or the hybridization of a whole new subfield within physics that now is often called particle cosmology. We'll talk about institutions, and politics, and some broader shifts in the field, out of which come this new now quite flourishing subfield. It studies the smallest units of matter, the fundamental forces and elementary forces. It is actually very cool, and it's also flourishing by any measure. It's a fairly new invention. This whole field of study came together fairly recently in historical terms. constituents of matter. And it asks about what role they might have in shaping, really, the fate of the entire universe. It's one of the best examples we have of how we now use our tools about quantum theory and elementary particle physics to try to make sense of and, in turn, be constrained by measurements. The field is doing pretty well these days by other measures. Its annual budget just within the United States is on the order of $1 billion a year. That's if you combine spending in this subfield from the National Science Foundation, the Department of Energy, NASA, and other federal grants. On average, there are on average two new physics papers, two new preprints posted to the central preprint server archive.org every hour of every day just in this subfield. That's averaging over 24 hours a day, seven days a week. So it is really a booming, booming subject of study. And I find that all the more astonishing since this field literally didn't even exist 45 years ago. So this is a $1 billion area of study with devoted colleagues all over the world, not just here in the United States. or particle physics and that it somehow this set of ideas that bubbled up in the mid-1970s of that we'll look at today. And so there's a lot going for that explanation, but it's also, I think, really, really quite incomplete. So of the sort that we've been looking at throughout the term, we'll be talking about some changes in institutions, in training, in broader politics, and the support for science, and that these shifts were deeply consequential. In the 1950s and '60s, physicists in two different subfields were focusing on the question of mass. Why do objects, say, resist changes in their motion? Was there a deeper origin or way to make sense of this common notion of mass? And that helps us trace the precursors for this field of particle cosmology. Then we'll take a look at some of the broader institutional shifts that were also coming to be very dramatic, and some of them quite unexpected, that also helped propel this new merger of fields. Einstein was inspired by some of Mach's writings on this. Mach himself didn't call it Mach's principle. But it was attributed to Mach by Albert Einstein as early as 1918. So from the early days of the study of general relativity, it was often framed as a question. Do we have to think about the distribution of matter throughout the whole universe in order to make sense for why this block slides down this inclined plane at a certain rate? Local inertial effects, are they somehow tied to cosmological distributions? The problem of mass was given a concrete form by Einstein's general theory of relativity in the 1950s and '60s. The idea was should we be constantly paying attention to the global distribution of matter and energy when we try to make sense of local phenomena associated with mass? So that was a very challenging question, and we'll say more about it soon. But that was one of the ways that the Problem of mass took form. It was given form by specialists who were pursuing things like Einstein's General Theory of relativity. acceleration throughout the 1960s, a number of high-energy theorists were trying to put together these highly symmetric models to account for things like the nuclear forces. We looked at one example of that at the end of class last time, Quantum Chromodynamics, or QCD, which was really coming together in the early to mid 1970s. There were other instances of that, cousin models, similar kinds of models that were getting a lot of attention for the other main nuclear force, for what's called the weak force. Self-evidently of short range, unlike gravitation or electromagnetism, which, in principle, can extend arbitrarily long distances. The nuclear forces really exert themselves across nuclear dimensions, very tiny fraction of the size even of a single atom, let alone macroscopic scales. So the idea was could have finite range nuclear forces if these force-carrying particles had a very large mass. That will make it very unlikely for that force to be felt across a verylarge distance because of the whole set of ideas about virtual particles. uncertainty principle. All well and good, but the problem was with these new fancy highly symmetric models of the nuclear forces. So you can have one or the other. You could have a short-range nuclear force that does not have any of those fancy symmetries. So this was a pretty substantial challenge. It got lots of theorists very exercised over the 1950s and especially 1960s, which is really like, why do these particles have mass at all? Can we account for mass of these elementary particles in a self-consistent way? The Brans-Dicke theory of gravity was published in 1961 by Carl Brans and Robert Dicke. Their idea was to try to go back to this notion of Mach's principle and more thoroughly account for it. Even though the ideas were bubbling up around the same time and often published in the same journals, they still were embedded in quite different research traditions and conversations. Theories of mass came from members of the gravitation and cosmology crowd on one side and the high-energy particle physics community on the other. for that within a quantitative theory of gravity. So they wanted to modify Einstein's general theory of relativity in a very specific way to try to address this question of mass. So their idea was to introduce a whole new kind of matter, a newkind of particle in nature. They labeled it with the Greek letter phi. And now the idea was that instead of having a single constant unit strength of gravity labeled by Newton's constant capital G-- that's the G that's in like Newton's force law. F equals G M1 M2 over R squared. is actually not a constant? What if the strength of gravity could vary across time and space? So it was an attempt to modify Einstein's theory of general relativity. In Einstein's version, you can represent Einstein's general theory of relativity by an action, in a sense, by writing down a Lagrangian. This R is one of those geometrical objects that he had to learn about from his friend Marcel Grossmann because Einstein had cut too many of his math courses in school. Geometer's tool of quantifying the warping of space and time is called the Ricci curvature scalar. multiplying that is this constant, this unit strength of gravity in Einstein's theory. So what Brans and Dicke do is say, well, let's replace G by 1 over phi. So now 1 over G becomes phi in the Lagrangian or in the action for gravitation, where in principle phi, the local strength ofgravity could change across time and space. their version would depart from the ordinary behavior from general relativity. The idea is that if omega is a very small number of order 1 or a fraction of 1, then, in some sense, it doesn't cost very much. So as omega becomes larger and larger, the field becomes more and more wobbly. And so, inSome sense, you're stiffening up the trampoline. It's like saying you can have quite dramatic differences in the local strength of gravity because this field phi could be wobbling. field is much less likely to vary either over space or time. In the limit that omega becomes arbitrarily large, then phi, in a sense, can't afford to vary at all. The kinetic energy cost is too high. And so, on average, the field doesn't change at all, it acts like a constant. So you get back to the Einstein-like limit. So they had this very clever fudge factor, a coupling constant, so that, in principle, the local strength of gravity could be changing. Carl Brans and his advisor Robert Dicke suggested a new form of matter. They'll label it by the Greek letter phi. It extends to all of space, and everything else interacts with it. And meanwhile, phi very locally affects local inertial effects. So this would be a way to incorporate Mach's principle going beyond even just Einstein's version. It would take into account Mach's idea that the effects of this strength of local strength of gravity right here right now, really is attuned to the broader cosmic distribution of Matter. certain elementary particles have a short range if we can't accommodate a mass while keeping this symmetry? This is now they're back in this question of things like the nuclear forces. Could you have nuclear forces mediated by the exchange of particles? Could those particles themselves be very massive? So they don't go very far-- so a short-range force-- and yet, still be respecting the very symmetries for which people had invented those particles in the first place. All this work was bubbling up between 1961 and '64, again, often being published in that same journal as the Brans-Dicke work. Goldstone was among the very first to show this. If you adopt a certain kind of characteristic shape for that potential energy function, then you could accomplish what they came to call spontaneous symmetry breaking. So the idea was, at the level of the governing equations for these nuclear forces, you would continue to assume that these force-carrying particles really were genuinely massless. They had zero mass, just like the photon from electromagnetism. So that would preserve all the symmetries. And you wouldn't put in any symmetry-breaking. terms by hand. You'd leave those particles massless. However, you'd add in a new additional form of matter even beyond those force-carrying particles. It's what's now called the Higgs field. That separate field isn't responsible for the nuclear forces. But it's responsible for giving everything else the masses that we measure, including those forces. The equations are perfectly symmetrical, in this case, by a simple left-right symmetry. So the equations respect the symmetries. But this is a dynamical field. seek its equilibrium. The governing equations maintain the symmetry, but the symmetry is broken spontaneously when the system relaxes to some lowest energy state. So now once this scalar field, once this what we now call Higgs field gets anchored or gets stuck in one of its local minima, it now acts like it has a molasses. It actually is stuck at a nonzero value of its field. Instead of being stuck at the origin, it's stuck at some non zero value. example, interact with phi, then, all of a sudden, they have drag this field around. They start acting as if they have a large mass. It's an induced mass coming from this spontaneous symmetry breaking. So now, again, you can have your symmetries and your short range. You can have his cake and eat it too. It was a lovely idea. It also was introduced right around the same time as Brans-Dicke also as one way to try to get to this question of why do objects have mass. The Brans-Dicke field phi seemed very exciting. It got a lot of attention, as I'll say more about in a moment, because it offered the first really concrete quantitative alternative to Einstein's general theory of relativity in nearly half a century. And so that helped to spur high-precision tests. Depending on the value of that parameter omega, there might be really measurable astrophysical effects between whether it's really what Einstein said or this other seemingly self-consistent alternative. a way forward to be able to maintain these very fancy, very abstract mathematical symmetries of the nuclear forces and keep them short-range. The force-carrying particles could become massive due to their interactions with this all-pervasive field even though they had no intrinsic mass on their own. So that was answering a separate set of puzzles and quandaries. No one suggested, at least in print, that these two scalar fields with the same Greek letter might be similar for nearly 20 years. A paper is considered technically renowned if it accumulates at least 500 citations in the scientific literature. So each of these papers-- the Brans-Dicke paper and the Higgs papers-- became technically renowned within fewer than 20 years. These were getting a lot of attention very quickly. So on the right-hand-- excuse me-- on the left-hand side in red are the worldwide citations to the 1961 Bran-Dicske paper. That was the gravity-type paper. And in blue are citations just to Peter Higgs's papers, not even counting the comparable number. that went to Geoffrey Goldstone's early work. In blue, I'm plotting just cumulative citations to Peter Higgs's work specifically on what we now call the Higgs mechanism. And again, they cross 500 within fewer than 20 years. And yet, only six of those-- so less than 1%-- cited both the Brans-Dicke paper and Higgs papers in the same article during this whole 20-year period. So both articles are getting lots of attention, but within really quite separated communities. those fields were. So why was there such a sharp divide? Why was there no overlap? Were these fields just different from each other? Am I just asking a silly question? Why would anyone have ever thought that the Brans-Dicke field had anything to do with the Higgs field? Well, no. As we'll see in the third part for today, in 1979, two separate theorists working independently of each other actually suggested that the two fields might be literally the same, not just comparable or worth considering side by side. It was not a rule but a pretty widespread convention by that point that a field that had no spin-- so a scalar field-- would often be labeled by the Greek letter phi. The Greek letter psi was often reserved by this point for spin 1/2 particles. So the notation isn't super surprising that it was so similar. But the rest of it that is a new hypothetical state of matter, it pervades all of nature, everything else interacts with it, that's what gives rise to mass. more than just the letter that they chose. There was a lot of what we might have considered similarities. And yet, the two sets of ideas really were treated so separately. Let's look at what might have changed to make it possible, let alone feasible or likely for those theorists in the later '70s to consider these two scalar fields in a new light. Other questions on that? OK, I will charge on. But as usual, please don't be shy. Feel free to jump in with questions anytime. Robert Dicke was one of the last physicists of the 20th century who was really, really active and gifted both in theory and experiment. He invented Brans-Dicke gravity in the mid 1960s. Now you can do very precision monitoring of very weak or subtle gravitational effects, not just in the space of one laboratory, but literally on a solar system scale. To look for these effects, including things like human-built artificial satellites that can be sent throughout the solar system. the Sun, what was called solar oblateness. If the Sun is measurably different from an actual sphere, then that could actually have an impact on things like the orbit of the planet Mercury. If you have a more of an oblate spheroid from the Sun, then some effects that had been attributed to Einstein's general relativity might actually be different. So Dicke himself found some compelling evidence against Brans-Dicke theory, again, I'd say, to his credit. objects like the Viking Mars spacecraft and so on. By the end of the '70s, things did not look very good for Brans-Dicke gravity experimentally. That is all the tests were easily consistent with the predictions from Einstein's theory within experimental errors. To match all of these increasingly precise new experimental measurements, Brans' Dicke theory was not highly favored. In fact, Einstein's looked really good. So that's on the gravity side. Meanwhile, as most of you probably know, there was literally zero experimental testing of Brans's theory. evidence, a big fat goose egg nothing in favor of the Higgs-Boson until July of 2012, or if you're extra generous, maybe December of 2011, the first hints experimentally. So it wasn't a new experiment. The main story that's mostly given is actually hearkens to changes in ideas and, in particular, on the particle physics or particle theory side. And these are brilliant and beautiful ideas. These ideas are well worth appreciating. I just don't think of the whole story. asymptotic freedom. And actually, it's the reason why our friend and colleague here at MIT, Frank Wilczek, received the Nobel Prize. So this was work introduced by Frank and his then advisor David Gross, and independently by a different very young grad student at the time, David Politzer. And what they found was that the strength of the strong nuclear force, that QCD force that we talked about quite a bit at the end of last class session, that the force actually decreases with the energy scale. The effects that Frank Wilczek, David Gross, and David Politzer were talking about would be noticeable exponentially higher energies, right? Well beyond anything that can be achieved even today, let alone in the 1970s. So it's suggested that if one could ever get to really super crazy high energies, you might see some very qualitatively different behavior among nuclear particles-- really cool, a very interesting set of ideas. The present-day experiments at the Large Hadron Collider are here. idea from asymptotic freedom. The force strengths look like they might converge. It's not just that these two get stronger with high energy, and this one gets weaker. They actually might overlap at a single value. The idea was that maybe all of these highly symmetry mediated forces that we see as very different at these low energies-- they have very different behaviors and characteristic strengths-- maybe they're actually all signs of the same force. If you could scatter particles with that average energy, maybe all these three separate forces would have the same unit strength. a single force-- the grand unified theory, which would unite these three forces of nature into a single one modulated by a single force strength, a single effective charge. That was called GUTs. And you can see that only makes sense in the light of asymptotic freedom to get this strength to come down so that it can meet the very gently rising strengths of the two forces. You can probably get a sense for where this is heading. It starts to become a natural question to ask about conditions when particles could have interacted with literally astronomically high energies, cosmologically high energies. the 16 GeV, rather than 10 to the 3 GeV. So this became a natural reason-- this is the main argument-- for particle theorists to ask about things like a very high-energy cosmology. And the phrase that was often used at the time, a gendered term, was a cosmology would provide the so-called poor man's accelerator, the poor person's accelerator. And so this becomes the main reason that's usually given, the main kind of cause for why these two previously quite separated fields of study-- gravitation and particle theory-- were somehow merged. story. It's a large part of ingredients, but it doesn't quite add up. If we go back to things that we can investigate empirically, it don't quite make sense. The rate goes from roughly six or six and one half papers per year worldwide to around 21 on average. And not only that, you can see that the inflection point really comes quite a few years earlier than this purported cause from asymptotic freedom. GUTs became really, really hot years later. So many particle theorists got very excited about that notion. Grand Unified Theory, but not in 1974, more like in 1980. So if we want to account for changes in 1974-- and even the particle theorists weren't paying much attention till a half a decade later. The ideas were published in 1974. That's true. But as we've seen a few times in this course, just publishing an article doesn't guarantee that people will pay attention to it right away. And that was certainly the case with that work in particle theory. So even though it offered a very interesting reason to ask new questions, most people weren't asking those questions at that time. The US budget for high-energy particle physics fell in half in just four years. The field that had, so to speak, the most to lose or that lost the most during this reversal of fortune was particle physics. When particle physics is getting hit harder than any other field, you have twice as many people leaving that field than joining it. And that's where the people who stay within physics at all that you have a net outflow by a factor of 2 just within the field of people fleeing particle Physics. was cut most dramatically. And the job scene was most hard hit, and experiments looked like they'd be on hold and so on. And so in some of these reports that tried to make sense of the crash, like this 1972 report commissioned by the National Academy of Sciences, they single out particle theory. They say it's not coincidental that these young theoretical physicists in particle theory had the hardest time when the trouble came because this report claimed, at least, they'd been poorly trained. These symmetry arguments about nuclear forces. weren't being exposed to or responsible to the many, many other fields of physics. And so when trouble came, they were least adaptable. That was the kind of explanation that this blue-ribbon panel of leading educators, including many leading particle physicists themselves-- that was their explanation for why that one subfield fared so especially poorly, even as the whole field had trouble. And one of the recommendations is to forcibly broaden the training of young physicists in particle theory. the discipline, including explicitly more focus on gravitation and cosmology. So that means that more and more departments, including very elite trend-setting departments across the country, start rushing to offer new graduate courses in general relativity. Questions on that field, really for the first time in the U.S., start showing up regularly on the general exams for physicists across all fields, all specialties, not just those who wanted to study relativity. And you see a market response as well. You see a flood of new graduate-level textbooks on general relativity on Gravitation and Cosmology-- twice as many published in the 1970s versus the 1960s. vast majority of those came really in the later '70s, in the wake of these pedagogical reforms. So remember that big report comes out in 1972. You start seeing curricular changes as early as '73, '74. By '75, '76, '77, you start seeing, in some sense, the market respond with many textbooks being really rushed into print. Some of these textbooks were basically mimeographed lecture notes. And now there's very, very fancy books published in a more typical way. for more than half of my life, to his great chagrin. He's won a number of awards, gold prizes and that big award-winning fella. But the award that I take most pleasure in is the fact that he won Boston's Messiest Office. So yes, we'll work on that. Let's see. Fisher says, on the chart of interactions with the field strengths, are those groups? Yes. Fisher, thank you. That's right. So I was avoiding the nomenclature, but you're quite right. a continuous unitary symmetry, which is like saying you could rotate the electron field by any continuum amount, and the equations remain unchanged. The photon only has to mop up a relatively simple symmetry, the U1 gauge symmetry. Whereas SU2 was what I was pointing to when I was referring to the weak nuclear force. That's a discrete symmetry. It's a more complicated symmetry structure. And that's the symmetry group that these force-carrying particles-- the W and the Z particles-- are invented to enforce. broken at lower energies, they take on different features. It's another example of spontaneous symmetry breaks. And that's super cool and fun and lots more to be said about that. But that is, indeed, where that nomenclature came from. Any other questions on that? OK. Anyone else want to share stories of Alan's messy office? No, going once?OK. Then let me press on for the last-- the last part is pretty short, so the last little part, and we'll have time for more questions and discussion after that. There's a direct coupling between this new hypothetical field and this geometrical structure, the local curvature of space and time. And so this is really, again, playing the role of the varying unit strength of gravity. That's in place of Newton's constant G. If that field can vary, then you better include its kinetic energy with, Again, some fudge factor. that's all the Brans-Dicke stuff. And give that field its own potential energy with that very specific shape, that symmetric double-well type shape. Even the electromagnetic force is exponentially stronger than the gravitational force. The force between an electron and a positron when they're close together is exponentially higher due to their Coulomb attraction compared to their gravitational attraction. So why is there such a strange hierarchy? Why such a huge divide in the average strength of gravity compared to these other seemingly elementary forces? And so that could be. And so if phi becomes stuck at some large nonzero value, either plus or minus, then the square of that will be some large number, some large positive number. setting the inverse gravitational field strength. So why is gravity so weak? They suggested maybe it's because it's arising from some broken symmetry. Much like the Higgs-Goldstone mechanism, the field is dynamical, but it's getting stuck. Only in the broken-symmetry phase do we experience a phenomena that we are used to. So gravity gets stuck being weak because its local strength is arising through the Brans-Dicke field getting accurate in a symmetry-breaking potential. physicist with whom he again kind of accidentally wound up swapping apartments happens to have been immersed in gravitation and cosmology. And as Tony recalls, he found these stacks of preprints all around the apartment that looked interesting. He'd been an undergraduate at Princeton, Tony had. And there, he studied a little bit of gravity with John Wheeler for his undergraduate thesis. So by the mid to late '70s, he's now asking questions at this interface between his formal training in high-energy particle theory and gravitation. Lee Smolin was the other person who independently introduced that broken-symmetric theory in 1979-- same year as Tony Zee. He was actually, from the start, combining the two fields, both in the courses he took and eventually with his advising team for his thesis and for his dissertation itself. So unlike this accident of trading apartments in Paris and reading a few preprints, more and more members of Lee Smolin's generation were going through a training more like his, partly by design. entered with an interest in particle theory. They learned a lot of particle theory, but both formally and informally, coursework general exams and advising for theses, they were working from the start with a combined set of ideas and advisors. So I find this really interesting because there's a tradition for trying to think about how physics changes over time. We, often think about whole-scale theories, and one theory replaces another. And I think there's just that misses lot of what people do all the time. Few physicists today think Brans-Dicke theory of gravity best describes our Universe. But the theory is still very much alive today. In fact, interest in the field grew even as it was getting experimentally less and less favored. The idea that we're picking single theories and that they replace each other, I think, just misses this fine structure, says David Weinberger of the University of California, Los Angeles. He and Weinberger will look at inflation next time on inflation. does exactly the kinds of things that Smolin and Zee had been doing, trying to unify the Brans-Dicke and Higgs field. And in fact, there were a bunch of concrete changes-- some of them geopolitical, the ramping up the Vietnam War, worldwide economic crisis, huge changes in policy priorities within the United States. All these things on a huge range of scales are helping to mold what's going to seem natural or, quote/unquote natural, for younger people to consider doing. in turn, these new folks, especially people like Mike Turner and Rocky Kolb, went on to become real institution builders in their own right. So in fact, they were accelerates. Not only had they been trained to think carefully at this new interface, they helped really accelerate the trend. Turner and Kolb became the directors of the very first institutional center devoted to particle cosmology. It was called the Center for Particle Astrophysics at Fermilab when they were still relatively young in their careers. And so they were actively working to perpetuate this new hybrid area. new hybrid area, really of what becomes the poster example of particle cosmology. And as I say, including my own students and many people now around the world, it's now just totally bizarre not to consider the Brans-Dicke field and the Higgs field is somehow relatable or maybe even identical. So it goes from who even thought of it to who wouldn't even try that? What counts as natural can shift in a pretty short time scale. Those shifts can be driven as much by things well outside of the physicist's control, geopolitics, and national scale budgets. the hall from Alan's. And by a quirk of the old building 6, we had the same key. A single key would open the whole hallway. Couldn't get rid of it now. And one time, my parents were visiting. And I basically broke into Alan's office. They couldn't believe me when I described what it was like to try to work with this person. So I actually broke into his office to show them the safety violation, fire code violation, horror show that was the den of entropy. So that's a true story. soon, everyone. Soon, everyone will be able to play together again. Soon. Everyone will be playing together.soon. Everyone. Will be. Playing together again soon.soon,everyone. Everyone, playing together againsoon.soon,. everyone. soon, everyone, will be. playing together once again. soon.everyone. will be Playing Together again.soon! everyone. will. be.playing together soon. soon! Everyone. will play together soon! everyone will.be. playing again soon! soon.

ROUGE-1: 56.30, ROUGE-2: 53.94, ROUGE-L: 52.71
BERTScore: 74.02

==============================================
==================== [12/100] ====================
Summary:
The "Victoria" made the first circumnavigation of the globe in 1522. But this story really begins in 1494, two years after Columbus's voyage on behalf of Spain. Spain and Portugal, the two major seafaring super powers at the time, agreed to these terms in what came to be called the Treaty of Tordesillas. At the time the nations had their eyes on the same prize: trade routes to the Spice Islands in today's Indonesia. The spices found there were used as seasonings, food preservatives and aphrodisiacs. Ferdinand Magellan was captain of a Spanish armada on a voyage to the Spice Islands. The crew included a young slave named Enrique, captured by Magellan on a previous journey to Malacca. After 98 days at sea, dozens of sailors had succumbed to scurvy and famine. Enrique is believed to have plotted with the Rajah to have about 30 of the Spaniards killed at a feast on the beach. He may have been the first person to make it back toMalacca. actually circumnavigate the globe. Magellan's legacy lingers. He had galaxies and space programs named after him. The "Victoria" continued west, piloted by Juan Sebastián Elcano, one of the pardoned mutineers. The small vessel made it back to Spain with a full cargo of cloves and cinnamon, enough to cover the expedition and turn a profit. An obsessive chronicler, Pigafetta described the lands and people they encountered. With the help of a humble slave, he also compiled the first phrase book of native languages.

ROUGE-1: 48.19, ROUGE-2: 43.32, ROUGE-L: 43.62
BERTScore: 67.45

==============================================
==================== [13/100] ====================
Summary:
Ani was a real person, a scribe from the Egyptian city of Thebes who lived in the 13th century BCE. His Book of the Dead was a 78-foot papyrus scroll designed to help him attain immortality. Ani's epic journey begins with his death. His body is mummified by a team of priests who remove every organ except the heart, the seat of emotion, memory, and intelligence. It's then stuffed with a salt called natron and wrapped in resin-soaked linen. The wrappings are woven with charms for protection and topped with a heart scarab amulet. can imagine him happily tending his crops for all eternity. Can't imagine him being happier than when he was tending to his crops. Can imagine him growing his crops all day and all night. Couldn't imagine a better way to spend the rest of his life than in the fields. Can picture him growing crops all night and all day long. Could imagine him tending his crop all day, all night, all day. Could he be happier than he was right now? Could he ever be happier?

ROUGE-1: 34.15, ROUGE-2: 25.37, ROUGE-L: 29.48
BERTScore: 63.27

==============================================
==================== [14/100] ====================
Summary:
JUDY HOYT: We're going to begin this lecture on handout number 14. We'll be moving now to chapter 7. This will be our first lecture on chapter 7 on the topic of dopant diffusion and profile measurement. Today I'm going to give an overall introduction to diffusion in silicon. And here I'd like toGive an introduction to the basic concepts of why we care about the details of diffusion in Silicon. And what's being shown here is obviously a silicon MOSFET. of the doped regions. The placement of those regions determines many of the so-called short channel characteristics of MOSFETs. The doping of other materials, not just the silicon itself, but of the polysilicon gate affects things like gate depletion and limits how well the gate voltage controls the channel potential. So we really need to understand the placement of these atoms. Let's go on to slide 3. We know that the resistance in ohms can be calculated by the product of rho, the resistivity of the material, and the length of the resistor. In semiconductors or in silicon, we typically don't have a cube or a chunk of material. We're usually measuring the resistance of a thin sheet in the near surface region. So the resistance in rho L over a.bar divided by the cross-sectional area through which the current flows is known as the resistivity of the cube. This resistivity is given by, essentially, the electric field divided by. the current density in the material and is called the resistive. the width of the square are equal-- in this case, equal to W. The sheet resistance is just given by rho over the resistivity over xj. If the doping concentration throughout the sheet is non-uniformly doped in depth, then we can still calculate the sheet resistance. But at this point, we need to integrate. So it's 1 over the integral of the carrier concentration N minus the background doping concentration NB-- so that's just the net doping concentration-- times the mobility. function of the doping concentration. We integrate that over from 0 to xj. You can do that numerically, essentially, for an arbitrary doping profile. Experimentally, we measure the sheet resistance using a four-point probe setup. We'd like the resistance of the regions that are extrinsic to the device, such as the contact resistance, the source and drain resistance, to be no more than about 10% of the channel resistance. That is, we'd like to have the intrinsic resistance of a channel dominate the overall resistance. In general, as we scale devices, the channel length becomes shorter and the channel resistance goes down. We similarly need to scale down these extrinsic resistances of the source drain and the extension regions. To reduce those resistances, we would like to increase, in general, the junction depth xj. However, there's a problem that if we make the junctions deeper, it will make it easier for voltages at the drain to affect the current flow in the channel. So this two-dimensional spreading of the electric. has control over. field from the drain can attract carriers from the source, even when the device is supposedly in the off state. So we end up with something called drain-induced barrier lowering if the junctions are too deep. This results in, for device designers, kind of a fundamental design tradeoff for MOSFETs that is a design trade off between the series resistance versus the DIBL or the ability of the gate to control the current and turn the device on and off. And you can see the effect of these conflicting requirements to a certain extent by examining this chart. 1997 Technology Roadmap for Semiconductors. As we go smaller and smaller channel lengths out further in time, that's scaling down to shallower and shallower junction depths at the channel. And at the same time as we're scaling these junctions to maintain the good electrostatic control, the drain extension concentration-- so that's the doping concentration in the extension regions-- is going up dramatically. And that higher doping requirement is arising from the fact that we're making the sheet shallower. There's a fundamental physical limit on how much dopant we can put in the silicon and how much it will be electrically active. We need to find new ways to activate dopants to higher levels if we're going to be able to manage this design tradeoff. Being able to scale the device really amounts to, in the front-end processing to a large extent, to being able to control very precisely the shape of the doping profiles where the dopants end up. And what I'm going to spend some time in the next few slides is giving you examples from the present literature on device scaling. detailed device physics, but it's just to give you a flavor for why studying dopant diffusion is such an important topic. So let's go on to slide number 8 and talk about a topic called the short-channel effect. And this basically takes place when the distance between the source and drain-- that is the channel length L-- becomes comparable to the MOS depletion width in the vertical direction. And then that the source-drain potentials themselves from the sources and drain regions end up having a strong effect on the control of the current in the device. down these three terms, roughly, to calculate the threshold voltage. The third term, which is represented on the second equation by the bulk charge QB prime over WLC ox. That term ends up being smaller than it would be in the long-channel case. And this QB prime is smaller, and that ends up affecting-- that third term being smaller affects the Vt. Threshold voltage actually goes down. And it's essentially because charge sharing-- that some of the charge under the gate is balanced by the charge from the source-drain regions. This, I've got a reference on the bottom. There are a number of books, but this is one by Taur and Ning where you can look at this so-called Vt roll-off effect. And you can see, indeed, the threshold voltage is dropping or rolling off going towards 0 as we decrease the channel length-- same trend for the pMOSFET. And that's an effect that needs to be controlled as we scale the devices. And the way we partly control that is by controlling the dopant profiles underneath the gate. gate or the n-type regions under the gate in the pMOS in the channel region. So this is just a schematic cartoon picture of cross-section of a MOSFET. And this channel doping profile engineering is referring to these dark red so-called halo regions that are marked here that go around the perimeter of the source-drain extensions and this lighter red retrograde well regions. These two-dimensional dopant profiles are engineered or designed to minimize these short-channel effects. This is an extreme case of scaling, where we're trying to scale the MOSFET gate length down to 25 nanometers dimensions. In order to do this, there's a paper by Taur, Wann and Frank in 1998-- the so-called the super-halo profile. And you can see this is designed to create a fairly complicated two-dimensional boron doping profile. So, again, this is an example of how you need to control the doping profiles in order to optimize the device design. put reasonably high boron doping against the source-drain regions to help stand off the field. And so that's refers to this halo design-- very sophisticated. And there's also the doping of the source and drain regions themselves designed to be quite abrupt in both the vertical and the lateral dimensions. So what exactly are the effect of these doping profiles on electrical performance? Let's go on to slide number 13, which shows the short-channel threshold voltage roll-off and basically how the Vt varies with channel length. is not that sensitive to the vertical junction depth, as you can see by comparing the diamonds to the stars. So this lower variation of the Vt with L effective or with channel length allows a larger design window, which we need because there's always going to be some process variations in the channel length across the wafer. And this enables the technologists to push the channellength down to smaller dimensions. So it's not so much a fundamental improvement in device performance, but it really enables you to manufacture circuits with these shorter channel devices. refer to different lateral source-drain gradients. For lateral gradients larger than about 4 nanometers per decade, the Vt roll-off is just too large. The threshold voltage is approaching 0. You wouldn't be able to make a 25 nanometer MOSFET-- so, again, illustrates the importance of controlling the lateral doping profile and of controlling diffusion processes themselves. So given that brief introduction to the electrical effects, let me go on now on slide number 15 and talk about dopant diffusion fundamentals. really become large. In silicon IC processing, there are two different steps that we refer to in diffusion historically. The first step was so-called predeposition. And what this refers to is that you had an initial step in which the dopants were introduced into the silicon wafer with a required integrated dose into the substrate. The second process in creating a region of the wafer. with a certain doping is what is typically referred to as the drive-in. This is a subsequent anneal after the pre-dep that then diffuses and redistributes the dopant, giving the required junction depth. right resistance and giving you the right profile or surface concentration, hopefully. So, again, schematically we have two processes going on here. The first one would be the ion implant step or the pre-dep, which would result in the bright orange or the red region. And that has introduced a controlled integrated dose of atoms per square centimeter into the silicon. And then without introducing any additional atoms but keeping the dose constant, we then diffuse in-- or drive in-- that profile. It gives you a very precise control of the number of atoms that are introduced per square centimeter into the substrate. It also gives you very accurate depth control. The problems with it, of course, is as the implant process occurs at high energies, it actually damages the crystal to a certain extent. But unfortunately, the damage itself can enhance the diffusion rate. The dislocations or extended defects associated with the damage can lead to junction leakage, which is not desirable. We'll talk about how that affects the profiles in chapter 8. control the shape of the profile to certain types of shapes. And low-dose predepositions are very difficult, and that's a major limiter. So, as I said, except in very special cases, people typically use ion implantation for the predeposition step. Let's go on to slide number 18. In that case the dopants are typically introduced at their solid solubility limit. So you have some atmosphere of gas, say, that you introduce the wafers at high temperature into this gas atmosphere. And at the surface, you would end up with the solidsolubility of that dopant. get of these dopants if you did a predeposition at that temperature. At 1,000 degrees, you can get something like 3 to 4 times 10 to the 20 electrons per cubic centimeter by introducing arsenic into the lattice. If you introduce more arsenic than that, it may still be below the solid solubility, but you won't get any more electrons. It's not electrically active. It may not precipitate until you get up into the 10 to 21 range. out for a couple of reasons, mainly because it points to the fact that as we increase doping, we don't always get an increase in the electron concentration, and therefore a decrease in resistance. OK, so let's go on to slide number 21. And we're going to consider macroscopic models for diffusion. Later on, we'll talk about the more atomistic diffusion mechanisms and effects. And hopefully, you've read part of chapter 7, and you know that Fick's first law, which describes how the flux or the flow of dopant depends upon the doping gradient. steep you get a large flux, and therefore a large movement in the profile. As you get near the top of the profile, the concentration gradient is getting small, and then the flux is a little bit lower. The proportionality constant is called the diffusivity D. It has units of length squared per time or centimeter squared per second. And as it turns out, we'll see that D is related to the atomic hop rate or the jump frequency over some kind of energy barrier. Fick's second law describes how the change in concentration in a small volume element is determined by thechange in the fluxes into and out of that volume. The negative sign in this Fick's first law indicates that the flow is down the concentration gradient. In all the other cases and most of the cases we'll end up using in this course, we'll have to do numerical solutions. But for now, let's look at a couple of special cases where we can solve this equation by hand. In a steady state solution to the diffusion equation is a linear equation. So we can just simply integrate this equation twice, and we end up with a linear profile over distance. In fact, when we did the solution of the diffusion of the oxidant through the oxide during thermal oxidation, this is the equation that we actually use. This is implicitly the solution that we were assuming. And I think you'll recognize-- from the last few lectures, you'llrecognize on the lower pictures this steadyState solution is either in the thin oxide regime, we get a straight line. profile of the oxygen through the oxide during thermal oxidation. And again, in that case it's a concentration profile that's not changing with time. So, basically, the boundary conditions are that we have essentially a delta function at time t equals 0 and that the dose-- the integral of this delta function-- is a constant. And we find that the solution that satisfies Fick's second law is written down by this equation. The concentration is a function of x and time can be time. given by that constant dose Q divided by 2 times the square root of pi Dt times the exponential of minus x squared over 4 Dt. So that's what's known as a Gaussian profile. And the important consequence of this are that one, of course, the dose Q remains constant. That means then that the peak concentration-- so the concentration at the origin-- is going to decrease according to the squareroot of Dt over time. So the peak Concentration goes down. And in fact, what we do is we often call this distance-- we give it a special name. the profile. So let's go on to slide number 27 which shows pictorially the time evolution of a Gaussian profile. The left hand plot is on linear y-axis and the right handPlot is on a logarithmic scale. So, first, let's look at the left. And we there are three curves shown here. The red is for time t equals some time t 0. The blue curve is 4 times t0. So it's dropped by a factor of 2. And same thing by looking at the green curve. In semiconductor processing, linear scales for dopants are not all that useful. We often care about how the dopant falls off over many, many orders of magnitude of concentration. If we can assume that there's no dopant loss through evaporation or segregation at the surface, we have a relatively simple trick for solving this. See what the broadening actually looks like on slide number 28 and talk about the second case, which is a fixed dose Q, just like we talk about, constant in time. that the annealing takes place over a long time so that the initial profile is reasonably can be reasonably approximated by a delta function compared to the final profile. If those two assumptions are hold, then we can essentially solve it by assuming that we have virtual diffusion. We have a symmetric diffusion with an imaginary delta function of equal dose Q on the left-hand side. So, in fact, if we go on to slide number 27, that same the graph is shown at the top. surface where we have no loss from the surface. Again, it's a Gaussian profile. And the third case, essentially, that we can solve analytically is called the case of an infinite source. And what this is essentially an infinite. source of dopant which is made up of small slices, essentially each diffusing as a. Gaussian. So how are we going to solve for this? Well, actually, we do it by using the solution we had obtained previously. linear superposition of solutions for each of these thin slices. So we break up this infinite source on the left-hand half plane into a series of very, very small thin slices, each of which has a certain dose. And in fact, after some time t, we know how to write down for that little slice what the profile looks like. In fact, it's a Gaussian. So, now, if each slice then of all these slices can be added up, their Gaussians associated with their diffusion, we can then find the diffused profile. along the x-axis. That exponential squared over 4 Dt. So we're summing up all these Gaussians at the bottom of slide 30. The solution which satisfies Fick's second law is written down at the top of slide 31. The concentration is actually equal to concentration C prime over 2 times the quantity in square brackets 1 minus the error function of the argument x over2 times the square root of Dt, where the second equation and third gives you the definition of what we mean by theerror function. function is what the shape of this profile can be calculated according to. So let's look at slide number 32, which, again, the error function solutions are made up of a sum of Gaussian delta function solutions. And what you see is that here in this plot, the initial profile is shown in the dashed line in green. The subsequent profiles are time t equals t0 in black, 4t0, in blue, and 9t0 in red. And that the dose beyond x equals 0 continues to increase with annealing time in this infinite source sort of solution. above the solid solubility of the dopant. Then, in that case, at the surface of the silicon wafer the concentration of the dopamine is fixed. And the dose is given by this integral, which can be done integrating from 0 to infinity. So, again, now we see that this dose or the number of the integral of these curves on the right-hand side is increasing with time according to the square root of Dt. So we're getting a higher and higher dose into the sample. side the two different types of classical processes that we talked about in terms of their diffusion profile shapes. On the left is the predeposition case where we have, say, a constant surface concentration, assuming the pre-dep was being done by a gas phase in diffusion. And that at the different times, you can see the twice square root of Dt is 0.1, 0.5, and 1 micron. And so you see what's happening over time at the same time. shorter time. We have a certain peak concentration. That peak concentration is then falling or dropping for the second profile. And the profile is broadening, and then it falls again, and the profile broadens further. So that's for Q equals a constant, integral is constant, and left-hand side is for the surface concentration is a constant. That's just to get your eyes calibrated for complementary error function versus a Gaussian type of solution. Let's go on to slide number 35 and talk a little bit about dopant diffusion coefficients themselves. of the pot that are dopants in silicon. So, for example, if you look at boron, it has an activation energy here of 3.5 electron volts. And the prefactor is about 1.5. Thing to note is that n sub i-- the intrinsic carrier concentration-- is very large at process temperatures. When we get above that-- when the doping concentration is larger than n subi-- we'll talk about next time there's some interesting Fermi level effects that come into play. Boron, the only really available p-type dopant, is relatively fast. It can be up to a factor of 10 or 20 or 30 faster diffusion coefficient than the slower diffusers such as arsenic or antimony. So this gives you a rough idea of, when we talk about doping diffusion, what we're going to have to worry about a little bit more would be the fast diffusers-- say, boron. The other thing I want to point out with respect to this plot on slide number 36 is that earlier versions of the text had an error in this corresponding figure. The placement of dope regions is critical because it determines many of the characteristics of short-channel MOSFETs. The time evolution of a doping profile, if the case is simple, is governed by a fixed loss-- the so-called diffusion equation. That's why we spent so much time calculating in great detail dopant diffusion, as we'll do over the next three or four lectures.right values. One way to check that, of course, is to back to slide 35 and actually compute directly with a calculator the diffusion coefficients. of cases where there are analytic solutions. We talked about the diffusion of a Gaussian profile with a fixed dose. We apply this diffusion to a constant surface concentration. And finally -- we talk about the diffusion of a complementary error function, which we apply for a constant level of surface concentration. The diffusion of this error function can be applied to a fixed level of surface concentration, or a constant level of substance on the surface, for example.

ROUGE-1: 57.43, ROUGE-2: 55.48, ROUGE-L: 54.54
BERTScore: 74.64

==============================================
==================== [15/100] ====================
Summary:
We were looking at our atas model and we had real GDP a real output whatever you want to call it doesn't really matter we had our price level that aggregate demand short-run aggregate supply long- run aggregate supply and we were at some full employment level of output which we called YF. We had some Price Index equal to say 100 and we said ok what happens if we have some increase in aggregate demand. We saw aggregate demand increasing and we see aggregate demand doing this so we had some increase. in output to say y2 and we saw some. increase in the price index to say 110. see happening is that firms respond to this by saying we want to make more output right we're seeing profits increase so they increase output out here to say y2 but in order to do that right unemployment has to fall employment rises so we saw unemployment decreasing you see employment increasing right which makes sense if real wages are falling firms want to hire more people not less. Eventually people get to the point where they say look you know this stinks my real wage is actually falling you have to give me a raise and when they do that we see the short-run aggregate supply curve actually began to shift back in. and point c is what price level prices went up all right it just takes more green pieces of paper to buy the same goods and services at C as it did at a let's see what happens if we have a decrease in aggregate demand it's gonna be very similar but let's run through it anyway. With this decrease here's our real output here'sOur price level so same thing is before you start off at some full employment level of output why I for just have our price index equal to be 100 it's just the easiest number I think for students to deal with so we have this price index now. firms are seeing here here they're seeing output prices decline and input prices stay the same. What are they seeing in terms of profits exactly here we're seeing profits actually decrease. What's happening to people's real wages they've gone up alright if input prices are staying the same and output prices are declining real wages are actually increasing. firms respond to that increase in the price of labor by doing the same thing that they do for everything they use less of it right and so we see output begins to decline we see unemployment increase and we see employment decrease. level of output unemployment Falls to this natural rate of unemployment employment Rises the only thing that's different is the price level Falls to 80 it takes fewer green pieces of paper to buy the same goods and services at sea than it does at eight now how often do you see prices falling generally pretty often are not very often not very many all right so we can make this model more dynamic if we think of this not being as the price levels but the change in the pricelevel these suit I'm saying so and same thing for here not output but kind of like thechange in output. right so we've got a lot of excess labor but what's true about the price level what did it do that's going up right well this price level increasing so here we have both inflation and we have unemployment it's not inflation because demand pull its cost push inflation here. People's real wages decline so they should be wanting to hire more people right yes but they don't write because there's been something that's changed the fundamental relationship of generally speaking when it takes to meet goods and services in the economy. important anymore so if these guys over here you're kind of going from A to B to C right same thing over here. What could we do if we want to return the economy to full employment what could we change. We could do this oops wrong direction all right I mean that's an option is what I'm saying. But doing that returns you to fullemployment but it also increases the price level right and remember I said if we think of this model dynamically is that not that this is the pricelevel but this is more like inflation than we've just gone permanently from one rate of inflation to a rate offlation. much higher rate of inflation whatever this guy up here is you know 120 or whatever he is a higher rates of the prices are increasing faster similarly if you have a increase in your short-run aggregate supply curve it's the exact same thing. You've got real output you've got the price level and you get the man short supply long line at supply curve here you alright say YF here you are a hundred all right same thing as before. We move basically back to point a alternatively rather than going. back to this higher price level we could if we wanted to which do you know you're going to return to YF at some point in time anyway you could do what you could lower aggregate demand somehow. If we make the model dynamic at a lower rate inflation let's look at our changes in long run because remember when we said the long-run changes it brings the short-run with it so here's our real output there's our price law here's a go get them in that supply long where that good supply is. we're going to see this change in long-run aggregate supply remember what was changing long- run aggregate supply the quantity of our resources quality of ourresources or our level of technology. We have this increase I'm going to call this YF - we see that output increases but which type of output increases our our real output our would we call this guy our full employment level of output right so our full Employment level of outputs actually going up. So we're gonna have a change in one of these things right we know that the long- Run aggregate supply curve is going to increase and remember the short-run is really just a special case of the long run. our ability to make goods and services using all of our resources is increasing right so we're seeing this increase in our full employment level of output. We're seeing an output increase from YF to Y 2 similarly you're seeing the price level fall or like I said if you want to make the model dynamic and you know look at changes in real output and changes in the price levels then you're looking at the rate of inflation declining but what's this guy gonna do overtime typically I agree with the man he's going to increase as well all right. we said for most of the 20th century this guy was about 3% now we're wondering is he maybe 2% I'll have to see but our real business cycle model over here said we're gonna see these ups and downs in economy are gonna see periods where it's increasing. We've got this general long-run trend that's going up at some point 2 percent 3 percent 1 percent 4 percent 12 percent whatever the number is. For most of human history it was this right it's some really low level of output. it's gonna be trust me I've been doing this for 20 years questions on the AAAS wanna yes so that's what we're going to talk about when we talk about fiscal policy and monetary policy. Changes in taxes and changes in government spending are also pretty obvious right if your taxes go up and the government doesn't give you more goods and services for that you have less stuff. If taxes go down and thegovernment doesn't change the amount of services that they give then you have more money in. your pocket right so you can change people's wealth by changing their taxes or by changing the services that they're getting in exchange. Keynes comes along and says famously and the long run we're all dead in other words yes eventually we'll get back to a but why wait why not go ahead and do something change aggregate demand and get you here to see. There's really no difference between a and seeing anyway other than the number of green pieces of paper it takes to buy the goods and services. Keynesian model has problems too it doesn't work perfectly either so that's why we have these changes in aggregate demand. We'll get to that when we look at fiscal and monetary policy okay so I will see you guys on Wednesday we only have the exam. We only had the exam we only has the exam so we will be back on Wednesday to talk about fiscal and Monetary Policy. We will be talking about the impact of the stimulus package on the U.S. economy and the global economy.

ROUGE-1: 56.32, ROUGE-2: 53.94, ROUGE-L: 53.50
BERTScore: 78.28

==============================================
==================== [16/100] ====================
Summary:
As a nurse you play an important role in teaching the parents about car seat safety. This education actually starts at birth before the child even goes home from the hospital in their first car ride. In this lecture we're going to concentrate on the main concepts that you need to know as a nurse. For exams first let's talk about the four types of car safety restraints that you can use in a motor vehicle. You can access the free quiz that will test you on this content so let's get started. lap belt should be used together when using this type of restraint and lastly is the seat belt. This sits the child forward in the vehicle using the car's seat belt and again both the shoulder and the lap belt should been used together. When selecting a car seat safety restraint you want to educate the parent that they don't want to solely go by the child's age especially whenever it's time to upgrade the car seat. The child's height and weight limits set by that car seat manufacturer should be taken into account. restraint instead they want to look at these other factors. They want to see how well their child's actually fitting in that restraint. There's some signs that you can tell if your child actually fits in thatraint which we're going to talk about here in a moment. Now let's dive into these different types of car seat safety restraints and talk about those main concepts that you need to know so first let's talk about the rear-facing restraint so with this restraint again the child is going to be backwards facing in the car. all the way up until that child is like a toddler or preschooler but it really varies depending on how that child's growing. The american academy of pediatrics actually removed that age criteria and just said whenever the child outgrows their rear-facing device is whenever they need to be switched now there are different types of rear- facing devices that you want the parent to be familiar with because they have different height and weight cutoffs so this is where it's very important that you stress again to that parent to become familiar with that manual. A rear-facing to forward-facing restraint is for a child up to 65 pounds. A convertible restraint is not mobile so you can't carry the child around in it like with the other one. It's important that the child's head is one inch below the top of the restraint. The straps of the harness at the shoulder should be at or below the child’s shoulders. You should not be able to detect any slack in the harness when the child is sitting forward- facing. in the harness so whenever you go to pinch it you shouldn't be able to pinch the harness together also the chest clip when it's buckled should rest at the level of the armpits on the child and that it's normal as a child grows to not have as much leg room in the back so you may start to notice that the legs start to come into contact with the back seat. Many car seat manufacturers are actually adding an extension panel to help with this since children are staying in this rear-facing position longer.

ROUGE-1: 35.95, ROUGE-2: 34.24, ROUGE-L: 32.49
BERTScore: 75.96

==============================================
==================== [17/100] ====================
Summary:
Today will be our first lecture on machine learning. Up until now, we have been assuming that somebody gives us a model. We want to build accurate systems. You get them from good models. And good models come from good data, and we're going to shift gears and look at machine learning, which is about how to acquire a model, from data and experience. The main topic for today is Naive Bayes models, but the real context here is that today will be Our first Lecture on Machine Learning. Machine learning is all about learning hidden representations and hidden concepts. We can learn parameters. These are the individual numbers and other details that determine exactly how our model works. For example, the probabilities that live in each conditional probability table of a Bayes net, that's an example of parameters. We could learn structure, so we could learn, for example, given a bunch of random variables, and then a. bunch of data showing observations of those random variables. We're going to work through some details of how the Naive Bayes models work. Then in the next few lectures, we'll work through a sequence of different different models. takes on machine learning that are going to highlight different subsets of the big ideas on this topic. We're going to have a couple running examples. One of them is that spam classifier that pulls out all the emails you don't want from your email. And something like digit recognition, we'll start to give you a window into how other vision tasks work. We'll see more in-depth examples and more structured examples of these kinds of problems later on when we talk about applications. as spam, and congratulations. You've just labeled some training data for a classifier. Somebody has to hand-label this data, and that can be expensive, or it can just fall out of the ecosystem that you have around you. So how are we going to make these decisions? Well, we have a bunch of data like what's shown on the right. I'll read you some of these. These are from an actual corpus, collection of data, that's labeled, that people use. This one is relatively small, and it's an older corpus, but this is a corpus of email that people used to test this problem. "To be removed from future mailings, simply reply to this message and put Remove in the subject" "99 million email addresses for only $99" "I know it was working pre-being stuck in the corner, but when I plugged it in, hit the power, nothing happened" "Had an old Dell Dimension XPS sitting in the corners and decided to put it to use." "I'm beginning to go insane. I know this is blatantly off-topic, but I'm beginning-to-go insane" very much an individual question which emails you want to receive or not. The boundary between what is actually spam, unsolicited commercial email, and emails you just don't want, this can be a fuzzy boundary. Some people just click on an email they wish people hadn't sent them, even if it's like from their mom. What is it about the top two emails that let you conclude that they're spam, and how could we automate this? Well, machine learning is going to do some amount of work, but something has to power this. probably something about "only $99" that's probably a sign of spam, but it's not like those words couldn't occur in ham. For example, maybe any dollar sign followed by some numbers is a bad sign, and that's a feature that abstracts over individual words. And so what we're going to need to be able to do is build a model that can aggregate that information, combine all of those little bits of weak evidence, manage that uncertainty, and then give us a prediction. In practice, for actual spam detection, a lot of the evidence of spam versus harm comes not from the word or even the content of the email in any way, but rather, its relation to other things in the ecosystem. For example, is the sender of this email in your contacts? Well if it is, this is probably not spam, even if it's got some sort of marginal contents. Has this email been widely broadcast within a short amount of time? Your email account can't tell this, but your email account provider can. these features, and then some match is going to happen in the middle where we're going to build a model and make predictions. We want to be able to predict labels of new images that are not the ones we've already seen, OK? So that's actually subtle, but it's super-important. We are not, like this is not-- This is not the sort of the Pokemon collection task here. We have to collect every digit, every image, right? Every image you see of a digit. is going to be unique. It's going to have to be at least one pixel off of something else you've seen. So you can't just collect all the data. You can get data that is similar, but then, in the end, you're going to need to generalize. What features might you use to detect digits? Well, somebody puts a grid of numbers. Your eyes and your visual processing system is already doing all kinds of processing. People will think about computer vision, replicate some of that processing. really noisy, and you're training set, they might be hard, expensive to label, because they're noisy. And then at test time, you're going to make mistakes because machine learning is not perfect. So people think about computer vision, think about invariances. What are better? We're just not all even going to agree on what the heck that's supposed to be. We need to find a way to make computer vision more accurate and more reliable, and that's where machine learning comes in. representations that if the thing gets tilted or it's a little bit lighter. It's not the exact pixels being on that we care about. But the pixels are something we could use. We could look at how many connected components of ink there are. What's the aspect ratio? How many loops are there? It's increasingly the case, especially for problems like this, that we feed in low-level features like pixels, and higher level features like edges. We'll talk about that in a couple weeks when we talk about narrow nets. some account activity and you want to red flag accounts that are suspicious. Automatic essay grading, auto grading, this can be a machine learning problem. Customer service email routing. You'd like to automate the routing of that. Review sentiment. Here's a bunch of reviews of my product. Which ones are good and which ones are bad? Have they gotten better in the past 10 days since the new announcement? And so on. You can do that with classification. You gotta do that before you can do things like translation. you will have enough information to go and build a basic classifier. But there's a whole bunch of detail behind all this. First thing we're going to do is talk about model-based classification. After today we'll look at the model-free methods. So what are the challenges? What structure should the Bayes net have? Today, we'reGoing to give it the simplest structure that could possibly work, and it turns out it often does. And then, the thing we are going to mostly talk about today is called variable illumination. We can do that with probabilistic inference, for example. is how should we learn the parameters of a model from data once we've decided it's structure? So here's what a Naive Bayes model would look like for digits. It's in fact super-simple as Bayes nets go. We say that the probability distribution over y, the class, and all the features which collectively basically are your input x, is the prior probability of the class. That's what lives at the bottom of the page. We'll be back in a few minutes. A general Naive Bayes model places a joint distribution over the following variables, y, which is your class, and some number of features, which you get to define. You're going to have to write code which extracts them from your input. The machine learning will do the work to connect the probability of that taking on a certain value up to the class. In addition, the way this joint probability is going to work, is you'regoing to have a prior probability of the feature. The Naive Bayes model will be linear in the number of features, whereas the joint probability distribution that you're implicitly describing is exponential. The thing we actually build is quite compact. All we have to have is y parameters, one for each class value, and then, for each feature, we need to have a little description of how likely that feature is for eachclass. And that's it. There's nothing new here. In fact, it's a simple case of inference by enumeration. to compute, the thing I actually want to compute is the probability of y, that is the distribution over all the different class labels, given my features. But I know that I can just compute the joint version of that, Y comma the features. What is that? Well if that were a lower case y, it would be a scalar. It would be an entry of the joint probability table. So it's a one-dimensional vector here that has an entry for each value of y. If I had all of these probabilities and I normalized, I would have the conditional probability of the class. The Bayes net assumes all the features are conditionally independent, given the label. Each one is the product of a prior probability of the class, which says whether or not before you see the evidence, this is a class that's common or not. How likely is it that the center pixel will be on for the number seven? These questions can only be answered by going to data.local probabilities. All right, so you compute all those products. You normalize them. You're done, OK? That's it. is we're going to need to figure out the prior probability over labels, and for each feature-- which is each kind of evidence-- we'll need to compute a bunch of conditional probabilities for each class. These things collectively, all these probabilities that we use to plug and chug and get our numbers out, are called the parameters of the model. So it has to come from data, which parameters we want. All right, let's see some examples of what these conditional probabilities in a Naive Bayes model would look like. 1 to 0 is equally likely. If you're looking at lots of round numbers, maybe it's 0. You can think about why that might be. So these come from data. And this actually underscores the point that depending on the data, depending on where you are, it depends on what you are looking at. And that's what we're trying to figure out here in this article. We want to know what you think is most common in real data. Or are they all equally common? So 0 might be common. how you collect the data, it can actually shape the distributions that you are imagining are going to exist at test time. We'll come back to that as well when we talk about risk minimization. All right. In addition to the prior probability of each label, we can compute things like, what is the probability that pixel 3 comma 1 is on, given each class? This isn't a distribution over on or off. These are just the probabilities-- what I'm showing here-- just the probability of that pixel for each class. The standard model for text is to say that the features are the words and that the random variables are the word at each position. So you would say something like, well, I have a joint probability over the class-- which could be spam or ham or document classes, or positive or negative sentiment, or whatever-- along with the rest of the document, the words. And so again, this is a naive Bayes model, and-- but the random variable now are not something like we're-- they're not-- the presence or absence of individual words, they're the product across each position of. the document of what word is at that position. So this is actually interesting, because I have-- in the image case, I had lots and lots of features, because it's a big grid. But each one was either on or off, right? With a document, one, they can be of any length. And two, each position has a large event space. There's a whole bunch of words that can be at position 23 in the document. But for the purposes of detecting spam versus ham, it doesn't really matter whether a word occurs at position 24. that comes in is going to get a probability for each class. And there's going to be a race to see which class wins in terms of probability. So what am I going to do? I'm going to have to see the words that come in, but I'mgoing to, in the end, compute two things. Whichever one is bigger, that's going-to be my prediction. If I want to know the probability that I assign, I have to take these two numbers and divide them by their sum. In this example, 2/3 of the emails are ham, and 1/3 are spam. This underscores that just because there's some distribution that your data reflects, and then there's the real world. And if there's major, major systematic ways in which your data and the distribution it was drawn from in its construction do not match the distribution in thereal world, you're going to have issues. One major issue you can have is reduced accuracy. And in spam, the most likely word is the. word free. predict 2/3 chance of ham. Gary is not particularly likely under either distribution. Direct address, actually knowing who you're writing to, that's much more likely in ham. Most people aren't named Gary. All right. But if you look, suddenly now, if you stopped me and you said, OK right right right, I would say, "Oh, my God, what is this?" I would be shocked. I would go, "What, minus 1.1. What is that?" Now that I've seen the word Gary, I'm 10 times more confident that spam is real. Gary, would is one of those words that's actually quite common, but it's not asymmetric. You can think about these as belief updates. Evidence is coming in, my beliefs update as I multiply in terms of probability. Maybe makes me think a little more ham, because would is a nice, harmless, common words that occurs in natural text. But you can see how, like, it is not like I'm going to delete every email that has the word you in it. model, the way they're aggregated is multiplying their conditional probabilities. Gary, would you like to lose weight while you sleep? And if you look at this now, it thinks it's spam. Somewhere in there, somewhere around lose weight it changed its mind. You can see, weight is a pretty strong indicator. Apparently so is sleep. OK. So this is what it's like to be a Naive Bayes model. Features come in, you aggregate all of the weak evidence, and then you output. be weighed, and that's what's going on here in the conditional model. It's actually very common when you're multiplying probabilities to just add log probabilities instead. In the end, when you want to turn it into probabilities, you do need to sum them. And summing the logs won't do that. You need to do a sort of log sum, which one way to do that is to convert them back to probabilities by taking exponentials. That's actually not the way you would do it. You would sort of shift them by their minimum or their maximum as appropriate. word depends on the class and also the previous word. This Is a better model of language. Will it be more accurate for classification? It really depends. In general, it will be a little more accurate, but at a cost of having significantly more complicated conditional probabilities to estimate. How much more accurate will depend on how much more complex the probabilities are to estimate, and how many words there are in the whole word set. If you started, if you did prediction in this, and you cranked out a pretend document, it would look significantly more like a real email. to what degree the bag of words assumption is dangerous. If you're looking for a class which is not kind of strongly connected to the actual ordering, Naive Bayes is really good. Otherwise, you add other correlations like this to fix it. All right. Let's take a break now. We are now into the machine learning section which means we are done with the spooky Halloween time ghost-busting section. But I have candy. So during the break, everybody get up and come grab candy if you would like. Come up and grab some, please. I'm not allowed to take it home. [NO SPEECH] All right, we're going to get started again. Let me say, your candy consuming I would rate as middle of the road. You can come back up to the-- at the end of the class if you would like to grab more. Allright, so let's talk about training and testing. So we talked a little bit about we want to build classifiers. We're going on the basis of data. How the heck am I supposed to know what pixel 7 comma 3 is for the number eight? I've got to get that from the data. all of the spam with high accuracy. So there's got to be some connection between what's going on in your data and this future used to which you're going to put the classifier to. A lot of machine learning theory is really based on trying to say something precise about the connection between those two things. We're going talk about a couple things relating to training, the mechanics of how you do parameter estimation in this particular model. But really, the reason we're doing this is not just for Naive Bayes, or probabilistic model estimation in general, but to see examples of more general phenomena. of empirical risk minimization goes something like this. We would like to find the model, classifier, whatever, that does the best on our true test distribution. We don't actually know that true distribution. So instead, we try to pick the best model on our training set and hope there's a connection between those two. Today, we're going to appeal more to just directly estimation of probabilities, but by the time we get there, we'll have a much better idea of what the true distribution is. to optimization-based methods over the next couple of lectures, you'll see this more generally. It's usually an optimization problem. Optimize some quantity on my training set in the hopes that that quantity will remain optimized on the test set. So what can go wrong here? The main worry, and this will be a little abstract now. The mainorry is that you over-fit. That's going to be a problem. So you worry about over-fitting. There's ways you can-- first of all, there's a couple of different things that can gowrong here. Machine learning theory has the most to say about the first few things, right? How-- what's the danger in having a small amount of training data, which means high sampling variance? And then, you can have tons of data drawn from the wrong distribution. What would this mean? You spend weeks doing practice exams for CS189, and then you walk into the CS188 final. You're like, something's wrong here. I learned really well. I understand the concepts, but it's just not lining up. In general, when somebody gives you a big vat of data, you're going to split it into pieces. You take one piece and you say, this is my training set. Someday it'll all be your training set if you want it to be, but when you're doing experiments, you want to try a bunch of different things. Does this Naive Bayes thing work? Maybe a neural net. So things like that. This idea of the test distribution sort of being not stationary against the training distribution is something that's really important in the real world. to have a test set, which is not the real future test use that it's going to be put once it's deployed, but you need something that is not in your training data to check. This is why you might, when you're studying, take some of those practice exams and not look at them until right before the exam, because you need to check your understanding. And so we take our data and we break into training, where we learn our parameters, and tests where we check our accuracy. You go through an experimentation cycle, it looks something like this. Get your model and learning already, and then you're going to learn the parameters. parameters are things like what's the probability of pixel 73 for the number eight? Then there's hyper-parameters, like, do I want to have features for the lowercased version of the words in case I've seen the word, but never uppercased? Right? These are questions about, is this or this orthis going to work better? You always know you're training data. The question is, do you generalize? This can happen to your classifier too, so you always want to test your performance on data that was not used to train it. And there can be a slow leak of your test data into your training data if you're not careful. So you try not to peek at the test set, and that's another reason why I say don't test your classifiers on the test data.to see that today. we have held-out data, which gives you something you can peek at. I ran 20 experiments. How did they go? Am I doing well? Is this thing good enough to release? You need to have some metric, and there's a lot of possible metrics. An easy one is accuracy. For how many of these emails did I make the correct decision? Fraction of instances predicted correctly, but actually, that's actually not a great metric for spam detection. Any ideas why? What's wrong with accuracy? cost-- of different kinds of mistakes may not be the same. And so accuracy isn't always what you want. What you really want, is you want a utility here. You want to know what was my utility, and you should have different costs for these things. There are also cases like machine translation, where you're always going to be a little bit off, a little word here or there, but there's a difference between being completely off and a tiny bit off. And again, we're going talk a lot today and next time about over-fitting and generalization. Spam detection is, in some ways, a very poor example of a canonical classification problem. The problem here is not that you're test accuracy is low, but your training accuracy was also low because you didn't learn anything. We'll investigate these things formally in a few lectures. I had a really good question during the break, which I want to answer for everybody, which is, couldn't you just defeat this Naive Bayes spam classifier by pasting the word Gary 100 times to the end of your offer to lose weight while you sleep? Spam is being generated by people who are trying to defeat spam filters. Spammers are going to double down on what's working. And so if you have features that are like, did the same email get sent to a lot of different people? What do spammers do? They're going to start modifying that email in some templated way. Now you have some feature that detects templates. Now there's sort of an arms race here. and so in that sense, in a sense, there's a spam arms race. over time, spam classification doesn't actually look like a standard classification problem because it's adversarial. OK, so in these images, you want to fit the hat right. You don't want it to be too small, because if you over-fit, you're not going to be able to generalize. Here's an example of this tradeoff. In general, we're going to do discrete classification. But for this example, let's imagine the thing we're trying to do is to fit a curve to this data. the data points of the squared distance or something. So what is my constant approximation to this? Does anybody want to hazard a guess? Let's call it five. OK, did I fit something about this data? Yeah, I felt something about the data. I fit basically it's mean. Did I capture the major trends? No. All right, let's try again. Let's fit a linear function. It's close, right? It's a better fit than the constant function. Notice that when I went to linear function, the space of hypotheses grew. than the quadratic. It's about fitting your data to the point where the patterns that you are capturing are ones which generalize to test, and that's a tricky balance. Over-fitting shows up not just on these continuous functions. It also shows up on discrete functions. And so, you can't basically just judge by your training accuracy. You need some measure of whether you've gone too far in the fitting process. And in this case, we talked about hyperparameters. A hyperparameter could be something like, what's the maximum degree of polynomial I'm allowed? In a hypothetical digit classification, we might say, here is an image I've never seen before. Let's use Naive Bayes to classify it. We'd say, all right. Well, before I look at any features, the numbers are the numbers two and three, let's say, are equally likely. So, so far, a three is winning. But eventually, I'm going to get to some pixel, maybe like this one here. And in my training data, this is almost never on. This is. in a corner where there's no number. This is an example of over-fitting, because this probability versus this probability, that is about the idiosyncrasies of the samples I have in my data. I can instead ask, when I do these multiplications together, into that running product, which are the words which sort of swing the product most one way or the other? I can look at odds ratios, which is the ratio of the probability in the two. And if two's going to win, because it didn't have that zero, that's bad. the ratio is one, it means it's equally likely. Whether it's common or uncommon, it doesn't affect the competition. It's things that are more common in one than the other that have a big impact on these odds ratios. What do you think, in my training data for ham versus spam, things with the highest odds ratio for ham would be? These are things that're significantly more likely for ham than for spam. Words like Gary, except when I look at my data, it's actually a mess. It turns out, there are a bunch of words in this data which occur in spam once, and it could occur in once and occurs in spam zero. of over-fitting, where the exact details of which sample points you drew when you collected your data get captured in a way that doesn't generalize. In Naive Bayes probabilistic models, over- fitting usually shows up as sampling variance. For other methods, it's going to show up in totally other ways. OK. To do better, we need to smooth, or regularize, our estimates. So let's figure out some ways to do that, to just illustrate what it would look like to limit over-fits. you shrink a hypothesis space, you fit less. Using it too much, you under-fit. So let's take a look at the distribution of a random variable, just to sort of show why we need to do these kinds of things. We can do elicitation, right? You can ask a human. You can go to a doctor and say, hey, I'm building a classifier. What fraction of people with meningitis will present with a fever? And a doctor can give you a guess. You could also do that empirically. of patient treatment or something like that. And this is basically what learning does. You take your training data, you take the trends out of the training data. The simplest version of this is for each outcome to look at the empirical rate. So, for example, if I am a jelly bean-counting robot, and I am trying to figure out in this vat of jelly beans, how many reds versus blues there are, and it's two reds and two blues, well, what can we do? In practice, you need some smoothing. But we want no surprises to our model. We want our model to assign probability to events it's never seen. So that one errant pixel or word that is rare doesn't completely torpedo an otherwise very nuanced balancing of evidence. All right, so what was the maximum likelihood estimate? You have to work this out, right? Maybe we can just go back and do it real quick. OK. So let's say r is my probability of red, and one minus r isMy probability of blue. What is the probability of D.for red. of this data? Well, it's basically I got an r, and then I got another r. And then I've got the other thing, which is one minus r. So as I change the probability of red, this term, the likelihood of the data, is going to go up and down. And the balance, the point where that's going to be maximized you can sort of, if you set it up carefully, take derivatives, find the extreme point, you'll get the relative frequency answer out. the parameters which maximize the product of this, which is what we were doing before. This denominator here doesn't matter. It's just some constant. But there's this extra term, p of theta. And so what this says, is it says, if I want to know what parameter or what probability is most likely, I need to weigh the likelihood of the data against how likely I think that parameter is in the first place. OK, so this doesn't have a closed-form solution without giving you more information. But here's a basic idea of how you might approach it. the sun will once not rise. So I know that this estimate is wrong, and I need some way of mechanically incorporating the fact that there are events which I haven't seen, but which I know to be possible, or at least that I'd like to model as being possible. So basically, add one to all your counts, including the ones that are zero. So the maximum likelihood estimate for red, red, blue, if I say, what's the probability of red, comma, probability of blue? 2/3, 1/3. two reds, there's three. There's those ones, plus my pretend red. And instead of one blue, there're two, because I have my pretend blue. Now what do I get? I get 3/5 and 2/5. Red is still winning, but this distribution has gotten flatter. And if there had been zero blues it would no longer be given probability zero. So pretty reasonable. We can do better. And so if I add zero, if I take Laplace's extended method and I addzero, then I just get my 2/3, 1/3 estimate from red, red, blue. there's 100 blues. Now how many reds do I have? Well, I do my computations as if I had 102 reds and 101 blues. And suddenly, even though there are still more reds than blues, in my posterior estimate here, it's pretty close to 50-50. So as I crank up k, I have a stronger prior, and I fit less. If I crank downk, I fit more, and so I now have a dial which can trade off the amount of fitting against generalization. example, I can go into my spam, and instead of computing odds ratios on the maximum likelihood-- or empirical relative frequency estimates-- I can instead do some smoothing. And suddenly things that only occurred once, they don't percolate to the top, because they haven't occurred enough to overwhelm that flat prior that I'm associating them with. So this is the top of the odds ratios for ham on the left, and favoring spam on the right. Some of these maybe make sense. Like, there it is. Free is probably in there somewhere. If you see money, that's a good sign that it's spam. But you might be wrong. Sometimes things surprise you, and that's why it's always good to like actually look into your model and see what has been learned here? Is there something that I can learn about this problem from what the machine has learned about the problem? All right. We talked about tuning. So let's say I build my Naive Bayes model for spam, for digits, whatever. I've got my features. Let's say they're mostly words and pixels. On your projects, you'll see you can do better. And I have some tuning to do. In general, your model is going to make errors. So we learn our parameters from the training data. We tune them on some different data, like some held-out data, because otherwise, you'll get crazy results. And then eventually, you're going to take the best value, do some final tests, test run. We're talking a bit more about features, because I think it's important for when we start to get to neural nets, where the stories here are going to change. In general, in general, you're going to need more features. In spam classification, we found out that it wasn't enough to just look at words. For digit recognition, you do sort of more advanced things than just looking at pixels, where you look at things like edges and loops and things like that. Try to do things that are more advanced than just pixels, like looking at loops and edges and edges, and try to look at other metadata from the ecosystem as well as just words. are invariant to rotation and scale and all of that the vision folks think about. You can add these as sources of information by just adding variables into your Naive Bayes model. We'll also talk in the next few classes about ways to add these more flexibly, and also ways to induce these. All right, I'm going to stop there for today, and as you go, please come up and grab some more candy. Thank you. Back to the page you came from.

ROUGE-1: 57.84, ROUGE-2: 55.36, ROUGE-L: 53.21
BERTScore: 72.73

==============================================
==================== [18/100] ====================
Summary:
in this video we're gonna talk about how a country can gain from exporting goods or services through international trade. We're gonna look at how consumer surplus producer surplus and total surplus are going to change when we introduced the idea of trade in allowing Chile's copper manufacturer producers to trade on the global market. The world price of copper is five thousand four hundred and forty dollars a ton. Because the world price is higher than the price in Chile Chile will export copper. There is a shift of some of the consumer surplus is going to go to the producer surplus.

ROUGE-1: 14.64, ROUGE-2: 13.69, ROUGE-L: 13.40
BERTScore: 67.04

==============================================
==================== [19/100] ====================
Summary:
After you watch this youtube video you can access the free quiz that will test you on this medication. The name specifically the family name of the drug because this tells us how the drug works on the body. The medication works in the early part of the distal convoluted tubule that's found within this nephron and what this drug is going to do is it's going to prevent this transporter. The transporter is called the sodium chloride co-transporter and it is considered a cyanide sensitive transporter so hence why this drug works so well. from being able to do its job and just as its name says is that this transporter transports sodium and chloride from the filtrate to go back into the blood to be reabsorbed by the body. Thiazide diuretics are not as potent or as powerful as loot diuretic like furosemide and the reason for that is because each type of diureic that you have is going to affect different structures within this nephron. Without them working properly the kidney fails to do their job. and there are millions of these little nephron structures within each kidney and they function to filter the blood and manage the amount of water ions and waste in the blood. Each part has its own unique role for tweaking this filtrate which is why certain diuretics work on certain areas of the nephrons. The parts of the nephron include the afferent and efferent arteriole. and the proximal convoluted tubule. This area is going to reabsorb water ions etc and the parts that we've talked about hang out in the renal cortex of the kidney. by that descending limb of the loop of Henle and the collecting duct so once it leaves the proximal convoluted tubule it's going to go down into the loops. The distal convoluted tubules is where the thiazide diuretics works specifically in that early part. One of the side effects of thiazides is that it can increase calcium levels and also it plays a role with secretion of potassium into the filtrate then it left the DCT and it's making its journey to the collects ducts. sodium and chloride ions from leaving the filtrate and going back into the blood and hanging out in the blood. Because we're not going to be receiving that sodium we are going to potentially lower the sodium levels in theBlood leading to hyponatremia. calcium is affected by a particular channel known as the t RP v v channel and because we inhibit this sodium chloride coat transporter it's actually going to inhale how this channel works so it helps the body reabsorb calcium. be beneficial and we're going into a little bit for what this drug is used for but patients who have recurrent renal stones that are composed of calcium can actually benefit from this. Patients who have low calcium levels we can possibly throw in a thiazide to help increase the reabsorption of calcium in the blood which can hopefully help increase their bone density. As a nurse you want to watch that calcium level. Thiazide diuretics can cause hypokalemia and that was similar to our loop diuretic they also can lower the potassium level so they share that. channels are influenced by aldosterone. Aldosterone causes the body to keep water and sodium in exchange for potassium. The patient could possibly experience metabolic alkalosis due to the loss of those hydrogen ions so remember that and patients may have to take potassium supplements. If they're on other medications which we'll talk about here in a moment and educate them about foods that are rich in potassium and they want to definitely keep those in their diet those are diuretics can also alter the blood sugar. Thiazide diuretics can increase uric acid levels which can lead to gout attacks. These drugs alter how the proximal convoluted tubule deals with your ate and it actually increases how urate is reabsorbed which can increase your gas levels and lead to gaol attacks so you may need to monitor those uri acid levels. High uric Acid levels for a male tends to be anywhere anything greater than seven and four females greater than six. If you see a uricacid level of 15 that is not good that means that they have high uric acids levels. These medications can do is they can be prescribed a lot of times with ACE inhibitors and this can help actually increase the function of the heart and help the patient feel better. Thiazide diuretics can be used in the treatment of renal calculi which are those renal stones that are composed of calcium now let's talk about nursing responsibilities the side effects and education pieces for the patient who may be taking a thigh-high diuretic so whenever you have a patient taking a thiazide you really want to be watching out for signs and symptoms of dehydration. is you can look at their vital signs how is their blood pressure if it's hypotensive low that's the salts less than 90 that probably means that we've removed a little bit too much fluid volume from their blood. The heart rate will be increased as well we're tachycardic from where the heart's trying to compensate for that loss of fluid volume. We can also look at the eyes and O's you want to make sure you are strictly measuring that and the patient can help you with that. because if they're gaining weight instead of losing weight we made not very effective with this diuretic they may need something else. A lot of patients with heart failure may be on these medications and we want to teach them to weigh themselves every day and to write it down to keep track. If they've gained more than like three pounds in one day that could mean that they're retaining fluid and they may be having heart failure exacerbation and will need to go to their doctor to get treatment. on digoxin and their potassium level goes too low it can increase the risk of digoxin toxicity. A normal lithium level is about 0.5 to 1.2 millimoles per liter so remember these two drugs if we go into these hypo conditions either hyponatremia or hypokalemia with those it can cause toxicity. No exams love to ask about the hyper conditions that these drugs can cause our hyper hyper Cal C Mia the high calcium level hyperuricemia. the high uric acid level and hyperglycemia again teach your diabetic patients to monitor their blood glucose really closely while taking a thigh. Avoid giving doses of diuretics at night because we want our patients to sleep at night we don't want them up using the bathroom all the time so make sure you're not doing that. orthostatic hypotension this is where the when the patients maybe they've been sitting or lying down they get up they can fall they become dizzy you want to teach them to change position slowly. weight or losing weight so we play a huge role with that as well okay so that wraps up this review over thighs I diuretics. thank you so much for watching don't forget to take the free quiz and to subscribe to our channel for more videos. Back to the page you came from. Follow us on Twitter @CNNOpinion and @bbcopinion. Follow our Facebook page and our YouTube channel for all the latest from CNN.co.uk and CNN iReport.

ROUGE-1: 51.93, ROUGE-2: 49.17, ROUGE-L: 50.97
BERTScore: 73.57

==============================================
==================== [20/100] ====================
Summary:
Future John Green tells you that in a stunning turn of events the 2020 presidential election will be won by - Harry Styles. We’re going to change the constitution to make it possible. Because… that’s how much we love Harry Styles in 2020. The U.S. was facing what turned out to be the 2nd worst economic crises in the past 150 years. The Wall Street Wamboozle, the Financial Fartstorm. And the U.N. Security Council. The Financial Fartstorm that began in late 2008 was a mixture of public and private activities that tilted towards short-term economic thinking, speculation and irresponsible spending. First, there are the Federal Reserve’s policies of keeping interest rates freakishly low in response to the 2001-2002 recession. And this, combined with unscrupulous mortgage lenders, encouraged people to buy houses that they could not afford. Back then you could buy a house with a so-called NINJA loan which sadly this did not involve mutant ninja turtles or pizza. Traditionally, people in this situation can’t borrow hundreds of thousands of dollars, but in the early 2000’s, these loans were giving the benign sounding designation “subprime” All this created a classic housing bubble, which was doomed to burst. With the interest on government Treasury Bills effectively zero, investors had to look elsewhere for better returns. This led to the idea of issuing securities – these bond-like instruments that were backed by mortgages. The thinking was that the interest people paid on their mortgages would supply the underlying value of the security. but the important thing is that when the mortgages turned bad, these securities became toxic assets. When banks stop lending, business can’t function. So the stock market collapsed, with the Dow Jones Industrial Average dropping from above 14,000 to around 8,000 which wiped out about $7trillion of shareholder wealth. With it being harder to borrow money, Americans finally cut back on their spending, which resulted in many businesses failing. By mid-2009 more women than men held paying jobs for the first time in American history. Bush administration tried to stop the damage by getting Congress to pass the TARP. TARP was basically a $700 billion bailout for banks like Citigroup and Bank of America. Regular individuals also received tarps, but they had to buy them and they weren't as cool. Most of the banks that received a rescue from the taxpayers didn't help the homeowners facing foreclosure, and despite receiving millions of federal dollars, AIG continued to pay huge bonuses to its top executives. After a decade of Americans spending more than they had, government took over. In 2008 Obama’s election seemed a political watershed and not just because he was the first African American president. He appealed to young people and minorities, and he harnessed the power of social media to communicate with supporters. He appeared to break Republicans’ solid hold on the south, and also raise TONS of money. Also, he was on the cover of US Weekly. You didn’t see Martin Van Buren on thecover of USweekly. What’�s that? It didn”t exist? Of course it existed! he won Virginia, and North Carolina and Florida, and his supporters represented a coalition of African Americans, and Hispanics, white liberals and, especially, young people. “For everywhere we look, there is work to be done. The state of our economy calls for action, bold and swift. And we will act, not only to create new jobs, but to lay a new foundation for growth.” “We will build the roads and bridges, the electric grids and digital lines that feed our commerce and bind us together. We’ll restore science to its rightful place. We will harness the sun and the winds and the soil to fuel our cars and run our factories’ Obama promised to change the culture of Washington. To be fair, he did end the squabbling, it became full blown yelling. He also wanted a foreign policy based on diplomacy, he wanted to reduce inequality and increase access to health care. He wanted to end the wars in Iraq and Afghanistan and, as critics mocked, reverse global warming. That’s a tall order. Some would say not great either. The getting shocked part of my life has come to an end. Hopefully in Crash Course Literature when I get things right I’ll get a puppy and when I getting things wrong I'll get a rainbow! For instance he launched diplomatic outreach to the Muslim world, but a lot of this was more rhetoric than action. He signed into law the Lily Ledbetter Fair Pay Act, which made it easier for women to sue when they had been systemically underpaid. And speaking of women he appointed two of them to the Supreme Court, Elena Kagan and Sonia Sotomayor. He also followed through on his promise to end the war in Iraq, although to be fair the Bush administration had really set him up for success there. Obama has been criticized internationally for backing off his promise to close the Guantanamo Bay detention camp. But the Obama administration has deployed far more unmanned drones to kill suspected militants around the world. Despite provoking outrage on the left and the right, Americans generally appear to support the use of drones and extra-legal assassination of accused terrorists. Obama was fortunate to have a Democratic Congress for his first term in office, so he could push through a lot of legislation. In the end, the recovery act cost $787 billion - more than the government had spent on a package of programs ever. The stimulus is estimated to have saved about 3 million jobs, but it also increased the deficit quite a bit. Liberal economists see America’s current 7% unemployment rate as evidence that the stimulus’ Keynesian policies should have gone further. Obamacare aims to reduce the number of Americans without health insurance by making it easier and less expensive for the uninsured to buy it privately. The Affordable Care Act is arguably the most significant piece of social legislation since Medicare. It seeks to move the United States into the ranks of countries with universal health care. government insurance plan and the government will subsidize those who can’t afford insurance. In 2012 the core of the law was upheld by the Supreme Court when they ruled that thiants was a constitutional use of the government’s taxing power. Not one Congressional Republican voted for Obamacare, and many used it to campaign against Democrats in the 2010 mid-term elections. One of these responses was The Tea Party, a reference to the Boston Tea Party and an acronym for Taxed Enough Already. The Tea Party is very concerned that deficits are out of control and that rising government spending is going to ruin America. Bolstered by 80 or so new Tea Party congresspeople, the Republicans took control of the House in 2010 and John Boehner became the Speaker of The House. All these Tea Party freshmen took their mandate to cut taxes and reduce spending very seriously, and that made it difficult for Boehner to compromise with the Obama administration. In fact, the 111th congress was one of the least productive in American history. ceiling. Things that Congress used to be able to hash out back when their business was governing not ideological rigidity. Meanwhile, the economy has slowly added jobs and looks halfway decent at the moment mostly because Europe looks so bad. That qualified questioning yay is about the last word I have to say on American history. We have to ask ourselves again, “What does freedom really mean?” Can you be free when you live in poverty or when you’re one injury away from bankruptcy? Can you being free when the government can go to a secret court to read your text messages? job to protect you not only by having a standing army but also making you wear your seat belt? Those are ultimately ideological questions, but we have to grapple with them in a real practical way. And the great story of American governance is compromise. But that is also often been the tragedy of American Governance. So if you’ve learned anything this year, I hope its been that the American story that we find ourselves in now isn’t entirely novel. And I think we have much to learn from those who came before us, both from their successes and their many, many failures. Crash Course World History has been on the air for two years. The show celebrates two successful years of teaching history. This has been one of the great professional joys of my life and I’m so grateful to everyone that has helped make the show and everyone who has watched it. Thank you again for watching, and as we say in my hometown, “Don’t forget to be awesome.” You can find a full list of your reading for Crash Course Literature in the doobly-doo.rolling.

ROUGE-1: 63.68, ROUGE-2: 60.66, ROUGE-L: 59.19
BERTScore: 67.85

==============================================
==================== [21/100] ====================
Summary:
Simple graphs are simpler. The edges don't have direction. They just correspond to a mutual connection, which is symmetric. A directed graph might have a self loop, an edge that starts and begins at the-- starts and ends at the same vertex. Those are also disallowed in simple graphs. There's a thing called multi-graphs where there are multiple edges between vertices. And there could also be self loops, but we don't need those. Let's not complicate matters. graph is that it's an object G that has a bunch of parts. Namely it has a nonempty set, v of vertices, just like directed graphs. It has a set E of edges, but the edges now are somewhat different since they don't have beginnings and ends. An edge just has two endpoints that are in V, and we don't distinguish the endpoints. So let's just draw a picture. Here's a case where there are six vertices V shown in blue, and there are these undirected edges shown in green. A basic concept in graph theory, which is what we're going to make a little bit of in this video segment, is the idea of the degree of a vertices. The degree is simply the number of incident edges that touch it, and the edge is said to be incident to its end points. So let's examine some properties of vertex degrees that are motivated by a simple example. If I asked the question, is it possible to have a graph with vertices of 2, 2, and 1, implicitly it's a 3 vertices graph. The handshaking lemma says that the sum of the degrees summed over all the vertices is equal to twice the number of edges. There can't be a degree 3 graph with this spectrum of degrees 2, 2, 1. It's impossible. Well, we could have reasoned more generally. And there's a very elementary property of degrees that we're going to actually make something of in a minute. There it is. The handsh shaking lemma. Theorem: The degree of a graph is the degree of an edge. written as a formula, twice the number of edges. So that's the cardinality symbol. Absolute value of a set means the size of the set. E here is finite. Twice the number. of edges is equal to the sum over all the vertices of the degree of the. vertices. And the proof is trivial, but let's make something of this. You might wonder why it's called the handshaking lemma. That will emerge in some problems that we're going to have you do. There have been repeated studies that are cited in the notes that show again and again that when they survey collections of men and women and ask them how many sexual partners they have, it's consistently the case that the men are assessed to have 30% more, 75% more. We're going to come up with a very elementary graph theoretic argument that says that this is complete nonsense. The most recent study that we could find was one that's mentioned in 2007 by the US Department of Health. And the statistician who collected the data knew that the results were impossible. to model the relationships between men and women by having a graph that comes in two parts. It's going to be called a so-called bipartite graph. So looking back at this graph, this edge from that blue M to that orange F indicates that they had a sexual liaison. They were partners. OK, so this is a simple graph structure that we can use to represent who got together with whom in any given population of men and woman. The left hand side is the number of-- is the sum of the degrees of men divided by the size of the M population. And here I'm doing a little trick. Notice that the F's cancel out. In the US overall there are slightly more women than men. There is 1.035 women for each man in the US population. The men degree is the female population divided by the M population times the average degree of the females. But this has nothing to do with their behavior, or promiscuity, or lack of it. It's simply a reflection of the ratio of the populations. But we do get them consistently in one survey after another. You will no longer be fooled by such nonsense.

ROUGE-1: 55.01, ROUGE-2: 52.80, ROUGE-L: 51.60
BERTScore: 73.14

==============================================
==================== [22/100] ====================
Summary:
Robotics is a really cool and important direction for the future. We are moving towards a world where so many routine tasks are taken off your plate. I really believe that in the future we will have AI assistance whether they are embodied or not to act as our guardian angels to ensure that we maximize and optimize our lives to live well and work effectively. It turns out it's 19. Can you count how many robots there are in this in this image? Anybody wants to want to take a guess how many Robots do I have in this Image? Okay that's so that's that's really close! cognitive and physical work. And so today we can say that with AI we we will see such a wide breadth of applications for instance these technologies have the potential to reduce and eliminate car accidents. These technologies have potential to keep your information private and safe to transport people and goods more effectively and faster and cheaper to really make it easier to communicate globally by providing instantaneous translations. To develop education to everyone to allow human workers to focus on big picture tasks with machines taking on the routine tasks and so this future is really enabled by three interconnected fields. is about learning from and making predictions on data. This kind of application of machine learning is Broad it it applies to cognitive tasks and physical tasks. We can characterize how machine learning works as using data to answer questions that are either descriptive predictive or prescriptive. So when we think about these questions in the context of a robot we have to kind of get on the same page about what a robot is and um and so think of a Robot as a programmable mechanical device that takes input uh with its sensors reasons about this input and then generates an action. can do so the robot can only do what its body is capable of doing a robot on wheels will not be able to do the task of climbing stairs so we have to think about that body and we have at T Cell we have a lot of machine learning based research that allows us to examine how to design optimally a robot body for a particular task. In the context of robots we have three types of learning and you have seen different aspects of these methodologies throughout the course we have supervised learning, unsupervised learning and reinforcement learning. Road and we do this so that when the system when the car sees a new image for example this one the car could say oh this is a this is ducks on road now. In order to in order to actually provide solutions for this object classification problem we have to employ multiple algorithms. The exciting thing is that we already have very good algorithms that that can segment images very fast so we can we can do this. We can take an image and we can find the object in the image very fast we don't know what the objects are. of people to label the objects that we have and so this is exciting but it but labeling is a very labor intensive activity and a significant challenge to machine learning. The most popular Benchmark for measuring the accuracy of image classification is imagenet and we see performance of various variations of of image Classification algorithms that perform well into 90 90 accuracy. But if those algorithms were to run on a car that's not good enough because the car is a safety critical system and in fact we cannot afford to have any errors in how images get recognized in the car. Boris Katz did an experiment a few years ago where they took regular objects and they put them in a different context. With this significant change in context the performance of the top performing imagenet algorithms dropped by as much as 40 to 50 percent. So keep this in mind as you think about deploying or building and deploying deep neural network Solutions. There's another thing um that is very critical for for autonomous driving and and for robots you have heard a beautiful lecture on adversarial attacks well it turns out you can attack very well. The images that get fed from the camera streams of cars are fed to the decision-making engine of the car. Machine learning is very powerful for building perception systems for robots but as we employ machine learning in the context of robots it's important to keep in mind the scope when they work when they don't work and then it'simportant to think about what my what kind of guard rails we might put in place at the decision time so that we have robust Behavior. "With all small perturbations you can turn the stop sign into a yield sign and you can imagine whatkind of chaos this would create on a on a physical Road" to do given input reinforcement learning is causing a huge revolution in robotics. We have built fast simulation systems and simulation methodologies that allow us to run thousands of simulations in parallel in order to train a reinforcement learning policy. We are also decreasing the gap between the hardware platforms and the simulation engines so you have seen reinforcement learning earlier in the in the boot camp and so reinforce learning is concerned with how intelligent agents ought to take action in an environment inorder to maximize the notion of a cumulative reward. error and and eventually the positive rewards dominate the negative rewards and that that directs the the agent towards the the best action and so here is an example where we have a reinforcement learning agent that is trying to drive on a race track and you can see that it starts off and it initially it makes mistakes but eventually it learns how to how to take the turns at high speeds. It's very it's really a very exciting area reinforcement learning much like deep learning has been invented decades ago but it works well now because of the Advent of of computation. years ago and so these techniques that did not do so well back then all of a sudden are creating extraordinary possibilities and capabilities in our agents now this is a simple simulation in order to get the simulation to drive a real robot we actually need to think about the Dynamics of the robot and so in other words we have to take into account what the vehicle looks like what are its kinematics and its Dynamics and so here is a vehicle that is running the policy learned in simulation so it's really cool because really we are now able to train in simulation. they get the position of the other vehicles on the track but only only so they get this position from an external localization system but they only know where the vehicles within their field of view are. I think that these these advancements in robotics are really enabling the possibility that you saw in the first Slide the possibility of creating many robots that can do many tasks and much more complicated tasks than what we see here. What I want to talk about next is the autopilot how do we take these pieces together to enable a self-driving vehicle.  Carnegie Mellon project called nav lab built a car that was driven by a machine learning engine called Alvin and Alvin drove this car all the way from Washington DC to Los Angeles. The car was in autonomous mode for a large part of the highway driving but there was always a student there right ready to um to take control and the car did not did not drive inonomous mode when there were when it was raining or when there was a lot of congestion or when the car had to had to take exits. In 1986 German engineer Ernst Dickman started thinking about how he could turn his van into an autonomous vehicle. He put computers and cameras on the van and began running tests on an empty section of the German Autobahn which had not been open for for public driving. He was able to actually get his van to drive on that empty road but interestingly when he started developing the MIT autonomous vehicles he was not able to do the same thing. It's extraordinary to think about what is needed uh in terms of of advancement in terms to get from where we were back then to the point where we can actually see deployed autonomous vehicles. This work um computers needed about 10 minutes to analyze an image can you imagine okay so how do you go from that to enabling an autonomous vehicle to drive at 90 kilometers an hour well um what they did was they they developed some very fast solutions for paring down the image to only the the the aspects that they needed to look at. They assumed that there were no obstacles in the world which made the problem much easier because all the car had to do was to stay on on the road so it's really super interesting to think about how visual processing improved from one frame per 10 minute to 100 frames per second. vehicle we deployed and in fact we had the public ride our vehicle in 2014 we have vehicles at MIT we have a lot of other groups that are developing these vehicles now before we had lidar we had sonar and nothing worked when we had Sonar. With lidar that problem went away so all of a sudden a powerful accurate sensor made a huge difference all the algorithms that were developed on Sonar and didn't work started working when the later was introduced it's really exciting um okay now when we think about autonomous driving there are several key parameters that emerge. of these systems are one one question how complex is the environment where the car t Road like in the German case then the problem is much easier then we have to ask ourselves how how complex are the interactions between the car and the environment. We have very effective and Deployable solutions for robot cars that move safely in Easy environments where there aren't many static nor moving obstacles and you can you can see from this example this is this is an example of the MIT car and it'sYou can see this this car operating autonomously without any any obstacles. issues at Fort Devens where there aren't too many obstacles and the car is perfectly capable of avoiding the obstacle by the way that's my car. The sensors don't work well in weather and the uncertainty of the perception system increases significantly if it rains hard or it snows. The uncertainty also increases in the case of extreme congestion where you have erratic driving with vehicles with people with scooters even with cows on the road and this is a video I took during a taxi ride in Bangalore there come the cows so um there are so many important preconditions. them follow a very simple solution which you can adopt and turn your car into a self-driving car. Here's what you have to do you take your car you extend it to drive by wires so that your computer can talk to um to the steering and the acceleration the throttle controls. Then you'll further extend this car with sensors and most of the sensors we use are cameras and lidars. Then there are Suite of software models modules and this includes a perception module that provides support for making maps and for detecting a static and dynamic obstacles. country on a country road or in the city on a city road or you're on a road with no Lane markings so these are these are really challenging things that that the first solutions for autonomous driving had to had to reason through now in Alexander's PhD thesis his idea was to utilize a large data set to learn a representation of what humans did in similar situations. The solutions that we employed build on things we have already talked about we can use deep learning and reinforcement learning to take us from from images of ofroads onto steering and and throttle onto what to do so this is really great because you can train on certain kinds of Roads. completely different driving environments and driving situations and you don't need new parameters you can go exactly directly to what the car has to do so in other words we can learn a model to go from raw perception and here you can think of this as pixels from a camera. The other thing we feed the vehicle is noisy Street View maps so these are not the high definition maps that are usually created by autonomous driving labs and companies and so you can do this to directly infer a full continuous probability distribution over the space of all control. from this from this data this data is processed and it's from thisData we can learn to maximize the likelihood of particular control signals for particular situations. The solution also allows us to to localize the the vehicle so it's really super exciting okay so we can we can get this human-like control but assuming light control requires a lot of data. It'd be pretty expensive to take a car and crash that car in order to generate the data so instead what we do is we do the training in simulation and so Alexander developed the Vista simulator. The Vista simulator has been recently open sourced you can get the code from vista.csel.mit.edu and a lot of people are already using the system. What we get from Vista are is the ability to simulate different physical sensing modalities that means including 2D cameras 3D lidar event cameras and and so forth. You can also simulate different types of interactions so here's how we use Vista we can take one high quality a data set taken from a human-driven vehicle we can turn it into anything we want. very realistically into a new simulated trajectory that is erratic and that now exists that's part of our training set in Vista and so we can we can do this and we can use this data and then we can learn a policy we can evaluate this policy offline and ultimately deploy it on the vehicle. Here you can see the results of comparing what happens in Vista with the existing simulators in the state of the art so the Top Line shows crash locations in red and the bottom line shows mean trajectory variation in color. The decision engine has about a hundred thousand neurons and about a half a million parameters and I will challenge you to figure out if there are any patterns that associate the state of neurons with the behavior of the vehicle. So it turns out this vehicle is looking at the bushes on the roads in order on the road in order to make decisions still it seems to do a pretty good job but we asked ourselves can we do better can we have more reliable uh learning based Solutions and so yesterday Ramin introduced liquid networks and introduced neural circuit policies. have a better understanding of how liquid networks work and what their properties are now we can take this model and apply it to many other problems. Here is a problem we call Canyon Run where we have taken a liquid Network and we have implemented it on a task of flying a plane with one degree of Freedom. Here's another task we call drone dodgeball where the objective is to keep the a drone at a specified location and the Drone has to protect itself when balls come its its a very complex task. way and you can see a two degree of Freedom solution to drone dodgeball and that's the network. You can really associate the the function of of this controller of this learning based control with activation patterns of the neurons and so very excited because in fact we're able to extract decision trees from these kinds of solutions. These decision trees provide human understandable of human understandable explanations and so this is really important for safety critical systems all right um so um let's see um Ramin told you that these liquid networks are Dynamic causal models and I want to show you some more examples that explain how these models are Dynamic ozone models. standard deep neural network and we have asked this network to solve this problem and the attention map of the network is really all over the place you can see that the network the the Deep neural network solution is very confused but check out something else the data that we collected was summertime data and now it's fall so the background is no longer green we have we don't have as many leaves on trees and so the context for this task has completely changed by comparison the the liquid network is able to focus on the task is not confused. tree lines and the environment looks much much different than than the environment where we trained. This kind of this kind of ability to transfer from one set of training data to completely different environments is is truly transformational for the capabilities of machine learning. We see other examples where we take our solution and we deploy it to find the same object the chair just outside of the stata building and this is uh the the Deep neural network solution that gets completely confused and here is the liquid Network solution that has the exact same input and has no problem. by hop we're actually searching the object and doing multi-step Solutions and in fact in fact we can if I can get to my next video I'm sorry so um I am the next one is it shows you that we can actually do this forever so here is an infinite hop demo that was done just outside on the baseball field and we we placed uh three of the same objects that we trained on and we placed them at unknown locations. We can see that liquid networks generalize very well whereas if we take an lstm solution it gets confused and goes to the wrong object. that yields models that generalize to unseen scenarios essentially addressing a challenge with today's neural networks that do not generalize well to unseen test scenarios. I think it's so exciting to use machine learning to study nature and to begin to understand the nature of intelligence and we in in our lab here at C cell we have one project that is looking at whether we can understand the lives of whales and so what do I mean by this so here is an example where we have used a robotic drone to find whales and look at what they do. The system is able to use machine learning to identify the whales and then once you have identified the whale we can actually Servo to the center of the whale essentially tracking the whale along the way. Here's a here's Sophie our soft robotic fish um which Joseph who is with us today has participated in in building and here is this beautiful beautiful very natural moving robot that can get close to aquatic creatures that can move in the same way aquatic creatures do without without disturbing them when you put thruster-based robots in Ocean environments they behave differently than than the fish do and they they tend to scare the fish. Machine learning can be used to look for the presence of language which is a major sign of intelligence. We are trying to understand the phonetics the semantics and the syntax and the discourse for whales. We have a big data set consisting of about 22 000 clicks. Using machine learning we can identify coded types. We can identify patterns for Coda exchanges and we can we can begin to really ask ourselves how is it that that that Wales exchange information and if you're interested in this problem please come see us. that model to run on edge devices or on huge devices uh you have seen that many of our Solutions are Black Box Solutions and sometimes we have brittle function we have we have easily attackable models you have also seen some alternative models like liquid networks which attempt to address some of these questions. There is so much opportunity for developing improved machine learning using existing models and inventing new models and if we can do this we can create an exciting work world where machines will really Empower us will really augment us. Just-in-time Holograms could be used to make the virtual world much more much more realistic much more connected and so here they're discussing the the design of a new flying car and let's say we have these flying cars and then we can integrate these cars with the it infrastructure and the cars will know your needs so that they can tell you for instance that you can buy the plants you have been wanting nearby by Computing.your dimensions and can create a bespoke shoe just for you. Robots can help us with cognitive and physical work. There's the garbage ban the garbage bin that takes itself out. After a good day when it's time for a bedtime story you can begin to enter the story and control the flow and begin to interact with the characters in the story. These are some possibilities for the kind of future that machine learning artificial intelligence and robots are enabling. I'm personally very excited about this future with robots helping us with Cognitive and physical Work but this future is really dependent on very important new advancements that will come from all of you. Thank you very much and uh come come work with us.

ROUGE-1: 59.32, ROUGE-2: 57.42, ROUGE-L: 57.11
BERTScore: 74.65

==============================================
==================== [23/100] ====================
Summary:
hair up grab an apronlet's go now with the new chefs in place let's go Tatiana okay Gordon knows it's critical that Tatiana is familiar with the inner workings of the kitchen so just go maybe right to the just to the right of it right in the middle there perfect when was the last time you made a lasagna I've never made a Las never made lasagna ever that's crazy let's start off with mixing take your white sauce nice and clean with your PL scraper good get close to it got nothing to be intimida absolutely. Tatiana and her team eagerly learned a few of the new recipes last night. The message is clear nobody scared to walk through that door and get their hands dirty in that kitchen no we're not tomorrow is a big day let me tell you I need everyone on their game good night guys get some sleep thanks thank you very much chefs oh my God this is amazing last night Tatiana andHer team eagerly learn a few new recipes. The new menu will be unveiled on Thursday night at 8pm ET. spaghetti meatballs absolutely delicious and then finally pizzas four of them Margarita prito zucchini done with the shrimp and the meat lovers and again we have a massive asset there in that pizza Cen and we're going to take advantage of that yeah dig in let's go oh my gosh this is so beautiful m oh my God I am thrilled this is amazing this is like the menu of my dream Oh my God the pizza are incredible ohMy God I love that I know I'm excited for the new menu.

ROUGE-1: 62.82, ROUGE-2: 60.65, ROUGE-L: 61.89
BERTScore: 76.10

==============================================
==================== [24/100] ====================
Summary:
HONG LIU: This is a key relation between the bulk and the boundary. The more you go to the interior of the space time, then corresponding to the lower energy process when viewed form the field theory. So here, the same process is happening here compared to happening here, and here corresponds to the IR process, and the [INAUDIBLE] boundary corresponding to UV process. This is the IR-UV connection between the Bulk and the Boundary. It's called the IR/UV connection. the boundary theories. And also, this gives you an intuitive understanding where does this actual dimension come from from the field theory point of view. Then from a field theory perspective, this actualdimension can be considered as a geometrization of the energy scale. So any questions regarding this? Good. So now let's talk about some further aspects of the duality. The duality is that once you realize there's such relation, since the two sides are completely different objects, so the game is that you really have to do lots of guess work. We have N equals 4 super Yang-Mills theory. And then here, you have type IIB string in Ads5 times ds5. So here on this side, there is a conformal symmetry which we explained before because this is a four dimensional theory. On this side there's precisely the same group, which is isometry of Ads5. And you can write down the transformation on both sides. For example, this special conformal of a d dimensional series SO d, 2. HONG LIU: In N equals 4 super Yang-Mills theory, there's also global symmetry we discussed before. This is global symmetry associated with space time. And there is also global internal symmetry, SO6 internal symmetry. And the others, like translation or rotation, et cetera, it's clear. And we will not be explicit. You can also actually map the supersymmetry between them. And this can be considered as coming from the D3 brane. HONG LIU: So there's a 4 supersymmetry, which just comes from N equal to 4. But the conformal symmetry generates another 4. So all together, you have eight [INAUDIBLE] as the supercharge. And similarly, you find-- I will not do this side. But in this case, for example, the low energy limit. Let's just talk about the lowEnergy limit of this theory. So this all together is 32 real superchargers. the low energy limit, as we said before, just has to be super gravity. Then you find you actually have exactly the same amount of supersymmetry in this geometry. But the interesting thing is that by definition, the supers asymmetry on the gravity side is actually local. So if you look at this correspondence between each other, then you actually see a pattern. So now let me make some remarks. On this side, all these symmetries are global symmetry. But on the other side, they are local symmetrie. for each global symmetry in the field theory side, there's a corresponding local symmetry on the gravity side. If you talk about diffeomorphism, then this is a huge group-- certainly much, much larger than what we are talking about here. So why we are only talking about isometry? Why we don't talk about other parts of the diffeomorphicism, only talk about isometric? So what's special about the isometry?" he asks. "The isometry is important for the following reason," he says. "It can be considered as a subgroup" asymptotic geometry of the space time. So these are not ordinary diffeomorphisms. So-called large transformations is that they don't go to the Identity at infinity. And of course, this is precisely the large gauge transformations which leaves the asymptotic invariant. So in a sense, these large gauge. transformations can be considered as the global part of thediffeomorphism. So any questions on this? Yes? AUDIENCE: What does it mean that those those are the large transformations? isometries are local? What do you do with isometry [INAUDIBLE]? HONG LIU: These are just coordinate transformation. A coordinate transformation is always defined point by point, right? Just these are specific coordinate transformations. AUDIENCE: And what happens to gauge symmetries [INAudIBLE]. HONGLIU: No. The gauge transformation in the Yang-Mills part, you don't see it. Gauge freedom is just redundant freedom. You never see it on the other side. HONG LIU: Large gauge transformation means the gauge transformations which don't vanish at infinity. And those large gauge transformations essentially is like the global part of the u(1) gauge symmetry. So even on the gravity side, in some sense, you should think of them as global symmetries. And they are large gauge Transformations, not ordinary gauge transformations. The ordinary gauge transformation is just corresponding to redundancy of degrees of freedom. And that should not be reflected on the other side. HONG LIU: Conformal symmetry of the component of the field is the Minkowski space. So on this side, you have isometry of AdS, and on the other side you have conformal symmetry. And any internal gauge symmetry, say if you have some u(s) global symmetry here, then this will be mapped into a u(1) gauge symmetry. That is the gauge symmetry being gravity side. And it's always the case that global supersymmetry here would be corresponding to the local supers asymmetry here. previously we said, from the relation of the d-brane, so the G Yang-Mills square here is related to the 4 pi GS here, string coupling. So the N is the gauge group N. I should say the flux N. And then here is corresponding to you have SU(N). So this R, this curvature radius is related. to the alpha prime squared and the gs in this way. And so on this side, the dimension parameter is given by R squared divided by alpha prime. the relation between the parameters. So on the gravity side, we said these are the two parameters. And of course, you also have this N. And we can also, instead of using GS, as we said before, you can also use the Newton constant. So the 10 dimensional Newton constant is length dimension eight. Then the dimensionless parameter would be GN divided by R to the power 8. And the GN is related to the GS and alpha prime by this formula. So now you can just use this relation to exactly translate this into Yang-Mills coupling. expanding 1 over N squared. So as we said before, we often do dimensional reduction on S5. Let me get a five dimensional Newton constant. So fivedimensional Newton constant is equal to the 10 dimensional Newton Constant. And the difference is the volume of S5, we wrote this down before. And then from here, you can just work out. G5 has dimension 3. Then G5 divided by R cubed, again only related to N given by pi divided by 2N squared. The classical gravity limit is the same as QFT, Quantum Field Theory in curved space time. So gravity does not fluctuate. But your matter field can fluctuate, h bar equal to 1. So in the type IIB super gravity, there are many, many such kind of matter fields, and this is all in the unit of R. And here, when I write these relations, I have all set h barequal to 1, and then alpha prime should go to zero. So this means the string effect is not important. they all should be treated quantum mechanically. It's just that you should consider this small. So let's consider what this means. So GN small as a dimensionless parameter, this translates into field theory side if we use this relation. So that means N goes to infinity. So this is the large N limit of the Yang-Mills theory. And then alpha prime goes to zero. This is consistent that on the gravity side, the fluctuation in the geometry is very small. And now, we see that the decoupling of the string effect requires on the field. theory side the strong coupling. This is also something roughly we said before. If you look at just those [INAUDIBLE] diagrams, of course you don't see a space time interpretation. And I already alluded before that the continuous surface can emerge if that diagram becomes sufficiently complicated. The strong coupling, then the diagram with many, many vertices will dominate. And then the most dominated diagrams are those diagrams with not a lot of vertices. And they essentially are going to continue to limits. side is simple, we can just deal with quantum field theory in the curved space time, which we know how to do. But on this side, it's highly non-trivial because this is an infinite coupling limit. So this will tell you that the strong coupling limit is described by classical gravity. So that means that we can actually use classical gravity to, in principle, solve problems which are strongly coupled. So also, of course, there are corrections beyond this. So quantum gravity corrections on this. side, so this is a classical gravity limit if you take those parameters to go to zero. essentially the semi classical. gravity limit. Here I should call semi classical gravity limit because we still treat the matter fields essentially as quantum. So from now on, so we will mostly just consider the semi Classical gravity regime in the gravity side. Because essentially, we know very little about the string theory in this geometry. And also, I will often use the phrase which applies to the general correspondence, and not necessarily just N equal to 4 super Yang-Mills theory and the type IIB string theory. I just use the language assuming there's a general correspondence. group, say of this SO(d, 2). And similarly here, because here, the SO( d, 2) is the isometry group which lives in infinite invariants. And again, you should be able to organize your [INAUDIBLE] space using the representations of the SO('d', '2') And those representations, of course, should be the same. So if there's one representation here, then there must be a [INAudIBLE] representation here. theory, there must be a corresponding bulk vector field in the gravity side. And similarly, if you have some symmetric tensor, then this must also be related to some symmetry tensor. If the theory has some other symmetries, say some global symmetry or supersymmetries then again, all those fields and the state, they should transform on the representations of those symmetrie. They should all match together. Yes? AUDIENCE: So we proved that the super Yang-Mills theory really lives on the boundary of the AdS? HONG LIU: No. We did not prove that. you can imagine that this is the boundary, this relation is related to the bulk and the boundary. And this is a postulate based on that fact. Yes? AUDIENCE: I thought one of the motivations for thinking about the holographic duality was to try to escape [INAUDIBLE] theorem. And all of a sudden, it strikes me, so we're trying to get on the boundary spin to massless particles. Then they will also exist in the bulk. HONG LIU: Sorry. In the field theory side, there's no massless spin to particles. on that. You can say I don't need to worry about that whether this is on the boundary or bulk, et cetera. These are just some different theories. I want them to be the same. HONG LIU: But, as I said last time, if you believe this bulk and boundary relation, then this is powerful because then, you can immediately deduce that the Yang-Mills theory on the S3 times time then is related to the gravity theory in the global AdS. will give you a direct way to argue that. Also, in your p-set, you have checked this holographic bound. And so that's a confirmation of this. Yes? AUDIENCE: So what does the massless [INAUDIBLE] field on the right map to if it's the same representation of SO(d, 2)? HONG LIU: Sorry. Say it again. We are going to talk about it. So even though this relation was discovered in '97, actually in the '80s, people already worked a lot to consider this type to be supergravity on this space. On the string theory side, you always have this dilaton. And on the N equal to 4 super Yang-Mills theory, that's a local operator. And it turns out that operator is mapped to this Dilaton. So I won't go through those details. But let me just mention the most important such kind of mapping for these two theories. And actually does have consequences for the general story. So the mostimportant mapping. And then you can immediately see they actually map to certain representation of operators. theory side, we have this SO6 gauge symmetry. Then we have the SO6 conserved current. And it turns out this, on the gravity side, just maps to sO6 gauge field. And then another universal operator on the field theory side is the stress tensor. And this is mapped to-- turns out, to the metric perturbations. It's a deviation from the AdS metric. But physically, this is also natural. Physically, alsonatural. a few minutes. So now, given this mapping, any operator is due to a bulk field. Then you can ask some immediate questions. For example, the quantum numbers of these operators will map to the quantum number of the bulk fields. And that's something I said you can check their symmetries. So do you have any questions regarding this? So for local operator on the field theory side, so once we have this mapping we can immediately ask questions related to operators on this side, and try to ask what's the counterpart on the other side. we will discuss a bit later. But now let me discuss another natural question. And the natural thing to do is to deform your original theory by adding this operator to the Lagrangian. So this phi 0 is often called the source. So immediate question you can ask-- and when phi0 is equal to constant, then this corresponding to a change in the coupling for this operator. But in general, you can make it space time dependent. And then this deforms my theory away from the original theory. And if this operator is not there, then you just add the new coupling. operators coupling without if we say phi 0 is a constant? HONG LIU: Sorry? AUDIENCE: If phi0 is a Constant? Hong LIu: No. O is the operator. It's the local operator. There is no other operator this operator O coupling with. The meaning of operator is that O is a sum of the product of fields. So example is O in the scalar field theory. If a scalarField theory has a gauge field, then I can write O as trace F squared. guesswork is based on some very small clues. Good physicists do is that they can see non-ordinary things from ordinary things. So here, I will try to deduce the answer to this question by starting from this relation. Let's forget about p for pi. And now, we've talked about before GS string coupling can be considered as the expectation value of the dilaton field. Let me actually call it capital Phi. And similarly, for space time like AdS with a boundary, and the value of this dilaton can be identified. with the value of the dilaton at the boundary of AdS. HONG LIU: Phi in principle can fluctuate. And its expectation may also be able to fluctuate in the space time. But the only sensible way to talk about expectation value is to. talk about its value at the Boundary. It's the same thing for flat space. And in the AdS, which is also space time with a boundary, than we can associate the constant parts of the expectation value as the value at. the boundary. The Yang-Mills theory coupling with the value of phi at the boundary of AdS is related. This is the coupling or source for the Lagrangian of N equals to 4 super Yang-mills theory. And this corresponding to you essentially change the boundary value of dilaton because these are related. And the second is that phi 0 O, in the boundary theory, adding a. delta G, says the Lagranter of N equal to 4superYangMills, deform the boundary set. phi 0 O in the boundary theory must be related-- now I'm generalizing this story. The bulk field phi due to O has a boundary value phi 0. If you want to preserve the symmetry of the original Lagrangian, then you can choose a certain O. But in principle, you can choosing any O. You can break the symmetry if you want. Impose this kind of boundary conditions. Then you may break AdS symmetry too. So now we have answered this question. And then, of course, this just provides the answer. methods. Now I'm saying because I already know it's true. But in real life, what you will do from this example, you will say, ah, this must be the case. Then you will start trying to find examples to check it. And we will describe it later. I will not contradict myself in my later discussion. So if we assume this, I can also use this to argue. I can use this identification to make star and star star natural for any duality, not only N equals 4 super Yang-Mills theory and type IIB gravity. J mu. For simplicity, let me just take it to be u(1). Then I can deform the boundary theory by adding a source for this J mu. And a mu is the source. And then according to this identification, the A mu must be A mu. So this is a bulk vector field. But now we can argue why this should be a gauge field. And to see this is very easy because since J mu is conserved, then this coupling-- so let me call this star star star. mu, this A is the boundary value of A. So that means this capital A, that means the dynamics of this A mu should also be invariant. So we deduce that somehow, this must be some subset of the bulk gauge transformation. Similarly, you can do this for the metric for the stress tensor. So for the star star, again, we can add h mu mu x x. Then star to the power 4 also must be a subset of some bulk gauge. T mu mu to the boundary Lagrangian. And this is the source to the stress tensor. This is when h is very small. When we consider the information, we always consider the source is small. But now, we can argue this thing, mass corresponding to boundary value of the metric in the gravity side. So this is a very general statement valid for any correspondence between the gravity and the AdS metric. And now, from your knowledge of quantum field theory, when I add such a term to the field theory,. it's the same. and the field theory. And that also tells you that if you have a theory which due into a higher dimensional theory, and then that theory has a stress tensor, then this bulk theory must have gravity. So you can say, if any field theory is due to a theory of one higher dimension, that theory must involve gravity-- nothing about quantum gravity. Let's stop here. We're not going to get into quantum gravity right now, we're just going to talk about the theory of gravity.

ROUGE-1: 54.91, ROUGE-2: 52.86, ROUGE-L: 50.47
BERTScore: 72.28

==============================================
==================== [25/100] ====================
Summary:
Bolek Wyslouch is a teacher substitute for Professor Lee. He will talk to you about coupled oscillators. We will work on two, again, simple physical systems, one that consists of two pendula driven by forces of gravity, each of them. And then they are connected with the spring. Each of those pendula,Each of those masses will feel the effects of gravity and effects of a spring. We may, depending on how much time we have, start driving, have driven coupled oscillator. The system is very simple, just two masses, a spring, a little bit of gravity on top of that. The way they behave could be extremely complex, but it can be understood in terms of very simple systematic way of looking things through normal modes and normal frequencies. Once we understand two, we will then generalize to infinite number of oscillators, which is actually-- so this model, which consists of weights hanging under the influence of gravity plus the springs will be then used for many applications of the concepts. And everything is in Earth's gravitational field, g. We assume that this is an ideal system, highly idealized. We only consider motion with small angle approximation, only small displacement. There's no drag force assumed. Of course, this thing here is very far from being ideal, but hopefully basic behaviors are similar. It's approximately ideal. To study the motion of this thing, to understand how it works, let's try to parameterize it, and displace it from equilibrium, and look at the forces. The coordinate system is this. When we start talking about the system in principle in the case of somewhat larger angles, you have to worry about vertical positions as well. So there is also a coordinate y, which we will need temporarily to set things up. So x is, as I say, x is measured from equilibrium. Y is positioned vertically. So to calculate the equations of motion, we have to look at the forces. So let's look at what are the forces acting, for example, on this mass. When the spring is displaced from equilibrium, there is a spring force, Hooke force, in the direction of -- in the usual direction. In this case, it's actually in the opposite direction. There is a tension the spring, which has to be calculated such that we understand the acceleration of this object. This is m acceleration of object number 1 in x direction is equal to minus T1 sine theta 1 plus k x2 minus x1. And in the y-hat direction, we have m y1 direction isequal to T cosine theTA 1 minus mg. can be ignored. The force of spring depends on the difference of position x1 minus x2. If you move mass 1, the spring force is in the right direction, minus kx. So there is no motion x1, so we can conclude from here the T cosine1 is approximately equal. Yes? AUDIENCE: How do you know which way [INAUDIBLE]?? BOLESLAW WYSLOUCH: Excuse me. The spring is connected to mass 1. And the force of the spring on mass 1 is k times however the spring is squashed. T is simply equal to mg. So the tension in the spring can be assumed to be mg. We don't have to worry about it. Also the angle can be converted into position by realizing that the distance times the angle is equal to displacement, the usual geometry. The net result is that by simplifying things, I can write down equations for acceleration in the horizontal direction for mass 1. OK? So this is an equation of motion for mass1 in our coupled system. And I could say most of the terms have to do with a motion of mass 1 itself. focus on the mass in question. You take all the forces, you calculate them, and then this coupling will somehow appear in the equations. So we can repeat exactly the same calculation focusing on mass 2. And then the equation which you will get will be very similar. So the motion of mass x1 depends on x1 itself multiplied by something with a spring term and gravitational term and depends on the position of mass 2 only through the spring. And the trick in this whole mathematics, and calculations, and the way we do things is how do you solve those coupled equations? OK? me do everything. Let's write down everything in the matrix form, because it turns out that linear matrices are very useful for that. So let's introduce to them and show vector, which consists of x1 and x2. So we will be monitoring the change of this x2 as a function of time. We will introduce a force matrix k, which is equal to k plus mg over l minus k here. And then we need a third matrix, mass matrix, which simply says that masses are mass of first object is m. as X, the second derivative of the vector capital X, is equal to minus m to the minus 1, this matrix, multiplying matrix k and then multiplying vectors x again. So instead of repeating writing, all the x1s, x2, et cetera, instead I just stick them into one or two element objects. I use matrices to multiply things, and if I want to know x1 and x2,. I can always go, OK, the top component of vector x, lower component of vectors x gives me the solution. Simple. Right? So let's try to use this terminology to find solutions. But hold on. What form of oscillation? OK, all kinds of complex numbers can write, but any particular-- AUDIENCE: [INAUDIBLE] BOLESLAW WYSLOUCH: That's the physics answer, all right? Complex notation is a mathematical answer, how to solve a mathematical equation. The physics answer is to find fixed frequency modes us such that the system, the complete system, oscillates at one frequency. Everybody moves together. This is so-called normal mode. introduce variable z, just kind of a two-element vector, which has a complex term, a fixed frequency, plus a phase, a rhythm complex, multiplying vector A. And vector A is simply has two components, A1, A2, or maybe I should write it differently. So vector A contains information about some sort of initial conditions for position x 1 2. And also, we will, because we have this phase here, we can assume and require that is a real number. So A is real. So I have to do-- so I plug this here. So Z double dot is simply equal minus omega squared times Z. OK? And this term is a proportionality constant at any given moment of time. So it goes through the matrix multiplication. So you can just delete this. You can divide both sides. You have signs here. And then I have an equation which is a linear matrix equation, which is M minus 1 K times vector A. And I can rewrite it a little bit again. So this is the equation which we need to solve. to obtain the solutions to at least one normal mode, and we expect that there will be two normal modes, because we have two masses. So mathematically, the way to find out the oscillating frequency is you take a determinant of m minus 1 K minus i omega squared must be equal to 0. So let's try to see how to calculate things. So I take a big object like this. And so in this element here, I have to multiply this matrix times that. The only variable which we have to change parameters of this matrix-- you know, the spring constant and the mass this affects is given. So the only parameter here, which I can change, or adjust, or find is omega square. So I will try all possible matrices of this type until I find one or two that have a determinant equal to 0. But if I find them, this would correspond to the normal frequencies. We need to find which parameter omega sets this to 0, and then this is a pretty straightforward calculation. is basically equivalent to the following equation g over l plus k over m minus omega squared must be equal either to plus or minus. Right? I took a square root of both sides. There are two solutions which corresponds to plus here. The other one corresponds to minus here. So we have a-- so what this says is that if I set my frequency to g over. l, then it will be-- I will be able to set things up such that it oscillates forever at this frequency, one fixed. frequency forever. This is a frequency. It does not depend on the strength of the spring. How is it possible? Somehow spring is irrelevant for this motion. And it turns out that there is a very simple oscillation, easy to see, if basically that this is the frequency of a single pendulum. So basically, you got both pendula going together, each of them happily oscillating by themselves. And the spring is completely irrelevant forthis motion. If I cut it off, the motion will not change. It just happens that two identical pendula are going at their own natural frequency. so it's stretch from both sides. And the whole system oscillates at the same frequency, and because of this additional force of spring, the frequency is actually higher, it's larger. It oscillates faster. All right, so that's the first step in understanding the system. We now know that there are two oscillations and two normal frequencies. The next step to finish our understanding of the system in a mathematical way, to describe it fully, I have to know what is the shape of oscillations. In principle, we know, now, at the end of the day, I still want to know how much 1 moves, how much 2 moves. So we have to put it all together. We have identified the frequency and the kind of, in the matrix notation, shape of the node. But of course, the final solution is a linear superposition of all possible normal modes. And then you calculate a shape of a normal mode. Is that clear? Any questions at this time? Right? This one is minus 5. This one is plus 5 and so on. Whereas in this mode, both of them move together. All right? So let's try to go back to the-- you can get rid of this one. Let's write down x1 and x2 for positions of the two masses. So x1-- so basically, the x will have to be-- I used z there. Sox will be real of vector z. So from an exponent, I will end up with a cosine appropriately. And then I will use the [INAUDIBLE].. This is real part of e to the i omega plus phi. or they go opposite. So to make it more general, I have to give some multiplicative factor there. So if I do everything, I end up with x, the mode 1 will in general have some sort of overall constant C. And the mode number 2 will be C2 cosine omega 2 times t plus phi 2 times 1 minus 1. So the omega 1 and omega 2 are fixed given by the construction of the two coupled oscillators. This shape, 1 and 1, and 1 plus 1 is fixed, because these are the shape of normal modes. arbitrary mode-- this is the most general motion of the two coupled oscillator systems. To describe it in specifically-- defined for a specific configuration, you will have to determine the values of alphas and phis. So what you see here is the following-- you have the green is the normal mode, number 1. They are all stationary. This one is at position 0. This is not the ideal decoupled oscillator, right? OK, and then you see the things start moving. The magenta is normal mode number 2. And blue and the red are the actual pendula. And the motion of blue and red is simply a linear sum of the two. And this is exactly what-- this is the computer simulation that shows you that one of them is going up, the other one down, et cetera. Now, is there a way to disable one of the normal modes? How would you disable a normal mode? Is there a quick way to set things up such that the second normal mode, whichever you choose, doesn't show up in their equations at all? AUDIENCE: You said [INAUDIBLE]. BOLESLAW WYSLOUCH: Hmm? Audience: [INAudIBLE] BOLesLAW: Yeah, so what you do, is you just change the initial conditions. So you set it up at T equal to 0. I have initial conditions that basically favor or demand that only in this general equation either alpha or beta is equal to0. no shifting of energy from one to another. So you can have all kinds of motions by simply adjusting initial conditions. And those motions can be done a very different way. So do you know-- so this is how we can have different shape of motion, depending on the initial condition. Is there another way for me to change the way this system behaves? Let's say I have exactly this system, and I want to change, for example, the frequency of oscillations. How will I do it? It could be a very expensive proposition, yes? could put it with me some spaceship, and go to a place where the gravity is different, right? Why not? So what would happen? So if gravity changes, then basically what will happen is both this term and that term will change. So let's say, in fact, do I have it in this one here? Yes. Solet's say I do again. So now, let's take it to, for example, Jupiter. Jupiter, g, is much larger. So what do you think will happen when we go to Jupiter? the fact that the energy was moving from one to the other. Do you think this transfer of energy will be faster or slower? Two omegas closer to each other. Any guesses? AUDIENCE: Smaller. BOLESLAW WYSLOUCH: Take kind of longer. Let's see what happens, right? So we go on the rocket, and nowadays, you don't have to go to the rocket. Just remove one comment. And I went from about 10 meters per square second to 25 meters persquare second. now go to the Moon, which has much lower gravitational acceleration. Let's see what happens. It's a little bit not completely clear what's going on, but you see, actually the motion is kind of a little strange. Look at the red one. The red one is stopping. Then it's going halfway out. It looks kind of messy, doesn't it? And so it doesn't show up here very well, because the parameters have changed so much that I have-- I have those fixed pictures which are-- just a second. the frequency of how the energy shifts from one to the other. And also you can see the frequency going up and down for the same exact conditions. This is now, just a moment, this is a Jupiter. So Jupiter, you see that the frequency itself it's much higher. And the energy transfer between the two things takes longer. On the Moon however, the oscillations actually look really weird. It's kind of, you know, the two frequencies are so far away, and it's really not even a nice oscillatory motion. center mass of the system or just one of the two --? BOLESLAW WYSLOUCH: This one, I think, this one is just one. Actually, the one-- on the difference-- it normally doesn't matter. What matters this is the frequency and how these move to the other. OK? Let's just forget about it. Just keep it. So let me now talk about this thing, which is called beat phenomenon, because when you look at the motion of one of those objects, or the difference between them or whatever. plus cosine beta is equal to two cosine alpha plus beta divided by 2. Right? That's the trigonometric identity. So there is-- we have those two frequencies which are playing a role. And for example, at Jupiter, those twofrequency are actually very close to each other, because everything is dominated by the gravity, and we have a very weak spring. So the omega 1 and omega 2 actually are veryClose to Each other. So this thing, this term here, kind of goes omega 1 plus omega 2 divided by t. 2 is like omega, right? 100 plus 105 divided by 2 is about 100. Whereas this one here carries information about the difference of frequencies-- 100, 102, the difference is 2, which is very small. So we have-- so this term here-- it basically oscillates at the frequency of omega. And the other term is much, much smaller. How does this look? Well, it turns out that if you make a sketch of this, if you do signs, for example, it looks like this. like this. OK? So there are in fact two-- when you look at this picture, you can see two frequencies. One which is clear the oscillation of the-- high-frequency oscillation. But there's also this kind of overarching frequency of much smaller frequency, and this is what corresponds to a difference of two things. So the system oscillates. So one of those pendula, either of them, is moving fast. But it's going faster. It's amplitude is larger, and after some time, it slows down to 0. There's this kind of frequency of energy moving from one to the other, which is something called beat. So we see this here. We see it on the pendula. But now what we are going to do is we're going to try to hear it, right? So this is a demonstration which maybe it works, maybe not. So let me-- it will work, OK? So we have two speakers. And they basically go on very, very similar frequencies, all right? And so when I switched on, you should hear-- hear the sound. the original sound. And it's kind of the loudness of the sound overall is changing. All right? This is faster. This is kind of extra, extra sound which you hear is the difference of mainly the frequency is not stable here, so I'll change it. So this is, again, this is a single one, perfectly constant frequency. No change in amplitude, no change in loudness. Put them together, right? That's what they do. So if you have two, and I can adjust the frequency, and thefrequency is close, then this frequency of changing is very slow. So you can actually hear it. they have an amplitude of 1. And clearly, you see that they have a different frequency. So if you take two of those together, same amplitude, just slightly different frequency, and you simply make a linear-- superposition of the two, you will get exactly the beating effect. And this is something that, again, happens very often. There's another demonstration here. I have two tuning forks, and they are very similar frequency. They are coupled because I gave this guy some initial condition. In the experiment, energy is being transferred by this air oscillating here. The coupling goes through the air to the sound here, right? And they have very similar frequency. So they are nicely coupled. But what we can also do-- we can [TONE]. Right? So they're both going.going. Then I stop it. But there's still sound, because the second one picked up some energy, and it took off. Of course, you don't see them. BOLESLAW WYSLOUCH: I don't have to go to Jupiter to modify it, because this one is just a little mass here, right? [TONE] Ah, cool. So now, this thing is probably-- I know it's a period, a fraction of a second,right? Yes? AUDIENCE: Should both of those sine and cosines have Ts in their arguments? BOLESlaws: Of course always. They are both time dependent, yeah. sort of early on, to instead of, so far, when we talked about pendula, we describe their motion in terms of motion of number 1. It turns out we can rewrite the equation into some sort of new variables, where, so-called normal coordinates, where you'll simultaneously describe both of them and then kind of mix them together to have a new formula. So you do change of variables. So instead of keeping track of x1 and x2 independently, you define something which I called u1, which is simply x1 plus x2. equations, which I conveniently erased and make a sum or difference, it turns out that this coupling kind of separates. So I will end up having two separate equations for this one. So in general, the equation of motion would be-- would look like, so let's say I can write down m x1 plus x2. And this immediately-- and it looks-- if I now write it in terms of normal coordinates, then I have that m u1 double dot is equal to simply minus mg over l, u1. The determinants needed no matrices, no nothing. We just added and subtracted the two equations, and things magically separated. So you can always have a linear combination of parameters for arbitrary size coupled oscillators system where you combine different coordinates, and you basically force the system to behave in a way in which it induces the single oscillation, single frequency. So this is a very powerful trick, but usually for most cases, you can do that only after you have solved it, after you've found out normal modes, et cetera. then you can say, ha, ha,. I can I can introduce normal variables and make things simpler. But at the end of the day for complicated systems that work is the same. But for simple systems like this one where there is a good symmetry, you can do it. Anyway, so I think we are done for today. And on Tuesday, we'll continue with forced oscillators. All right? Thank you. "I think we're done for day one. We'll continue on Tuesday," he said.

ROUGE-1: 54.25, ROUGE-2: 52.83, ROUGE-L: 52.43
BERTScore: 65.96

==============================================
==================== [26/100] ====================
Summary:
GILBERT STRANG: This is the second of the three basic partial differential equations. We had Laplace's equation, that was-- time was not there. Now time comes into the heat equation. We have a time derivative, and two-- matching with two space derivatives. So I have my function. My solution depends on t and on x, and I hope I can separate those two parts. This is exactly like the way we solved the ordinary systems of differential equations: We pulled out an e to the lambda t. The second derivative of my function is some number, times my function. What I'm looking for for functions S, they'll be sine functions. S will be, S of x, will be the sine of K pi x. What's the eigenvalue? Take two derivatives of this, I get back sine k pi x, which is, that's great, it's an eigenfunction. So I have found a bunch of eigenvectors, eigenfunctions, and theeigenvalues. sum here, of some coefficients, let me call them B k, times this solution, e to the lambda-- minus k squared, pi squared t, times S, S number k. So the dependence on t is fast decay. And if K, as K gets larger, later terms in this sum, the decay is really fast. The term that decays most slowly, k equal 1, there'll be a B1. That's decaying already pretty fast. When I'm talking about decay, what's happening here? I have a bar, a material bar. ends are kept at freezing, and the inside of the bar, whatever heat is there at the beginning, is going to flow out the ends. So I'm freezing it at both ends. The temperature is escaping out of the center. So maybe I start with-- here is my bar from 0 to 1, and I'm keeping it frozen. F for frozen, f for frozen at that end. So u at 0 and x, I'll say it'd be 1. This way is x. have to find these numbers. And those numbers, of course, the numbers are always found by matching the initial conditions. T greater than 0 uses those Bks. And we're again faced with a Fourier series problem. And I'm finding the coefficients, so that this will match 1, the initial condition. And then, for t greater. than 0, solution u will be, as we said, the sum of these Bk's, which come from the initial. conditions, come from this-- Fourier coefficients. We have numbers, we have something depending on time and decaying rapidly. We're talking about a partial differential equation. So at time 1, if I drew a picture, suppose the heat is, the temperature starts out through the whole bar at 1. But with this kind of time decay, a little later in time, the Temperature's going to be something like that. It'll be way down at the ends, pretty low in the middle. So that's what solutions to the heat equation look like. And this is the step of finding the coefficients in our infinite series of solutions. differential equation. We have a whole function to match, so we need all of those. And Fourier series tells us how to do that matching, how to find these Bk's. So that's a separate and important question, Fourierseries. Thank you for your time. Back to Mail Online home. Back To the page you came from. Back into the article you came From. The story behind the story: Click here to read the full transcript of this article. Back onto the page of the story you come from.

ROUGE-1: 62.00, ROUGE-2: 58.17, ROUGE-L: 58.74
BERTScore: 76.21

==============================================
==================== [27/100] ====================
Summary:
MIT OpenCourseWare continues to offer high-quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourse Ware at ocw.mit.edu. The following content is provided under a Creative Commons license. Your support will help MIT Open courseWare continue to offer free, high- quality educational resources in the U.S. and around the world. For more information on MIT Open CourseWare, visit opencourseware.org. maybe you'll see the distinction between those things and understand why one version of the problem is much easier than another. But we try to respond as quickly as possible when we notice a typo like that so that we can set you guys on the right course. So we've got two lectures left discussing linear algebra before we move on to other topics. We're still going to talk about transformations of matrices. We looked at one type of transformation we could utilize for solving systems of equations. Today, we'll look at another one, the eigenvalue decomposition. This course moves at a pretty quick pace. We don't want anyone to get left behind. Speaking of getting left behind, we ran out of time a little bit at the end of lecture on Wednesday. That's OK. There were a lot of good questions that came up during class. And one topic that we didn't get to discuss is formal systems for doing reordering in systems of equations. We saw that reordering is important. In fact, it's essential for solving certain problems via Gaussian elimination. be stuck. It won't proceed after that. So it's the difference between getting a solution and writing a publication about the research problem you're interested in and not. So how do you do reordering? Well, we use a process called permutation. There's a certain class of matrix called a permutation matrix that can-- its action, multiplying another matrix, can swap rows or columns. So if I want to swap column 1 and 2, I multiply A from the right by P transpose. P permutation matrices are one class, maybe the simplest class, of unitary matrices. They're just doing row or column swaps, right? That's their job. And so if I have some reordering of the equations or rows of my system of equations that I want, that's going to be indicated by a permutation matrix-- say, P1. That would reorder the rows. If I swap the rows and then I swap them back, I get back what I had before. So there's a formal system for doing this sort of swapping. This is a form of preconditioning. It's always done via Gaussian elimination if we want an exact solution. You're studying one of them in your homework assignment now, where you know the matrix is banded with some bandwidth. So you don't do elimination on an entire full matrix. You do it on a sparse matrix whose structure you understand. We discussed sparse matrices and a little bit about reordering and now permutation. I feel like my diffusion example last time wasn't especially clear. So let me give a different example of diffusion. seen The Price Is Right? This is a game where you drop a chip into a board with pegs in it. It's a model of diffusion. The Plinko chip falls from level to level. It can go left or it can go right with equal probability. So the probability that I'm in a particular cell at level i is this Pi plus one. And there's some sparse matrix A which spreads that probability out. It splits it into my neighbors 50/50. And we'll see the simulation that tells us how probable it is to find the Plinka chip in a certain column. values for a couple of elements of this matrix. But this is a sparse matrix. It has a sparse structure. It models a diffusion problem, just like we saw before. Most of physics is local, like this, right? I just need to know what's going on with my neighbors. And I spread the probability out. I get this nice diffusion problem. Here's something to notice. This probability distribution always seems to flatten out. It becomes uniform. It turns out there are even special distributions for which A times A times that distribution is equal to that distribution. is one of the eigenvectors of this matrix A times A. It's a particular vector that when I multiply it by this matrix AA, I get that vector back. It happens to be unstretched. So this vector points in some direction. I transform it by the matrix. And I get back something that points in the same direction. That's the definition of this thing called an eigenvector. And this will be the subject that we focus on today. And finding the amount of stretch, which are complex numbers. eigenvector-eigenvalue pairs involves solving N equations. We'd like to know what these eigenvectors and eigenvalues are. They're non-linear because they depend on both the value and the vector, the product of the two, for N plus 1 unknowns. We don't know how to solve non- linear equations yet. So we're kind of-- might seem like we're in a rough spot. But I'll show you that we're not. understood them, then we can do a transformation. So I'll explain that in a minute. But how do you actually find these things, these eigenvalues? Well, I've got to solve an equation A times w equals Lambda times w. And so the solution set to this equation is either w is equal to 0. That's one possible solution to this problem or the eigenvector w belongs to the null space of this matrix. It's one of those special vectors that when it multiplies this matrix gives back 0. Determinant of a matrix like A minus Lambda I is a polynomial of degree N. The N roots of this characteristic polynomic are called the eigenvalues of the matrix. So if we can compute that determinant and solve for Lambda, then we'll know the Eigenvalue. There are all the possible amounts of stretch that can be imparted to particular eigenvectors, right? We don't know those vectors yet, but we'll find them in a second. do an example. Here's a matrix, minus 2, 1, 3. And it's 0's everywhere else. Can you work out the eigenvalues of this matrix? Let's take 90 seconds. You can work with your neighbors. Nobody's collaborating today. I'm going to do it myself. OK. What are you finding? Anyone want to guess what are the eigevalues? AUDIENCE: [INAUDIBLE] JAMES W. SWAN: Good. OK, so we need to know A minus lambda I and its determinant. The elements of a diagonal matrix are always the eigenvalues because the determinant is the product of the diagonal elements. So these diagonal values here are the roots of the secular characteristic polynomial. It turns out the diagonal Elements of a triangular matrix are eigen Values, too. This should seem familiar to you. We talked about easy-to-solve systems of equations, right? Diagonal systems of equation are easy to solve. It's also easy to find their eigen values. If a matrix is real-valued, then we know that we're going to have a polynomial of degree N. It can have no more than N roots, right? And so A can haveno more thanN distinct eigenvalues. But complex eigenvalue always appear as conjugate pairs. And here's a couple other properties. The trace of a matrix, which is the sum of its diagonal elements, is the product of the eigen values. It's possible that lambda 1 here is an eigen value twice. a matrix is also the sum of the eigenvalues. These can sometimes come in handy-- not often, but sometimes. Here's an example I talked about before-- so a series of chemical reactions. We want to know how the concentrations of A, B, C, and D vary as a function of time. And our conservation equation for material is here. This is a rate matrix. We'd like to understand what the characteristic polynomial of that is. The eigen values of that matrix are going to tell us something about how different rate processes evolve. The characteristic polynomial looks like this. What are the eigenvalues of the rate matrix? What is this eigenvalue 0 correspond to? What's that? OK. Physically, it's a rate process with 0 rate, steady state. What physical process does that represent? It's something evolving in time now, James Swan says. He asks the audience to guess what 0 is and what it means. The audience's guess is that it means 0 is a solution. It's 0. Minus k1 is another solution. The eigenvalues can be interpreted in terms of physical processes. This quadratic solution here has some eigenvalue. I don't know what it is. But it involves k2, k3, k4. And this is a typo. It should be k5. And so that says something about the interconversion between B, C, and D. Is that too fast? Do you want to write some more on this slide before I go on, or are you OK? Are there any questions about this? No. There's a null space to this matrix, right? We won't be able to eliminate everything. So let's try to find the eigenvectors of this matrix. They're minus 2, 1, and 3. So I want to solve this equation A minus this particular Lambda, which is minus 2,. times identity equals 0. It's already eliminated for me. I have one row which is all 0's, which says the first component of my eigen vector can be freely specified. The other two components have to be 0. This eigenvalue? 0, 0, 1, or anything proportional to it. All these eigenvectors have a geometric multiplicity of 1, right? I can just specify some scalar variant on them. And they'll transform into themselves. Can you do that? Can you find this eigenvector? Try it out with your neighbor. See if you can do it. And then we'll compare results. This will just be a quick test of understanding. Are you guys able to do this? Sort of, maybe? James W. Swan: Try this example out. See if you can work through the details of it. I think it's useful to be able to do these sorts of things quickly. Here's a matrix. It's not a very good matrix. But it's all 0's. So what are its eigenvalues? It's just 0, right? And they're 0. That eigenvalue has algebraic multiplicity 2. Can you give me the eigenvectors of this matrix? of equations or for transforming systems of ordinary differential equations. But we're only going to be able to do that when we have this complete set of eigenvectors. When we don't have that complete set, we're going to have to do other sorts of transformations. You have a problem in your homework now, I think, that has this sort of a hang-up associated with it. That's something to think about. A times a matrix W is equal to W times the matrix Lambda. made them the columns of a particular matrix. But it's nothing more than a restatement of the fundamental eigenvalue problem we posed at the beginning here. But what's nice is if I have this complete set of eigenvectors, then W has an inverse that I can write down. So another way to state this same equation is that the eigenvalues can be found from this matrix product. And under these circumstances, we say the matrix can be diagonalized. There's a transformation from A to a diagonal form. ways of writing this fundamental relationship up here when the inverse of W exists. So this is a useful sort of transformation to do. We haven't talked about how it's done in the computer. The computer won't do Gaussian elimination for each of those eigenvectors independently, right? Each elimination procedure is order N cubed, and you got to do that for N eigenvctors. That's pretty slow. There's an alternative way of doing it that's beyond the scope of this class called-- it's called the Lanczos algorithm. N cubed sort of calculation to find all the eigenvalues and eigenvectors solving a system of equations. Here's an example of how this eigendecomposition can be useful to you if you did it. So we know the matrix A can be represented as W Lambda W inverse times x equals b. But there are times when we deal with so-called symmetric matrices, ones for which they are equal to their transpose. So this becomes trivial to do then, this process of W inverse. in a lot of cases. You can prove-- I might ask you to show this some time-- that the eigenvectors of a symmetric matrix are orthogonal. They're also useful when analyzing systems of ordinary differential equations. So here, I've got a differential equation, a vector x dot. So the time derivative of x is equal to A times x. And if I substitute my eigendecomposition-- so W lambda W inverse-- and I define a new unknown y instead of x, then I can diagonalize that system of equations. There are many times when there's not a complete set of eigenvectors. And then the matrix can't be diagonalized in this way. So there's an almost diagonal form that you can transform into called the Jordan normal form. There are other transformations that one can do, like called, for example, Schur decomposition, which is a transformation into an upper. And you'll find out that this same sort of analysis can be quite useful in nonlinear systems of nonlinear equations. triangular form for this matrix. We'll talk next time about the singular value decomposition, which is another sort of transformation one can do when we don't have these complete sets of eigenvectors. You'll get a chance to practice these things on your next two homework assignments, actually. So it'll come up in a couple of different circumstances. I would really encourage you to try to solve some of these example problems that were in here. Solving by hand can be useful.

ROUGE-1: 47.83, ROUGE-2: 45.47, ROUGE-L: 45.40
BERTScore: 70.00

==============================================
==================== [28/100] ====================
Summary:
A random variable is a number that's produced by a random process. The number of faulty pixels in a monitor is also produced from an unpredictable randomness in the manufacturing process. One example is a system that you're watching and you're going to time it to see when the next crash comes, if it crashes. That number is produced by this random process of whether the system works or not. It's called a random variable because it's unpredictable that it happens in some random way. It can also be called a non-random variable, because it can't be predicted. that really is modeled in physics as random is when you have a Geiger counter, you're measuring alpha particles. And if I flip coins then the number of heads in a given number of flips-- let's say I flip a coin n times. OK what is abstractly a random variable? Let's look at that example of three fair coins. So each coin has a probability of being heads that's a half and tails being a half. Or alternatively you could think of flipping the same coin three times. heads is a number that comes out of this random process of flipping the three coins. Another one is simply a [? 0-1 ?] valued random variable where it signals 1 if all 3 coins match in what they come up with, and 0 if they don't match. One of the things that's a convenient use of random variables is to use them to define various kinds of events. The event that C equals 1, that's an event that-- it's a set of outcomes where the count is 1 and it has a certain probability. We think of the outcomes in the sample space as the results of a random experiment. They are an outcome and they have a probability. And when the outcome is translated into a real number that you think of as being produced as a result of that outcome, that's what the random variable does. So formally, a random variable is not a variable. Or it's a function that maps the sampleSpace to the real numbers. And it's got to be total, by the way. It's a total function. Usually this would be a real valued random variable. I look at the event that R is equal to a, that's an interesting event. And it's one of the basic events that R puts together. If you knew the answer to all of these R equals a's, then you really know a lot about R. That's why this little topic of introducing random variables is also about independence because the definition of independence carries right over. Namely, a bunch of random variables are mutually independent if the events that they define are all mutually independent. could say explicitly where it comes from as an equation. It means that the probability that R1 is equal to a1 and R2 isequal to a2 and Rn is Equal to an. And the definition then of mutual independence of the random variables R1 through n, Rn holds is that this equation it holds for all possible values, little a1 through little an. So let's just practice. Are the variables C, which is the count of the number of heads when you flip three coins, and M, [? the 0-1 ?] valued random variable that tells you whether there's a match, are they independent? Well certainly not. 2 tails and there's no match. So without thinking very hard about what the probabilities are we can immediately see that the product is not equal to the probability of the conjunction or the and, and therefore they're not independent. Well here's one that's a little bit more interesting. In order to explain it I've got to set up the idea of an indicator variable, which itself is a very important concept. So if I have an event A, I can package A into a random variable. And it means that really I can think of events as special cases of random variables. of random variables one way. We have another concept of independence that holds for events. The definition for random variable was motivated by the definition for events but it's a different definition of independence of different kinds of objects. Now if this correspondence between events and indicator variables is going to make sense and not confuse us it should be the case that two events are independent if and only if their indicator variables are independent. And this is a lovely little exercise. It's like a three-line proof for you to verify. number of heads we can ask whether the event M, which is the indicator variable for a match-- the random variable M-- and the indicatorvariable IO are dependent or not. Now both of these depend on all the three coins. IO is looking at all 3 coins to see if there are an odd number of heads, M is looking to see whether they're all heads or all tails. And it's not immediately obvious that they're independent, but as a matter of fact they are. this can have value 0 and 1. If R is independent of S then R is really independent of any information at all that you have about S. And of course the notion of k-way independence carries right over from the event case. If I have k random-- if I have a bunch of random variables, a large number much more than k, they're k- way independent if every set of k of them are mutually independent. of f of S, any transformation of S by a fixed non-random function. course as with events we use the 2-way case to call them pairwise independent. If we have k coins and Hi is the indicator variable for how coin I came out, whether or not there's a head, now O can be nicely expressed. The notion that there's an odd number of heads is simply the mod 2 sum of the Hi's. And this by the way, is a trick that we'll be using regularly that events can be defined rather nicely in terms of doing operations on the arithmetic values of indicator variables. makes the k plus 1-- k plus first. And the reason why any k of them were independent was discussed in the previous slide when we were looking at the events of there being an odd number of heads and a head coming up on the i flip. For a bunch of major applications this pairwise independence is sufficient. It's harder to check mutual independence. You've got a lot more equations to check. We'll be making use of it in an application later when we look at sampling and the law of large numbers.

ROUGE-1: 61.37, ROUGE-2: 58.35, ROUGE-L: 58.37
BERTScore: 72.82

==============================================
==================== [29/100] ====================
Summary:
s gawan and the Green Knight um I believe this is the last piece where we don't know who the author is where it's unknown um I find the background interesting and that through textual Clues they're able to figure out who wrote it. SAR Gowan as a ruthless bloodthirsty Warrior um we really don't see him in that regard um this is just an excerpt so the rest of the story maybe um but what we want to focus on here as you see the the lit term archetype. archetypes um you know these certain types the of characters you know the Damsel in Distress the heroic KN you know that type of thing those are those are phrases and names and roles that go throughout history in literature and movies and books. As we go through this look at the the role of the hero I think straight off we can say that that's probably gow or sir GA however you want to say it okay then you have the villain or the dams and all as we come through the story try to put these titles with certain characters. well must be five it's pentag the five things that the way that they live their life you know being good to women and being chorous and all that stuff but being HonorBound having honor is huge you've seen that in movies you know Samurai and stuff people would rather die than be captured and so they fall on their sword right that's very you know Roman to some degree with regards to Brutus and and uh some of those other Emperors um you know from from the past um so anyways follow along uh we're going to uh go through this it'll take a little bit of time and uh we'll talk about it upon completion but it's a sir Gowan or G and the Green Knight back to the beginning we start to get those archetypes. if you look down at the bottom of uh uh uh well it's actually on 176 now he comes in and addresses everybody and everybody gets kind of kind of quiet uh because this is a huge monstrous man with a monstrous Axe and he saysi come to uh speak to the person in charge and off Arthur King Arthur says that would be I and he goes I've come to search you based on reputation remember how we talked about the the honor okay people don't do you know if the knights do something it's a reflection of Arthur and Arthur as we know from all of our you know illusions of movies and cartoons and stuff that you know he is a good guy. your reputation Royal sir is raised up so high and your castle and Cavaliers are accounted the best the mightiest of male clad men in mounting fighting the most warlike the worthiest the world has bred most Valiant to VI with in viral contest and as chivalry is shown here so I am ass assured at this time I tell you that has a track here so he goes on in great detail say I've come here because of the reputation did you notice some of those alliterations sprinkled throughout there hopefully it did. I so a game but to see if people here are as good as their word and so he says on page 177 that I am here not for war and I shall offer to him this fine axe freely that they strike a blow in return for another. Arthur says oh well surely you just this is ridiculous but I will do this if this is what you truly want I'll do it and we all know that Arthur based on what we know of him from the past you know is true to his word. As you firmly seek Folly find it you shall. do it and I will give it to you not out of punishment but that's that's what you're looking for um and no good man here so his other Knights is a ghast at your great words. Think about it if Arthur for some reason fails their King has to willingly take a hit with an axe do you see GA getting in the way and say no you're too valuable you'reToo important you're the king let me take this for you let me deliver this shot and if for somereason I fail then I alone will take the shot so a very Noble thing yes compared to the Knight that we've been experiencing thus far the type of night from the wife of bath. see a big difference uh Raper and this guy big difference okay and so he says I will do this and I will take the axe um where's the actual beheading there on line 182 or so uh they're kind of getting the groundwork going goes when I have taken the blow after you have duly dealt it then you may keep your Covenant and call on me and if I waft you no words then well may you prosper stay long in your own land and look for no further trial so if after the deal I'll tell you where you can find me I will give you my name there are no tricks here. bath he didn't know that he was going to have to marry that woman did he no would he have still done it well how much does he value his life you know probably. The Green Knight graciously stood on the ground with his head slightly slanted he even got down exposed his neck the naked neck for the business now doe go gripped his ax gathered up and slashed down and what happened well line 203 the fairhead fell from the neck struck the floor and people spurned it as it rolled around. his Steed snatched the bridal stepped into the sturup and swung a loft holding his head in his hand by the hair he settled himself in the saddle as steadily as if nothing had happened to him though he had no head. Then the head will obviously have to tell him his name and where you can find him are you envisioning this cut the head off the body walks over I mean you've seen it comically where a headless body is looking for a head on the ground right. will be able to pick it up and still live and survive and so oh crap this is not going to turn out well. The Knight tells him you have a year to find me you can find me I the Knight of the green Chapel green Chapel no kidding Everything Green line 232 233 come or be called a coward and it's not just sir GNE being called a cowardly we've got to understand that mindset who would that be calling a coward Arthur and everybody else the Knight came here specifically to challenge the best that Earth has ever bred. mind um in this you know kind of lengthy introduction just to set up the fact that this guy is having some supernatural abilities that the normal person like probably GNE does not have. So that will lead us into uh into the uh the coming up here with him looking for the night so at the bottom of 181 uh he's gone off on his journey had a year and a day to find it and throughout the book you I'm sure there are tons more Adventures probably more of those uh you know uh battles or actions. you receive the the hunter the owner of the house the husband says whatever you receive you must give to me that seems kind of weird what possibly could he receive while he's there well we find out that the wife really kind of starts to come on to him over time okay real flirty she's she's a temptress okay very seductive uh she gives him a kiss what does he do when the husband comes home that day cuz the husband's going to share his his food share his everything with him as long as GNE you share with me. you know of his pact uh with King Arthur to be a good individual. She eventually does give him a green girdle um a green corset a a sash some sort of clothing that he can wear under his stuff and she gives that to him and he accepts it okay which isn't necessarily so bad. She says you wear this and no harm will fall upon you that's about the best thing you can say to somebody who's getting ready to go get hit in the head with an axe. up my sleeve come time to get that shot in the head um and so he does leave and he keeps that GLE for himself um and doesn't give that away page 185. He roamed looking for this man he roamed up to the roof of that rough dwelling then from that height he heard from a hard rock on the bank beyond the brook a barbarous noise. What it clattered amid the cliffs fit to cleave them apart as if a great sight were being ground on a grindstone. thing and so he hears it you know happening and um so he screams out and the and the um and the Green Knight comes he says by there said one on the bank above his head and you shall swiftly receive what I once swore to give you. He chastises him and tells him take off your helmet uh and offer no more argument or offer noMore argument or.thing and he gets ready to hit him and it's one of those kind of like you've had friends before probably have come up to you and go like that. action than I did when you whipped off my head with one stroke no s GNE by God who gave me a soul the Grievous gash to come I Grudge you not at all strike but the one stroke and I shall stand still and offer you no hindrance you may act freely I swear but page uh not page line 401 uh the dawnless man would have died from the blow but go glanced up at the Grim axe beside him as it came shooting through the shivered shivering air to shatter him. that upsets him obviously it's calling into question his his loyalty his OES his his manhood um he says do it again I will not flinch go on game on 185 187 excuse me um I shall stand your stroke not starting at all till your axe has hit me um gaw waited unswerving with not a wavering limb but Stood Still as a stone or the stump of a tree gripping the rocky ground with a 100 grappling Roots then again the Green Knight began to GD so now you have a whole heart I must hit you. take his head off like he did with the like what happened to the Knight he just dinged them and so there was some blood. We find out all along that sir gain was never really intended to get any Nick at all if he stayed true to what his words were. The most he was ever going to do was scare him and probably wasn't even going to hurt him and then congratulations you guys are honored okay you guys exude honor you are like what you say you are and not just you but King Arthur and the other night but since you lied that's why you got the Nick. little of all but ultimately the main one you need to get away from this is think about it you live your whole life a certain way and honor Cod and you were just proved to be a coward and you broke your oath to Arthur. How do you think he's going to respond embarrassed have you ever had somebody say to your parents not necessarily I'm mad at you I'm angry at you but I'm disappointed in you Justin you just I'm just very disappointed inYou? That crushed him. in this and the Green Knight pushed her along hey try to seduce him see what happens we're testing him to see what's uh if he's truly a good uh a good person or a coward as it turns out. 510 curses on both cowardice and Covetous uh their Vice and villainy are virtues undoing um uh where I you finally see that now I am faulty and false and found fear fearful always in the train of treachery and untruth go woe and shame. celebrate was it New Year's is that what it is we'll come back and celebrate this cold New Year I'm not mad at you so now we need to go back and look remember the archetypes we talked about we have the the protagonist the antagonist who is the real villain of this piece is there a villain in the Green Knight? The Green Knight's ultimate purpose is simply to challenge challenge King Arthurs and his crew and see if they truly are as honorable as they say as legendary as Legend has as the stories have it. so he's the protagonist but yet I don't think uh you know the whole good vers bad protagonist you know hero villain protagonist antagonist it's kind of a a mdl you know very murky we don't understand exactly who it is. We do have the Damsel in Distress we have that woman the temptress um the sexual being that's trying to corrupt the hero um and take him down the path maybe uh satanic in some degree with regards to trying to lure the good person away with the forbidden fruit.

ROUGE-1: 67.51, ROUGE-2: 65.98, ROUGE-L: 66.78
BERTScore: 74.91

==============================================
==================== [30/100] ====================
Summary:
hey what's going on YouTube boy Robert and my mission is to teach you everything in the kitchen now earlier this week at work I learned and I was wondering what are the fruits and vegetables I can turn in the salt as well so today so these are the fruit and vegetables we have today we have blueberries strawberries Kiwis red beets yellow beets pineapples right in fruit and cucumber this is the equipment you'll need for today you don't need one blender sheet trays mason jars parchment paper aluminum foil a spice grinder a bowl with a strainer and a plastic spatula. I did that right because the fruit was already soft and I blue knitted with water it went right through the strainer so next time I'll call it just smear it on the actual cutting board itself another cutting board the sheet tray yeah I'll smear on the key trade first but the two prettiest ones I would have to say it was probably the red beets [Music] now movies be sweeter you can blend it with sugar and but I had sort of sweetness as for these a cucumber the Brendan beets and the red beans a blue noodles with salt so they could be added to savory dishes.

ROUGE-1: 53.94, ROUGE-2: 53.58, ROUGE-L: 53.94
BERTScore: 69.91

==============================================
==================== [31/100] ====================
Summary:
The six Vital Signs are pain oxygen saturation temperature heart rate respirations and blood pressure. Before you start you want to perform hand hygiene and provide privacy to the patient and tell them what you're going to be doing. If they do have pain ask them the quality what does it feel like and where it is at so hi Ben my name is Sarah and I am your nurse and I'm going to get your Vital Signs and I'll be getting your hand hygiene as well as your hand movements. first thing I want to ask you what your pain rating is are you having any pain rate on a scale of0 to 10 yes pain in my shoulder and it's a three okay and what is it feel like it's just a sharp pain when I raise my arm okay now I'm going to get your temperature there's several ways you can take a temperature every facility has a different system set up so use what they have but you can taking it orally you can takes it axillary you cantake it tanic in the ear or you can taken it temporally or rect um rect is the preferred route usually on your pediatric patients but in adult patients normally we do it orally. we're going to do turn your thumb Omer on make sure you're using the proper sleeves if you have any sleeves for it clean it everything like that follow your hospital protocols and have the patient lift up their tongue and put the probe underneath the tongue and have them close the mouth with the tongue over the probe and hold it there until it beeps a normal temperature is about 97° fit to 99° F okay and take the thermometer out and read it and his temperature is 98.2 and then clean it properly per Hospital protocol. In a second I'm going to show you how to actually count the heart rate using the radial artery. While I'm counting the heart rates I count that for 30 seconds if it's regular and then the next 30 seconds I count the respirations which I look at the rise and the fall of the chest and that equals one breath. If you tell a patient you're going to count their respirations they change the rate of breathing so it's good to conglomerate those two together so you can get a more accurate reading. groove right there or you can use the brachial artery which is in the bend of the arm where the anticubital fosset area is. You can also use the cored but here we're going to use the radial. Count for 30 seconds if it's regular if it is irregular count for 1 minute. A normal pulse rate in an adult is 60 to 100 beats per minute okay the heart rate I got 60 and his respiration were 16 now we are going to get his blood pressure. may have to learn how to do a manual one now my previous video and a card should be popping up I go over the two-step method if that's how you're being instructed. In this video we're going to go over  the one step blood pressure of how to obtain it manually so what we'regoing to do we are going to palpate the brachial artery this is in the bend of the arm and make sure you ask the patient which arm you can take their blood pressure in because you don't want to take it in arms with if they've had blood clots. to 200 mm of mercury or until you don't hear that braak your artery anymore okay we're blowing it up to about 200mm of mercury. We're listening for that first sound and that first s sound will be our top number of our blood pressure which is our systolic. That is how you check bottle signs now whenever you're done remember to let the patient know what their bottle signs were and um do hand hygiene and clean your equipment before you go to the next patient so be sure to check out all my other videos on nursing skills.

ROUGE-1: 60.35, ROUGE-2: 57.47, ROUGE-L: 59.68
BERTScore: 74.60

==============================================
==================== [32/100] ====================
Summary:
so we saw that the three-point correspondences are needed to solve the camera pose estimation problem in the grenade formulation. The disadvantage of this particular formulation is that it ends up with a four degree polynomial which means that it could give up to a total of four possible solutions. In order to choose the correct solution at least the fourth point is needed here so what we usually do here is that if we choose the grenade algorithm we'll use the three point to solve for the p3p problem and given that camera pulse of rnt because we also know k. would be considered as the correct solution since minimal or fourth point is needed to check for the correct solutions. The algorithm was formulated by quan at all in a paper that was published in the 1990s. The question becomes whether can we find the solution directly from any four point correspondences or more than four point Correspondences such that the solution is unique, the answer is yes, says Quan. The solution can be found by solving a system of three polynomials equation from the cosine rule. rewritten into this form and uh interestingly we note that for every equation here it's only a function of our two unknowns so uh we'll get this system of uh polynomial equation written as f12 that is dependent on s1 and s2 and f13 and f23. If we use three point correspondences here we can actually add on to this fourth order polynomials or equation and to over constrain the system. So as a result we'll first get six polynmials in terms of uh s i and s j and now one of the straightforward way is that since we have six of them the six choose three this is going to give three. us three polynomial equations three fourth degree polynometric equation so which we denote as g x g prime x and g prime prime x where x can simply be equals to one of the s square for example we call it s i square. One straightforward way would be to simply solve for x independently in each one of these three. polynomials equation and then just find a common solution to the to this subset. But it's not a good approach for three reasons because what we have to do here is that we. have to solve several four degree poylnomial equations which can be time consuming. furthermore we have three polynomial equations with the same unknown variable so there's no guarantee that all this are going to be the same solution due to noisy data and probably the most important part is that we cannot profit from this data redundancy which should increase the stability. In this case here because get solutions doesn't agree well due to the noise so it means that the solution is not stable at all and a better solution here is proposed by uh kwan and lan in the paper published in active tipami in the year 1999. any of the unknowns in the the depth where we simply write it as s i square over here so this can be derived in in this way so here i wrote out all the six combinations of the polynomial equations f i j over here we can see that each one of this equation it's a just a function of two unknowns. When we can factorize out all these coefficients as a matrix and the knowns which are x 4 x 3 x 2 x and 1 can be written as a vector over here 0 0 and as a result we'll get a three by five matrix and a five by one vector. over here which is in the form of a x equals to zero uh we have seen this homogeneous linear equation many times so now this means that we get this form of equation over here. A t which is written as a t equals to 0 over here and what it means is that we simply have to solve for the unknowns over here so this matrix here is known and the unknown contained in this particular vector here and we know that uh since a is a three by five matrix uh at most have a rank of uh three this is the same as solving ax equals tozero. the svd of a is going to give us a left octagonal matrix of three by five and a square singular matrix with a diagonal of sigma one sigma two sigma three where the last two singular values here are going to be zero. We can rewrite the solution we can write the solution of t5 that we have formulated earlier on here in terms of the two the null space basis vector that we've found from the right singular. We have to now determine Lambda and rho in order to get a solution for t which will lead to the solution. s1 we know that t5 here is actually a vector that is made up of the same entry but of different order so x4 x3 x2 x and 1 of different entry. By observation any two elements the product of tij is going to be equal to tk and tl for this constraint to be valid where i plus j must equal to k plus l we can verify this suppose that i here equals to 1 and j here equalsto 2 and if k here for example equals to 3 so k here equal to 3 l here must be equals to 0 we can substitute this in. We can substitute the respective components of t5 into this particular constraint to get this equation over here. For example in in this case i choose i equals to 1 j equals to 2 and k equals to 3 and l equals to 0. If we look at all the combinations we are in total get seven such equation that is given by this table over here that fulfills the constraint of i plus j plus k plus l and within this particular range that is written here so as a result we'll get seven of these equations over here which we can stack together. three by one vector it consists of lambda squared, rho squared which are the unknowns that we want to solve. Taking svd of b we get the left singular factors multiplied by the singular values as well as the right singular vector matrix over here. The solution would be the one that corresponds the last column of v over here so once we have solved for the null space vector y using the svd what we can do is to proceed on to solve for lambda and rho because we know that y 3 over here is equals to a lambda square. rho square equals to y 2 which we can take this divided by this to cancel away Lambda one of the lambdas here to get the ratio of Lambda over rho. We can do the same thing by y1 divided by y2 where rho cancels off and we will get the same ratio so there are two possible solutions. After we obtain the ratio we can substitute it back into this equation over here which i have gotten from the two null space basis vectors e4 and v5 respectively earlier on when we solve for t5. where we can solve for since we know that x equals to s1 squared. Once s1 is solved we can back substitute s1 into the polynomial equation of f i j s i and s j equals to zero. After we have gotten all the unknown depths we can do the same thing to to apply absolute orientation to recover the camera pose as in the grenade algorithm and here what's interesting here is that because we have four point four point we can get all the depth in this way. correspondences and we can see that because rho and lambda here can be determined in a unique way and uh x here can also be determined  in the unique way where we simply take out the average of this because all the illusions are going to be quite similar or quite close to each other. As a result we'll get the unique solution provided that the four points are not degenerate so uh in this linear four point algorithm the the there will still be two degenerate cases. as what we have seen earlier on now uh it happens that the linear four-point algorithm can also be applied to more than four points so for example when n equals to five when there are five point correspondences and in this particular case uh we uh we will end up to have a system of polynomial equations that is in this form a uh t equals to 0 where t here still remain as a 5 by 1 vector that consists of x that we saw earlier on where x here is simply equals to s 1 square. equation we can stack them all up so one two all the way to six equations and we end up with a coefficient matrix with an a matrix of of dimension 6 by 5. in order for non-trivial solution to exist then this guy here better be of a maximum of rank four so what we can do here is that we can take the svd of a and this will give us u sigma v transpose where we simply the vector that corresponds to the least singular value in sigma. The same algorithm that we use to solve the linear four point and the linear five point can be applied to any number of point correspondences that is four or uh more points. Here we just need to solve for the svd of a m minus 1 multiplied by m minus 2 divided by 2 by 5 uh matrix of a to get the solution for the vector t 5 but the problem here is that the overall complexity of a svd is much higher than the number of points involved in the solution. The epmp algorithm mitigates the problem of the linear endpoint algorithm that was shown earlier on by quan and lun that was published in the year 1999. The algorithm has cubic complexity in the order of the number of points that is used to form a. The cubic complexity here becomes a limiting factor for us to apply for this particular algorithm to a number of point correspondence which is significantly large now in 2006 the paper published by vincent lapati which is called the epMP algorithm was first published. proposed by lapati in the year 2006 is that instead of using every single point correspondences that is given to us the the core idea is that here we'll make use of all these points to define four control points. Even for a very large n the number of control points still stay constant as uh fall. We'll first look at the case where these four control Points are non-coplanar control points this means that these four Control points will not lie on a plane. We can see that uh here it becomes more tractable because uh even for avery large n of points. a pi uh with a superscript of w what this means is that uh this pi this particular point pi is defined with respect to a world frame which we call f w over here then similarly we will define the four control points that do express the world coordinates so given all these coordinate points of piw here that we've seen earlier on what we want to do here is to find out the relative transformation between the camera frame and the world frame. The number of unknown depth actually grows with the number of points and so now since we are using the control point which stay consistent as four points we will see that uh we have a lot lesser number ofunknowns. over here so we'll make use of the same set of alpha the sameSet of weights that we have seen defined earlier on to weigh the control points in the camera frame. We'll first see how to solve for alpha as well as cj in the world frame using a simple technique that was proposed in this particular paper. The first step would be to compute the centroid of the world points that means that i give uh we are given all the this points which we denote as p i c over here. and then we select the other three control points because all together we need four uh control points. The only set of unknowns that remain would be the control points in the camera frame denoted by cj to the superscript of c where j here equals to uh 1 2 3 and 4. Once we have solved for the alpha as well as the control point so we know alpha ij for every 3d point we'll use the same alpha here in our expression of the 3d points expressed in the world frame. the 2d to 3d correspondences where these 3D correspondences correspondence simply refers to pi in w but we also know the the the corresponding projection into the camera frame so what we can do here what this means here is that we know the projection of pic into the image now let's denote the camera intrinsic value a over here. We can substitute this p-i-c using what we have defined earlier on as a weighted sum of the control points to get this equation over here so now this equation can be expanded into a matrix notation where we fill up every entry in the matrix. Now we have two equations over here in terms of the control points and all the known parameters because this is just a projection of one single point i over here. Since each point correspondence gives us two independent equations what this simply means is that we need to stack them up into 2n by 12 matrix which we call m. The number of basis solutions that we can get from solving the equation mx equals to zero over here depends on the size of m and which in turn depends upon the number of point correspondences that we have. way of solving for the basis equation from this uh mx equals to 0 where m here is a 2n by 12 matrix and x here it's a 12 by 1 vector. Most expensive step of computing this equation over here would be to compute m transpose m itself. Since m is linear with respect to the number of points n this means that uh to compute this particular step over here it was it would be in the time complexity of a linear in the order of uh n and that's why the epmp is a linear complexity uh solution. have only one basis solution where capital n here equals to 1. what this means is that the rank of m must be equals to 11 and means that there are 11 unique constraints that forms the metric of m. Since we know that each point correspondence is going to give us two constraints this simply means that we need a total of 5.5 point correspondences in order to form a metric m with rank of 11 and that would equate to be six point. So in this particular case uh where we have six or more point Correspondences we'll always have a one null space equation that's parameterized by beta over here. that parameterize the four unknown control points in the camera coordinate frame and we'll make use of the known distance between the control points to solve for the unknown beta over here. Since we have four points and all together we would have six constraints over here we have all together six pairs of distances over here one two three four five and six the six distances which we can put together into this weighted sum equation over here which we normalize over all the combination of the distances. We can stack those six constraints into a non-homogeneous linear equation that looks like this l beta equals to rho where beta is parameterized by beta 1 1 beta 1 2 and beta 2 2. be simply the unknowns that is made up of beta 1 beta and beta2 so this is an over-determinant system where we can just take the pseudo inverse of l where beta here is given by the pseudoverse of l multiplied by rho. This will give us the solution for beta which we can then use to solve for beta 1 andbeta2 so in the case where n equals to 3 which means that the solution is a formed by a linear combination of 3 null space basis vector v1 v2 v3. in practice we actually do not end up here because we will not take 4.5 points usually we will just take a minimum of 5 point in order to get these equations over here mx equals to 0. so uh here we solve for beta one beta two and beta three using the same method as uh described earlier on because we have six constraints where we have three unknowns over here. Using the same way we end up with l beta equals to rho which is a non-homogeneous linear equation where l here is a 6 by 6 matrix. four of them are lying on the same plane that means that any one of the point is dependent on all the other three points which means that we have less constraints right now. We'll still use the same formulation as before to formulate m but now m is going to be only two by nine where there's a nine dimensional eigen vector that we need to solve for that's a basis uh uh solution. The main difference here it would be that uh the number of quadratic constraints that we've had before would be between two and nine. The points are actually the same 3d points that is defined in two different reference frames so let's say these are the 3d point p i w would be all expressed with respect to f w. We can solve r and t between these two frames using the absolute orientation algorithm. The efficient pmp algorithm is a on complexity algorithm that solves the camera post estimation problem using theabsolute orientation. It solves for the unknown depth and then make use of the known depth to solve for the rotation and translation using the Absolute post-estimation problem. for the camera pose using a set of control points using four control points in particular and we saw that this uh it's uh the complexity is a linear in terms of the number of points which is much easier to compute then we also saw the degeneracy cases for the camera post estimation problem in particular. If all the points plus the camera center forms a plane then this is also a degenerate case and that's the end of today's lecture thank you mx equals to zero. Mx equals zero.

ROUGE-1: 54.78, ROUGE-2: 52.76, ROUGE-L: 52.65
BERTScore: 74.77

==============================================
==================== [33/100] ====================
Summary:
Time dilation is a change in the light frequency. If there is a time dilation effect due to gravitational fields, then there's also a redshift which is of gravitational fields. The way to think about this is first to say, OK, now the light-- the delta t equals the light to travel-- is l divided by c. The change in velocity is g, acceleration. So the Doppler shift then is c divided by l, which is the speed of light. And I would like you to get a feeling. How big can this effect be, the effect of redshift here? the frequency, the new frequency, divided by the initial frequency. And that can be approximated by 1 plus delta v over c. So we find that it's 1 plus g times l over c square. Now the speed of light is pretty fast, 3 times 10 to the 9 meter per second. And this distance is only 22 and 1/2 meters. But nevertheless, experimentalists at Harvard tested this effect. So Pound, Rebka, and Snider in the 1950s and '60s were able to show this very tiny effect.

ROUGE-1: 72.00, ROUGE-2: 68.07, ROUGE-L: 57.52
BERTScore: 81.34

==============================================
==================== [34/100] ====================
Summary:
During the semester we have a few recitation instructors they help with the students during the recitation section. During those sections your the the instructor will solve a similar problem like what is actually covered during the same during the lecture and that give the students another chance to look at more example and to get for media will get used to the calculation which we carry how for the first time during the the lecture. We did not record the Recitation sections during the fall semester in 2016 on the other hand we included problem-solving videos from Professor with Busha.

ROUGE-1: 67.77, ROUGE-2: 66.22, ROUGE-L: 67.77
BERTScore: 85.45

==============================================
==================== [35/100] ====================
Summary:
The CDF of x is the probability that X is less than or equal to little x. We use the standard formula, which is minus infinity to infinity t times fx of t dt. The integral of u to the a t is 1 over a times e to the t. The derivative is what's going to go in that integral. The CDF is evaluated from 0 to infinity, but then you take the limit as x goes to x. It's not going to going even if you try all kinds of u substitution. infinity. So that's going to help us here. And this negative-- these negatives cancel. And we're left with negative x minus lambda x plus the integral of this. All right, so now the limit. So for the limit, notice that x increases as x goes to infinity, and this exponential decays. But the exponential is going to win because it decays way faster than x. And so this first term isgoing to go off-- the limit is goingto go to 0. the same set of steps from before. For x squared, it's just going to be t squared. The only thing that's going to change is what we choose for u here, for the u substitution. So the derivative is going to changed to 2t dt. And so here in this term, we get negative 2t e to the minus Lambda t. But there's a negative sign out here, so the negatives cancel and we're left with a positive sign here. the limit as x goes to infinity-- the exponential will beat x squared. No matter what polynomial we put in there, the exponential's going to win. We're given that x1, x2, and x3 are independent and identically distributed. They're exponentials with rate Lambda. We are asked for the PDF of z, which is the max of x1,. We take the CDF and then take the derivative, right? And so we have 1 over Lambda squared for the variance. of structure as before. If z is less than 0, x1, x2, x3 are positive-- non-negative. And so this is the probability that if you get little z less than0, you're not going to have any probability there. And if z is greater than or equal to 0 is where it gets interesting. We need to do something special. So the special thing here is to recognize that the probability of the max being less than orequal to z is actually also the probability. of each of these random variables individually being more than or less than z. events are equivalent and this is true. By independence we can break this up. And we get-- these are all CDFs of the exponential and they all have this form. Plug this in here. And then, try to take the derivative to get the PDF. Let's see. So it's going to be the same, like this for z less than 0. For z greater than or equal to 0, the derivative of this thing is by chain rule, 3 times 1 minus e to the minus lambda z squared. that the min-- if the min of x1 and x2 is less than or equal to w, that each of them isLess than orequal to w? No, right? X1 could be less than and equal to. And x2 could be bigger than w. So that's definitely not true. So what do we do here? The trick is to flip it and say we want to compute the min being greater than. w. In that case, let's check if we can do this trick. So it's going to be-- Notice the similarity between this and this. The only difference is this has a 2 lambda in there. That means that w is an exponential random variable with rate 2 Lambda. You can also take the derivative of this and find that you get this. OK, so we're done with the problems. We computed some interesting quantities for the exponentialRandom variable in this. So then the PDF isgoing to be an exponential, whatever it is for an exponential.

ROUGE-1: 52.39, ROUGE-2: 49.72, ROUGE-L: 48.85
BERTScore: 71.64

==============================================
==================== [36/100] ====================
Summary:
Professor: Can you explain the physical significance of the crystal momentum? Professor: Let me answer that in a slightly backward way. Let's step back and think about the momentum, and ask what the momentum is. Professor: If you have a wave function, sine of x, such that, the expectation value of the wave function is x, then the momentum of that function is 1/x. The momentum is the same as the speed of light, which is the speed at which light travels through the air. in the state SI of x in the stateSI is equal to x naught, and the expectation value of p in theState SI is p naught. Then if you want to change the momentum, increase momentum by h bar k, the way to do that is to take SI and build a new wave function, SI tilda. And then the expectationvalue of x is the same. So, the information about the momentum can be encoded in these spatial variation of the phase of the wave function. question of what is momentum, apart from it's the thing that commutes with p or with x by i h bar. Another way to answer is to say that translations by l can be expressed in terms of momentum as e to the minus i upon h bar p l. A last defining property of the momentum is at the time variation d dt of p is equal to the expectation value of minus d the potential of x d x, also known as the force. So let's turn all these facts around into the crystal momentum. function. So what is this parameter q doing? Q is governing the spatial variation of the phase of the wave function. If the force is zero, we turn no external driving force, your wave packet maintains its crystal momentum. It's time independent. So the crystal momentum is something that time independent, unless an external force is applied, just like the momentum. However, it's different in a crucial way. It is not the eigenvalue p on five sub e q is not equal to a constant p naught times 5 sub eq. The eigenfunction, or the eigenvalue of our wave function, under translations by l, is a quantity that can be determined simultaneously with knowing the energy. If you have q, which is 0, and you increase it to pi over l, that value is effectively the same as the value minuspi over l. But that's really strange because that means that q itself, it's not strictly conserved. It's conserved mod 2 pi overl. When you have momentum conservation, momentum is strictly Conserved if there's no force. And even if there is a force, it is increasing control by the force as you turn on the force. just constantly increases. For the crystal momentum, that's not the case. You turn on a force, it increases according to the conservation law. But it's not increasing constantly. It's periodically defined. So it increases then it ends up at a smaller value. It increases and ends up in a phase. So developing an intuition for the crystal. momentum, I think, is best done by just playing with examples. And you'll do that more in the course on solids, which I encourage you all to take. Because it's really beautiful stuff. glossing over in the entire story here. So, is u of x a real function? Well, so when we started out asking what are the eigenfunctions of the transit by l operator, all we showed was that, and I'm going to do this on a separate board just to make it clearer. Tell me if this turns off, because it kept bumping. OK. So we've determined is that if we take q l is equal to alpha, then Phi sub q if eigenvalue is written in the form e to the i q x u sub q of x, where this is periodic. The potential of a free particle is also periodic under shifts by l. So the common eigenfunctions of translate by l and the energy are the wave functions Phi sub q, comma e, are equal to e to the i q l.to the iq l. Since this is periodic under. shifts of q, by 2 pi upon l, I can just choose to define q up to 2. pi over l. 2 q, I will take to be equivalent to q plus 2pi over l, because it gives the same eigenvalue. i q x times some function u of x, on general grounds. But we know what these eigenfunctions are. They're just e to the i k x. Where k squared upon 2 m is e. We just say u is constant and q is equal to k. But if we want to think about q is periodic by 2 pi upon l, then we cannot require that u is real. Because it must be the phase that makes this up. It must be, so I can always write this as e. that we allow u to be not real. It must be able to be an overall phase. But if we want u to. be always real, we can do that. We just can't impose this periodicity. Different values of q mean different wave functions. And this is really what's going on when you see those plots, sometimes you see the plots as parabolas. The bands are represented by parabola with wiggles, and sometimes they're folded up. And that's the difference. 2 pi upon l? Well, OK then. But u can't be real. Or we could take q to be not periodic by 2 pi l and impose that u is real. It's just a choice of variables. But it can't possibly give different answers. The point is, this is a subtle little distinction it we gloss over, and is glossed over into my knowledge every book on intro to quantum mechanics that even covers periodic potentials. So for the moment, let me deal with-- let's work with u real. And q, q an unconstrained, real number. the imaginary part, h bar over 2 m i. Well, hbar over m times the imaginary part of SI complex conjugate derivative, with respect to x, which is the current, in the x direction of SI. And we need this to be imaginary, or we will get no current. You show this in a problem set, if you have a pure, real wave function, for example. A single real exponential, that's decaying, as on the wrong side of a barrier. we want the imaginary parts, that's going to be e to the I over m. And then we're left with u squared of x. So this is the current, but we have to do it-- we had take advantage in order for this to be sort of clean, we had to take advantage of u being real. Everybody cool with that? Now there's one last twist on this, which is that if I have k-- if I've got q. If I have q, and I want, I can always write it as some q naught plus n pi over l. function not by single number q, but by q naught and an integer n. n is an additional integer, and what it's telling you is how many times did you have to shift back to get into that fundamental zone between pi and minus pi. So the current depends on both the part defined mod 2 pi over l, and the integer, which tells you how many factors of 2pi over l did you need to subtract off to get to that fundamental domain. And this fits nicely into this story, because now all we're going to get here is q, which isq naught plus n pi. minus 2 pi over l. Or minus pi overl. OK. And what we see is that there isn't a single energy. Because this is the energy the vertical direction for the band pictures. And so we can write the current now, in terms of h bar q naught upon m, u squared. And that's exactly the integer piece in n pi overL. And when you unfold this into the parabola picture, remember where these came from. Came from shifting over. And the higher up you go, the more you had to shift over. upon m u squared of x. So we get a contribution from the crystal momentum and from which we're in. OK? So sort of an elaborate story to answer the phase question. Yeah? AUDIENCE: [INAUDIBLE] PROFESSOR: Good. So here we had SI-- so SI-- I'm sorry. I should have done this for Phi. But I meant this wave function, right. This is Phi, this is Phi q. So from here we're going to get the imaginary part. in terms of the wave function. The eigenfunction of translate by l. U is just some periodic function which is contained which is defined from the wavefunction. From the energy. Did that answer your question? OK. So here, it just came from the fact that u is Phi is the e to the i q x u, x and then a factor of u for each of these. Other questions? Yeah. Yeah, I'm sorry, I don't know what the other questions are. function of q, not q naught, but so here'spi over l. Here's 2 pi over l, Here's 3 pi overL. And I need to do this carefully, because it's incredibly difficult to get the straight. OK. So here's the parabola that would have been, if we had not turned on a periodic potential. As we turn on the periodic potential, we know that the energies change. And so in the first band it's easy to see. is slightly above, and then it increases and decreases. For every value of q, there's an allowed energy. But it's different than it would have been for the free particle. And then we do the same thing for the next state. And it looks like this. So now imagine what happens when we take this, and we it over one two. What we get is a band the looks-- that should look like. That's what the second band should looklike. And indeed, when we put it in the fundamental domain, this is what we get. to plot u with respect to k instead, would that just be a parabola dotted line? If so, why do we not have really-- PROFESSOR: If we just wanted-- sorry. Say it again? AUDIENCE: E as a function of k instead of q. PROFessor: Oh. But k is not a well-- so what is k? K is just defined as h bar squared, k squared upon 2 m is equal to e. So this doesn't tell you anything. this diagram is telling you is which e's are allowed. If you put on a capacitor, played across your perfect lattice, you don't get any current. So the particle, the charged particle in your lattice just oscillates back and forth in a block oscillation, running up the band, and down the band. The question is could you explain again how imperfections and a lattice leads to actual conduction? The first question is given that that's obviously not what happens in real materials, why don't you explain it? we just give up on quantum mechanics and say it totally failed? And so this is a totally reasonable question, and I want to emphasize something important to you. That model led to a prediction, which is that if you put a capacitor plate across a perfect crystal, then you would get no current flowing across, you would just see that the electron wave packets oscillate. And that is manifestly what happens with copper. But the experimentalist comes back to you and says look dude. That is a ridiculous model because the copper isn't in fact perfect, it's messy. the theory side, because I'm a theorist and you should not let me in a lab. But I collaborate with experimentalists, so they're nice people. They're very good physicists. So here's something you can do. You can build a system that has exactly a periodic potential. It turns out it's very difficult to do this with quantum systems. But what you canDo it with lattices not of atoms, but lattices of dielectric. That equation can be put in exactly the same form as the Schrodinger equation for the time evolution of a wave function. To handle an electric field, you need the potential to be constantly varying. Instead of making it just perfectly periodic, let's make the index ramp just a little bit. In this experiment, so as the wave packet moves along, what's discovered is that the position-- if I draw the x as a function of t, so now the role of t is being played by the distance it's moved along the wave guide. It exhibits beautiful block oscillations. And this has been proved in a very small number of real honest quantum mechanical systems. this part of the field right now is we know that it's true, but we want to see it. We want to feel it, so various people around the world are working on making a truly beautiful demonstration of this bit of physics. But, the basic question is how robust is this. And the answer is it's not robust at all. But which you can tell because everything in the real world has enough impurity that it conducts. Or as an insulator. Yeah. And that's actually, it depends on the lattice. situation, it depends on the system. And exactly how it depends is something that is an active area of research. So don't throw away the model. Observe that you've modeled the wrong system. If you find a system that fits your-- that is-- that shares the assumptions of your model, that's when you ask did it work. And it worked like a champ. OK. So now let's talk about real materials. This is going to close up our discussion bands and solids. But that's OK. There are lots of questions and they were good questions. This is an extremely brief. But I want to ask you the following question. What happens in the following three systems? So first, imagine we take why don't we take a system with built out of single wells, which have some set of energy eigenstates, and then we build the periodic array out of them. What do we expect to see when we build a lattice? We expect that this is going to-- that these states are going to spread out into bands a funny way Yeah and let's just talk about the 1 d potential. single electron, and let's put it in the system. What will happen? Well if we put it into the system, what state will this single electron fall into? Yeah one event. But which state? AUDIENCE: [INAUDIBLE] PROFESSOR: Yeah, if you kick the system around, you let it relax a little bit. It's going to fall down to the ground state. You have to couple to something else like hydrogen has to be coupled with an electromagnetic field to decay. have to do? What kind of state corresponds to the position changing in time? Yes. Superposition. From the superpositions we'll get interference terms. If we put it in a superposition of these guys, then it's meaningfully moving. It has some meaningful, well defined time variation of its position expectation value. In order to induce the current, I must put the electron into a higher energy state and in a particularsuperposition of higher energy states. Here's why this is so important. atom is hydrogen, just for-- this doesn't actually happen, but just imagine-- in particular what it means is it has the ion, the nucleus is charge plus 1. And so in order for the system to be neutral, I must have one electron for every well. So if I put in the n electrons I need to neutralize a system, where do those n electrons go? Yeah, they fill up the first band. And if we let the system relax with lowest energy configuration, every state in this lowest band will be filled. This system is in an energy eigenstate. In particular, it's in a completely antisymmetrized configuration, because they're identical fermions. If we want to induce a current, what do we have to do? Yeah. We have put them in a superposition. But where's the next allowed energy eigenestate? Next band. So it's on the next band. It's in the next energy eigestate. The next allowed Energy Eigenstate is in the second band. macroscopic amount of energy. Well, it's not macroscopic. it's large. It's not infinitesimally small. That means that there's a minimum amount of. energy that that incident light must have in order to excite the. electron in the first place. So very long wavelength light will never do that. Light along wavelength will not have enough energy to. excite an electron across this gap into the next band to allow. there to be a current, which could oppose the electric field. be transparent. They would respond by having free electrons that could respond like a metal. In one dimensional crystals, the only thing that can happen is, look if you have each band come from allowed energy state. You can't have a partially filled band if each band comes from a bouncy, in a single well, and each well comes with an integer number of electrons. You just-- You just have filled bands, and then a gap. Does everybody agree with that? Well, MIT. It's all about the intellect. And everything else has to--  spin in one dimension is little-- I'm lying about spin. Electrons spin up, and electrons spin down, will generically have different energies. In 3D, this isn't such a big deal, because those splittings are tiny. But in 1D they can't. So I mean, that's also not exactly true, but it depends on exactly the details of the system, is what I wanted to get to. Curse you. But do you really want me to get in spin? Man. the story changes in a dramatic way. There the gaps are not the same. That they do not remain constant. And then we turned on an interaction which was the energy costs, the energy penalty for having angle momentum in z direction. Which added an l z term to the energy. And what you found is that as a function of the coefficient, which I think we called epsilon, of that perturbation of the energies of the energy was equal to l squared over 2 i plusepsilon. LZ: States from different multiplates, with different values of l, had energies that could cross as a function of the strength of the deformation of your system. LZ: There's no nodes here in three dimensions. There's one that changes, one that doesn't. And then this guy has five. One, two, three, four, five. And what we found here is that these guys could cross. And this split into, so this is the [INAUDIBLE] l equals 1. So l equals zero. we add in a lattice we get bands again. The structure's a little more intricate because it depends on the momentum. But these bands now can overlap. OK. Everybody see that? Because there's nothing preventing states from different-- in different multiplates from having the same energy in three dimensions. There's no nodes here that tells you have to keep the ordering constant. Now we turn on the multiple particle potential, and they can interact, they can overlap, and that's what happens. is the length of the energy of the last electron that you put in. How much energy do you have to give the system, do you. have to add the system to excite the electrons into excited states, in. particular into superpositions so that the electrons can move? AUDIENCE: [INAUDIBLE] PROFESSOR: Yeah. Preposterously small amount. An amount that goes like one over the number of particles. So in the continuum limit, it's zero. There's an arbitrarily nearby energy. called a band insulator. Because there are other ways of being an insulators. So what determined the exact band structure in for a 1D periodic potential? Two properties. One was l, the periodicity. And that came in the q l and k l. And the second is the detailed shape of the potential. In three dimensions, the things that are going to determine the potential are not just the distance between atoms, but you have a three dimensional lattice. It could be cubic, it could be hexagonal, could be complicating in all sorts of different ways. could have all sorts of different crystallographic structures. So that's going to go into it, in the same way that l went into it. Different materials for example, diamond versus copper, are going to give you different bands allowed energies, because the potential is different. It has different shape. And so when you solve the problem for the energy eigenvalues is a function of now the three different components of the crystal momentum, you'll just get a different set of equations. And working those out is not terribly hard. But it's a computation that must be done, and it is not trivial. the atomic orbital structure of the individual atom, the crystal structure, and the resulting band structure. You will almost always find overlapping bands in three dimensions in sufficiently high energy. What we need is one of two things. We need either the band gap coincidentally is ridiculously small, or we need a free particle, which is a conductor. But that's sort of stupid. But a better answer would be, well, can you have a system where there are bands in one dimension? And this is why Matt was barfing at me. but you didn't have one electron per potential well? And yeah. You could orchestrate that in lots of ways. Now it involves orchestration. So it's not the generic system that we were talking about here. But you can't orchestrate it. So spin is a useful thing that gives you an extra handle. If you have twice as many states per well then you can have half a band filled. That's one way to do it. Then it becomes dependent on details of the system, which is what I didn't want to get into. The temperature controls an energy scale for a real material. If you have a hot piece of copper, then the lattice is wiggling around. And every once in a while, an ion can hit one of the electrons and excite it, give it some momentum. And so there's an available reservoir of energy for exciting individual electrons. So when I say small, that doesn't mean anything. I need to tell you small compared to what.what that means. OK. Delta e is very small. Now delta e has dimensions. It has units. excited above the gap. The probability goes as e to the minus delta e over kt. At very low temperatures, if the gap isn't 0, then this is 0. It doesn't happen. But at large temperatures, the denominator here is large. If the temperature is large compared to the width of the gap, than this is a thermal fluctuation. And as a result, you constantly have electrons being excited up, cruising around, falling back down. And they can ask-- and both when asked, although not quite in this language, how likely are you to get an electron up here? small number. And e to the minus of a small number is close to 1. So at high temperature, you're very likely to excite electrons up here. This is called a semiconductor. And there are notes on the Stellar web page that discuss in a little more detail what I just went through and show you how you build a transistor out of a semiconducting. OK. So that finishes us up for the band gap systems for periodic potentials. And that's pretty good for 15 minutes of work. It's not bad. Photonic crystals are periodic arrays of dielectrics. They have bands of allowed energy and gaps of disallowed energies where no waves propagate through. The structure of a photonic crystal on the surface of a butterfly wing makes it shiny and blue. It looks like it's a crystal reflecting in a specific frequency. At some sharp blue. And the reason is, it is exactly this form. If you look at it under a microscope, you see little rays of protein which have different dielectric than air. and metallic without actually being shiny and metallic. And it's not a pigment, so it doesn't absorb light and decay over time. It's like the best thing you could ever do if you wanted to be a shiny, fluttery, flying thing. OK. So that's it for band gaps. And I want to move on to the remainder, the last topic of our course. Which is going to be entanglement and quantum computation. And here I need to give you one quick observation. The probability of finding the particle at point A is given by chi a squared. This is normalized, so when we integrate against it, we get 1. And similarly, the probability that we find the second particle at b is this thing norm squared. And it's independent of what a is. But we also studied the symmetric configuration, which was equal to 1 over root phi, root 2. And this tells us something totally awesome. We either find it at chi of a or chi. So there's a factor of one half. Quantum physicist David Wheeler: Measurement of one particle tells you something about the second particle. Wheeler: I could've taken these particles, put them in this entangled state, and sent one particle off to a distant planet. And my sister measures this second particle and determines what state it's in and is immediately determined what state the first particle is in over in this distant planet Zorg, right? So that's deeply disconcerting, he says, to those of us who have studied quantum mechanics up to this point. yet another moment of serious discomfort. How can something here dramatically change the state, the configuration, the initial configuration, of a particle arbitrarily far away? Isn't that deeply concerning? And if you think about relativity, this should be all the more deeply disconcerting. So there was a person that roughly this time, a little earlier, who was troubled by this problem. And his name was Einstein. And so one of the things that's kind of amazing is that he created a thought experiment which we're going to study in detail next week. who have taken courses in [INAUDIBLE]-- and I'm sure that's all of you because of the GIRs-- know this is larger than the usual [INAudIBLE] class. OK. Is this-- yeah, it's on. Can you hear me? All right. So there are lots of ways to slice the story of Einstein by the time he reaches the EPR experiment, which is Einstein, Podolsky, and Rosen for the three people who actually wrote the paper. That's one of many different ways you can ascertain that. And so he came to Princeton in '33. He actually went to Caltech before we went to Princeton. As part of an ongoing visitor-ship he had there. Came back to Europe, hung with the queen of Belgium who was a friend of his. Went to England. And then headed across the Atlantic and took up residency in Princeton at the Institute for Advanced Studies where he stayed for the rest of his life. He worked with a lot of different, mostly younger physicists. Hard to find. It's really sweet. Jeremy Bernstein, who is a physicist. A physicist and writer. He's in his eighties now. He lives in Aspen. He worked with CERN for a number of years. He wrote for the New Yorker. Bell had a friend named, I think, Bartelstein. Who had two quirks. An unusual color sense and a taste for mismatched socks. Bell used to say, if you saw one leg and that sock was pink, you knew to a certainty that the other sock was not pink. I think-- I'm trying to remember who this is originally attributed to. Same thing. If you have a coin and you cut it in half down the-- so you've got two coin shape disks. And you see the head that you know somebody-- somebody at some other casino is cheating by tossing in the half coin that only has a tail on it. So there are lots of ways to represent this. And many physicists being very witty indeed have come up with different metaphors for it. if you're sort of approaching it naively. What Einstein, Podolsky, and Rosen argued was actually something a little bit-- in fact, the paper comes to an end on that note of queasiness. And they have definition for what reality is. And that is something whose-- if you can perform a measurement, you know that quantity absolutely. But you can't do the-- so on the one hand, quantum mechanics says you can’t know physical reality to this level of precision. they claimed was a paradox. And this paper was published. And it received a range of reactions from indifference by younger physicists who said, we don't care that it's weird. And most notably Niels Bohr found this paper really troubling. And he spent about six weeks, apparently, discussing this and trying to come up with a response to it. And what he responded was essentially that-- in some ways, it was in some way a paradox, as well as a good thing. was the same reaction as his younger colleagues. Get over it. But more precisely, it was he said, there's no description of reality that excludes the measuring apparatus anymore. And that's just the nature of the quantum world. It's still true that the complementarity in essence means that once you know one part of the picture, you know some other part the picture. And you've said that we can measure this one quantity with precision and know the other thing. And then we can subsequently, in a separate observation, measure a complimentary quality and knows the other one. The experiments were done, and I imagine are still being done, as sort of demonstrations. And they showed that Bohr's interpretation was correct and that yes, quantum mechanics produces results that are non-local. And that the world really is as strange as people first glimpsed in 1925, '26, and '27. And the question of whether or not that strangeness is adequately explained without the explanations that you're going to learn in this class and subsequent ones are quote "complete" or not. quantum mechanics is somehow unsatisfactory in any kind of formal a technical sense is one that's at least partly dependent on your scientific temperament. So that's the cartoon version of what happened in '35. Einstein with his two young colleagues proposes-- really you should understand the EPR paper as a description in detail of a consequence of quantum theory as it was then expressed. No reasonable definition of reality could be expected to permit such a result. In fact, it's called a paradox, but it isn't. It's a complaint. In 1905, Einstein publishes The Quantum Theory Of Light. In June he publishes Special Relativity, which treats light as a wave. He's the first person to suggest there might be a problem with causality in quantum mechanics. In 1917, eight years before quantum mechanics is invented, he starts looking at what the quote "classical" quantum theory tells you about the emission of radiation from an excited atom. The year is called the annus mirabilis, the year of miracles, in part because Einstein is able to really focus on these things. He realized you can't predict it precisely. Radioactive decay has the same problem. He says, well-- he writes in a letter. I don't want to give up causality, but we may have to. So he's aware of these things. So juts to finish off, the question here is why does Einstein give up on this. And the answer, I think, is because in addition to his-- as he started at the beginning of his career, he says with the quantum theory of light and with special relativity, ignore your physical pictures. stupid. He was Albert Einstein. But he was aesthetically incapable of pursuing this new physics in ways that were possible under the research possibilities of the time. And that is what I would leave you with. Physics is an aesthetic as well as an intellectual pursuit. So thank you all. [APPLAUSE] Back to Mail Online home. Back to the page you came from. Follow us on Twitter @dailymailonline and @MailOnlineernews. Back To the pageyou came from, back to the Daily Mail home.

ROUGE-1: 56.16, ROUGE-2: 53.79, ROUGE-L: 51.96
BERTScore: 68.37

==============================================
==================== [37/100] ====================
Summary:
The proper way to chop fresh herbs to get maximum flavor is to chop them not bruised them now basil this is a soft herb so treat it with some respect when people go mad chopping herbs all the goodness comes out on the board I want the goodness left inside the basil place them all inside one another with the largest leaf at the bottom and it's almost like rolling a cigar large one at thebottom small ones in the center and then look place them down together just roll them nice and gently don't bruise them step one rolled ready to slice sharp knife imperative fingers tucked in the bottom part of your knuckle is the guide between you and the herbs. bunch of coriander hold it down and just lightly shave the leaves off the stalls bunch them up together and then just again let the knife do the work tuck the fingernails in and just chop once and once only don't hack it just chop it you can always identify when you bruise the herb when you've removed the herbs off the board that's a big green patch mmm full of flavor and none of the goodness is left on the chopping board if you have fruit that's not perfectly ripe the tip is to put a banana in a paper bag then add your unripe fruit. lemon squeeze a little bit of lemon juice and that instantly gets rid of the heat fresh lemon juice for perfect ball potatoes always start them off with cold water and never boarding water this way by the time the center's are the potatoes are cooked the outside won't be falling apart my tip to get the flesh out of a Kiwi this is simply cut the fruit in half and scoop out with a teaspoon try it it really works I absolutely love these peppers now they have the most amazing sweet delicious flavor with a really nice crunchy texture and the most exciting thing about the peppers is that they're just as delicious raw or cooked. Julienne is a chef's word for strips these are absolutely perfect for sewing and that's what we're looking for they're crunchy delicious and more importantly no seeds deed for a great tip to check if a pineapple is ripe is to pull a leaf out from the top if it comes away easily it's ripe and ready for slicing. A great tip for getting meat or fish to cook faster is to score it which allows the heat to penetrate quicker this also allows mayonnaise to be absorbed more deeply.

ROUGE-1: 71.92, ROUGE-2: 71.08, ROUGE-L: 71.92
BERTScore: 79.04

==============================================
==================== [38/100] ====================
Summary:
In this video we're going to be going over our weekly inlex practice question. Let's see what our question says a patient who has a health history of uncontrolled hypertension coronary artery disease and diabetes militis is prescribed to take propanolol. If you have provided the patient with education about this new medication which statement by the patient indicates your teaching was effective. If I miss a dose it is important that I double the next dose to prevent potential side effects. I will immediately stop taking this medication if I experience cold hands or feet. correct so before we do that let's analyze this scenario now as you read the scenario some things should be jumping out at you for instance the patient's health history and they have a history of uncontrolled hypertension which is high blood pressure they also have coronary artery disease and diabetes malius. Now let's talk about that drug propanolol that's what they're prescribed now let's think back to pharmacology this is the generic name of the drug generic names tend to have the same letters for the ending and and the ending for this is ool these are our beta blockers. beta blocker you have to watch out for some certain things that can happen Okay so what do beta blockers do in a nutshell beta blockers block your sympathetic nervous nous system. Whenever you take this drug it acts on those neurotransmitters specifically norepinephrine and epinephrine so those will be blocked and in the heart. What will happen is that you will get a slower heart rate instead of that tacac cardia now think about diabetes malius whenever these patients have hypoglycemia their heart rate goes up.  Beta receptors do they increase a process called glycogenolysis what it means is that whenever a patient has hypoglycemia the body tries to correct that. If they're taking a beta blocker that is blocking that response they're not going to have that classic Tac of cardia so they may later on their sugar will drop so much and it may be too late before they can treat it. Now Beta two receptors where are these mainly located they are located in various places number one your lungs you have two lungs that's how I remember beta 2. increase that blood sugar naturally with that process so you have this double-edged sword you have where they're not going to be able to notice their blood glucose because they don't have that tack of cardia going on and they don’t have that process of increasing that blood glucose naturally themselves. The patient wouldn't want to take their beta blockers with grapefruit juice. They need to take medic this type of medication or various medications with great fruit juice cuz grapefruit Juice contains chemicals that can slow the absorption of the medication. to be educated to actually avoid that and to take it strictly with water so this is wrong option b says if I miss a dose it is important that I double the next dose to prevent potential side effects. If a patient misses a dose of their beta blockers they don't need to double the dose they need toTake it as soon as they remember unless that next dose is due. These medications as we talked about with the beta blockers um they decrease your heart rate they do a lot of things to your heart and if you're taking double the doses they are at high risk of a cardiac event. look and see why D is wrong this patient says that they're going to stop their beta blocker immediately if they experience cold hands and feet well this is a normal side effect with these non-selective beta blockers. You would never just immediately stop taking a beta blocker they need to be tapered off of this because if they just all of a sudden quit taking that medication they can go have cardiac death or something worse can happen so that answer is wrong for that reason okay so that wraps up this inlex practice question.

ROUGE-1: 65.42, ROUGE-2: 63.52, ROUGE-L: 62.62
BERTScore: 74.77

==============================================
==================== [39/100] ====================
Summary:
This is part 2 of a guide to clinical reasoning or how to create an accurate differential diagnosis from a patient's presentation. In the first part I reviewed a practical five-step bedside approach to clinical Reasoning. In this part I will demonstrate how to use this approach with an actual patient case at the student level. I present this patient to you the same way in turn might present the patient to his or her attending on rounds or to their colleagues during a morning report or teaching conference as I present the case I'll keep a running list of the key features of the presentation. The patient is a 75 year old woman presenting with epigastric pain for four hours. The pain is relatively well localized to the midline in the region between her ankus and xiphoid process. There did not seem to be any particular trigger and the duration from initial onset to its maximal intensity of 8 out of 10 was about 45 minutes. She had moderate nausea it has refused to attempt to eat or drink anything since the pains onset because she is concerned that it will concert a vomit which she has not yet done. include hydrochlorothiazide 25 milligram daily and below to pain 5 milligrams daily metformin 500 milligraphic daily thymine 100 milligrap daily and folate one milliggram daily in her social history. She is an elderly woman a piercer stated aged in moderate discomfort secondary to abdominal pain her temperature is 99.8 heart rate 110 blood pressure 132 over 80 respiratory rate 26 and oxygen saturation of 98% on room air h ee and t. She has smoked one pack per day for 40 years for her family history. exam reveals normal oral pharynx but poor dentition her neck is supple without breweries and without lymph adenopathy her chest is clear to percussion and auscultation bilaterally her cardiac exam has a regular tachycardia hypertension her jbp is undetectable at either 45 degrees or when she's completely sipping on abdominal exam. bowel sounds are unusually quiet but present rectal exam with normal tone no tenderness and minimal guaiac negative brown stool musculoskeletal exam revealed full range of motion in all joints without bony abnormalities. The patient is a 75 year old woman with abdominal pain for four hours. She has hypertension diabetes moderate alcohol use smoking and is drinking water from a newly drilled well. The patient is epigastric well localized progressed over 45 minutes is constant with no exacerbating or alleviating factors and associated with nausea from the rest of her history. Her CBC revealed a white blood cell count to 15 with 85% neutrophils her hemoglobin was 14.5 and platelets were 325 basic metabolic panel was normal lfts. well on exam she is MA in moderate distress she has a borderline temperature tachycardia and tachypnea. She has a non distended abdomen that was soft with no rebound severe epigastric tenderness and guaiac negative. The key test results are a white blood cell count to 15 normal basic metabolic panel mildly increased indirect bilirubin modestly elevated lipase normal troponin and CK and an EKG with only sinus tachycardsia. primary symptom using semantic qualifiers and ending with the highly relevant diagnostic data using clinical syndromes when possible. For this patient we would start with mrs. Smith is a 75 year old woman with multiple cardiovascular risk factors and alcohol use presenting with acute constant epigastric pain. We would then group together the white blood cell count borderline fever tachycardia and tachypnea as sirs or the systemic inflammatory response syndrome. The soft abdomen and lack of rebound would be grouped into the collective descriptor of absent peritoneal signs and we would also include the elevated lipase. lipase the next time you are in rounds or in a teaching conference and the senior physician asks you to summarize the case if a statement similar to this one effortlessly comes out of your mouth I guarantee you everyone in the room will be impressed. Step four adopt a framework as I discussed in part 1 of this video series no problem representation has only one correct framework the organization of a particular framework may just appeal more to some people than others in general when the primary problem is some form of abdominal pain most people find an anatomic framework works best. In addition to epigastric structures structures that physically sit within the right and left upper quadrants can cause pain. The major structures are of course the liver and gallbladder along with other components of the extra hepatic biliary system. There is really just one unaccounted organ the spleen. This particular list is not meant to be unusually comprehensive for example I have not included the bowel that can cause acute epigstric pain in the right upper quadrant. It is meant to provide a framework for our anatomy based framework. included the transverse colon which crosses through the epigastrium though pain the transversely colon more typically is localized to the periumbilical region also because structures in the lower quadrants and retroperitoneal space can on rare occasion radiate to the upper abdomen. If one wanted to be unusually thorough with the framework one could also include structures and diagnosis such as appendicitis in the right lower quadrant diverticulitis in the left lower Quadrant and even a dissection of the dominoe aorta in the retro peritoneum though the presentation does not really suggest any of these in the framework stage. pain from a pulmonary embolism can be referred to the abdomen although it more typically is to the right or left upper quadrants and not the epigastric. Now that we have a framework we move on to the final and hardest step applying the key features to that framework so here is our framework once again and here are our key features how does one start this process the brute force method would simply be to take each diagnosis listed one at a time and review each individual key feature to decide if it impacted the probability of the diagnosis. In the absence of an ulcer perforation there is not a very reliable means of distinguishing PUD from gastritis on clinical grounds. Alcohol may be less of a prominent risk factor for PUD as it was for gastritis pancreatitis the alcohol use is definitely a risk factor here which argues for the diagnosis pancreatitis is also usually associated with a systemic inflammatory response syndrome with its elevated temperature heart rate and white blood cell count along with a severe epigastric tenderness the elevated lipase is thought to be a relatively specific finding for pancreatitis increasing the probability of the diagnosis though the degree of elevation isn't so great as to eliminate other possibilities. severe nausea at that so the presence of knowledge here definitely argues in favor of the diagnosis arguing just modestly against pancreatitis is the fact that the pain had no exacerbating or alleviating factors the pain from pancreatitis classically improves with setting up or leaning forward which this patient does not describe. The sensitivity and specificity of this symptom feature to the best of my knowledge has never been studied therefore we don't know exactly how much to weigh this in our assessment of the probability of pancreatitis there. I would place relatively little weight on the lack of positional component to the symptom how about food poisoning and gastroenteritis. your geographic region so for food poisoning the association with nausea is an argument in favor although the lack of vomiting is atypical unlike gastroenteritis. The lack of diarrhea is not inconsistent with food poisoning although one might speculate that the nuwell could be a risk factor for this diagnosis well water does not become contaminated with preformed bacterial toxins the same way that foods sitting out at a sketchy salad bar might one arguments against food poisoning includes her sirs physiology food poisoning can cause a number of these vital sign findings but usually as a consequence of severe dehydration. Gastroenteritis is not thought to typically cause a high lipase for a bowel infarction her cardiovascular risk factors put her at risk of this. A key feature that would help further assess this possibility is the presence or absence of an elevated lactate. The unremarkable lfts in and of themselves rule out acute hepatitis a paddock abscess usually has symptoms localized to the right upper quadrant and is also associated with lft abnormalities. A normal light bass cholecystitis also typically causes right upper Quadrant symptoms and signs.  acute cholecystitis has been described as a cause of elevated lipase. The patient has no elevation of direct or conjugated bilirubin that is no evidence of jaundice the patient is simply too sick appearing for this to be biliary colic. The combination of epigastric pain and nausea is not an uncommon way for acs to present particularly in a either a woman or a diabetic the major thing which is not fit is the severe epigstric tenderness since the pain is referred from the right upper quadrant. A pulmonary embolism can cause abdominal pain but as with acs would not be expected to cause abdominal tenderness. The patient has no major risk factors for RPE and has no shortness of breath. There are no causes of four hours of epigastric pain in which we would expect the troponin or CK to be abnormal even in the event of RPE. It's possible to present with a PE with just pain this case is just not what a PE looks like either in its classic presentation or even atypical variations. that the patient had an acute MI it really is too soon for these enzymes to become elevated and so therefore they probably should not be key features. The guaiac negative stool was critical in establishing the problem representation in step three. The history of the newly drilled well depending on where you are in your training is the most interesting. The combination of acute abdominal pain nausea and a possible contamination of well water is all consistent with heavy-metal poisoning specifically arsenic and lead this brings up an important point. element does not fit into the framework yet still seems to be a key feature the framework must be incomplete in this case I would add another category of diagnosis to our four existing categories of epigastric right upper quadrant left upper quadant and chest. That fifth category is acute abdominal pain secondary to systemic toxic metabolic problems. The four major members of this group are heavy-metal poisoning a rare genetic disorder called acute intermittent porphyria another virgin etic disorder called familial Mediterranean fever and finally angioedema. nearby then I would definitely still consider it and would try to arrange for the water to be tested if an alternative diagnosis was not immediately secured. In the more likely case that there was no mind or other unusual industrial activity near her home this can probably be crossed off the differential at this point. If the patient's pending CT scan showed clear evidence of an alternative more prevalent diagnosis such as pancreatitis for example that would also be sufficient to cross off heavy metal poisoning. I have not mentioned the diagnosis of diabetic ketoacidosis which can definitely present with acute abdominal pain and nausea in a diabetic. The most likely diagnosis for this patient is acute pancreatitis. pancreatitis is associated with her heavy alcohol use. It explains her nausea her distress the vital signs her tenderness on exam leukocytosis and is the best explanation for the elevated lipase. The only key feature arguing against it is the fact that the pain is not made better or worse with changes in position which as I suggested earlier is not likely to be a highly sensitive or specific finding. This is a relatively classic presentation of a common disease and therefore our leading diagnosis also known as the provisional diagnosis. atypical presentation those diagnoses which are rapidly fatal if missed for which this could plausibly be a presentation. Finally any diagnosis that is specifically suggested by an unusual element of the presentation even if the diagnosis itself is rare common disorders which could be a typical or atypical Presentation include gastroenteritis food poisoning and either gastritis or peptic ulcer disease which I have grouped together because I think it's very difficult to tell the difference between them without endoscopy don't miss diagnosis for this presentation would include a bowel infarction and acute coronary syndrome. involves the provisional diagnosis and as you move further down the list ideas start to diverge a little bit I would certainly expect most experienced doctors to identify pancreatitis as the leading diagnosis in this case so that concludes part 2 of 3 of this video series on the clinical reasoning. I hope you found it interesting and useful while the approach I presented here is not the only one in use I guarantee medical trainees that if you consciously employ it while on the wards you impress your peers and evaluators and more importantly create a more accurate differential.

ROUGE-1: 64.78, ROUGE-2: 62.61, ROUGE-L: 61.19
BERTScore: 72.99

==============================================
==================== [40/100] ====================
Summary:
Today is the day that you have to have done the mid-quarter survey by. Hundreds of people have, but if you haven't, this is your last chance to get the half-point for that. Final project proposals are due. We really encourage you to try and hand them in on-time or nearly on- time. And then today, delighted to have our first invited speaker. And there is a reaction paragraph talking about something that the speaker talks about. There is also assignment 5, which we're giving you one extra day for. Danqi Chen is one of the foremost researchers in question answering. Once upon a time she was the head TA of CS224N. She's quite familiar with the context of this class. So here's my plan for this lecture. I'm going to spend the most of this lecture focused on one type of question answering problems called reading comprehension. So I know that many of you are going to do a different project on the Stanford Question Answering Dataset. So understanding this part will be very crucial for your final project. short, is one of the earliest NLP tasks, and the early systems can even date back to the 1960s. So this system is built to try to find some kind of text matching between the question, and somekind of text segments. And there are many different types of question answering problems. And we also have categories of these question answer problems, based on the information source, or the type of the questions. So for the question part, we can also build systems that can answer factoid questions or non-factoid questions. The question and answer has enabled a lot of really useful real world applications. For example, today if you just put your question in a search engine like Google, it can find a short snippet of text. And then you can actually click on the correct answer, which is actually our concise answer. And those kind of systems are also in use today in a number of other industries. So just have in mind there's many different types of questions in problems and all these problems may require very different techniques or different data. able to handle more complex questions like how-to questions. People actually really like to ask questions on these digital assistants. Ask a question is actually the second most used case. Only ranks after listening to music and before the check the weather and set up. The best way to prevent illness is to avoid being exposed to this virus. And to help prevent the spread of COVID-19, you can do the following. If you just click this link and read through the article. So this is also one type of the question answering problems. timer. So question answering has been really useful in digital assistants. And another very famous example of the question answering system is this IBM Watsonquestion answering system. So in 19-- in 2011, so this IBMatson QA system has been shown to beat two national Jeopardy champions in answeringJeopardy questions. So this is a part of a historical event, at least in the NLP history. So if you look at the inner working of this kind of system more closely, so you can see that it is actually a very complicated and highly modularized system. NLP modules that have included. BERT. And now this system has been over 10 years older, actually, exactly 10 years now. And this is actually representative of state of the art 10 years ago at that time. So we know that this class is about deep learning. So today different has completely really transformed the landscape of the question answering systems. So in this lecture, I will be mostly focusing on the text based, or textual question answering problems. So basically, we are trying to answer questions based on text. the unstructured text. There are many other really big question answering problems. And each of them can be really like a subfield in NLP and they actually have very different challenges and also model designs. So basically we wanted you to question build answering systems to answer questions that can answer questions over a very large database. So to solve this problem, some approaches need to take this question and convert this question into some kind of logic forms. And another class, bigger class of the question Answer problems is called visual question answering. So this problem basically requires both understanding of the questions and also images, and is actually a very active field between the computer vision and NLP. dig into these problems today. So next, I'm going to start with a part 2, reading comprehension. I just want to quickly check if there are any quick questions I can answer before I start us on part 2. OK. So let's talk about the reading comprehension then. So reading comprehension is a basic problem that we want to comprehend a passage of text and answer questions about the content. So here is one example. So basically to answer this question, so you need to find this sentence, like, in 1861, Tesla attended this school where he studied. he studied German, arithmetic, and religion, and only German is a language. So the answer to this question should be German. OK, here is another example, OK? Another passage of text. And the question is, which linguistic minority is larger, Hindi or Malayalam I think 5 seconds. OK. So next I'm going to talk a little bit so why do we care about this problem? So why do you care about the reading comprehension problem? It has actually many useful real-world practical applications. Reading comprehension has been also viewed as a very important test bed for evaluating how well computer systems understand human language. So this is really just similar to how we humans actually test the reading comprehension test to evaluate how well we actually understand one language. And also there is another interesting and important reason that reading comprehension is important. So in recent few years, some researchers actually found that, OK, well, there are many other NLP tasks. So we also reduce them to a reading comprehension problem. personal subject, Barack Obama. So we want to fill in what is-- fill in this question mark and figure out, OK, where Barack Obama was educated at. So one way to solve this problem is basically trying to convert this relation into a question. So where did Barack Obama graduate from? And taking all of that relevant piece of text and then by applying a reading comprehension problem. Then basically, we can find out-- the correct answer should be Columbia University. That is also the output of this information extraction system. Reading comprehension can be very universally useful to many other tasks. So next, I'm going to introduce this Stanford Question Answering Dataset called SQuAD. So if you are going to develop for the final projects, you will need to use this dataset. It consists of 100K annotated passage question and answer triples. So by converting all these kind of semantic role relations, we can also just apply the reading comprehension problem and give you the correct answer. So here is one example from this data set. sets have been also collected, basically runs this size around 100K. So 100K is actually very important to train these neural models. So for these datasets-- so the passages is like a single paragraph selected from the English Wikipedia, which usually consists of 100 to 150 words. And the questions are crowd-sourced, basically like from Mechanical Turking. And this is a very important property of the dataset, is that each answer is a short segment of text, or we called it span in the passage. Stanford, so it's called Stanford Question Answering Dataset. Today, after four or five years now, so SQuAD still remains the most popular reading comprehension data set. So it's actually very clearly a high quality dataset, but is also not a very difficult dataset. So today, basically the SQuad dataset itself has been almost solved, and the state-of-the-art already exceeds estimated human performance. So basically for the development and testing set, there will be three gold answers collected because for some questions, there could be multiple plausible answers. articles and also the punctuation excluded. And basically you can compare the exact match score and also F1 score by comparing the predicted answer to the gold answer. And there are many different examples in the dev or test set. And then finally, we just take the average of all the examples for both the exactmatch and the reference score. So by using this evaluation metric, the estimated human performance estimated by the researchers at the time is. 82.3% and the F1 scores is 91.2. the F1 score would be taking the max. Danqi, one question you might answer is, so if you can do other tasks like named entity recognition or relation extraction by sticking something on top of BERT and fine tuning for it or do it as a question answering, does one or the other method work better and by how much? That's an interesting question. So I haven't really seen the-- OK. So there has been some claim, OK, that all the tasks can be converted into question answering task. But I'm not sure if there is really a very fair comparison. answer to that. So next, I'm going to talk about how to build neural models for reading comprehension. And in particular, how we can build a model to solve the Stanford Question Answering Dataset. I also to just quickly mention that because there are many different papers that actually use different notions to refer to the same thing, so starting from-- so I'mgoing to use the passage, paragraph, and context, and also question and query basic interchangeably. OK. The answer must be a section of text in the passage. So the output can be just written this way. We are going to predict a start and end. So start and then end would be within the range between the 1 and the N. So it's basically just two checkpoints-- sorry, two end points of the answer. So SQuAD has been collected beginning late 2016. So after 2016, there have been-- there are two families of neural role models to solving this SQuad data set. So pre-trained language models for these kind of reading comprehension problems. So here are the two-- the illustration of these two families of the models. So on the left is an LSTM-based models with attention, and on the right is the BERT model. And then we need to fine-tunel this model for the reading comprehension task. So I'm going to walk us through hard to build this model step by step, and hopefully with that, you'll have a good understanding of how this model works. comprehension problem because they really share a lot of similarities. Just like some sequence to sequence model, we need to model the attention between the source sentence and the target sentence. So we only need to train the decoder to generate the target sentences. OK. Next, I'm going to talk about this model called BiDAF. So it stands for Bidirectional Attention Flow for Machine Comprehension. It was proposed by Minjoon Seo and other folks in 2017. It remains one of the most popular reading comprehension models. this model from the bottom to the top, it actually can be decomposed into many different layers. So the idea here is that OK, let's take the context part of the passage in question. We need to encode them separately. So to do this, so this model basically proposed to use a concatenation of the word embedding as well as the character embedding for each word in the context and the query. And then we just concatenate them and pass this to a highway network. LSTM model from another direction. So we just need to concatenate the two hidden representation in two directions. And finally, we can get a contextualized representation for each single word in the context. And we can do a similar thing for the question representation. I also want to quickly mention, because I mentioned the sequence to sequence model, we cannot really do these bidirectional LSTMs for the two sequences because the decoder is an autoregressive model. But because here we don't really care about the generation, so we can just use two bid Directional L STMs to represent the representations. called context-to-query attention. The idea is for each context word, can we find the most relevant words from the question for the query words. And then the second type of attention is called the query to context attention. So here the idea is to choose some context words that are most relevant to one of the queryWords. And this is also why this model is called a bidirectional attention flow because there's a context- to- query attention and there is also a query-to.-context attention. similarity score for every pair of the contextualized vector ci and then for everypair of the question with qj. So this is actually the output from an encoding layer. So the way they do this is basically just taking these metrics, the similarities for sij, for each row. Each row basically correspond to one context word. So here, i actually enumerates over all the context words. And this can give us another attention score of beta i, which captures how important this context word is relevant to this question. Is there a reason why you use both query-to-context and context-to the query attention? Is it sometimes advantageous or OK to use just one? Difficult question. Yeah. So I'm going to show us some operations from this figure, so way we just find both directions can really help. So there'll be some operation studies. So by using one set is useful, but it's sometimes advantageous to use both sets. I hope this answers your question, yeah. It's a good question, yes. just not with us using the both directions. In the bottom right, we sum over i, so why does the i remain in bi? Is that correct or is that a typo there? This is another typo. So the output of gi will actually range from the 1 to N, which is the number of the context words. There are lots of questions about this. What is the rationale for the expression of the gi? How does one come up with such an expression? OK, OK, I'm sorry.  query-to-context attention is trying to measure the importance of these context words with respect to some question words. So by taking the max for each row in this matrix, so it's basically trying to see, OK, which question word is actually most relevant to this context word? And then you can just apply your softmax. And then this will give you a probability that OK, what is the probability of this condition i, would be based on the start position of the final answer string. the dot product between w end and this vector, and this can produce all the probability over all the conditions which predict how likely this position will be the end the position of the answer. So by passing the mi to another bedirectional LSTM, their reasoning is that they're trying to capture some kind of dependence between the choice of the start and end. OK. I'm done with this part, describing the BiDAF model. Any quick questions I can answer? I think you can actually go on. BiDAF model achieved a 77.3 F1 score on SQuAD data set. They found that both attentions in two directions are actually important. If you remove the one direction, the performance will actually drop quite a bit. And the whole model can be just trained in an end to end way from the encoding layer to attention layer to modeling layer and to output layer. And basically all of the models that account at that time between 2016 and 2018 are BiDAF models. the models are actually a very similar ballpark. So numbers range from the highest number here, 79.8 until after the ELMo was introduced, the numbers have actually improved quite a bit. Each model actually improved the previous model by one point or two points. And now here is our attention visualization to show that how this smorgasbord of attention actually can capture the similarity between the question words and the context words. So it show the actual question word here. And each column's matrix basically indicates the attention score, the similarity score that has been learned by this model. those negative scores pretty well, yeah. OK, so next, I'm going to talk about BERT, how to use the BERT model to solve this problem. So BERT is basically a deep bidirectional transformer encoder pre-trained on large amounts of text. And it is trained on the two training objectives, including masked language modeling and the next sentence prediction. So, OK, we can actually use BERT for our reading comprehension. So it's actually very easy and very straightforward. question is how many parameters does BERT-large have? So you can see that they basically just take the questions here and then take the passage here. And also for the questions that we just need to pass the A to a segment embeddings. And then finally, the training loss is also the same. So you basically just try to maximize the sum of the negative log likelihood of both the start and end positions. Well here, the way that they compute thestart and end probability is slightly different. L.hi is the output from the BERT encoder, and then we are training this two Wstart and Wend for these two probability distribution Pstart and Pend. If you just take this BERT model, and by just optimizing all the parameters together, it can give you a very high performance. I will show you BERT in a minute. And even if you use a stronger pre-training models or modern, like a-- stronger models than BERT models, they can even lead to better performance on SQuAD. BERT models are pre-trained while BiDAF models only builtd on top of the GloVe vectors. So here it is very clear that pre-training is a game changer here. Pre-training basically can just change everything and it also gives you a very, very large boost in terms of the performance. But I also want to raise another question. So if we first think of this pre- training, these BiDAf models and BERT model are really fundamentally different? I don't think so, so this is actually my argument. So let's try to see how these two models are actually connected, especially in termsof model design. BERT models can do really well on this kind of reading comprehension data set. But you probably cannot really build a model as big as 110 million parameters or 330 million parameters models. So as we train the model between these family of LSTM models and BERT models. They're called QANet from Google. So that the model actually can perform better than the BiDAF models and other models. But it actually under-performs Bert models a little bit. So just check it out on QANnet.is. pre-training has been so important. So next I will quickly talk about-- OK, a question here is that can we actually even design better pre-training objectives for reading comprehension or question answering? And the answer is actually yes. So this is actually a work I did with Mandar Joshi and other folks one year ago called SpanBERT. So think about this. So for SQuAD and other a lot of extractable reading comprehension datasets, the goal is trying to predict the answer span from the passage of the question. The idea here is that can you try to compress the two end points of answer span to predict all the words in the middle? So this is why it is called SpanBERT. So I encourage you to check out our paper. And this actually really helps a lot, at least for the question answering data set. So as you can see from this figure-- so this is SQuAD 1.1 and this isSQuAD 2.0. And these are many other question answeringData sets. And our BERT is actually just the-- is actually our re-implementation of the BERT model using the same data where we have been trying to train this model for slightly longer. So SpanBERT actually greatly outperformed Google BERT and other BERT basically across all of the datasets. This number has already exceeded even the human performance on SQuAD. Does this means that reading comprehension is already solved? The answer is of course not. So in the recent last couple of years, there's been a lot of work on reading comprehension. a lot of evidence showing that the current systems still perform poorly on adversarial examples or the examples from out of domain distributions. So here is a very classical example proposed by Robin Jia and Percy Liang in 2017. They're trying to just insert a random sentence to the end of the paragraph. And this sentence actually has some overlap with the question. It's actually very similar to this question, but actually the numbers have been changed. And they found that these kind of adversarial example are actually very easy to fool the current system and makes the system to predict the answer to be Jeff Dean. is another paper that actually just came out in 2020. So there has to be a lot of evidence showing the similar things. So today we compute a very good reading comprehension data set on the individual data sets. But these systems trained on one dataset basically cannot really generalize to other datasets. And all the other numbers in this table basically shows that if you train one system on one datasets and then evaluate on another dataset, the performance will drop quite a lot. So it basically really cannot generalize from one dataset to another dataset. Open-domain question answering is a problem that-- so it's different from reading comprehension that we don't assume a given passage. So here, we use the assumptions that we only have access to. And they found that a BERTlarge model cannot solve and basically failed these type of test cases 100% of the time. So I have 10 minutes left. Chris, is there any question I should answer at this point here? I think you can go on. OK. So in the last 10 minutes, I'm going to give you a very, very brief introduction of what is open- domain question answering and what we have been trying to do in the past couple of years. a large collection of documents. So one example is just taking the whole Wikipedia, which has five million articles. And we're going to return the answer for any open-domain questions. So the term here open domains is just in contrast to closed domains that deal with questions under a specific domain. OK, so how can we solve this type of problem? Because for the reading comprehension problem, we just make sure to answer questions based on a simple passage. So this is actually a much more challenging and also more practical problem. by using a retrieval and also a reader framework. So the idea is that let's take a question-- OK, so here, the article is trying to answer questions using a very large collection of documents such as the Wikipedia. So we can just decompose this problem into, as I just mentioned, in our retrieval and the reader component. The retrieval is basically trying to take a large collection. of document D and Q, and is trying. to return a set of documents or set of passages. From let's say 5 million documents. And finally the reader basically takes the question and takes this type of the passages and finally returns the answer. So the idea is very simple, but it's trying to bridge with two things, how to have a bridge as the retrieval and also the reader to do this kind of open-domain question answering. So I'm just going to quickly go over some really exciting ideas that has been happening in the last two years basically. So here is actually-- so this idea has been first proposed in Kenton Lee's paper in 2019 called Latent Retrieval for Weakly Supervised Open Domain Question Answering. This model kind of works really well, and it can largely outperform the traditional IR retrieval models. So here is actually a really nice demo. So again, the database ferries the whole Wikipedia. And you can see that if you ask a question of who tells Harry Potter that he is a wizard in the Harry Potter series. And the system had really found out the correct article should be Harry Potter films series, and then finally gave you the correct answer. OK. So by looking at all these different curves basically using a different number of training examples, so it actually largely greatly outperforms thetraditional IR models. answer, which is exactly what you have seen here from the Google example here. So the answer would be the Rubeus Hagrid, who is actually the person who told tells Harry Potter that he's a wizard. OK, I'm going to skip this slide. And then finally, very quick. Some researchers have demonstrated that maybe you don't even need this retrieval stage. If you just use a very large language model, you can also just use all open-domain questions answering. So this kind of QA model is also called Coastal QA systems. OK. So this is one direction that personally, I'm very excited about. This is actually a new direction that basically shows that maybe for the open-domain question answering, maybe this reader model is not necessary anymore. So instead we can just record all the phrases in Wikipedia using some kind of dense vectors. And by taking a question, you can just encode this question in a single vector and then we canjust do the nearest neighbor search. And then it can directly give you the answer. that for the BERT reader model, you essentially have to run the Bert model at the inference time. This is actually very expensive. Well, you just get a read off the reader model. You can just do the similarities search, you can justDo the nearest neighbor search without running a BERT model. So this could be very fast and they can even run on the CPUs without needing to run a very expensive deep neural network and then it can still run very well, perform very, very well. Today, because she doesn't have a Stanford login, we're going to do questions inside Zoom. So if you'd like to ask a question, if you use the raise hand button, we can promote you. And if you hang around and don't leave the Zoom for more than a few minutes, maybe we'll just promote everybody who's still there into people in the regular Zoom for some bits of discussion. There are now four people who've been promoted. OK. Should I read those questions? Should I look at the chat or? No. Out: How can we train the reading comprehension model using only a small number of training examples? Out: If we can leverage a very large and very powerful pre-trained language model, there is a possibility that we can actually do the question answering well. Out: And also there are some other promising directions, including some other models that could be used in the future. OK. So thank you so much for the lecture today.OUT: Maybe he could start by asking a question, and then the other people that we've promoted. OUT: How small can your training dataset be for you to get reasonable results? unsupervised question answering so by using some kind of approach like some form of unsupervised machine translation, this kind of idea. That can be borrowed-- can borrow the idea from that and can also work pretty well, reasonably well in unsuper supervised question answering. Yeah, also I have seen a lot of works like [INAUDIBLE] showing that synthetic Pure-DSS can also help a lot in boosting the performance if you don't have enough supervised examples. So my question is I guess it's kind of interesting that there's not really that strong of a transfer effect between data sets that are kind of ostensibly similar. Most existing question answering datasets or reading comprehension datasets have been collected from Mechanical Turk. So it is very difficult to avoid some kind of artifact though, like a simple clues or superficial clues-- let's say not superficial but some simple clues that are for the machines to pick up. Natural Questions was a dataset that Google put out about a year and a half ago maybe where they were actually taking real questions from Google search logs and then trying to find answers for them in web documents. But there's some other issues that people like to ask some common questions. in the training set that is not really generalization, right? Yeah, but this is more on the open-domain setting not in the really [INAUDIBLE] here. Do you want to ask a question? Yes. So you mentioned in the last part of the presentation that the reader model may not be necessary and you presented the DensePhrases which also work well on CPUs. So do we know how well it performs on the question and answering datasets compared to other models including BERT and those on computer of course. The goal of this project is trying to ingest all the phrases in the Wikipedia. So these conversations are built using the training set of the question answering datasets. So if we use say a different data set that does not present the information using the structure presented in Wikipedias, this model may not work as well as.kind of the intuition behind the dense phrases apart from the answers will probably be in close proximity. And what if the datasets has answers to a specific question like very far from the actual information? Say, the answers to your question may not resided in close. proximity to the words in the question. the answer? So why do you think the nearest neighbor-- I mean, you always can find something, right? The question is that whether it's close enough or not. So the question is what if in the datasets that the answer is not close enough? Yeah, that's a good question. I don't know. If you really come up with something that is really very far away from all the questions that we have been seeing in the training set, that could be possible. It depend on how the text are formatted. The nearest neighbor search may not work as well as other models. while asking a question if you want. So next person is [AUDIO OUT]. All right. Thank you for taking the time to teach this. My question is kind of quick. So you mentioned work, they brought up a set of relatively simple questions that show how brittle or poor the current models can be, right? I'm curious if that-- yeah, exactly. Did that kind of change the community to improve how to evaluate the models? Because they're actually doing pretty poorly on some of those. thank you for bringing this one up. It's really interesting. Next is-- Hi, thanks for taking the time. In what extent can in context learning help models to be more robust with respect to different domains? Can you tell me what you mean by in context? So like basically you provide the template generated by BERT. And then instead of directly predicting the classes of text classifications, you just use some word to represent that class or predict the wordings there. OK. Thanks. Do you think that in order to solve NLP in the sense that you can perform on par with humans on all NLP tasks it's sufficient to only interact with text data? Or do you think we'll eventually need the sort of experiences and common sense. that you get only from seeing and viewing the world and having a set of interactions that we as humans have? Yeah. I mean, common sense is a very difficult-- even in the context question answering, commonsense is aVery important topic that I think still remains unresolved. solve the easy problems. So all these things need to be resolved. Do you think that the current sort of benchmark data sets are maybe a little bit too easy for- [INTERPOSING VOICES] Or just like that. Yeah. One final thought is that having a lot of transversely trying to have a lot. of humans in the loop of the frameworks to evaluate these kind of systems. Just try to break the current system, come up with some harder questions. OK. Are you still game for a couple more questions? Sure. encountered this paper called Learnable Quantizers, which essentially learns baseless representation for the quantizers jointly with the leads of the network. And while this would be extremely effective if you were to just like, say, train from scratch, I was just sort of curious, do you think there is some way to do this say a pre-trained BERT model or something like that? I had a few ideas with like beam search for instance, but I don't see a very clear way of doing that. Next question is from Danqi, who was one of the co-organizers of the EfficientQA task. Danqi: How concerned should we be about potential encoding sort of biases into these record labels or how we evaluate them, or is that just more of a concern for more open ended questions? John: I'm not sure I have a good answer to that. Some people do a de-biasing of the pre-trained language models, all these things are very important. yeah, I guess I'm just a little worried about who comes up with the test cases? Who determines what the right answer is? I mean, we will have more discussion of toxicity and bias coming up very soon, including actually Thursday's lecture as well as a later lecture, not specifically about QA though. OK. Next person is-- Thank you for the lecture. Yeah, my question is also related to the open domain question answering. So there is some very specific designs like domain server alignments and efficient level disentanglement techniques that has shown some interesting performance on other tasks. people also leveraged similar things for question answering. So I was just wondering to what extent these kind of techniques can work on one group of tasks, not just limited to question answering, but mainly question Answer. I have seem some work sort of trying to learn some kind of disentangled representations that can better generalize to the different domains on adversarial examples. Yeah, I'm not sure. I think we have to try that. But it's a little bit more specific for-- so there's a paper called domain. definitely an interesting point. At least for the work that I have seen so far, it all applied or operated at a very simple sentence classification task. I feel like QA is a more structured task and also handles longer bar sequences. Yeah, so I don't know if it works unless people have tried that. OK then we've got-- and maybe we should call this the last question. Hi, I'm just wondering what is the intrinsic difference between solving question answering with generative models like T5 versus encoders like BERT. So if the retrieval returns like, say, 100 passages, so they have to extract the answer from each of the passages and then finally figure out which one has the highest score. But for the generative model, essentially they are trying to aggregate all the 100 passages and the dense representations together and do the generation jointly. So essentially, you're taking the 100 representations together through the joint generation. So I think that is actually the key difference. So that's why thisGenerative model can do really well compared to the extractive models. These numbers are a little bit confusing. So it's actually basically really on par. Their base perform similarity. So the key difference between the generative model and the extractive model is that for generative models, you can actually leverage more input passage together and do the generation. Is that clear or not? Yes. Thanks. Yeah, otherwise, you should just check out this paper here. So this paper actually explains it pretty well why this model works better than the previousGenerative model. The model is very large, like 11 billion parameters. So the parameters are basically trying to memorize a lot of information that has been.information. So by just taking this input, it has to just rely on the parameters to infer this answer. So it's actually very hard to-- yeah, it's a definite balance between memory and the generalization from it, yeah. All right, thanks. Do you want to call it a night or do you want one more question? It's up to you. Japanese, or Arabic, or some other languages? Another followup question maybe not exactly in your domain expertise is there's a lot of interest in modelling user behavior. And then you can use that to predict how users-- like embed users, so that you can can predict user's actions. How promising do you think that would be? I just want get your thoughts on that. OK. The first question is whether these techniques can be generalized to other languages. I think the answer is yes. collect so many examples for other languages. And there has been also a lot of work trying to do cross-lingual question answering and stuff like that. If we have, actually, I think that the techniques can be generally applied to other languages, he says. "I think that we have a lot to learn from each other," he adds. "We have a long way to go, but I think we're making progress." "We've got a lot more to learn," he says, "and we're getting better at it."

ROUGE-1: 55.56, ROUGE-2: 53.85, ROUGE-L: 51.92
BERTScore: 66.57

==============================================
==================== [41/100] ====================
Summary:
 homework two is out now. We're gonna be having some more background on deep learning this weekend. You're not expected to become, or, or to be a deep learning expert to be in this class, but we, you only need to have some basic skills in order to do homework two, um, be able to use function approximation with a deep neural network. Um, we're also gonna be reaching, uh, releasing by the end of tomorrow. Uh, but the sessions will be a good chance to catch up on that material. [NOISE] Um, just a quick humble, which of you have used TensorFlow or PyTorch before? The assignments, [inaudible] are they limited to TensorFlow? asked the question. I'm pretty sure that everything relies that, er, you're using Tensor Flow. Um, I'll believe you guys also should have access to the Azure credit. If you have any questions about getting setup without feel free to use the Piazza channel. We also released a tutorial for how to just sort of set up your machine last week. So, if you're having any questions with that, that's a great place to get started. Piazza: We're gonna go ahead and get started. Um, uh, what we're gonna be covering today is sort of a very brief overview about Deep Learning, um, as well as Deep Q Learning. Could look at the tutorial, you canLook at the video, or you can reach out to us on Piazza. Any other questions? All right. So, we've been discussing how to learn to make decisions in the world when we don't know the dynamics model of the Reward Model. We need representations of models. T, T or R or a state-action values Q, or V, or our policies, um, that can generalize across states and our actions. You might never see the exact same image of the world again, but we wanna be able to generalize from our past experience. And so, we thought about it, instead of having a table to represent our value functions, we were gonna use this generic function approximator where we have a W, which are some parameters. when we thought about doing this, we're gonna focus on function approximations that are differentiable. Um, and the nice thing about differentiable rep-representations is that we can use our data, and we can estimate our parameters, and then we can take use gradient descent to try to fit our function. And that information now could be [NOISE] in the form of episodes or it could be individual tuples. When I say a tuple, I generally mean a state-action reward next state tuple. is the same as the full gradient update. Our objective function is again the mean squared error. And the key hard thing was that we don't know what this is. So, this is the true value of a policy. But the problem is we don’t know what the trueValue of a Policy is, and so we can't get a value for a policy that we think is the real value of the policy. And so, we have to change the way we think about a policy to get a true value. otherwise we wouldn't have to be doing all of this learning. And so, the two ways we talked about last time was inspired by a work on Monte Carlo, or on TD learning is we could either plug-in the return from the full episode. Or we could put in a bootstrapped return. So, now we're doing bootstrapping. Where we look at the reward, the next state, and the value of our next state. And in this case we're using a linear value function approximators for everything. all for linear value function approximation, but there are some limitations to use the linear valuefunction approximation, even though this has been probably the most well-studied. So, if you have the right set of features, and historically there was a lot of work on figuring out what those rights set offeatures are. They often worked really well. And in fact when we get into, I think I mentioned briefly before. When we start to talk about deep neural networks you can think of, a deep neural network is just a really complicated way to get out features. and how easy is it for us to converge to that. So, one alternative that we didn't talk so much about last time is to use sort of a really, really rich function approximator class. Um, where we don't have to, have to have a direct representation of the features. Er, and some of those are Kernel based approaches. These actually have a lot stronger convergence results compared compared to other approaches. The problem is, um, that the number of data points you need tends to scale with the dimension. The intuition is that if you want to have sort of an accurate representation of your value function, um, and you're representing it by say, uh, local points around it. For example, with the k-nearest neighbor approach. then the number of points you need to have everything be close like in an epsilon ball scales with the- the dimensionality. So, basically you're just gridding the space. Um, and everyone just [inaudible] name first please to stop me. a square, you're gonna need four points so that everything can be somewhat close to one of the points. Generally, the number of points you need this going to scale exponentially with the dimension. A really cool thing about averagers is sort of by their name. They're guaranteed to be a non-expansion, which means that when you combine them with a bellman backup it's guaranteed it'd still be a contraction. So, that means these sort of approximators are guaranteed to converge compared to a lot of other ones. These for things like, um, health care applications and how do you sort of generalized from related patients. So, they can be useful but they generally don't scale so well. What we're gonna talk about today is thinking about deep neural networks which also have very flexible representations but we hope we'll be able to scale a lot better. Um, now, in general we're going to have almost no theoretical guarantees for the rest of the day, and- but in practice they often work really really well. In this example, we're going to use a loss function called j which is like our Q. Then we're gonna push that into another function, and throw in some more weights. I'm gonna do that a whole bunch of times, and then at the very end of that you can output some y. Then, we can output that to some loss function j. These are- happen a lot in unsupervised learning like predicting whether or not something is a cat or not or, you know, an image of a particular object. functions, um, you could represent really complicated functions by adding and subtracting and taking polynomials and all sorts of things you could do by just composing functions together. But the nice reason to write it down like this is that you can do the chain rule to try to do stochastic gradient descent. So, we really want, you know, dj with respect to all these different parameters. We can write down dj of hn and dhn of dwn and we can do- do this kind of everywhere. When I first learned about deep neural networks, you have to do this by hand. One of the major major innovations that's happened over there, you know, roughly what? Like last 5 to 8 years is that there's auto differentiation. So, that now, um, you don't have to derive all of these, uh, gradients by hand instead, you can just write down your network parameter. And then your network of para- which includes a bunch of parameters and then you have software like TensorFlow to do all of the differentiation. sort of hand writing down of what the gradients are. So, what are these h functions? Generally, they combine, um, both linear and nonlinear transformations. If it's nonlinear, we often call this an activation function. So- so, you can choose different combinations, uh, of linear functions or non-linear functions,Um, so- so- you can think of hn is equal to some function hn minus one. Um, basically they just- they have to be differentiable. and as usual we need a loss function at the end. Typically, we use mean squared error. You could also use log likelihood but we need something that- that we can differentiate how close we are achieving that target in order to update our weights. [NOISE] Yeah? Name first. So, this ReLU function is not differentiable, right? It is differentiable. It's ended up being a lot more popular than sigmoid recently, though I feel like it [OVERLAPPING]. Yes. But I don't see how gradient [inaudible] is gonna work on the part where it's flat. Nodes are basically just sort of a sufficiently complicated set of features and functions. This is a universal function approximators which means that you can represent any function with the deep neural network. So, that's really nice. We're not gonna have any capacity problems if we use a sufficiently expressive function approxIMators. Um, they're good to be aware of, um, and we're also happy to give other pointers. But yeah, if it's flat, it's okay, you can still just have a zero derivative. About what we're doing with linear value function approximators, it was clearly the case sometimes that you might have too limited features and you just wouldn't be able to express the true value function for some states. That will not occur for, um, uh, deep neural network if it is sufficiently rich. Another benefit is that potentially you can use exponentially less nodes or parameters compared to using a shallow net which means not as many of those compositions to represent the same function. Then the final thing is that you can learn the parameters using stochastic gradient descent. Convolutional neural networks are used extensively in computer vision. One of our primary sensory modalities is vision, and it's very likely that we're going to want to be able to use similar sorts of input on our- our robots in our artificial agents. So, if you think about this, um, think about there being an image, in this case, of Einstein. Um, and there's a whole bunch of different pixels on Einstein, and then they would be going as input to another. layer and, um, you might want to have a bunch of different nodes that are taking input from all of those and so you can get a huge number of weights. So, you can have lots of sort of functions being computed in parallel. You might have 10 to the 6 weights per- the st- the- often, we think about sort of- I know I haven't given you enough details about this, but often we think of there as being sort of this deep neural network. Convolutional neural networks try to have a particular form of deep neural network that tries to think about the properties of images. So, in particular, images often have structure, um, in the way that our- our brain promises images also has structure and this sort of distinctive structure. Um, if we think about doing this many times and having lots of hidden units, we can get a really an enormous number of parameters. There'd be 10 to the 6 parameters here. That's a lot. And then if we want to do this for doing different types of weights all in parallel, then that's gonna be a very very large number. features in space and frequency. So, when you have a convolutional neural network, we think of there being particular types of operators. Having so operators again here are like our functions, h1 and hn, which I said before could either be linear or nonlinear and then convolved neural network learn a particular structures for those, um, uh, for those functions to try to think about the properties that we might want to be extracting from images. The point of doing this is gonna be trying to extracting features that we think are gonna be useful for either predicting things like whether or not, you know, a face isn't an image. the key idea- one of the key ideas is to say that we're gonna have a filter or a receptive field. At the beginning, that's just gonna be a subset of our image and instead of, um, taking in the whole image, we're just going to take in part. So, it's like we're trying to compute some properties of a particular patch of the image. There's also this thing called zero-padding which is how many zeros to add on each input layer and this determines sort of help determine what your output is. this case, if you have an input of 28 by 28 and you have a little five-by-five patch that you're going to slide over the entire image, then you're gonna end up with a 24 by 24 layer next. So, one thing is instead of having our full x input, we're just gonna take in- we're gonna direct different parts of the x input to different neurons which you can think of just different functions. Um, but the other nice idea here is that we'regoing to have the same weights for everything. So, you can imagine I'm trying to detect whether or not there's something that looks like a horizontal edge in that part of the image and I try to- and that is determined by the weights I'm specifying. So, now the weights are identical, and you're just moving them over the entire image. We think that often, the brain is doing this. It's trying to pick up different sort of features. In fact, a lot of computer vision before deep learning was, um, trying to construct these special sorts of features, things like sift features. captures important properties of the image, but they're also may be invariant to things like translation. This means also that rather than just computing, uh, you- you can do this. You'll use the same weights all the way across the feature, er, all across the image. There's a really nice, um, discussion of this that goes into more depth from 231-n, which some of you guys might've taken. Um, and there's a nice animation where they show, okay, imagine you have your input, you can think of this as an image. then you could apply these different filters on top of it, which you can think of as trying to detect different features. Um, the other really important thing in CNNs, is what are known as pooling layers. They are often used as a way to sort of down-sample the image. So you can do things like max pooling to detect whether or not a particular feature is present, um, or take averages or other ways to kind of just down, ah, and compress the, the information that you got it in. for really high dimensional input and kind of average and slow down until we can get to, um, a low dimensional output. So, the final layer is typically fully connected. We're kind of computing this new feature representation of the image, and at the very end, we can take some fully connected layer, where it's like doing linear regression, and use that to output predictions or scalars. So these type of representations, both Deep Neural Networks and Convolutional Neural Networks, are both used extensively in deep reinforcement learning. How we could use these type of approximations for Atari. So why was the surprising? I just sort of wandering back. In around 1994, personally in 1994, we had TD backgammon which used Deep Neural Networks. Well, they used neural networks. I think there was someone that deep, and I think out like a world-class backgammond player out of that. So, that was pretty early on. And then we had the results that were kind of happening around like 1995 to maybe like 1998, which said that, "Function approximation plus offline off policy control, plus bootstrapping can be bad, can fail to converge" success and then there were these results in sort of the middle of the nineties that indicated that things could be very bad, and the risk was some of the- In addition to the theoretical results, there were sort of these simple test cases, that, you know, these simple cases that went wrong. So, it wasn't just sort of in principle this could happen, uh, but there were cases which failed. And so I think for a long time after that, the, the community was sort of backed away from Deep Neural Networks for a while. DeepMind, DeepMind combined them and had some really amazing successes with Atari. And so I think it sort of really changed the story of how people are perceiving using, um, this sort of complicated function approximation, meters, and RL, and that yes, it can fail to converge. But it is also possible of them that despite that- you know, the fact that we don't always fully understand why they always work, that often in practice, we can still get pretty good policies out. the mid '90s? Or, is it just that kind of through increases in computational power and the ability to gather a lot of data, that when it failed, it kinda doesn't matter, and we can try some different, like we- you know, try it again and kinda put it together and just keep trying until it works? I guess my question is, did we actually overcome any of the problems that arose in the late ' 90s, or is itjust that we're just kinda powered through? The question is how we sort of fundamentally resolve some of the issues of the late my '90's, or, um, we kind of brute forcing it. I think people knew about this when they started going into 2013, 2014. And so they tried to think about, "Well, when might this issue happen, and how could we avoid some of that stuff?" Like, what's causing that? And so at least algorithmically, can we try to make things, that people often talk about stability, so can wetry to make sure that the Deep Neural Network doesn't seem to start having weights that are going off towards infinity and at least empirically have sort of more stable performance. where they changed things to be more on policy or, or which we know can be much more stable. Um, ah, they are doing deep learning in, in this case, Deep-Q Learning. And so it can still be very unstable, but they're gonna do something about how they do with the frequency of updates to the networks. We'll see how it works here. Anyone else? Okay, cool. So, we'll- we'll see an example for breakout shortly, um, of what they did. Dennis and David, both had sort of a joint startup on, um, video games, a long time ago. So, their idea was, we'd really like to be able to use this type of function approximator to do Atari. They picked Atari in part.as well as in our derivative. And whether we're gonna see is, is uh, an alternative to that. Okay. Um, so, they're both interest in this it's clearly, uh, games are often hard for people to learn. I'm so, it's a nice sort of, uh,. demonstration of intellect. In these games, you typically need to have velocity. So, because you need velocity, you need more than just the current image. So what they chose to do is, you'd need to use four previous frames. So this at least allows you to catch for a velocity and position, observe the balls and things like that. It's not always sufficient. Can anybody think of an example where maybe an Atari game, I don't know how many people played Atari. Um, uh, that might not be sufficient for the last four images. visible on screen, it maybe sad, um, and, er, maybe it stored in inventory somewhere. So you have to sort of remember that you have it in order to make the right decision much later or there might be some information you've seen early on. And the reward can be the change in score. Now notice that that can be very helpful or may not be it, depends on the game. So in some games it takes you a really, really long time to get to anywhere where your score can possibly change. are the important things that they, um, did in their paper, this is a nature paper from 2015, is they use the same architecture and hyperparameters across all games. Now just to be clear, they're gonna then learn different Q functions and different policies for each game. But their point was that they didn't have to use totally different architectures, do totally different hyperparameter tuning for every single game separately. It really was the sort of general architecture and setup was sufficient for them to be able to learn to make good decisions for all of the games. approximators act. And the nice thing is that, I think this is actually required by nature. They, they released the source code as well. So you can play around with this. So how did they do it? Well, they're gonna do value function approximators. They're going to minimize the mean squared lost by stochastic gradient descent. Uh, but we know that this can diverge with value function approximation. And what are the two of the problems for this? Well one is that there is this or the correlation between samples which means that if you have s, a, r, s prime, aprime, a prime, r prime, double prime. lot of correlations. Um, and also this issue with non-stationary targets. What does that mean? It means that when you're trying to do your supervised learning and train your value function predictor, um, it's not like you always have the same v pi oracle that's telling you what the true value is. That's changing over time because you are doing Q-learning to try to estimate what that is and your policies changing. So you don't have a stationary target when you are even just trying to fit your function. standard approach, just uses a data point. A data point is really one of these sar, S prime tuples. In the simplest way of TD Learning or Q-learning, you use that once and you throw it away. That's great for data storage, um, it's not so good for performance. So the idea is that we're just gonna store this. Uh, we're gonna keep around some finite buffer of prior experience. We're gonna re-basically redo Q- learning updates. data instead of just using each data point once, you can reuse it and that can be helpful. So, even though we're treating the target as a scalar, the weights will get updated the next round which means our target value changes. This is like saying that periodically I- like let's say I went s1 a1 r1 s2 and then I keep going on and now I'm at like s3 a3 r3 s4. That's really where the data is going. I am in the world, I'm now in state four. It's like I suddenly pretend that I'm back in s1, took a1, got r1, and went to s2 and I'm gonna update my weights again. The reason that that update will be different than before is because I've now updated using my second update and my third update. So, it'll cause a different weight update. In general, one thing we talked about a long time ago is that if you, um, uh, do TD learning to converge it, which means that you go over your data mu- like, like, an infinite amount of time. learn to model, a dynamics model, and then the planning for that which is pretty cool. So, this is getting us closer to that. But we don't wanna do that all the time because there's a computation trade-off and particularly here because we're in games. Um, but we can talk more about that later. Yeah, question and name first please. And so, the experienced replay buffer has like a fixed size. Is those samples, like, replaced by new samples after fixed amount of time? Or is there a specific way to choose what samples to store? you remove items from it. It's a really interesting question. Different people do different things. Normally, it's often the most recent buffer, um, can be for example the last one million samples, which gives you a highlight of how many samples we are gonna be talking about. But you can make different choices and there's interesting questions of what thing that you should kick out. It also depends if your problem is really non-stationary or not, and I want to mean there's, like, the real world is non- stationary, like your customer base is changing. based on the experience replay versus getting, um, putting new samples into there. So, generally right now is really heuristic trade-off. Could certainly imagine trying to optimally figure this out but that also requires computation. This gets us into the really interesting question of metacomputation and metacognition. Um, but if, you know, your agent thinking about how to prioritize its own computation which is a super cool problem. Which is what we solve all the time. use in that value of S prime for several rounds. So, instead of always update- taking whatever the most recent one is, we're just gonna fix it for awhile and that's basically like making this more stable. Because this, in general, is an approximation of the oracle of V star. What this is saying is, don't do that, keep the weights fixed that used to compute VS prime for a little while. Um, one is gonna be this weight and the other is this weight. minus. I'll call it minus because, um, well there might be other conventions but in particular it's the older set of weights, the ones we're not updating right now. Those are the ones that we're using them as target calculation. So, when we compute our target value we, again, can sample and experience tuple from the dataset from our experience replay buffer, compute the target value using our w minus, and then we use stochastic gradient descent to update the network weights. help, um, in terms of stability? In terms of Stability, it helps because you're basically reducing the noise in your target. If you kept your target fixed forever, you would learn the weights that- that minimize the error to a constant function. That would then be stable because you always have the same target value that you're always trying to predict. And eventually you'd learn that, and that would eventually be stable. And that's what we're trying to do with GT. This is just reducing the noise and the target that we're trying to sort of, um, if you think of this as a supervised learning problem, we have an input x and output y. The challenge in RL is that our y is changing. If you make it that you're- so your y is not changing, it's much easier to fit. Uh, assuming we want to do [inaudible] approximator. Is there something that's specific to the deep neural networks? This is not specific. This is really just about stability and that's- that's true for the experience replay too. Experience replay is just kinda propagate information more- more effectively. Uh, so these aren't sort of unique using deep neural network. I think they were just more worried about the stability with these really complicated function approximators. Yeah, in the red. Do you every update the- Minus at all, or is that [inaudible]. Great question. So, the- Di- Dell? Dian. Dian's question is whether or not, um, we ever update w minus, yes we do. These sort of Q learning are not true gradient descent methods. They're- they're are approximations to such, they often do shockingly well given that. There's often particular patterns or- or hyper- it's a hyperparameter choice of how quickly and how frequently you update this. Um, and it will trade-off between propagating and updating the gradient. This is hopefully gonna help but we have no guarantees. Yeah? Uh, George, uh, so in practice, do people have some cyclical pattern and how can they refresh the- the gradient that's used to compute the gradients? information fester, um, and possibly being less stable. If n is infinity, that means you've never updated it. There's a- there's a smooth continuum there. We notice, like, for w, there are better initializations than just like zero, uh, something, if you take into account, I guess like the mean and variance. Uh, would you initialize w minus just two w or is there like an even better initialization for w minus? Yeah, his questions is about, you know, the- the impact of how we, um,. uh, initialize w ca- can matter. It stores the transition in this sort of replay buffer, a replay memory, um, use sample random mini-batches from D. So, normally sample in mini-batch instead of a single one. You do your gradient descent given those. Um, you compute Q learning using these old targets and you optimize the mean squared error between the Q network and Q learning targets, use stochastic gradient descent, and something I did not mention on here is that we're typically doing E-greedy exploration. of what the agent is doing. So, remember the agent's just learning from pixels here how to do this. As it gets more and more data, it learns to make better decisions. But one of the things people like about this a lot is that, uh, you can learn to exploit, um, the reward function. Uh, so in this case, it figures out that if you really just want me to maximize the expected reward, what the best thing for me to do is to just kind of get a hole through there and then as soon as I can start to just bounce around the top. the reward, it'll- it'll learn the right way to maximize the reward given enough data. Um, and so this is really cool that sort of it could discover things that maybe are strategies that people take a little while to learn when they're first learning the game as well. So, when they did this, they then showed, um, some pretty amazing performance on a lot of different games. Many games they could do as well as humans. Now, to be precise here- oh yeah I'm sorry. Uh, I'm just wondering why, um,. why was it [inaudible] around a lot, like, it wasn't sure of its movements. clearly sort of an inexperienced player to do that. That would be a strange thing but from the agent's perspective, that's completely reasonable. Um, and it does not give him positive or negative reward from that. So, it can't distinguish between, you know, stay in stationary versus going left or right. If you put it in a cost for movement that could help. This might become a little bit of [inaudible] but is there a reason to introduce a pulling layer? Puling layer? There might be one in there. uh, they're not talking about how long it took them or their agent to learn and as you guys will find out for homework two, it can be a lot of experience. So, they did very well on some domains. Some domains, they doing very poorly. Um, I think that it's clear that the really important feature is replay. We'll probably talk- uh, we'll talk a lot more about exploration later on in the course. so, what was critical? So, I- I like the, uh, there's a lot  lovely things about this paper and one of the really nice things is that they did a nice ablation study.  replay is hugely important and it just gives us a much better way to use the data. Using that fixed Q here means you seem like a fixed target. You do replay and suddenly you're at 241. Okay, so throwing away each data point what- after you use it once is not a very good thing to do. Um, and then if you combine replay and fixed Q you do get an improvement over that but, uh, it's really that you get this huge increase, um, at least in break out in some of the other games. So, the question is like, "Well, maybe we could use, like, linear-" also I guess I should be clear. So, we've done some work, um, using a Bayesian last layer, using like Bayesian linear regression which is useful for uncertainty. But you could certainly imagine trying linear plus replay and it seems like you might do very well here, it might depend on which features you're using. There's some cool work over the last few years looking also at, uh, whether you can combine these two. a talk about reinforcement learning, and like 40 people would show up, but most of them you knew, and, um, and then, uh, then it started really changing. I think I was maybe in 2016, when, er, ICML, I was in New York and like suddenly there were 400 people in the room for reinforcement learning talks. And then, this year at NLP's which is one of the major machine-learning conferences, it's sold out in like eight minutes. So, there's been a huge amount of excitement based on this work. double DQN is kind of like double Q learning, which we covered very briefly at the end of a couple of classes ago. The thing that we discussed there was this sort of maximization bias, is that, um, the max of estimated state action values can be a biased estimator of the true max. This is to try to separate how we pick our action versus our estimate of the value of that action. It turns out that it gives you a huge benefit in many, many cases for the Atari games. back to the Mars Rover example. Um, er, so, in Mars Rover we had this really small domain, we are talking about tabular setting through just seven states, um, and we're talking about a policy that just always took action a1 which turned out to mostly go left. So, it was this. And the first visit Monte Carlo estimate of v for every state was 1110000, and the TD estimate with alpha equal one is this. That was when we talked about the fact that TD only uses each data point once and it didn't propagate the information back. So, let's say you get to choose two replay backups to do. Maybe it doesn't matter if you can just pick any of these, you're going to get the same value function no matter what you do. So, are there two- two updates that are particularly good, and if so, why and what order would you do them in? [NOISE] Hopefully you had a chance to think about that for a second. First of all, does it matter? So, I'm going to first ask you to pick the same one twice. guys, uh, the question. Vote if you think it matters which ones you pick, in terms of the value function you get out. That's right. So, it absolutely matters which two you pick. You will not get the same value function no matter which two. Now as for another voting, I will ask for which one we should do first? Should we update- should we do four first? Four is the last one on our replay buffer. Should we do three first?should we do two first? you get to backup that information. So, um, if you wanted to get all the way to the Monte Carlo estimate. What you would wanna do here, is you'd wanna do S3, a1, 0, S2 which would allow your V of S3 to be updated to one. So it definitely matters. It matters the order in which you did, do it. And that's the same as the last time I [inaudible] That's right. Yes. have changed. Um, so ordering can make a big difference. Uh, so not only do we wanna think about like, what, um, was being brought up before but I think to say like what should we be putting in our replay buffer. What order should be in a replay buffer but also what order do we sampled them can makea big difference in terms of convergence rates. There's some really cool work from a couple of years ago looking at this formally of like how, at what the ordering, matters. The number, of, um, updates you need to do until your value function converges to the right thing can be exponentially smaller, if you update carefully and you, you could have an oracle tells you exactly what tuple the sample. Which is super cool. But you can't do that. You're not gonna spend all this. It's very computationally, expensive or impossible in some cases to figure out exactly what that uh, that oracle ordering should be. Um, but it does illustrate that we, we might wanna be careful about the order that we do it. In the old ways and uh, example we're just going through, after you like propagated the one back once, you wouldn't be able to do anymore because your value's totally zero. So there's gonna be this tension between, when you fix, um, uh, your w minus, then, if you were looking at our case that we had before, then you would be able. to continue propagating that back, because you wouldn’t update yet, yet, that's exactly right. things versus her propagating information back. So why does it, what does ordering matter, that if you're fixing, and so you are not changing, uh, like, then it wouldn't matter what order we sampled those previous ones, right? Uh, okay. So basically, ordering matter at all, in that case. It still matters because we're still gonna be doing replay, o- over. So that buffer could be like, million and you might re-update your weights like every 50 steps or something like that. among the existing tuples? So out- so Pi is our, uh, sort of basically our DQN error. If we set Alpha equal to zero, you know, it's right. Yeah. So, so this sort of trades off between uniform, no prioritization to completely picking the one that, um, like if alpha's infinity then that's gonna be picked the one with the highest DQn error. So it's a trade-off. Most, the time prioritize replay is better and there's some hyper parameters here to play with. One of the best papers from ICML 2016 was dueling.do, short through this just so you're aware of it. Um, the idea is that, if you want to, make decisions in the world, they're working some states that are better or worse, um, and they're just gonna have higher value or lower value. What you really wanna be able to do is, figure out what the right action is to do, in a particular state. So I'm looking at this advantage function. A2 minus V of s.a2 minus S.a1 is called prioritize replay. It's an architectural choice and learning a recombine these for the Q. Empirically, it's often super helpful. So, again compared to double DQN with prioritize replay, which we just saw, which was already better than w- double D QN, which is also better than DQn. Um, this again gives you another performance gain, substantial one. So basically these are sort of threes, three different ones that came up within the- for two years after DQ n that started making some really big big performance gains. It could be super tempting to try to start, by like implementing Q learning directly on the ATARI. Highly encourage you to first go through, sort of the order of the assignment and like, do the linear case, make sure your Q learning is totally working. Even with the smaller games, like Pong which we're working on, um, it is enormously time consuming. It's way better to make sure that you know your Q Learning method is working, before you wait, 12 hours to see. whether or not, oh it didn't learn anything on Pogge. So, that, that- there's a reason for why we, sort of build up, the way we do in the assignment. Um, another practical, to a few other practical tips, feel free to, to look at those, um, and then we were on Thursday. Thanks. Back to Mail Online home.back to the page you came from. Back from the page where you come from. back to MailOnline home.

ROUGE-1: 61.16, ROUGE-2: 58.96, ROUGE-L: 57.38
BERTScore: 74.73

==============================================
==================== [42/100] ====================
Summary:
 salt makes up a tiny part of any bread though which has a huge effect on it and most bread is made with salt nowadays. salt has only been used in bread making for the last couple of hundred years which i can't believe surely someone would have thought to add salt to bread. Earlier bread has been around for thousands of years but regardless of what the truth is salt is an essential ingredient in breadmaking. We're going to make three breads one without salt so here's what we're Going to do today. This is not a recipe video so i'm not going to talk you through the steps here i'm making 3 breads they contain all the same amount of ingredients except the salt. Instead of talking about these breads i'll talk about how to use salt in ahsoka. This is a method of adding seeds and grains to your bread though and i will make a whole separate video covering this topic in detail right so we'll start with the three breads.just flour yeast and water the second one made with a standard two percent salt and the final one will be made with way too much salt at 10 percent these are of course extreme examples and only the tubes and dough is the correct one. Salt has a tightening effect on the gluten it strengthens the dough and makes it more cohesive as yeast consumes the sugars in the dough it expels carbon dioxide. bread made without salt is bland and has no character. salt helps with controlling fermentation it draws moisture through the cell walls of yeast in a process called osmosis yeast needs water to work effectively and the more dehydrated it gets the slower it will work. unbleached flour has carotenoid pigments which give the crumb of our bread the creamy color and a wheaty aroma. standard across the board you can of course lower the amount to reduce your sodium intake but i wouldn't go lower than one percent on the other hand two point five percent is the most that you should ever had. This would normally be for extremely rich though like brioche which can contain up to 50 butter extra salt is necessary in this case for correct balance of flavor and that kind of recipe would also generally use more yeast since the salt and sugar in the dough will slow down fermentation. The bread with no salt has gained less volume than one wood salt and instead of rising vertically it has spread out more sideways this is due to the weakness of the gluten it prevents the bread from keeping in good shape. right had no chance let's cut these open see what's inside and do the taste test there should be some clear differences in the crumb of course i'm not talking about the bread made with too much salt it has no crumb it's just a piece of dough. The bread without salt has a more open crumb but at the same time at a smaller volume. The texture is quite dry and spongy and it's a little bit rough it almost feels like a dishwashing sponge and taste wise it's pretty bland. Ahsoka would be made with hot or boiling water leaving it to soak at room temperature and keeping it warm for a long time would run the risk of it going off and spoiling salt inhibits enzymatic activity. adding just two percent of salt to your soaker will ensure that it doesn't get any funky flavors. You should account for the amount of seeds and grains and for the flour in the recipe when you're calculating the total amount of salt. If you don't add enough salt you'll end up with a bland tasting loaf. starter or yeast you would mix your flour water yeast or starter and then leave to ferment for several hours ahead of time before making the final dough pre-ferments add a great deal of flavor improve the texture and the keeping quality of your bread. Normally brief mints don't contain any salt that's why in hot kitchens or hot climates they can ferment too rapidly. There are ways of controlling this you can lower the temperature of the briefment you can place it in a cooler area or even lower the hydration of it by adding salt. it's rising more slowly whilst the one on the left is already collapsing. the one in the right is still pushing on. what did you think of this experiment did you learn something new let me know down in the comments see more videos like this one click right here that's all i have for you today thank you for watching i'll see you in the next one. i'll be back with a new video in a week or so. I'll let you know what it's about.

ROUGE-1: 56.54, ROUGE-2: 53.83, ROUGE-L: 49.85
BERTScore: 73.26

==============================================
==================== [43/100] ====================
Summary:
In this section, we're going to talk about the relativistic Doppler effect. And we make good use of our space-time diagrams, which we discussed earlier. So the situation is as follows-- to simplify this, we have a source which is emitting pulses. The question now is, how is this being observed by an observer which is moving with a relative velocity v with respect to the source? So let's analyze this. We can say x1 is equal to ct1 or equal to x0, and v is the velocity in which the source is moving. is moving. And similarly for t x2, we find c times t2 minus tau. And that's also equal to x0 plus vtimes t2. So the question is not how this observed-- how this is seen by the source but how this was being seen by an observer. So we have to apply Lorentz transformation. And we find then-- this is a little bit of an algebra exercise here-- that delta t prime is equal to gamma delta t minus v over c squared delta x. that the period now is given by 1 plus beta over 1 minus beta square root of that times tau. And the frequency is the inverse. So we just calculated relativistically how the period and the frequency of a wave is Lorentz transformed. We'll have 1 minus Beta over 1 plus Beta squareroot of that [? times ?] the frequency. That's how we get the period of the wave and the rate of its movement. The period is the same as the frequency, but the rate is the opposite.

ROUGE-1: 69.01, ROUGE-2: 61.87, ROUGE-L: 57.37
BERTScore: 78.26

==============================================
==================== [44/100] ====================
Summary:
New racecraft in town that's fast and designed to Perfection. E1 racing series that aims to prove the potential of electric power in the Marine industry. Will Smith is here he is who owns our team and uh we're looking to throw down hopefully some some some points. We are the pioneers of a brand new series so this is electric Hydro foil powerboat um there's nothing like it this is the first uh invention of its type here that we're racing in E1 Series. good times to get our first win all right have fun all right yeah you did hear right Will Smith owns this team and he isn't the only celebrity backer before the main event tomorrow first some competition between the team owners in the red Hollywood Legend Will Smith and in the orange and purple tennis champion laughing ital copy that ready to [Music] go these boats can reach 50 knots that's around 93 km per hour so how do they reach those speeds the key bit here is getting up on the thin bits of the foil and staying above the water to have the speed that's right. keep the boat happy but uh it always wants to stay unhappy so it's a challenge being a pilot in the race bird with the boat back on dry land there's a question I'm desperate to ask can we get in and have a l thank you it's tight yeah it is very tight yeah yeah I think Will Smith had a bit of a hard time getting into there can we fire it up of course we can yeah we we can't go to the full full load because we're in the garage but basically turn the Master on so it just takes a little while to boot up. drawing too much power while and while they're lift and that lifts them up onto the foils. While they're on the foil we can then obviously play around with the lift which is on the left hand side of the of the wheel. The trim on the right hand side and it's we're just altering that by a few points depending on wave conditions. This sport is still in the very early stages the nine teams have the same boat but they're working out how to push the tech. E1 is a brand new racing concept. It's foiling boats with an electric motor in a format that's never been done before. The E1 concept is basically a big figure of eight but it's a little bit more complicated with the long wrap and the long motor. The drivers themselves explain to us how this competition Works than some of the drivers themselves and who better to explain to them how it works than someof the drivers itself. The first E1 race will take place on Friday night. stars and things like that so you'll see a series of uh single point turns and then turns that have larger apexes we're racing some really spectacular locations on the sea in lakes and we're really trying to push the foiling technology to the max so every team has a male and a female pilot and it's up to the team to decide which pilot will go first um after the first race they'll alternate from there qualifying down in a single boat format so we're all about maximizing our one lap time and then we go into the semi-finals and the finals which is head-to-head racing. to it when you're really cooking and flying and um it's really unlike anything it's unlike any boat any jet ski any watercraft the course is a very simple Loop but those green boys mark an extra special part of the track and the teams have to choose very wisely when you take that turn you have to take the Long Lap one lap during the race. If you nail the timing depending on where you're at in the pack you can either pass other Pilots or you can stay out in front. as we go there's no set plan and it completely depends on where we are during the race and yeah it can change in a matter of minutes [Music] at the end of the day you know the teams really have to work together both Pilots have to be consistent you know One Pilot can be really fast if the other one is slower then it may come down to the wire. Having two very consistent Pilots that can work together is how you're really going to win let's po that champagne [Applause] hope it continues for many years to come. We are proud to be a part of the history of the city. We hope to see it continue for many more years. Thank you for all your support and good wishes. We will continue to support the city in any way we can over the next few years. Back to Mail Online home.Back to the page you came from. Back To the pageyou came from, click here for more information on this story and to read the rest of the article.

ROUGE-1: 66.18, ROUGE-2: 59.84, ROUGE-L: 58.71
BERTScore: 72.33

==============================================
==================== [45/100] ====================
Summary:
Marginal rate of substitution of good 1 with respect to good 2 is infinity. When we do not say when we say just MRS, we are not using any particular term, you can use both way. We will always use this, yes here is 0 and MRS here is infinity, but in both the examples MRS of cola is Infinity. So, just be careful what we are talking about. This is you know a point of confusion many people just change the axis when they talk about it. getting x you get 1 by x, and why? Let us see what do we mean by marginal rate of substitution mathematically. We will let us change it little bit, let us put it here 3.25 just for example, because what is the marginal rates of substitution here, MRS by the definition that we have used is minus 0.75. Just wait I will come to that, why what is happening, increase in x is, why we are getting minus sign, because of course, when we have convexity what we will get. To get 1 good you will have to give up the other good, both what we are assuming that both these items are good, means they give certain satisfaction or certain you know utility to the person, and what we want. So, of course, when we are increasing the amount of 1 good to bring what will happen using this, if we use the monotonicity what will happening. If more of 1Good what is happening let us see. From here you are moving here in this direction, here at the screen, its increasing from 2 its going to 3. accompanied by decrease in the other good, if both are the goods. So, here we have in denominator we have good 1 and changes 1 unit. How much change do we need in the second good, 4 minus 3.25 and of course, I should put a minus sign here, and this is you get 0.75. Marginal rate of substitution is nothing, but the slope of this indifference curve. It would be mathematically more sound to talk about very small unit of good 1, and with respect to get very little amount of good. good 1, how much the other person is willing to give up, the another good, but we have to measure in terms of per unit of good 1. So, that is why in that case MRS is going to be, let us say in other word, 'MRS' MRS. 1 is the original bundle is x y, and let us. say what is happening from x y what we are having, change is x plus delta. x and y plus delta y, what would be the slope. see, that MRS is given as a positive number, that only means that the author has introduced a negative sign here to convert the MRS into apositive number. So, it does not matter. Is it clear? Do you know the answer to this question? If so, please email us at jennifer.smith@mailonline.co.uk. If you don't, we would like to hear from you. Please send us a photo of your MRS and we will send it to you.

ROUGE-1: 58.30, ROUGE-2: 53.31, ROUGE-L: 54.71
BERTScore: 70.84

==============================================
==================== [46/100] ====================
Summary:
in this video we're going to discuss what externalities are in economics. An externality is when you do something that affects the well-being or the good of another person or a company but you're neither harmed or rewarded for what you did to that person. The externalities can be positive they can be negative. A negative externability is whenyou've harmed someone you've done something to somehow impose a cost on someone or some some company or something and you haven't reimbursed that person or paid them any money. the children are getting sick but if the company hasn't done anything to reimburse that family or somehow you know paid them or done something then they're basically creating a negative externality. As they produce the chemicals they're they're creating the sludge that that is getting in the river and it's it's harming these people but the people aren't being made whole so another thing would be let's let's say that you live in an apartment complex and your neighbor on the other side of the wall really loves to play Britney Spears music at 3:00 in the morning. at 3: a.m. and you said okay you know what I'll deal with this but I need you to give me an extra 50 bucks a month toward my rent and then you work out an agreement that's different but we're assuming here they haven't done anything to reimburse you they're not paying you. Now a positive externality is where you are doing something that doesn't harm someone it actually benefits that other person you're doing something good that just as a side test like it's as a tangent it's actually helping some other person or people. If you're not receiving the full social benefit you're just getting your own private benefit basically things where there's a positive externality the good is going to be under supplied. If you were actually paid if people said hey I really like what you did you might be more likely to get a flu shot and and and just if you even think with your house let's say you've you you you live in a neighborhood and there's other homes that are nearby and you do a good job maintaining.so forth so I'll just get this flu shot but you're actually helping other people as well right. your lawn and you mow your lawn and stuff but you don't really spend a l a lot of time making your house look pretty now if your neighbor is trying to sell their house they have a for sale sign up they might appreciate if you went out and really did a great job maintaining your home they would really just love that because then when people come to see their house which is for sale that would increase the value of their home right if the neighboring properties like yours look really really nice then that would help them sell their home. where you have a negative externality like pollution or something like that it would be overs supplied relative to what is socially efficient or optimal. Where you have an over-supply of something like pollution, for example, you would have it over supplied in a way that would be socially efficient and optimal. For example, if you have pollution, it would have to be over supplied to avoid it becoming a problem. This would be a way to reduce the amount of pollution or other negative externalities in the environment.

ROUGE-1: 69.14, ROUGE-2: 63.77, ROUGE-L: 61.84
BERTScore: 77.32

==============================================
==================== [47/100] ====================
Summary:
Professor Steven Smith: Let me start today by asking the question, "what is political philosophy?" In one sense, you could say political philosophy is simply a branch or what we call a subfield of the field of political science. Yet in another sense, political philosophy seems to be the oldest and most fundamental part of politicalScience. Its purpose is to lay bare the fundamental problems, the fundamental concepts and categories which frame the study of politics. In this respect it seems to me much less like just a branch of political Science than the foundation of the entire discipline. Political philosophy is the oldest of the social sciences. It can boast a wealth of heavy hitters from Plato and Aristotle to Machiavelli, Hobbes, Hegel, Tocqueville, Nietzsche, and so on. Study of the great books or great thinkers of the past can easily degenerate into a kind of antiquarianism, into a sort of pedantry. We find ourselves easily intimidated by a list of famous names and end up not thinking for ourselves, says the author. books, risk overlooking the issues facing us today? What can Aristotle or Hobbes tells us about the world of globalization, of terrorism, of ethnic conflict and the like? Doesn't political science make any progress? After all, economists no longer read Adam Smith. I want you to remain alive to them throughout the semester. Yes? Okay. One reason I want to suggest that we continue to read these books is not because political science makes no progress, but because these works provide us with the most basic questions that continue to guide our field. that were asked by Plato, Machiavelli, Hobbes, and others. We may not accept their answers and it's very likely that we do not, but their questions are often put with a kind of unrivaled clarity and insight. The fact is that there are still people in the world, many people, who regard themselves as Aristotelians, Thomists, Lockeans, Kantians, even the occasional Marxist can still be found in Ivy League universities. These doctrines have not simply been refuted, or replaced, or historically superceded; they remain in many ways constitutive of our most basis outlooks and attitudes. This course will be devoted to the study of those "academic scribblers" who have written books that continue to impress and create the forms of authority with which we are familiar. But one thing we should not do, right, is to approach these works as if they provide, somehow, answers to the problems of today. Rather, the great works provide us, so to speak, with a repository of fundamental or permanent questions that political scientists still continue to rely on in their work. Again, we still think in.influences, are usually the slave of some defunct economist. terms of the basic concepts and categories that were created for us long ago. In political philosophy, it is never a sufficient answer to answer a question with a statement "because Plato says so," or "because Nietzsche says so" There are no final authorities in that respect in philosophy because even the greatest thinkers disagree profoundly with one another over their answers. We are called upon first to read and listen, and then to judge "who's right?" "how do we know?" The only way to decide is not to defer to authority, whoever's authority, but to rely on our own powers of reason and judgment. What is justice? What are the goals of a decent society? How should a citizen be educated? Why should I obey the law, and what are the limits, if any, to my obligation? And of course, the all important question, even though political philosophers and political scientists rarely pronounce it, namely, quid sit deus, what is God? Does he exist? And what does that imply for our obligations as human beings and citizens? Those are some of the most basic and fundamental problems of the study of politics, but you might say, where does one enter this debate? The concept of the regime is perhaps the oldest and most fundamental of political ideas. Broadly speaking, a regime indicates a form of government, whether it is ruled by the one, a few, the many, or as more common, some mixture of these three ruling powers. Regimes are necessarily partisan, that is to say they instill certain loyalties and passions in the same way that one may feel partisanship to the New York Yankees or the Boston Red Sox, or to Yale. Fierce loyalty, partisanship: it is inseparable from the character of regime politics. Henry Adams once cynically reflected that politics is simply the "organization of hatreds" This raises the question whether it is possible to transform politics, to replace enmity and factional conflict with friendship. Is such a thing possible? It can't be ruled out, but such a world, I would note--let's just say a world administered by international courts of law, by judges and judicial officials. tribunals--would no longer be a political world. The regime constitutes an ethos, that is to say a distinctive character, that nurtures distinctive human types. Every regime shapes a common character with distinctive traits and qualities. So the study of regime politics is in part a study of the distinctive national character types that constitutes a citizen body. It is only possible within the structure of the regime itself. It consists of the entire way of life, the moral and religious practices, the habits, customs and sentiments that make a people what they are. moralism and religious life, our defensiveness about democracy and so on. All of these intellectual and moral customs and habits helped to constitute the democratic regime. And this regime--in this sense the regime describes the character or tone of a society. What a society finds most praiseworthy, what it looks up to, okay? You can't understand a regime unless you understand, so to speak, what a people stand for, what they look up to. This raises a further set of questions that we will consider over the term. The Federalist Papers by Alexander Hamilton even begins by posing this question in the starkest terms. Hamilton asks the basic question about the founding of political institutions. Are they created, as he puts it, by "reflection and choice," or are regimes always the product of accident, circumstance, custom, and history? The idea that regimes may be created or founded by a set of deliberate acts raises a further question that we will study, and is inseparable from the study of regimes. Who is a statesman? What is a stateman? In its oldest sense, political science simply was a science of statecraft. What are the qualities necessary for sound statesmanship? How does statecraft differ from other kinds of activities? Must a good statesman be a philosopher versed in poetry, mathematics, and metaphysics? Or is statesmanship a purely practical skill requiring judgment based on deliberation and experience? Is a streak of cruelty and a willingness to act immorally necessary for statecraft, as Machiavelli infamously argued? Political philosophy is an imminently practical discipline, a practical field. Its purpose is not simply contemplation alone: it is advice giving. None of the people we will study this semester were cloistered scholars detached from the world. Plato undertook three long and dangerous voyages to Sicily in order to advise the King Dionysius. Machiavelli spent a large part of his career in the foreign service of his native Florence, and wrote as an advisor to the Medici. Hobbes was the tutor to a royal household who followed the King into exile during the English Civil War. his name always Jean Jacques Rousseau, "citizen of Geneva," and was approached to write constitutions for Poland and for the island of Corsica. Tocqueville was a member of the French National Assembly whose experience of American democracy deeply affected the way he saw the future of Europe. The study of regime politics either implicitly or explicitly raises a question that goes beyond the boundary of any given society. A regime, as I've said, constitutes a people's way of life, what they believe makes their life worth living. Political philosophy is always guided by the question of the best regime. But what is thebest regime? Even to raise such a question seems to pose insuperable obstacles. The best regime will always favor a certain kind of human being with a certain set of character traits. This issue received a kind of classic formulation in Aristotle's distinction of what he called the good human being and the good citizen. For the good citizens you could say patriotism is enough, to uphold and defend the good regime. Aristotle says the good citizen is not the same as the good human being. The good citizen loves what is good simply, not because it is his own, but because it's good. Abraham Lincoln said Henry Clay loved his country "partly because it was his own country" Lincoln's point was that Clay exhibited, at least on Lincoln's telling, something of the philosopher, what he loved was an idea, the idea of freedom. That love of the laws of your own country simply because they are your own is both necessary and sufficient. idea was not the property of one particular country, but it was constitutive of any good society. The good human being, it would seem, would be a philosopher, or at least would have something philosophical about him or her. But of course the best regime lacks actuality. We all know that. It has never existed. The philosopher can never be truly loyal to anyone or anything but what is best. Think of that: it raises a question about issues of love, loyalty, and friendship. unnecessary or redundant. It would wither away. Political philosophy exists and only exists in that... call it "zone of indeterminacy" between the "is" and the "ought," between the actual and the ideal. This is why political philosophy is always and necessarily a potentially disturbing undertaking. Those who embark on the quest for knowledge of the best regime may not return the same people that they were before. But there is some compensation for this, I think. The study of political philosophy may be the highest tribute we pay to love. see you back, and have a very good but thoughtful September 11^(th). See you back on 9/11/11. I'll see you back in a week or so. Thanks for your support and good wishes. I love you all, and see you on 11/11 /11. Back to Mail Online home. back to the page you came from. See you in a month or so, and I'll be back to see you in the U.S.

ROUGE-1: 58.44, ROUGE-2: 54.79, ROUGE-L: 54.84
BERTScore: 72.43

==============================================
==================== [48/100] ====================
Summary:
Ahern: So the exams are not graded. The TAs have exams of their own and I have told the TAs that, fingers crossed, I would like to have exams back sometime on Friday. That may not be until afternoon, I don't know at this point. But the aim is to get things back by Friday. When exams are available, what I will do is I will send an email out to the class announcing that they're available and announcing where to pick them up. exam. Ahern: I have never had an exam where I had fewer questions. There were maybe 10 questions I got on the exam and that was for a class of this side, really unusual. "I find most students are honest. I've only had a handful of situations where in this class, where I've had dishonesty as an issue," Ahern says. "There's just too many eyes here and not enough of our eyes," he says of his class. "So that's why I videotape those" Ahern: How many amino acids can form zwitterion? None. That's not trick. There are no amino acids, everything, so think about it. Ahern: What did you have in mind for the last question? The one about the Kcat? Oh,Yeah, yeah, yeah. okay. So the question, and by the way, I will post the key outside my door after we give the exams back. I don't post those now because students get all anxious until they see their exam. Ahern: How can you have two apparent Kcats? and the answer is it depends on how you calculate the concentration of the enzyme. If you take Vmax and divide it by the total concentration of enzyme, you will see a reduced Kcat compared to the uninhibited enzyme. Why? Because much of that concentration of. enzyme is not active, it's inhibited. However, if you take the inhibited out of it and you take. Vmax to divide it, you'll see exactly the same Kcat as if you have an uninhibited. enzyme. where time is sometimes a factor, and so I was going to have 3 of the longer answer questions and I decided not to do that and I made them shorter. So I had 2. There's trade offs in all these as I've told other classes. So one of the things that happens is the fewer the questions I have, the more points each question is worth. And so I have to try to strike a balance. And this balance, I think works fairly well. I'm glad to hear there weren't too many at least who indicated time problems. Yes, sir? be large and I can do what you recommend there. My concern is, well, what I always see is there's a bias. Everybody decides to do this question over here. And it seems to me that when I have that bias, it suggests that all of the questions aren't equal in difficulty and so that kind of makes me think well maybe that's not the way to go. But I have considered it and I have done it on some occasions. And I won't rule it out. Ahern: If you're going to spend a fair amount of time on something, it should be worth more points. The working of the problems, which usually is the time limitation, isn't as much of a factor because you've seen how to do these sorts of problems before. So I rarely, I won't say never because you, in a class of this size, I could never say never. But we're working problems, we have to work through problems and that's why. give an exam where I ask you to sign their name and people would say they didn't have enough time. But literally, I rarely have much of an issue with the other two exams. And usually I'll tell you. When I ask that question to this class, I would say I've seen as many as 2/3 of the hands go, 'I didn'thave enough time' So I was very careful to try to make sure I didn't ask you too many things. It meant I had to have 20 point problems because we have to have a 100 point exam. same manner that the enzyme is binding a substrate. And so the parallels of those with respect to concentration and so forth, that's really the reason you see those two curves being essentially the same. Everybody's all [Ahern makes groaning noises]. Alright, I hope everybody got how I start my lecture. Right? Student: No. Ahern: No!? Student: I said if you said something about starting the exam, we would give credit. Or starting the class, we'd give credit, yeah? S1 proteases are a class of enzymes that are called S1. They're called serine proteases because they all use serine in the active site. So they all have the catalytic triad. But there are some related proteases that have things like that that I want to spend some time on. And I'm going to talk about some of those today. But before I do that,I want to talk a little bit more about S1 proteased because so far all I've told you about them is that they are aclass of enzymes. Using genetic techniques today, it's very easy to alter the genetic code for any of these proteases and change which amino acid is presence at any given place. Doing that, researchers have changed, for example, a serine residue of 221, which is the serine, gives it its name, to an alanine. Or changing the histidine position 64 to anAlanine, or changing aspartic acid at position 32 to analanine or changing all 3. And when they do that, and they compare the activity, so this is the log of Kcat. like these are half, this is 1, 2, 3, 4, 5, 6, 7 orders of magnitude, meaning that the wild type is 10 million times more active than the enzyme that has its serine changed to an alanine. So obviously that serine is a very important residue. What this graph also tells us is that histidine is also very critical. And that's not surprising because, as you saw, in that catalytic mechanism, histidine had to pull that protein, protein, proton off of the serine to make the alkoxide ion. the water as if it didn't have a proton that could be pulled off in the first place. So these are important. When we look at removing the aspartic acid, we still see about 5 or 4 or 5 orders of magnitude lower. That tells us it's not absolutely essential for its catalysis although it does play some importance in that. But this tells us that that as partic acid residue is not as important as the other two. The other 2 are much more important. [inaudible] such as this where you can replace the serine, histidine, or aspartic acid with something other than alanine and perhaps increase the function. Ahern: Okay, so it's actually a very good question. The question is A, would I see activity? and B, might it even be better? And his question is also good because when we think about the process that gave rise to this proteases in the first place, they were mutation and selection. of like what these individual ones are here. Some mutations actually give rise to more functional enzyme. That's how enzymes evolved evolutionarily in the first place. But histidine to alanine here, that's a pretty big change. What if I put something like let's say a tyrosine here that might have a lot of electrons and ability to perhaps influence that proton. That might have an intermediate effect or some other effect. Make sense? Yes, sir? Student: Why is it just as ineffective when you replace as three as when you take off one them? Ahern: Very good question. Why is this one the same as this? Why would that be? good question but remember we have a very little activity and we have the rest of the structure of the enzyme intact. We have the binding site, we have an environment in there that maybe, in addition to the specific amino acid we see in an environment there that's favoring to some extent these activation and breaking of peptide bonds. So that's an interesting observation. What I want to do now is show you some related proteases. Subtilisin is a protease, it's an S1 prote enzyme, but there are other proteases that aren't S1 that behave very much like S1. Ahern: The nitrogen on histidine withdraws the electron from the sulfhydryl group on cysteine, which is then nucleophilic and attacks the substrate. Ahern: It's actually removing the proton. The histidine is removing theproton from the sulfur left behind with extra electrons. Those extra electrons are nucleophobic, they attack the peptide bond and very much like we saw, and I'll show you a mechanism in a second, very muchlike what we saw with the serine proteases. Ahern: mechanistically, this class of proteases is essentially identical to that of the serine protease, at least for our level of understanding. But those similarities aren't all the way through like we see with the cysteine proteases. Ahern: We extract a proton using the electrons of the aspartic acid residue, creating a reactive hydroxide ion. This acts as a nucleophile. The nucleophile attacks the peptide bond just as we saw before. for example, the serine proteases, we made an alkoxide ion, right? We had that oxygen atom that had an extra electron. It attacked the carbonyl group that caused one part to fall off and what happened to the oxygen? It became covalently bound to the other change and that chain is therefore stuck at the enzyme. That oxygen was attached to the rest of the enzyme, right?! So we're not going to see a fast step and a slow step with this. is not attached to anything. When water attacks that carbonyl group, the bond breaks, it's free. One step, bam. Student: Does this reset itself by [inaudible] stealing the hydrogen off... Ahern: yeah, yeah. Is that how it resets itself? Student: How does the enzyme reset itself? How does it get back to its original state? How do you do it? A Chern: I'm not trying to compare speeds, I'm just saying we won't have two steps. The 3rd class of proteases are called metalloproteases. These enzymes derive their name by virtue of the fact that they use a metal ion as their way of holding on to a water molecule. The most common ion that's used is zinc. The water played an important role in that catalytic process. The metalliproteases have a means of holding water there. That actually could make the enzyme more efficient because in the aspartyl proteases, that water could be bouncing around. Ahern: If we're going to break that peptide bond, we have to have a nucleophile. And that nucleophile and coming from water, we'reGoing to make a reactive hydroxyl group just as we did for the aspartyl protease. First, water is bound by this zinc ion. The zinc, you'll notice, is positively charged. The positive charge of the zinc is attracted to the negative, or the relatively negative charge, on the oxygen of the water. The basic mechanisms are the same. We created a nucleophile, the nucleophile attacks the carbonyl group, the peptide bond breaks, and the pieces go their way. Well this business of creating nucleophiles is not unique to proteases. There are other enzymes that use nucleophile and generation of nucleophile in their catalytic mechanisms. One of these is an enzyme we've been talking about some already, that's the carbonic anhydrase and that's right here. You guys look very tired. of a sudden realizes, "Whoa! What's that?" He grabs it, you know. Wipes the dust off of it. Of course in the process polishes this thing. And out pops this magic genie. And he says, "oh master, thank you, I will grant you 3 wishes." and the guy says, 'oh, this is really great' he says,. "I guess I want a billion dollars "so that I can be a very rich man." and poof, a certificate appears in his hands and it says he has a billion. dollars in a Swiss bank account. Carbonic anhydrase can catalyze the conversion of a million molecules of substrate into product per second, per enzyme. Most enzymes have a fairly narrow pH range where they work that's ideal. But this guy tops out at about pH 9, where we get up to a million per second. Why is its Kcat so high at such a high pH that it really doesn't encounter in the body? And so that's what I want to show you next. It's going to relate to the things I've been talking about. The rate limiting step in the catalytic action of this enzyme like that of the proteases that you saw before, is the rate of formation of the nucleophile. At pH 9, the enzyme is still holding its shape enough that it's actually able to continue catalysis. When we get above that, we're going to see the ending drop off precipitously. So that's a very interesting step. This actually shows the mechanism and again, it's nothing like you haven't already seen. We see the water being bound and we see something pulling off that proton. them? You can stick your neck out, I won't chop it off. I hear a no. Do I hear any yesses? What do aspartyl proteases have to do, folks? What about the metalloproteases? They both use water. Do they work better at a higher pH? Probably would. They probably work a little better at higher pH. The stability enzyme structure. That's going to be the only limitation. If the enzyme structure is stable at pH 10, the enzyme will be way better at 10 than it is at 7. their efficiency. In the case of carbonic anhydrase, though, remember what's limiting them is actually defusing it into the active site. It's probably not going to get much better than that million even if we were to improve that. But for a metalloproteases, it may very well be useful because now we can stabilize the enzyme with disulfite bonds, we can use it at a higher pH, that might very may be a strategy. We're slithering along through this. Let's take a, spend the last 5 or 6 minutes talking about restriction enzymes. We'll see some similarities we saw before. They use water to break the bond. And that should give you some hint about the mechanism that they use. One of the things we see in restriction enzymes is that they all require magnesium for their action. magnesium, like zinc, is a divalent KCat ion. It does help to position the water so that it can lose a proton and make an attack on, in this case, a phosphodiester bond. We're not breaking peptide bonds, obviously. But we're breaking phosphodiesters because those are the bonds between the adjacent nucleotides in a DNA molecule. A restriction enzyme is a protein. That protein grabs a hold of DNA. EcoRV recognizes the structure, the sequence GATATC and it cuts right in the middle of it. Now I want to explain to you just physically how a restriction enzyme works and then I'll show you very briefly a little bit of mechanism. DNA is a very complex substance. It's very difficult to understand. It has a lot of different functions. It can be used to help people understand how DNA works. is a negatively charged molecule, we would expect that to grab a hold of DNA, perhaps positive or neutral, we certainly wouldn't expect the protein to be negatively charged because it wouldn't interact very well with DNA. Most of the time it's going down that trip down the DNA molecule, it does not encounter the sequence GATATC. In fact that sequence will occur randomly, only about once every 4,000 residues. In the case of the serine proteases, that shape change resulted in the creation of the enzyme. alkoxide ion. In the case of the restriction endonucleases, that shape change is more dramatic. What it does is it actually causes a bend to occur in the DNA. So we think of the DNA molecules of being straight and linear, but when the enzyme is bound to that proper site, the enzyme goes "oh, whoa!" and it bends. The DNA molecule is physically bent at that point. It's physically bent. Now that bending turns out to be critical for the catalytic action. like we saw with the peptide bond and everybody's happy. I will very briefly go over that next time and I will see you on Friday. Thank you for listening to our show on CNN.com. We will be back on Friday at 10 a.m. ET for a new episode of CNN Live in the U.S. and 2 p.M. ET in the UK. For more, visit CNN.co.uk/live and follow us on Twitter @cnnlive and @CNNLive.

ROUGE-1: 54.53, ROUGE-2: 51.65, ROUGE-L: 50.77
BERTScore: 71.95

==============================================
==================== [49/100] ====================
Summary:
AA and I are going to show you how to make vanilla extract so easy so yummy so good for all the things that you would use it for cakes whatever really really good isn't it so let's go [Music] simple now all you want for this is about 1 oz or roughly 30 G of vanilla beans so they'll be you know long Dobby whacker things and just cut them up into I don't know a couple of cenm you may maybe maybe qu an inch half an inch or so. cup of vodka that's it all you do is put on the lid and just give this a shake and you just have to shake this once a day for at least a month preferably 2 to 3 months cuz you'll get more flavor it will ferment and it'll be a nice strong flavor just store this in a dry cool place and just as I said just shake once aday as you can see it's nice and dark I've been shaking this every day for about 2 months now a month will be enough but the longer you leave it the more flavor you'll have. like this no no you don't want to try it oh it smells so good do I smell this no you sure no it's really good can I smell it no oh let's give this a little little taste hold on oh yummmy do you want totry no no I'll see you next time for my next [Music] meal. Like this noNo, you won't even try it. No, you're not going to even smell it. You're not even going to taste it.

ROUGE-1: 72.43, ROUGE-2: 68.28, ROUGE-L: 68.11
BERTScore: 78.76

==============================================
==================== [50/100] ====================
Summary:
RAFAEL JARAMILLO: All right, let's talk about intermediate phases and line compounds. So I want you to recall intermediate phase in a three-phase system. And I'm going to recall it visually, and we're going to remember what the free-energy composition diagram looked like in such a case. And it looked-- let's say an alpha phase and the beta phase. We had some intermediate phase. So the common tangents are to look like this with a common tangency there. In this case, n is fixed. It doesn't vary in nature. So this is a little bit more like a molecule than a solution. How does that look on the free-energy composition diagram? Let's see. I used blue, green, and maroon, I guess. But now let's say that-- here's n. That's that composition. And this solution model is going to look like this. What I drew is something that's really narrow. So there's a minimum to this curve. But as soon as we deviate from that composition a little to the right or a little left, we have to pay a huge energy cost. solution model becomes very narrowly shaped, like a pin. All possible common tangents are going to converge at the same point. That point is x of B equals n. That's that one composition that we find in nature. So I no longer need a solution model. All I need is that one point, thatOne point, is one free energy point and one composition. OK. So here, I can't help myself. I got to draw the mouse-face plot. The magnesium nickel system has a number of different phases. At high temperature, this Laves compound develops some width. It can be made as a solid solution with a very, very narrow range of solid solubility. But when it's made into a line compound, it actually broadens. And this line compound down here, it also broadens at high temperature. So it's a mouse-face plot. But the point here is that these whiskers are all the common tangents kind of coming together at one point. You don't reach this hexagonal magnesium 2 nickel phase just by individually substituting our atoms from the HTP magnesium phase. And they're really fundamentally different structure. These Laves phases are of interest for people that study magnetism because they have these triangular sheets which are interesting for spin liquids and spin ices-- and then this FCC nickel. But this is the point I want to make here is that these are very distinct structures, and they're only occurring at very distinct compositions. That's a hallmark of an intermediate phase. like this. Magnesium nickel-- actually, magnesium nickel system, right? So, for instance, at some low. temperature, we have here this is going to be x nickel. And my taut rope construction, or my common tangent construction, ends up being just a series of straight lines. This is magnesium nickel 2 nickel. All right. So now let's talk about the size of these vertical segments. And it's often written as delta form. It is the free energy change for formation of 1 mole. of compound from the elements in their reference states. So, for example, I might have 2 moles of magnesium in. its alpha phase plus alpha-- let's say HTP-- plus a mole of nickel in its alpha. FCC phase. And these can react to form magnesium 2 nickel. This formation energy is per mole of compound. When we draw free energy composition diagrams, we assume 1 mole total of the components. So there's a normalization that you need to apply in order to use formation free energies. Modeling we have a model for how the free energy changes when you combine a total fixed amount of atoms in different composition ratios. This measure is 1/3 times delta form magnesium 2 nickel. So that is kind of a a solution. But this is different in the formation energy, right? This is a delta formation free energy on a free energy composition plot. So 2/3 a mole of magnesium, 1/2 of nickel combined to form this magnesium 2 Nickel 1 phase. That green arrow is the change of free energy. algebraically-simple point, but it's a conceptual point that it's easy to mess up. So you have to apply that normalization if you need to draw such plots. All right, I want to give you some examples of line compounds in nature and in technology. And then we'll come back to discuss the thermodynamics a little more. Before I move on to some examples, are there questions about this algebra, this arithmetic, the concept of formation energy, the mouse-face plot, anything, anything of that nature? have some examples here. So you can see that you can get a fair amount of silicon into copper. That's this kind of purple region. There are silicon bronzes and silicon brasses-- that is, bronze and brass alloyed with silicon. Those are ternary systems. But silicon tends to be a pretty useful additive for copper-based alloys. I used a silicon bronze when I was in grad school and we were designing high-pressure cells that needed to be actuated at low temperature, below 1 Kelvin. agencies around the world have developed in the last century. There's no real lubricant that you can use. And so there are certain silicon-based bronzes that have been developed for that application. And I didn't know anything about all that, really, when I was in grad school. But I needed something that would work for my high-pressure experiments. So we ended up with that. So let's see. There're a couple of other solid solution phases. But how many line compounds are there? Trick question. That's why it's a trick question. Silicon's not an intermediate phase, but it is a line compound. The solid silicon phase appears to have no equilibrium solubility of copper. In reality, you always have some finite solubilities of a solute in a solvent. So in the case of silicon, the solubilty of metals is very, very low. The solubileil limit is typically parts per billion. But in principle, there is a purple region extending along this y-axis of solubiliy of copper into silicon. Doping semiconductors is why we're able to talk to each other over Zoom. Doping some metals into silicon is as important as it gets. The solubility limits can be in the parts per billion. But they're rarely above parts perbillion. There's always a solution to doping semiconductor devices, says Dr. Richard Branson, founder of Branson Semiconductors, a company that specialises in semiconducting materials. The company's products include the gallium arsenide line compound and gallium arsenic system. gallium arsenide. Where silicon isn't fast enough are the transmitters and receivers of your phones, gigahertz RF networks. Another place you're going to find it is anywhere you need light. And so gallium arsenicide and alloys, thereof-- which we don't show here-- are the basis for all optoelectronics and photonic technology. So right now, we're Zooming. But likely, some part of the data between me and you is carried by fiber optic. arsenide and similar-material-based chips doing the work. Silicon carbide is a refractory-- some people will say it's a ceramic. Some people say no because it doesn't contain oxygen. It's used for grinding, so it's of enormous industrial importance. It also is an emerging semiconductor material for high-power electronics. The idea that you could replace those discrete elements with integrated circuitry-- saving power, saving money, saving weight and so forth-- that is the future. field of power electronics. And the thing is, you can't do it with silicon because silicon doesn't perform well at very, very high voltages. So in 50 years from now, if the idea of a power substation is a thing of the past, it will be due to silicon carbide and similar high-power electronics that are being developed today. And this last one, this is a big old mess. This is the titanium-sulfur system. It has this totally wacky kind of mismatch between two elements that are nothing alike. third of the Nobel Prize work that was recognized recently in 2019 with the chemistry Nobel Prize was for work on titanium-sulfide-based cathode. It's a layered material, so you can shove a lot of lithium in it. So these are-- for example, systems that have line compounds and other things. Do we have any questions on reading these, interpreting these, using these? AUDIENCE: Yeah, I have a quick question. So on the bottom left one and the top right one, do they both contain three line compounds? doesn't have to be that way. Here's a case of a line and an element that actually does have a pretty wide, solid solution, great range. At low temperature-- actually, similarly to gallium arsenide at low temperature, it's going to be a really boring free-energy composition diagram. Let's draw what that looks like. And let's say this is 50/50. All I need is a number to represent the free- energy change on forming silicon carbide. I just need that point. carbon from carbon doesn't take any energy to form. Silicon from silicon doesn't takes any energy. No solution models anywhere needed because nature doesn't form solutions. And here is my free-energy composition diagram. It is just a triangle. So it's simplified. It's simplified a lot. Any other questions on the meaning or importance of this stuff? I'll go back to this slide quickly. And then if there are no more questions, I'll finish up on the board. I suppose that because silicone is not a compound, the right answer probably was that there are three line compounds. But there are 1, 2, 3, 4 if you take pure phrases in the system. the free-energy composition diagram. That's what I meant to say. OK, then we move back to the board. I'll just make a couple of conceptual points and then we'll finish up. Comparing solutions at equilibrium to line compounds at equilibrium. So this is going to be two solutions. Let's imagine an alpha phase and a liquid phase. And I'm going to draw just a representative phase diagram just to have something in mind. So here's alpha. It is liquid. Here's x. we have these composition variables. We're familiar with that. The equilibrium condition, the equilibrium condition dG equals 0 satisfied by common tangents. Now let's imagine two line compounds. B3A2 and B4A3. How did I come up with that? Well, I sketched an imaginary phase diagram, and then I had to follow through on my sketch. And that means I had a congruent melter. And then I drew as this and then like this, peritectic, and something like this. I had this complicated thing which I do. low temperature where I have two line compounds coexisting. There are no internal composition variables. Before, we had composition variables because the composition of the phases was variable. Now, we don't have that. What that means is that the equilibrium condition dG equals 0 is satisfied trivially, trivially. There's no need to do common tangents. The compositions aren't changing. I can write out the total Gibbs free energy. It's going to be determined just by the phase fractions, phase fraction of the II-III phase. 1/7 of the Gibbs free energy of the IV-III phase. And these phase factions are determined by lever law. This is really the point. When you have line compounds in coexistence in equilibrium, there are no internal composition variables. Whereas when you have solution phases in equilibrium,. the internal compositions are variable. And that's what's led to everything we've been enjoying over the last month and a half. And now we have these cases where the compositions are not there [INAUDIBLE] anymore. Z is determined by charge balance. Oxygen is always O2 minus in compounds. Metals have various oxidation states. Some metals have more than one oxidation state. Z is in its reference state. That could be solid, liquid, or even gas-- although, we don't really encounter that so often. Oxidation of metals at low temperature, the metals are solid unless it's gallium or mercury. Oxides are line compounds. That z is not a variable. That's what that's supposed to mean. z is an integer or a rational fraction, and it's fixed-- SiO2, magnesium oxide, Al2O3, so forth. So when we return on Wednesday, we're going to talk about the thermodynamics of this reaction. We'll use this property of being line compounds, and we're also going to use a bunch of other things as well. Back to the page you came from. Follow us on Twitter @CNNOpinion and @cnnopin.

ROUGE-1: 59.50, ROUGE-2: 56.39, ROUGE-L: 56.21
BERTScore: 76.09

==============================================
==================== [51/100] ====================
Summary:
A random variable can take different numerical values depending on the outcome of the experiment. We restrict ourselves to discrete random variables, and we will describe these relative likelihoods in terms of the so-called probability mass function, or PMF. The PMF is also sometimes called the probability law or the probability distribution of a discrete random variable. Let me illustrate the idea with a simple example. We have a probabilistic experiment with four possible outcomes. We then introduce a random variable that associates a number with each possible outcome as shown in this diagram. We can think of the event that X is equal to 5. Which event is this? This is theEvent that the outcome of the experiment led to the random variable taking a value of 5. So it is this particular event which consists of two elements, namely a and b. And that probability we will be denoting with this notation. And in our case this probability isequal to 1/2. Because we have two outcomes, each one has probability 1/4. The probability of this event is equalto 1/1. with a probability, and we indicate it using this particular notation. More formally, the probability that we're dealing with is the probability, the total probability, of all outcomes for which the numerical value of our random variable is this particular number, x. We use a subscript, X, to indicate which random variable we're talking about. This will be useful if we have several random variables involved. For example, if We have another random variable on the same sample space, Y, then it would have its own probability mass function. The argument of the PMF, which is x, ranges over the possible values of the random variable. The probability mass function is a function of an argument x. For any x, it specifies the probability that the random variable takes on this particular value. Since the total probability of all outcomes is equal to 1, the probabilities of the different possible values of the random variables should also add to 1. The probability massfunction is always non-negative, since we're talking about probabilities and probabilities are alwaysNon-negative. In terms of our picture, the event that x isequal to 3, which is this subset of the sample space. The PMF of a discrete random variable is defined to be the sum of the random variables, X and Y. In order to do any probability calculations, we also need the probability law. Let us assume that every possible outcome, there's 16 of them, has the same probability which is therefore 1 over 16 for each one of the outcomes. We will concentrate on a particular random variable, X, which is the result of two rolls of the tetrahedral die. The probabilities of these events are the probabilities of the different values of X. We need to find this value for all choices of z, that is for all possible values in the range of our random variable. We can continue this way by marking, for each particular outcome, the corresponding value of the random variable of interest. After you are done, you end up with a table-- or rather a graph-- a plot that has this form. And these are the values of the different probabilities that we have computed. And you can continue with the other values. It's a reasonable guess that this was going to be 4 over 16. the form of the answers. And it's always convenient to also provide a plot with the answers that we have. The answers come in the form of a plot. The plot comes in the shape of a map. The map is a map of the world as seen from the top of a mountain. The top of the mountain is a mountain with a waterfall at the top. The waterfall is a waterfall as well as a river. The river is a river that runs through the middle of the village. The rivers run through the village and the valley.

ROUGE-1: 60.20, ROUGE-2: 54.31, ROUGE-L: 51.72
BERTScore: 79.27

==============================================
==================== [52/100] ====================
Summary:
Protein three-dimensional structure is an important part of proteomics. Structure has implications for the binding of small molecules such as drugs. We will in short order get to the scary pumpkin-like molecule. We'll connect it to last week's through the vehicle of focusing on motifs that are involved in protein interactions with the two nucleic acid macromolecules. We're going to be covering, just as we introduced RNA omics with RNA structure, we'll spend this entire class talking about protein three-Degree Structure. of the proteins and the three dimensional structure of the nucleic acid and these symmetry elements would align. Now in order to introduce these symmetry element and the possibility of having codes that you can at least program, even if they may have been tinkered about during an evolution, the question is to what extent can we get our hands on these kind of protein and nucleic Acid motifs that interact. In order to get at this issue of where there is a code-- and I just take this as one of the ways of dealing with the incredible complexity of proteins is to give this a theme. all kept within the helix with a repeat of 3.6 residues per turn. In the beta sheet, they tend to have a longer, straighter chains where there are unpaired hydrogen bonds. The arrows typically point from the n terminus to the c terminus just as in nucleic acids is from five prime to three prime. OK, now how can we use these basic motifs? These are the smallest meaningful units of protein three dimensional structure. How can we used these to recognize other macromolecules, other proteins and nucleic acid? We have these motifs that we could find, weight matrices for them by aligning lots of sequences. Now instead of aligning sequences, let's see what we can do by mutating both the protein part and the nucleic acid part. Make every possible peptide sequence in the middle or randomly sample the vast space that might occur in changing a few, say, six or more key amino acids. And then we know from the three dimensional structure that it interacts mainly with the middle three nucleotides. sequence alignments where we're going to get the weight matrices. We can get them by actual experimental measures of the binding in vitro. And the sequence that it mainly binds to-- remember this is a weight matrix. It's not a consensus sequence, this TGG. It obviously recognizes a variety of other sequences. This just happens to be the amount of the chunk of DNA that a zinc finger will cover. But remember, there's about three nucleotides on either side of it that the other two zinc fingers bind to. it's not coincidence that 4 to the third is still 64, just like the genetic code. And if you run through all possible nucleotide sequences for this wild type, you find the winner is TGG, and it has that particular binding constant. The binding constant is measured in the molarity, roughly where you get half maximal or equilibrium binding. That's 10 to the minus 9 moles per liter. You can now mutagenize the peptide and select for peptides that bind to GCC. is based on how much binding you get for each of the 64. Trinucleotides all result in a rather poor selection for any kind of peptide. None of them do particularly well, and the result is a weight matrix which has very little information content. So this is a way. of getting a really good empirical data set. In principle, you can combine it with similar functions on the flanking ones, and you can dial up any sequence of a nucleic acid protein interaction. you can get the binding at a lower concentration, which means a stronger binding. How you relate that to the binding constant we had in the previous slide is the subject of this slide number eight. Now we call this the apparent equilibrium association constant because these experiments, just like many binding in living cells, is not at equilibrium. It's a dynamic. And what you do is quantitate the fluorescence of the zinc finger protein indirectly by the binding of the covalently-attached phage to the antibodies. process in the cell and in vitro. There are ways that you can measure the equilibrium constants, but what this is apparent in the sense that you need to wash off the excess fluorescence in order to detect the fairly low signal that you get from the specific binding, rather than having fluorescence. And so as you're doing that wash, you're obviously not at equilibrium. In the end, you take a snapshot before you wash off everything. That's what you want. And the fraction of DNA molecules with the protein bounds can be found from this. by the amount of the fraction, which is the total DNA. That's the D plus PD. And then you just substitute in this definition of the association constant. The definition is product over reactants, and then you get this intermediate term. Now let's return the question that connected this talk with the last one, which was the symmetry of DNA protein interactions. We illustrated already one of these three zinc finger complexes. The double-stranded DNA is in blue and the three zinc fingers follow along the major groove, the large large groove. groove of the DNA. And the reason the textbook is wrong, first of all, it emphasizes the non-helical part of the zinc finger. You can barely see the helix with the background there. And also the way it loops through the DNA, if you look at this carefully in your textbook, this is actually the [? Mount ?] book, it actually interdigitates with a phosphodiester bond, basically going through the base pairs, which is not at all what happens. of the protein maintaining almost perpendicular to the DNA axis. But again, so on the left is the three tandem repeats, and on the right is a dyad axis. These are the two major symmetry classes, and it's amazing how many nucleic acid protein interactions fall into one of these two classes. Can we extend this to RNA? This is a much more complicated situation with RNA because you don't have these long perfect double helices anymore. You have these very short RNA helices that I found. showed in the last couple of classes. This is transfer RNA, one of our favorite molecules here, with the anticodon at the bottom of each of the pink structures. And the amino acid acceptor three prime end of that 70-some nucleotide-- 70 to 80 nucleotide nucleic acid. So the pinks are all the tRNAs, and there are at least 20 different types of amino acid and has 20 types of transfer RNAs and 20 type of proteins that add amino acid onto the three prime ends of the transfer RNA. If you wanted to create a new code, as these authors have, you'd have to find homology among the proteins or graph domains of recognition between each one. You can arrange to make a new amino acid by carving the pocket the amino acid recognizes and grafting on the appropriate nucleotides. OK, you've had some programming experience that hopefully will prepare you for the real world of interacting with input and output from various devices. The topic today is proteins, and this really is the main contact between the exquisite regulatory mechanisms. that you can basically program the almost digital nucleic acid world inside the cell but via clearly analog inputs and outputs. We also-- I've listed some of the scariest proteins that I could think of. And we're going to talk about three of them. One of them in the slide, which is the proteins that are actually involved in causing the symptoms that come from when you're worried about anthrax. And then we'll talk about HIV yet again, this time, polymerase mutants that cause drug resistance. not inside the cell. But the whole complex gets internalized. Still, topologically, it's as if it were outside the cell when it's inside this little vesicle. So you can see that when we're talking about protein three-dimensional structure, whether we're predicting it or solving it, protein is not a static object. Here, it associates with one factor. It associates seven of itself. It interacts with lethal factor. You need to think of these as dynamic systems with many different states. minus 9th seconds. That's atomic motion. Transcription that we talked about, all of the regulatory mechanisms of transcription last time, the rate of the constant for that process is around 50 nucleotides per second. Not entirely coincidentally, that's about the rate at which it is translated into protein. That could be used as a timer in a circuit of these longer time frames, like cell cycle, circadian rhythm, very long time frames in ecological systems with bamboo and various pests. then development and aging, which can be on the order of hundreds of years, at least for humans, turtles, and whales. So what we think proteins are good for depends on the accuracy. And the accuracy depend on the method. At the very bottom right, we have a very appealing approach, which is de novo, a priori, or ab initio prediction of secondary-- of protein three-dimensional structure from the sequence alone. But unfortunately, accuracy so far-- and we'll delve into this in more detail in a moment-- is on the orders of six angstroms of difference between the predicted structure and what it actually is. your accuracy, as you can get from NMR and X-ray crystallography, you now are in a position to study catalytic mechanism and design and improve ligands, such as drugs. This is really where we want to be. There may be a day where we can do this all from ab initio prediction or modeling at very great distances. But for now, modeling atVery short, say, 80% to 90% amino acid similarity, is important. Remember, there's a variety of different protein structures. And ways that you can discover the small molecules by a clever use of parts of it that you know bind. This is one of the most sequenced molecules on Earth, which is the HIV gene encoding the reverse transcriptase polymerase. And it's been sequenced many times because as a patient takes the drugs, their population of the AIDS virus changes. And each of these little diamond-shaped substitution sites clustered around the binding site in the protein. And these little diamonds indicate substitutions, where the nomenclature is single-letter code for the wild type, the position in amino acids from the end terminus. Mutations in DNA polymerases can lead to drug resistance in the HIV. DNA polymerase is a class of nucleotides that is incapable of extending. The complex between the nucleotide, whether it's a deoxynucleotide shown here with a 3 prime hydroxyl, which could then be extended by bringing in the next 5 phosphate. This Hydroxyl is near in the complex, so it can be used as a sequencing reagent for DNA sequencing. The dideoxys.letter is the new amino acids. So for example, D67N means a [? sparcade ?]. space to the position on a phenylalanine or a tyrosine, position 762 of this polymerase. If you now put in a dideoxy inhibitor, you now have too much space in there, and you start trying to fill that space with other bulky molecules, like water. And basically, the binding constant, it becomes much less favorable binding when you're lacking both oxygens. So this presented an opportunity to engineer some polymerases which had a phenylicalanine there to become more accepting of the dideoxys. This has an 8,000-fold effect on the specificity of this polymerase. Now, that's how we program a particular atom to achieve an important goal. Point mutants are not the only way to generate conditional mutants. Many of them historically were. But there are ways that you can program, and conditional, meaning you can regulate under what conditions. It's the ultimate where we go in and if the protein is already present, we can change that particular nucleotide in situ in the correct place so it's properly regulated and everything. the protein is expressed or not or active or not with an entire domain, or with single nucleotide polymorphisms. Now, so this is one way. This is the nucleic acid way. Another way is by modulating the activity of the proteins from the outside with drugs or drug-like molecules and chemical kinetics. And under the subheadings for that, you can make these by combinatorial synthesis-- and we'll show an example of that. But combinatorially synthesis can be based on design principles, not just completely random. that we didn't discuss before. But in previous classes. But it's related to what we've been talking about. In the case of the zinc finger, we made an altered specificity. We made new zinc fingers with bind to completely new trinucleotides. With the DNA polymerase, by changing one amino acid, we could make it now accept almost four logs better an inhibitor is very useful. And here, many different-- many of these are enzymes, where you can not just knock out the enzyme, but actually make it recognize a new substrate. ApoE refers to its involvement in cholesterol metabolism and transport. ApoE3 is present in about 80%, and is far more common in human populations. The ancestral form of this, for example, found in chimpanzees at nearly 100%, is this arginine 112, instead of what's now common inhuman populations was cysteine 112. We now eat a lot more fatty things. We live long enough to get Alzheimer's. And so maybe this was something that was-- this bad allele was good in chimpanzees that have different diets or lifespans. strand, to fall back and interact. And you can see that one of the nearest amino acids to this arginine 112, which is the main difference between ApoE4 andApoE3. Arginine 61 is the same on the two alleles. But you think of this as one haplotype, and in chimpanzees the haplotype is now threonine 61. So it's like this compensating, complementary mutation, just like we had in the oxygens in the polymerase a couple of slides ago. think of these things in terms of proteins. You can have-- a disulfide is a very important thing to lose. They tend to be highly conserved. If you introduce a proline into what would normally be an alpha helix, this is something where knowledge of the three-dimensional structure would say, oh, that proline, this a priori, without any knowledge of conservation, could be a huge change. And then these multi-sequence profiles are a good way of looking at the conservation. That's a way of prioritizing single-nucleotide polymorphisms that might have impact on pharmacogenomics or disease. The idea of chemical diversity, in a way I hope nicely connects to where we've been with RNA arrays. RNA arrays, and the double-stranded RNA array that we used earlier in class today, can be generated in a commentorial sense. You can make an exhaustive set. Or you can make them as a mixture of solid phase particles and then separate the [INAUDIBLE] phase particles out in some manner. Solid phase comes up again and again in arrays. It's very obvious why you have a solid phase. You want to be able to address it by its positions in x and y on the array. purification of your products simply by washing rather than doing complicated purification procedures. And it allows you to, in the case of beads, there now-- you can think of it as an ultimate and flexible array. You can move the beads around and put them in new arrays, and identify them later. Anyway, so we're going to introduce the general way of making either-- complex chemicals, whether they're linear polymers like proteins or nucleic acids, or much more tighter and small molecules.  Synthetic way of getting short peptides, either by directly synthesizing the peptides or synthesizing nucleic acid that encodes that peptide. And you can think of these as drug-like molecules. These are naturally related-- they can be analogs of nucleic acids and proteins, not just straight ones. And we'll talk about opportunities for making these analogs. And the process is cyclic in the sense that each cycle, you return, and the polymer gets a little bit longer. You start with one monomer. on a solid phase, shown by these little hexagons on the far right side of the slide. And you add-- you remove the protecting group on the immobilized polymer, one protecting group. And then you bring in this reactive group, otherwise protected. And there's really one major product that you expect. You wash off all of the excess. You now have one longer. You deprotect. This DMT group is removed. There may be additional steps, such as oxidation, which will stabilize the new bond. I said there's an opportunity here for modifying the nucleotides or oligopeptides or other chemicals to make them so that they're related to, but not identical in every property, to normal constituents of your body or of a bacterial cell that you're aiming at. And why would you want to make derivatives? Why not make the exact thing? And examples are, in the previous slide, you can make modified bases. And in slide 29 here you can change the backbone itself. which you can make small molecule diversity which are less cyclic than processes we just talked about. These are more a set of ordered reactions that has a conceptual repeat, but in a sense, you can think of it as a linear program that you go from the beginning to the end. And that's to make these polyketides, which are shown on the right-hand side of the slide. A large class of pharmaceuticals, including most of the antibiotics, are made by a fairly small set of organisms, such as streptomyces in certain plants. Drug-like molecules are small, so they diffuse quickly and get to their site. Because they're small, they have less surface area to bind to their binding pocket. They have to be highly cross-linked in order to maintain the rigidity. And the third source of biological diversity is one you're probably more familiar with, which is the immune receptors, B and T cell receptors, the antibodies, and cell-mediated immunity. And these use recombination machinery to program various combinations of nucleic acid motifs. to a template-independent polymerase, [? thermotransferase, ?] which will extend a few nucleotides of completely random nucleic acid sequence. This is one of the examples in biology where you generate sequence de novo. The proteins themselves, these little arrow-shaped things with boxes in them along the top, labeled Module 1 through 6, those proteins are, of course, made on ribosomes. But then they act kind of like the solid phase synthesis. where the acyl carrier protein, ACP in the box, binds to the first monomer, and it starts transferring it from protein to protein along this multi-domain huge protein. And there's actually three proteins in a row here. And each of the steps are taken in order along the protein. But you can see each of these has a substrate specificity. And by changing the order of substrate specificities, you can build up a huge combinatorial collection here in microbial communities, and also in the laboratory. known protein might be, [INAUDIBLE],, which binds to DNA, and B42, which activates transcription of something for which you have a good visual assay, like [? URO3, ?] life and death. And so this is a so-called two-hybrid assay and variations on it. And you get this information about-- you can either collect a big data set of proteins that interact from a proteomic scale experiment, or from molecules that inhibit one or more of them. those interactions. You can model the three-dimensional structure of this interaction if you have sufficient data to do that. Now, if you look at the top right-hand part of slide 34 here, you can see this huge diversity of all of these different colored shapes. And if you wanted to use these in a combinatorial assay, you'd connect them in every pairwise combination and try them against your target by some bioassay. However, if that library is too large either to make or to screen, then what you can do is to study a part of the molecule and see-- and then take the subset of the diversity that can bind. if each one has a very low binding constant, then it will be roughly the square of that. And you get some point of diminishing returns, eventually. So this is an example of a strategy where you use a little bit of prior knowledge, which can be empirical or it could be purely computational, about how to limit your library and make interesting combinations. We have hundreds of proteins for which we have three-dimensional structures. From some of them, we have information on what ligands they bind. But these are other criteria that are sometimes used in the field for target selection. If they are homologous to previous interesting targets, then that puts them high on the short list. If they're conserved and you knock it out, then you might expect that to be lethal. And that might make it a good target for an anti-bacterial. If you want to limit the action of your therapy to the surface in order to, say, reduce the cross-reaction with internal molecules, you can sometimes restrict yourself to surface-acceptable proteins. And in fact, a very large class of drugs is aimed at surface-accessible membrane proteins. would like to have-- you've got your target. You've gotyour genome sequence-- gene sequence for that target. How, then, do you get the three-dimensional structure that helps you design drugs or improve the drugs that you have? Well, one very attractive approach, given a protein sequence which might get from their deluge of genome sequences, the practical approach might be to start with this gene sequence. And try to predict the three dimensional structure of the protein and its ligand specificity. Once you have a regulated gene, getting the protein sequence is easy. Getting from the sequence to secondary structure is easy in the context of some of these other things. But still, the accuracy is only around 77% for secondary structure and about 25% for ab initio three-dimensional structure. Then even if you have the three- dimensional structure at adequate accuracy, getting ligand specificity is problematic, and it depends on the ligand. If it's DNA, it's a good case; if it's small molecule, it can be as low as 10% or worse. all of those, which is dismally small at 0.0005. And so it behooves one to use as many extra-experimental data as one can, or improve the algorithms that are weakest in this journey from genome sequence to ligand specificity. We'll pick up this thread right after a break and carry on to actually how we get the three-dimensional structure, whether it's predictive or experimental, and the computational tasks there. Take a break. Thank you for your patience.

ROUGE-1: 61.51, ROUGE-2: 59.59, ROUGE-L: 59.05
BERTScore: 71.37

==============================================
==================== [53/100] ====================
Summary:
More than half of large US firms plan to use AI within the next year to automate tasks that were previously done by staff. The New York Times reports that generative AI could automate activities equivalent to 300 million full-time jobs around the world open ai's chief executive that's Sam mman says governments will need to assume the bulk of responsibility in supporting workers AI labor market disruptions and the question will employees just end up training AI systems only to them be replaced by them the potential human cost to all of this. New York Times also looks at how call center workers are quickly being overtaken by generative Ai. There are now warnings that entire Industries could be compromised mostly by AI. AI chat bots in as soon as a year well later in the program we'll speak to the writer of both of those New York Times articles. Our regular AI contributor Stephanie hair and also with us jintan Patel who's chief technology officer for Cisco in the UK and Ireland. natalis Gardino who's President and chief people officer at Salesforce. moment what we're seeing and uh often with these sorts of technological changes we see that we sort of tend to overestimate the impact in the short term and underestimate the long-term impact. We do believe that actually you know some of the the sort of the mundane activities and tasks that can be automated are being automated but actually driving up productivity for organizations which can only be a good thing on in its broader sense and and Stephanie I mean there's always that concern isn't there that AI is going to pinch all of our jobs. or doing something with your hands where I think you're quite safe from computers for the moment you're probably fine. If you are working in a call center something where your job could be automated that is something that you need to be looking at for the next few years. open AI CEO Sam ultman said it's the government's job to be retraining people and taking responsibility for all of this job losses but the government is us so it's really the taxpayer who's going to have to pick up the bill for this technology. last decade you know over a trillion customer insights are built on our platform every single week and now here we are in the generative AI Revolution um when it comes to the employee experience some of the AI deployments are things like uh you know a lot of our employees were spending time looking at disperate systems to find knowledge articles access to benefits who to speak to on the first day how to onboard and ramp. Now with AI applications that we've deployed they don't have to go to multiple systems anymore. One quarter of employees saved a combined 50,000 hours. At.at what that's allowed you to do I mean as you said free up time allow those staff to do other things. I mean how does that work how do we square that Circle well I think like you know any other uh benefits of becoming more efficient or more productive it is now spending more time on higher value impact work in your job those are the core benefits that we've seen from our teams instead of spending you know 10% of your time looking for information. There's a danger that we focus on all of this and on what it can deliver but frankly it needs people that understand it. There is no AI without data without the network to actually connect the you know act as the connective tissue to to the algorithms that are answering our questions and giving us our responses. If you can't secure that end to end then that's where that trust issue arises. We can draw a lot of parallels from the internet where you know we've been at the heart of the internet for over 40 years. really comes into as you mentioned around cyber security and you know when we when we first started sort of the the journey in the internet we saw the opportunity to actually train people around a program called Cisco's networking Academy. You know that's been going for over 25 years we've trained 20 million people in 190 countries around the world. We see the same thing happening again where you know we have to train the Next Generation in both these Advanced AI skills but also some of the fundamental essential digital skills that we need. of companies say that yes they know they need to do this but I think what 14% say they're actually ready to do it that's quite the Gap yeah. Who is we talking about overhauling the education curriculum from what age 5 to 18 and then into the universities who's funding that and who has the skills to even do it yeah yeah and that is a big question and Stephanie you're always our guide on this program aren't you through all things Ai and I know you've got questions uh for our panel we've got two big players here um what do you want. to know so what I want to know is first of all all of this um automation we're saying we're going to be getting rid of the most sort of benal tasks and making it so that people are free to do value added tasks but that value ad is going to shareholders and CEOs it's not going back to people. What can we do to make it. so that AI is valuable for everybody and not just the usual people who profit from technology yeah um Natalie let's throw that to you. Salesforce and we want to make sure that we're not leaving any talent unhidden and AI is helping us optimize that so I do see um you know the advancements of democratizing uh access to AI through those efforts as well but it's something we think about all of the time related to trust and you know making sure that how you're creating your products is representative of the world of societies of communities all these things are also core to the design process yeah chintan do you want to come in on that as well?  AI decoded looks at the impact of AI in the world workplace. The tech may be able to speed up and automate all sorts of monotonous or repetitive roles but there's also now a concern that Tech like intelligent chatbots could replace roles that have traditionally relied on a more human touch things like customer service or call center helplines. We're going to speak to one reporter who's been researching the threat posed to workers and how some are now fighting back around the world and across the UK. some workers are feeling the effects of that already and they're starting to ask who is going to protect us you know what entities are stepping in to take responsibility for retraining or providing opportunities for workers whose jobs might be entirely eliminated by AI technology. I think that would be incredibly demoralizing for anybody who's asked to do that so I think employers really are going to have to think about the messaging but also the after plan so once you've trained up an AI to do your supposedly Bol tasks what are employers offering are the higher value more creative more interesting. Emma asked if we would actually see an increase in Union membership for private sector workers in the United States. She said a lot of workers want to feel that their voices are part of the process in deciding how AI is going to be used. She argued that actually the people making all the decisions about the AI are not the ones who will be affected by that change it's workers further down the food chain that will find their job disappears before the ones sat in in the boardroom. EM: The role that I'm seeing unions play is just reminding employers that they should be bringing workers to the table to help make and shape decisions. frustrated because she felt that she was being asked to train her replacement whenever she used an AI tool because the AI was watching her do her job to the best of her ability. What she was asking asking from her Union was just the ability to be at the table making decisions about AI along with company Executives and Emma. This made me think of the difference between what it's like to work in the United States where Union representation is so low and often in opposition with management. Could we see that that cultural change happening not just in the US but even more widely across the globe it's a important question. in decades um so unions are are becoming much more popular the their um the number of workers that they represent is still quite low but you're seeing Union drives at companies like Starbucks and Amazon many companies that hadn't previously been unionized. People are hoping that this kind of momentary shift of power toward unions will turn into a more um long-term and sustained power moment for unions. They can then play a role in pushing companies to treat workers well as they're bringing AI to the table. Could we actually replace CEOs or Executives and actually end up having AI run companies and just get rid of those High expensive salaries altogether absolutely. were most at risk because of automation. People are realizing you have to throw out the door any ideas you had about who is really at risk and say every job is going to be changed. We just hope that the workers whose jobs are changing have a voice in saying how yeah it's turkeyy is not going to vote for Christmas are they if those are the ones that could find their jobs being replaced. There's uh there's so much in there and Stephanie just a final thought from you in all of this about briefly if you will. I think we also have to be realistic you're not just going to suddenly go get an engineering degree in two weeks right learn cyber security overnight um these are these are highly complex skills that require usually years of training so this will involve I think a sort of again look at the Danish model of the government and companies working together to sponsor re-education and retraining for workers. This is a total pivot of our economy uh Stephanie really good to have you with us again guing us through all of this and now Emma thank you so much.

ROUGE-1: 62.49, ROUGE-2: 60.36, ROUGE-L: 59.30
BERTScore: 71.07

==============================================
==================== [54/100] ====================
Summary:
foreign I'm really excited especially for this lecture which is a very special lecture on robust and trustworthy deep learning by one of our sponsors of this amazing course themus AI. Theyus AI is a startup actually locally based here in Cambridge our mission is to design advance and deploy the future of AI and trustworthy AI specifically. I'm especially excited about today's lecture because I co-founded Themis right here at MIT right here in this very building in fact this all stemmed from really the incredible scientific innovation and advances that we created right here. Sadhana sadhana is a machine learning scientist at Themis Ai. She's also the lead TA of this course intro to deep learning at MIT. Her research focuses specifically on how we can build very modular and flexible methods for AI and building what we call a safe and trustworthy Ai. Sadhana will be teaching us more about specifically the bias and the uncertainty of AI algorithms which are really two key or critical components towards achieving this Mission. She'll be talking to you all about robust and trustworthy deep learning on. behalf of Themis so over the past decade we've seen some tremendous growth in artificial intelligence across safety critical domains in the Spheres of autonomy and Robotics. We now have models that can make critical decisions about things like self-driving at a second's notice and these are Paving the way for fully autonomous vehicles and robots. That's not where this stops in theSpheres of medicine and Healthcare robots are now equipped to conduct life-saving surgery. We have algorithms that generate predictions for critical drugs that may cure diseases that we previously thought were incurable. rooms is this these are some headlines about the failures of AI from the last few years alone in addition to these incredible advances we've also seen catastrophic failures. Every single one of the safety critical domains I just mentioned these problems range from crashing autonomous vehicles to healthcare algorithms that don't actually work for everyone even though they're deployed out in the real world. At a first glance this seems really demoralizing if these are all of the things wrong with artificial intelligence how are we ever going to achieve that vision of having our AI integrated into the fabric of our daily lives. A lot of the problems in modern day AI are the result of a combination of unmitigated bias and uncertainty. In this lecture we're going to focus on investigating the root causes of all of these problems these two big challenges to robust AI are bias bias and uncommunicated uncertainty. This lecture will look at how to overcome these two challenges and how to make AI more robust and reliable. The lecture will also focus on how to improve the quality of the data that is being used to train AI models. Bias bias is a word that we've all heard outside the context of deep learning but in the context. of machine learning it can be Quantified and mathematically defined. We'll talk about how to do this and methods for mitigation of this bias algorithmically and how Themis is innovating in these areas in order to bring new algorithms in this space to Industries around the world. After we talk about uncertainty which is can we teach a model when it does or doesn't know the answer to us to its given task and we will talk about the ramifications for this for real world AI. a lot of clinical data sets where they often contain fewer examples of diseased patients than healthy patients because it's much easier to acquire data for healthy patients than their disease counterparts. We also have selection bias at the data portion of the AI lifecycle think about Apple's series voice recognition algorithm this model is trained largely on Flawless American English but it's deployed across the real world to be able to recognize voices with accents from all over the world. These biases can be propagated towards models training Cycles themselves which is what we'll focus on in the second half of this lecture. I have a model that I trained on the past 20 years of data and then I deploy it into the real world in 2023 this model will probably do fine because the data input distribution is quite similar to data in the training distribution. What would happen to this model in 2033 it's it probably would not work as well because the distribution that the data is coming from would shift significantly across this decade. If we don't continue to update our models with this input stream of data we're going to have Obsolete and incorrect predictions. Commercial facial detection systems are everywhere you actually played around with some of them in lab two when you trained your vae on a facial detection data set. Facial detection systems also present in the automatic filters that your phone cameras apply whenever you try to take a picture and they're also used in criminal investigations. We'll analyze the biases that might have been present in all of them for in the in the next few minutes. We're going to face evaluation bias so now let's talk about another example in the real world of how bias can perpetuate throughout the course of this artificial intelligence life cycle was also comprised mostly of lighter skin faces these accuracy metrics would be incredibly inflated and therefore would cause unnecessary confidence and we could deploy them into the real world in fact the biases in these models were only uncovered once an independent study actually constructed a data set that is specifically designed to uncover these sorts of biases by balancing across race and gender. There are other ways that data sets can be biased that we haven't yet talked about so so far we've assumed a pretty key assumption in our data set. This is a really big problem and it's very common across a lot of different types of machine learning tasks and data sets. The first way that we can try to mitigate class imbalance is using sample re-weighting which is when instead of uniformly sampling from our data set we instead sample at a rate that is inversely proportional to the incidence of a class in our dataSet. The second way we can mitigate class and balance is through loss re- weightsing which means that samples from underrepresented classes contribute more to the loss function. input face to a as a negative it'll be highly penalized if it does so because the loss of the faces would contribute more to the total loss function. The final way that we can mitigate class imbalance is through batch selection which is when we choose randomly from classes so that every single batch has an equal number of data points per class so is everything solved? There are other forms of bias that exist even when the classes are completely balanced because the thing that we haven't thought about yet is latent features. latent features are the actual represent is the actual representation of this image according to the model. set of features can we still apply the techniques that we just learned about the answer is that we cannot do this. The problem is that the bias present right now is in our latent features all of these images are labeled with the exact same label so according to the as the model all we know is that they're all faces. We can't apply any of the previous approaches that we used to mitigate class imbalance because our classes are balanced but we have feature imbalance now however we can adapt the previous methods to account for bias in latent features which we'll do in just a few slides. our biased features and then apply resampling so let's say in reality that this data set was biased on hair color most of the data set is made up of people with blonde hair with faces with black hair and red hair underrepresented. If we knew this information we could label the hair color of every single person in this dataSet and we could apply either sample re-weading or loss relating just as we did previously. The second thing is exactly what you said which is once we have our bias features going through and annotating every image with this feature is an extremely labor-intensive task. to dbias a model so what we want is a way to learn the features of this data set and then automatically determine that samples with the highest feature bias and the samples with lowest feature bias we've already learned a method of doing this in the generative modeling lecture you all learned about variational autoencoders which are models that learn the latent features of a data set. We want samples that are similar to each other in the input to decode to latent vectors that are very close to eachOther in this latent space. walk through step by step a de-biasing algorithm that automatically uses the latent features learned by a variational autoencoder to under sample and oversample from regions in our data set. This debiasing model is actually the foundation of themis's work this work comes out of a paper that we published a few years ago that has been demonstrated to debias commercial facial detection algorithms and um it was so impactful that we decided to make it available and work with companies and industries. good representation of what a face actually is so now that we have our latent structure we can use it to calculate a distribution of the inputs across every latent variable. We can estimate a probability distribution depending on that's based on the features of every item in this data set essentially what this means is that we can calculate the probability that a certain combination of features appears in our data set. Then we can over sample denser or sparser areas of the data set and under sample from denser areas. The approach basically approximates the latent space via a joint histogram over the individual latent variables so we have a histogram for every latent variable Z sub I and what the histogram essentially does is it discretizes the continuous distribution so that we can calculate probabilities more easily. This allows us to train in a fair and unbiased manner to dig in a little bit more into the math behind how this resampling works. We can Define the adjusted probability for sampling for a particular data point as follows the probability of selecting a sample. data point x will be based on the latent space of X such that it is the inverse of the joint approximated distribution. As Alpha increases this probability will tend to the uniform distribution and if Alpha decreases we tend to de-bias more strongly. This gives us the final weight of the sample in our data set that we can calculate on the Fly and use it to adaptively resample while training. Once we apply these this debiasing we have pretty remarkable results. Keep this algorithm in mind because you're going to need it for the lab 3 competition which I'll talk more about towards the end of this. lecture so so far we've been focusing mainly on facial recognition systems and a couple of other systems as canonical examples of bias however bias is actually far more widespread in machine learning consider the example of autonomous driving many data sets are comprised mainly of cars driving down straight and sunny roads in really good weather conditions with very high visibility. In some specific cases you're going to face adverse weather bad um bad visibility near Collision scenarios and these are actually the samples that are the most important for the model to learn. an extremely famous paper a couple years ago showed that if you put terms that imply female or women into a large language model powered job search engine you're going to get roles such as artists or things in the humanities. If you help input similar things but of the male counterpart you'll end up with roles for scientists and engineers so this type of bias also occurs regardless of the task at hand for a specific model. Finally let's talk about Healthcare recommendation algorithms these recommendation algorithms tend to amplify racial biases. uses that UL will also be developing today and for the next part of the lecture we'll focus on uncertainty or when a model does not know the answer. We'll talk about why uncertainty is important and how we can estimate it and also the applications of uncertainty estimation. To start with what is uncertainty and why is it necessary to compute let's look at the following example this is a binary classifier that is trained on images of cats and dogs for every single input it will output a probability distribution over these two classes. Uncertainty estimation is useful for scenarios like this this is an example of a Tesla car driving behind a horse-drawn buggy which are very common in some parts of the United States. The exact same problem that resulted in that video has also resulted in numerous autonomous car crashes so let's go through why something like this might have happened. There are multiple different types of uncertainty in neural networks which may cause incidents like the ones that we just saw we'll go through a simple example that illustrates the two main type of uncertainty that we'll focus on. of a regression task the input here x is some real number and we want it to Output f of x which is should be ideally X cubed so right away you might notice that there are some issues in this data set assume the red points in this image are your training samples so the boxed area of this image shows data points in our data set where we have really high noise. If we queried the model for a prediction in this part of in this region of the data set we should not really expect to see an accurate result. names to the types of uncertainty that we just talked about the blue area or the area of high data uncertainty is known as aliatoric uncertainty. The green areas of this just the green boxes that we talked about which were Model uncertainty are known as epistemic uncertainty. This cannot be learned directly from the data however it can be reduced by adding more data into our systems into these regions okay so first let's go through alliatoric uncertainty so the goal of out estimating alliatorIC uncertainty is to learn a set of variances that correspond to the input. model we have the same output size that predicts a variance for every output so the reason why we do this is that we expect that areas in our data set with high data and certainty are going to have higher variance. The crucial thing to remember here is that this variance is not constant it depends on the value of x. Now that we have this model we have an extra layer attached to it in addition to predicting y hat we also predict a sigma squared how do we train this model? that we're estimating is accurate so in addition to adding another layer to estimate alliatoric uncertainty correctly we also have to change our loss function so the mean squared error actually learns a multivariate gaussian with a mean y i and constant variance and we want to generalize this loss function to when we don't have constant variance. We can think about this for now as a generalization of the mean square error loss to non-constant variances. Now that we know how to estimate aliatoric uncertainty let's look at a real world example for this task we'll focus on semantic segmentation. a data set called cityscapes and the inputs are RGB images of scenes the labels are pixel wise annotations of this entire image of which label every pixel belongs to and the outputs try to mimic the labels they're also predicted pixel wise masks. Why would we expect that this data set has high natural alliatoric uncertainty and which parts of this dataSet do you think would have aliatoric uncertainty. Even if your pixels are like one row off or one column off that introduces noise into the model the model can still learn in the face of this noise but it does exist and it can't be reduced. uncertainty can best be described as uncertainty in the model itself and it is reducible by adding data to the model so with epistemic uncertainty essentially what we're trying to ask is is the model unconfident about a prediction. A really simple and very smart way to do this is let's say I train the same network multiple times with random initializations and I ask it to predict the exact I call it on the same input. We should see that with familiar inputs in our Network our networks should all converge to around the same answer. very little variance in the um the logits or the outputs that we're predicting. If a model has never seen a specific input before or that input is very hard to learn all of these models should predict slightly different answers and the variance of them should be higher than if they were predicting a similar input. training an ensemble of networks is really compute expensive even if your model is not very large training five copies of it tends to it takes up compute and time. However the key insight for ensembles is that by introducing some method of Randomness or stochasticity into our networks we're able to estimate epistemic uncertainty. can keep these Dropout layers enabled at test time usually we don't keep Dropout layer enabled attest time. We don't want to lose any information about the the Network's process or any weights when we're at inference time. When we're estimating epistemic uncertainty we do want to keep Drop out enabled at Test time because that's how we can introduce Randomness at inference times. So we have that that measure of Randomness and stochasticity so again in order to implement this what we have is a model. epistemic uncertainty so both of the methods we talked about just now involve sampling and sampling is expensive ensembling is very expensive but even if you have a pretty large model um having or introducing Dropout layers and calling 24 word passes might also be something that's pretty infeasible. At Themis we're dedicated to developing Innovative methods of estimating epistemic uncertainty that don't rely on things like sampling so that they're more generalizable and they're usable by more Industries and people. training The Ensemble and calling multiple ensembles on the same input we received multiple predictions and we calculated that variance. Now that we have many methods in our toolbox for estimating epistemic uncertainty let's go back to our real world example let's say the again the input is the same as before it's a RGB image of some scene in a city and the output again is a pixel level mask of what every pixel in this image belongs to which class it belongs to. Would you expect to have high epistemic uncertainty in this example? the sidewalk to the road and other parts of the sidewalk are labeled incorrectly and we can using epistemic uncertainty we can see why this is the areas of the sidewalks that are discolored have high levels of uncertainty. maybe this is because the model has never seen an example of a sidewalk with multiple different colors in it before or maybe it hasn't been trained on examples with sidewalks generally either way epistemic Uncertainty has isolated this specific area of the image as an area of high uncertainty. and uncertainty to mitigate risk in every part of the AI life cycle. We have analyzing the data before a model is even trained on any data we can analyze the bias that is present in this data set and tell the creators whether or not they should add more samples. Once we're actually training a model if it's already been trained on a bias data set we can de-bias it adaptively during training. Afterwards we can also verify or certify deployed machine learning models making sure that models that are actually out there are as safe and unbiased as they claim they are. is by leveraging epistemic uncertainty or bias in order to calculate the samples or data points that the model will do the worst on the model has the high the most trouble learning or data set samples that are the most underrepresented in a model's data set. Lastly we can think about we're developing a product at Themis called AI guardian and that's essentially a layer between the artificial intelligence algorithm and the user and the way this works is this is the type of algorithm that if you're driving an autonomous vehicle would say hey the model doesn't actually know what is happening in the world around it right now. i's product called capsa which is a model agnostic framework for risk estimation so capsa is an open source Library you all will actually use it in your lab today. It transforms models so that they're risk aware so this is a typical training pipeline you've seen this many times in the course by now we have our data we have the model and it's fed into the training algorithm and we get a trained model at the end that outputs a prediction for every input. With capsa what we can do is by adding a single line into any training workflow we can turn this model into a risk-aware variant that essentially calculates biases uncertainty and label noise. then further analyze and so this is the one line that I've been talking about um after you build your model you can just create a wrapper or you can call a wrapper that capsa has a an extensive library of. Capsa wraps models for every uncertainty metric that we want to estimate we can apply and create the minimal model modifications as necessary while preserving the initial architecture and predictive capabilities. This could be adding a new layer in the case of a variational autoencoder this could be creating and training the decoder and calculating the Reconstruction loss on the Fly. Themis is unlocking the key to deploy deep learning models safely across fields. We can now answer a lot of the questions that the headlines were raising earlier which is when should a human take control of an autonomous vehicle. What types of data are underrepresented in commercial autonomous driving pipelines. We now have educated answers to these questions due to products that Themis is developing and in spheres such as medicine and health care we can now answers questions such as when is a model uncertain about a life-threatening diagnosis. compete in the competition which the details are described in the lab but basically it's about analyzing this data set creating risk-aware models that mitigate bias and uncertainty in the specific training pipeline. At Themis our goal is to design advance and deploy a trustworthy AI across Industries and around the world. We're hiring for the upcoming summer and for full-time roles so if you're interested please send an email to careers themesai.io or apply by submitting your resume to the Deep learning resume drop and we'll see those resumes and get back to you.

ROUGE-1: 61.14, ROUGE-2: 59.04, ROUGE-L: 59.60
BERTScore: 66.95

==============================================
==================== [55/100] ====================
Summary:
HONG LIU: So at the end of last lecture, so we discussed this LSZ theorem, which tells you how to obtain scattering amplitude from correlation functions. OK, so if you want to compute, say, some scattering. amplitude from alpha to beta-- so alpha's some initial state and beta's some final state. Say alpha consists of momentum p1 and PN-- or pm, and beta, say momentum p m plus 1 and pn. And then you can get this scattering amplitude just by taking your momentum-space correlation function, OK, for the n points. When you obtain a correlation function, you don't distinguish what is the initial and the final state. You just have some momentum. This is a function of some arbitrary momentum. But the scattering amplitude, of course, those momentum are on shell. So the way you distinguish the initial. momentum and thefinal momentum is by taking the initial momentum, say to go to the negative root, and the. final momentum to take the positive root. But since the alpha, it consists of minus p1, and then the initial state, you have positive energy. HONG LIU: So for each external momentum-- so here there's a propagator, and just as if that-- when you get-- so this scattering amplitude was corresponding to this one with all external propagators stripped. OK, so that's why you consider the truncated diagram not including the external propagator. And you take it on shell.correlation functions, OK, and then you sum over-- youSum over, say, the truncate-- so you see the relation between these correlation functions and the scattering amplitudes. So they differ by this product. I will explain a few things. OK, so remember this Gn, so let's go back to the definition of this Gn. These momentum-space correlation functions. So this is obtained by doing a Fourier transform. Say-- I think it would be minus sign. So then you want those phi corresponding to the initial state to act on the right. And so this, if you just record the mode expansion, can be written as the following: phi x1 andphi xn. for phi and the phi contains a and a dagger-- and the a pieces acting on the zero will just give you zero, so only a dagger piece will survive. OK, with k it's the on-shell momentum, so k is given by omega k and k. When you do the Fourier transform and then you find just p, then your p just equals to minus k, OK, so that's related to the minus sign there. When your p equal to minusk, then that means p0 is equal tominus k. that sign in the initial state come from. And the same thing with the final state, so for the final. state, then you need to look at the phi x acting on the left to this, and then you do the. Fourier transform. So this explains the sign. It's just from whether you act on the initial. state or act onThe final state. OK. Good? So-- yes? AUDIENCE: Right, so time-ordering of x1 to xn right here? HONG LIU: Yeah. HONG LIU: To derive that theorem, the time-order matters. OK, you can do this for the full interacting theory. Yeah, just use the free scalar as the-- yeah, because when you go to plus or minus infinity,you can just reduce to the free particles. OK. Other questions? OK, good. So this is the first comment. The second comment, each side, we need to here-- from here, weneed to truncate the external propagator. propagators, so that means you also throw away diagrams like this. You can consider arbitrary, complicated diagram, OK, as far as that only happens-- yeah. So such kind of diagrams, they only change the external propagator, but since we truncate the external propagateator, and then they don't matter at all, OK? So the reason is the following. All this diagram do is just modify the properties of the external. propagator. And the only way all these diagrams can modify the. external propagators is to give you an overall constant. truncated them, and so you don't need to worry about them. So Z also has an expansion, just 1 plus order Lambda, et cetera, so the leading order, so Z does not contribute. OK, you can just set it to 1, and when you go to the higher order, then the Z can make a contribution. OK. So you just need to separately take into account the Z, and there's no need to contribute-- to calculate those things separately. HONG LIU: Z is the same for different processes, but it's different for different particles. Z is a constant for all of them, yeah. If it depended on momentum, then it would be kind of useless, right? So we will not go into details of the Z. And that is what is called the "Z" principle. It is the principle that all such things don't change the momentum. OK, the momentum don't changed. Yeah.things, they-- yeah, all these things, essentially, they just modify the-- give you the correction to the external propagator and include it in that constant Z. HONG LIU: This is the self-interact-- yeah, just when the-- when you have an interacting theory, so the particle can interact with itself. It just all comes from this kind of diagram. You can have single particle, and you can have such a diagram like this and all these diagrams. Correspondingly, you have a particle propagating, but that particle can interacts with the virtual particle, its own virtual particle. OK, and so that, this is the rule corresponding to the particle loop. kind of interaction, will affect the property of the propagation but can have the most effect by prefactor, but actually can change the mass, too. But for the-- oh, it can correct for the mass-- and also, that's the subject of the QFT2. I think at most canchange the overall factor by z. Other questions? Good. If you don't have other questions, so let's conclude our discussion of chapter 3 on interacting theories. OK, and now let's discuss how to describe fermions. The Dirac equation is one of the most beautiful equations in mathematical physics. It's actually describing electrons, so it's not only beautiful, but it's actually useful. The Dirac theory is a prime example of how people make great discoveries often for the wrong motivations. But the key is that if you are good enough, you will find something new and that something new will be useful. We'll talk about fermions in the next section of the lecture. We're going to talk about the Dirac equations and its covariance. go to a different frame. OK, yeah, that's what we mean by-- just when you go to aDifferent Lorentz frame, the equation, the form of the equation looks the same. Just different observers in different laboratory, they see the same equation, OK. So your first-order derivative, then, has to have the following form, alpha minus i-- yeah, so this is the gradient operator,Yeah, spatial derivatives. And then you can at most add the constant, OK, so let me just write this constant as m times beta. doesn't make any sense, OK? So alpha and beta, they have to be some kind of constant, OK, but if alpha andbeta are constant, then this is not even a rotational invariant, not to mention Lorentz environment. So alpha is just some constant, so this cannot be LorentZ covariant, even cannot be rotational environment. OK, and psi is the ordinary function. So yeah, so you can have alpha x, partial x, alpha y, partial y, alpha z, partial z, OK. So you can easily convince yourself, when you rotate xyz, this isNot symmetric because alpha is some constant. purely imaginative, OK, just nothing like this before. Like when Einstein wrote down his theory, et cetera, you can still trace-- there some clues, OK. But when Dirac-- this one just really-- [LAUGHTER] --like music, just came out from his mind, OK? It just-- and then he reasoned, OK,. OK, if this is constant which does not work, and then let's make alpha and beta to be matrices. Take them-- OK, so let's say they are n-by-n matrices, then in order for that equation to make sense, then psi has to be a n- component vector. They're just some constant Hermitian matrices. And then, so then he reasoned that for this equation, if we want this equation to be Lorentz covariant, then at least it should have the relativistic plane wave as its solution. If it does not even have that type of solution, then you, yeah, of course cannot be covariant. OK, so the minimal requirement-- so before we really try to see how can we make this into a covariant equation, we say let's consider minimal requirement. The Klein-Gordon equation has the following form. So when we square this star, we just act twice, so essentially, you have-- so you have partial partial t square psi equal to H square psi. OK, and then we try to make this of this Klein- Gordon form. If that works, then we're guaranteed to have a plane-wave solution of such a dispersion relation because this equation has such solutions. OK? So this will be satisfied-- can be satisfied if square of star, OK, satisfies reduced to the Klein-Graham equation. with that kind of dispersion relation. So now we just compare the both sides, so for this to be true, so we just need to have-- so let's compare the second-order derivative term. And then we need alpha i. So we need-- first, when i not equal to j, the off-diagonal terms, they all should vanish, OK, because here there's only diagonal terms. So that means that the alpha i alpha j plus alpha j alpha i should equal to 0. We said the alpha and the beta, they must be Hermitian, so that means that the alpha i dagger is equal to alpha i and thebeta dagger equal to beta. So if we satisfy all these four conditions, and then we will guarantee that that equation star should have the plane-wave solution. And so now you just try to find matrices, satisfy those conditions. OK, you actually find the infinite number of solutions. So you see that to satisfy them needs at least a 4-by-4 matrix, so n has to be 4. HONG LIU: Alpha and the grad, they don't act on the same space. So that derivative just acts on derivatives, and alpha acts on a different component of psi. AUDIENCE: Sorry, so when you have alpha times grad psi, is it-- do you act the grad on each element of psi and then multiply by alpha? Or do you-- like, what's the order of operations? HONG LIu: Oh, it doesn't matter because alpha is just some constant, right? means that psi should be a four- component vector. So alpha equal to 1, 2, 3, 4, OK, and we-- for the moment, let's just take the most general situation. HONG LIU: Yeah, alpha 1, alpha 2, alpha 3, they are all-- they are three matrices. No, alpha are just matrices, so this means that alpha 1 alpha 2 plus alpha 2alpha 1, as a matrix product, should give you zero. matrix. HONG LIU: Just, if you have alpha 1, alpha 2, alpha 3, each component is a matrix. OK, so this is a new object, so we call it spinor. Later we will see that this describes spin-half particles, so that's why we call them spinor, OK? So that'swhy I say this was really genius, because just nobody could have thought of this. OK? There was no clue of such a structure. HONG LIU: You can reduce always-- yeah, just from physical purpose, you can always reduce it to 4, yeah. If you know how to do the two halves, then you can generalize. It's just a convenient way to write these 4-by-4 matrices. Yeah, so one half, essentially, you could-- based on one half,. you could generalize it. Yeah. OK. Dr. Liu? HONG LIu: Yeah? AUDIENCE: So if we take n to be larger, then we describe all the spins? HONG LIU: So that I don't have to write all four components. I just-- yeah. AUDIENCE: Yeah, yeah, yeah. OK. HONG LIu: So I divided these 4-by-4 matrices into four 2- by-2 blocks, and then I specify each block. OK? Good? OK, so for later convenience, let's introduce a slightly different notation. OK, now we have this equation, so we have the form of this. you'd get an equation like this. OK. So now I will denote-- introduce a new notation so that it looks nicer. I'll denote the gamma 0 equal to i beta and then the gamma iequal to i times beta alpha i. OK, and then let's all pull it to the same side. Then this becomes the following equation, then the equation has the following form, gamma mu partial mu minus m psi equal to 0. And so I know this is annoying, but yeah, but this is just a fact of life. most simplest in terms of notation anyway, so that's the convention we use. Now let me just write it in the component form. I have gamma mu, which-- each of them is a matrix, alpha, beta, so alpha and beta, they're always run. OK, so this is a little bit intricate equation, but once you get used to it, it's not that difficult. Yes? AUDIENCE: There's no meaning to the upstairsness or downstairsness of alpha andbeta, right? HONG LIU: Yeah, because these two index are upstairs, yeah. not symmetric, so it's easier to put one upstairs, one downstairs. Yeah, these two indices are not symmetric. So yeah, it takes a little bit time to get used to it, OK, and I know some people develop psychological fears for fermions because you have to deal with those gamma matrices. For a long while, actually, I have this psychological fear myself. [LAUGHTER] When I look at fermion, I want to be away from it because I don't want toDeal with those Gamma Matrices. No summation over i here, OK, because each matrix gamma i square equal to 1. So you can write this more compactly as gamma mu gamma nu anticommutator equal to 2 eta mu nu. When mu equal to nu, when there is-- when they're both 0, then this gives you minus 1. And so this equation, when the later mathematicians, of course, studied this, a mathematician would say this is a beautiful object. So this object is called Clifford algebra. algebra. And so then any sets of gamma mu-- so gamma mu are a set of four matrices satisfying this equation. And then we can write down explicit solutions for those gammas, so that's two representations. So for example, for 1, you're corresponding to gamma 0 equal to minus i. So now this is minus i times a 2-by-2 matrix, OK. And the gamma i is equal to 0, minus sigma i, minus i s Sigma i, 0. HONG LIU: So this is a new space, and so that's called-- this is called spinor space, yeah. Yes? AUDIENCE: How do we know that-- are these the only two representations? HONG LIu: There are infinite number of them. We will talk about that. OK? Good? So now let me make some remarks. Yeah, so first, if you consider the case m equal to 0, and then this is, like, for massless, so when mequal to zero, then when you reduce to this Klein-Gordon equation. same story just here, you just forget about beta. OK, the same story, you forget the beta, and then you only need alpha i alpha j the commutator to be 0 for i not equal to j, essentially just that equation 1 there. And then also, you'd want the alpha i square equal to 1, OK, so for any i. So now these are the conditions for the alphas, and now you can actually satisfy by 2-by-2 matrices. they are all just complex. So this actually tells you that actually the massive particle have more degrees of freedom than the massless particle. And then the second thing is what Dirac essentially was-- Dirac's original motivation. So from Dirac equation, you can show you can derive a current. Just as you can do for the Schrodinger equation. You can derive an equation like this for some j mu and with j 0, with the 0-th component of this thing, positive definite. the meaning of all these different solutions for alpha and beta or for gammas, OK? So as I mentioned, you can have infinite number of solutions. What's the meaning of them? So first, let's imagine when we look at this equation-- so as I said, this is a matrix equation. In this matrix equation, then you have this psi which is a four- component vector. OK, so imagine, just say, consider making a basis change in psi. So now, so psi prime satisfies essentially the same equation but a different gamma matrix. because one is going to change the basis. OK. So you can show any matrices which satisfy that equation, they're all related by similarity transformation. They're just corresponding to a change of basis. So but different forms of the gamma, they may be useful for different purposes. For example, this I, solution I we wrote down before, it's convenient for if you want to take the nonrelativistic limit. And II is actually the most convenient form, the matrix to use. actually in the-- opposite regime, it's convenient for the ultrarelativistic regime. OK, so it depends on which regime, sometimes you use different gamma matrices. So now having introduced the Dirac equation and then the structure of theDirac equation, but still we haven't showed that the DirAC equation is covariant. So we, of course, won't have time to do that today, but let me just remind you how this Lorentz covariance works for the scalar case. Consider such a Lorentz transformation, OK, so and then phi transforms as following, phi prime x prime phiprime. New phi evaluated at the new position should be the same as phi evaluation at the old position. So the phi-- yeah, just equal to phi lambda minus 1 x. So now if you look at the Klein-Gordon equation, let's see how this is covariant, OK? OK, it's the same in any frame. to show, OK, so now we want to show that the Dirac equation has the same property, OK. OK, that's much more nontrivial. Again, it's really ingenious, ingenious, yeah, but we see, actually, it works.OK, so we will do it next time. Next time, we will show you how to do the same thing in a different way. We will do that in a few minutes. We are going to take a break. We're going to have a drink.

ROUGE-1: 52.98, ROUGE-2: 50.58, ROUGE-L: 48.85
BERTScore: 78.87

==============================================
==================== [56/100] ====================
Summary:
There's no age, education, profession, or even native-born citizenship requirement. Most presidents nominate individuals who broadly share their ideological view. So far, six justices have been foreign-born. At least one never graduated from high school, and another was only 32 years old when he joined the bench. For example, when President Eisenhower, a Republican, nominated Earl Warren for Chief Justice, Eisenhower expected him to make conservative decisions. Instead, he chose to appoint him to the Supreme Court. After the president interviews the candidate and makes a formal nomination announcement, the Senate leadership traditionally turns the nomination over to hearings. Depending on the contentiousness of the choice, that can stretch over many days. The Judiciary Committee votes to send the nomination to the full Senate with a positive or negative recommendation, often reflective of political leanings. Most rejections have happened when the Senate majority has been a different political party than the president. When the Senate does vote on the nomination, it usually takes 60 days. approve, it's by a simple majority vote, with ties broken by the vice president. With the Senate's consent, the president issues a written appointment, allowing the nominee to complete the final steps to take the constitutional and judicial oaths. In doing so, they solemnly swear to administer justice without respect to persons and do equal right to the poor and the rich. This job is for life, barring resignation, retirement, or removal from the court by impeachment. Of the 112 justices who have held the position, not one has yet been removed from office as a result of an impeachment. to be debated and dissected by the ultimate judges, time and history. To be debated, dissected and debated, we need to look to the past, present and future. We need to see how far we have come and what we can learn from the past. We also need to learn from our mistakes and learn from each other. We want to be the best we can be, and we want to do it in a way that honors the past and the present. We hope you will join us in this quest.

ROUGE-1: 64.37, ROUGE-2: 53.55, ROUGE-L: 52.83
BERTScore: 70.18

==============================================
==================== [57/100] ====================
Summary:
Jake Xia: This is the second time we are having this class. We had it last year in a smaller version. That was for six units of a credit, and we had it once a week. And mostly practitioners from the industry, from Morgan Stanley, talking about examples how math is applied in modern finance. And so we got some good response last year. So, with the support of the math department, we decided to expand this class to be 12 units of credit and have twice a week, as you know. WebEx.is has added math lectures focusing on linear algebra, probability to statistics, and some stochastic calculus. The purpose of this course is really to give you a sampling menu to see how mathematics is applied in modern finance. Last year when we finished the class, we had a few students coming to work in the industry. Some work at Morgan Stanley, some work at elsewhere. And so hopefully, this will give you enough information to decide this is a field you would like to pursue in your future career. really, to prepare you some basic background knowledge about the financial markets. Some terminologies will be used, which you may not have heard before. So before I get into the introduction, I always like to know who are actually in the classroom, so let me ask you a few questions. You just need to raise your hands so I know roughly what kind of background and where you are. So I would say 80% percent. How many graduate students are here, just to verify? Yep, that's about right, 20%. And how many students are in finance and business major? Just one. and the Sloan school here. So anyway, thanks for that. We will be doing a bit more polling along the way, mainly to get feedback of how you feel about the class. Last year we had it online, so if you feel the class is going too fast, or the math part is. going too slow or the finance part is a bit confusing, the easiest way is really just to send us. emails, which you will find from the class website. So Anyway, I will start today's lecture with a story, and a quiz at the end. Don't worry, it's not a real quiz. Just going to ask you some questions you can raise your hand and give your answer. my personal story. I want to tell you why I tell the story later. But the story actually was in the mid '90s. I just left Salomon Brothers -- that was my first financial industry job -- to go to Morgan Stanley in New York. So the first day, I sat down, I opened the trading book, I found something was missing. So, I turned around, I asked my desk quant. I said, where is the vega report? So, let me show you. Volatility is a measurement about a book or portfolio or position's sensitivity to volatility. At Morgan Stanley this is not called vega, it's called kappa. Kappa is actually a Greek letter. So the footnote about why it's kappa is on the same page as the explanation of what volatility is. That's all you need to know right now. I'm not going to ask you questions later. So, what is volatility? Which again, you will learn more in rigorous terms how it's defined in mathematics. called kappa at Morgan Stanley. Kappa is also called vega by some uneducated traders at the Salomon Brothers. They have mistaken vega as a Greek letter after gambling at Vegas. So obviously, I learned how to call kappa very quickly. And I called it kappa in the last 17 years, but you will hear people calling it vega. But anyway, so that's my first day atMorgan Stanley. But why did I tell you the story? What point I try to make? So this story is actually-- when you think about it, mathematical or quantitative finance is a rather new field. from mostly under-educated traders. Some of them typically joined the firms in the mail room and became trader later on. That's typical career path. And to nowadays, if you walk on the trading floor, you talk to the traders, most of them have advanced degrees. So what has changed over the last 20 or 30 years? I myself, personally, was probably one of the data point experiencing this change. And I certainly didn't expect I would be doing this when I was at MIT, but I did that in last 20 years. everything are changing very rapidly. Even nowadays, they're still changing. So with that, I will give you some background on how the financial markets actually started, and that's really the history part of this industry. In early days people need to exchange goods. Then it becomes centralized. There are stock exchanges, futures exchanges all over the world where these products will be listed as securities on these exchanges. That's one way of trading, which is centralized. Obviously, in the last 10, 15 years, now we have ECNs, electronic platforms. typically specialize in local products, local company stocks, local bonds, and local currencies. So again, what's in common? That's the question you need to ask. And the currencies, money itself, are also traded. And that's where different currencies issued by different countries. So, there are different products. How the stock get listed on the stock exchange? It goes through IPO-- Initial Public Offering process. And equity or stock is one form of trading. What are other forms? Loans. Actually, debt products are more generic than equity products. has money to lend out, someone needs to borrow money. Loan is really a private agreement between two counterparties or multiple counterparties. Commodities, actually, you know. Metal, energy, agriculture products are traded, mostly in the futures format. When you actually buying and sell, you build a warehouse to take them. You ship a tank to store above the ocean. And the real estate, you're buying and selling houses. And when you look at bonds, every government will issue large sovereign debt. Before 2008 financial crisis, large amount of CMBS-- basically, it's a commercial real estate backed securities, mortgage securities, and the residential, as well. And further of all of these, you heard probably a lot about the derivative products. So, that started with swaps, options. And the structure of the products, it become more tailor-made for either investors or borrowers to structure the products in a way to suit their needs. And some of the complexity of those structured products become quite high and the mathematics involved in pricing them and the risk management become rather challenging. After 1933 Glass-Steagall legislation, there were two main types of banks. Commercial bank is supposedly, you're taking deposits and lend out the money. Investment bank supposed to focus on the capital markets, raising capital, trading, and asset management. So that's how banks are organized. Outside banks, other players, basically, the asset managers, are obviously a very big force in the financial markets. So the really bank.type of player is really the investment bank. The investment bank is the player that is really bank-like. question a lot of people ask is, is this a zero sum game? I'm sure you've heard this many times. A lot of times, it depends on the specific products you trade, the market you're in. But why do we need financial markets? This comes back to what I described before. There's a need for it. It's really the need to bridge between the lenders and the borrowers. So, investors who have money need to have better yield or better return, better interest. Banks and so-called dealers play the role of market making. What is market making? So, when you or some end user wants to buy or sell, typically, if there's no market, you don't really find the match. And so the trade between lenders and the borrowers, is again, essentially the main driver of the financial markets. The dealers step in the middle, make you a price. Say, this stock, I make you price. $0.99, and that's my bid. brokers. So, brokers don't really take principal risks. Mutual funds, who actually manage public investors' money, typically in the long-only format. Insurance companies has large asset. They need to generate a return, generate cash flow to meet their liability needs. Pension funds, same thing. As inflation goes higher, they need to pay out more to the retirees, so where do you get the return? Sovereign wealth fund, similarly, endowment funds-- they all have this same situation, have capital and needs to deploy. are different types of strategies, which I will dive into a bit more. Hedge fund play the role in the market-- they basically find opportunities to profit from inefficient market positioning or pricing. And the private equity is different type of funds. They basically look to invest in companies and either take them private or invest in a private equity form to hopefully improve the company's profitability, and then catch up. And governments obviously have a huge impact on the market. So, to summarize the types of trading, the first type is really just hedging. have some exposure. Let's say you borrow money, you bought a house, so you have mortgage payments. Or your corporate has a large income coming from Europe. So, you have euros coming in, but you're not sure if euro would trade stronger to the US dollar in the future, or trade weaker. If you think it will be stronger, you just leave it. But if it will trade weaker, you may want to hedge it. And so that's the hedging type. The second type, as I mentioned, is a market maker. In the new regulation, obviously, proprietary trading is banned, right? And so the third type is really the proprietary trader, the risk taker. These are the hedge funds or some portfolio managers. They need to focus on generating return and control the risk. So, that's where the beta and alpha, the concept comes in. matched the S&P 500 index fund, R(b). That's a return of that index. So you can find a correlation between those two time series. say, this actually-- somehow it came out. It's supposed to be alpha and beta, but it turned out to be the letters. So, in a short description, beta is really-- just think as correlated move with the other asset. Alpha is really the difference in the return. You want to beat S&P 500, so you want to basically have certain tracking of this index, but you Want to return more on top of that. So let me just go in bit of details of how each type of trade actually occurs. So, you invest in the Australia Ozzie, Australian dollar. The Australian dollar may become weaker to the yen. You may lose all your profit, or even more. And further, if everybody plays the same game, then when you try to exit, you have the adverse impact of your trade. So, let's say you think that's the right time to do it, but then at one time, you wake up, you said, huh, I think too many people are doing this. I want to hedge myself. Even if you are not a finance guy, you work in a corporate, you just do you import, export, or building a factory, you have to know, actually, what the exposure is. Risk management, nowadays, becomes pretty widespread responsibility. It's not just the corporate treasury's responsibility. So, that's on the hedging side. If you're entering in a merger deal, and one company is buying another, you need to hedge your potential currency exposure and your interest rate exposure. stock, I think a lot of people know pretty much where it is. But if it's not transparent, so what do you do? So, if instead of asking you where Apple is, probably you're going to tell me $495 today. So you're probably less transparent. So that market maker comes in to provide that liquidity, and then takes the risk. They manage the book by balancing those Greeks, which I mentioned earlier. That's called delta. Gamma is really the change of the portfolio. Take the derivative to the delta, or to the underlying spot. "VaR" concept is also, obviously, a very important concept. And we talk about the volatility exposure was vega. And on top of that, what are the tail risks? What are the events that can actually get you into big trouble? So people use value at risk. Then capital. How much capital are you using? It becomes a veryimportant issue nowadays. And balance sheet. You have asset, you have liability. How do you leverage? How much leverage you have? Before the crisis, for example, lot of the banks leverage up 40 times. Trading is about finding relationships between prices, and trying to profit from those relationship mispricing. Not many people focus on arbitrage, because lot of people are gut traders. If you trade gold in the States, the gold price happen in Asia and in Europe matters, right, because you're trading the same thing. And that's just a simple example. But a spot price versus forward price, that's a deterministic relationship. It's a mathematical relationship. If that relationship breaks down, you can also profit. So there are many examples mathematical relationship which gives you the arbitrage opportunity. Math is very effective, because when you, your bank, your corporate, you want to buy some financial instruments, you have to know where is the price. So it goes through those fundamental analysis. And there are special situations. Some companies are going through particular difficulties, assets are priced very cheaply. So, there are firms out there -- you probably heard Bain Capital and many others -- where they focus on these private equity and special situation opportunities. So what have all of these to do with mathematics? Where does math come in? How do you use math? So, I want to give you some aspects of that. adjust to your assumptions to fit into the market. How do you price all these instruments? And when I say pricing, it's not in the narrow definition of just coming up with the price. When you build a pricing model, you also generate the risk parameters of these instruments, and how do you risk manage them. So math is very useful in risk management, which I will give you some -- not quiz -- questions after this slide. You can see that risk management itself is very challenging. It's not a purely mathematical question, but yet, math plays a very important role to quantify how much exposure you have. come back, you'll have more in your bank account. Obviously, that's not going to happen. The robotrader, a robotic trader, is a dream. It has its place or its use, but it's a fast evolving market. You have to constantly either upgrade your research and adjust your strategies. There's no such thing you can build and leave it alone. But I just want to mention that because maybe towards the end of the term you will feel, hmm, I came up with this brilliant trading strategy. I think it's going to make money forever. facing two choices, choice A and a choice B. Choice A being you have 80 chance to lose $500. You have 20% chance to win $500, right? That's choice A. Or choice B, you basically just lock in you have 100% chance of losing $280. Let me ask you, for whoever likes to choose choice A, please raise your hand. One, two, three, four. About six out of say, let's call it 50. So, can I ask you why you think choice A makes sense? When the stock goes up, makes bit of money, the natural tendency -- for especially someone is new to the market -- is to let's take profit. Trading is really all about how do you risk manage, have the discipline, and how to manage your losses. The natural tendency of a lot of people is, well, I think there's a 20% chance to come back, and I'm going to make $500 more. Why do I want to lock in to stop myself out at 280? So even if you have the Discipline to get out, that's great. though the expected value-- I think lot of people said, you lose expected value, which is $300 in choice A, but you would still not to choose choice B, because you don't want to lock in the $280 loss. So, that's really the common behavior, which mathematically may not make sense, but lot ofPeople still would like to do. And also, really, when you think about it, depends on your situation. And let's say, you think the market-- I'm giving you the stock example again. If you just think the fundamental picture has changed. You really don't think the stock should go up anymore. A lot of people don't really want to choose choice B, because they don't want to lock in the loss. The answer, I think it can go you either way, as you said. I mean, the last day of the class, hopefully we'll have much deeper discussion on this. It's not unique. I think we can talk a bit more along in the class. Yup. Well, let me just leave it here. Anyone want to give me a reason for choice B? AUDIENCE: Higher Sharpe. your bank account balance is-- let's say you are a freshman student. Your choice will be very different from someone has $100,000 in his bank account. And also, your risk tolerance, how much you can tolerate. I'm not going to give you say, this is right or wrong. But with that, let me move on and give you some homework. So, before I give you the homework, I want to make a few more comments. Do people always learn from their experiences? In science, we collect evidence, we build models. try to trade on those, how do you really build models? Is the market really efficient? What part is efficient? How do you apply those theories in your day-to-day risk management or trading activities? And sometimes, people tend to oversimplify. So learn the math, learn the finance first, but keep those questions along the way when you are learning during this class. So suggested homework, optional. Go to the course website, read what we have put up for the financial glossary. we got maybe-- how about this? We still got about 15 minutes or 12 minutes left, so I'll pass it to Vasily, then maybe we can leave five minutes for some questions. VASILY STRELA: [INAUDIBLE] mentioned that, Apple trades, that now it's $494.4 Yeah, just a couple of [INAudIBLE]. Well, first of all, no offense to people who were [INA UDIBLE], but I just wanted to give an example. every time. So, if you want to differentiate this functions and get a derivative, then this derivative will be quite noisy. And so, instead of getting the true derivative, you might obtain something quite different from true derivative just because there is a confidence interval around any point. So obviously, there is somewhere balance, and the question was, is there an optimal shift size to get the derivative? And that's what-- uh oh, the slide got corrupted. There was an answer. optimal size, that would be your numerical derivative of this blue function. While if you use an optimal shift size, which [INAUDIBLE] computed, it would be much smoother and much better. So, that's one of example, and that's what he did. And we actually are implementing it in our systems and plan to use it in practice. Another project was actually quite different. And it was about electronic trading and basically how to better predict prices of currencies and exchange rate. We put syllabus there, a short list of literature. We will be posting a lot of materials there. Probably most lectures will be published there. Jake's slides are there already. So, any questions? We like to get your emails so we can put you on the website for further announcements. But it's probably easier if you put your email on the sign up sheet, so that we can [INAUDIBLE]. VASILY STRELA: Yeah, but please visit and sign up here, because there will be announcements to the class.

ROUGE-1: 61.05, ROUGE-2: 58.73, ROUGE-L: 57.67
BERTScore: 69.21

==============================================
==================== [58/100] ====================
Summary:
Scientists are warning we are on course for devastating changes to our climate. Researchers are now starting to understand that it's also already affecting our mental health. In the UK one in four adults and one in 10 children experience mental illness. There's growing evidence that dealing with a changing climate is adding to that burden. The patterns of change in temperatures in particular are very Stark in 2022 we had the hottest year on record where daytime temperatures soed over 40° for the first time in history the past hour or so we've had the UK Met Office have the hottest day on record. Charles and a team of researchers set out to study how the extreme heat affected people's well-being over half of the the people they spoke to experienced negative impacts on their mental health due to the heat. A lot of this impacts could be linked to sleep disruption lack of sleep was one of the most commonly cited impacts they saw their parks and local grain areas totally dried out by the Heat. It triggered climate anxiety a lot of people manage their stress by going for a run or doing something outdoors and when you're able to do that the pressure just mounts and mounts. Clayton has interviewed numerous doctors and scientists who are looking at how the changing environment is affecting our minds brains and bodies. You don't even need to be alive to experience some of these effects a study of expecting mothers who experienced Hurricane Sandy in 2012 the huge storm that hit New York showed that in unborn children who did experience that storm girls as early as preschool were 20 times as likely to experience anxiety. Boys were 60 times more likely relative to those who had not been exposed to the storm in utero to express some kind of ADHD. Charles's research also saw the heat affecting men and women differently often due to societal factors such as traditional gender roles. People on Lower incomes and other disadvantaged groups groups were more likely to feel the negative effects of extreme heat because it was harder for them to keep their homes cool. People with more income have more resources to cope during the sorts of periods right this is true within a given City. It's true across countries around the world in the case of Hurricane Katrina for example the huge storm that struck new orans and in the United States in 2005 an academic study that looked at the experience of low income people. people in that storm showed that about half of these folks had some kind of post-traumatic stress and that's relative to 5% of the general population. Direct effects of climate change on people's mental health there's also knock on effects like loss of income and Rising prices which inevitably have implications for people's well-being. Although the impact of a changing climate on our mental health can be profound both Clayton and Charles's Rec search has shown that there are things you can do to support your wellbeing engaging with nature so spending more time in Green Space. people use that as a way to cope with stress so this is very beneficial social connection is a really big one as well. We are not separate from our environment we are connected not just to the world around us but of course to one another and it and it is only in working with one another that we're going to be able to move forward [Music]"It's a very exciting time for us. We're looking forward to it," says singer-songwriter. "It's going to give us a lot of energy. It's a really exciting time"

ROUGE-1: 72.36, ROUGE-2: 67.85, ROUGE-L: 68.92
BERTScore: 69.63

==============================================
==================== [59/100] ====================
Summary:
Adam Martin: How do you go from something you're interested in learning about an organism to actually identifying genes and mechanisms that are important for that? At the end, I'm going to tell you how you can try to figure out the genes and mechanism that are involved in determining the behavior of an organism. And on my title slide here, I have three fruit fly mutant phenotypes that you can see, and each of them is a different type of gene. And each one has a different effect on the behavior. of these mutants defined genes that were subsequently found to be present-- or homologous genes were present in humans and were shown to play important roles in human biology. So later on in the lecture, hall kind of explain what each of these phenotypes is. But first, I want to just highlight the importance of model organisms and their use in biology. You've been seeing them already. I've talked a bit about flies, we talked about Mendel's pea plants. I just now have a compendium of model organism that I'm going to throw up to tell you about. The roundworm, Caenorhabditis elegans, and the fruit fly, Drosophila melanogaster, are the heroes of today's lecture. The mouse is our lab mascot, but it's also an important genetic model. Human cell lines are important, but you have to understand that they're sort of an in-vitro system, and they're not functioning in the context of an entire organism. So it's really unethical for us to do a lot of different types of experiments on humans. Most of them are fairly small, and they're easy to house large numbers of them in a lab. They're often cheap to house in the lab and work with. Also, they develop fast. And maybe most importantly is the fact that we are related to each of these model organisms through evolution because we all arose from a common ancestor. The rate-limiting step in genetics research is the time it takes from the conception of an organism to the time that that organism can reproduce sexually. the human-disease causing genes have a homologous gene in the fruit fly. So we're similar to these model organisms, such as the fruitFly, in particular, genes that are important for understanding human disease. So genetics really plays a fundamental role in biology and the discovery of new biological mechanisms. And I'm going to take you through a type of approach that's called a "forward genetic screen." And I'll get to the orchestra in just a minute, but I briefly just want to define what a forward genetic screen is. are involved in a specific process, but you want to identify them. So in a forward genetic screen, you don't know the genes and mechanisms involved. So you have to, then, infer what a possible phenotype would look like if you broke genes that were involved in that process. So the mantra of geneticists is that we are going to break genes and then look at the result and see if it gives the phenotype we're interested in. In this case, we're looking for a phenotype that you would expect if you affected a certain process, if you disrupt a process. regulator of this orchestra, if you will? And so conceptually, what a genetic screen would involve is taking hundreds, maybe thousands, of orchestras like this one, and just shooting an individual in this orchestra. So then the logic of Drosophila genetics, you would then name that gene uncoordinated and infer that that gene has some important role in coordinating the different sections of the orchestra. And rather than taking a gun and shooting members of the Orchestra, in genetics,you try to identify mutations. induce mutations. So we're looking for mutations. And these mutations could be spontaneous mutations, meaning you didn't do anything to induce it, but they just appear as a variant in the population. In the way we can induce mutations is by using some type of mutagen. For example, you could have some sort of chemical mutagen that increases the error rate in DNA replication. Or you could use radiation to induce DNA damage, and that essentially accelerates the frequency of mutations that occur in the genome of an organism. In model organisms, we can actually find these types of mutations. There's a specific class of mutant that was called "wingless"-- where the flies have fewer than two wings. This particular mutant defines an entire signaling pathway, which is important in stem-cell biology and is also over activated in cancer. But obviously, we don't have wings, so this gene didn't get discovered in humans. It was discovered in flies, and then only later on, it was inferred-- or it was discovered that there was a gene for wingless. is a related gene in humans. One of the other phenotypes I showed you is called "notch" Normally, a fly wing has a nice, smooth margin. notch mutants have wings that have this chunk taken out of them at the end. But again, there's a human notch, and human notch is involved in human diseases, such as cancer.. How can you have a concerted effort to identify genes that have that function in a given process? I'm going to tell you about work done by Eric Wieschaus and Christiane Nusslein-Volhard. treated the males with a mutagen to induce mutations in the gametes these male flies would then be passed to subsequent generations. And they mated the mutagenized males to females, and then they went on to look at-- to isolate individual F1 progeny. To see random mutations, you have to take individual flies. Now, are you're going to see a phenotype in this F1 generation? So Miles-- is it the Malik or Miles? Sorry. ADAM MARTIN: Miles. can get an F2-- multiple F2 males and females that will have the same mutated chromosome. From each of these lines, you're going to cross siblings to each other. So you're doing a sibling-cross. What fraction of the progeny for each of those sibling crosses should be homozygous for the mutant chromosome? Yes, Steven. ADAM MARTIN: One-fourth, exactly right. So Steven's exactly. So now, you have males and female. And now you can look an F3. right. A quarter of the progeny should get two copies of the mutated chromosome. So 25% should be homozygous recessive. And so you can screen this F3 progeny for each of these independent lines, and look for flies at some stage of development that are defective in patterning. It turns out all of the mutations they're interested in are lethal, so they have to look at the larval stages for ones that have a defect inpatterning. So this is what a screen looks like. Drosophila larvae looks like. And you can see it has a segmental pattern here. But you see there are these segments that alternate between smooth cuticle and hairy cuticle. And because there's a lot of hairlike projections here, it reminded the researchers of a hedgehog, and so this mutant became known as "hedgehog" And the hedgehog gene was the founding member of an entire signaling pathway. That plays important roles in human development and also, human cancer. the sonic-hedgehog gene is important in cancer. And actually, there are now a number of drugs that are being developed to target the hedgehog pathway. One was approved back in 2012 for use in treating basal-cell carcinoma. There's currently another drug that's in phase-II clinical trials for treating some forms of leukemia. So this is a story that goes from identifying this weird fly mutant all the way to clinical trials, developing drugs, whose purpose is to inhibit this signaling pathway. whether or not a cell lives or dies during development. One fate that Horvitz, Sulston, and Brenner saw is that sometimes, cells-- their fate was to just die. And this was defined as "programmed cell death" because it followed a very stereotypic pattern. This also is called "apoptosis" So what really enabled this work is the biology of C. elegans. And, here, I'm showing you C.  elegans zygote. This cell divides into two cells that are different. is called AB, one is called P1. And we know exactly what the fates for the descendants of both these cells are based on the work of Sulston, Brenner, and Horvitz. Every worm has these 947 cells. That's showing you what happens to every single cell in the development of C. elegans. They know when every cell divides and what the daughter cells of that division will turn into. In other words, they know the entire lineage of this animal. Robert Horvitz's lab identified a pathway of genes that were involved in cell death. The cell-death process starts with a live cell. That live cell dies such that you then have a dead cell. After the cell dies, the remnants of that dead cell are engulfed by neighboring cells. This is the last step in this process is engulfment. And this gene is called ced-1. There's the first cell- death mutant that was identified. "Ced" stands for "Cell Death abnormal" so C-E-D is short for "ced" CNN's John Sutter shows how scientists screen for mutations that affect cell death in worms. Worms are hermaphrodites, meaning they are both male and female sex organs. When a worm self-crosses, a quarter of the progeny will be homozygous recessive for the mutation. Sutter: Is this necessarily a mutant that's involved in cell death? Can you think of an alternative explanation for why you're seeing this behavior in the worm? The answer is yes, of course. would lose these sort of bubble-like structures? What else could be happening? When you do a screen like this, and when you do science in general, you have to think through all the different types of possibilities. So one scenario here is you could have some type of revertant, or you couldhave a suppressor mutation. Maybe you have a mutation that bypasses the function of ced-1 such that now, the cells can engulf the dead cell. Or the alternative scenario, the one that we want, is that we've affected the cell-death process and identified something that is a bona-fide cell- death mutant. if this is a bona-fide cell-death mutant, then you should have extra cells. And it turns out the ced-3 mutant blocks all 131 of these cell deaths. So there's an active mechanism involved in the cell death. Any questions about how these screens go in the crosses before I move on? OK, so I have one more story to tell you about, and this relates to behavior. We all behave, some of us better than others. So how is it we can go from something as abstract as behavior to specific genes and mechanisms that control? Adam Martin: circadian rhythm is a behavior. We are awake during certain parts of the day and are asleep at night. If you're hidden from the light-dark cycle, you continue this cycle for some amount of time. Martin: There's something intrinsic in our system such that we want to exist on this 24-hour wake-sleep cycle. He says a genetic screen can identify genes that are important for circadian rhythm. The Nobel Prize-winning work was done by Konopka and Benzer. you need an X chromosome and you can't have three X chromosomes. But your females are all attached XY. So the females actually get their X chromosomes from their mom, which is the opposite of the way it normally works. And males getting their X chromosome from dad because the attached X strain has a Y chromosome. So it's a little bit of a genetic trick that, in this case, served the researchers a generation on their screen. But to establish a line of flies that have this mutation, they then took these. F1 mutated males, and crossed them, again, to attached X flies. So now, you have multiple males, all of which are mutant. The mutants that the Benzer Lab identified had altered period of the sleep-wake cycle, and therefore, the gene was named "period" So this screen identified a gene called "period." This is a gene. And the gene in humans is associated with familial advanced sleep-phase syndrome. So defects in the genes that were identified in Drosophila are relevant to human sleep disorders.

ROUGE-1: 51.90, ROUGE-2: 49.32, ROUGE-L: 48.31
BERTScore: 72.71

==============================================
==================== [60/100] ====================
Summary:
In this chapter we will discuss two applications, one price control and second taxation, so right. Sir, does this slope of this graph denote anything price demand upon, some price upon some quantity. So, wait little later we will talk about that that topic, right now we are not, we are just talking about movement and shifts. We are not talking about the slope. Slope is also very important very good question but little later, we you have to wait little bit to get the idea. Government can come up with a regulation to fix price ceiling or price floor. Price ceiling is maximum price for a unit of good established by law or by government and similarly price floor is the minimum price. So, price floor typically is minimum support price. What happens typically, let me also add government does not only say in the case of price floor that this is theminimum price. One ways is that government says that because there is a law that you cannot buy or sell the product. Now there are two possibilities that above this particular price or below this specific price. says you cannot you know this is the price below which you cannot buy yourself. If government says that the minimum support price is less than the market equilibrium price what would happen. Excess supply it means there will be a downward pressure. sellers On the sellers to decrease their price of per unit of good, but if government wants to support them then what does the government say. That you bring the goods. It will buy by itself. We will buy it at this particular price. So, what government does that it artificially jacks up the demand in a way that we will buy. devote their resources to produce wheat. So, supply of wheat would increase even further it may increase further. This may be a result of price, that the price floor. Where do we get the price ceiling typically? Petrol or even in the rents. Maximum rent that you can charge is given by the government. You cannot increase the rent beyond a particular level, you can't increase it beyond that level. Nothing will change if that level is above the market equilibrium price. We get excess demand and when we have excess demand what happens there. pressure. There is an upward pressure, but by law sellers cannot increase the rent or buyers cannot pay more. So, then what do we observe in the market. Role of government. Black marketing. Black market you know under the table payment. What we observe is something I can call non-market. Rationing mechanism. For example, petrol the people would like to buy more, but very little amount of petrol is available relatively less amount of gasoline is available at that particular price. This is in a way, it is a non market rationing mechanism you have to wait little longer. illegal you know it is not illegal but just because there are so many people who would love to buy a good at that particular price, but there are not enough supply. Another example is that you have to pay pagadi. Right now that pagadi is something that security deposit that land the house owner or the apartment owners they take from the person who would like to rent their house. But you can think it is kind of a non-market rationing mechanism that they cannot, that the landowner or the house owners cannot charge the market equilibrium price. In Bombay you pay almost the price of apartment as security money, sometimes more than that. So, it is non market rationing mechanism. Now, we can also think about the black market, the rise of black market or in other words illegal trade at prohibited prices. This is not the blackmarket, but this is one kind of blackmarket. Sir, actually the pagadi system. Ha. Like you said some security. So,. sir is it taken thinking that we would earn interest on that caution money and the prices would be rising on its own, you compensate the No see. drop in price. Yes, sir we do have agents like who supply. I am not trying to say that they do they provide us they of course, provide us a service. The idea here is not to defend them, but to explain why it is happening and then what we have is some kind of tie-in deals. Then tie in deals is many people would like to have gas connection. And that is also quite common. You are not interested in buying gas burner at really at the price which is much higher. than the price that you will you have to pay in the market for a gas burner. So, this is the tie in deals, it is not that you are buying the gas burner here. Similarly, when you go for apartments in Bombay, the apartment owner may say rent is this much. You have to take the furniture that I have put in the house, you also have to rent the refrigerator. These are tie-in deals that is what you get. I am not defending their position that they do a right or legal thing. Let us look at what happens when we have a price floor. Of course, you will have excess supply and also you'll have non-market rationing. Can you give me one example of non- market rationing mechanism in case of excess supply of wheat because of price floor? Sir, like the payment is not done at the time of buy, it is done after year or after few months. That can be one, again it is very difficult to discern it because of some other reason. And one more thing we have to pay a minimum wage to the laborers. That is stretching too far. very very, they wait long period to sell their product or when they go to the government unit to sale their product there is a long queue. So, long waiting period is there for offloading their products. What else, illegal market; you will have to pay bribe, illegal trade instead of writing market illegal trade to offload your wheat at government units. All these things happen whenever we have price control. It is to incentivize the production for a few like for wheat or if we talk if there's a new production of potato and if we put price floor on potato, it will incentivize it. We do not have a proper distribution to.production and they can serve the market better. So, what we are doing basically is that we are buying at the minimum support price and leaving grains to rot in open, in absence of proper distribution system. But even when we have proper distribution, why cannot government buy these the items that government needs to provide to poor at the market price and give it to poorest, just a point that you should ponder. But I am saying definitely that there are definitely better ways to cater to the welfare of public.

ROUGE-1: 54.37, ROUGE-2: 51.96, ROUGE-L: 51.66
BERTScore: 76.50

==============================================
==================== [61/100] ====================
Summary:
In order to make proteins like hemoglobin and antibodies-- these are made up of amino acids-- we need large entities. And so the things that will feature today are the transfer RNAs and the ribosome. And I want you to look at the size of this molecular machine. This is we're getting pretty large now. We're needing to use large machines to make the smaller catalysts that are essential to making proteins and other molecules that we use every day. And we are going here now from the smallest carbon atom. The ribosome organelle is a large entity in the cell. And, when you do look at electron micrographs of cells, you can see these dark dots, which represent ribosomes. They're big enough to see, whereas the proteins themselves are not. So that's what you're destined for today. The structure of the mature messenger RNA just for a minute because, in the last class, we talked about a lot of manipulations of that pre-messenger RNA. And now I just want to remind you that the messenger RNA is the fresh thing out of transcription. messenger is single-stranded RNA, obviously. It has a 5 prime cap, which has got this funky 5 prime, 5 prime bridge that's resistant to exonucleases. Somewhere in that sequence is a start codon. It's something that says this is the bit I want to translate. Often, there's a lot of stuff here that you don't translate. And there are many features in this part of the sequence that are very important for translation. They contribute to the efficiency of translation. time to stop and finish translating. The other end the message has a poly-adenine tail. Remember that, once again, is structural to protect the ends of that transcript. Even if some of the hundreds of adenine nucleotides are nibbled off, you don't get into the part of the gene that's critical to be translated. At a certain stage, though, you might get in. And they may end up chewing up your transcript, but that probably suggests that the messenger has been around too long, and it's time for it to retire to a better life. There are a couple of other amino acids that might be designated as the so-called 21st, 22nd amino acid. We have selenocysteine in just very, very few proteins. There are other organisms, for example, in archaea, these guys who hang out in bubbling hot pots in Yellowstone. This is the ones you really need to think about are the ones we're encoding in the global genetic code. It's something beyond the list of 20 that you saw. ones that are common to everybody, all right? So, obviously, when you look at the language of bases, one base-- if the language translated directly one base to one amino acid, we could only encode for amino acids. So it's finally deduced that three bases encoded each amino acid. That would give us 64 possible words in the language that needs to be translated. That's a lot more than we need. We only need 20 for the encoded amino acids, so 64 possibilities. We need a few more things anyway. Once the structure of double-stranded DNA was deduced, everyone was moving on to trying to understand how that converted to the translation to proteins. Crick and Brenner realized it was three bases to code for one amino acid, but Khorana, Nirenberg, and Holley defined that genetic code and got all of the details. So that's the work thatKhorana and others did. And that was awarded them a Nobel Prize for that work. And then, later on, things started to get-- you know, these are decades of work I want to point out to you. decade later, the sort of details of the structure, but not the structure itself. And it was really exciting in the 2000s when Ramakrishnan, Steitz, and Yonath solved the structure of the prokaryotic ribosome. So each of these things has taken a decade to happen, but they are fundamental, major, important things that we can act on and move forward to understand more. All right, so let's move to the transfer RNAs. And I've flashed up this slide a couple of times, but I actually now have the movie of theructure of a transfer RNA. The ribosome is a large structure, but don't mistake it for being something that's just sort of amino acid and anticodon. One of the loops has a special name. It comprises three nucleotides that are complementary to the nucleotide in your messenger sequence. So this really is a decoder because, at one end, it's carrying an amino acid, but it'scarrying the amino acid that corresponds to the code that's in the messenger via that anticodon loop. A lot goes on with the rest of the structure. It's a very important structure in the mechanisms of protein translation and synthesis. And, coming down to the anticodon loop, you're going to read the messenger 5 prime to 3 prime. And so, if you look up here at the acceptor stem, the amino acid is joined by an ester bond to the 3 prime end of the transfer RNA, but, hopefully, you can see in here. There's the carboxyl. And CHR designates the aminoacid where R would be the side chain of your amino acid. the symbol for it that you've picked out. And it's a base known as pseudouridine. It turns out that these unusual bases show up in RNA sequences. Pseudouridine has an interesting structure where the bond to the ribose ring is not a carbon-nitrogen bond, but, rather, a Carbon-carbon bond. So, in RNA, there's some of these other unusual bases. And pseudouridine is the most common of the unusual ones. It can still hydrogen bond. But it tends to show up. in these sort of different loops and turn-type places. We're starting to understand the tRNAs. What we need to move on to now is really taking a look at the genetic code. This is the absolute-- the sort of Rosetta Stone for translating messenger RNA to amino acid sequence using codons. So this sort of-- whoa. Getting a little-- I love translation. I'm getting a little bit excited about translation. OK, so there are a few features of this genetic code that are very important. Number one, you won't have to remember it. is how we designate the triplet of nucleotides. So the way you read this table is you read the first letter. And then, within each block, there are the four alternatives for the other four bases. So you can read, for each amino acid, what three-letter codon would correspond to it. Some people quite like this other rendition where the first of the three letters is in the center. So it's either G, U, A, or C. Then the second one comes out. It's in the brown circle. well get used to that particular table. Now there's a couple of characteristics in the table. The first thing to notice is that, within that table, there is a codon to start. And it's AUG. And the one thing that's sort of sent to drive you crazy is that AUG codon equals start, but it also equals methionine. Methionine is fairly rare. There may only be one or two more in the protein. And I hate the illogic of that, but, nevertheless, it is the case. stop codons. The stop codons tend to be used variously. Some are more predominant in some organisms than other. And some of them respond differently when the process of stopping occurs. The next important thing to notice about the genetic code is that it's what's called degenerate. What this means is there are all, for several amino acids, more than one codon that specify it. It's at its most extreme with residues such as leucine where there are six codons that specify leucines. The genetic code is the code that's going to be embedded within the messenger RNA. When you're looking to read what your amino acids that get put in may be, you're going to look at the codon. And it will tell you exactly the amino acid. So, whenever you see a particular three-letter code on the messenger, you will then be able to know what amino acid it would code. The codon and the anticodon are antiparallel. And so what I want to do is, basically, you would be reading from the 5 prime to the 3 prime end. cartoon form. And, to attach an amino acid to the 3 prime end of the transfer RNA, you have an amino Acid residue. And what we do is we need adenosine triphosphate to activate this chemistry. And then the OH at the 3prime end reacts with the amino acid. So you attach through an ester to the amino Acid from the 3Prime end of these transfer RNA. That's what's done. The ATP makes this chemistry feasible, but there's one more player here. synthetases for different amino acids that show you that there's a recognition not just for the amino acid that's being loaded, but, rather, for the entire transfer RNA. So some of these look quite different. The isoleucine one interacts in one way. The valine one is a little different. And the glutamine one is different again. So they vary in the way they interact with the transfer RNAs. That's how you get the specificity. Does that address your question from earlier? Hello? small and large subunits. And I've shown them there in two different colors. The prokaryotic ribosomes are pretty different from the eukaryotic ones. The small subunit would have a 30S sedimentation coefficient. It's how fast its sediments in an ultra centrifuge. And the large subunit, the 50S, correspond to a certain number of daltons. And, when you start to bring all the pieces together, what we can see on this slide is the messenger, the transfer. RNAs, and the ribosomal all to scale in such a way that it can really explain it. So what I show you here is the small and large subunit. In orange-- well, that's kind of a burnt orange-- is a sneaky little bit of the messenger. In yellow are the transfer RNAs. And there's one more unit on here that I won't describe too much. It's a protein factor that helps all the processes occur. Generally, it's thought to help the loaded tRNA come to theribosome, get it in place, and then go away. Methionine is the first amino acid. And it's always at the N-terminus. Then there's another amino acid comes in. And then the next thing that happens is there's a movement such that a new bond gets. formed between the methionine and the phenylalanine. And that new bond is an amide bond. It's not any of the others. So you're literally intercepting this complex on the transfer RNA with the amine of a new amino acid, and that's how that comes together. amino acid to come in, and translation finishes and releases the protein in its complete form. Now the reason I want to differentiate between the release factor and an RNA that has the complementary stop codon is because the RNAs that are known as the suppressor RNAs have now been completely hijacked to make an enhanced genetic code. This occurs at about a rate of 20 amino acids per second, meaning you're reading about 60 bases per second. That's far faster than the rate of replication. a protein, you will see that ribosomes line up on the messenger RNA. And you'll have many proteins being made at once and at different stages in the game. So, when proteins are made on the ribosome, they have a bit of a choice. They can get made and fold beautifully into active proteins. Occasionally, proteins misfold. Maybe the rate of synthesis is too fast, or the environment isn't right. So there will need to be mechanisms whereby proteins get degraded if they're not folded properly. Proteins are starting to fold almost immediately from that N-terminus to, ultimately, attain their compact shape. The editing at that stage, by the way, to fix errors is editing when you've loaded the wrong amino acid onto a tRNA. When we have here-- and, on all these slides, I'm going to show you the double-stranded DNA. And they're all lined up so you can follow them really nicely, always always, always. But that's the story for another day. writing 5 prime to 3 prime, except when we have double-stranded because we have to put the bottom strand in a different order. So this would be a situation where you have a wild-type enzyme. Everything is transcribed and translated properly. Occasionally, though, there are errors that will introduce defects into the ultimate protein. The first type of error is a nonsense mutation, which might be leaving out a base pair, inserting one, substituting one. And this would, ultimately, cause An error in the DNA that causes an error in messenger RNA. A frame-shift mutation introduces a nonsense mutation and puts a stop codon into your RNA. The next types of mistakes are what are called silent mutations. It doesn't matter, for example, if you made an error. in DNA, which ended up with anerror in the messenger RNA, if. you still code the same amino acid, right? I go to the genetic code. I'm like, oh, oh. Mutations that cause errors in DNA that result in errors in proteins that may cause genetically inherited diseases. Here it's a missense mutation where we've got an error in the DNA. And then the last one I want to show you is a non-conservative mutation that causes a serious defect. And this takes you back to the beginning of the class. And I just want to remind you of the situation in hemoglobin when we've changed a glycine to an arginine. And that's a big change. we had a missense mutation, and we incorporated a valine instead of a glutamic acid, just through one change in the DNA. The missense mutations are the more serious ones because you end up with a full length protein that might have a mistake in it. And then that would affect the function. Am I being clear enough to everyone? Yeah? Good. OK, I am going to tell you that I'm handing over the baton to my colleague, Professor Martin. He'll take over on Monday. He's pretty excited about genetics. "I think this field is fascinating. Once you get used to the mechanics of it, it's really cool to think of how you go from DNA to RNA to folded proteins," he says. "Don't forget my office hours on Monday if you need them," he adds. "I'll be in the lab all day, every day, if you want to talk to me about it." "I've got a lot of questions for you," she says, "but I'll be happy to answer them."

ROUGE-1: 54.17, ROUGE-2: 51.75, ROUGE-L: 51.17
BERTScore: 71.40

==============================================
==================== [62/100] ====================
Summary:
Professor Donald Kagan: We have been looking at the question of the rise of the polis. He says the concepts and the kind of characteristics I've been describing appear to spread all over the place. One of the ways in which we can date the pol is has to do with the Greek traditions about the establishment of colonies throughout the Mediterranean, he says. Kagan says the idea of the farmer hoplite citizen is a critical element in shaping a polis and for my money that's what the poli is about to start with. are a clue is because every time we see a colony, learn anything at all about it, it appears to exist in the form of a polis. So, that's the chronological significance of it. I should say all of these dates that I will be giving you are some combination of Greek tradition--and the Greeks dated these colonies very specifically. But you shouldn't take the date that I give you, the traditional date, as being firm. It's a general thing; it's around that time is the best we can really say. Greece is again that date we keep talking about, 750 roughly. But in fact, the earliest date according to Greek tradition, if my memory is correct, was something like 773. The Greeks thought the earliest colony they ever established -- a place that they called Pithaecusa, which is the island of Ischia in the Bay of Naples. There's no question that there was a Greek colony there and as I say the archaeological remains confirm the general time for this happening. the natural thing to do given the character of life, which was based upon farming, if you leave you lose your farm, and based upon the difficulty of transportation. The Greeks were, even though they went to sea plenty, they were terrified of the sea for very good reason. Their ships, their boats were not very seaworthy; storms come up in the Mediterranean very suddenly and terribly; you take your life in your hands when you travel. So, what I'm saying is, when you leave the place you were born, you leave your ancestors as well. south Italians in the late nineteenth century and come--well, go all over the world actually, to South America, Australia, but the largest numbers to the United States. Why did they do that? Well, we don't have to do a lot of guessing. We have written evidence from the people who went and they say why they did it. One answer, and it's the one that is most widely believed among Greek scholars, is that the growth of population that we have mentioned in connection with the rise of the polis. four, how do you provide for the extra two? Well, sometimes you divide up the land equally, but if that land continues to get smaller and smaller, it will not sustain an additional person, not to mention additional family. So that clearly is a problem and the notion that land hunger is a key explanation, I think, is supported by the fact that wherever we find a polis, whatever other characteristics it has, and they vary, some of them are located at wonderful places on the sea. place for trade. They would have had to be damn fools to have settled there without that being in their minds. Some of the places where they settled leave us puzzled, and have left the ancients puzzled. One of my favorite examples is the colony on the south shore of the Bosporus, which is called Chalcedon. It's right opposite Constantinople--that doesn't exist, Istanbul. Winston Churchill never, never conceded that it was Istanbul; he called it Constantinople till the day he died. In any group of people there is a small minority, I want to emphasize small, who just love to do risky things. They just love adventure; they're never happy if they're safe, and so off they go seeking adventure and seeking to make a fortune however they're going to do it. So, for these reasons and probably for hundred of years, they've been colonizing. And now that we do have something, namely, this wave of colonization, they join that as well. Colony is a Latin word ultimately for colonia and the Roman colonies were, first of all, garrisons that they planted in land they had conquered to keep the people quiet. The Greek word for this is, apoikia, and most literally it would mean a home away, an away home and that's what they're making. They are establishing for themselves a household, a home someplace away from where they started. That's the name. And then later in history, in Roman history, that was the name given to establishments, rural establishments, when the civilization was breaking down. on those rural places really were not free men. They were the antecedents of the Serfs, which we will see later on in medieval history in Europe. So, when you see the word colonia in late Roman history, it's talking about something very, very different from what we're talking about. Remember that these are apoikiai from the Greek point of view. Somebody in one of the old Greek cities has to decide that he wants to go out and establish a colony. of eminence, and yet unlikely to be part of the sort of dominant faction in that city, because otherwise why would they leave? Anyway, the Greeks had a name for this individual. He was called an oikistes; he is the found of the colony. So, now he has decided to do it and he's gained recognition from the town council, let's say, and he can go forward. Now, he has to have an idea. He can't just say, I think I'd like to found a colony. What is more typical is that he thinks, I would like to take and have found a colonies on the southeastern coast of Sicily. Delphi is halfway up Mount Parnassus and it was thought by the Greeks to be the omphalos, the navel of the universe, the center in every way. There the god Apollo had established an oracle. Gases would escape through this gap in the earth and there were priests who worshipped Apollo there. They would place a young woman there who would sit as these gases came up and she would after a while begin to speak in tongues, which is to say she would rattle off a lot of language which nobody could understand. or so it sounded, or Greek but making no sense to anybody, and then the priest would listen to this stuff and he would say, what Apollo said through the priestess here is. Well, archaeologists investigated this carefully, and the French School of Archaeology late in the nineteenth century dug everything up and concluded this was baloney; it was a myth. There were no gases coming up from any of this stuff, and so everybody believed for the next century. John Hale of the Yale Class of 1973, who is now an archaeologist at the University of Louisville. learned, or having agreed, let's say, with my prejudice, that the higher naiveté must reign. And so he decided to investigate this and he took with him a fine geologist from Wesleyan just to go to the place there at Delphi. They discovered evidence that, in my judgment, but I don't think really anybody doubts it anymore, that totally confirmed the Greek story. They tell you precisely what the gases were, what the characteristics of those gases were. It squared beautifully with all details that we heard about the Delphic Oracle. King Croesus of Lydia, the richest man in the world, decides it would be a nice thing to conquer the Persian Empire, his neighbor to the east. So, he goes to--he's a barbarian, but the barbarians came to the Delphic Oracle too, because you want to know what the gods want. He said, "If I cross the Halys River, that's the boundary between Lydia and Persia, what will happen?" The oracle replied, "A great empire will be destroyed" lot of money to consult the oracle. Most of the things they asked were questions that really had a yes or no answer. According to my thinking, there's no way they could have been wrong very much. These people knew more than anybody else about these things, and so consulting that oracle was a very rational act indeed. "I'm suggesting to you is that this was the best information gathering and storing device that existed in the Mediterranean world," he says. 'I'm not going to do the words that they would have come up with' will decide whether it's a good idea for him or not. Recruiting is tremendously important because you need to have a certain number of settlers to make the settlement viable. So however many that is, that is what you try to recruit and you recruit typically at a time when it's easy to get people together so you can tell them the story. There are festivals held in each city just for its own citizens and my guess is that when you could do that, when you felt that you could recruit a full colony from your fellow citizens in Corinth, let us say, that's what you did. were not enough Corinthians who were ready to go with you on your expedition. So, you would try to take your message to one of the Pan-Hellenic festivals which were getting organized about this time. That would be a place where Greeks from all over might come and you could then try to recruit settlers for your new colony. So now you have everything in place, you've recruited your settlement, you get on your ships and sail, in this case out to the west central Mediterranean, you find your way to Sicily, work your way into the harbor at Syracuse and things work out. Syracuse is an independent polis, autonomous, self-governing, whatever regime it wants, etc. It is not a subject of anybody, not Corinth or anybody else. The most typical, the usual, everything else is an exception is that there are friendly relations between the mother city and the apoikia. But keep in mind that they are always independent, and an example is in the Peloponnesian War. The question really is, what kind of relations did they have? I would say there are three categories that they fall into. The city of Corinth sent out a lot of colonies, which is why we know something about their arrangements. From where we sit, it looks like the Corinthians were making a gesture of friendship, of solidarity, the kind of thing you would expect a mother city to do, not to ignore its apoikia when it was in trouble. So that's all that they did. Corinth really had a very great deal to say about what was going on in the Peloponnesian War. Potidaea. got into trouble with Athens, and found itself besieged, Corinth sent a real army to go in there and fight, and I think that's because of this very special relationship that they had. At the other end of the spectrum it's again Corinth and they have a colony up in the northwest called Corcyra, it is the modern Island of Corfu. The first relationship between them is a navel battle, and thereafter we hear of them quarrelling and fighting with each other just about at least once a century. more time, that the overwhelming normal situation is the first one I described, friendly relations. These guys that have gone out, let us say to Syracuse, they are your people, they have relatives back home. They have friends back home, it is natural--oh by the way, they're accustomed to worship the gods in the same way that the Corinthians do. We do know, again, Thucydides is our source, that it was customary for colonies to send representatives back to the mother city for the religious observations that were common to them all. shop, but you can't get now, so you would want to buy what the Corinthians sell. Guess what? You've got great grain fields out there in Syracuse. Hard to believe today, but Sicily was one of the major granaries of the Mediterranean world at that time. Corinth always needs that kind of stuff, so we sell you our wheat, you sell us your pottery. You sell good wine that we can't grow yet and maybe never will be able to grow in our neighborhood. So you can see why it would be very natural for all sorts of ties to unite these colony and mother city. Kagan: Nobody was compelled to do anything. The British practicing mercantilism passed navigation acts, saying what ships could carry what and so on--nothing like that in the Greek world. Everybody--all of this is voluntary on both sides of every agreement. Okay, now where are these colonies? Let me give you a little run down. Before we get to that, I should say that the Greeks have already, before this period of the period, had colonies. In the back, yeah? Student: What extent was the primitive form of [inaudible]Professor Donald Kagan: Primitive form of what? By the tenth century B.C., we see Greek cities lining the coast of Asia Minor on the west, and even around on the bottom and to some degree on the north, and on the islands in the Aegean. So, there has been a Greek--what's the word I want? There is an expansion of the Greek world already by the 10th century. I might point out that the way the Greeks did their immigration into Asia Minor had a pattern so that you can go from north to south and you will find some consistency. The Black Sea is not a Greek lake, but there are Greek cities that are spotted along the coast. When the mythical mission of Jason and his Argonauts go sailing out to that territory, he is out there in Tarzan country. As far as the Greeks were concerned, it was just the wild out in that territory and remember he marries and brings home a wife, Media, and she, of course, is like no Greek woman who ever lived. She can perform magic and she can do monstrous things that you can't imagine a Greek woman doing. there, Palestine, there are no Greek cities there and that is because during the period we're talking about those regions were occupied by civilized powerful people. Nobody would even dream of trying to take them on and building cities that would challenge their control of that area. So that is not territory that you can build colonies; you've got powerful empires to deal with. There is one exception. In the sixth century, I think it's around--imagine around 550 or something like that, the Greeks settle a single colony in the Delta. of the Nile of Egypt at a place called Naucratis, and the root of that word is ship. It is a trading post and it's there by permission of and under the protection of the King of Egypt. So, that's a great exception to everything I've been saying. Going west, would you believe, when you get into what is now Libya, there was a very important Greek colony of Cyrene and that whole region was called Cyrenaica and it was a Greek. powerful. It tried to control not only North Africa, but the waters of the Mediterranean in the west entirely. The Carthaginians, in fact, have a powerful pied à terre in the western part of Sicily. So, that's how far east they get and in time the Carthaginian also cross over into Spain and they control some portion of the Spanish coast closest to Africa. There are now Greek cities on the coast of Spain and there continue to be Greek cities, not everywhere, in a spotty way into France. Greeks are not interested. You will find very rare of the case of a Greek city, which is founded away from the sea; they always wanted to be close to the sea. Lots of these towns sent colonists up north into the Dardanelles and so on and beyond. Some of the same cities send out colonies to Sicily, so that for the real colonizing states there was no limit to where they would send people who wanted to go in those areas. Thebes, the greatest city in Boeotia, also does not colonize. what can we speculate is the meaning of that? What we find is that the states who are doing most of the colonizing are located where most ofThe trade was going on at this point in history. When I say manufacturing, you understand everything is done by hand, but you see things like shops that contain a number of slaves working for a master. In some cases, especially the later on you go, some shops that have quite a few slaves that worked to produce these things. Well, these places are the ones that have the trade, the industry, and also engage in colonization. is easy to see that where there is that kind of conflict and trouble, there would be people who would want to flee that and to go elsewhere. It might well be that the people who won those wars, internal wars, would have been glad to send them away rather than to have these discontented people and these folks who were their enemies hanging around town and making trouble. It is only speculation, but it seems to make sense and we know we don't hear of such troubles within Athens and Thebes, and Sparta. they never lived before and their presence has a real impact of a different degree in every place. I would say that typically their impact was greater in the west and the north than it was in the east and the south. They had very little to teach or to impose upon those people rather than vice versa. If you look at Greece in this period, I don't know if I've used this term before, but some scholars refer to this general period we're talking about as the Greek renaissance by analogy to the renaissance in Italy. Greeks learned a great deal from Mesopotamian and Egyptian civilizations. The Greeks are sopping up tremendously useful information and talent, and skills. It is inconceivable the Greeks could have developed a civilization that they did without contact with these eastern civilizations. There was also, of course, some influence of the Greeks on the people they went to. But it's evident that they borrowed stuff from the Greeks in every element of life, although it didn't shape their lives in a potent, fundamental way. who have interests rather different from those of the most primitive polis you could imagine. Some scholars early on in the century, moved by Marxist theories, suggested that you had a capitalist class growing up, there's just no evidence of that; it's just wrong. My guess is that the earliest traders of any scope were probably noblemen who also had land and estates back home, but who had the opportunity, the know-how, the connections to make it possible to make a lot of living in trade. is going on. More and more farmers are becoming independent, self-sustaining, hoplite farmers of the kind that I've described. They're not going to feel the same way about it, there's going to be pressure from them for a better participation in the decisions that are made in the state. And also there will be some rich people, very rich people,. rich in a different way from the way people used to be rich; rich meant the best land. There will be people who will have wealth in the form of precious things and I would use the word money. come to mean weights of silver or gold. So now you have a change in fundamental economic things. Well, all of this is tied up with this colonial story I've been telling you. Finally, I think, it works in both directions at the same time in terms of the impact all of these changes have on the political situation. On the one hand the changes, that is (A) the rise of the hoplite class; (B) the development of lots of commerce and industry and wealth in a new kind. especially, some scholars have pointed out, I think persuasively, also for some considerable time provided an answer to that problem in the form of an escape valve. Americans didn't have the kind of terrible class warfare and the terrible warfare within cities that the Europeans had experienced throughout most of their history. Really unhappy and angry people could always go west, get new places. I mean, fundamentally, Kansas is a colony in a certain Greek sense, all of these places are. So, that's part of the story of why America had the very lucky early history that it had. that colonization provided something analogous to that for the Greek people. So now, here we are somewhere in the seventh century, most of these places I've been talking about have been settled, the currents that I have been describing are flowing and the kinds of problems they have give rise to what will be felt in most of the towns. That is the proper introduction to the next topic, which I'll discuss next year. No not--it seems like a year, but it's next Tuesday actually.

ROUGE-1: 53.91, ROUGE-2: 52.15, ROUGE-L: 51.60
BERTScore: 72.59

==============================================
==================== [63/100] ====================
Summary:
Instructor: We are asked to identify the areas of consumer surplus, producer surplus, tax revenue, and deadweight loss in this market after the tax. So pause this video, have a go at it. Even if you struggle with it it will make your brain more attuned to when we work through it together. All right, now let's work through this together. And I just want to sort of understand what's going on here before I even try to answer their questions. So first, let's think about the consumer surplus. The consumer surplus is going to be the region above our new horizontal price. And below the demand curve. unit quantity. And so this area is the government, is the revenue to the government. So, S plus U is equal to tax revenue. Tax revenue. And then last but not least, what about the deadweight loss? Well remember, the dead weight loss is the difference between the original the total surplus. When we just let things naturally go to equilibrium. The difference between that and now our new total surplus, which is now lower because we have not allowed the market to function in a very natural way because of this tax on it.

ROUGE-1: 34.57, ROUGE-2: 33.61, ROUGE-L: 34.23
BERTScore: 73.66

==============================================
==================== [64/100] ====================
Summary:
King Arthur was thrown a party at Camelot for Christmas. A towering knight riding an emerald steed burst into the room. He proposed a game. The bravest warrior present would attack him with his own axe. If they could strike him down, they would win his powerful weapon. However, the knight would be allowed to return that blow in one year and one day. No man could survive such a strike. Arthur’s nephew, Sir Gawain, took the weapon instead. And with one swift strike, he beheaded the grinning knight. The Green Chapel is said to be located at a shimmering castle on the horizon. The castle’s lord and lady were thrilled to help such an honorable guest, and informed him that the Green Chapel was only a short ride away. They implored Gawain to rest at their home until his meeting with the Green Knight. In exchange for their hospitality, the lord made a strange request. Over the next three days, he would go hunting and share his spoils every night. In return, Gawain must give him whatever he'd gained during his day at the castle. of Arthur’s knights. He’d planned to spare his neck entirely, until Gawain concealed the sash. Filled with shame, Gawain returned to Camelot. But to his surprise, his companions absolved him of blame and celebrated his valor. Struggling to understand this strange journey, it seemed to Gawain that perhaps the whole world was playing a game. With rules more wild and bewildering than any man could understand, he wondered if the world was a game, too.

ROUGE-1: 53.97, ROUGE-2: 49.27, ROUGE-L: 51.46
BERTScore: 74.10

==============================================
==================== [65/100] ====================
Summary:
well welcome back everybody to uh the last lecture 162. this is kind of a a special lecture um i did get some requests for more information about distributed storage and quantum computing and so i think we're going to do that. i want to make sure that we talk through the chord algorithm since that's a i think relatively simple thing to understand and is very cool and applied pretty much everywhere so if you remember one of the things we talked about last week was basically this cap theorem which was really a conjecture that eric brewer put forth back in the early 2000s. is a good way to understand global storage systems as a result now um at the very end of uh last lecture we were talking about key value stores. Key value stores are very simple in interface excuse me so basically uh you can have an arbitrary key although that's usually a hash over some value. You can have a value associated with it and if you do put a key comma value that goes somewhere into the ether and then when you do get of the key you get back the value that you started with.  node except that in reality what happens is this gets distributed over a whole bunch of nodes and so the question is really many parts to this question one is how do we actually do that distributing another is when some client does a get how does it figure out which node to go through. So far we haven't really talked about how to even make that work okay. So today i want to tell you about the cord uh algorithm which has been turned into storage systems of many sorts including those used by amazon et cetera okay facebook. here's an example of a recursive lookup which is like routing so basically if i say i want to get uh whatever key 14 has got it goes to the master directory and then that directory forwards it on it routes it to the particular node that's got the results and then the the node returns to the directory which returns back to the original client that's recursively routing its way through. An iterative approach is one in which the client basically talks to the directories then they talk to the individual nodes and um we're not routing queries through anywhere every individual client is. if you think about this randomly so let's see keep those two implementation technologies in mind they're really interchangeable um and are more about what you do with the control plane portion of this than anything else. The challenge of that central directory is really that it's got many entries that are sort of key value pairs or at least key node mappings and you could have billions of entries in the system and so um i would say that anything that thinks of a directory here like a single server is bound to be a bad idea okay. clean way to distribute them throughout the system without having to know pretty much all of the nodes that are participating so this seems like a strong ask when you think about it. This is basically going to be a mechanism to divide our space up and we'll talk you through that in the next slide. i'm going to show you how the chord algorithm lets you get by with only knowing essentially a logarithmic number of nodes in the total system and you can still do this well so we're going to associate each one of those storage nodes is going to get a unique id. so imagine you take their i don't know their ip address and their owner and whatever you concatenate all those things together and you hash them and you get a single 256-bit id out of that now we're going to talk more about secure hashes a little bit later in the lecture but so every node has an id and it's going to be in this ring space this unit dimensional space from 0 to 2 to the m minus 1 where m is going toBe big okay and so let me just show you the picture here so here's an example of the ring. are a set of servers that are they have their id that's been acquired by hashing their ip address and their name or whatever so this node here has an id of four and that means that we think of it as in position four on the ring. Now hopefully what you can see here is these are not evenly distributed in fact probabilistically they're evenly distributed. But they're really a random hash over um over some data that's associated with the node and so they're they're distributed through the ring but they're not equally distributed okay. after four to eight and fifteen is gonna store everything from nine to fifteen and twenty is gonna storage everything from sixteen to 20. so the way to think about this is we put a bunch of storage nodes on this ring and then we're going to decide where to store our key value pairs. okay now there's a lot of stuff i haven't told you yet like for instance what does this mean physically. since these are randomly hashed um these nodes are going to be spread physically all over the planet potentially. said in practice m is really something more like 256 and so uh this ring is really big and um these nodes are much more sparsely distributed around the ring okay questions we only have a very small class today so you guys are likely to get your questions answered anybody okay no questions all right should we move on now is a system that was developed uh with a group of researchers at mit and at berkeley um and you can think of it as a distributed lookup service uh and it's in my view i like to teach about it because it's the simplest and cleanest algorithm for distributed storage that i have seen. we're going to combine that central directory and the storage nodes together and spread them all amongst all the nodes. So we no longer have a single lookup directory and a set of storage servers instead we're going on to have aSet of storage Servers that are just going to talk to each other to make this work. The properties uh are as follows so correctness we'll make sure that each node knows about neighbors on the ring so it needs to know how to go forward and how to going backwards a predecessor and a successor on theRing. product there's cademlia there's a lot of interesting ones several designs here at berkeley and so this problem of how to look up a key value pair got a lot. study in the early 2000s okay and let's look about the way to think about chords lookup mechanism is once again routing so it's going to be we're going to describe this in a recursive fashion to start with and then of course you can do this uh in an iterative way as well i think the recursive version is a lot easier toThink about. all these nodes but we're looking down from above and you can clearly see that no lookup for a t37 is going to want to get back node 44 because that's what's going to store key 37. so how does this happen well 4 says well i don't know what it is so it routes to 8. 35 knows that it's uh successor is 44 and so it just responds back and says hey i happen to know that node 44 is responsible for key 37 and at that point node4 can talk back to the client and the client now knows just to talk to 44. correct so how did we find the first one again that's a great question so the answer is that any clients that talk to the storage server need to know at least one node in the system. The client which i haven't shown separately out here happened to know about node four and node four serves as a gateway into the ring all right did that answer that question now you can see that this doesn't seem very ideal because if i've got a thousand nodes that are storage nodes i may have to take many hops to find out what i want here. Just its successor then we can always find the server we're looking for okay now what does this really mean okay so here's this ring and here's you know key 14 stored on node 15 let's say what it really means is something more like this right so these nodes since we we're doing hashes over their ip addresses and some metadata it means that they could be anywhere in the world and then we're connecting them together based on their hash name so fort talks to eight eight talks to 15 and so on so that for instance key 14 happens to be stored here on the east coast node 4 is up in alaska. means that no particular part in the in the world here might be a hot spot it means unfortunately though that we don't have the most uh local of look up because if we start at node four it'd be nice if we could just go down to 15 and back okay now this is a really good question here about redundancy how do we get redundancy out of this for the moment uh suspend that question for just a second certainly we could put raid servers or what you know raid storage on each of these nodes and that would be great if the disks fail but uh we would like something even more powerful. beachfront property in nevada and then has a plan to basically cause uh california to fall into the ocean and therefore have really expensive properties fortunately superman uh saves the day and it doesn't happen so um okay so if we move um forward with this by the way i'm showing you these clients now to make this a little more clear the clients need to know one gateway into the system in order to talk to the system okay so that's going to be part of the initial lookup. wrong with who's connected to whom and then if it finds a problem it can run notify to help reconnect the ring okay so let's uh these are the kind of things that are a lot easier to see with um animations and so what i want to show you here for instance is here's a new a new node or it's a node that crashes coming back then suppose that what iwant is to join the ring so what do i do well just like we've been talking with clients presumably what i know is i know one of the nodes in the system. about this algorithm is all that the ring is going to do is it's going to figure out who is responsible for storing key 50. 50 starts by updating its successor 58 so now it's technically connected somewhat to node 58 but you know 44 is also connected to 58 so we now have a kind of a weird partially connected ring okay and let's look through what happened so node 50 is going. to run stabilize and so it'sgoing to talk to the successor that it knows about and ask it well what's who's its predecessor.  node 58 says oh your predece my predecessor is 44. okay and at that point now things are getting interesting. node 44 is going to ask 58 who it thinks its predecessor is and it's going to say well i think it's 50. okay. node 58 then notify 50 about itself at which point 50 knows its predecessor. and when all said and done we have the the node 50 has joined now what i want to point out about this joining operation i went through it pretty quickly but you're welcome to go back to slides and animate it. If you lose two nodes in a row then what i've just described to you is no longer going to work so there is a way to completely break the ring such that the stabilized procedure won't reconnect it can anybody think about what the right thing to do there is in that scenario how do we make sure that two failed nodes can't prevent the ring from re reattaching itself? So far we still have this pretty expensive lookup process which is order n now we have figured out how to make this stable so first of all as long as we have a fully connected ring we can always find the storage uh for this for the data. now um and what you should do is you should take a look uh take aLook at that paper because they describe this in more detail but basically what you want is a stabilization procedure that can work even when nodes uh several nodes in a row are failing. What you'll see is that that there's a way to do that as long as you have multiple links and what we're going to do right now for performance is going to make that even harder to destroy the connectivity okay so if you look here the question is sort of how do we make sure that we have better than order n? be 96 what node would store 82 well that would also be 96 what nodes would store 84 that'd be 96 at some point we get to what node will store 80 plus 32 so 112. okay and we're going to keep track of a logarithmic number of these pointers. The power the powerful thing about this is once i've got all these nodes now i can do a really fast routing process to figure out how to find which node is going to store the key i'm interested in. first routing hop is going to say well if i'm at 80 and i want to get somewhere over on the ring i'm going to connect i'mGoing to correct the bit i've got in this case it would be a 1 in the high point. Then i'll turn it to 0 by taking a long hop, then i'll take a less long hop and so on. i end up with a logarithmic number of hops to get me to my destination and you can view that like i'm correcting the bits from my starting point. first of all we're going to have um more than one forward and backward link called the leaf set. In the predecessor reply message node a can send its k minus one successors and so on and so you can see what's going to happen. During these heartbeat process of looking things up you know asking well hey my successor who's your predecessor during that process the stabilized process we'll get back multiple nodes. This is going to help us get a forest of connection connectivity forward and backwards and that's gonna allow us to keep our leaf set as as correct as possible. The finger table look uh lookup process that just keeps renewing these pointers over and over again. As new nodes come in the finger table adjusts as new nodes leave or as old nodes leave. So that we end up with really high probability even if half of the nodes fail so you can find data with the right number of leaf nodes. That's kind of what's proved in that chord paper and that's not that many because it's a logarithmic number okay so uh before i.me okay and so that that's a very good way to start. key 14s stored on node 15. If node 15 weren't there key 14 would be stored on 20. If 15 dies or goes away we don't have the data. So it's fine that the consistent hashing tells us where it should be stored. But we can't store it there because we've lost our data so we got to do something else here okay. We're going to take the forward leaf set or you can do both forward and backwards up up.go on to uh storage fault tolerance for the data does anybody have any questions on this we good okay. depends on the algorithm. We're going to store 14 on the successive nodes that we know about because of the leaf set so we'll store it on 20 and 32 and now what's good about this is if node 15 fails which is the point that's supposed to store it we've already got a copy on node 20 and node 20 can notice oh 15 went down therefore node 20 will start the process of making sure that 35 gets a replica. okay questions and the ring is going to stay connected because of our connectivity. algorithm and so what's good about this is like i said you store the data in the cord ring and it it's very hard to destroy okay why are they called leaf sets that's a good question the reason they're called Leaf sets is because in some sense you can view the uh if you take any given starting node like 58 and you view the set of fingers that’s a tree and so eventually you get to the leaf set and so it's like a tree with leaves so that's where the leaf is coming from. i guess you could call them branches if we don't want to mix metaphors too much and the leaves and none of those quite have what i want so i'll follow one of these branches it's a little shorter and then eventually i'll get to a node that's this one where that node knows because of the leaf set which node is the one i'm looking for which is going to be the one that's just bigger counterclockwise or excuse me clockwise from the id i's looking at okay. So this leaf set not only serves to help us with our replication but it also serves as uh as part of the last couple of hops we can use it to basically find who's supposed to have our data. randomness is helping us to avoid correlated failures where yeah we have a bunch of copies but they're all in the same machine room and the building got struck by lightning so that doesn't happen in a chord algorithm. The downside of course is performance might hurt if you happen to be too far away from a copy um and so i will tell you that there are subsequent versions of cord which uh when you're doing this routing and you have a lot of options here see how we have many places we could go. Think of this like a dns built out of cord and so what the client does is the client doesn't know where the data they're interested in is they ask the cord ring. The cord ring tells them who to talk to and then they can talk directly to them and exchange data over the shortest path possible using tcpip or whatever. So you can now get the best of both worlds and that you have very hard to destroy lookup process and then you can choose to replicate that data on close to the client. what we did with the the tapestry lookup process back for ocean store okay so i did want to point out that what i've just described to you this chord ring is actually used in lots of uh cloud services these days the idea at least. For instance dynamodb and i have a paper for that up on the reading from last time uses the chord rings and you can look down here but it uses them rather than spreading them around the planet. It uses them within their machine rooms as a way to distribute load. have a service guarantee that says we'll get a response within 300 milliseconds uh for say 99.9 percent of the requests okay. This is very in contrast essentially to what we've been talking about a lot of the rest of the term uh which is focusing on mean response time. Instead we want to have guaranteed performance okay and this is again thinking i want you to think back to when we were talking about real time scheduling and what was important there was keeping the predictability of the scheduling time low. it adapts automatically which is pretty good okay so what i wanted to do next uh i'm going to leave that there a little bit i want to talk a littlebit about security and then um talk through a couple of things and then i wants to uh try to get to quantum computing as well so we can i know there was some of you asked some questions about that so i'mgoing to leave this topic unless there's more questions okay so i's going to talk through  things that i'm pretty sure i'm assuming everybody kind of knows but i want  to make sure we all have the same terminology so um you know security is an interesting thing it's basically computing in the presence of an adversary. Security is basically using those mechanisms to prevent misuse of resources so for instance virtual memory is a mechanism that can be used for protection security policy would be making sure that when we use virtual memory we don't let malicious processes or different processes owned by different people use the same memory and have a potential for screwing each other up. "It's a it's a constant arms race uh preventing people from breaking into things you care about by using new techniques and the distinction between protection and security i think is an important one" security policy built with our protection mechanisms okay so i wanted to point out something interesting i don't know if you've ever seen this before but here is a car in the ditch. Back in july of 2015 there's a team of researchers that took complete control of a cheap suv remotely exploited a firmware attack over the sprint cellular network. They basically caused the car to speed up and slow down and and veer off the road and uh totally wirelessly so this is a little scary uh to think about now fortunately no humans were harmed. Firmware in this car was accepted as authentic even though it came from a malicious third party. One of the questions that's important is do you know where your data came from that's a provenance question. Do you know whether it's been ordered or changed or altered in any way that's an integrity question. This is a question of the rise of fake data which is kind of much worse than fake news which is about corrupting the data and making the system behave very badly.  confidentiality is making sure that the data is read only by authorized users. Non-repudiation is a surprisingly important thing that people don't often talk about. cryptography is one of the central points of many of these mechanisms. You just have to use it correctly and this is communication that's in the presence of adversaries. It's been studied for thousands of years there's actually something called the code book which you should look up which talks about you know Thousands of years of cryptography and cryptography. The central goal has always been confidentiality about encoding information so an adversary can't extract it the general premise is that there you know there's a key and if you have the key you can decode things if you don't have thekey it's impossible. Public key cryptography where there's really two associated keys and you encode with one and decode with the other really leads to all sorts of really interesting authentication problems okay so basic cryptography which you've probably heard about is you have a secret key and you take the plain text and you encrypt it with the secret key. single symmetric key encryption work which symmetric because the same secrets used at both sides is to prevent a adversary from holding on to an old message and sending it later. The idea of a secure hash function is one where you take data and you run it through a hash function and you get a bunch of bits out of it. If you change the data even slightly you end up with a good hash function with something that essentially roughly half of the bits change so the change from fox to the red fox runs across the ice will give you something very different. often talk about is the hash of a message is a set of bits say 256 bits and this is a good example of what we used on the chord ring where that ring was two to the m possibilities well that might be a result of a hash function like sha-256 okay. What makes this secure is that it's not possible for somebody to come up with another source that matches the hash function okay. It's not even easy with a good secure hash function to come. up with two different items that you come up. with yourself that have the same hash function. we can take a plain text something like a contract and we can run it through a hash function where we take that key and an append m and that's called a digest now we can send that across and the data and at the other side we can verify by re uh computing that hmac okay and if they match the one that was sent across versus the one you computed yourself then you can know that the message is not corrupted otherwise it's corrupted. So we can use hashes to prove later that you know after the transmission has happened that the data is authentic okay so hashing is pretty powerful. it wasn't uh you know if the integrity wasn't high you know it was basically didn't match then we could know that that firmware is probably bogus and we shouldn't be using it okay now the downside of everything we've talked about is both sides share the same key and so if you leak the key then you got problems okay and furthermore you have to somehow share the key. So that requires you to go in a dark alley and you know hand the key over and so this seems like only part of the solution. it's private key and that private key is something that i hold uh secret but the public key i broadcast and so this is basically uh this is the the basis for all sorts of modern algorithms okay among other things if i were to encrypt uh the hash over data and then encrypt it with a public key then i can know for a fact that that data has made it through and only could have come from somebody okay so that's part of uh how we actually sign things all right so for instance here's alice and bob let me show you a fun algorithm here bob sends his public key out in to the wild to alice. Now alice can encrypt messages and send to bob and only bob can decrypt him. Alice can send her public key and now bob can send things to her. is a valid public key requires public key infrastructure but that's another story so now i'm i'm going i went through this very quickly how many people have never seen anybody uh never seen this kind of thing before or is this all pretty familiar okay good oh great this is in cs70 great so let's talk about a project that i've been working on so again you could view security as trying to protect things with a firewall or you could View security as it's all about the data and if you can protect the data then you can protection everything okay. um are a topic for another day as well but this is a special um virtual machine that's in modern hardware that basically allows you to set up a secure channel and do some secure encryption in a way that not even a um not even the local operating system can see the data okay. If we have these secure enclaves stored everywhere and secure encrypted data then perhaps we can do some interesting things okay and we canDo them securely and so um let me see i'm running low on time here i wanted to say something a little bit interesting here about why data breaches are so prevalent. do that then the system's secure okay and so this is what i like to call as border security rather than data security and so if you think well i'm going to put some firewalls and now i can say look this is a trusted computing base that's secure this is one as well there's one around the cloud and then you know the only thing left is cell phones which i make secure tunnels with and this just is fine. The problem with this point of view which you've probably heard about everywhere is that all of a sudden not only is the data breached but somebody who is inside that firewall can produce data that looks authentic even though it's not. and now we suddenly have this issue that physical devices that are trusting on this security suddenly start performing things they're not supposed to okay so the real reason we get these data breaches everywhere is because people think that they can put these boundaries up in a way that don't um can't be breached and of course we know that's not true. The problem really is not only are things breached but the integrity and the provenance of that data is not known so what do we do the data centric vision which is one that i've adopted in uh my research group is one in which we think about shipping containers full of data. One person said well why don't we just make things that are all the same size and shape and then all of a sudden we've got ships trains cranes all of the the the infrastructure for handling these things are the same across the planet. Now i can ship something from my house in lafayette to beijing the outskirts of beijing just by calling the right trucks to come pick up a shipping container which gets taken to the port of oakland put on a ship and then it goes across the ocean and it's unloaded and and so on. a data capsule and inside the data capsule is a bunch of transactions that are hashed so remember those hashes we talked about and signed where we uh we use a private key to sign a hash over something and as a result we trust that this really came from the person who said it did because only they could have the private key. As a result of these data capsules this gives us a cryptographically secure way of moving data around to the edge to the cloud and back again in a way that nobody can fake out okay another way to look at this is this is like almost a blockchain in a box okay. handle this standardized metadata and what is the standardized metadata well it's a hash over an owner key and some other metadata about who created this and that forms a unique address that you can route to in our system unlike um not unlike an ip address. The data becomes a first-class entity so your data basically can float pretty much anywhere so you could put a data a data capsule server in your house and all of a sudden your local data capsules could be stored there or if you're doing some communication with somebody else you could get a copy of their data. data capsules and again because it's like a blockchain in a box it's not possible for somebody to fake data that doesn't belong in there okay and so think back to that firmware issue with the car in the ditch okay and the other thing is that metadata we're looking at actually has details about what the network should and should not enforce and so you can even start talking about privacy where if you had a bunch of cameras in a local edge domain and they were taking a bunch. of data and putting them in data capsules you could make sure that the network would refuse to route those say outside of the house or outside of your building if that was disallowed. the cord ring spanned the globe okay it's again it's a peer-to-peer system uh just like ip as well that does routing and multicast it has things we call trust domains and accounting below you can have many utility providers kind of like comcast or at t that all provide service. above there's an api that allows all of these apps to access their data in the data capsules okay and so this is like me and my house calling a truck to pick up a shipping container. of ip there's a bunch of routing clouds and there's also transit providers okay and so this is exactly how we get ip working. In the global data plane we do the same thing where we have global data planes domains we have routers that route globalDataPlane traffic and they're tied together just like we get with tcp ip. As a result we can actually have clients which might be compute they might be little robots they might are smart cars or teslas can all tie into the global DataPlane. how we want to be dealing with data all right sorry if that's a lot of information but i wanted to see if there's any questions there before i switch over to some quantum computing all righty give me a second i'll be right back and then we'll see ifthere are any questions that came up one moment okay so good so we have some good questions here so first question is how do we know the data is secured so um just like with a blockchain let me just back up to the picture here which i think is a is a good one to be talking about. that we know and the second thing is of course we can put arbitrary encryption on top of this as well to make it uh private so really the signatures are about integrity and who put the data there and uh the encryption would be about privacy. There are many ways of uh deciding kind of which keys to use for that encryption and how to share them with people you want to decrypt okay. These are all of the things you get out of a blockchain by the way for those of you that are familiar with bitcoin or whatever you get it here with the data capsules. bundles of data and if somebody tries to put garbage in there a legitimate person who's trying to look at this can just throw the garbage out because there's no way that that garbage could have been put in there uh in a way that meets the integrity constraints of the data okay. So it's not forgeable um it's uh it maintains its integrity the the transactions can't be swapped or whatever and so it's a unique umly uh high integrity kind of bundle of data. and so if you breach the private key of course that's a problem but potentially every data capsule could have a unique private key which leads to an interesting key management issue but that could be another topic. If any of you want to come work on this project come talk to me uh separately we have plenty of uh places we can talk to you okay now i'm gonna i promised you some quantum computing i did wanna show you one other interesting slide here potentially which shows you kind of an an interesting scenario potentially. idea of how we can build things up um here so uh the data capsule infrastructure is it spans the globe kind of just like tcpip does. Part of what we're doing is we're working with roboticists and machine learning folks to put their data and their models for grasping and so on inside of data capsules. As a result they can reside securely in uh in the edge in say your robots or whatever in a way that can't be breached okay and so this is really targeted at secure edge infrastructure in addition to the cloud. unforgeable all right good so let me say a little bit about using quantum mechanics to compute and since there's only a few of you tonight if you're uh willing to hear me out i can talk for a little longer just to get through a couple of other things on quantum computing. It's basically using weird but kind of useful properties of quantum mechanics two of them quantization and superposition and that quantization really gives us the ability to talk about something like a one or a zero. Superposition is having a bit which is both a zero and a one in certain fraction of uh between the two and that's where things get interesting okay it's like it's fifty percent zero fifty percent one or something in between that's called superposition. Most digital abstractions that you might learn about in 151 or pick your 141 some of those uh various vlsi classes is you're spend a lot of time trying to get rid of the quantum effects. However if you're willing to allow things to not be always a one or a zero that's a different story. always a zero what you can do is you can just start doing quantum computing and that's basically using quantization and superposition to compute. Some interesting results just to tell you uh quickly here is for instance shore's factoring algorithm factors large numbers in polynomial time even though the best known classical ones are sub-exponential in the number of bits. If you could get a shores algorithm running on a quantum computer pretty much all rsa cryptography would be broken because you could factor okay. a time that's a square root in n rather than half of n okay that's pretty interesting right um the other uh so uh 191 is mentioned in the chat. That's a good class to take if you're interested in quantum computing. Another one that's my favorite i think best application of quantum computing is what i like to call material simulation. This was kind of the original uh the original application ofquantum computing that was uh thought of and basically the idea there is if i want to design a brand new element or brand new material to build things out of. Google and ibm are building quantum computers. The goal is to prove that quantum computers could be faster than classical ones. The machines are currently running at four degrees kelvin or something really cold. There are other types of technologies including ion traps that potentially are pretty interesting that there have been some thoughts over the years might be able to run at something closer to room temperature not there yet the current goal of google and ibM is to do something which they call quantum supremacy which is basically to prove quantum supremacy. you know maybe have order 100 bits maximum it's very hard to do anything interesting with 100 bits but they're focusing on demonstrations that show that with those 100 bits they could potentially do something a lot better than a classical machine so that's called quantum supremacy. What i wanted to do just to give you a little flavor for quantum computing that you can go away with here is a version of quantization that's particularly simple to get once you got it. There are certain particles so protons and electrons and neutrons those are good examples that are what are called spin one-half particles. are particles like protons or electrons have this intrinsic spin and so now i got one and zero or up and down okay and a representation called the heisenberg representation looks at this uh messy physical situation like this which is either a zero or a one in these brackets and that represents spin up and spin down okay or vice versa. If you're with the field then that's a lower energy so that's probably spin zero it's probably zero now one proposal for building quantum computers from way back when was called the cane proposal. something people were looking at okay but the temperature here was less than one kelvin which is really cool okay but let's suppose now here's where the quantum computiness gets pretty tricky okay and and uh bear with me just a little bit i know i'm going a tiny bit over here but um if you think of the zero and the one thing okay this is actually a wave function if you take quantum mechanics representing spin up and spin down and what's interesting is the wave function in quantum mechanics is a complex function. we don't normally get a wave function notation in 162. but um the thing that's uh like i said is very interesting about this is that this is a description of a combination of zeroness and oneness. The probabilities can be adjusted anywhere any way you want such that they their squares their norm squared adds up to one okay and if you measure the bits you actually said well do i have a zero or i have one what's funny is you find out you don't have this thing. here is actually sort of in one state and in another okay and those are those are two options and it turned out that there was there's a set of famous bell uh inequality experiments that were done that showed that reality is actually the second choice so in fact as weird as it is uh that proton is is a combination of zero and one at the beginning and it's only when we look carefully and force it to be one or the other when we actually try to measure it then it gets forced into a state okay. example of a superposition in which there are eight options and i can simultaneously have one of those eight values in different proportions. As long as the probability sums up to one okay so as long as c zero zero uh norm squared plus zero zero onenorm squared plus this plus this positive this sum up toone that's a real physical situation. The moment i take a look then i force it to be one value okay and so if you only measure one bit for instance you can say that the first bit will be a zero with probability. codes believe it or not which can protect this quantum information from being measured by accident by the environment. As a result really we can we can hold these quantum states for a long enough period of time to actually do something interesting with them. So let me show you this simple two-bit state okay this is called an epr pair for einstein pradonsky rosen. It was produced by einstein and pedonsky and rosen as a thought experiment and the idea is i've got two bits but i don't have all four options i only have a zero zero or a one one. light travel in fact instantaneous travel of information from the earth out to that far planet einstein really didn't like this he called it spooky action at a distance okay but in fact uh what's interesting about this is you can prove that there's no actual information transferred okay so however we can use this to do what's called teleportation um which is take information uh at one side do some measurements send some data to the remote side and recreate the data recreate the quantum state at the other side. you do a bunch of computing on it such that the probabilities are kept and you measure okay and the way it looks is that you take uh let's say you put an input with all possible combinations of the input input of the inputs being equal values all possible probabilities it looks like you're doing computation on all possible values at once but then when you measure you pick up exactly one and that's the answer you get okay. If you don't do anything very interesting here this is going to look like you randomly picked some input and computed on it so basically what we're talking about here looks like a random computation. high probability some answer that was hard to find that's what we would like okay and so if you look here um you know if the two n inputs are equally probable there could be two to the n outputs that are equally likely. What we'd like is the probability of the outputs to be piled up high on the answer we want and it turns out that something like fourier transform does the trick okay so if we can do a fourier transforms on some input we can actually get an interesting output. quantum computer can do it polynomial time and let me show you how here's how it is in a nutshell you pick a random x between 0 and n that's easy you say if the gcd the greatest common divisor between x and n is not 1 you just found a factor you win. We find the smallest integer r such that x raised to the r is is congruent to one mod n okay so that uh you know basically is doing modulo multiply that's really hard to do well. This out what r makes this equiv equation satisfied and we could do that quickly then um we win and that's something that uh you can't do easily classically but with a quantum computer what we can do. i guess i don't have time to do this because we're running out of time but i can set up a situation where my input to my algorithm is all the possible k's uh if i take a bunch of values and i compute uh the the value x to that value and i add them all together as a superposition and i do a fourier transform what i'll find is that x to the r congruent to one as i have r go through all its possible values. are and that will give me that value that i need which i can do this i have to repeat this a polynomial number of times and then voila i've just factored that number okay so that's the essence of the shortest factoring algorithm and it all hinges on the fact that i can come up with this superposition state where it's all possible values of x to the k where k varies from 0 to n okay. i think it's looking more promising now one of the things that we did do and we don't have time to talk about this but we do. actually investigated if you were to build uh that factoring algorithm and you could do it as quantum circuits that could run on a quantum computer what would that look like. We actually investigated ways of optimizing that and we could actually look at performance of different options for the shortest factoring algorithms. So we built a cad tool to do that so um i i don't know i think it's a pretty interesting area right now and there's a lot of interest in it all right so um sorry i kept you guys way over but this is the last lecture i figured if anybody was interested. i think it's it's pretty exciting project we got working on it if anybody's interested in that and then we told you a little bit about quantum computing and uh feel free to come ask me or also look at 151 or 191 excuse me um which is an interesting class on quantum computing all right well thank you everybody sorry for going way over today thank you for those of you that stuck around and uh i hope you have a good uh finalizing of project three andThose of you listening in cyberspace later as well you are all great.

ROUGE-1: 66.67, ROUGE-2: 64.73, ROUGE-L: 65.83
BERTScore: 76.20

==============================================
==================== [66/100] ====================
Summary:
see then it will go right but some extra amount of plasma or plasma fluid most of it enters into space or DC and then goes back but some which remains extra which is no drain back into sinusoids that will drain into the periphery and that will convert into length right so lymph is moving from the center to the periphery now in between the hepatocytes the parasites are draining on this side secreting on the other side what does what is the substance bile and bile is moving to the center. This is the lymphatic which is a drainage system right and here we can make what is this bile duct so how many things were in present how many channels or systems are present at the corner of this classical Lube you the four systems but unfortunately because early astrologists did not recognize the lymphatics so they thought there are only three system there is a branch of portal or this branch of puerto bean. Later on of course the new it is not portal triad it is portalTriad this is it right or simply we call it. portal area what we call it plural area so at the outer corners of the hexagonal lobules we have portal areas in every portal area. We have portal vein input we have artery hepatic arterial input and we have two drainage system there is lymphatic drainage system and bile duct drainage system. Blood is moving from the periphery to the center into these hepatic classic lobules and of course you should not forget to mention that bile is that right and in the same direction. you understanding me right these bile ducts from every corner and this is left hepatic duct and what is this right hepaticduct. I will drain the I will draw the whole structure here so once forever it must be clear hopefully is a side diagram but it has it is a very important anatomical implication. What is this here yes what is the structure thank Ria's great now what really happens this is right hepatics duct what is  common hepatic  duct and from here which is coming here I will make the gallbladder here. coming here what is this cystic duct and now all this together is called common bile duct it is coming behind the do denim of course come into pancreas. Common bile and pancreatic duct come together and open here in Tudor denim at the employ of weatr here pancreatic juices and bile will come down other right again the relationship right and left the Patek duck and - what is the common hepatic duct meeting with the sister making what isThis.

ROUGE-1: 55.84, ROUGE-2: 54.16, ROUGE-L: 55.59
BERTScore: 77.01

==============================================
==================== [67/100] ====================
Summary:
Causality says that the policy at time t prime can't affect the reward at another time step t if t is less than t prime. This is another way of saying that what you do now is not going to change the reward that you've got in the past now. In the next portion of today's lecture we're going to talk about how we can modify the policy gradient uh calculation to reduce its variance and in this way obtain a version of the policy gradients that can be used as a practical reinforcement learning algorithm. always true for any process where time flows forward the only way this would not be true is if you had time travel and you could take an action or travel back into the past and change your action but we're not allowed to do that all right. i'm going to claim that the policy gradient that i've derived so far does not actually make use of this assumption and that it can be modified to utilize this assumption. i've simply rewritten it and what i've done here is i use the distributive property to distribute the sum over rewards into thesum over grad log pies. over time steps from 1 to capital t of grad log pi at that time step multiplied by another sum over another variable t prime. At every time step i multiply the grand log probability of the action by the sum of rewards over all time steps in the past present and future. If we generate enough samples eventually we should see that all the rewards at time steps t prime less than t will average out to a multiplier of zero and they will not affect the log probability at this time step in fact we can prove that this is true. the proof is somewhat involved so i won't go through it here but once we show that this is true then we can simply change the summation of rewards. Instead of summing from t prime equals one to capital t simply sum from t Prime equals t to capitalt basically discard all the rewards in the past because we know the current policy can't affect them now. For a finite sample size removing all those rewards from the past will actually change your estimator but it will still be unbiased so this is the only change that we made. that is it's the rewards from now until the end of time which means that it refers to the rewards that you have yet to collect basically all the rewards except for the ones in the past or the reward to go. We will get much more into this in the next lecture when we talk about extra critical algorithms but for now we'll just use a similar symbol with a hat on top to note that it's a single sample estimate all right now the causality trick that i described before you can always use it you'll use it in homework two. think back to this cartoon that we had where we collect some trajectories and we evaluate the rewards and then we try to make the good ones more likely and the bad ones less likely that seemed like a very straightforward elegant way to formalize trial and error learning as a grain ascend procedure. But is this actually what policy gradients do well intuitively? We want to center our rewards so the things that are better than average get increased and theThings that are worse than averageget decreased for example maybe we want to subtract a quantity from our reward. grad log p by r of tau we multiply by tau minus b where b is the average reward this would cause policy gradients to align with our intuition. subtracting a constant b from your rewards in policy gradient will not actually change the gradient in expectation although it will change its variance meaning that for any b doing this trick will keep your grading estimator unbiased. We can show that you can show this using the convenient ending in the blue box over there i i know this is equal to the integral of grad p of t Tau times b now by linearity of the gradient operator i can take both the gradient operators and b outside the integral. this is equal to b times the gradient with respect to theta of one but the grading withrespect to thea of one is zero because one doesn't depend on theta. For a finite number of samples it's not equal to zero so what this means is that subtracting b will remain will keep our policy gradient unbiased but it will actually alter its variance so subtracting a by a baseline is unbiased in expectation the average reward which is what i'm using here turns out to not actually be the best baseline but it's actually pretty good. baseline to optimally minimize variance so to start with we're going to write down variance. The variance of the policy gradient is equal to the expected value of the quantity inside the bracket squared minus the whole expected value squared. The second term in the variance doesn't depend on b but the first term does so then in order to find the optimal b i'm going towrite down the derivative d var db and solve for the best b so the derivative of the second part is 0 because it doesn'tdepend on b. terms do so we can eliminate this part and the second two terms if we take the derivative with respect to b the minus two term is linear in b and the plus term is quadratic in it so we get the derivative is equal to negative 2 times the expected value of g squared r plus 2b times theexpected value ofg squared right. Now looking at this thing you could try to imagine what is the optimal baseline really intuitively well perhaps one thing that might jump out at you is that the baseline now actually depends on the gradient which means that if the gradient is a vector with multiple dimensions you like to have a different baseline for every entry in the gradient. different policy parameters you'll have one value of the baseline for parameter one a different value for parameter two. In practice we often don't use the optimal variance we just uh sorry we typically just use the expected reward but if you want the optimal baseline this is how you would get it all right so to review what we've covered so far we talked about the high variance of policy gradients algorithms. We talked about how we can lower that variance by exploiting the fact that present actions don't affect past rewards and we can use baselines which are also unbiased.

ROUGE-1: 60.47, ROUGE-2: 58.37, ROUGE-L: 58.13
BERTScore: 75.61

==============================================
==================== [68/100] ====================
Summary:
Today we're gonna talk about learning in the setting of games. So what does learning mean? How do we learn those evaluation functions that we talked about? And then, er, towards the end of the lecture, we wanna talk a little [NOISE] bit about variations of the game- the games we have talked about. So, uh, how about if you have- how about the cases where we have simultaneous games or non-zero-sum games? So that's the, that's the plan for today. So I'm gonna start with a question that you're actually going to talk about it towards the end of the lecture, but it's a good motivation. So, uh, think [NOISE] about a setting where we have a simultaneous two-player zero-sum game. So can you still be optimal if you reveal your strategy? So lets say you're playing with someone. If you tell them what your strategy is, can youstill be optimal? That's the question. small. So, so the question is more of a motivating thing. We'll talk about this in a lot of details towards the end of the class. But, like, the reason that we have put this I guess at, at the beginning of the lecture is intuitively when you think about this, you might say, "No. I'm not gonna tell you what my strategy is, right? Because if I say, I'm gonna play it, like,. scissors, you'll know what to play." We had this minimax tree and based on that, the utilities that are gonna pop up are minus 50, 1 and minus 5. So if your goal is to maximize your utility, you're gonna pick bucket B, the second bucket, because that's the best thing you can do, assuming your opponent is a minimizer. So, so that was kind of the setup that we started looking at. And the way we thought about, uh, solving this game by- was by writing a recurrence. This is V which was the value of a minimax at state S. And if you're.going to pick bucket A, bucket B or bucket C, then the opponent is going to pick a number from these buckets. at the utility, er, so if you're an- at an end state, we are gonna get utility of S. And if the agent is playing, we- the recurrence is maximize V of the successor states. If the opponent is playing,. you wanna minimize the value of the successors states. And so that was the Recurrence we started with, and, and we looked at games that were kind of large like the game of chess, the branching factor is huge. The depth is really large. So we, we started talking about ways to- for speeding things up. One way to speed things up was this idea of using an evaluation function. of this weak estimate of your value is going to work well and give you an idea of what to do next. So, so instead of the usual recurrence, what we decided to add this D here, um, this D right here which is the depth that un- until which we are exploring. And then we decrease the value of depth, uh, after an agent and opponent plays. When depth is equal to 0, we just call an evaluation function. So intuitively if you're playing chess, for example, you might think a few steps ahead, and when you think about how the board looks like. In chess, you have this evaluation function that can depend on the number of pieces you have, the mobility of your pieces. Maybe the safety of your king, central control, all these various things that you might care about. So, so the hand- like you can actually hand-design these things and, and write down these weights about how much you care about these features. Okay. Well, one other thing we can do is instead of handcrafting it, we could actually try to learn this evaluationfunction. "I care about the number of kings and queens and these sort of things that I have, but I don't know how much I care about them. And I actually wanna learn that evaluation function. Like what the weights should be." "So to do that, I can write my evaluation function, eval of S, as, as this V as a function of state parameterized by, by weights Ws" "And, and my goal is to figure out what these Ws, what these weights are. And ideally I wanna learning that from some data" In the first part of the lecture, we're going to look at backgammon. And then towards the end of the class, we will talk about simultaneous games and non-zero-sum games. And, and that kind of introduces to this, this, um, temporal difference learning which we're gonna discuss in a second. It's very similar to Q-learning. Okay. So let's think about an example and I'm going to focus on the linear classifier way of looking at this just for simplicity. can actually, like, roll two dice and based on the outcome of your dice, you move your pieces various, various amounts to, to various columns. So your goal is to get all your pieces off the board. But if you have only one piece and your opponent gets on top of you, they can push you to the bar and you have to start again. Um, there are a bunch of rules about it. Read it, read about it on Wikipedia if you're interested. But you are going to look at a simplified version of it. maybe like the location of the X's and O's. The number of them. Yeah. So similar type of way that we- we've come up with features in the first few lectures. So for this particular board, here are what those features would look like. So if you look at number of O's in column zero 0 to 1, that's equal to 1. Remember we were using these indicator functions to be more general. So, so like here, again, we are using. these indicator functions. You might ask number of O's on the bar that's equal to 1, fraction of Os that are removed. So, so we have a bunch of features. These features, kind of, explain what the sport looks like or how good this board is. And what we wanna do is we wanna figure out what, what are the weights that we should put for each one of these features and how much we should care about, uh, each one. So that is the goal of learning here. somewhere. So, so one idea that we can use here is we can try to generate data based on our current policy pi agent or pi opponent, which is based onOur current estimate of what V is. Right. So currently, I might have some idea of what this V function is. It might be a very bad idea ofwhat V is, but that's okay. I can just start with that and starting with, with that V function that I currently have, what I can do is I can, I can call arg max of V over successors of s and a to get a policy for my agent. of episodes. We go over them to make things better and better. So, so that's, kind of, the key idea. Um, one question you might have at this point is, um, is this deterministic or not, like, do I need to do something like Epsilon-Greedy? But in this particular case, you don't really need toDo that because we have to get- we have this die that, that you're actually rolling the dice. And by rolling the Dice, you are getting random different- different random path that we might take- so that might take us to different states. us explore a little bit more. So then we generate episodes and then from these episodes, we want to learn. These episodes look like state action reward states and then they keep going until we get a full episode. One thing to notice here is, is the reward is going to be 0 throughout the episode until the very end of- end of the game. Right. Until we end the episode and we might get some reward at that point or we might not. Uh, but, but the reward throughout isgoing to be equal to 0 because we are playing a game. So s, take an action, you get a reward. You go to some s prime from that and you have some prediction. Right. Your prediction is your current, like, your current V function. So your prediction is going to be this V function and add state s parameterized with W. And this is your prediction. I'm writing the prediction as a function of w. Because it depends on w. And then we had a target that you're trying to get to. And my target, which is kind- kind of acts as a label. So it's kind of, the reward. playing games, in games Gamma is usually 1. And then one other thing to notice here is, I'm not writing target as a function of w because target acts kind of like my label, right? If I'm, if I'm trying to do regression here, target is my label. So I'm gonna treat my target as just like a value. So with respect to w, okay? How do I do that? I can take the gradient. What is the gradient equal to? This. is simple, right? 2 reduced, 2 gets canceled. Gradient is just this guy, prediction of w, minus target, times the gradient of this inner expression. So the objective function is prediction minus target squared. And then the update is this, this particular update where we move in the negative direction of the gradient. This is, this is what you guys have seen already, okay. All right. So so far so good. Um, so this is the algorithm we're going to use. is the TD learning algorithm. This is all it does. So temporal difference learning, what it does is it picks like these pieces of experience; s, a, r, s prime, and then based on that, it just updates w based on this gradient descent update, difference between prediction and target times the gradient of V, okay? So what if my V of sw is just equal to w dot phi of s, yeah phiof s. So what happens to my update? Minus Eta. between the two? Yeah, so this is very similar to Q learning. There are very minor differences that you'll talk about actually at the end of this section. All right. So, so I wanna go over an example, it's kind of like a tedious example but I think it helps going over that and kind of seeing why it works. Especially in the case that the reward is just equal to 0 like throughout an episode. So I want to just go over like one example of this. to write it in a simple for- not a simpler form but just another form. So w the way we're updating it is, the previous w minus Eta times prediction minus target, I'm gonna use p and t for prediction minus the target, times phi of s. So at this point, w hasn't changed, w is equal to 0. What is target equal to? So I'm predicting 0 but my target is 1, so I need to push my w's a little bit up to actually address the fact that this is. If you use like, uh, initialize rates do not be zeros which you update throughout instead of just to the end. Yeah. Okay and section two, so S4 and S9 are the same future of activities but you said S4 is S9 [OVERLAPPING]. Uh, this is a made up example, [LAUGHTER] so don't think about this example too much though. Well, is it that possible to have, an end state and not end state have the same feature vector, or no? As one, uh, entry that's always isn't [inaudible] like instead of 1, 2, we have 1, 0 leading to the, the final weight then the weight corresponding to that. Is going to- [OVERLAPPING] Yeah. It will never converge. And that kind of tells you that that entry in your feature vector, you don't care about that. If it is always 0, it doesn't matter what the weight of that entry is. So in general, you wanna have features that are differentiating and, and you're using it in some way. on the relationship between the features and the weights. Uh, they always have to be the same dimension, and what should we be thinking about that would make a good feature for updating the weights specifically, like- So, uh, okay so first off, yes, they need to be always in the same- in dimension cause you are doing this, um, dot-product between them. And then it's usually like hand designed, right. So, so i- i- it, it's not necessarily- you shouldn't think of it as how is it helping my weights. of 10, uh, if you're using the same feature extraction for both, how does that affect the generalized ability of the model, the agent? Yeah, so, so you might choose two, two different features and one of them might be more like so. So there is kind of a trade-off, right? You might get a feature that actually differentiates between different states very well, but then that makes learning longer, that makes it not as generalizable, and then at the end- on the other hand, you might get one that's pretty generalizable but then it might not do these specific things. to 0.25 and 0.75 then it kind of stays there, and you are happy. All right so, so this was just an example of TD learning but this is the update that you have kind of already seen. And then a lot of you have pointed out that this is, this is similar to Q-learning already, right? This is actually pretty similar to update, um, it's very similar, like we have these gradients, and, and the same weight that we have in Q- learning. of this idea of, I have this evaluation function, I wanna learn it from data, I'm going to generate data from that generated data. So, so that's what we've been talking about so far. And the idea of learning- using learning to play games is, is not a new idea actually. In '50s, Samuel looked at a checkers game program. So where he wa- he was using ideas from self-play and ideas from like similar type of things we have talked about. This idea of learning in games is old. People have been using it. In the case of Backgammon, um, this was around '90s when Tesauro came up with, with an algorithm to solve the game. And he was able to reach human expert play. And then more recently we have been looking at the game of Go. So in 2016, we had AlphaGo, uh, which was using a lot of expert knowledge in addition to ideas from a Monte Carlo tree search and then, in 2017, weHad AlphaGo Zero, which wasn't using even expert knowledge. all, like, based on self-play. Uh, it was using dumb features, neural networks, um, and then, basically the main idea was using Monte Carlo tree search to try to solve this really challenging difficult problem. So, in this section we're gonna talk a little bit about AlphaGo Zero too. So if you're attending section I think that will be part of that story. All right so that was learning and, and games. Now, so, so the setting where we take our games to simultaneous games from turn-based. Minimax sca- strategy seemed to be pretty okay when it comes to solving these turn-based games. But not all games are turn- based, right? Like an example of it is rock-paper-scissors. You're all playing at the same time, everyone is playing simultaneously. The question is, how do we go about solving simultaneously, okay? So let's start with, um, a game that is a simplified version of rock- Paper-Scissors. This is called a two-finger Morra game. Play the game and think about what would be a good strategy to use when you are solving this, this simultaneous game. We have these possible actions of showing 1 or 2. And then, we're gonna use this payoff matrix which, which represents A's utility. If A chooses action A and B chooses action B, this is the outcome. Make sense? So can you guys talk to your neighbors and play this game real quick? [LAUGHTER] How many of you are in the case where A chose 1, then- and B chose 1? Oh, yeah one. this value function, uh, over, um, over our state here. Now, we have this value function that is- do we- we shall use here, I'll just use here. That is again from the perspective of agent A. So, so I'm trying to like get good things for A. In this case it's not at the end [inaudible] ? Uh, yeah. And then this is like a one-step game too, right? So, like you're just playing and then you see what you get. write that pay-off matrix here. I'm gonna write A here, B here. agent A can show 1 or can show 2, right? If both of us show 1 at the. same time, agent A gets $2. If we show 2 at the same time,. agent A get $4. Otherwise agent A has to pay, so agent A. gets minus $3. So, so what is a policy in the setting? And, and then the way we refer to them in this case are as strategies. policies. So a pure strategy is just a single action that you decide to take. We have also this other thing that's called mixed strategy which is equivalent to, to stochastic policies. And what a mixed strategy is is a probability distribution that tells you what's the probability of you choosing A. So, so pure strategies are just actions a's. And then you can have things that are called mixed strategies and they are probabilities of, of choosing action a, okay? All right. game. So, so for this particular case of Two-finger Morra game, let's say someone comes in and says I'm gonna tell you what Pi A is. Policy of agent A is just to always show one. And policy of agent B is this, this mixed strategy which is half the strategy. Pi A chooses action A, Pi B chooses action B times value of choice A and B, summing over all possible a and bs. Okay, so let's look at an actual example for this. time show one, half the time show, show two. And then the question is, what is the value of, of these two policies? How do we compute that? [NOISE] Well, I'm gonna use my payoff matrix, right? So, so 1 times 1 over 2 times the value that we get at 1, 1, which is equal to 2. And, well, what's that equal to? There are two 0s here, that's minus 1 over2. 2 based on- based on this strategy, okay? Okay. So I guess this doesn't seem like we only have this one statement, so it's, we only take one action. Ah, so you might be interested in looking at what happens in repeated games. So that opens up a whole set of new questions that you're not discussing in this class. So, so the value is equal to minus 1 over 2. Okay? All right. so that was a game value. If we had more than one state, Would we have that for every single one. someone tells me it's pi A and pi B, I can evaluate it. I can know how goodpi A andpi B is, from the perspective of agent A. But with the challenge here is we are playing simultaneously, so we can't really use the minimax tree. Like, like think minimax. So agent B should be min- minimizing this. agent A should be maximizing this. That's, that's what we wanna do. So I'm going to go ahead and do that. assume we can play sequentially. So that's what I wanna do for now. So, so I'm going to limit myself to pure strategies. So maybe I'll, um, I'll come over here. I will just consider a setting- very limited setting and see what happens. And then each of them have actions of either or showing 1 or showing 2. They can show 1, show 1 or 2, right? If we do one- if we show one, 1, 1. player A gets what? $2? Is that right? It's 2, right? I can't see the board. Um, otherwise player A gets minus $3 if you have 2, 2, player A get $4. Right? So okay. So, so now if, if we have this sequential setting, if you're playing minimax, then player B is going second. Player B is gonna be like this one and in this case player A is going to be like. this one. What should player A do? Well in both cases Player A is gettingminus $3. If we have pure strategies, all right, going second is better. What's going to happen if we have mixed strategies? Are we gonna get the same thing? So, so that's the question we're trying to answer. So the value of the game, uh, would be, maybe I'll write it here.of the board, maybe up here. Okay. So what did we just learn? We learned, if we had pure strategies. That sounds intuitive and right. So far so good. the value of Pi A and Pi B. Pi A is already this mixed strategy of one-half, one- half, right? It's going to be equal to Pi- is this- yeah, actually. All right. So well, what is this equal to? Uh, that's equal to minus 1 over 2 Pi B of 1, plus 1 over Pi A of 1. We're gonna get $4, plus Pi B choosing 2 times Pi A choosing 1, and that's minus $3. So, if someone tells me, "Well, this is a thing I wanna do," I should try to minimize value of Agent A, right? So, so what I'm really trying to do as Agent B is to minimize this, right, because I don't want Agent A to get anything. So the best thing that I can do as a Agent 2 is to follow a pure strategy that always shows 1 and never shows 2. So that tells me that never show 2 and always show 1. deciding to go first. Player A is going to follow a mix- a mixed strategy. The way I'm writing that mixed strategy is more generally saying Player A. is gonna show 1 with probability p and is. going to show 2 with probability 1 minus p. And then after that it's Player B's turn. We have just seen that Player B, the best thing Player B can do is, is to do a pure strategy. So Player B could really like [inaudible] terms with the same then like Player B following a mixed Strategy. negative term, okay. So, uh, what's gonna happen is if you have 1, 1 and then, then that is going to give me 2, value 2, right? So it's 2 times p. Am I writing it right? 1 minus p times 3. Right. So with probability 1minus p, this guy is gonna pick 2. If this guy picks 1, you're gonna get minus 3, minus 3. So that is minus 3p. All right. So what are these equal to? In this more general case, Player A is playing first, uh, and is following a mixed strategy but doesn't know what p they should choose. Player B has to follow a pure strategy. And then under that case, we either get 5p minus 3 and minus 7p plus 4, okay? What should Player B do here? This is Player B and this min node. All right? So Player B is going to take the minimum of 5pminus3 and plus 7pplus4. here. So player is going to maximize that and also, I'm saying Player A needs to decide what P they're picking. So they're going to pick a P that maximizes that. Is this clear? [inaudible] Like these computations? Yeah, so these are the four different, uh, things in my payoff matrix. With probability 1 minus p, A isgoing to show me 2. I'm going to show 1, that's minus $3, times probability 1minus p. probability of 1 minus p. With probability P, A is going to show me 1. So that's why I'll lose $3, that's minus 3 times probability p. So what, what p should Player A decide? Uh, Player A should decide the p that maximizes this. Okay? All right, so the interesting thing here, is some line, right? With positive slope. This is 5p minus 3, let's say. And this minus 7p, plus 4 is another line. It's another line with negative slope. minimum of this? Where is going to be the minimum of this happening? Minimum of these two lines? Where they meet each other, right? Okay? So, so the p that I'm s- going to pick, isGoing to be actually the p, where, th- th- the value of p is where these two are equal to each other. And that turns out to be at, I don't know what it is, 7 over 12 or something. Yeah, so it's going to happen at 7 over12. And the value is minus 1 over 12. Right? So okay, so let's recap. Probabilities. So the thing A is deciding is, "Should I pick 1 with probability p and should I pick 2 with probability 1 minus p and what should that p be?" So, so what is the probability I should be picking 1? So that's what A is trying to decide here. So whatever A decides with p and 1 plus p ends up in two different results. Based on them, B is Trying to minimize that. So even in this case, where A was trying to come up with the best mixed strategy he could do, the. best mixed strategy A is doing is show, show a 1 with probability 7 over 12 and show 2 with probability 5 over 12. Even under that scenario, A is losing. A is always going to be either showing 1 or 2 and A is deciding which one. So A has to play a pure strategy because of that, right? Like the best thing A can do, is going to been a pure Strategy. So what if B plays first? So I'm going to swap this. If you are playing a mixed strategy, even if you reveal your best mixed strategy at the beginning, it doesn't matter if you're going first or second. So this is called the von Neumann's theorem. For every simultaneous two-player zero-sum game, with a finite number of actions, the order of players don't matter. If you, if you play mixed strategy,. your opponent is going to follow a pure strategy. Either 1 or 2 with probability 1. But with probability p, like, if we're doing like ordering, one of the two answers might- will come out. to 7 over 12 here, like these two values end up being equal. Equal, right? [inaudible]. [OVERLAPPING] Uh, none of them are actually equal. The reason that they end up be equal is you are trying to minimize the thing that this guy is trying to maximize. So no matter what your opponent does, like you're gonna get the best thing that you can do. So, so that's kind of the idea. All right. So let let's say I would pick a p that doesn't make these things equal. The key idea here is revealing your optimal mixed strategy does not hurt you which is kind of a cool idea. The proof of that is interesting. If you're interested in looking at the notes, you can use linear programming here. So, so let's summarize what we have talked about so far. Next 10 minutes, I want to spend a little bit of time talking about non-zero-sum games. In real life, you're kind of somewhere in between that, and, and I Want to motivate that by an example. dilemma? Okay. So, uh, so you have two players A or B. Each one of you have an option. You can either testify or you can refuse to testify. So you can- B can testify and A can refusal to testify, and I am going to create this payoff matrix. This payoff matrix is going to have two entries now in each one of these, these cells. And, and why is that? Because we have a non-zero-sum game. Because this was for player A, player B would just get negative of that. different players. So the von Neumann's minimax theorem doesn't really apply here because we don't have the zero-sum game. But do you actually get something a little bit weaker, and that's the idea of Nash equilibrium. So a Nash equilibrium is setup policies Pi star A and Pi star B so that no player has an incentive to change their strategy. So, so what that, that means is if you look at the, the value function from perspective of player A. from here. I start from A equal to minus 10, B equal to 0. Can I get this better? Can I make this better, or did I flip them I all? [NOISE] Okay. So let's say I start. from here. What if we start here? A has 1 year of jail, B has 1 years of jail. A has an incentive to change this now and get 0 years jail. B has an incentives to get 5 years jail instead of 10 years. Similar thing here. In general, there is at least one Nash equilibrium if you have a game of this form. In a collaborative Two-finger Morra game, it's not a zero-sum game anymore and, and you have two Nash equilibria. And then Prisoner's dilemma is the case where both of them testify. Of us are testifying and both of us are getting 5 years jail. Just kind of interesting because there is like a socially better choice to have here, right? Like both of me would refuse, like we would each get 1 year jail. There's a huge literature around different types of games, uh, in game theory and economics. Uh, but we have multi- we also have multiple game values from- depending on whose perspective you are looking at. If you're interested in that, take classes. And yeah, there are other type of games still like Security Games and or resource allocation games that have some characteristics that are similar to things we've talked about. And with that, I'll see you guys next time.equilibria.com.

ROUGE-1: 51.75, ROUGE-2: 50.25, ROUGE-L: 48.89
BERTScore: 73.59

==============================================
==================== [69/100] ====================
Summary:
The famous example was posed by Comte de Buffon back in the 18th century. It marks the beginning of a subject that is known as the subject of geometric probability. The problem is pretty simple. We take a needle that has a certain length -- l-- and we throw it at random on the plane. We're interested in the question of how likely is it that the needle is going to intersect one of the lines if it is thrown completely at random? We will answer this question, and we will proceed as follows. In order to have a complete model, we need a joint PDF in our hands. Here, we're going to make the assumption that x and theta are independent of each other. So the joint PDF is going to be equal to 4 divided by pi times d. By this point, we have completely specified a probabilistic model. We have made some assumptions, which you might even consider arbitrary. But these assumptions are a reasonable attempt at capturing the idea that the needle is thrown completely at random. much more streamlined. There's not going to be any choices. We just need to consider the event of interest, express it in terms of the random variables that we have in our hands, and then use the probability model to calculate the probability of this particular event. When will the needle intersect the nearest line? This will depend on the following. We have an intersection if and only if the vertical extent-- which is this vertical green segment-- is larger than the distance x. Or equivalently, if x is less than the vertical amount of the needle. our case is four over pi d-- and integrate it over the set of x's and theta's for which the PDF is non-zero. So what are these pairs? This event can occur with any choice of theta. So theta is free to vary from 0 up to pi over 2. How about x? For this event to occur, x can be anything that isNon-negative as long as it is less than or equal to this number. And all we need to do now is to evaluate this double integral. is this 4 with this 2 give us a 2. We have 2l over pi d. And then the integral from 0 to pi over 2 of sine theta is minus cosine theTA. This turns out to be equal to 1. And this is the final answer to the problem that we have been considering. And now, a curious thought. How can you figure out the number pi? Take your needle, throw it at random a million times, and count the frequency with which the needle ends up crossing the line. If you believe that probabilities can be interpreted as frequencies, this gives you a good estimate of this probability. This is a so-called Monte Carlo method, which uses simulation to evaluate experimentally the value, in this case, of the constant pi. Of course, for pi, we have much better ways of calculating it. But there are many applications in engineering and in physics where certain quantities are hard to calculate, but can be calculated using a trick of this kind by simulation. Here's a typical situation. Consider the unit cube. Inside that unit cube, there is a complicated subset which is described maybe by some very complicated formulas. And you want to calculate the volume of this complicated subset. What you can do is to start throwing at random points inside that. unit cube. So you throw points. Some fault inside. Some fall outside. You count the frequency with which the points happen to be inside your set. And as long as you're throwing the points uniformly over the cube, then the probability of your complicated set is going to be the volume of that set. You estimate the probability by counting the frequencies with which you get points in that set, and so, by using these observed frequencies, you can estimate the volume. It turns out that these days, physicists and many engineers use methods of this kind quite often and in many important applications.

ROUGE-1: 49.09, ROUGE-2: 47.37, ROUGE-L: 48.95
BERTScore: 69.23

==============================================
==================== [70/100] ====================
Summary:
Professor: We had formulated an exact approach using the time evolution operators and diagrams. And well, I think we understood what it means when atoms in the ground state emit photons which are virtually absorbed. So we figured out what is really inside this formalism and what are the processes. What we want to continue discussing today is one problem which you often have such approaches. And this is the problem of resonance. And that means if you write down the perturbative expansion, you have a 0 in the denominator. You have a divergence. I reminded you that in a phenomenological way, you've seen that this problem can be "fixed" by adding an imaginary part to the energy level. I want to show you what are the tools to treat those infinity source divergences in a consistent and a systematic way. And one hint how we have to do it comes by simply taking this energy denominator and expanding it in gamma, simply a Taylor expansion in gamma. And then, we realize gamma is often calculated in second order Fermi's golden rule. That tells us that doing something here probably means infinite orders in a perturbation series. means to sum up an infinite number of diagrams. It's a very elegant way to combine equations with graphical manipulations. So that's our agenda for at least the first part of today. And OK, we want to understand the time evolution of this system. Our tool is a time evolution operator. And at the end of the class on Monday, I told you, well, let's simplify things. Let's get rid of those temporal integrations and multiple integrals by simply doing a Fourier transform. now the starting point for our discussion today. We want to calculate the Fourier transform of the time evolution operator to infinite orders. So unfortunately, [INAUDIBLE]. We should copy this equation. Because we need it. And now we want to iterate it. So the resolving G in 0's order is G0. Now plug G0 into the right hand side of the equation, and you get the first order, G0VG0. I think you've got the idea. It's almost like a geometric series. terms, which are 1 over Z minus Eb. Sometimes, scattering and evolution equations are better formulated when you do it in the complex plane. Just remember, Z is the energy. And it is the initial energy. The initial energy is if it's a ground state and a resonant photon, we have a problem. Because the denominator is 0. So in other words, for resonant excitation, we are interested in the case that Z is on the order of this close to Eb. easy part, which has no divergence, we can make any kind of approximation we want without altering the physics. But the resonant part, this needs special attention. Because if I treat it literally in those expressions, they don't make sense mathematically. Because they cause infinities. But because I think it's just beautiful method, I want to look at this equation and write it down in symbols. So we want to arrive at a diagrammatic representation for this matrix element of the resolvent Gbb. Quantum mechanics is an algebraic equation. We want to figure out which of those expressions include this problematic term exactly twice or three times or four times. So we regroup the terms, and then we see what we can do. Now, I've picked the matrix element Gbb. So that means over here and over here we start out in the state b. So if I write down all terms which contain this resonant term twice, well, we start with a resonance term. And we have to end with a resonantterm, because we have the matrix elements Gbb, which I'm focusing now on. We can go through two vertices. But it can only include dashed lines in between. So we start with that state. We end with a state b. But in between, we can sort of once, twice, three times go through other intermediate states. But we never are allowed to create another divergence. And this infinite sum over all other states-- I don't know how to calculate it yet. But I'll just call it a square box. The square box is the circle plus all terms like this. equations. We call this the function Rb of Z. And it's clear how to go to higher terms. So we've just defined this function R by focusing on two occurrences of the straight line. Well, let's look at higher order terms. What happens when Z minus Eb, the divergent term, comes to the power n? Well, we just dealt with n equals 2. Let's now look at n equals 3. And what I've shown in diagrams above is nothing else than the circle Vbb, the matrix element of the interaction. Professor: R has a real and imaginary part. One is a self energy, and the other one is a decay rate. The real part will be the self energy. Yes, we connect a lot of passwords you may have heard here and there. But the nice thing is no. Because n equals 3, we don't have to find more and more symbols for more complicated sums. We just have to use the same symbols as we have always used. We don't need to change our passwords. means we have to start in state b. And one time in the time evolution, we can go through stateb. But one thing is not allowed-- to involve the state B. And everything else other than the state b has already a symbol. It is the square symbol. So this is the exact representation for n equals 3. And the contribution to the resolvent G, the Fourier transform of the time. evolution operator, is-- well, we have factored out three occurrences of the state. And then, we need two square boxes. But the square box has already an algebraic definition. we ask what happens when we allow more appearances of the state b, for each of them, we obtain another square box. So by looking at the terms which are bothersome and regrouping the infinite terms according to one occurrence, two occurrence, three occurrence of this divergent denominator, we have now found an exact expression for Gb of Z. And since this is now an algebraic equation with a geometric series, we can write it exactly as this minus Rb ofZ. non-trivial expression, the function of the kernel, has no divergences. And therefore, because there is no critical part to it, rather simple approximations can be made and lead to physically meaningful results. That's an idea you may see often in physics. You have a theory whether it's something complicated, non-perturbative divergence. But you just rewrite the theory, transform the equations in such a way that structure of the equations now accounts for the physics behind it. then, the perturbative expansion involves no divergent terms and can be performed. So therefore, we are now in a position to make approximations to the function R. And the simplest approximation which we can do is we can just try to see if we can get away with very low order. And let me call this now the triangle. So that would mean the following, that the exact formulation involved-- let me get black-- had a propagator. The state b has to go through multiple squares. This is how it propagates. And an approximate result is now that the squares are replaced by triangles. light scattering. We have derived it. I just go now and apply to an excited atomic state. So the state we are interested in is the atomic state b and no photons. And if you use the lowest second order approach, then diagrammatically-- just give me one second, photon was emitted. And this is the matrix element between state B0B0 and the time evolution operator. So we are calculating, of course, the Fourier transform. And all the work we have done with our diagrams means instead of calculating G, we're calculating the kernel of Z. Yeah, sorry, so the process we have considered is that we go to second order. We can go through an intermediate state, can say, absorbing it and meeting a virtual photon. So that means now that we, with this approximation, approximate Gb of Z, the Fourier transform, the resolvents. We let b just propagate, which is problematic because this has divergences. But we are allowing now the state b to go through intermediate states a. And remember, since this appears in the denominator, that means for G, just make a Taylor expansion in R. a photon, go to another state. It's reabsorbed and such. So the question is now, what is neglected? So what we neglect is actually a lot. In this lowest order approximation for the function R, we approximated R by second order. We have not included processes where we go through states a, a prime, a double prime, and then eventually we go back to the state a. Or we don't go back. to b. We go to a prime. Then, we scatter again. And then, we are back in b. Fermi's golden rule where we-- well, with a little twist-- have the initial state. The dipole interaction or the [? p.a ?] interaction takes us to an intermediate state with a photon with [INAUDIBLE] and polarization epsilon. We propagate in the intermediate state Ea. And now we have to go back with the same matrix element. So therefore the matrix element is squared. And we have a double sum. We sum over all possible states of the photon. The time evolution operator has poles in omega. So we can't just Fourier transform. But what we can do is we can add an imaginary part plus or minus eta. And we can just go around the poles. And then, it becomes mathematically meaningful. And what we're doing here is-- but I'm not really explaining it mathematically-- we have played those tricks here. But I hope it becomes clear if I say what the real and imaginary parts are. So the real part is this matrix element squared, but the imaginary part is also squared. double sum. But what we use is the principle part of it, which is well defined in the theory of complex functions. And it's divergent, but you take a certain symmetric limiting procedure. So the imaginary part gets us Fermi's golden rule. And the real part has a 1 over [INAUDIBLE] dependence. So this is actually nothing else than the AC Stark shift not due to a laser beam, but due to one photon per mode. Because we started with an atom in an excited state. It can emit a photon in any mode. Now creating an AC Stark shift. And this is mathematically the expression. And such AC Stark shifts which appear as self energies, as energy shifts created by the state, this is nothing else than the famous Lamb shift. So that's what we get out here. I have already-- do I in this sum? What we have here is we have this function R in the real and imaginary part, which depends on the energy E. But remember, we worked so hard with diagrams to make sure that the triangle-- first the square, and then the triangle, and this is what we calculate here-- has no resonant structure at the energy Eb. So this replace, neglect E and set, or replace the dependence by E, by taking the value at Eb, this corresponds to the Markov approximation. And by neglecting the energy dependence, we are now saying everything is constant as a function of energy. And that means in the temporal domain that we have a delta function. And we obtained, as promised, the Fourier transform of the time evolution operator, which initially had a divergence at energy b. But by now, calculating the function R, we had a correction, which is a radiative shift, which comes from the real part. imaginary part, which we can approximate by Fermi's golden rule. If we now Fourier transform back and obtain the time evolution of this state, it no longer evolves with the energy Eb. It has a shifted energy by this self energy. But in addition, because of the imaginary part, it has now an exponential decay. But there are two things you should learn. The first thing is that the exponential decay would be different if we had not made the Markov approximation. spectrum of energies. And it's obvious that the properties of this expression where you sum over all states, something will happen when you go past the normal excitation energy or the ionization energy of the atom. So what you can immediately read form here is that exponential decay is a simple approximation. But at very early times, it will break down. Because then, the energy dependence matters. But the longer you wait-- if you wait a few nanoseconds, the relevant part of the Fourier transform is only a small energy or frequency interval around the resonance energy. And then, this approximation is excellent. infinite summation of diagrams, if we had done a perturbative expansion, we would have never obtained exponential decay. We would have obtained some polynominal decay. If you do lowest order perturbation theory, instead of getting an exponential decay, you would just get a linear slope. And if you fix it, I think you get quadratic terms. So it's not really profound what I'm saying. It's pretty much an exponential function is non-perturbative. we have an atom in the ground state, and a photon comes along, and it takes the atom to the excited state b. Then we go back to the same state-- could be also another state-- by emitting a photon k prime epsilon prime. And the relevant matrix element of the time evolution operator, which is the T-matrix, involves now the matrix element, the initial energy minus the intermediate energy. It transfers exactly to the light scattering problem, that we have to include now radiative shifts. to infinite order. If you're off-resonant, you don't have a problem. This extra term delta and gamma, the radiative shift and the line widths only matter when the black term is close to 0. So everything we have done by correcting the naked propagation of the state b by the correct propagation with this infinite emission and reabsorption of virtual photons, this is only needed if the denominator is 0. And then, we have to figure out what else happens.  chapter of diagrams. Until maybe 10, 15 years ago here at MIT, we were not teaching that. And I felt often in discussion with students that a little bit more of a complete picture behind atom photon processes is needed. What I summarized could of course cover a whole semester course in QED and how to do calculation. And if you're interested in mathematical rigor, the green book, Atom-Photon Interactions, is pretty rigorous and still very physical. But on the other hand, many of you experimentalists, I think you should have sort of this picture behind it. many modes. It emits photons and reabsorbs them. And you can often neglect that in the simple description of your experiment. But if you take certain expressions seriously, they would have divergences. And that's what we discussed without this infinite number of processes which happen. Of course, yes, the whole other regime which I should mention is when you can completely neglect the coupling to many modes. If you do Rabi oscillation with resonant interaction, you don't need all that. Because then, you're really looking at discrete states.  chapter-- to give you sort of the fundamental story, the profound story behind the optical Bloch equations. We want to describe a quantum system. But the quantum system is coupled to the environment. And that means we have dissipation. And this is something which is not easily dealt with in simple quantum physics. And so in this section, what I want to address at the most fundamental limit is, what is the step where we go from reversible equation, unitary time evolution, to something called relaxation, which is dissipative. A small system which I just described by Schrodinger's equation, now follows the density matrix equation, has relaxation, the entropy increases, and such. So in other words, we have coupling to the environment. And in this cause in part one, we've dealt with it and looked at vacuum Robi oscillation and a few really neat things. But what happens is that the system is an open quantum system. You can have spontaneous emission. And if your mirrors are not 100.00% reflectivity, some light leaks out. So this is our system. In general, if you write down the total Hamiltonian and do the time evolution, something will come out which, in general, is very complicated, very entangled. So you have to know, to keep track of all the photons, which have been scattered in the lifetime of an atom. So often, what we do is we simply put the photons in a trash can. We trash them. We're not interested in what the photons are doing. The vacuum chamber has taken care of them. So all that we are interested in is how do we describe the atomic system? emitted. But those million photons which have been emitted into the environment, they change, of course. They change this density matrix of the atom. And if you find a description, the master equation is including with extra terms what those photons have done. Maybe this sounds very abstract. But in the end, you will find that maybe photons which emitted produce some damping. Or if you put atoms in molasses, the atomic motion comes to a standstill. So that's the idea. it causes stimulated emission. And it causes absorption described by the Einstein b coefficient. And you have a similar equation for the excited state. So this is clearly the semi-classical limit of what we want to accomplish. We want to know more. We really want to find the full quantum time evolution. We have to be careful. The time evolution as a Hamiltonian, if you now bring in the environment, cannot be simply included by adding an imaginary term. This here violates the unitary time Evolution. Consistent with the loss of quantum physics. If you find an equation which describes the atomic system, it will be a requirement that a density matrix turns into a densityMatrix. And that is actually extremely restrictive. This is actually something which is the frontier of our field. We have some evolution of an atomic system by coupling it to the environment. But can you engineer the environment in such a way that it does something really fancy to your system? Well, you can dream of it. But you dreams are restricted by the mathematical structure of all possible master equations in the world. I will be telling you is also sort of relevant to understand this sort of frontier in our field which is called environment engineering. OK, density matrix-- good, five more minutes. So what we have is we have a system. And we have this environment. And what we are exchanging with the environment is both energy, but also entropy. And so when we transfer energy or heat, there is a corresponding change in energy. And it's a general property of all quantum systems. It's a consequence of the fluctuation dissipation principle. display that, that we do not get any form of damping without at least the fundamental quantum noise. So what we need is we need a description of the quantum noise, which comes from coupling to the environment. The tool which we use for that is the density matrix. The density matrix can be written as a probabilistic sum over states. This will actually play a major role. We will make certain models for damping. And it's really beautiful. On Monday, I will give you the beam splitter model for the optical Bloch equation. have certain quantum states k, and we just add them up probabilistically, this kind of microscopic interpretation of the density matrix is called unravelling. It's sort of writing it as a specific diagonal sum over states. But those unravellings are not unique. They describe one possibility. But there are other possibilities. And you can see by inspection that this will do the trick. So we'll talk a lot about unravelled of thedensity matrix. That's why I want to say up front, that the same density matrix can be thought of as being created by different processes. But this actually makes it even more powerful. processes. OK, any last questions? Well then, let's enjoy the open house with incoming graduate students, and I'll see you on Monday. I'll be back on Monday to talk to you about the classes we'll be teaching next year. Back to Mail Online home. back to the page you came from. Click here to read the full transcript of this interview. Back To the pageyou came from, click here to see the full Transcript of this Interview. Back in the page, please share your questions and comments.

ROUGE-1: 58.81, ROUGE-2: 56.69, ROUGE-L: 56.77
BERTScore: 73.39

==============================================
==================== [71/100] ====================
Summary:
David KAISER: In the last few class sessions, we were looking at some changes in high energy particle theory. And then in our most recent class session, we looked at some of the shifts within the fields of study. And today, we're going to focus on a kind of example of that new subfield, a relatively new sub field that's known as inflationary cosmology or simply cosmic inflation. So it's a framework for trying to understand the evolution of our universe over a huge expanse of time, increasingly using tools at the interface. lecture notes on the Canvas site which go into a little bit more detail of some of these parts from the lecture. Again, strictly for your own interest as your interest and time allows. There's some more material there. And again, I'd be glad to chat more about this if questions come up beyond that. OK. So oftentimes, astronomers will describe the most salient features of our universe in terms of what they call large scale structure. It's really quite remarkable. And this [CLEARS THROAT] picture's been emerging really over a century, for 100 years or even more. or our own Milky Way galaxy. Or if we zoom in even closer to home with the solar system or even really in human terms, there are concentrations of enormous matter and energy and activity separated by huge voids. It turns out that ordinary gravity-- even Newtonian gravity, let alone Einstein's fancier version that we looked at in class, general theory of relativity-- can account for that structure across these scales from meters or kilometers up to tens of billions of light years. The point is that there's a pattern to it. Matter is not uniformly smushed out in space. that these gravitational frameworks are sufficient to help us make sense of this hierarchy of scales, of structure across large distance scales. If we assume, to start, there's some initial, very tiny lumpiness to begin with, if we assume some very tiny inhomogeneity, a little bit of unevenness in the distribution of matter and energy at early times, then gravity will do the rest. Gravity will make those regions that happen to have slightly more matter or energy per unit volume than average-- the gravitational force will then attract more and more matter andenergy to those local regions. more and more uneven over time. So a challenge for astronomers for a century or so has been to try to make that account more precise and more quantitative. And there have been two main conceptual ingredients, especially as we'll come to in the more recent versions of this in the era of particle cosmology. One of the sets of tools, not surprisingly, is some theory of gravity. And the other main ingredient especially, as I say, refined in recent years with insights from high energy nuclear and particle physics. Nowadays people are pretty well convinced consists of things like quarks and gluons and even some more exotic particles like the Higgs particle. So we have these two ingredients of the structure and behavior of space time as governed presumably by Einstein's theory. And then the stuff that's filling that space time, an idea about matter, especially how matter behaves at very high energies and densities. So with those two ingredients, the goal has been, again, for many decades to account for the observational features of our universe even on very large scales. Einstein himself and then soon several other colleagues began applying these equations not only to local phenomena like, say, the warping of space outside the sun. His friend Karl Schwarzschild first found an exact solution for very early in this work not only for local phenomena, but actually for global phenomena. They took three particularly simple forms. Depending on the amount of stuff, depending on the distribution of matter and energy, if you had more than some critical value, you had a 'Goldilocks' situation. a critical value that came from the equations themselves above that, an overdense region, space itself would warp back onto itself like a closed sphere. If you had less stuff per volume, if the universe were underdense compared to that critical value, then, in fact, the universe would open up away from itself. You'd have a hyperbolic solution or an open geometry with negative curvature. Only if the amount of stuff perVolume were exactly equal to the critical value would the sections of space be flat. Einstein thought that was horrible. He had a very strong aesthetic and philosophical preference for a universe that had no beginning that was simply static. But some of his colleagues who began pursuing these cosmological solutions began to realize that the universe could not only have a shape at a given moment in time, but the shape could change over time. You could have expanding or collapsing solutions, also strictly consistent with Einstein's equations. And they could apply not only to local physics like the warping of spacetime outside a massive object like the sun. for an infinite expanse of time. But other colleagues showed at least it was consistent with his own equations to have universes that would change over time, that could either expand or contract. That was actually a prediction made by some of these colleagues even before some empirical evidence began to come in starting in the late 1920s. Hubble found this remarkable trend that the further away from us a given galaxy was, the faster it tended to be moving away from me further still. So you can actually then work backwards and say for how long has our observable universe been stretching? When did this stretching or expanding phase begin? Georges Lemaitre was at the forefront of this work, starting in the 1920s and throughout the 1930s. He was an ordained Catholic priest and an MIT trained PhD astrophysicist. He studied briefly in Cambridge, England with one of the first converge to general relativity, Arthur Eddington. And then he came to MIT to finish his PhD and then was finding many of these solutions to Einstein's field equations even before Einstein did. And it's consistent with the beginning of that expansion being not quite 14 billion years ago, billions of years ago. relevant in the light of data like Edwin Hubble's about the expanding universe. Lemaitre was one of the first to start thinking about playing that filmstrip backwards to say if things are moving further apart from each other on average today, and if the universe in general is expanding today, then was it, in fact, smaller at earlier times? And what if you ride that all the way back? Was there a primeval moment, was there a single moment when all the matter of the universe, at least all of the matter that we can see, was actually on top of each other? Lemaitre was calling it a primeval atom, that there was this initial fireball from a very, very hot, dense state. And he was very eager to understand the early stages of that expansion. That's where things stood really through the 1930s. And then soon after the Second World War, new groups began coming back to these somewhat old questions. Some of the newer groups had experience with things like the Manhattan Project and in general were better versed in things like nuclear physics than had been known even in Lemaitre's day. George Gamow was advising two younger physicists, Robert Herman and Ralph Alpher. They were coming back to some of these questions about the very early universe inspired by the writings of Georges Lemaitre. And in a series of really quite ahead of its time farsighted work starting in the late 1940s, this was a trio that began coming back in a big way in the '50s and '60s. It was much like the MIT Rad Lab, they worked on things like proximity fuses and so on. The Big Bang model suggests that the universe was very hot and dense at early times. The conditions in which these elementary particles would find themselves should be quite different than what we find commonly around ourselves today. Temperature, after all, is just a measure of kinetic energy of motion. So you have a very high temperature. It could've been, for example, higher than the binding energy of stable hydrogen atoms. So if that were the case, then every time some positively charged nuclear particle like even just a single proton would approach or be in proximity to a negatively charged electron, they might begin to form a stable electrically neutral hydrogen atom. At early times in cosmic history, the universe should've been opaque. You literally wouldn't have been able to see anything because the mean free path of any given photon would be very, very short. The photons would each be trapped, kicked like soccer balls between all these loose electric charges. Light can't propagate in a charged plasma because it's always bouncing between these very nearby free electric charge. So they could calculate how to make a proton. Proton would then piece all this together. When would that effect go away? Well, when the average or ambient temperature fell below the average binding energy of a single hydrogen atom-- and that would happen at a distinct moment in cosmic history. So as the volume of space stretches, as you have an expanding universe, the average temperature of all the stuff inside it should fall. It should fall in a quantitatively calculable way, again, using Einstein's equations. So again, they put numbers to that and say, well, at a particular moment in time, now using the modern values-- they had the right idea. years, after the start of that stretch after that primeval atom begins to expand, the ambient or average temperature of all the junk inside that universe should've fallen below this Coulomb attractive energy for neutral hydrogen. At that moment, the average energy per photon or per elementary particle would fall. So only at that time, a new phase in the universe would begin to unfold. The universe would be filled with neutral atoms of hydrogen. And now you have a mean free path for light that's arbitrarily long. energy continues to redshift. They lose energy as the universe continues to expand. So the energy of those photons would've started at the equivalent of around 10,000 degrees Kelvin and now today would be much, much,much lower than that. The universe has been expanding and draining that average energy per particle over time [CLEARS THROAT] so that today the universe should be filled with this remnant glow. This is all work that they predict around 1948, '49, '50, Gamov, Herman, and Alpher. out I don't attend dance parties very often. This is what the internet tells me they look like. If you just Google "dance party" and throw away the bad pictures-- anyway. So at early times, the DJ's playing some raucous house music, and everyone's just jostling around. The average energy per dancer is very high. That's like the charged particles where the mean free path is effectively zero. No one could cross that dance floor. And then at a calculable moment, if the DJ knows what she's doing, she'll put on some slow music. And you start having couples form like in Harry Potter at the Yule Ball. Gamov, Alpher, and Herman were putting real numbers to to try to make sense of these different phases of the very early universe. They predicted as early as 1948 that there should be this remnant glow from the Big Bang. And the question was, where is it? Well, almost 20 years later, two radial physicists working at Bell Labs, Robert Wilson and Arno Penzias, were using a new horn antenna sensitive to radial microwave and radial band frequencies. This was basically left over from the early telecommunications age. actually given time on this telescope not only to fine tune the corporate program for telephonics, but also to conduct actual radial astronomy. This should've been among the most precise instruments available on the planet for that band of the spectrum. And they couldn't get rid of a residual hum. At one point, they climbed inside that huge horn antenna on their hands and knees to scrub out what they graciously called special dielectric materials from pigeons who had made a nest in there. in Southern Jersey. They were close to Princeton. They all got together. They said, oh, what you found is actually the remnant glow from the Big Bang. This residual hum in your receiver consistent with an energy of about three degrees above zero, three degrees Kelvin. The average energy per photon had fallen steadily since the time when they were first released in that early dance party. Soon afterwards, they were very soon afterwards awarded the Nobel Prize for actually detecting evidence of the Big. Bang. The idea was the whole universe is filled in the early times with very high energy particles that are at early, early times too high energy to form stable, electrically neutral atoms. And so from every part of space, from every single direction in the sky, those photons began to move freely at this single moment in time. So basically, the universe should've been filled with light, originally avery high energy. And then actually the energy of that light should be falling as the container expands, so as the average energy inside that balloon goes down. a galaxy there, a quasar, a particular bright star in our neighborhood. The photons were everywhere. And it's like sitting in a bathtub full of these photons. And they're just losing their energy as the overall size of space continues to grow. The idea was that there should be-- so it's not just that they should have a particular temperature. They should be everywhere in the sky was the idea, a uniform pattern. So if they could point that radial telescope in any direction, and they should find more or less the same signal, which is indeed what they were finding. everywhere. So every part of space that we could see today once had been at the Big Bang, so to speak. The Big Bang happened there. It happened at x equals 0, and x equals 1, equals 2. But I say all that as if that's obvious. It's not obvious. I'd be glad to chat more about it. But that's the kind of reckoning that people like Lemaitre got very comfortable with starting in the '20s and '30s. This day or let's just say earnest disagreement over what's called the cosmic distance ladder. We can get the velocity from these very fancy spectroscopic-- I say we. The people who do it are actually astronomers. They kindly share their information. I don't know how to do it well. But one can do it very, very well. What's hard to do is to calibrate. How far away is that object right now, let alone how quickly is it continuing to move away? compared to modern day values in Hubble's time. In fact, his value was-- well, let's see. 500 versus 70. So what we now call Hubble's parameter is roughly 70 in appropriate units. And he measured 500. So he measured a much quicker average rate of expansion than what we have mostly settled on today. But the basic picture was there. The picture was enough to get a small number of people to pay attention to Georges Lemaitre's otherwise quite obscure mathematical solutions. whether we agree with the number he inferred of the actual rate, it seemed pretty clear to many people at the time that this was consistent with an actual overall expansion, with the change over time. And that made these seemingly pure mathematical solutions like Friedmann's and especially the follow up work by Georges Lemaitre, that made those mathematical solutions look much, much more curious and interesting than they had prior to Hubble's data. So this is a, I think, safe to say, remarkably successful set of ideas that eventually becomes called the Big Bang model. to give real quantitative teeth to these internal phases or intermediate phases by people like George Gamow and his younger assistants. And it starts to match observations really quite well. And yet we're not done. People began to get worried about some of these features of the Big Bang model not only to cherish its successes. So for this next part, it's actually really helpful to adopt convenient coordinates. If we accept the notion that there is a universal stretching of space, then it'sactually helpful to adopted coordinates that take that into account. space in between is stretching. And you can accommodate that by inserting this one universal stretching function called the scale factor. So the distance between, say, the Milky Way and the Andromeda galaxy at any given time, the physical distance really would change. This is actually called conformal time. That might remind you of our beloved friends, the 19th century Cambridge Wranglers. We're really doing a Wrangler-ish thing here, very similar idea, to adopt coordinates for the time, for the rate at which we think clocks should tick. what we call conformal time, often labeled by the Greek letter tau, is basically a variable tick rate that is really convenient because then we can start making a dynamical changing spacetime look just like the spacetime of special relativity. In these special, very simple fine coordinates, light just travels on 45 degree diagonals. We sit still at a fixed value of comoving location. And then light comes to us at 145 degrees. That sounds very abstract. We do that all the time. This is just. an example in space time of a conformal mapping of a sort that we all use every day like a Mercator projection. So what this does is it inserts certain kinds of location dependent artifacts. We're doing the same thing here. We are stretching our time coordinate so time gets more and more stretched out towards earlier times. And it makes other relationships remarkably easy. Likewise our conformal maps here make the paths of light, for example, very easy to follow. When people begin using these convenient coordinates, they also go back to some questions about or features of the Big Bang model. Robert Dicke was an expert in microwave electronics, a radar Rad Lab veteran. He went back to Princeton and became very interested in general relativity and cosmology. In 1961, he published this alternate to Einstein's own theory of gravity, the Brans-Dicke theory ofgravity. He introduced this conundrum in 1969, so soon after the discovery of the cosmic microwave background radiation when people began to take the Big Bang model more and more seriously, including Robert Dicske. stuff per volume, the actual density of matter and energy per volume. If omega is larger than 1, you have more stuff for volume. You expect it's open or hyperbolic geometry. So far so good. Then Dicke plugged this quantity into Einstein's own equations. A universe should generically become more and more different from flat over time. And so this solution that looks like the Goldilocks solution, the spatially flat solution where you have just the right amount of stuff per volume is actually an unstable solution. If a universe started out being close to but not identically equal to flat at early times, it should look nothing like spatially flat at later times. So the difference from a flat universe, the deviation from spatial flatness, generically should grow over time. As Dicke points out, you have these exponential fine tunings for the universe to be even remotely close to a flat or Euclidean-like behavior today, which is looking more and more consistent with observations by the '60s and '70's and '80s. equal to flat, this parameter omega was, say, 0.3. And yet a measurement of anywhere near 1 today suggested that it had to have been exponentially close to 1 at early times. And that seems like this very strange or unexplained fine tuning. If the universe has been stretching for 14 billion years, what set it to be so arbitrarily close to spatially flat given that is an unstable equilibrium point? That became known as a flatness problem. That was introduced by Bob Dicke in 1969. And 10 years later he introduced the next big real conundrum for the Big Bang model. years later, Dicke and Peebles introduced the second big conundrum. And this one's called the horizon problem. So now let's go back to this very convenient, conformal diagram. I'm mapping the history of the universe using comoving distances. So I've taken into account that universal stretching of space and that variable clock rate, that conformal time. According to this, we should be receiving these microwave photons today from literally every direction in the sky. This goes back to Steven's question. Imagine you have a three dimensional version of this. Einstein's theory says light travels at a fixed speed at least according to Einstein's theory. So if the universe has only been around for so long, then light could only have traveled so far. That's called the horizon distance. What's the furthest possible distance that a light beam could've traveled traveling at that constant speed of light for as long as it was able to? So even though an actual physical light beam couldn't have traveled because the universe was optically opaque, any information, any physical signal, any force, anything that is limited by Einstein's speed limit should only be able to travel up to and limited by the speed oflight. The universe was still so young that the furthest possible distance that any causal influence should've been able to travel was a tiny fraction of the distance across which we actually measure remarkably uniform signals on the sky today. That became known as the horizon problem. And this was heightened as more and more data came in. It became clear that signal really is uniform to one part in 100,000. It was at 1,000th of 1%. That signal is remarkably uniform to a tiny fractions of a percent. is uniform across every direction we look in the sky today, even though it's coming from all these regions that when that light was emitted couldn't have possibly had any physical interaction with each other. That becomes known as the horizon problem. So why on Earth would the CMB be so uniform today to this exponential accuracy from regions of sky that were never ever in causal contact? Plus, why on earth do we have this distribution of scales that I started off in the beginning? Where does large scale structure come from? Oh, I'm sorry. I skipped ahead. The Big Bang model has still had to assume by fiat with no real explanation that there was some initial lumpiness, there's some inhomogeneity that over time could then grow to become this cascading hierarchy of scales. So we'd have super clusters of galaxies separated by huge voids and all the rest. That's the point of this series of ping pong balls distributed through space. And that's what it's like to have these causally disjoint regions emitting these photons with the exact same energy. the Big Bang model had some amazing successes but some pretty stubborn quandaries as well. So I'll pause there again and ask the questions about that. Any questions on the shortcomings of the Big Bang as people began articulating them throughout the '60s and '70s? Feel free to jump in or use the chat or either way. And again, there's more on the quantitative details of that in that optional primer you can find on the Canvas site. So Fisher asks, is it useful to think of the universe as spherical still? Yeah. These pictures get pretty hard. like circa 1980. Here's a very young smiling Alan approximately 40 years ago. He was wondering about these questions as well as we'll see in a moment. But he was, however, coming at this having been trained at MIT in particle theory. He wasn't trained in relativity or cosmology. And he was much more the same generation as Tony Zee, whose work we talked about briefly in the previous lecture. When Alan was in graduate school, he was studying high energy physics. He wound up doing a series of postdoctoral studies. but he was haphazardly encountering some of those questions, again, very much like Tony Zee around the same time. What Alan was interested in was in things like spontaneous symmetry breaking and the Higgs mechanism. That was all the rage for a lot of particle theorists in the early and mid '70s by then. And he was wondering about shapes for the potential energy function of that Higgs field that might have a extra structure. There might be a kind of dimple to that energy function. or relax that energy arbitrarily quickly because it's stuck in this metastable so-called false vacuum, then that could have implications for the global shape of space and not just for the behavior of elementary particles. Alan is unbelievably anal retentive and writes everything down and has pretty neat handwriting. A lot of people who write things down and have egregious handwriting, and there's more people who don't writing things down. And so I note the date. 41 years ago to the day-- today is December 7-- to theday, he was up very late as is his wont piecing together his ideas about these Higgs like functions with these funny metastable states. Einstein's notebook is now on display in the Adler Planetarium in Chicago. He realized that this kind of feature could actually lead to a cosmologically distinct kind of evolution. If the energy density, the stuff per volume, remains constant, then very counterintuitively, you have a runaway growth in the size of space. That stretch function, the scale factor going back just to Einstein's equations, will grow exponentially quickly, will have a period of accelerated expansion during which universe won't just get bigger. even as the volume grows exponentially. That could happen. Alan began wondering if you have this weird state of matter that was at least hypothetical and of right interest to particle physicists. Alex, I'm going to skip the monopolar problem, but it comes from this discussion as well. And I'd be delighted to chat more about that if you'd like afterwards. But in the interest of time, Alan was worried about some exotic features from these Higgs fields that can get twisted up in some topological shape. But he was really just wondering what happens if the universe gets stuck even temporarily. equations exactly in the form that he began learning from Bob Dicke from that series of lectures, then you have these very different solutions for the average size of space. It grows exponentially quickly. And as Alan and others were quick to confirm, this happens very naturally, or at least it's a kind of feature that one stumbles upon readily, if when studying these exotic Higgs-like fields from particle physics. And then again, realizing that if you study the dynamics, the behavior of these exotic quantum fields like a Higgs field. in a stretching space time, if you take that stretching of space seriously, then you don't even need to cook up those exotic Higgs-like potentials that Alan was first thinking about. Quite generically, you'll have a damped oscillator behavior. This comes from the fact that space itself is stretching. And that alone it turns out is enough to find these self-consistent solutions in which the field moves very slowly. You can imagine it rolling down this hill, rolling down-- sorry-- rolling down slowly as a function of time. shape for the potential energy function just when you think about these fields like a Higgs-like field in the early universe. So then you come back to those quandaries that Alan had first heard about from Bob Dicke. And you ask, how would these things look if you now take into account this very early, very brief phase of exponentially fast stretching of space? The universe today should look indistinguishable from a flat universe because the difference from flatness was driven to 0 dynamically. The latest measurement from the Planck collaboration using a satellite is that this parameter in our actual universe today is 1 to better than a percent level accuracy. In grad school, it looked very much like omega was 0.3. And if you squinted at it, you could maybe make it 0.35. It was not 1 according to the best. In more quantitative detail in the primer, we'll go into more detail about the new measurement in a few minutes. We'll be back next week with a look at some of the other things we've learned about the universe this week. If inflation happened, there should've been a very brief period before what had previously been called the Big Bang. So we're adding more real estate along our time axis. We're unfurling a little bit extra time that hadn't been taken into account in the standard Big Bang model. So then it would at least be plausible there's at least now a causally self-consistent mechanism by means of which the universe could have similar conditions everywhere because they actually were causally connected. smoothness scale we observed. It takes an unbelievably short amount of physical or cosmic time, the time that we measure on our wristwatches, to accomplish that. In fact, it takes about 10 to the minus 36th of a single second. That's all it takes for this inflation. If the universe expanded exponentially just for that sub, sub,. sub blink of an eye, then all of a sudden, the causal structure of the entire observable universe is turned upside down. You basically erase the horizon problem because there actually was a time when all the stuff we see would've been in causal contact. distance and conformal time. The universe was so tiny, it could very easily have been in a kind of equilibrium or at least a causally self-connected state. So during this tiny blink of an eye, the universe grew exponentially quickly and then mapped onto the standard Big Bang evolution. And that alone is enough to address the flatness and horizon problems. It turns out it does more than that as well. That Higgs-like field that was driving inflation, that was very slowly evolving in its potential should've been subject to the uncertainty principle just like all matters should be. first papers on inflation. By 1982, '83, pretty early on, people realized that not only would you have a gross feature of the evolution of those exotic particle physics-like fields. They should also have quantum wiggles because how could they not because they should be subject to the uncertainty principle. These are quantum fields evolving in a dynamical spacetime. But you can actually take into account that frictional damping, the stretching of space, and the reaction of that jittering trampoline. moment, that field would be subject to slight, slight quantum fluctuations in the distribution of energy across space. That starts to yield this tiny little fluctuation in why there's slightly more matter and energy in this region of space than the other one. So now those very tiny quantum scale fluctuations get stretched as the whole universe stretches. As the scale factor grows exponentially, you have the average length between the distance between crests of those tiny wiggles get stretched to galactic and even super galactic scales all within that blink of an eye. higher energy photons in the CMB and slightly lower energy photons. The regions of the sky from which these photons were emitted are telling us about the very, very tiny unevenness in the distribution of matter and energy. There's a tiny, tiny little excess gravitational potential. So the photons we receive today had to spend less energy gravitationally to overcome that. They should have slightly more energy on average today than the average. We should receive it today as being a little less energy than average, very slightly less. ground based measurements as well. And each of these came out 10 years apart with an increase of about a factor of 30 in the angular resolution of the sky. They were the first ones to measure these tiny, tiny fluctuations on the order of about one part in 100,000 but over huge scales. It was like they had very poor eyeglasses. The first of these released their data in September 1992. I was a senior that year. And the [INAUDIBLE] team led actually in part by our own Rai Weiss. solid green line is the generic prediction from the simplest models of inflation, what's the pattern of bumps and wiggles on the sky you should see today. The red dots are the actual observations from Planck team. And in many cases, the error bars are expanded so we can see them with our naked eye. So now not only do we know do we live in a universe that is indistinguishable from flat as inflation suggests we should, but the actual pattern of those wiggled matches predictions to, again, better than a percent level accuracy. should be slightly more or less energetic depending on the quantum fluctuations of that Higgs-like field. There should be primordial gravitational waves as well. This is now much like the waves that Rai and his huge team found locally from the collision of, say, black holes. Inflation says similar kinds of things should've been happening in the earliest moments everywhere in space through this very violent, rapid stretching of space. So a version of these were found by the LIGO collaboration and announced early in 2016. These are not primordial. While atoms are forming, gravity waves would be rippling through them. That should yield a characteristic twisting or curl pattern of polarization in that cosmic microwave background radiation. In March of 2014, a team using the BICEP satellite at the South Pole announced they had actually measured exactly that corkscrew pattern. Unfortunately, pretty soon after that, it turned out the BiceP team had measured data consistent with local noise. This is from their now famous or infamous paper. We had a celebration here at MIT. Many of my friends on the BICEP team managed to find out the Milky Way galaxy is dusty, which we knew. So basically, the signal they had hoped to measure was actually swamped by foregrounds they had not yet been able to control. And this was found by a number of very sophisticated analyzes soon afterwards. So it remains an open question to this day whether these primordial curling, twisting patterns really can be detected. Maybe there's such small magnitude, it'll evade our detection. We don't know. makes specific predictions for what we should see on the sky today, including very minute statistical predictions for things like the cosmic microwave background radiation. The simplest models fit to unbelievable accuracy despite what my mean dormmates used to say in the mid '90s. So why is the universe lumpy? Why is this cascade of scales? Because space time is wiggly, and matter is jiggly. Now, there's an alternate hypothesis, my final set of slides. I mentioned this last time. And I just want to make it clear. why the universe is so messy is actually because Alan's been generating the mess in his own office, and it's expanded to cosmic scales. So if you want to study that part of today's lecture, it's probably the most important lesson, you'll ever take away. And I'll be glad to stay a bit longer if people have questions. Again, I'm sorry for running late. Feel free to drop off if you need. Any questions on that? The photos in Alan's office are on Canvas.

ROUGE-1: 59.36, ROUGE-2: 57.38, ROUGE-L: 56.06
BERTScore: 65.35

==============================================
==================== [72/100] ====================
Summary:
The Peloponnesian War is over. No sooner is it over than another kind of trouble starts. The irony of that is really quite extraordinary. Power has a certain life of its own. The capacity to be able to do something without somebody preventing you makes you think about what you might do in ways that you never thought about before. When you didn't have the power to do it, this is what happens to the Spartans. They find themselves presented with choices that they could take. something they couldn't forget, they were desperately outnumbered at all times by people who hated them and whom they lived off. So, the notion of leaving with an army from the Peloponnesus at any time was always a questionable proposition, even though sometimes it was necessary. For the first time there were lots of Spartans, who had lots of money and of course, as you know, not only was that not a characteristic feature of Spartan society normally, it was forbidden. The laws in Sparta did not permit coins. Some Spartans wanted to contest control of the Aegean and of the coast of Asia Minor. This would require money but would also make money available, he says. In a certain sense, Spartans who took this point of view had it in mind to take the place of Athens as the great imperial power. That was a possibility. But in any case, many a Spartan would have been deterred by that prospect, and again by the prospect of having to have a fleet, because there was no. way to pursue this third policy without having a fleet that began to approach the power of the Athenian fleet when it had been strong. It meant using not the traditional Spartan military advantage--hoplite soldiers fighting infantry battles, but also rowers and expert naval people. I don't have the time to go into a detailed account of how naval warfare was carried on in the Greek world, but it's easy to forget that in addition to the rowers of whom there were 170 in each trireme, they made the thing move. They were that and they were more than that. By the way, it's a very nice word, because all the words that have to do with governor, government, govern all derive ultimately from the kubernetes. So, this would have meant that all kinds of people who were not Spartiates would be critical for the success of such a mission. So many a Spartan felt that was too much of a derangement of Spartan life and didn't like it for that reason. But you could still be in favor of a middle policy which would mean extending Spartan power or maintaining Spartan power on the Greek mainland. of the first rank, at least somebody who could sit equally at the table with the Spartans rather than subordinate to them. The fear that some Spartans surely had was that if the Spartans simply stayed in the Peloponnesus, Thebes would become the master of Attica. When you have a power which is superior to that of the other states, but you don't conquer them, the question is do you want to relate to them as the Greeks would have said as a hegemon? part of the war they won two important battles of which the final battle was critical, the Battle of Aegospotami. If you really look at the whole story it's not at all clear that the Spartans ever developed the kind of system that would produce a navy. So, that was a practical limitation. Well anyway, however that might be, the man of the hour in 404 was Lysander, the great victor of the Peloponnesian War. His policy was the extreme policy, the "let's conquer it all" policy. he did, as a few others like him in the last years of the war, rose to be a general and the very best general of all. But he was a man of extraordinary ambition, and the ancient writers tell us that he had developed the notion of actually bringing about a revolution in Sparta. If he was going to do anything like that, even if he was only going to try to retain the position he had achieved of tremendous influence and power, he would need to have a command and money. His policy for Sparta was very much a policy that fit the needs of Lysander. ten men chosen from the local people who were friendly to him, who were reliant on him, his people, his puppets, if you will. To make sure that they were safe he placed a Spartan garrison, or at least a Peloponnesian garrison in that city led by a Spartan commander called a harmost. All of these people, the harmosts, the decarchs were all his creatures, not anybody who had any independent power or influence, simply his people who did the job for him. Empire was different from the Athenian Empire in a variety of ways. The Spartans had simply betrayed the Asiatic Greeks whom they had engaged in the rebellion against the Athenians. In many cases, frequently, these governments established by Lysander were tyrannical and rapacious. The oligarchs whom he had restored to power in Samos loved him so much, and were so grateful for what he had done, that they held religious ceremonies on the island and literally worshipped Lysander. This is the first time in Greek history that anybody had received such treatment. this elevated his influence and power, everybody wondered at him and so on. On the other hand, it presented a problem, because you can imagine how that went down among the aristocrats of Sparta. So, there was jealousy and resentment and fear at Sparta that something bad was going to happen to the Spartan way of life. Pausanias and his tradionalists bided their time for the opportunity to put a spike into this development. There were other things that were flowing from what I've already described that were threatening the traditional character of Spartan life. The Law of Epitadeus was a new law about inheritance in Sparta. It allowed people to buy someone right while they were still alive. People who had been raised as Spartans and expected to inherit their father's property would sometimes find that they had been cut out and now they were Spartiates by birth, but they lacked the necessary wealth, necessary land to provide for them. If you wrote somebody into your will, you were in effect giving him money after you died. So, meanwhile he could serve you and be your political supporter. for their meals at the common mess and so they could no longer be Spartiates in the full sense. A term was discovered for them, they were called hypomeiones, which means inferiors and some of the guys who rose to power late in the Peloponnesian War as generals. So, there is Sparta coping with these various problems and trying to decide how to handle their future and I'd like to shift the scene now to Athens. Athens, which had been the greatest empire that the Greeks had ever seen, had been reduced now to total defeat. fear that the same fate they had visited upon some states that had defied them. In both places, the Athenians killed all the adult males on the island when they had finally put an end to the siege and sold the women and children into slavery. The Athenians had every reason to fear that that might be what happened to them. Instead, with Lysander very much in charge, they placed in power a small group of oligarchic Athenians just as he had the same kind of people in the rest of the empire. the great rhetorician and sophist Gorgias and he was also in the circle of Socrates, along with Plato and Xenophon and various other bright young men of the upper classes in Athens. Also, he was a poet, an orator himself, a philosopher and so on and some of his fragments remain for us to look at. But one thing that he was by 404 was a bitter enemy of the democracy. He had been exiled or had voluntarily taken exile, in order to get away from the democracy, and was determined now that there should be no democracy in Greece. kind of idiotic idea that a democracy would come up with so that democracy itself was seen to be not just--how can I put--Let me say it was seen as inherently wicked. It violated what seemed to be the truth about human beings and which was very much a part of all Greek tradition from the first time we hear about it in Homer until--well forever. The Greeks thought a division into two kinds was the right kind, the most important kind, a division between the high and the low, between the good and the bad. guys and therefore you shouldn't have anything to do with ruling anybody. So, that was the basic widespread view of what was natural in the Greek world. Now, you add to that that they've just lost this terrible war and you could point to what seemed to you to be both a wickedness and foolishness. How in the world could anybody think democracy was a good thing after that? Lest you think there's something special about that, that's such a characteristic of the human race. had to do with the rightness or the wrongness of wisdom of the foolishness of the kinds of arrangements that you had. Critias, in any case, was determined that Athens in the future would not be a democracy. In fact, it looks like he was very much taken with the virtues of Sparta, because Sparta had won the war. So, it's easy to say the characteristics that the Spartan state had must be good ones, because they can do the most critical thing that a state can do, win in competition with the other. Lysander had in mind to establish in Athens the closest facsimile he could of the Spartan Constitution. He was trying to do something like that, but it was going to be narrow, a smallish number of people were going to control the city. Lysander agreed to the idea of making the Thirty compose of twenty men who were Critias' men, very extreme oligarchs, but allowing Theramenes, an Athenian general, who was very clearly not an old fashioned democrat. But Athens, of course, was also inhabited at that time by all of the exiles who had been sent into exile during the democracy. The Thirty ruled between September of 404 and May of 403, just a matter of months as it turned out. They established a council of 500--well, that's the same number as the Athenian council, but it was quite different. It was made up of extreme oligarchs; they were given judicial powers. The Thirty began with an act that was not unpopular by putting to death all the sycophants that they could find and identify, but they also put to death well known leaders of the democracy. The Thirty limited citizenship, active participation in the government of any kind to only 3,000 Athenians out of what would have been at least 21,000 and probably more. Only these had citizen rights. The rest of the Athenians did not. And so that's why Krentz suggests that this is not an accident; that it's a conscious effort to model the future Athenian state upon the great successful, admirable, Spartan state. That's why Theramenes didn't like that. troubling for the future for Theramenes. He pointed out the contradiction, he says, how clever is this? Here you are, a minority in the state, and instead of trying to bring on more people to make yourselves stronger, you're driving out people and guaranteeing that you will have more people against you than you have for you. Well, pretty soon people objected to what the Thirty was doing, made complaints, and the Thirty began to go after them. Sometimes when things got really bad, when the Thirty needed money they actually put people to death just because they were rich, so that they could take their money away and this of course increased the amount of resistance on unhappiness. So that finally a small, I want to emphasize small, very small group of Athenians fled the city and went into exile to neighboring cities. The cities that were most receptive to these anti-Thirty, anti-oligarchical,Anti-Spartan people were Corinth, Megara, and Thebes. The answer is, they are both angry at the Spartans and I think fearful that the Sparta that is arising now will be a menace to their autonomy. of Athenians and the one town that was most important from this purpose was Thebes. The leader, the most important of the leaders of this group of exiles, they wished to restore the old democracy. He and another important politician by the name of Anytus actually began a counter revolution and the. with only 70 men they went from Thebes to a natural fortress in the mountains between Boeotia. The sources differ but the accounts that seem to be most plausible are most plausible. and Attica, a placed called Phyle, and built a fort there to which they hoped other discontented Athenians would flee and join them in the resistance. I'm using the word resistance, and it brings to mind of course an analogy that has always struck me as helpful in comprehending the situation confronting the Athenians at this time. To my mind, it is helpful to think about France in June of 1940 after the Germans had defeated France and occupied part of it and left the other part unoccupied, but absolutely beholden to the Nazi Regime. Now, a Frenchmen had three choices, just as the Athenian did. One possibility would be to join up with the new regime. Others would do what Thrasybulus did, and in France it was the De Gaulle who did this. people's minds. It was a terrifying prospect to tackle this regime, which looked like it was unbeatable. The Spartans ruled the world. What could anybody expect to change that situation? Just as the Nazis looked like they were in business for the thousand years that Hitler had claimed he was going to have. So, it didn't look like you were a very courageous man if you joined De Gaulle. They thought he was a goddamn fool, there was no chance, this was idiocy. They tried to win. as much as they could in collaborating with the Germans just to make their--the fate of the Frenchman less hard and to help France in the future in that way. That's the way it was with most Athenians; most Frenchman and most Athenian didn't do either of those things. They kept their heads down and tried to live their lives as best they could. I think what you need to understand is happening and this all puts what Thrasybulus and Anytus, and their friends did in a very special kind of a light. went to fight. Others, like Lysias the orator, used his money to hire mercenary soldiers to fight for the Thrasybulus democrats as well. Well, the first test came in the month of January. There were these seventy guys or so up in the fortress on Phyle. By now the Thirty were worried enough about this nascent army to send an army of their own, much bigger, to try to get them. And really the British--the English fleet didn't do anywhere near as much damage to the Spanish fleet as did the winds. of the Protestant Wind, which had come along to save the new English faith against the forces of the Pope. Well, if they can invent a Protestant Wind I think it's okay for me to speak about the democratic snow that fell on Phyle that went. That's just what happened. A big snow storm came up, and so when the Forces of the Thirty came after Thrasybulus, they just couldn't get there; they were fought off and they had to retreat. As they retreated the seventy came down after them and chased them, and killed them as they fled, and did a certain amount of damage. forces in the state had come, and we might mention also that the ancient sources estimate that something like 1,500 Athenians may have been killed by the Thirty tyrants. Well, that's a very large percentage of the population when you think about how many Athenians there were. And finally, that caused so many of their relatives and friends to turn against the Thirty and to join forces. When the Thirty brought an army out to try to defeat him there he defeated them. They were forced to flee to Eleusis on the northwestern frontier of Attica, and the democrats were in position to take control of the city again. A commission sent from Sparta to sit with Pausanias sat down with these Athenians and worked out a reconciliation for the future. There would be an amnesty for anybody, no matter what, except for the Thirty themselves. Small groups of people who were thought to be especially responsible for the nasty things that had happened in Athens were not summarily put to death. They could submit their accounts at ansettlement. The Thirty were the police force, so to speak, the head of the security forces in Athens and so on. Thrasybulus and his friends in control in Athens. They reinstated the Democratic Constitution pretty much as it had been before all of this had happened. They kept closely to the amnesty; they did not in fact, prosecute people that they should not have done. Aristotle in his Constitution of the Athenians goes out of his way to praise this successor Athenian Regime. The idea of sharing citizenship with anybody who was not, so to speak, a member of the family, was beyond what they would contemplate. as they could, to achieve stability. It's a very rare thing. What the Athenians did was very abnormal. It was evidence, I think in part, of a great deal of wisdom on the part of the key leaders at the time. I think there was a general kind of good feeling that made that sort of mass execution something that seemed foreign and too undesirable. So, if we look at Athens in 401, the democracy has been completely restored and I'd like to draw my comments about this to a close by focusing on Thrasybulus, a man, who I think probably none of you had ever heard his name when you came into this class. A Roman historian of the first century B.C. wrote the following about Thrasybulus: "If excellence were to be weighed by itself, apart from luck, I believe I would rank this man first of all" A few years before 180 A.D., Pausanias the great travel writer of antiquity, wrote his guide to the famous and historic places of ancient Greece. "His is the first grave and after it comes that of Pericles," he says, "in every way the greatest of all famous Athenians"

ROUGE-1: 50.55, ROUGE-2: 48.71, ROUGE-L: 49.10
BERTScore: 66.01

==============================================
==================== [73/100] ====================
Summary:
The coherent state has a simple definition, simple but subtle. It's an eigenstate of the annihilation operator, and it has a complex eigenvalue alpha. The person who popularized those states was Glauber, and he got amply rewarded for that. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu. today is that the coherent state is a complex number. The coherent state has a time evolution. It moves in a circle. And this is really the phasor of the electric field associated with it. So coherent state, the alpha value is directly related to an electric field. That's why this state is closely related to the classical limit of the electromagnetic field. We looked at the fluctuations and showed that it's a Poissonian statistic. And then we use now-- once you define something, you can use it as a tool. I think the standard deviation here is-- what is it, square root 1 over square root 2? Because the Gaussian has usually 2 times sigma squared. And that showed us that the coherent states are not orthogonal. So therefore the coherent state is not a delta function in the causal probability. It's a little bit blurred circle with an area on the order of unity. And you have some homework assignment to look at it. You can read pretty much everything you want from this diagram. look at a number state-- Well, you often know in quantum mechanics, number and phase are complimentary. If the number of photons is fixed, you know nothing about the phase. And indeed the quasi-probability of a numberState is a ring. It has no phase. It's completely random phase over the 2 pi circle. The energy is sharp of aNumberState, since the energy is e squared. But what you get is also something blurred on the order of unity. In the analogy with the harmonic oscillator, the electric field was a minus a dagger. In those quasi-probabilities-- and we will see more about it-- something which is sharp in momentum is a sliver parallel to the x-axis. So therefore, since momentum is electric field, you always get the electric fields by projecting onto the vertical axis. And if this quasi- Probability starts to rotate due to the time evolution, we get an oscillating electromagnetic field. fuzziness. For instance, if you would say the phase is determined by the 0 crossing, you don't know exactly when the0 crossing happened, and that corresponds to an uncertainty in the phase. So this fuzziness here is the intrinsic uncertainty of quantum physics. So that's what we want to discuss today. But then we will immediately start with non-classical states. And that is, well, if this area is determined. by Heisenberg's uncertainty relation, what can be maybe deform the circle into an ellipse, and these are three states of light. In quantum mechanics, you cannot measure x and p simultaneously. These are non-commuting variables. So therefore, what happens is, if you now define a phase space function, which is done in quantum mechanics textbooks, you can actually do it in three different ways. And the three different way are Q, P, and W. The definition of those functions involves the operator definition, a and a dagger. If you define something in units of X and p or a and the dagger, you could actually do something in three ways. have a product which is fully symmetric i in the ordering of x p, which is anti-normal or normal. The reason why I picked for the course Q of alpha is that it's a real probability, it's always positive. The other guys, P of alpha, can be positive or negative. And also, W of alpha can be negative or positive. But the fact is all three have their advantages and disadvantages. So they all have pluses and minuses. And as a result, it can be written like this. the coherent state is now not this Gaussian. It doesn't have thisGaussian distribution as a course of probability. The probability of the coherent state alpha has a delta function peak at alpha, which is sort of nice. And the number state is not a ring of a finite radius. You would naively expect the energy is sharp. The square root of the energy's electric field, shouldn't it be sharp? And indeed, it issharp. It's actually worse than aDelta function. The Wigner distribution is something you actually find in most quantum mechanics textbooks. The Q and P distribution are more common in quantum optics. The projection on the x- and y-axes are indeed psi of x squared, psi of p squared. So you get actually the x wave function and the p wave function. But of course it has a disadvantage that it has negative values, and try to explain to your next neighbor what is a negative probability. Some people don't get it. actually see negative probabilities spring out the non-classical character. In the bigger picture, all the three distributions are the same. It's more sort of on the level of whether something is a delta function or has widths unity. So on the small scale, it matters. But if you map out something on a bigger scale, they are all related to each other. And for the rest off today and the next class, when I show you those phase space distribution, I'm not completely rigorous which of the three functions I've really chosen. want to understand in more depth the fluctuations. And in particular, I want to show you that coherent states are minimum uncertainty states. So by identifying the vertical axis with p, the horizontal axis with x, we immediately expect that we find a result related to the Heisenberg uncertainty principle. And what we find is that it's square root h-bar over 2 omega and, for delta P, it is squareroot h- bar over omega 2. And maybe, Colin, to address your question, I could imagine that. coherent states were maybe invented by simply saying, We have an harmonic oscillator data. We want to find the minimum. uncertainty states for which the uncertainty in x and p, when expressed in natural units, is. The coherent state is the solution to the following question. If you plot the quasi-probability distribution, you give yourself an uncertainty area. The minimum uncertainty state means that the area of the 2 uncertainties, delta P times delta Q is h-bar over 2. In the real part of alpha times the uncertainty in the imaginary part ofalpha for the quasibability, then this is 1/4. OK. So what we have learned is that-- just one second. We have learned about one way to characterize uncertainties-- the quantumness of the electromagnetic field. The fluctuations of the intensity are usually expressed by the second order temporal coherence function. The classical description is you measure the intensity of light. And then you'll see what is the difference between quantum states of light and classical light. But I always feel that if you want to really appreciate the quantum character, you have to know the classic description first. It is simple. It's quantum mechanical. It’s exact. That's what we want to introduce now. Yes, this is theSecond order temporal correlation or coherencefunction. the product. And you normalize it by the average intensity squared. So if tau equals 0, it's nothing else than the intensity squared average. And I've left the proof to the homework to show that the classical g2 of tau is always larger than 1. But you can show that this is also the case for finite tau. So quantum mechanically, we will see that the g2 function is not necessarily larger than1, it can be smaller than1. And that's actually an interesting-- you can see-- litmus test for the quantumness. with it and use a classical intensity to calculate the second order correlation function, you get something which is larger than 1. This is similar to what I said before when you want to show that you have non-classical light, you do quantum state homography, measure the Wigner distribution, and show that the Wigneder distribution has negative quasi-probabilities. It's only possible if you have a truly non- classical state. The expectation values would need averaging over time, not over ensembles of I of t. In classical physics, you can determine an ensemble average by taking an ergotic system and observing it at many, many times. The idea is that one system as time goes by will sample all possible states. So in other words, you would actually think, if you switch on a light bulb with a stable power supply, that the light emitted by the light bulb will go through all possible quantum states as time evolves. So how do we generalize that to quantum mechanics? Well, one possibility would be that-- OK. of tau is we measure the intensity now and a little bit later. But measuring the intensity really means absorbing photons. So what is more closely related to an experiment how you measure the correlation function is you want to look at something else, namely at the probability of absorbing 2 photons. And this is your total probability that you can absorb 2 photons out of an initial state. But since you're in sum now over all final state, this turns into-- Now, I could put for you as in the final state is a complete basis. But I can't. In many, many textbooks, the discussion would start with this expression. And you realize yes, for some measurement with photomultipliers, that's what you measure. But I wanted to show you how it is related to the intensity correlation function defined classically. But this looks like it's constant in tau, which doesn't really make sense intuitively to me, because at least classically, it shouldn't be constant intau. Also, I just wanted to give you the structure of the operators. the time argument here. But the fact is that as long as we limit ourselves to a single mode of the electromagnetic field, a single harmonic oscillator, things are independent of tau. And nothing happens as a function of time. It's constant. You can actually say-- and that sort of tells you where the fluctuations come. If g2 of t Tau changes, it comes because you have several modes of theelectromagnetic field, which, as afunction of time, constructively and destructively interfere. But if you have asingle mode, in a single modes-- and what is a single Mode? It's just a sine wave. But when I transitioned to quantum states of light, I decided to deal with only one mode of the light. We should now sum over-- I should put double or triple indices on all the alphas for polarization, for spatial modes, for different frequencies, and we sum over all of them. But instead what I did is I wanted to just show you the simple case. I think you will be thankful for that in your homework, that you only have to look at a's and a daggers in the operator algebra for single mode. The g2 function is related to number fluctuations. It's related to an average and an n-squared average. It is independent of tau. And the reason is we have now limited ourselves to just one mode of the electromagnetic field. We find g2 functions which are smaller than 1.2 modes to get out of phase. But if you have 1 mode, there is no coherence time. And this sort of tells us now where do we find the most non-classical behavior, namely when g2 of t Tau is as small as possible. The Fano factor is-- wants to compare the fluctuations. n square average minus n average squared. The classical fluctuation-- well, I say classical, classical in the simplest case-- are Poissonian fluctuations. So with those definitions, we can now compare the different states of light we have introduced. We started out with black-body radiation, thermal radiation. We defined coherent states. And now finally, maybe the most interesting state from the perspective of non-classical light-- of quantum light-- is the photon number state. number state, the number of photons is an eigenvalue. Therefore, n squared average is n average squared. The Fano factor is minus 1. Sub-Poissonian distribution. And the g2 function, which classically cannot go below 1, is now n minus 1 over n. It is smaller than 1. And you see immediately that the biggest violation for g2 is to go to minus 1 for the case of a single photon state. Any questions? AUDIENCE: Shouldn't it be 0 for [INAUDIBLE]?? PROFESSOR: The g2function? No, if you put in-- wait. Gosh. I'll double-check. Light is not a continuous stream of energy, it comes quantized in photons. The granularity of light due to the photon character is, of course, most pronounced for a single photon. If you've only one photon, you find one photon and for the next photon, there is no photon to be detected. So the probability of detecting two photons is 0. And that only happens when you go down to similar photons. So this is when certain fluctuations are most pronounced, because the energy is dependant on a singular photon. me first address one misconception. You can say, Well, let's just use a coherent state. Coherent states, as I've just shown you, are very classical. They've always a g2 function of 1. And attenuation is not changing it. Attenuation is preserving that. So now I want to show you explicitly why an attenuated coherent state may have an average photon number of 1 but it shares nothing else with a quantum state of 1 photon of n equals 1 Fock state. coherent state with an expectation value of 1 photon is not a single photon. The probability to find 0 photons-- no photon at all-- is actually 1/3. In 2 percent of the cases, you will find 4 photons. If you want to get n equals 1, you cannot just use a strong laser beam or a strong light source and attenuate it. You have to work with something which genuinely creates only 1 photon. It's called the Fock state with quantum number n. The creation of single photons has been a small cottage industry over the last 10 or 15 years. Single photons are often needed for protocols in quantum computation. We can control single atoms. And then we can make sure that single atoms create single photons. It's a little bit a way that we cannot control the bullets which are fired. But we can control the guns. And we make sure each gun can emit exactly one bullet. So that's a way how we can create non-classical light. states of light. So we obtain the quasi-probability distribution by taking the single photon state and projecting it on a coherent state. The ring immediately tells us that there is no phase defined. All the phases are equally probable. And that also means, if you don't have a phase, the average value of the electric field this 0.1. The equation of single photons is essential for studying non-classical light, but also since it's a very active frontier of our field. it's about-- it involves single atoms. But it's a little bit more demanding like that. So you want to take 1 atom home or 1 ion. But the problem is if the atom or ion emits a light, it can emit the light into all directions. And therefore, you have a single photon afterwards. But you have many, many different spacial modes. And in any given mode, it will not have asingle photon. So therefore, what you have to add to the single atom or single ion is-- you haveto put it in a cavity. state decays to the state 2. So in other words, you're not starting with single atoms, which is sometimes more demanding. It has other disadvantages that n atoms have. With n atoms, they have a super-radiant factor n with n atoms. You can get an n-times enhancement of emission into a single mode. So there are real, massive advantages in working with many atoms. But now you know that one atom is in state 2 when you detect the first photon. And then you have the same situation. single photon out of it, which is the photon for the inverse Raman transition when you pump the system back to state 1. There are some uncertainties. We don't have perfect single photon sources. But to involve, for instance, three levels is sort of an advantage, because you're not limited by the preparation of a single atom. You can have many atoms. The atoms are always there. And the moment one atom is prepared in state 1, one photon is released. And if you can get now a single photon in 90 percent of the cases, you publish a wonderful paper. 2, this atom announces itself with a single photon. Then you can gate your whole experiment to a time following the detection of the first photon. And for your gated time afterwards, you have a very, very high probability of finding this photon. Or if you want, you can now do experiments with 2 photons. And now you can do correlations between two different single photon states and such. It's a very rich frontier of our field. You have another question? AUDIENCE: Yeah. Is this also within a cavity now, like the single photon [? reflection ?] in the first test? I don't want to go into details-- but those who have an understanding of that-- is the following. If you n atoms and you prepare one atom here in state 2, you do not know which of your n atoms is prepared. And if you have n indistinguishable probabilities which atom you have prepared, the emission of the photon back is n times enhanced. So therefore, you have actually a system which has an n times stronger coupling to the cavity. Having n atoms makes it much, much easier to construct a high finesse cavity. You get this super radiance increase of the strong coupling for free. The famous Hanbury Brown Twiss experiment was done in the 1950s. It was the first experiment which really looked at g2 functions correlations, which one could say was the beginning of quantum optics and modern experiments with light. You will look at it a little bit more closely in your homework assignment. They're really the world experts in that. OK. Finally, we're not really getting to squeeze light. We start with squeezing the light tomorrow. It's time to go to bed. When you want to find click click-- double clicks in the stream of light-- you have to involve a beam splitter and involve two photodetectors. In principle, you can now find 2 photons which are only a few picoseconds apart, because the first photon is observed by the first detector, and the second photon is detected by the second detector. So what we are asking here when we measure the g2 function is that in a very small temporal window, 2 photons are detected. simultaneously. The classical version is the g2 function is the product of the intensity at. time t times the product at time t plus tau. So what you would do here in this circuit, you would take the signal. from this detector, the signal from that, and multiply the two. This is how you determine I of t times I ofT plusT. So whether you do it in. the classical domain or whether youDo it in the quantum domain, this is the way. how you experimentally measure the second order correlation function. say photon, I should actually say intensity. The intensity splits equally. And if you do the measurement with the coincidence detector, you find the difference between the g2 function, which I discussed earlier. That's actually the only way how you can distinguish a light bulb from a laser beam. But it is the correlation experimental which shows you that you started with a thermal source. It has a g2function of 2, and you can never get rid of it, whereas the laser beam has ag2 function of 1. especially when we have a single photon, the photon can go to only one detector. And that means, for this extreme case of a single photons, the g2 function is 0. Anyway, you will look at those situations in more detail in you homework assignment. Yes? AUDIENCE: Sir, if you know that different for tau non-zero, then even the single mode in the function would have a final g2 [INAUDIBLE],, because there would be some probability. The experiment how it is done is often done as in an open system, where you couple the system to a light source, which is always replenishing your experiment. I think, in essence, the experiment would be done with a single photon light source. But the single photons have a high repetition rate. You have an heralded single photon. You know the term heralded photon. I showed you how to generate single photons. But in other words, what we have focused in the simple description is that we have a quantum state which is prepared-- it's a closed system. And now we do our detection. single photon comes now. You do the experiment, and then you repeat it again. And then you find indeed, that during that temporal window, you will never find a second photon. So this may happen in a few nanoseconds. Then you wait a microsecond, and the next photon arrives. But this is then related to the repetition rate of a single photon and not to the single photon itself. I think you've got the taste. Your homework is a really simple. You just deal with a closed system. The way we can distinguish from a thermal state and a coherent state is through the g2. Even if you do not put in any light, we put in the vacuum state. And you will find that the description of the beam splitter in the quantum state is incomplete. All the laser cooling, all the absorption imaging-- all that would work if you had a single mode thermal source. But the only property which distinguishes a laser from the thermal light source-- we're not taking advantage of it. course practically, if you take a thermal source and filter it down to a single mode, you will be left with only a few photons. You cannot create an intense enough single mode light source unless you use stimulated emission. And that's a laser. So anyway, what Colin says is there are actually more different light sources that just the laser and the thermal light source. There are LEDs or semiconductor devices, which provide photons with interesting statistical properties. OK. We have to stop. I'll see you on Wednesday.

ROUGE-1: 55.86, ROUGE-2: 53.69, ROUGE-L: 51.82
BERTScore: 67.10

==============================================
==================== [74/100] ====================
Summary:
This lesson will first dive into some signal Theory and then move on into things that we're more familiar with things like deconvolutions and using Transformers for next note prediction. The first thing we want to talk about is how can we sample and quantize a continuous time signal. We'll then go into some geometric signal theory and with Transformers and finally how how we can kind of generate sounds using these. The lesson will end with a soft introduction to digital signals and then we'll move on to the next lesson. not very easy for a computer to do given that every operation needs to be in on a continuous time signal. The way that we we can fix that is through the process of discretization or to to make a an analog signal a digital signal for us to be able to process. The two kind of main ways that we can make our signal easier to process is one by taking samples at certain time periods and two by quantizing our level so instead of dealing with A continuous scale we can quantize at certain levels for example a frequency of like 2 4 6 8 Hertz. signal to an analog output we can kind of start by talking about the ADC circuit. This uses something called the SARS ADC algorithm essentially what this is is a binary search to figure out what is my best digital approximation of my analog signal right so I have a continuous signal pass it through my sample and hold circuit. From here we take in our our input and our output is based on the amount of bits of precision that we want to have so depending on whether we want a two-bit approximation a three bit approximation. here we use a low pass filter which is also covered in courses like 16b um the motivation behind this is that we we maintain a signal that's the pass band. We allow every signal to pass when we hit certain cutoff frequency we Wane our signal by a certain factor and that factor dictates the slope of this line. Our signal will continuously Wane after that cutoff frequency is hit on the right is kind of the picture of the approximation where we can approximate a different quantization levels different bit parodies based on the Stars ADC algorithm. are the kinds of bins that we can put our signal into if we have three bits we have a lot more Precision we increase the amount of information that we have. With a bit depth of two our approximation isn't very great with a big depth of three um it's definitely getting better our errors reduce significantly. There is a trade-off though the trade off is compute power how much time do you have to process this if this is something where for example a lot of musicians they want to sample their. voice and Pitch it up very fast right what quantization level do we do we want there. Can we do a lossy pitch up with a uh with by filling in the the blanks in some intelligent way through prediction or kind of note fitting which is an interesting consideration I think given the fact that audio is a continuous time signal um the digitization process and the choices you make matter a lot and because of that this field is so interesting and there's a lot of really didactic work around how we can take these continuous signals. with a whole bunch of things in digital signal processing. If the sampling frequency is less than double of the highest frequency present aliasing will happen. This asserts that you need at least two samples per period. The aliasing phenomenon is incredibly interesting this happens both visually and um auditorily um and aliasing is an entire um topic just based on itself. As you you can see here your approximation gets very different as your your sampling rate increases and decreases if your assembling rate is 0.3 Hertz. also increases we're at one Hertz you're almost perfectly fitting the polynomial on the the points um something interesting to consider is that at a sampling rate of of 0.3 you are fitting a polynictional right because you're you're creating apolynomial through the points that you have. However this polynomal is very not indicative of the actual signal that you're trying to process right while we we can see that this this does kind of capture the trends of our data and that it falls when our data has fallen.  aliasing is the byproduct of poor sampling. A lower wave resolution will result in a modified output signal as compared to the original input that we're trying to process. frequencies that are higher than one half of the sampling rate will be automatically transformed to lower frequency sees that's where information loss stems from. There's a lot of literature about um aliasing effects um including spatial illnessing right um you see that uh there's there's a lots of different ways that aliasing takes place. we we take certain points along this you can see that the image changes we get kind of the gist of this um but this is a a compressed image it contains similar information it allows us to kind of see what's happening but it contains this in a very compressed format super sampling is where um you know this this image is uh take in this this 4x4 uh image and we're kind of running a kind of stride over top where uh we're losing some information in the background as you cansee it really Blends together but in the foreground. um this is is kind of uh and and add add-on um to this presentation it uh doesn't uh really contribute exactly to what we're talking about but I thought this was incredibly cool. With one line in C you're able to to generate Melodies um which is incredibly cool um yeah so please check it out if you if you guys have a chance. The next thing we're going to talk about briefly is geometric signal Theory and how that can tie in to reconstructing signals. Projections are an application of inner products where one vector can be projected onto another Vector and you can kind of see what the projection is based on that. The projection formula is the dot product between X and Y this is I guess you can think of it as a similarity measure between these two vectors. You're dividing this by the uh the norm squared and multiplying this back on X um and through that process you're applying a transformation that allows you to shift this vector. A high value means that they're co-linear right that they's they're very similar to each other. by a certain angle um and then rescale it onto a given vector so projections for reconstructions right um like I mentioned earlier a vector can be reconstructed with a linear combination from its projections onto another set of vectors if and only if the set used is a basis. By defining a Subspace of vectors of certain vectors linear combinations of these vectors can form any Vector in the vector space that I'm interested in um so given that a basis is required the set of vector used must be orthogonal to one another and this is very important as it ensures that that we're maximizing the amount of information gained. The idea behind the the last two sections here was to give you motivation for for how signals work and how kind of classical reconstruction can occur using math that we're all familiar with. This really covers any Vector in R2 um e0 uh we can Define as one zero so a horizontal Vector E1 is zero one a vertical Vector if we look at where we we're trying to project some Vector X onto uh the the e0 space right we can kind of see how the math works out here. familiar with perhaps in terms of how we can use those to reconstruct signals and ultimately how we could use them to generate audio right predict the best uh kind of next node um so looking at the next the next step here we want to use deep learning for reconstruction right where we are are reconstructing a low quality audio to high resolution audio right um and this is this is the kind of uh model framework um that we can used for this um you might notice it really closely resembles a unit which is something that we talked about during image segmentation. to uh kind of increase uh the uh the resolution of a certain low quality image form so as you can see if this is our initial wave our our final wave is is much more populated right we're able to gain information through this unit process. At each layer the number of filter Banks is doubled so that while the the mention along the waveform is is halved the filter Bank Dimension is increased by two. We're reducing the size of our uh of our image but we're increasing the dimension the dimensionality of it. we're developing a representation of these these audio signals so as we pass through the bottleneck layer which is constructed identically to a down sampling block right these connect eight up sampling blocks which have residual connections to the down sampling blocks. What this allows you to do is it allows you. to preserve features and share features that are learned from the low resolution representation of the image into our higher resolution output. The final convolutional layer um has a restacking operation and it does the reordering operation following our our sub pixel deconvolution. after this restacking step um and the the loss function used throughout this process specifically was was kind of a mean squared error loss function so by playing around with different kinds of loss functions you might be able to yield better performance. I thought this was incredibly cool um as it kind of it parallels a lot of Concepts that we talked about earlier on um units um the swin Transformer keeping residuals we talked very very uh very very in depth about how residuals are able to um kind of keep information across solves a bunch of problems vanish ingredients um as your network gets bigger. kinds of techniques are used in a variety of ways to reproduce music from bands from the 1900s. The reconstructed Spectrum after the passing through the unit um has a lot more depth. The SNR signals noise ratio goes down between the the down sample and the reconstructed Spectrum. The listening experience for the end user is uh is improving so yeah these are some of the results that were found from uh this uh this audio um where you have a true Spectrum um and uh you can see the waveform here. waveform and the reconstructed waveform. As you can see on the reconstructed Waveform matches um the kvps of the the true waveform, we're adding color to our our downsampled waveform to to ultimately get something that hopefully resembles our true waveforms better. We're going to kind of uh kind of transition now into Transformers for audio generation right how can we use Transformers to predict the next note for example for example. We want to take notes and for example produce the next notes in a Melody. music realm does provide a different issue than it did for our other two representations um of of of image and text we want to then build the model and train it to predict the next token right the first step takes the form of converting data which is music files into a token sequence which is individual notes. So eventually we wants to start with with this kind of notes format and we Want to tokenize it into something that our model can understand right um this presents a unique problem that we're going to be talking about extensively. The Transformer music model is trying to do sequence generation through next token prediction. We can tokenize this into a series of tokens that all correspond to our vocabulary which is very easy to map by a dictionary to certain Keys. So where our key is are our actual vocabulary and our our value is associated with that. We want to be able to predict that this this will happen um and we we want to get our our end of sentence token as well as well um so going into the actual tokenization right. intuitive what we can do for uh for music is We can approximate this which is a series of notes in a piano roll right or a graph that has our offsets and our pitches right so our pitches span you know a certain uh pitch set um and we want our our information to be captured in multiple Dimensions right we want the the pitch of the note as well as the length of thenote for example these two notes at the bottom right they correspond to to e and A2 we want these to be half notes we want them to last for half as long as our C4. piano roll right which is a plot of frequency across time um we know that um a single music note is a collection of values you can think of these as the different features that make up a music note right um the two naive ones that you can immediately think of are pitch and duration um but this can be expanded into multiple things right um as shown other attributes you can use as part of this are instrument type Dynamics Tempo can be used for more complex representation. We need to figure out how to tokenize this 2D data now this this representation into a single Dimension to be fed into our transform model. have a value and then you have a duration um and this this is kind of a a naive approach to to how we can represent a certain music node. So yeah they're they're kind of different approaches we can use. We can use notes which is one to many um where you have individual notes and you have many of them where you're trying to encode a single node into a sequence of tokens um and combine the values into a single token right whereyou have c chord node D chord node e half note right. and you have less control over predictions given that your vocabulary size will grow as you add nodes right um the other kind of thing is polyphony right taking many notes and mapping it for one specific kind of tokenized set where you play note sequentially if it's separated by a SCP a separator token if not we want to play all nodes together right so this keeps track then of where notes will start and end right we have a series of notes that we wants to play together and then aseries of notes right. n62 which is this actual note representation on piano. A single song can be transformed into 12 songs of different Keys which can help increase our sample of training data and generalize key scales and beats throughout a data set. Data augmentation provides an amazing data sub multiplier to to Simply get more data. The more data you have the more data that can be used to improve training data. We're able to capture information in a a very sequential and very structured way so putting this all together you can get your initial translation right where you have a um our our initial translation. the better your model will be and the more generalizability you have in your Transformer the better it'll perform right we talked about Occam's razor. A generalized Transformer a generalized solution can fit the Goldilocks of what we want in a model. It's easier for machines to predict keys without flats and Sharps um which has you know similar to what humans do it's easier to focus on the regular keys on piano um so this specific example was trained on on those um however the glass andSharps with specific augmentations and specific training processes can also be added to our vocabulary. example um this specifically I believe this uses like a music 21 framework but it's able to you know tokenize a certain item and then you're able to transpose this to a certain amount of notes or a certain key. Just by transposing you'reable to increase your your training sample size which is very cool and can improve model performance by a ton. The next thing to consider is positional beat encoding right we want to include some metadata to feed into our model to give it a better sense of musical timing because the position of the token in our our tokenized representation it doesn't correspond to its actual position in time. then it won't really learn a a very good representation of the data that you're providing right we want to be able to mask information that it previously had as well as mask information it'll have in the future. We want to apply an attention mask to keep the model from peaking and essentially leaking information at the next token it's supposed to predict we can do this by kind of observing this model right um so here we at each at each step the model can only see itself right at the first step where zero is a token you can see one is a tokens you can't see. 2 here at the first step you only see yourself right at the Second Step you don't even see what token you're on. You're essentially enforcing a window size of two where you're only updating the information you see every two time steps. Right at the very end you can't see the final two bits of information and that lack of information is very important to a Transformer as it allows you to predict several steps ahead and will ideally produce a more generalized model. This is a reverse teacher forcing where we're masking future tokens and potentially pass tokens depending on what window masks we're applying. hidden state memory Transformer memory specifically to this model enables very fast inference for music prediction right we've done a lot of things to optimize for for our prediction we're including a beat embedding so that's not something it has to learn. We're able to get a sense of of relative position with Transformer XL whereas vanilla Transformers will use Absolution absolute position only. It's important for music models to know the position of each token relative to one another because positionality matters right the order that you're playing the notes really is is what matters the most. our positional beat encoding which we're including for the the model to have um so I'd kind of like to end with a little demo generated by by somebody who who use this model to kind of predict the end of Canon in in D Major by by Pachelbel so here'sPachelbel's Canon I'm kind of in the spirit of Christmas coming up as well um yeah so as you can see there um this is the original pocket balls Canon and this is what's predicted. So yeah there's a a lot to do in this field um a lot of really cool things happening um. things a try yourself uh yeah thank you guys for tuning in have a good one. Things you might want to try yourself. Things that you may want to give a try. uh yeah. things you might be interested in trying yourself. things that you might like to give yourself. uhYeah. things a try yourselves. uh Yeah. Things a try themselves. Things your might like yourself.things you may like to do yourself. thanks you guys. for tuning into this week's episode of The Daily Discussion.

ROUGE-1: 60.70, ROUGE-2: 57.57, ROUGE-L: 56.07
BERTScore: 70.58

==============================================
==================== [75/100] ====================
Summary:
The amygdala is closely connected to the basal forebrain. In discussions of aging in human pathologies, you always hear about the basalForebrain. The degeneration of acetylcholine containing neurons in the basal nucleus, located there, is the cause of aging. The amygdala is a major part of the basal ganglia, which includes the hypothalamus and the brain stem. The basal fore brain is one of the most important areas of the brain in the human body. It is responsible for the development of the limbic system. forebrain structures here. Includes a collection of structures, including the olfactory tubercle right at the base. You see it in the sections. See, here we're in the hypothalamus. There's the amygdala in the hemisphere. This is in front of the optic chiasm. And there you see all the major basal forebrain structures, plus the septum. We usually don't include the sePTum as part of the basal fore brain, but it could be. Functionally it's very closely allied to these structures we call basal fore Brain. But the amygdala primarily projects to the more caudal one here. This is where they overlap. That's the bed nucleus of the stria terminalis, which we mentioned last time. And I've indicated in blue there the acetylcholine containing neurons that you see in the medial septum. You see them in this diagonal band of cells. And then the basal nucleus at the bottom here. Those are the cells that have this very widespread projection to the neocortex. They project to most if not all of the neoc Cortex. and visual system that I and other people had done. It was inspired by a study of people with temporal lobe epilepsy that had been operated on in order to get the tissue generating seizures removed. And they found that the patients could be grouped into two types. And I've summarized there at the bottom the real basis for this idea, other than the fact of early lesions. And that is that the earlier the lesion in these other systems, at least, the greater the plasticity, that is, more sprouting, more chances of regeneration. of the catecholamines, the monoamine, serotonin, and some acetylcholine axons as well. I knew at the time I drew up this hypothesis that there were dopamine abnormalities in the prefrontal cortex in schizophrenics in many of them. And I would predict this kind of sprouting. For one thing, by removing this structure we've eliminated these projections to basic forebrain and prefrontal cortexes. But we've also pruned these axons, making it likely that they will show compensatory sprouting in other areas. and early damage? The fact is, a number of schizophrenics, particularly the ones that are the hardest to treat, have enlarged brain ventricles. Now, of course, with more drugs to treat them, more of them are not in the mental hospitals. But this just shows schizophrenian monozygotic twins, where you have one twin with schizophrenia. The other doesn't have it. And as they often find in these cases, the affected twin has larger ventricle. And we know that larger ventricularles can result from early damage. of them do have this temporal lobe damage. Of course, there's always a lot of variability in the studies like this. But-- yes? AUDIENCE: [INAUDIBLE] in like epilepsy in schizophrenics? PROFESSOR: That's a good question. You'd like to know if in studies of schizophrenics, how many of them have epilepsy. Usually they're kept separate, but I don't know of studies that have just looked broadly at schizophrenics. It'd be worthwhile checking. are a little more widespread according to recent studies than they were in the earlier studies, where they were seen mainly in the cortex. Now we know they are also in the more caudal areas, but just less dense. But also we know the basal nucleus projections are shown here. They could be affected too. And in every case these four systems of widespread projections all go to the amygdala as well as to other parts of the brain. All right? And this is just to show you binding to receptors for these different transmitters of the various anti-psychotic drugs. that we know if you bind the receptor you'll reduce the effects of the [? rejections. ?] If the prefrontal cortex is functioning abnormally because of sprouting of these axons, also the basal forebrain, then binding to the receptors will move it more towards the normal. And that could be a reason. Just saying that it does [INAUDIBLE].. Let's talk about the other part of the basal ganglia, the larger part, the corpus striatum. In mammals and other amniotes, the skates and the rays-- sharks, skates, and rays comes from the ventral tegmental area. We know that, especially if you look in fish, that a major input to the hypothalamus in those animals is from the taste [? cyst. ?] In mammals it's never been emphasized, but we know taste can be very rewarding and influences the te segmental area cells. The studies of rats have indicated yes, there are some projections, even in mammals, from that system. In the evolution of this structure you start out with the ventral area getting olfactory input. But then we know that non-olfactory inputs came in. And that led to expansion of the striatum, this area here. And some of it still gets direct olfitory projections. Whereas sensory inputs come into thestriatum. And I'm just showing you here for a rat or a hamster or a mouse. Many of the neurons in those structures project to one or the other, either cortex or striatum. In mammals, the neocortex expanded. That didn't happen in amphibians at all. Amphibians have this little dorsal cortex that's equivalent to a parahippocampal area. And they have a medial pallium. But none of it's like neocortex, really. Even though it does get some non-olfactory input. And just of the striatum. What is the big change that happened in mammals? In general, in the forebrain, what was the bigchange in mammals. The older picture of this was when we talked about the lateral and medial forebrain bundle. And then these more ventral and ventromedial structures are ventral striatum. And they connect through the medial fore brain bundle. Whereas the dorsal striatum and neocortex, they connect to more caudal structures through the lateral forebrain. And here we're talking mainly about that midbrain locomotor region. The literature names it pedunculopontine nucleus, and not always called it by its full name. to the VA of the thalamus, which then projects to motor cortex. The one with the colliculus goes directly from the dorsal striatum to the nigra. And then you need to know what we mean by doubled inhibition. Notice excitatory input from cortex. Inhibits the globus pallidus and inhibits the Nigra. So you're inhibiting an inhibitory pathway. Important for understanding the pathologyies when something goes wrong with these structures, as in Parkinson's disease. The subthalamic nucleus excites both segments of the globus pallidus and the nigra. So it's unique in that way. And it's critical for the balance of this system. So anything that goes wrong with it can cause major problems with movement. For people to see how knowing these connections explains some of the disorders. So we'll leave it here. But just note, if there's just a subthalamic nucleus-- here's the Nigra down here. So these are the two main satellites of the corpus striatum.

ROUGE-1: 38.14, ROUGE-2: 36.17, ROUGE-L: 35.64
BERTScore: 70.17

==============================================
==================== [76/100] ====================
Summary:
The first technical discussion of the actual solar cell device itself. We're going to be talking about the interaction of light with matter. This lecture could alternatively be called "Light Not Getting Absorbed" or "Optical Losses" Both are important, and both are related, as we'll see. We discuss cost trade offs of implementing this particular technique for the way for it to absorb more light, for example. We'll talk about the technologies and the cross-cutting themes. Conversion efficiency is really what dictates the performance of the device, the solar cell device. So from the solar spectrum, we have to absorb that light and excite charge within the material. Then that charge has to move around inside the material to get to the metallic context in the front side. And finally, the charge collection process. And so the total efficiency of this device is the product of each of these individual processes. So one of the easiest ways of boosting efficiency is simply to take care of your optical losses and to minimize the amount of light reflected or not absorbed. of your solar cell device. We want to, obviously, maximize this part right here. This is going back to the particle wave duality of light. The visible photon wavelengths are usually in the hundreds of nanometers. And the solar spectrum peaks somewhere around 550. So just to situate ourselves with broad numbers, so when we dive in and talk about spatial dimensions in relation to the wavelength of the light, we're in a situation where we can actually have a horse sense, a common sense, about it. So this was that solar spectrum, the integrated solar radiance versus wavelength. And the second point that is equally valid, we can describe the wavelengths of the incoming light. We're interacting with a very specific type of electron inside of our system. It's the valence electrons. These are the electrons that are typically most loosely bound inside of a system or I would say in the outer shells of the atoms within the material. You're typically not interacting with core shell electrons with visible light. For that, you need x-rays. you can have, for example, in the visible range, a decreasing depth of penetration of the light with increasing energy, whereas with x-rays, it's the exact opposite. It's because you're dealing with different types of electrons and the material. The real component of the refractive index is material-specific property. So if I have silicon or if I've silicon nitride, it'll have a particular type of glass. It'll have different refractive indices for different materials. a particular refractive index. It's comprised of a real component which indicates the phase velocity inside of the material and an imaginary component, which can be thought of as an extinction coefficient. And it is related to the attenuation of the light intensity as it travels through that material. And we use that information to calculate engineering relevant parameters such as reflectance of light off of a surface. And the reason that's important is because we want to minimize reflection off of surfaces. So I've come up with the first equation right here. which is describing the reflectance from air to a solid, in this case, from air where the refractive index is 1. And so I have an equation here that describes thereflectance. Let me dive a little deeper into it and try to understand what exactly that equation is telling me. So from the folks who have studied mechanics, many of you are mechanical engineers in the room, you may recall studying a problem wherein you have two springs that are connected. They have different spring constants, different stiffnesses, shall we say. interface. In reality, those ends have a very similar meaning, the n and the z. The n, in the case of light, which is the real components of the refractive index. Mind you, this parameter right here, this indicates phase velocity in material. It could also be thought of very loosely as the ability of an electromagnetic wave coming into material to slosh those electrons around. So I would advise taking this analogy as far as it will go until it breaks down. And you'll see at some point it actually does, but it's a useful place to start. If I add a coating, for instance, to a window that increases the reflectivity, then the amount of light that is able to escape from the inside to my eyes decreases. If I have a bigger n, I would get bigger reflectance. Is that right? r goes up? Well, you'd have to plot it out, I guess. So if I change the refractive index of the material that I am working with, I can change the reflectance off of that interface. reflected off of one side is equal to the amount of light reflected off the other side. So just the same way that I'm losing the ability to see inside, the folks inside are also losing the able to see out. What if that glass pane was flipped around? Would it change anything? If I'm outside on a sunny day, how much brighter is it outside versus inside right here? Factor of? AUDIENCE: 100, maybe? TONIO BUONASSISI: Maybe a factor of 10, somewhere in that range. If I took that glass and just flipped it, would it change it? What about the symmetry argument, that the amount of light is reflected, the r reflectance, is the same from both sides? TONIO BUONASSISI: Yeah, so I would advise you to actually walk through that calculation. And what you'll find is it winds up being the same. And it's because you have to take all reflectances off of all these interfaces into account. We're just assuming that all of these layers are well above the wavelength of the light. These linear equations, are valid. So we're happy to walk through that perhaps during recitation. OK, so what we're going to do now is we've talked about reflectance off of surfaces. What I'd like to do is talk about a light absorption inside of a material. And for that, we apply a very simple formulation inside of this class, which is called Beer-Lambert's Law. And now the light that's incident on the material is actually going to go inside and get absorbed by the material inside. very simple yet very powerful formulation that describes not only the interaction of light with the solar cell material but also light through the atmosphere, light the water, many other forms of optical absorption. And for that, I'd like to call Joe up for a quick demo that will allow us to actually plot out Beer-Lambert's Law. And so I'm going to come up with a hypothesis. What we're going to be doing is taking many sheets of material. This is just some polyethylene material, a little bit discolored. And we'regoing to shine a laser down on to this photodiode. of what's going to happen. I'm going to say that if we double the thickness of the polyethylene that we're going to halve the amount of light going through. And let's see if the hypothesis is correct. It's not. And it's a logical thing you might assume. And then we'll walk through a derivation that will correct our missed logic. So go ahead, Joe. Take it away. JOE: Sure, so if you guys want to play along, that's fine too. Right now we're getting about 1.32 milliamps. Then as we keep increasing and put one layer of polyethylene, that drops to 0.75. There's kind of this sense that it should be exponential. What don't we add some more filter in front, and we'll see what exactly this comes out to be. It's actually starting to go in a straight line. We're going to see what it's like, what the power of our-- yeah. to curve down. Exponential. It looks like one at least. And we can test whether or not the hypothesis is correct by an exponential fit, which happens to match pretty well. JOE: Now one other quick thing you notice is that if you look at the fit, the first point's a little bit higher than that fit. Anyone have an idea of why that might be the case? What are we ignoring in this experiment? AUDIENCE: The reflection is [INAUDIBLE]. Joe: The reflections, yeah. TONIO BUONASSISI: OK, so we notice that we have some exponential character to be decay of the intensity of the transmitted light through a medium. And the amount that's absorbed is following another trend, which is just 1 minus that. So it's the amount of light that'sabsorbed is following a curve looks something like that. OK, let's look through the formalism of Beer-Lambert Law and try to understand why it is that we come up with that exponential function right here. by some sort of scattering intensity within the medium-- and this sigma here can refer to a variety of processes. The sigma is independent of thickness throughout. And then as you integrate through, you wind up with that beautiful exponential function at the end, the sigma l times n. That alpha is an absorption coefficient. The l is the total length or the total thickness of this medium right here. So if we increase the total. thickness, we're going to decrease the total amount of light coming through via that exponential function. a geometric parameter. It's an intrinsic material parameter. This alpha will vary as a function of wavelength inside of a material. And so from an engineering point of view, we don't really-- to first order, it doesn't really matter what sort of scattering or absorption process is happening in a material for us to calculate the amount of transmitted light. We just need to know the alpha. We need to known the optical absorption coefficient. We can measure, experimentally just like we did right there, our alphas for materials. states within the material, that light, depends on the energy of the light. So there's a wavelength dependence. And that general equation is the same one that drives the reduction of light intensity as it travels through the atmosphere. So if we increase the atmospheric path length, we'll be reducing the amount of light that actually reaches the surface of the earth. That's at air mass two or air mass three, there's less solar flux coming down than at air Mass one or air Mass zero. The only geometric parameter that is of essence is really our l.variable, Tonio Buonassisi says. Oftentimes we're operating in a wavelength regime of light wherein free charge is excited. But we can also keep increasing that the wavelength of light, say, out to 10 microns, very long wavelength light, very low energy light. That can excite free carriers within the material-- carriers that are already excited, essentially excited them further, without generating any new free carriers inside of our material. Alpha is a function of the wavelength of light and the property of the medium. We're talking about an energy range quite broad here, from about 6.2 eV to 0.62 eV. The visible wavelengths range would be somewhere in this regime right here, so a very limited band. And the infrared out here, ultraviolet over here, and we can see for a variety of different types of materials what the absorption coefficient is. The red would be crystalline silicon, gallium arsenide, indium phosphide, and amorphous silicon. The thickness of gallium arsenide is necessary to absorb 90% of the incoming light at 550 nanometers. To make sure people are setting this up right, i divided by i0 is 0.1, 1 minus 0.9. If we're absorbing 90% the light, it means only 10% is going out the other side. That means their i is going to be 1/10 of i0. And then we would take the log of both sides, typically, typically. and solve for our l based on the alphas that we have here. Again, units of alpha would be in inverse centimeters. Did anybody manage to walk all the way through that calculation? Did anybody get any other numbers for gallium arsenide. How about the silicon? Is it larger or smaller? Let's just for order of magnitude first and the general trend and then try to pick up the precise number. For silicon, crystalline silicon that is, with an optical component, that is. absorption coefficient and order of magnitude less than gallium arsenide. Is the thickness needed to absorb the same amount of light going to be greater or smaller? AUDIENCE: Greater. TONIO BUONASSISI: Greater by an-- AUDience: Order of magnitude. OK. All right, so that was at 550. And there's a lot of solar radiation right around 550, so the numbers that I have on the top of my head work somewhere out to be on the order of a micron. peak of the solar spectrum. Most of these solar cells that you see of crystalline silicon are on the order of 100 microns, typically a little thicker for some technological reasons, which we'll get to. But if you just assume one pass through the material, you'd need about that thickness to absorb a lot of the light. And I'll pass around some of these materials right here just so you can get a sense of how thick they are. And you can actually pick them up if you like. Just be aware that these little pieces of silicon are-- silicon's brittle material. It's like glass. inside of that little bin, these are small shards of silicon solar cell wafers. Their thicknesses in the order of 100 microns, those are particularly thin. You can go down to a few hundreds nanometers and still make-- actually the record efficiency of gallium arsenide solar cell is a few hundred nanometers thick. And our calculations right here assumed one pass through the material. That's all we gave the light. We only gave one chance to go through thematerial and get absorbed. 10% of the light that didn't make it, that's going to get reflected back. The first thing that we can do is texturize our front surface. If we don't have texture, if it's absolutely flat, what we call specular surface-- specular coming from the root mirror. We're just focusing on the lights, the rays that get reflected. That beam that gets reflected off, instead of just going back out toward the sun, it's now going toward the material again. As the material goes from one medium to another, the refractive index changes. Texturization increases the probability that light will enter the device. And what it also does-- this is a secondary benefit-- is it increases the path length, the effective path length of the incoming light. The way to understand that particular phenomena is called Snell's Law. So the way in which the electromagnetic wave oscillates the electromagnetic waves. We discussed this right at the beginning of lecture. So we have a texturized front surface. Let's go there. electrons instead of the system is changing from one medium to another, let's say from air into the solar cell device. Now, we can ascribe the refractive indices to air and to our silicon like so. And the light path will obey what is called Snell's Law, which is the product of refractive index and sine of that angle, the angle relative to the surface normal. So a simple way to think about this is when the light goes from a low index of refraction medium to a high index ofrefraction medium, light bends toward or away from the normal? The refractive index of silicon is going to be greater than that of air, so light would bend toward the normal. So there are two benefits to texturizing your front surface. One is you have an additional pass, additional bounce, an additional encounter with the material. And the second benefit is that you're able to increase the optical path length by the delta in refractive indices and the fact that the path of the light will be Snell's Law. Of course, the light actually falls along the surface or actually bounces back in. most often, depending on the angle. You have what is called total internal reflection, which is this case right over here. You might change the nature of the anti-reflection coating on the glass. Even if the panel looks black, there are some really aesthetically pleasing solar panels out there that look completely black. They may still have white back skin, but the glass is just very good at absorbing that light and preventing it from escaping. To engineer front and back surface reflectances, you really have to carefully select your refractive indices. When you look down, the ray of light is traveling like this and it bends toward the normal and likewise symmetric. What change of property would give you these two images over here? In one of those two images, the refractive index of the medium inside the pool is not 1.3. It's 0.9. And in another one of these two, the Refractive Index of theMedium is actually going to be negative. So which of thesetwo do you think is which? our reflection condition. I'm going to come back to Snell's Law in a minute. But for the time being, I want to move on to the next concept here, which is Lambertian reflector. You'll hear this topic or this word thrown around quite a lot in the solar cell community. And it's used rather liberally to mean a lot of things. But in optics, it has a very specific meaning. It's a very loosely used term. It is wrong by the book, but nevertheless, it's one of these things that live on in our industry. The back skins of our solar modules can quite often be Lambertian scatters. And we have a certain amount of light that comes off at some angle here that will get trapped by a total internal reflection inside of a modules. And so the notion of a Lambertian scatter is important on our solar panels. It's those waves, those rays that are bouncing off at those large angles that are causing the totalinternal reflection event. It is not sub-wavelength, but smaller features such as texturization on the back skin right here. the backsides of solar cell devices. We would obviously wants to even change the scattering profile. We wouldn't want necessarily specular reflectance. We might want to maximize the amount of light reflected off at particular angles. And there is, of course, research being done to figure out how to make light do that. And you don't only have to texture your back skin. You can also texture the bus bars. The bus bars are these little metal wires right. Let's ignore front surface texturing for now. Let't just focus on the backside. here that are collecting the charge from each of the solar cells. They're connecting essentially the front side of one cell to the backside of the next. And this metal right here is just really shiny, and it's reflecting light right back out into space. What if we instead were to texture that metal so that when laser light shined on it a certain amount would be reflected off at an angle and then caught by total internal reflection? That's exactly what you're seeing right here. There is a limit to how much we can trap light simply by modifying or corrugating the surfaces. A gentleman by the name of Eli Yablonovitch, who's now a professor in Berkeley calculated these parameters I think back in 1982. He came up with an upper limit to the optical path length. That's a pretty good litmus test for the ability of a material to trap light. If you have silicon, for instance, with a refractive index of, let's say, in the infrared some around 3.6, your Yabonovitch limit is around 50. we have a grading of refractive indices going from air, our anti-reflection coating, to silicon. And right over here we have a certain thickness, d1. And over here, d2, over there, over here. So what is happening in these two images? Let me show you with another, a little bit more clear figure, coming from our beloved Wikipedia, and then go back to that other image right there. What's happening is we have an incoming wave that for some reason is ignoring Snell's Law. at a trough. The trough will be at a peak. So the two waves will are going to be destructively interfering when they come out. If you add these two together, due to the wave nature of light, you get suppressed reflectance. And that's a really interesting property. You can begin varying the thickness of this layer, and of course changing the nature of the reflected light. And so without going into the hairy math, to calculate this right here, it's definitely possible. It's definitely something that should be done. photon wavelength at the peak of the solar spectrum, we have to design the thickness of our anti-reflection coating to satisfy that equation right there. That's the phase shift we want upon one pass of the anti-reflective coating so that two passes, when it goes through and then back, it's phase shifted relative to the surface reflected light. So just to give us a sense, kind of an estimate, and to give. us some confidence in these engineering methods, what I'd like you to do is to calculate the. thickness of an ideal anti- Reflective coating. bare silicon. And you can see it's rather reflective. So calculate for me what is the optimal thickness of an anti-reflection coating of silicon nitride? And we'll give it a refractive index of, say, 2.1. Let's call it 2, just make our lives simple. And the peak of the solar spectrum we'll again call 550. What should that thickness be? Tonio, I'm sorry, could you repeat the constant again? TONIO BUONASSISI: Sure. is the photon wavelength at the peak of the solar spectrum in vacuum or in air, is 550 nanometers. The anti-reflection coding is enabling the light to be absorbed because it's suppressing the reflectance. So they're 70 nanometers thick. And you gain quite a lot in terms of cell performance. I'll show you some slides to drive that point home in a bit. This is really really briefly-- I'll post these slides online so you can have access to them. to them. If you use the matrix transfer method, as described beautifully in [? Gonchen's ?] textbook, you can calculate the amount of light reflected across a broad spectral range for a given thickness of anti-reflection coding. The important thing to note here is that it really, really matters. This is silicon under glass right here, for example, typical solar cell material in blue. It's better than the bare silicon. Why is it better? Glass has a refractive index of 1.5 or so. Recall that equation that described the amount of reflectance, there was that-- what was it-- n1 minus n2 quantity squared, right? The bigger the delta between the ends, the bigger the difference in refractive indices between material one and material two, the more the reflectance is going to be off that interface. So you can begin reducing reflectance off of a stack of light going both ways by grading the refractive index of the material. And so you get a reduction in the total amount of reflected light when you put silicon under glass. front surface of your sample by using an intelligent combination of the very first equation that we're exposed to in the class today, which was the reflected light as a function of refractive index. And secondly, by engineering by engineering an anti-reflective coating, which oftentimes in the lingo of solar cell science we call it an ARC. And those two things combined give us very low reflection off of the front surface. Probably 5% of our R&D cells that we make at MIT use these sorts of technologies, which are pretty standard in the industry. expressions that we just walked through. It's really important to understand the fundamentals behind any simulation software because you will get out of it what you put into it. You will not be able to pick up on obvious things that you might of-- for example, double clicked on this little material here and find the real component of the refractive index completely wrong. And you might not notice it if you don't have some good intuition which is grounded in the fundamentals. And so it's important that you understand what we've presented today. The absorber is the material, our photovoltaic material, the ones absorbing the sunlight and ultimately going to be generating the charge. So we want to ensure good light trapping inside it. There are fancier ways of light management as well that don't involve light trapping necessarily but light manipulation or even semiconductor manipulation. You can, for instance, change the wave length of the incoming light. One very simple example of this is when you shine red light on a phosphor and then it glows green in the dark. are folks out there trying to do spectral up converters where they take two lower energy photons then somehow convert that into a higher energy photon. And so since our absorption coefficient is dependent on wavelength, if we're able to shift the wavelength of the light around by engineering materials near the surface, we can enhance absorption as well. That is a form-- a valid form-- of light management. If we can eliminate the longer wavelength stuff out here, which is heat, performance of most solar cell suffers when they get hot. a coating on the back to reflect the light back so that it gets a second bounce through the material. I've engineered the front surface, texturized it so that we have not only the benefit of two bounces, double the chance of light going in, but also the Snell's Law working in our favor. And so all told, the one reason why this boost is so big right here is because I'm increasing the optical path length relative to the thickness of my material. And as a result, I'm getting a much larger current output. here from the change of refractive index going through your silicon to that dielectric material in the back. Where you have your metal, you're going to be absorbing the light. In the lab, 24.2%, in commercial production, 22% and change. 22.4%, I think. If you introduce a constant phase shift gradient throughout the device, now you can start doing some fun things. The device design can get pretty complicated for these super high efficiency devices. And they're worried quite a bit about trapping, other things as well. surface of a material, let's say right here, then you can cause each node, each point within your material, to lag by an increasing amount, so that your wave front now bends. And that will cause the light, essentially, if you trace through the points of maximum intensity, say the pink, you'll see that the light is bent. And so it's really exciting. There's stuff coming up every day. This is the point. We can, in principle, if this is hot off the press-- and then of course there's a whole flurry of researchers out there trying to figure out how to use this to our advantage. on light trapping and light management. Mostly it's for photonic devices, but they can be transferred over into solar cells as well. And another example of the photon up/down converters, there's recent reports in SPIE, a lot of interest in the optics community. There was a TR35 award given to a person who studying this topic. So it is, as well, a very exciting and up and coming field. Again, the opportunities there of manipulating light are large, are vast.

ROUGE-1: 54.78, ROUGE-2: 52.92, ROUGE-L: 51.92
BERTScore: 68.81

==============================================
==================== [77/100] ====================
Summary:
Professor Steven Smith: I want to look at two sets of issues. One is Locke's theory of the constitutional state, particularly focusing on the role of the executive, vis-a-vis the legislative branch of government. The other is thinking about Locke and the American regime and the current state of political philosophy, modern contemporary American political philosophy. Smith: Locke doesn't endorse necessarily one particular form of government from any other. He is an advocate of what we have come to call limited government, of constitutional government. a domestic, not an international issue, which is to say, in the case of a fire in a city it is sometimes necessary, he says, in his day for the fire department to tear down the house of an innocent person. This is acting for the public good of the community, even while in some ways it's clearly a violation of rights of property and so on. In fact, the example is not so far fetched. Think today for example about arguments we have today. Even in Connecticut, there's a big argument going on about the right of what's called "eminent domain" Locke asks what are the limits of this prerogative power. What check, if any, is there on this power to prevent their abuse? This is beginning to sound more and more in respects like Machiavelli than the advocate of, again, limited government. This power comes into play, he says, especially during times of national crisis or emergency when it is necessary to act for the public safety. And again, this seems to have special resonance for us today as we face issues like states of emergency and states of exception. utilize when ordinary constitutional operations, like the rule of law, prove to be inadequate. Consider Lincoln's famous suspension of habeas corpus during the Civil War. Lincoln argued quite forcefully that this sort of prerogative power is already deeply embedded within the structure of constitutional government. The Constitution seems to embody within itself, our constitution that is, this Lockean power ofprerogative that comes into effect or can be legitimately exercised in times of rebellion or invasion. Are we living in that kind of age now, not rebellion perhaps? John Locke's Second Treatise is a key source for thinking about constitutional issues today. In a constitutional crisis, Locke says the people have no other remedy but to appeal to Heaven. Locke affirms here a right of revolution. Locke's doctrine of consent and legislative supremacy should make him a hero to Democrats, to radical Democrats, and even libertarians, says Julian Zelizer. Zelizer: A judgment on America is very much a judgment on the philosophy of Locke, if anyone is to be considered more or less the philosopher-king of America. For many years and for many people, even today, the affiliation between Locke and America has been regarded in a largely although not wholly, largely positive light. For many historians and political theorists, our stability, our system of limited government, our market economy has been the result of a sort of broad consensus over Lockean principles. For still other thinkers, more or less on the left, Locke legitimized an ethic of what was called "possessive individualism" And for still others, in many ways more recently, Locke's emphasis upon rights and the protection suggests a purely or overly legalistic conception of politics. John Rawls wrote a book in 1973 called A Theory of Justice. In many ways, Rawls' book was an attempt to update the liberal theory of the state. He invokes the idea of a state of nature, an original condition, as he calls it, a theory of rights. For Locke, going back to chapter 5 of the Second Treatise, rights derived from a theory. of self-ownership. It is on this rock that Locke builds his edifice of natural rights, justice, and limited government. a more or less kind of random or arbitrary genetic lottery or social lottery of which I or you happen to be the unique beneficiaries. Fortune, luck, Machiavellian fortuna, in that way, is utterly arbitrary and therefore, Rawls concludes, I should not be regarded as the possessor but merely the recipient of what talents, capacities and abilities that I may, again, purely arbitrarily happen to possess. So what does that mean in terms of social policy or theory of government? The result of Rawls' difference principle and its fundamental difference with that of John Locke could not be more striking. For Rawls, our endowments are never really our own to begin with. They are part of a common or collective possession to be shared by society as a whole. The capacities of hard work, ambition, intelligence and just good luck that, for example, got you to Yale, on Rawls' account, do not really belong to you or at least the fruits of those ambitions and intelligence and good luck. They're not yours or mine, in any strong sense of the term, but rather, a collective possession. or your drive or your endowments are, again, what he calls a collective asset. Think about that. And it is this conception of common assets that underwrites Rawls' theory of distributive justice and the welfare state. Unlike Locke, whose theory of self-ownership provides a moral justification for the individual, for the self, for our moral personality, RawLS' difference principle maintains that we never again belong to ourselves at all. We never really have ownership in ourselves. but are always part of a larger social "we," a social collective, a collective consciousness whose common assets can be redistributed for the benefit of the whole. Both of these views, again, they begin from common premises but move in very different directions. Locke's theory of self-ownership regards the political community in largely negative terms. Rawls' theory of common assets regards the community in a far more positive sense as taking an active role in reshaping and redistributing the products of our individual endeavors for the common interests. John Rawls and Jean-Jacques Rousseau disagree on the theory of inequality. John Rawls says Rousseau's theory is more correct. John Sutter: Rousseau is right to be concerned about inequality. Sutter says his view is closer to American theory, to Locke's theory, than Rawls' is to Rawls. The debate will take place on Wednesday on CNN at 10 p.m. ET. Click here to watch the debate on CNN.com/John Sutter. Rawls wants government to work for the benefit of the least advantaged but this will require the extensive and often arbitrary use of judicial power. The result would be, I think if we follow Rawls' teachings to their letter, a class of chief justices endowed with the power to rearrange and redistribute our collective assets for the sake of achieving the maximum degree of social equality. It is no surprise that the warmest reception that Rawls’ writing gets today is in the schools of law. He has had an enormous influence on shaping the education of the current and the next generation of lawyers. Some historians, let me just mention again, Louis Hartz was but the most famous, treat America as a nation uniquely built upon Lockean foundations. America, he believed, remained something of a Lockean remnant--a Lockean, yeah, remnant, fossil in some ways, in a world increasingly governed by more radical forms of modernity. I am not suggesting for a moment that Locke is some kind of cure all. But Locke's effort to build a kind of modern republican government on the low but solid foundations of self-interest and self-ownership and the desire for comfortable preservation could not help but generate its own forms of dissatisfaction. satisfy the deepest longings of the human soul? Can a regime, devoted to the rational accumulation of property answer those higher order needs or higher order virtues, like honor, nobility and sacrifice? Can the avoidance of pain, discomfort and anxiety produce anything more than contemporary forms of Epicureanism and Nihilism? In any case, I'm suggesting no more than any other land could America insulate itself from the great heights as well as the great depths of later forms of modernity. We are but a moment in the kind of comprehensive self-dissatisfaction that is modernity so that a return to Lockeanism, in many ways, is not so much a cure for the pathologies ofmodernity.

ROUGE-1: 39.13, ROUGE-2: 36.46, ROUGE-L: 37.18
BERTScore: 65.11

==============================================
==================== [78/100] ====================
Summary:
JACK HARE: Let's do a little recap on electron cyclotron emission, and then we will go on to a few other things. We didn't actually derive the emissivity of it, but we gave ourselves a hand-wavy reason why there may be multiple peaks here. And these peaks are going to be occurring at frequencies-- I'm going to switch into angular frequency units, omega m. And we can say this is m equals 1,. m equals 2, m equals 3. And they're evenly spaced. "We agreed that these peaks would, in general, be broadened in some asymmetric fashion. But the exact shape will depend on exactly how big these two terms are with respect to each other" "And we said the neat thing about this is that these frequencies depend only on the magnetic field. And so, if you see some emission at some certain frequency, then you know that it's been emitted by a region of plasma which has this magnetic field" "That was particularly useful when we considered a tokamak because, if we have some magnetic field that goes 1 upon R" different because the magnetic field is dropping off nice and monotonically throughout our device here. So, for example, we might have a region down here corresponding to lowish frequencies at low magnetic fields. And what we would expect to get out if we put our little microwave horn and collected the different frequencies coming out from this plasma, is we'd expect some sort of spectrum where different parts of the spectrum correspond to different regions of this plasma. So that is the region of plasma that's emitting is emitting as a black body. So I've got this the wrong way around. R3 is the lowest magnetic field. We might have another region where the frequencies correspond to the center of the plasma. And at each of these points, if we measure the intensity, we then know straight away what the temperature is corresponding to the black body spectrum for that frequency. And, therefore, we know what the Temperature is inside our plasma. So we can go back and we can say, OK, using these measurements, maybe we have a temperature profile that looks like this. temperature as a function of frequency. Then we can say, well, that frequency corresponds to a certain magnetic field. And then we can says that magnetic field corresponds to. a certain spatial coordinate. And so, this is a technique which will give us, by looking at the spectrum for lowish frequencies, the first or maybe the second harmonics of this cyclotron emission, we can work out what the temperature is as a. function of space. This is correlation ECE, often called CECE. what we want to do is measure very small temperature fluctuations. We want to measure temperature fluctuations within the plasma that are maybe on the order of 1% of the baseline temperature. If the mean temperature is just Te, and we have some fluctuation around 1%, this intensity will also fluctuate by about 1%. And that 1% is actually extremely hard to measure. And this is because the noise is just too high on these systems. There are lots of different contributions to the noise. But, in general, they all add up to make it very hard toMeasure these very small fluctuations. want to understand in plasmas so that we can build an economically viable fusion reactor. Now, the fact that the noise is too high does seem like a big limitation. But there are some clever tricks that we play where we use correlations. And I'll talk now about what exactly these correlations are and how they provide us with information that allows us to get a signal out despite the overwhelming [INAUDIBLE]. So our setup here is borrowed from ASDEX Upgrade. And, in effect, I referred to Alex Creely's PhD thesis, which you can find online if you want more information. can get very detailed. So in ASDEX Upgrade, we don't really have a circular cross-section plasma, but I'm just drawing it like that, be a nice D-shaped plasma, got our plasma inside here. And our system, at first glance, looks an awful lot like the system that we sketched out up here. We're going to have some sort of special lens. It turns out, you can make lenses for microwaves. And that lens is going to collect light from a region like this. some sort of top hat. It's centered around the frequency where most of the electron cyclotron emission is. And this has a bandwidth of 10 gigahertz. So we've cut out an awful lot of the radiation in bands that we're not interested in. We are no longer going to study those, any bremsstrahlung, any higher order things. This is going to capture all of the information in, say, the first harmonic within some relatively small window. frequency range. Once we've got our bandpass filtered signal here, 110 kilohertz is still too fast for us to digitize. This would be an extremely expensive digitizer. So, what we actually do is we downmix it with the signal at 100 gigahertz. And so, then we get out our beat signal, which we can digitize, which is at 10 gig ahertz here. So this is-- actually, I will write this as 0 to 10 giga hertz. This is the sort of signal that we can actually digitize now. bins is 125 megahertz. It's important that these bins do not overlap in frequency space. They are each sampling a separate discrete part of the plasma inside here. So each of these represents a measure of the power that's being emitted by a very small region. And you can tell that these regions are very small because we're dealing with 100 mega hertz bandwidth. And we originally started with 110 gigahertz here. And so, you see we've gone down by a factor of 1,000. downsampled these is that digitized is now much less expensive. We're doing it something like 4 mega samples a second. And that is quite an affordable digitizer compared to the ones you would need to digitize this signal. So I have not yet told you anything about how correlation ECE works. I'm just giving you an outline of exactly how these measurements are made with an example from ASDEX Upgrade. But there are other similar devices on other tokamaks. many oscillations. And so, it will average out to-- well, because it's power, it'll average out out to 1 or something like that. So it's some DC offset that we can subtract off after. So all this is doing here is mixing the signal down so it gets to a regime that we could effectively digitize. Yeah, another question. [INAUDIBLE] JACK HARE: So if we were doing geometric optics, which we're not, then you would have a lens like this. That lens could collimate your beam. The idea here is that there was some region over which, in the transverse direction perpendicular to your collection volume, you have a very narrow scale. You can actually collect from a very small region on the order of 100 microns. Anyone know how micro splitters work? Looking at you? STUDENT: RF. JACK HARE: The answer I got is that you can buy something from DigiKey or something like that that will do it for you. It depends on your size of your lens and the wavelength of light. was RF, which I don't think is much more satisfying than my answer. So, yeah, there are circuits which will split microwaves. What they were actually doing with this system is all of these were very tunable. And so, if they wanted to look at turbulence in the edge or turbulence near the center, they could actually tune all their bandpass filters to do that. But this is getting way beyond what I was hoping to talk about on this. So let's get on to correlation ECE see what that does. we're going to write this little tilde here to remind us that this signal is some oscillating quantity or time varying quantity. And that signal has two components to it. It's got some fluctuation, which is due to temperature fluctuation. And then, it's also got some noise. This is the thing that we don't want to measure here. And so, the signal, as a function of time, is going to look like, again, our temperature signal, which might be some nice and smooth function like this corresponding to some turbulent eddy. of extracting this temperature from the noise here. And what we do is we pick two adjacent channels. These channels are adjacent in frequency space, which means that they are measuring from adjacent parcels of plasma in real space or inside the tokamak. So we say, our term is greater than delta R. Which means that, if there's a temperature fluctuation associated with this little vortex, it is the same temperature fluctuations in S1 as in S2. And, again-- oh, I don't need this to be much greater than. I just need it to be greater than or less than. on the order of. 100 microns or so apart. This is really, really tiny. But, the nice thing is now that these two signals are carrying the same components that we're trying to measure. And this is where the correlation comes in. We're going to find that the noise is uncorrelated at random, but theseTwo signals will correlate together, and we'll be able to measure it. And there are a few different ways to do it. But once you get it right, your signal will leap out. Do correlations, and I'm not going to go into them, but I will give you a citation at the moment. We get out a term here that looks like the temperature term squared, the thing we want. And because this noise is just random, when we do some sort of averaging, this could be in time or best to think of it is a short time integral, then these terms are all going to drop out. And we'll just be left with a correlation signal that is proportional to the temperature squared here. is an example of nominative determinism. Someone called Watts goes around making power measurements. Yeah, and this technique is incredibly powerful because it's enabled people to measure, again, delta Te upon Te on the order of 1%. And they've done this at 13-- on ASDEX Upgrade-- 13 radial locations. So 13 positions they can measure these temperature fluctuations. And they have done this with a time step of 100 kilohertz. So 100,000 times a second they've been able to measure these temperatures. we have positioned these two volumes, which are producing frequencies omega 1 and omega 2. And we think that that distance is smaller than the size of our turbulent eddy. The temperature should be the same going up and down. And if you do this correlation and you get out nothing, that probably means your volumes are too far apart because there is-- this T correlation would just go T1 T2. And there's no good reason to believe those temperature fluctuations are correlated, because they'll be part of a different turbulent Eddy. then tune all of this slightly differently and move slightly further in depending on where you think transport is important. But if you're looking at transport in the pedestal region, you have some idea where that is. But, yeah, you're right, this does not get you a huge spatial range. It gets you about a millimeter. But that might be enough for your measurements. And so, it will depend a little bit on how you do your time integration step here. So you may end up with a different result. situation where, at some point, your eddy has moved across, and these two are no longer correlated because the next two are correlated. So it-- yeah. I think we're reaching the limits of my knowledge. Yeah. Now we're going to go to bremsstrahlung. Some people these days just call this breaking radiation, which is just the translation from the German, and that's a perfectly reasonable term to use. And so, what we're dealing with is heavy ions, and all ions are heavy compared to electrons. And we've got some electron whizzing by. from its trajectory. Now, this electron isn't then just going to sail off and never see an ion again. In fact, it's going to see one very, very soon. And so, effectively, our entire plasma is full of electrons which are gently being deflected and breaking and emitting these photons. So the main thing we can say in a classical treatment is that the bremsstrahlung is going to be isotropic. That's actually quite different from electron cyclotron emission, even though we didn't really look at that in any detail. here with the ions and electrons as point particles. There's a semi-classical approach where you start bringing in some quantum physics and treat, I think, the electron as a wave. And then there's a full quantum approach. What's remarkable about all of these approaches is they all give the same answer with just a very slightly different coefficient. So we get a small change in coefficient. The scalings are the same. So, in some sense, although it's important to get the exact coefficient, it doesn't matter exactly which one of these techniques you use. from the point of view of this course, it makes no difference. Yeah, I think it's kind of remarkable that it doesn't make any difference. So, again, if you want the full treatment, go have a look in Hutchinson. And there's also a long treatment in Jackson of this same problem. I'm just going to quote some results. I kind of already spoiled it now. It's here. For the Maxwellian average, because we can have all sorts of different distribution functions, but our plasma tends towards a Maxwellian. This, therefore, has units of watts per hertz per meter cubed. And these constants are things like e, the electron charge, and the electron mass, and epsilon 0, and h bar, and c, all arranged in some way to make all the dimensions work. And you'll also find this Gaunt factor varies very weakly with the temperature of the plasma here. So this is a pretty weakly varying function. We can change it by two orders of magnitude in this parameter here, but this only changes by one order of. magnitude. And so, in general, it's reasonable to just treat G as being a constant and then, for this calculations we're doing, where we're going to drop the absolute intensity, we can just drop G with all the other constants as well. So we can drop [INAUDIBLE]. But if you want to go back and do this properly for some measurement that you'redoing, then you'd have to include this. And that is all you need to do Problem Set 3. at all frequencies, like a black body kind of spectrum here. That goes down to very low frequencies and goes up to very high frequencies. We're going to talk about lots of other effects which produce emissivity which is higher than the bremsstrahlung. But, often, when we're doing power balance calculations for a tokamak, we will just use this, and that represents our most optimistic take. So, I guess, you always need to worry about this, even if you managed to clear out all the impurities. something like that. But this bremsstrahlung may be quite small. But even if it's not quite small, it is constant because it varies only slowly as a function of a frequency. So for a small frequency window, it looks constant. And then you can just subtract off some background intensity and look at the actual signal you're interested in, like you see there. Yeah. So I mean, so the important thing to realize is what mode it couples in actually depends on where you're looking from in some sense. emits. And then the wave has to ask itself, well, what sort of wave am I? At this point, if I'm going perpendicular to the magnetic field, I'm. going to be O mode or X mode. And, in reality, there'll be some emission in O mode, some. emission in X mode, and the exact coupling between those will be related to the polarization of the bremsstrahlung. So I would guess, without thinking about it very much, you get roughly equal into both. In reality, for some plasma, we might have a spectrum that looks like this. So it goes back to being optically thin here for the high energy photons. But the low energy photons will get absorbed as well. There's actually another effect, which is in Hutchinson's book, which I haven't covered here. And so, the spectrum will be even further modified because that wave will be evanescent. But we're skipping over that this year. But it's in there if you're interested. at synchrotron, yes. Jack HARE: I think someone told me that maybe for a high field tokamaks synch rotron could start being significant. But I actually have no idea how big a deal it is. And I don't know if people are using it as a diagnostic. I've not heard of someone using it. But it's interesting in its own right. It's a source of X-rays for diagnosing many other things. It depends on what you're trying to diagnose. mostly on the magnetic field and the radius. And those are two things in a tokamak you already know. But maybe there's a really clever diagnostic you can do, like fast particles or something like that. So worth thinking about. STUDENT: [INAUDIBLE] JACK HARE: Right, but I'm not interested in [INAudIBLE]. This is a diagnostics course. Any questions online while we pause? So this is bremsstrahlung radiation, and often people call this free-free. That entire acceleration yields one photon, one energy. And so, initially, we have a kinetic energy, a 1/2 mv squared. Then, afterwards, we're going to have an energy 1/ 2 mv prime squared minus h nu. Now, if h nu is less than the initial kinetic energy here, then we still have some kinetic energy left. So v prime is greater than 0, our particle is still free, and it can continue. But, of course, there's another case where this photon takes away so much energy that this starts, I guess it becomes imaginary. where we have a range of different discrete energy levels that the electrons can occupy. These energy levels are labeled by the principal quantum number n. n equals 1, 2, 3, 4, and so on. And, up here, infinity, this is ionization. If your electron gets this much energy, it becomes free again. And the energies of these levels are given by this unit, Ry, which is the Rydberg z squared of our ion over n squared. It is not the density anymore. We're dealing still with the single-atom picture, one electron, one ion. fulfills this equation, which involves these discrete energy levels. And that equation is going to be the photon that is emitted. So that just has our familiar bremsstrahlung type coefficients, electron density times the Rydberg energy. And then we can sum them all up in order to get the total spectrum, which is equal to 1/2 mv squared plus z squared upon n squared times theRydberg. We're going to get out different photons. Now, of course, these are not going to. be at completely discrete lines because it's going. to be broadened by our distribution function. ion density times z squared e to the 1/2, e to minus h nu upon T times a constant. But now we have an additional term, which is a new Gaunt factor for level n. But, don't worry, these Gaunt factors are all about 1 again, so it doesn't really matter that much. And then we have a term z squared upon T Rydberg energy 2 upon n cubed. So the strength of this emission drops very fast with n. So it's going to be strongest for n equals 1 and less strong for the higher principal quantum numbers. The spectrum, therefore, looks like we had something like this for bremsstrahlung before, and now we have a spectrum that contains a series of edges, like this. And this lowest edge here-- I should draw this as a straight line-- this is n equals 1, 2, 3, 4, and all the way back up here, where, again, this is our brems result, and this isOur recombination.n of jn here. So if you're asking, what happens if you can't fulfill that, it just doesn't happen. Quantum mechanically, that would be a forbidden transition. I understand. So I was just wondering, because it's not the condition that there are photons that are released with greater than 12 mv squared the kinetic energy. It's the photon energy that's-- yeah, maybe we're doing this backwards in some sense. STUDENT: I see. So if you see a photon being emitted with more than 1/2mv squared, then the electron has over-emitted. And the only way it could have done that is if it fell down into one of these principles. we just did it in reverse. So this long tail here is due to the fact that we have electrons not just with v equal 0 but much more than that. Now, are they actually sharp or is it that we want f of distribution of v squared? I'll have a look into that. Any other questions? Yeah. I understand. JACK HARE: Yeah, I think maybe I motivated this the wrong way around. Yeah. Other questions? yeah. STUDENT: [INAUDIBLE] Jack Hare: Yes, exactly. related to the overlap integral between those with a dipole operator, the dipole operators being the thing that emits the photon in between them. So, yeah, it depends on the ion charge. If you've got some helium with 2 times ionized helium, and you'veGot some hydrogen, then it will have different recombination lines here. And that's because, fundamentally, the energy levels are in different places inside here. The energy levels shift by the ion charges here. Any other questions? time, that absorbs some [INAUDIBLE]. JACK HARE: Ooh. Wouldn't this balance out, electricity going in and out of ions? There's a very good question. We're going to get to that and the idea of detailed balance and thermodynamic equilibrium and things of that ilk. One use of this is a diagnostic called bolometry. It cares not at all about the detailed spectrum of what the emission is. It just wants to know how much power is being radiated by the plasma. this is balanced by conduction losses and what we, at the time, we assumed were bremsstrahlung losses, but in general could be any sort of radiative losses here. So, bolometry is focused on measuring the total power that's being emitted. And so, that is going to be the integral d nu of j of nu. So we take our beautiful spectrum like this, and we integrate over all of this. We lose all of the detail. But, of course, the detail matters when we're doing the integral because you can see the recombination increases the amount of emission. do bolometry is we have some radiation coming out of the plasma. We have a little sensor sitting at the wall of our vacuum vessel. And that sensor is just a resistor. It has a resistance M. And we apply some voltage, V0, over this resistor. We also put another resistor that is shielded from the plasma that we call R. And the voltage that we measure, VR, is equal to whatever voltage we used across all of this system R divided by M. So by measuring this voltage VR, we can measure the voltage M. This is a very simple resistive. divider just drawn in a complicated way. The reason why this is interesting is that, in general, M is going to change with T. We're going to have some resistivity as a function of temperature. And so, as this resistor heats up from absorbing the radiation, its resistance is going. to change. So if we're measuring the resistance M, we can then use some table of rho of T to get out the temperature. We'll talk a little bit more about how to do that in the next step. be digitizing this as a function of time. And so, this is also a function. of time and temperature. And all of this is time some heat capacity. And, in general, this resistor is going to be connected. It has its own heat capacity c, but it's also going to. be connected to some heat sink, which is unavoidable. And that heat sink will have some thermal transport time tau. So there's two different ways that the resistor is connected. There's actually a second term here, which was delta tau delta T upon tau, like that. radiation can affect this. And so, by measuring delta T up here, the change in temperature in our resistance, we can invert this equation and we can back out the radiation power. So this is just a really simple way of using a resistor to measure the power coming out of the plasma. And bolometry was one of the first diagnostics that we had on many MCF devices. It does not work because it is very susceptible to noise. So we have to, as always, come up with a clever system, which is noise resistant. resistors. So there's a resistor here, another resistor here. And we connect these resistors up. And the clever thing, in a bolometer, is we allow two of the resistors to see the plasma. And these are the ones we call the measurement resistors M1 and M2. So these measurement. resistors, they see the radiated power P rad, and their. temperature is equal to the temperature of the reference resistors plus a change in. temperature due to radiation. setup is your entire bolometer is going to heat up. And so, what you want to know is not just how hot they are, but howHot they are relative to the vacuum vessel. So, this is why we have this system where we're trying to measure a very small change between R1 and R2, which would be identical, and M1 and M2. And it's this small quantity here, delta T, that's due to the radiated power that we're really trying toMeasure. At the Wheatstone bridge, we also use a phase locked loop measurement, which is a form of heterodyning again, my favorite technique. And so, we actually have V0 is oscillating at around 50 kilohertz or so. So, we can see that our signal, delta T, or the change in temperature as a function of time, is a slowly varying signal which is embedded on top of this 50 kph signal. And then, using heterodyting techniques,we can measure it very cleanly without noise. This is often made out of gold. Gold is chosen because it absorbs all wavelengths relatively evenly. So you don't need to worry too much about the spectral response of this. This thin layer of gold has been deposited on top of a substrate. And it's on the back of the substrate that you have your resistor. And your resistor is literally a little zig zag of gold deposited on theBack side of this, so this is M or R. And depending on whether it is M. or R, you either have this open to the plasma or you have a thick block some distance in front of it so it can't see the plasma. heating down from direct heating and then also a time lag phenomena delta T on tau. And, effectively, this tau here sets the timescale at which we can measure. So the larger tau is the slower our measurement of the radiated power is going to be. If tau gets very large, because we've got a very thick substrate here, or it doesn't have very good heat transport, then we're going to have a very poor time resolution of our radiation power. difference between those. neutron damage leads us to use much thicker substrates, which gives us a longer time response and so, therefore, a worse bolometer. So, ironically, the bolometers that will be used on [INAUDIBLE] are significantly worse than the bolometer used on existing devices. And I'm sure that [? Spark ?] will have exactly the same problem. Almost everyone in the world uses this design of bolometer that they pioneered on ASDEX Upgrade in the '80s. No one has come up with a better system yet.

ROUGE-1: 60.54, ROUGE-2: 58.86, ROUGE-L: 58.75
BERTScore: 74.39

==============================================
==================== [79/100] ====================
Summary:
Reinforcement learning involves the idea of a model, a value, and a policy. A policy is a mapping from the state you're in to what is the action, um, to take. A model is a representation of the world and how that changes in response to agent's accident. A value is the expected discounted sum of rewards from being in a state and/or an action, and then following a particular policy. Markov Decision Processes is where we think about an agent interacting with the world. The Markov Process is to say that the state that the agent is using to make their decisions is a Markov state. The Markov process involves taking actions that affect the state of the world in some way, and then the agent receives back a state and a reward. Today, we're going to think of an agent, just focusing on the current state, um, so the most recent observation, like, you know, whether or not the robots laser range finders saying, that there are walls, to the left or right of it. decisions, is the sufficient [NOISE] statistic of the history. Um, but the idea is that, you might have a stochastic process that's evolving over time. And you could think of that as a Markov Process. And so essentially, it allows us to say that, the future is independent of the past given some current aggregate statistic about the present. The next time step. Here we're using t to denote time step, and the action that is taken a_t, is again the action. Markov Chain is a sequence of random states, where the transition dynamics satisfies this Markov property. If you have a finite set of states, you can just write this down as a matrix. So if we go back to the Mars Rover example that we talked about last time, we thought of a Mars Rover landing on Mars and there might be different sorts of landing sites. And then, it can go to the left or right, um, er, under the Markov process. of be, passively observing how the stock market for a particular, th- the stock value of a particular stock is changing over time. different actions or we could just think of those actions as being a_1 or a_2, where it's trying to act in the world. In this case, the transition dynamics looks like this, which says that, for example, the probability that I start in a particular state s_1, um, and then, I can transition to the next state on the next time step is 0.4. There is a 0.6 chance that I stay in the same state on  the next time step. [NOISE] that is independent of the start state, if you run it for long enough. So in this particular case, you could have it as, um, the transition of saying, "If you start in state, [NOise] uh, let me make sure that I get it right" So, you would have your initial state. So 1, 0, 0,. 0, 1, 2, 3, 4, 5, 6, and then times P, and that would give you your next state distribution. what are the probabilities computed of, like the rewards, I guess, the probability, based on the reward of going from state 1 to 2 [NOISE] or? Great question, so was, you know, one of this transition probabilities looking at Markov Chains. This is specifying that there's some state of the, uh, of the process. So it's as if you're, let's say your agent, um, had some configuration of its motors. And what this would say is, this is the transition probabilities of if that agent starts in state. this is how, yeah, this is how the world works. So we're assuming right now, the, this Markov process is a state of the world that you were, there is some the, the environment you're in is just described as a Markov Process, and this describes the dynamics of that process. We're not talking about how you would estimate those. This is really as if, this are how that world works, like the world of the fake little Mars Rover. So, let's say that your initial starting state is S four, and then you could say, well, I can write that as a one-hot vector. I multiply it by my probability. And that gives me some probability distribution over the next states that I might be in and the world will sample one of those. So, for example, if we were looking at state s_1, it has a 0.6 chance to abstain in s_ 1 or 0.4 chance of transitioning. It's like sampling from sort of a probability distribution. like before. But now we also have a reward function. So, again just like before, if we have a finite number of states in this case R can be represented in matrix notation which is just a vector because it's just the expected reward we get for being in each state. If we look at the Mars Rover MRP, then we could say that the reward for being an s_1 is equal to 1. The reward forBeing an s-7 isequal to 10 and everything else that reward is zero. rewards for the Markov Decision Process can either be a function of the state, the state in action, or state action next state. Right now we're still in Markov Reward Processes so there's no action. So, in this case, the ways you could define rewards would either be over the immediate state or state and next state, for example. Once we start to think about there being rewards, we can then think about returns and expected returns. We talked about those briefly last time, but it often we think about the case where, um, an agent might be acting forever. long time. The definition of a return is just the discounted sum of rewards you get from the current time step to a horizon and that horizon could be infinite. If the process is deterministic, these two things will be identical. But in general if theprocess is stochastic, they will be different. So, what I mean by deterministic is that if you always go to the same next state, no matter which if you start at a state if there's only a single next state you can go to, uh, then the expectation is equivalent to a single return. General case, we are gonna be interested in these stochastic decision processes which means averages will be different than particularly runs. So, for an example of that well, let me first just talk about discount factor and then I'll give an example. Discount factors are a little bit tricky. They're both sort of somewhat motivated and somewhat used for mathematical convenience. Uh, people empirically often act as if there is a discount factor. We weigh future rewards lower than, than immediate rewards typically. Businesses often do the same. convenience, um, if your horizon is always guaranteed to be finite, it's fine to use gamma equal to one in terms of from a perspective mathematical convenience. There, one could try using other participant is certainly the most common one and we'll see later why it has some really nice mathematical properties. Any other questions? Okay. So, what would be some examples of this? Um, if we go back to our Mars Rover here and we now have this definition of reward,Um, what'd be a sample return? So, let's imagine that we start off in state s_4 and then we transitioned to s_5, s_6, s-7. There's often a bounded number of time you know bounded length of course in many many cases that the horizon is naturally bounded. So, in this case you know what might happen in this scenario we start off in s_4. Um, and then on time-step s_7 we get a reward of 10. But that has to be weighed down by the discount factor which here is 1/2. And so the sample return for this particular episode is just 1.25. And of course we could define this for any particular, um, episode. other cases, um, it might go all the way to the left. So, if we then think about what the expected value function would be, it would involve averaging over a lot of these. And as we average over all of these, Um, then we can start to get different rewards for different time steps. Um, how would we compute this? One thing you could do which is sort of motivated by what I would just showing before, is that you could estimate it by simulation. And that would asymptotically converge to what the value function is. um, and there are mathematical bounds you can use to say how many simulations would you need to do in order for your empirical average to be close to the true expected value. The accuracy roughly goes down on the order of one over square root of N where N is the number of roll-outs you've done. So, it just tells you that, you know, if you want to figure out what the value is of your Markov Reward Process, you could just do simulations and that would give you an estimate of the value. roll out in the world then you can get these sort of nice estimates of really how the process is working. But it doesn't leverage anything about the fact that if the world really is Markov, um, there's additional structure we could do in order to get better estimates. So, the value function of a mark forward process is simply the immediate reward the agent gets from the current state it's in plus the discounted sum of future rewards weighed by the discount factor times the- and we can just express it with V, V(s'). to some state s' Um, and then you're going to get the value of whatever state you ended up in discounted by our discount factor. So, if we're in a finite state MRP we can express this using matrix notation. Um, we can say that the value function which is a vector is equal to the reward plus gamma times the transition model times V. And the nice thing is that once we've done that we can just analytically solve for thevalue function. The question was was if it's possible to have self-loops? Um, could it be that this is sort of circulator defined [NOISE] in this case? So, if one of the transitions can be back to itself, um wouldn't it be become a circular to try to express V in terms of V(s)? And if you have N states, it's fine if some of the states that you might transition back to the same state there's no problem. You do need that this matrix is well-defined. so let's say you have N states there's generally on the order of somewhere between N squared and N cubed depending on which matrix inversion you're using. Is it ever actually possible for, uh, that matrix not to have an inverse or does like the property that like column sum to one or something make it not possible? Question was is it ever possible for this not to has an inverse? Um, it's a it'sA good question. I'm trying to think whether or not that can be violated in some cases. The idea in this case is because of the Markov property, we've said that the value of a state is exactly equal to the immediate reward we get plus the discounted sum of future rewards. In this case, we can simply use that to derive an iterative equation where we use the previous value of the state in order to bootstrap and compute the next value. So, the advantage of this is that each of the iteration updates are cheaper and they'd also will be some benefits later when we start to think about actions. A Markov Decision Process is typically described as a tuple which is just the set of states, actions, rewards, dynamics, model, and discount factor. So, if you think about serve an observation you'd see something like this s, a, r, and then transition to state s'. And so a Markov decision process is typicallydescribed as a tuples which are just the sets of states,. actions, Rewards, dynamics and model. And so for most of the rest of today we'll be using that it's the function of both the state and action. in a state in K action, why is it deterministic what the next state is? Question is same like well why is this- why are there stochastic processes I think. Um, there are a lot of cases where we don't have perfect models of the environment. May be if we had better models then things would be deterministic. And so, we're going to approximate our uncertainty over those models with Stochasticity. So, maybe you have a robot that's a little bit faulty and so sometimes it gets stuck on carpet and then sometimes it goes forward. A Markov Decision Process policy specifies what action to take in each state. The policies themselves can be deterministic or stochastic, meaning that you could either have a distribution over in the next action you take. So, if we think about our Mars Rover MDP. Now, let's just define there being two actions A1 and A2. You can think about these things as the agent trying to move left or right but it's also perhaps easier just to think about in general them as sort of these deterministic actions for this particular example. If you have an MDP plus a policy then that immediately specifies a Markov Reward Process. So, in order to learn what is the value of a particular policy we instantiate the reward function by always picking the action that the policy would take. And then for whatever state I end up by next continuing to follow this policy. So that's what the V^pi_k-1 function is for a deterministic policy. And this is also known as a bellman backup for a specific policy. specifies. What would happen if the expected discounted sum of rewards we get by continuing to follow policy from whatever state we just transitioned to. So, imagine your policy is always to do action a_1 and your discount factor is zero. In this case, what is the value of the policy and this is just to remind you of what like the iterative way of computing it would be. Um, and I think that will be zero for everything except s-1 and s-7 where it's +1 and +10. computation. And it just requires plugging in what is the value of the reward. The value is and- and the particular numbers for the dynamics and the old value function. So as we do these iterations of policy evaluation, we start to propagate the information about future rewards back to earlier states. So if you think about looking at this, that's with information of the fact that state s_7 is good, is going to kinda flow backwards to the other states because they're saying "I might reach that really great +10 state" So what if you just uh, let's ask a question then we can all take a second to uh. I'm just wondering, er, if repeating the same process to find the value function. So what we've done here is we've said, we've initialized the valuefunction to be zero everywhere. That is not the real value function, that just sort of an initialization. And what this process is allowing us to do is we keep updating the values of every single state until they stop changing. And then that gives us the value. expected discounted sum of rewards. Now you might ask, okay well they- are they ever guaranteed to stop changing? And we'll get to that part later. The whole process is guaranteed to be a contraction so it's not going to go on forever. So the distance between the value functions is going to be shrinking. And that's one of the benefits of the discount factor. So if people don't have any more immediate questions, I suggest we all take a minute and then just compare with your neighbor of what number you get when you do this computation. equal to one. If your discount factor is less than one, then I which is the identity matrix minus gamma times P is always going to be invertible. So that's just an example of, um, how you would compute one Bellman backup. And that's back to my original question which is you seem to be using V_k without the superscript pi to evaluate it. Oh, sorry this should, yes. This should have been pi. That's just a typo. to be pi up there. Yes it was, thanks for catching. All right, so now we can start to talk about Markov Decision Process control. Control here is going to be the fact that ultimately we don't care about just evaluating policies, typically we want our agent actually be learning policies. And so in this case we're not going to talks about learning policies, we're just going to talking about computing optimal policies. So the important thing is that there exists a unique optimal value function. before we do this let's think about how many policies there might be. So there are seven discrete states. In this case it's the locations that the robot. There are two actions. I won't call them left and right, I'm just going to call them a_1 and a_2. Then the question is how many deterministic policies are there and is the optimal policy for MDP always unique? So kind of right we just take like one minute or say one or two minutes feel free to talk to a neighbor. This- what this how many policies there are and whether maybe- there maybe it looked like it was going to be linear and it's actually exponential. Um, the way that we're defining a decision policy here, um, a deterministic decision policy is a mapping from a state to an action. And so that means for each state we get to choose an action and so just as an illustration of why this ends up being exponential. So, you could either have action a_1-a_1, you can have action s_1 and s_2. simplicity, we're going to assume that all actions are applicable in all states. Um, in reality that's often not true. In many real-world cases, um, some of the actions might be specific to the state. Ah, for totally, there's a huge space of medical interventions. For right now, I think it's simple as just to think of it as there's one uniform action space and then they can be applied in any state. Okay. So, the optimal policy for an MDP and a finite horizon problem where the agent acts forever. is indexing which policy we're at. We evaluate the policy using the same sorts of techniques we just discussed because it's a fixed policy. A state action value says well, I'm going to follow this policy pi but not right away. So, that defines the Q function and what policy improvement does is it says okay you've got a policy, you just did policy evaluation and you got a value of it. Now I want to see if I can improve it. Noise. now I compute Q^pi which says if I take a different action, it could be the same. So, for all A and all S we compute this and then we're going to compute a new policy and this is the improvement step which maximizes this Q. Now, by definition this has to be greater than or equal to Q^πi(s, pi_i(a)), right, because either a is equal to pi_ i(a), sorry pi_I(s). So, either you the arg max is going to be same as that your previous policy π_i. maybe do some local monotonic improvement maybe, um but are we going to be susceptible to gain stuck. Um, in fact, ah for any of you that have played around with reinforcement learning and and policy gradient and stuff that is exactly one of the problems that can happen when we start doing gradient based approaches nicely in this case. So, we're guaranteed to converge to the global optima and we'll see why for a second. All right. So this is how it works. You do this policy evaluation and then you compute the Q function and thenYou compute the new policy that takes an arg max of the Qfunction. that quantity for each state. But then- so that's going to just define a new policy, right? Like I thought that might be the same or it could be a, a different policy than the one you've had before. Here's the weird thing. So, this is saying that if you were to follow that arg max A and then follow your old policy from then onwards, you will be guaranteed to be doing better than you were before. But the strange thing is that we're not gonna follow the old policy. We are going to follow this new policy for all time. that my value would be better than before. But what you really want is that this new policy is just better overall. And so the cool thing is that you can show that by doing this policy improvement it is monotonically better than the old policy. So, this is just saying this on a words, we're saying, you know, if we took the new policy for one action, then follow pi_i forever then we're guaranteed to be at least as good as we were before. strict inequality if the old policy was suboptimal. So, why does this work? So, it works for the following reasons. Let's go ahead and just like walk through the proof briefly. Okay. This is- what we've said here is that, um, V^pi_i(s), that's our old value of our policy. Has to be less than or equal to max a of Q#pi. Is equal to R(s, pi_i+1(s) The next questions that might come up is so we know we're gonna get this monotonic improvement, um, so the questions would be if the policy doesn't change, can it ever change again? And is there a maximum number of iterations of policy iteration? So, what do I mean by iterations? Here iterations is i.pi_i+1 value is by definition at least as good as the previous value function. So, why don't we take like a minute and just think about this maybe talk to somebody around you that you haven't met before and just see what they think. The idea in policy iteration is you always have a policy, that is- that you know the value of it for the infinite horizon. And then you incrementally try to improve it. Value iteration is an alternative approach. It says you always know what the optimal value in policy is, but only if you're gonna get to act for say k time steps. So they're just- they're computing different things, um, and they both will converge to the same thing eventually. It's useful to think about Bellman. work? The algorithm can be summarized as follows. You start off, you caninitial your value function to zero for all states. And then you loop until you converge, um, or if you're doing a finite horizon, which we might not have time to get to today. And basically, for each state, you do this Bellman backup operator. So you'd say, my value at k plus one time steps for that state is if I get to pick the best immediate action plus the discounted sum of future rewards. basically say what is the optimal immediate action you should take if you only get to take one action. So policy evaluation you can think of as basically just computing a fixed point of repeatedly applying this Bellman backup until V stops converging and stops changing. And so, if you see sort of a B with, um, ah, pi on top and saying, well, instead of taking that max over actions, you're specifying what's the action you're going to take. Wanna see if we can get to a little bit of that? on sort of the contraction operator. So, for any operator, um, let's let O be an operator and x denote a norm of x. So x could be a vector like a value function and then we could look at like an L2 norm or an L1 norm or L infinity norm. If an operator is a contraction it means that if you apply it to two different things, you can think of these as value functions. So just to, um- actually, I'll save examples for later. But this is the formal definition of what it means to be a contraction. doesn't get bigger and can shrink after you apply this operator. So, the key question of whether or not value iteration will converge is because the Bellman backup is a contraction operator. And it's a contraction operators as long as gamma is less than one. So how do we prove this? Um, we prove it- for interest of time I'll show you the proof. Again, I'm happy to go through it, um, I- or we can going through it in office hours et cetera. value functions and then we re-express what they are after we apply the Bellman backup operator. So there's that max a, the immediate reward plus the discounted sum of future rewards. And then the next thing we can do is we can bound and say the difference between these two value functions is diff- is, um, bounded by the maximum of the distance between those two. And so that means that theBellman backup as long as this is less than one has to be a contraction operator. between the two value functions can't be larger after you apply the Bellman operator than it was before. There has to be a unique solution. It's also good to think about whether the initialization and values impacts anything if you only care about the result after it's converged. All right. Class is basically over. There's a little bit more in the slides to talk about, um, the finite horizon case, and feel free to reach out to us on Piazza with any questions.

ROUGE-1: 49.92, ROUGE-2: 48.47, ROUGE-L: 47.09
BERTScore: 65.24

==============================================
==================== [80/100] ====================
Summary:
 angular momentum is a set of operators that provide observables, things we can measure. They are important for systems in which you have central potentials. Potentials that depend just on the magnitude of the radial variable are relevant to cases where you have two bodies interacting through a potential that just depends on the distance between the particles. We found there was another object we could measure, which was the square of the total angular momentum. l squared is, by definition, lx times lx, plus ly times ly, plus lz times lz. This is this operator. And we showed that any component of angular momentum, be it lx, ly, or lz, commutes with l squared. Given that they commute, it's a general theorem that two operators that commute, you can find simultaneous eigenstates of those two operators. And therefore, we set up for the search of those wave functions that are simultaneous eigestates of one of the three components of angular Momentum. Everybody chooses lz and l squared, lz being proportional to angular momentum has an h bar m. for it. All these things were taken care of by l squared. The differential equation for l squared ended up being of this form. For the case of m equals 0 it simplifies very much so that it becomes an equation for what were eventually called Legenre polynomials. We looked at that differential equation with m equals0. We called it pl 0. So we don't write the zeros. Everybody writes pl for those polynmials. And looking at the differential equation one finds that they have divergences at theta equals 0. are the Legendre polynomials. Solve this equation for m equals 0. Are there any questions? Anything about the definitions or? Yes? AUDIENCE: Why do we care about simultaneous eigenstates? PROFESSOR: Well, the question is why do we want to figure out what are the properties of the states? In general, you will be led in any physical problem to look for the maximal set of commuting operators. The most number of operators that you could possibly measure. for every allowed energy, except for 0 energy, but two energy eigenstates. And you would be baffled. You'd say, why do I have two? There must be some difference between these two states. And in that case the answer was simple. It was the momentum. You have a particle with some momentum in one direction, or in the reverse direction. So in general, it's a most important question to try to enlarge the set of commuting observables. Leading finally to what is initially called a complete set of commutes. and an electron we can reduce this system to as if we had one particle in a central potential. So that will be also very important physically. And here there is a simple observation that one can make. Is that the differential equation for p l m depends on m squared. We expect to need values of m that are positive and negative. You have wave functions here, of this form. The complex conjugate ones should be thought as having m negative. So we expect positive andnegative m's to be allowed. definition solves the differential equation star. This takes a little work to check. It's probably something you can find the calculation in some books. But it's not all that important. The important thing to note here is the following. That this provides solutions. And there's no great honor in finding zero solution of this equation. These are no solutions. So this produces solutions for an, absolute value of m, less than l. And therefore m in between l and minus l. It is a theorem that there are no more solutions. No additional regular solutions. that don't diverge. So this is very important. It shows that there is one more constraint on your quantum numbers. This formula you may forget, but you should never forget this one. This one says that if you choose some l which corresponds to choosing the magnitude of the angular momentum, l is the eigenvalue. You will have several possibilities for m. There will be several states that have the same l, but m different. So for example you'll have l equal 0, in which case m must be equal to 0. The spherical harmonicas are going to be those wave functions. They have a normalization, n l m, an exponention, and all that. When you have negative m you must do a little variation for m less than 0 y l m of theta and phi is minus 1 to the m y l minus m. If m is negative, minus m is positive. So you could plug this whole mess here. I don't advise it. It's kind of a thing you can never remember by heart. The specific forms of these polynomials we can find them. The only one I really remember is that y 0 0 is a constant. It's 1 over 4 pi. Here is another one. y1 plus minus 1 is minus plus square root of 3 over 8 pi e to the plus minus i phi sine theta. And the last one, so we're giving all the spherical harmonics with l equals 1. Here they are. Plus or minus 1 and 0.

ROUGE-1: 61.97, ROUGE-2: 59.57, ROUGE-L: 61.07
BERTScore: 74.34

==============================================
==================== [81/100] ====================
Summary:
In order to do that, I basically have to do the integral. So here it is. We have psi of x and t. It's integral dk phi of k e to the ikx minus omega of kt. If you want to see the distortion, you have to keep that [INAUDIBLE]. We'll do that in a week from now. And then, you probably need to think a second. And you say, look. There's lots of things making it look like a difficult integral, but it's not as difficult as it looks. here, e to the minus i omega of k0 t e to ik and some number that you call x, which has been changed to this. And now I can put phi of k to the i k x minus these two exponentials, d omega dk at k0 times t. And I ignore this. So far so good. For this kind of wave, we already get a very nice result because look at this thing. This quantity can be written in terms of the wave function at time equals 0.

ROUGE-1: 30.74, ROUGE-2: 29.79, ROUGE-L: 28.57
BERTScore: 68.69

==============================================
==================== [82/100] ====================
Summary:
There are three common uses of a rotation matrix. The first is to represent an orientation. The second is to change the frame of reference of a vector. And the third is to rotate a vector or frame. To demonstrate these, I will use these three coordinate frames, representing the same space with different orientations. To help you visualize these frames in 3 dimensions, I’ll use my handy tinkertoy frame. This is the z-axis, this is the x-axis and the y-axis. we will learn how to represent the angular velocity of a frame. We will also learn about how to use the frame to represent a frame's angular velocity. We'll also look at how the frame is used to represent an object's speed. We hope you will join us for the next few weeks of classes on how to work with a frame in this class. The next class will be on the physics of the frame in which we are working. The final class will take place in the next week or so.

ROUGE-1: 35.22, ROUGE-2: 26.36, ROUGE-L: 29.92
BERTScore: 66.09

==============================================
==================== [83/100] ====================
Summary:
 RAMESH RASKAR: So this is a position, and this is superposition. And that concept of a position or superposition applies to all three types, shadows- or refraction- or reflection-based techniques. So we saw this last time, and we'll see how-- we already have some projects that are inspired by biological vision. You know, Matt is trying the chicken. And I think it's going to be-- [LAUGHTER] It is going to. Coded imaging is a co-design between how you capture the image and how you process the image. In a typical film camera, or even it is digital camera, you take the picture, and that's basically the end of the story. Here, you're trying to do something clever about how the picture is taken. You can either take a really short exposure photo. But that's going to be very dark. If you take a high ISO, you can recover some information. Or you can just take a long-exposure photo by keeping the shutter open. Photographer RamESH RASKAR: When you try to recover this information, you start getting this banding artifacts. And we'll see it in the next slide, why that happens. If you keep the shutter open for even longer, it'll blur correspondingly longer. So you can basically represent that as a sharp photo, where there is a convolution of the sharp photo with some kind of a Convolution filter. But then you will get a blurry photo, which is well exposed, but a lot of high-frequency details are lost. have basically a 1D convolution that's converting this image into this image. And the way to think about that is in the Fourier domain because convolution in the image domain, our primary domain, is multiplication. So let's say we take this photo. Find the Fouriers transform here. Multiply that by the Foueline transform of a box function, which is a sync. So what that means is that I'm going to take the lowest frequency, multiply by that value, and so on. the frequencies in the image by the amplitude of the Fourier transform of this. And you can already see that lower frequencies will be preserved. But there's also something strange happening. Even some of the lower frequencies are actually being set to 0, which means that in this photo, these frequencies are missing altogether. They have been suppressed. So the moment you take the photo, the damage is done. And there's nothing you can do to recover those frequencies because in the Fouriers domain, you cannot divide those frequencies by 0 and recover an image. box function, which is equivalent to-- when you release the shutter, opening the-- release your shutter button-- opening the shutter and keeping it open for exposure duration and closing it. Instead of keeping the shutter open for the entire duration, you open and close it in a carefully chosen binary sequence. So at the end, you still get just one photo. But now something magical has happened because first of all, if you look at this number one, you'll see that it's not the same as before. It has-- it seems to have these replicas. frequencies-- they're all preserved. Of course, they're attenuated. It's not as high as-- it's not 1.0.0, it's reduced. Maybe it's 0.1 or so. There is still some hope to recover this photo back from this because, in the denominator, we will not have seen. this because of the shutter. So of course, if you try to implement this mechanically, where you open the shutter and then mechanically try to close the shutter, that will be problematic. The idea is very simple. Instead of keeping the shutter open for the entire duration and getting a well-exposed photo, the shutter is open for only half of the time. The support for the representation of the Fourier domain of that function that you describe there is infinite, right? So you actually truncate this in order to-- RAMESH RASKAR: It's not infinite because you still have some width. AUDIENCE: Right, but you have infinite high frequencies there by the sharp conditions. I mean, you can think of this one goes to infinity. But there's hardly any energy left. So although it went to infinity, there is not much energy left in the process. When you get to invert the process then, that's why you're still not getting the perfect images to-- RAMESH RASKAR: In this case as well. You still lost some high frequency, right? You haven't seen the results yet for this. But it's a very controlled experiment in a laboratory. but not 0. If you invert the process-- RAMESH RASKAR: From here, this is what you get. It cuts off and corresponding to the width. The width of this post was very short than yesterday were very far away. And that's this loss of these frequencies also shows up as these artifacts at regular frequencies, at regular intervals. So, again, this one-- this doesn't go to infinity all the way. It's open for two milliseconds, open for four milliseconds. filter from space? RAMESH RASKAR: It corresponds automatically to filter in space. So your 52 vector is going to stretch or shrink based on how fast the object is moving. And you mostly have to think about image space motion because the speed in the real world and-- the distance are they get-- you divide to normalize by the distance. If you're in a dark room, you can just strobe the light, rather than opening and closing the shutter. So you only have to worry about the image space distance. mobile demo of that scene. This women try to figure out the car make and the license plate number. RAMESH RASKAR: [LAUGHS] Well, I don't know how fast you can-- AUDIENCE: Well, the problem is you can't [INAUDIBLE].. RAMESHRASKar: Yeah. So what are some-- let's look at some pictures, actually. So you get a reasonable result. But going back, what are the limitations of this method? Yes. If we did 100 milliseconds, it picks up speed, then your assumption that the 52-length vector will map to some stretched or shrunk version of 52 is not valid. Some parts will go faster and slower. It's acceleration in the measurement, but in the real world, it's still constant speed. You can either go to object space or you can come back to image space to make sure there is no acceleration. it's all linear.this one. What else? AUDIENCE: I guess there should be a little less of an acceleration of-- all of them should be moving the same-- RAMESH RASKAR: Exactly. have multiple cars, for example, and they're all independent, then it's fine. As long as it's moving in a straight line at a constant speed, you're OK. But if the two cars overlap, what happens? Our model fails again. If two cars are partially overlapping during the exposure, it's possible, but it's more challenging because you don't know exactly how fast the two car are moving. So it's just like-- AUDIENCE: OK, but that's just so you can get more light. When I take a picture, the camera automatically decides what the exposure time should be. Similarly, you should look at the speed of how things are moving maybe with an ultrasound Doppler or whatever. You need to know how much the blur is. Another major disadvantage is let's say I want to take this bottle. And if I just rotate it and motion blur that, it will not work. For any point in the front that you're looking at it, it'll work. But the point that was in the back, that all of the 52 sequence-- maybe for the first 10, it was occluded. And the remaining 42, it's seen. during that 52 window. In general, the technique works well when things are moving naturally. But if somebody wants to do this kind of an experiment, or move things behind an occluder and move out, those are very challenging scenarios. Can you combine both horizontal and vertical [INAUDIBLE] masks? RAMESH RASKAR: Vertical, horizontal is fine. You can-- it doesn't matter. It could be moving vertically. Basically, your point spread function-- the blur function will be vertical rather than horizontal. of that object moves in a straight line, OK. It doesn't matter which direction and what speed. So the problem here really is the point spread function or the blurred function is very critical. And this is what we want to study about half of the class. And the concept is very, very,Very interesting because light is linear. So eventually, it's very linear. What happens to a point happens to the rest of the object. So if I have a car that's moving, and I tell you how exactly one point of the car is behaving in the image, I can tell you automatically how the other points are behaving. All of it is going to have the same behavior. same spread image. So you can either-- for experiments, you can just put an LED on the car and see how that LED moves. And that tells you everything. There's also an impulse response. And when you're trying to find a speed of a car, [INAUDIBLE],, a very small impulse. And it answers and comes back. It does. The point spread function for your time of flight. So that's the same concept here. You just want to call leading the world, take a picture, andsee how it works. to engineer activity of the camera. So in this particular case, a point that was moving created a blur like this. And by engineering the time point spread function, it stops looking a bit like that. And then it just turns out that this one is easier to deal with than this one. So that's the basic concept, engineering or actively changing the point spreadfunction. So this is very counterintuitive because you would say, let me just build the best lens and the best exposure time. And so that kind of mimics the human eye. hope, there is some computational technique, that will allow you to go from here to here. As far as I know, animals don't have deconvolution circuitry or deep-learning circuitry. I can look at a blurry image and kind of figure out. I mean, this was a challenge for you, right? Right. So we have pretty sophisticated eyes, but we're still not able to deep learn what this is. If you have some prior knowledge of how the Volkswagen logo looks like, maybe you can say, OK, maybe that was this. But on the other hand, you're immediately willing to believe that this photo is a blurred version of this photo. to recover some information. The goal of coded imaging is to come up with clever mechanisms so that we can capture light. The circuit is very, very simple. You just take the hot shoe of the flash, and it triggers. When you lose the shutter, it triggers the circuit. And then you just cycle through the code that you care about. What can we do for defocus blur that is for motion blur? What can you do fordefocus blur? We, again, want to engineer the point spread function. would you apply spatial coding? AUDIENCE: Coded aperture? RAMESH RASKAR: C coded aperture. So this is coded exposure, coded aperture-- very easy. And all you're going to do is put some kind of a code in the aperture of the lens. And this is how, actually, it started in the days of-- in scientific imaging, especially in astronomy, coded apertures are very well known. So I've been following this for a long, long time. And I thought, it must be useful for something in photography. system. It took almost two years to realize that to put this coded aperture in a camera, there are only a few places where you can put it to get good results. So out of that came this particular experiment. And that was just a graph paper. And then we said, OK, let's come back and think about this. What's going on? Why don't we get good Results? So it took nearly two years. To see the full interview, go to CNN iReport.com. This is a standard film lens, which, of course, can also be used with a digital camera. It's 100-millimeter focal length lens. When you focus with this, it works in very interesting ways. It has to deal with chromatic aberration, geometric aberrations, such as radial distortion. So it has to move all these lenses with corresponding ratios, OK? So I'll pass this around, and you'll see that there are these notches on this lens that are in a parabolic fashion. When you think about a visual camera, you make this very simplistic assumption. That is a pinhole, and there's a sensor. And when you put a lens, we assume that the center of the lens is the central projection, that this always can be assumed to go to that point. So we said, let's look at this aperture. And back then, it was still a reasonable-looking lens. And we went in our lab, and we cut open all the way. And you can start putting new apertures in this plane. and create one single center of projection for normal cameras. For professional lenses, that's not true. For normal cameras, you have the central projection. But again, conceptually assume that all the rays are going through that point because you can replace this whole thing by one single lens in a [INAUDIBLE]. So finding that plane is actually a tricky problem. In retrospect, it's very easy. If the lens makers are putting everything there, we should put a recorded aperture also in the same plane. But placing it over there, it turns out you get the same blur. a out-of-focus picture? What will happen to the LED? AUDIENCE: It's going to look like a code. RAMESH RASKAR: Why is that-- why is that happening? So let's think about [INAUDIBLE] focus. So we have our lens, right? And we have a point light. And we will put some code here. When it's in sharp focus, it doesn't really matter what the code is. Basically, you're talking about half the light, so the photo will be half a square. Ramesh Raskar: If you put the sensor all the way here, you'll see the whole code. If you start moving away, the code will shrink. When it's auto focus, we just see the code, all right? By the way, this is the same idea behind another project, which is [INAUDIBLE]. So the idea came around at the same time of how to make this happen. And eventually, when you put it here, we get another code. That's exactly what's happening here. I'm in a different mode. If I look at this picture, you will see that-- so this is a sharp photo. It's blurred with disc. And it's blurred With that function. You can already see that it seems to preserve slightly more information. But it's still-- you won't be able to with your naked eye. You'll not be able. to figure out what underlying patterns are. After the blurring, you can. do these simple tricks, where the person you're interested in is out of focus. But then you can refocus digitally. So this is the input photo and the stock photos, all right? its Fourier transform is 52 long. So there are 52 entries here, and almost all of them are the same. If I just take a square aperture, a traditional one, and take asquare transform, it will look something like this. So a Fourier transforms of 7 by 7 will have a peak in the middle. But the rest of the time, it's more distributed instead of just all being near the center. It's more like a crossword-puzzle-shaped item, should be easy. In communication theory, everything is [INAUDIBLE].. We think about carrier frequencies of radio stations in frequencies. And convolution, deconvolution-- much easier to think in frequency domain. Although all the analysis in the frequency domain, at the end, the solution is very easy-- just flutter the shutter or just put. the values will be constant. And that's the magic of a broadband code. So if we're placing a broadband. code, certainly we have an opportunity to recover all the information. a coded aperture. Extremely simple solution to achieve that. It's very similar to the [INAUDIBLE].. AUDIENCE: Half the light. Very good. RAMESH RASKAR: Are there disadvantages? Or challenges? Not really disadvantage. Remember, in the. in the photo, at a distance, take our false photo. They will all look like this. At a distance,. At adistance, takeOur false photo, they will allLook like this, or you could put hearts in it, or, like-- motion case, we had to know how much the motion is. But the size of the blur is dependent on what? AUDIENCE: Belt. RAMESH RASKAR: The belt. But not just depth-- depth from the plane of focus, right? So that's an extra parameter you would estimate somehow. Maybe you can use a rangefinder or something like that, or just a software. There are methods you can employ. That's what you would do, like, in a light field, when we did the refocusing. the depth. When it comes into sharp focus, my edges, that must be the right depth. Unfortunately, it doesn't work out in this case. The main reason is that, because it's coded aperture, no matter where you refocus, it still looks like it has very high frequencies. So that makes it challenging. Yes. And we won't go into the detail, but the main reason for that is that it's a coded aperture. So you need to find this 7-by-7 pattern or even the previous case, the 52 pattern. And you take a random sequence. I said, by the time I come tomorrow morning, I'll find a really good code. And I came back next morning. Nothing had happened. I waited all day. It was still running. And it never came out of that. So 2 the 52 is pretty challenging. But even if you use a cluster, it's still a pretty big number. And there are all these theories about how to create different codes for different applications. So you can start with some code and do a gradient descent and so on. good solutions for 2D. But for 1D, there are some really good solutions to come up with that. For 2D, for certain dimensions, they call it one more 4 or three more 4. Basically, when you divide by 4, the remainder can be 1 or 3. And there are certain sequences that are beautiful mathematical properties, of which sequences could have broadband properties and which may not. So it turns out you cannot-- there's a little bit of cheating going on here. filter to the beginning of the signal. This particular filter is actually not circular, but it's linear. So when you apply the filter here, when you start applying the filter at the end of the image, you don't go back to the front. For circular convolution, the match is very clean and beautiful and smoother course work. Or for linear convolution,. there is no good mechanism. So we came up with our own code called RAT code, R-A-T, which is after three quarters. convolution-- I mean the linear convolution is basically circular convolution with a lot of padding of 0s. Finding a code that's 1,000 long is nearly impossible. So, yeah, so it seems like can just choose a random sequence and get a similar property. But actually, it doesn't work. The chances of arandom sequence doing the right thing for you is very, very low. Instead of [INAUDIBLE].. [LAUGHTER] AUDIENCE: Are astronomy people are already using-- In astronomy, you have circular convolution because they use either two mirror tiles and one sensor or one mirror tile and two sensors. If you tile aperture, you'll get really horrible frequency response, unfortunately, because if you put two tiles, that means certain frequencies are lost. It's saying that, if I understand this right, basically, by taking the DC coefficient, you're reconstructing almost everything. But there is a non-zero value at other frequencies. But-- RAMESH RASKAR: No, no, that's very important. you could get a very good approximation. But if-- to a naive consumer, this photo-- so look at this part, OK? This photo and this photo looks almost the same, right? And remember, in this photo, many of those frequencies are lost. And in this picture, those frequencies aren't lost because all the frequencies are preserved. But that's because our eyes are not very good at thinking about what the original image could be, given either this one or the previous one. yet. There is no medium filtering or smoothing or anything. It's just pure x equals b, x equals a backslash b. What's amazing about coded imaging is that the math is elegant and beautiful and sometimes complicated, but the implementation is very easy. At the end, all I had to do is put this code or shutter it, and very easy to explain. All right, so let's move on. OK, let me finish this one. We only saw two ways of engineering the point spread function. question. RAMESH RASKAR: Yes, go ahead. AUDIENCE: What if the mask was not quite? If you have some information by the board so that you could set up approximate [INAUDIBLE].. RAMESHRASKar: So what would you have? RASkar: In case of aperture, yes. It doesn't have to be opaque or transparent. It could be a continuous value. It turns out that, for any continuous code, there is a corresponding binary code that will do an equally good job. so far. And that's because in a binary code, you get to play with the phase function. Mike? AUDIENCE: Has anyone tried to combine the coded aperture and the coded [INAUDIBLE]? RAMESH RASKAR: That's a great idea. People talk about it, but nobody has done it. It's like we are sick of it, so we don't want to do it. But I think it's worth trying. And because those are orthogonal motion blur. Can you use both at the same time and record? There are orthogonal technologies, basically. RAMESH RASKAR: Exactly. So it's amazing because motion is time, and the focus is space. They're completely Orthogonal. So you can play with it. It's very interesting. Eventually, it's going to have a 2D projection. Yeah, eventually, it'll be able to do that. It'll be very interesting to see how it'll work in 2D. It will be very different from what we've seen before. at the top-- I'm sorry, at the bottom. The bottom one goes at the top. And when you think about the cross-section of all the straws, it's kind of cylindrical, when they all come together. So no matter where you are, the image is out of focus but by the same amount. It turns out that from that, you can recover images. Like, so this is open aperture. We discussed it in the class, so I hope you remember that. saw this right in the very first class, by the way. And the benefit of that, it turns out, is that it preserves the spatial frequencies, and it has the benefit that, no matter which steps you are at, you have the same defocus blur. So the disadvantage of coded aperture was that you need to know what the depth was to be able to deblur. But now, because it's independent of depth, you can just apply the same deconvolution and get back a sharper image. smart people who invented this. It's very sad Because that part is done. So they just wanted the technology. And it's in a lot of cameras. There's another company called Tessera, which has a very similar solution. But what they do is-- this one, basically what it does is they are simply placing an addition here so that this part of the lens will focus on an image here. This one focuses here. The top of the Lens has a short focus lens. adding small matchsticks on top of the main lens-- or the way they do it is they actually put one single sheet that looks like that, an additional layer of support, a face mask. A face mask basically means you are changing the face of incoming light. That's why, as we learned about at the beginning, if you have something very far away, this slows down a little bit. This is the Syrian optic solution or the [INAUDIBLE],, which is actually bought as another company. the name. The solution is very similar. I'm sure they're fighting out in court right now. Same solution. Instead of putting this particular guy, that's just going to add some extra glass, but mostly in a minor form. It's just [INAUDIBLE] on that one. So basically the same solution but creating different focal length for different [? partners. ?] AUDIENCE: Yeah. Although you said, I mean, there's this portion there, where if you have another blur [INAudIBLE],, right? RAMESH RASKAR: Right. blur is only about 10 pixels, no matter where you [INAUDIBLE]. So maybe that was the matter. If you have a point of access, it's still going to create an image that's blurred 10 pixels. So this is, again, very counterintuitive, where you go to make the image intentionally blurred. It's just that it's blurred everywhere. And then we also saw this one very early on, where the point spread function-- typically when something goes in and out of focus, it looks like a point. of this? AUDIENCE: Does [INAUDIBLE]? [LAUGHTER] RAMESH RASKAR: She would have used it by now. If you go slightly out of focus, you get a very different point spread function. So when you're looking with a microscope, depending on what the depth of your tagged particle is, the point spreadfunction will look very different. So you can estimate the depth by looking at the orientation of those two dots. So that's very interesting. some point, they'll stay the same. RAMESH RASKAR: The xy still remains traditional microscope 1 micron, 1/2 micron. But the z-dimension is 10 nanometers. They are still working on a lot of these concepts. OK? So let's very briefly look at compressed sensing because it's something you should be familiar with. It's a very cool idea, by the way. As a scientist, I really like it. But when somebody like Technology Review or Wired Magazine says, Top 50, Top 10, of course, I wish I'm listed among them. Single-pixel camera was listed as one of the big things in 2005 by Technology Review. The idea is, instead of taking one single photo, what you're going to do is turn on a single photodetector and aim it at a set of micrometers. If I just turn on this one micrometer-- by the way, this is what's in your DLP projectors, the Texas Instruments Digital Light Processing Micrometer Displays. | just receive light from the scene for that one pixel. Group at Rice University claims it can take a million readings to get a million-pixel image. If you're on 2 megapixels, then you need to take 2 million [? pics. ?] All right? So the claim is that imagine if you go through this million pixels, you willget a million megapixel image, right? But of course, the light will be very little if you just turn on one pixel. And, again, if you take million such readings, you can recover this picture. That's the concept. you had this photo as a JPEG. In a composite, it might take up only about tens of thousands of bytes. So I can take this picture effectively with just 10,000 pixels but recreate a million-pixel image. And that's where the concept of compressive sensing or compressed imaging comes up. You want to take something that is much higher resolution but recover it in a compressed way, where it's taking the picture with a hardware and compressing the software. So how does it look mathematically? of these projections. This is the [INAUDIBLE] matrix, for those of you familiar. And these are our measurements. So we're going to say, given these measurements, I'm going to recover my original image. Now, when you think about a natural image, the claim is that if you just use DCT, some photo coefficients, then you can compress the image and represent them with very few bytes, only 10,000 bytes for a megapixel. That means that if I just put a Fourier transform here, then I can convert the coefficients into the image. can transform the image and measure in [? your ?] measurements. And there are certain cases where it is really true. You have signals that can be compressed very easily. A very classic example is in communication, where you have a huge band of frequencies, and software radio. Instead of tuning it with electromagnetics, you just capture the whole signal. And the necklace theory says, if your band is, I don't know, 100 megahertz, then you must capture it with a signal that has a bandwidth of 100 milliamps. When you do JPEG, it does frequency transform. It says, perceptually, the higher frequencies are not as important, so I'm going to represent them with fewer quantization grids. Or certain values are too small. So all this operation-- changing quantization bands, truncating, or thresholding, are all nonlinear operations. They are not linear operations. So in general, this scheme doesn't work. But you will continue to see people who come to you and say, you know, I have this magical thing I just heard or compressive image. dangers of [? compositions. So what this is achieving is basically allowing you to build a camera with a single sensor. But do we really want it just to do compressed sensing? RAMESH RASKAR: From a scientific point of view, if somebody can build this and show that you can take fewer measurements and recover the image, that's a breakthrough. How do you use it? I agree with you that, in terms of practical implementation, maybe this is the best application, maybe it's not. a very, very active field. If you think about a B1 and B2 and visual processing, there's a lot of work that has been done over the last 30 years. There's good work at CSAIL as well. But that's purely software. And maybe you're asking, can we use sensing mechanisms that are similar to our brain so that we don't need to do any software? That's the secret of success for film, of film photography, is that if somebody had given you this problem before the invention of film, that there is a scene-- and I want to give you a sensation of the same scene. Photography is a record of visual experience, which is great for humans, but not so great for computers. What computers care about are all these high-level features. That's why we're going back to the drawing board and saying, let's build cameras that are not mimicking human eye but actually extracting more information, like [? apertures ?] that we remove the flash camera, or additional information with light-field cameras or multi-spectral cameras and so on. of-- so Brett was asking, why would you want to do [? precisely? ?] When do you have to reduce the number of measurements? And I think one of the problem [INAUDIBLE].. I don't know. The debate about whether it's really better or not is photography. RAMESH RASKAR: Tomography, yeah. Tomography is a very high-dimensional signal. There are only a few places. If you think about taking a CAT scan of your body, there are only four or five types of materials. looks just like a cartoon does-- some whites clothes, some black clothes. And that's why compressive sensing works very well there. Compressive sensing allows you to take less measurements. But the problem is you need to actually have more information about the scene before you take the measurement. The measurements are done in a non-adaptive manner. So you don't have to know anything about the scenes to do this measurements. That's actually one power of compressive. But if you want it to actually succeed, you have to be able to reconstruct the scene. In software and reconstruction, I don't worry about some prior information about the scene, which is great. But in the case where you're just taking a set style of captures, that you're limiting yourself in what kind of scenes will be compatible with that capture. So for example, if I just had a scene that's all white, then just one captured would be enough. RAMESH RASKAR: No, the claim is that even if you don't, then you lose the benefit of taking less pictures. you don't know anything about the scene, you take very few measurements. Once you take its transform, some transform, it's very sparse. It can be represented in a complex place. The code for it's inside the dual photography thing. So tomography is the same. It's 4D capture for 3D representation. OK, so I'm sorry we're not taking a break. Should we take a 30-second break before we move on to two very small topics, such as quantum computing? which is how to write a paper and wishlist for photography. Which isHow to Write a Paper and Wishlist for Photography: How to Write A Paper and Write A Wishlist For The Camera. For more information on writing a paper or wishlist, go to: http://www.cnn.com/2013/01/30/photography/how-to-write-a-paper-and-wishlist-for-photography-how- to- Write-A-Paper-And-Wishlist.html.

ROUGE-1: 59.21, ROUGE-2: 56.51, ROUGE-L: 55.10
BERTScore: 71.44

==============================================
==================== [84/100] ====================
Summary:
Prof: You know why I am dressed up? When I do this course and when I do the first half of the French course I do a lecture on the bourgeoisie, the middle classes. Middle class was a form of self-identity that was constructed in the way being a worker was constructed, or being a noble. So, as a result, look at this. I wear this about once a year. Unfortunately, I wear it to funerals. The last time I wore it was something Bill Clinton had, some mutual friends. my one tie. The last time I bought a tie, ties cost fifteen dollars. This is a seventy-five dollar tie. That's a long way of answering your question about why I look like this today. But I hope to make some sense of that in the lecture. I didn't set that question up, did I? I Didn't ask you, "Please ask that question." When you're looking at me dressed, it's not Halloween. When you see Daumier or you see Delacroix's famous, Liberty Leading the People, and you see the bourgeois, there with his top hat, he's dressed in a bourgeois uniform like this. of class identity for ordinary people, for working people, the bourgeoisie had as strong a sense of self-identity as any social class you could imagine. It was, as I'll make the point in a minute, difficult to get into that class if you weren't born into it. The fear of falling out of it was something that helps motivate lots of political things in the nineteenth century. The ideal aristocrat, and this is how an aristocrat would have talked about him or herself, was born into the aristocracy through blood. The French Revolution and with Napoleon, middle-class values seem to be something to be emulated. The word "bourgeois" has really more cultural connotations, maybe, than objective or social categorization. We'll see some aspects of that in terms of access to private space. The middle classes shared some cultural values and symbols in common. When challenged by ordinary people, the middle classes could snap back in an extremely cohesive class-based manner. The class of middle classes is probably a better term. The French Revolution opened the way by removing legal blocks in very many places to the career open to talents. Napoleon used to say tediously that in each soldier's backpack there was a marshal's baton, or staff that you could get promoted with good work, hard work, if you didn't get your head blown off in one of these battles. The bourgeoisie did anything but that. Work was part of how they believed to get ahead, and getting ahead is what they wanted to do. It was always in the nineteenth century sort of classic to poke fun at bourgeois culture, and in some cases the lack of it. One employer wrote in the 1830s that, relative to his workers--is that the worker, I couldn't invent this, "should be constantly harassed by need, for then he will not set his children on the right path" It was a classic to ascribe to the middle classes philistine habits in which making money was really the only thing that counted. a bad example and his poverty will be the guarantee of good behavior." Of course, this is a caricature of middle class self-absorption, of narcissism, of this inveterate cruelty to the classes below them. On the other hand, the more we study the middle classes, we see certainly that no matter where you look one of the things the middle class people did was form voluntary associations. The middle class formed voluntary associations, and many of these were for extremely charitable purposes, particularly in Britain. to do an awful lot for ordinary people. It has a sense of moralizing. There's always this sort of top-down look about moralizing them. The Society for the Protection of Cruelty to Animals, these sorts of organizations really are one of the classic examples of bourgeois voluntary associations doing good things. They get together for social reasons in the coffeehouses of England, and in the clubs, circles you call them in France, and their equivalents. They also get together to hang out with each other and sort of try to gauge who has more money than the other. in Germany, and Italy, and Spain. One of the more ludicrous kind of mottos, we call it a devise, a motto, of the Society for the Protection of Cruelty to Animals was "One must love animals, but not fraternize with animals" You can see how, in places in which bullfighting over the long run in the nineteenth and twentieth century, such as the very south of France and in Spain--there were always movements to try to protect the bulls. Religion was a fundamental part of the British middle class's view of itself. The percentage of people who went to church could be exaggerated. There's a massive kind of church building campaign that has its counterpart in almost every country as well. After the Paris Commune of 1871 they start building churches in France, and in other countries as well, including the U.S. and Germany. The church movement in France is well studied, but you still had this de-Christianization. in the working class districts perched on the edge of cities. More about that in another lecture. Religion for the middle classes has a greater role in their lives than in working class cities. In the case of the peasants, there weren't any peasants left in England. I'll talk about that and it will be fun to talk about in one of these lectures. Anyway, there we go. How many people would have considered themselves middle-class? How do we know? How would you know who is middle class? the 1970s on what they used to call the new urban history, which is counting people up and deciding who might well have considered themselves middle-class. Inevitably I have to talk some about Paris because the work is so rich there. A woman called Adeline Daumard wrote a dissertation that was subsequently published called Les Bourgeois de Paris. She determined that somewhere between seventeen and nineteen percent of the Parisian population in the first half of the nineteenth century would have been considered bourgeois. Hamburg, Bremen, and Lübeck, and Hamburg above all, have a very enormous bourgeoisie. Barcelona is a really natural economy based upon important economic relations between its hinterland and Barcelona. Naples is one of the biggest cities in Europe right through the early-modern period. In Poland, Warsaw had a large--I was just at a history museum, a fascinating one at Warsaw Museum a couple months ago. In Russia, the estimates are about two percent of the population were middle class. of Istanbul, but Istanbul isn't in the Balkans, but with an important middle class. At the very top there are the great bourgeoisie, the big bourgeoisie. These are people who are big financiers. The nineteenth century bankers will become much more important for perfectly obvious reasons. They are big wholesale merchants who are making bundles shipping things from here to there. You won't yet find lawyers and people like that. What also makes them the high bourgeoisie, a small percentage, is that they have access to money. There's a revolution in France in 1830, yet another one that you can read about. Arguably--Marx says this and in a way it's sort of true--what it does is it brings to power in France the big bourgeoisie. They have the ear of the king, Louis-Philippe, who calls himself the Citizen King. He would rule from 1830 to 1848. He was noble. But in the official government he was not any bourgeois. That's what he calls himself. He's still the king. paintings of him you see people dressed like me who are coming into the throne room. They have power. He wants them in the painting with him. That's terribly revealing. So, these are people,. these are big bankers, high financiers at the top. Then you've got other layers of bourgeoisie. You can kind of fill in the gap. Here we have smaller bankers, not in size but in money, industrialists, merchants, these kinds of people. Lawyers rise up rapidly in popular esteem and usefulness. The middle class likes to see themselves as useful. Notaries know all of the secrets of people with money, he says. Notaries are important in all these countries, et cetera. Then at the bottom you have the petty bourgeoisie, and everybody's making fun of the petty bourgeois, but they too had a self-identity. Can you imagine going to a professional history conference where they all had their little nametags? All they do is they start up your body and look at your nameteags, and see if it's worth looking at your face. Pathetic. Can you imagine going to a conference like the World Congress of the Petty Bourgeoisie? "Hi, my name is Albert." But they had a self-identity. Who are in the petty bourgeoisie? Lots of these classically new nineteenth-century professions--schoolteachers. Schoolteachers were a way of social mobility for peasant families. Out of the working class or out of the peasantry female schoolteachers become increasingly more important. Master artisans own the tools that their journeymen work with. They rent or own their shops. times, as you know, in the French Revolution--;the French revolutions, and in the revolutions of 1848. They're always there. These folks are here, too. People are always dumping all over them needlessly. I will give you some example. If you've ever read the great French novelist--;he was paid by the word, but Balzac is really the novelist of the bourgeoisie. When he describes Paris and the seventeen to nineteen percent of the population who are increasingly living in the western part of Paris, he describes it as a jungle. as a jungle. In several hundred brushstrokes, Daumier captures the look of panic on his face because he's going to go home without his hat. He's got to buy one, and they've got to put the money together so he is not going to fall off the ladder in this jungle. Then you have to imagine this as a ladder, like this. In order to really give an image of what it was like, he's got this one magnificent print called the "Street of the Four Winds" mobility is the goal. You want to have enough money to leave to your 2.2 children. Then you'd have to grease this pole through bad economic times. What happens down below here? Holy cow! That's the big sea. I saw this wretched movie called the Poseidon Adventure once. It had an image where the water is kind of coming up below and it's going to finally get to the top and there's no more room to breathe. This is how the people on the bottom part of this ladder viewed the demands of the working class. Daumier is the greatest caricaturist in the nineteenth century and arguably ever, to make an extreme assertion, but it really is pretty true. This is what he captures, the prevailing mood in much of Europe in that money, more than blood if you were going to exclude places like Hungary, Poland, Spain, and Prussia. What is the.down here? This is ordinary people. The chances are that in these bad years you're going to fall down. But yet lots of people get up and the ranks of the middle class increases everywhere. man doing? He's counting his money. That's a very nineteenth-century profession, as it is for every subject. This guy, if you have extraordinary eyes and can read upside down, you will be able to see that he is reading a newspaper on the price of colonial goods, imports. He's one of these people that's at the very top of my triangle there. Look, this guy's got his coat, too. This is early in the century. You can tell. Some of these images, this is really not very interesting art, but that's not the point. The bourgeoisie didn't kiss and hug a lot. They still had arranged marriages. Love could count for something, but marriages were still essentially, less so for the middle classes than for ordinary people. That's what they were. They were economic relationships, wrangling over the dowry and that kind of thing. Look at our guy on the left. He's working very hard there. He had probably not secondary education. Most people didn't go to high school, secondary, lycée in France or gymnasium in France. in Germany, et cetera, and et ceta. It represents this world. By the way, we also know that this takes place in the center of Paris, right behind a big department store, subsequently the Hotel de Ville, but right near the town hall. This is very common. You see this in the book you're reading, I think. These things can be represented spatially very easily. One of the themes of the long run is the emergence of prosperous western Paris, prosperous western London, prosperous center Vienna and other places. minute. In Zola's great novel, L'Assommoir, Gervaise dies like a dog on a bed of straw, because there was no more mattress. She must be at the very top. Now these rooms then became in the twentieth century student rooms and then were transformed into enormously expensive lofts. But this is a way of visualizing the special concomitance of what I'm talking about. The more you go up there, you're still within the middle class. People were aware of what these symbols meant. This is your classic Hamburg financier's apartment. Ordinary people did not wear slippers. Domestic servants cost almost nothing. It was considered to be a way of moving up the ladder to say that you had four domestic servants instead of three. You've got brass or copper here on the heater. That's a good sign. You're on one of the lower floors. Why? Because you see the trees outside the window. And you've got a domesticated animal. Pianos were expensive, but the middle class has pianos. The piano replaces the harpsichord. The middle class wants privacy. They want their own rooms. There's the kitchen. This is the domestic with her children, who are part of the team who has been hired to help run this. There is more than one room. You'll see in a minute there's even more than two rooms. It's all obvious stuff. There are lots of rooms. These are very good chairs, sort of Louis-Philippe chairs. The middle class arguably helps create the notion of childhood. In many early-modern paintings children are portrayed as sort of little squished up adults. Most ordinary people--and some of the worst tenements in Europe were in Edinburgh, Glasgow, Lille in France, but also in Berlin and lots of places. There were no secrets at all. What the middle class wants is privacy and they also developed something else, he says. The middle class also wants to be able to make decisions about their own lives. class wants, besides social mobility and access to political power, is they want space. The notion of childhood, childhood didn't exist for ordinary people. To be sure, nobles had children, but it was a different way of bringing up your children. Nobles did not send their children to public schools or even to private schools. They were educated, to some extent at least, by private tutors. If they were poor and didn't have jobs, then they were sent out to beg. hour, when you're supposed to come out when there were guests and run through your extraordinarily modest bag of tricks for the guests. How about birth control? How about not having ten or eleven children? We have friends, one of whom unfortunately just died, very older friends who were born in the early 1930s in the south of France. One had thirteen brothers and sisters, and the other eleven. They grew up in absolute misery. The whole salon, the idea of going to see art shows. It really starts in the eighteenth century. birthday, papa." You didn't take time out to celebrate a birthday if you were an ordinary person having to get to the fields at 4:00 in the morning in the summer, or going to work during the day. There's a whole notion, and here again this would probably fit rather awkwardly into the birth control description, but there's this whole sense of being prepared that emerges with the middle class. It was the idea of protecting that one suit. We didn't carry umbrellas, because it rained all the time anyway and I'd just lose it. The bourgeoisie, the middle classes, and this is particularly true of Germany and France, and of England, too, and other places--they want the right to bear arms. They want to be in the national guard. The national guard might hypothetically be there in case there was an invasion of France or Germany by, I don't know, some distant place, the Fins or something most unlikely. But the main reason they wanted to join the national Guard--and you had to own property to be a national guard--was to be able to vote. You had to be defined as a property-owning citizen to have the right. until you have universal male suffrage, by how much taxes you paid and how much property you own. They didn't want to pay a lot of taxes, but property reflects one's belief in one's own social worth. No longer was it the worth of blood. So, they formed these national guards, particularly after revolutions and after 1848, or after 1830. But these are mainly there to protect them against the workers. Should one day all of these people try to rise up, climb up this ladder, you'll be down there to stomp on their fingers or to shoot them down. H.D. Daumier's light lines, and this is the last one, disappear in this painting, which is called the Rue Transnonain, April 15, 1934-don't write it down, in Paris. It's a street that no longer exists. It disappeared when Haussmann built the boulevards in the 1850s and 1860s. It was selected to disappear because it recalled an event in the early 1830s when these bourgeois panicked and started going into a house full of very ordinary people and simply shooting them. Transnonain, where this happened in the center of Paris, simply disappeared. It didn't quite disappear from the collective memory of people thinking about Parisian things. In conclusion, the middle classes extremely vary. They have a common material culture. They share a belief in achieved status, as measured by the amount of property that you had. They want a collective voice in decisions. Have a good weekend. See you on Monday. Back to Mail Online home. back to the page you came from.

ROUGE-1: 57.33, ROUGE-2: 54.62, ROUGE-L: 51.62
BERTScore: 72.14

==============================================
==================== [85/100] ====================
Summary:
Researchers have confirmed a second smaller space Rock smashed into the sea off the coast of West Africa creating a large crater during the same era. Scientists say it would have caused a tsunami at least 800 M High to tear across the Atlantic Ocean. The asteroid that's believed to have wiped them out 66 million years ago was not the only one researchers have confirmed. The discovery is exciting that it happens to be potentially close to the same time as the chicku event known to be the the main cause of the extinction event that killed the dinosaurs.

ROUGE-1: 38.76, ROUGE-2: 35.80, ROUGE-L: 31.78
BERTScore: 63.39

==============================================
==================== [86/100] ====================
Summary:
Dynamics plays a very important part in automotive design. There's a trade-off between how comfortable the ride is and how tightly the car handles. The subject that we're studying applications homeworks and exams I know that I mean beyond that followingYeah trajectories so missiles stuff like that anything to kill people you need Dynamics what else build a what building a car okay that's good good and what for that's actually that's right but what for well actually in automotiveDesign. MIT opencourseware at ocw.mit.edu. in Dynamics there two sides to it one is here's the system what is its trajectory going to be in other words how will its various degrees of freedom behave over time if you you know stretch it and let it go and it goes twang you know boing right and you want to figure out how it goes in time that that's analysis. H actually suspensions of cars tend to be passive although some suspensions are active but actually in a car cruise control right cruise control is called C control. going to uh go in a certain way right but then cruise control puts in this you know this artificial foot essentially on the throttle and it tries to maintain the speed at a constant level right so we're doing Dynamics end of the course we're going to solve the dynamical equations dou4 is controls where you actually try and put in extra things like cruise control so to make the uh system behave in a way you want it to behave so if you have a rocket open loop right it's called open loop and open loop system is a system that doesn't close the loop. The thrust is only for the first few minutes of its um journey and then it's ballistic ballistic means trajectory it's all Dynamics after that you control it initially to make sure it's pointing in the right direction compensates for wind Etc. A lot of missiles there's a little bit of fuel left so in the end you can do some adjustment right but a bistic missile most of its journey is ballistic okay okay. In the last class we did um I should also warn you I'm a little woozy today uh I had some serious drugs this morning prescription drugs and the result is that I might I think Sam. was saying if I might start babbling but you won't notice because I Babble anyway right so all right Sam didn't say that I said that I bet but anyway s was very respectful okay so uh in the last class we did uh uh we did a problem essentially the whole Pro class was we looked at you know the skier situation and there's a handout AJ's published right on the web where we do the energy formulation and we solve the problem. So today we're going to kind of flow the accelerator a little bit we've been slow and steady we've kind of pounded the concepts in.  angular momentum concept is our stepping stone into Dynamics of rigid bodies because then you can start looking at two and three particles more easily so we'll start with that. Any questions about the last class comments ridicule jokes nothing okay all right so so today we're going to do angular momentums we're still in points Point masses but this is the stepping stone the link to rigid bodies then we'll do a problem we're very problem oriented in this class and then we're Going to do yet another problem but we'reGoing to do multi- particle okay now just a couple of announcements uh one is that pet is that dog. 4 was due uh is due on Wednesday the 10th and the reason is there's no class next Monday and um we posted the solution to that problem from class uh just one last thing I won't have officers today only because you don't want to hear me Babel I'm really sick um but I'm also going to change my officers um several people suggest so the timing isn't right um so we'll talk about the end of class but I I might go to like a Monday off M um like later on a Monday or maybe Wednesday later or something like that. just hang out like at 3:00 p.m. on a Saturday is that something that you you folks would find useful okay we'll do that okay um so here's what we going to look at what no okay we're going to see our first angular momentums and torqus today. Let's say that you have a particle Point Mass heading that way some direction and let's define its velocity we'll call it a v p okay so I have um two questions both of which you probably know the answers to the first is what is the angular momentum of that particle just from your memory go ahead say it aha. point right so let us say I could have done it around o but here's the deal when you do angular momenta it's very useful to pick some point that's convenient you'll see this a lot right if I'm trying to calculate the angular momentum of that door I prefer to do it about the axis for various reasons right forces vanish all sorts of cool stuff happens so I need to tell you which point I just want to to pick a random point and do it that that way so let's say it's Q. going to write it with a little H okay don't don't ask me why angular momentum is written as H I guess it's angular momentum something right it's a vector I'm going to write little H because I'm referring to the angle momentum of a particle. It's a little U notational thing for me that when we refer to multiple particles we use capital a single particle write little so little F. okay this are just definitions no profound concept here um of particle P about Point Q very important what else do I need to say? it will be useful just take it from me for the time being I need the a here because there's an a here. If I use a different velocity to you know it's going to be a different angle of momentum. I'm going to write torque on a particle with a tow because Little T looks like time so I write as a tow torque on the system write to the capital T going forward okay now I missed something there what else do I need to say on point B or particle P what else with respect to Q now do Ineed a frame no and why is that anybody say againe that's right we assume we do it from inertial frame. The MIT way is to do it exactly right using all the mechanisms we've used and guess what you're going to find a stray correction term which you can only ignore in some cases. torque is not always equal to rate of change of angular momentum there's a correction term there are conditions under which it's a rate of angular rate ofChange of angular Momentum but not always you understand because you know it's an analogy so it all kind of makes sense. So let's uh write it out so um we have defined a uh so let's take the derivative of. derivative do I need to say which frame I'm taking the derivative in yes and this thing is going to be I need I'll put it out big let say scaler does that make sense I got to take the deriva to the right side there two pieces to it I need the uh chain Rule and yeah nothing special right everything is completely reasonable according to the laws of math and physics that we've learned so far now. What is this folks what is this this this thing acceleration right so this isGoing to come out to be M or in fact I can re you know I can just kind of write the terms simply like this. Rqp is an ugly term right what do you do with this guy here's what we're going to do. I'm leading it on a path which you would think I mean I'm not doing anything wrong why I'm doing that will be obvious in a second okay everybody Lauren everyone yeah okay so this I can write as this this thing a d by DT of r o minus r oq cross M A VP you understand I haven't done anything wrong I'm just going down. be clear this whole thing is this term and this is thisterm now let's let's write this The Next Step what is this what this m a acceleration of P or acceleration of p with respect to a hm H it's the force on particle P right cross product rqp yes now so I'm just going to put a dotted line so you know that that's what this is is this I don't think you'll disagree let me just write some draw some lines I'm trying to save space as I said. it just looks a little nicer make sense and now I'm going to write the final step what is the cross product of something so what what will this so we have to Let's expand this right associative. What is mavp is a linear momentum right so it's the momentum of particle p with respect to a right plus what is this guy look here what is it okay so so far I've done things that might be like why is he doing that but you you can't disagree with what I did now let me show you why I did that all that. of all engineering graduates who take a car class in Dynamics Berkeley Stanford Princeton might not even see this there is this term and you need to know about it okay it just so happens the term vanishes in many situations but it's key that you know see for Force f is equal to D by DT of P momentum completely coer Crystal Clear when you come to angular momentum it's say artifice yeah there's this funky term which vanishes okay so question to you when does this term vanish okay so let's give it a nice official sounding name how about we call it pesky ter that's nice. The correction term vanishes it's kind of silly but the reason this will become important is that when you look at rigid bodies it it actually you will end up doing something so this is a silly term but these are the two conditions yeah Q is fixed. If I'm taking the moment angular momentum but myself it's going to be zero right but it's also not going to being changing. It just so happens that we often take angular momenta momenta about things like this point of this door about this point. a so let's say there's a car right. Let's say I'm sitting here and I'm calculating velocity with respect to me and but I'm taking angular momentum with respect. to the car that's when the problem occurs. If I're sitting in a car and calculating the angle the velocity with. respect to a car then everything's fine you understand okay why is this important let me tell you why this is important in Dynamics inertial frame my arms robot this is one link. This is one degree of Freedom this is another link. it's not Kosher can't do it if I do I need to include that term right and you you've got a figure that a simple thing like my a robot is a very typical Dynamics application okay common mistake okay now that we've done this let's try and figure out why angular momentum is useful let's solve a problem any questions about this any questions bottom line if you're taking angle momenta about moving points be careful bottom line many conditions it'll be okay we'll elucidate we'll Express we'll we'll nail this conditions. A lot of MIT grads old friends work all over the world very important positions around the world for example the foreign minister of the new British government is an MIT grad. One of my friends Works in a congressional he she helps Congressional analyze things from a physics point of view so you know when Katrina occurred someone asked if it would be possible to change the temperature in the when when a hurricane approaches to dissipate the temperature. She did some analysis and showed that you need something like a nuclear weapon but like you know the most the largest the largest. nuclear weapon ever conceived to even you know impact it by like 2% because the energy in a in a hurricane all right I told you I'd Babble all right let's do a problem here's a problem so imagine a um a table right you notice I've drawn it in perspective you know what perspective is right it's very cool it wasn't intentional but looks good I see everything in perspective right now okay I have a hole on this table right so this is a table and and um it's frictionless hockey puck basically a point map attached by a string and the string comes through the hole. call this Theta the initial length is L one and the initial velocity is we'll call it a scalar because this is how I'm defining the problem of V1 when we actually solve it we might have to define a vector okay. As the thing's going around this person is going to pull the string down and as it kind of goes around it's going to spiral in and end up it's a new length L2 and the question is what is V2 going to be okay so I'll let you uh let resolve this for a second. that stuff let's let's examine it from a uh from a basic you know intuition point of view from what we studied so far first of all when is linear momentum conserved forget this in general linear momentum is conserved when what condition occurs no external Force right so let's study this guy this particle as it moves around does it feel an external Force. As the particle moves around kind of intuitively which direction is it accelerating in kind of cental right so it's has an acceleration in this direction what else is happening maybe there's a potentially a tangential acceleration kind of an Oiler acceleration as well potentially right kind of thing. is so where does force get applied on this the string so the string is applying a tension force on this right are there any other forces gravity is not an issue here are thereAny other forces no so the only Direction it can really accelerate in in fact is what towards this in this direction right so there is a force onthis so is momentum conserved in any direction linear momentum how about tangentially yeah yeah yeah tangentially it is conserved right it is Conserved tangential it's just not conserved towards the center but the problem with the tangential momentum is when it's here the tangentials momentum is conserving this way but then when it comes here it's the directions change so direction is always changing right right.  linear momentum conservation is a vector equation which is the vector linear momentum is conserved right. If if it's not conserved in One Direction but there's no force in the other it's still conserve in the the other direction understand so.that's basically what it is you understand so let's so is angular momentum conserved let's think about it is there any talk on this particle yep go ahead well there are no forces in the tangential Direction on this are there right isn't the velocity changes ah but the velocity.  linear momentum is conserved instantaneously but not continuously because because the direction is changing so we need some rotational momentum which is what this guy is get it. There is no torque on this particle at any point in time it's just a very long way to say listen things going in circles and the only force is radial if we take a cross product it's going to vanish which is why this is such a convenient formalism right because we're taking a cross products here right so it works in. rotation so it works in things where Works in situations where the force or something always points to the center get it I'm don't get a feeling that everyone's convinced there's a frisen of disbelief doubt anybody or it could just be that it's the morning okay tell me do you get it yes or no yes okay so torque is zero now what is the right hand side of this equation so that means that the right side is equal to zero which means a d by DT of ah p q is equal Z. would have to do one of two things I would have had to either calculate this term or calculate or make you know make my frame attach it to the truck. The whole point is to show you they could be surprises but be careful any questions about this all right snap quiz in the next 3 minutes I want you to calculate for me the final velocity literally 3 minutes because I have toDo the dumbbell problem now you know the irony is this problem you could have done before you took this class. momentum at length L2 V2 equate the two and get V2. Theta dot Theta one dot so I'm solving a slightly different problem here with the ma is but it's the same same problem in terms of math okay so if in of I giving you the initial velocity if I give you theinitial angle of velocity then you know you can just write just to make it more interesting L1 B1 cross AQ right angular momentum. A Omega B cross is theta. I do all the math the angular momentum as I get get it is a vector l^2 Theta 1 do s right so initial moment angle momentum is equal to final angular momentum. If I have the length of the cord the angular speed is going to double and the reason it's more interesting it could because when you watch a skater you know do the uh what's what's it called the twirl you know when figure skaters kind of rotate spin spin thank you yeah spin when they spin. I just want to write that okay so that's uh angular momentum conserved you've also seen by the way that angular momentum is a vector in the it's a cross product. It's a vector out of plane in 2D you see that okay is energy conserved for this particle why not? So where did the energy come come from yeah that's because you were doing work by pulling it right potential energy is constant so the can energies because you can also do this with energy by theway right but for that you need to formulate the problem differently. using angular momentum which we did or if you formulated the problem you had a lot of details you could formulate it using energy we're not doing that for example. For energy you need a little more detail of what I'm doing here right any questions can you get the angle the from the we did in fact we did right if you think about this angle the angular momentum the angular angle the energy term would go into the Energy term. The only thing is does the particle have a velocity towards the center yes or no well not necessarily. momentum formulation actually came precisely from FAL to ma. I just gave you a canned way to do it instead of doing it you know each time you have a question I meant ABP I think yeah it was meant to be AVP thanks for catching that I told you I'm on drugs okay and there's a master missing as well there you go and the mm will cancel out okay go ahead yeah it could have a velocity inwards yeah because it's a good question but I'm taking the question. and state it very clearly and I said it fast when I talking about energy so great question if the particle has an inward velocity when I look at that V2 State the L2 State then I missed some terms if however I State you which I I did not state I screwed up I made a mistake if I state to you that listen you start at length L1 is just going in a circle right and then I pull it in and thenI bring it to an length L2 and I stop pulling. is equal to ma there's nothing all this is f is equal ma right so far we've done nothing Beyond it energy comes from f isequal to ma these are all just tricks okay okay so with that now let me solve a multi-particle system so this is a stepping stone into uh into uh rigid body Dynamics in the fullest Glory so what we're going to analyze now is this system this is all think of this in the horizontal plane right like a skating rink um and this is an inertial frame. they always point in in the horizontal Direction in the on the Whiteboard right so they little Gyros they you point that way or maybe they're magnets and there's a big magnet at that end so it's only being pulled in that direction okay and the question I ask now is how does this thing behave so let's examine this first of all how do I parameter or to use the more technical term what nonstandard coordinates do I need to describe the configuration of this dumbbell let me make a proposal to you. p and particle Q is that reasonable it's perfectly reasonable but do I have a kinematic constraint and what would the kinematics constraint be H yeah it's a they connected by a rigid body so they can do whatever they want as long as the length between the two of them remains constant right by the way if instead of a rigid bar if I had a string connecting them what would  the kinematic constraint be? H is equal to R to R so it's equal to to R all right. time dependent and non-time dependent constraints right I mean imagine in the Str with changing length right over time right and by the way that does show up for example temperature something strings you know that does shows up but don't worry about all that the point is if I went with four non-standard coordinates X and Y of this I would have fourNon-Standard coordinates and one kinematic constraint right is there a better coordinate system General a non- standard coordinate system you can think about anybody clao are we assuming that CU will be on the same line okay all right. just say that we use the center of the bar as the kind of the XY location of the dumbbell and then use the angle of the Dumbbell. By picking the minimum number of non-standard coordinates I don't have to explicitly spell out the gtic constraint got it okay now however going forward just to make our math easier I'm going to assume that the same mass doesn't make any much. The problem just makes our lives easier later yep claudo if they had been different would you have placed them the point in theCenter of mass for reasons that are not clear yet. different you'll find out later I would have picked the center of mass which would not have been the geometric Center Center okay but you don't know why so I can't tell you why. A lot of terms cancel out that's the only difference I could still have by the way I could have picked a point on that line anywhere. There would still be reasonable generaliz coordinates there wouldStill be three just the math is easier that's it okay so I don't have to pick theCenter of mass but I pick thecenter of mass. understand the uh um right totally understand the reasoning behind kinematic constraints I'm going to call this point c r o That's when one vector now this angle of this thing is Theta and I'm defining um because this thing I've rotate a lot right uh I just you know it's a little confusing but let me just draw it for you like this if I had if if the way I had drawn it I hadn't rotated that dumbbell so much if I drawn it like this it'll make more sense. this R OC which is some component this way plus some components this way and an angle that we know the configuration of this dumbbell at any point in time. We're going to figure out how it behaves what it trajectory is going to be over time we won't solve it we write the differential equations to solve it right. You'll see that they come out to be very beautiful and you'll see out of the primordial soup you'll recognize the shape say hey that's a moment of inertia we'll do that. from a free body diagram point of view I'm not going to do it right now but very simply there are each bar applies a force on the part on the particle I'll do it later on because I want to the kinematics first so I'm breaking my own rule I'll doing the free body diagrams later on okay let's just do the k cinematics first all right so R of part the position of particle p is equal to r o Center plus since the length of the rod is 2 R I can just write it as did I do that right make sense. cool formula and tell me what's the acceleration of particle p a c yeah look at all the terms is is there a b acceleration of P that's zero What's the next term isthere a CH Stone no right because the points p and Q are rigid they're not moving with respect to frame B right they're attached to frame A. Is there a centripedal term yes and that's going to be what what well that's the oiler term so there'll be an Oiler term as well right. Point got it so we figured out the accelerations of these particles it's very cool in principle now we should be able to equate those ex multiply them by m and equate them to the forces do a free body diagram we should we done right nothing really special here any questions about this anybody okay so I'll just write it out now I won't do it because we have only about 2 minutes left but let me do this this side this white board sorry now let's do the free body diagrams on each particle. stick if I have something at the end of a stick can I apply like a you know does it only have to be a force inwards right. Next week we'll pick up on this and essentially what I'll do is I'll take components and write F equal to ma right I'll write f is equal toMa in two directions here. I'll get four equations one of those equations will turn out to be the same so we get three equations three unknowns we'll solve it and we'll end up with essentially what what what. we'll show is that the acceleration of the center of mass is uh related to the total force and the angular acceleration of. the whole rigid body is related to torque and we'll show it okay and then we'll generalize it. Define angular acceleration and moment of inertia and a more General sense okay so let's stop here because we are over time. We're going to take a break. We'll be back in a few minutes. We've got a lot to talk about.

ROUGE-1: 64.56, ROUGE-2: 62.92, ROUGE-L: 62.53
BERTScore: 72.09

==============================================
==================== [87/100] ====================
Summary:
In this module, I'm going to briefly introduce the idea of differentiable programming. Differentiable programming is closely related to deep learning. I've adopted the former term as an attempt to be more precise in terms of highlighting the mechanics of writing models as you would code. So let's begin with our familiar example, a simple neural network. And this is the programming part of differentable programming which allows you to build up an increasingly more sophisticated model without losing track of what's going on. In a three layer neural network, we start with our feature vector. In this case, it's a six dimensional vector. And we left multiply by a matrix. I've drawn some lines here to help us interpret this matrix as a set of rows where each row corresponds to a hidden unit. And I'm going to take the dot product of each row with the input vector to produce a hidden vector of dimension 4. I'm Going to add a bias term and then I'mGoing to apply an activation function. Now I have a vector and now I can do the same thing again. we're going to see a lot of these box diagrams which are going to represent functions that we can reuse and have a nice interpretation. So the FeedForward function takes in an input vector x and produces an output vector which could be of a different dimensionality. And the way to interpret what people are doing is performing one step of processing. In particular what that processing is, is taking this input vector, multiplying it by a matrix, adding a bias term and applying an activation function. So this is a very compact way of writing something that would otherwise be quite complicated. The FeedForward function that we just introduced, takes a vector as input and we can represent an image as a long vector by, for example, adding all the rows. But then we would have this huge matrix that we would need to be able to transform this vector resulting in a lot of parameters which may make life difficult. To fix this problem, we introduce convolutional neural networks which is a refinement of a fully connected neural network. So here is an example of ConvNet in action. It goes through a number of layers and over time it computes increasingly abstract representations of the image. ConvNets have two basic building blocks. You can take CS231 if you want to learn all about ConvNets. But instead I'm going to focus on the interface and show how these modules compare. And so Conv takes an image and the image is going to be represented as a volume which is a collection of matrices, one for each channel, red, green, blue. Each matrix has the same dimensionality as the image, height by width. And what the Conv is. going to do is it's going to compute another volume of a slightly different size, usually the height and width of this volume is going. to be equal. Conv is going to compute this volume is via a sequence of filters, and intuitively what it's going to do is try to detect local patterns with [AUDIO OUT] So here is one filter and how it works is I'm going to slide this filter across the image. And then for the second filter, I am going to use to fill up the second output channel. The second operation is MaxPool which again takes an input volume and then it produces a smaller output volume. going to slide a little max operation over every 2x2 or 3x3 region. So the max over these four numbers is going to be used to build this [INAUDIBLE] and so on. That's all I'm going to say about MaxPool. If you want to go into the details, you can check out this demo or you can learn more in 231. But again, I want to highlight that there's these two modules. One for detecting patterns and one for aggregating, to kind of reduce the dimensionality. be learned. The second thing is I also haven't specified the hyperparameters which is the number of channels, the filter sizes, and so on, which are actually pretty important for getting a good performance. But I just wanted to highlight the overarching structure and the idea that you can compose in a fairly effortless way. So now let's turn our attention to natural language processing. So here is a motivating example. Suppose we want to build a question answering system. We have a paragraph. It's from Wikipedia and we have a question. We want to select the answer from that passage, from the paragraph. somehow related to product. And also the fact that some words are ambiguous, like product can be-- multiplication or output. So there's a lot of processing that needs to happen and it's hard to kind of specify in advance. So we're going to define an EmbedToken function that takes a word or a token x and maps it into a vector. And all this function is going to do is it's going to look up vector in a dictionary that has a static set of vectors associated with particular tokens. is something that has an interface but not an implementation. A SequenceModel is going to be something that takes a sequence of input vectors and produces a corresponding sequence of output vectors. So in other words, I want to contextualize these vectors using the sequence models. I'm going to talk about two implementations of the Sequence models. One is recurrent neural networks and one is transformers. The SequenceModel can be thought of as reading a sentence left to right. So we have a word which gets mapped into a vector that produces some hidden state. And then we're going to read a second input vector, and I'm Going to update this hidden state along with this hiddenState. A simple RNN works by taking a hidden state, multiply by a matrix, take the input and multiply by the matrix. And then I add these two and I apply an activation function. So at the end of the day, I have the sequence model because that maps input sequence into an output sequence. And I notice that each vector here now depends on not just the input vector but [INAUDIBLE] So if you look at h3, h3 depends on x3, x2, and x1 following this computation map. Collapse takes a sequence of vectors and returns a single vector. There's three common things you can do. If you're doing text classification, you probably want to pick the average to not privilege any individual word. But as we'll see later if you're trying to do language modeling, you want to take the last. The score for, let's say, binary classification is going to be equal to taking the input sequence of tokens. You embed all the tokens into a sequence and now you can apply a sequence model, for example, a sequence RNN. The attention mechanism takes in a collection of input vectors and a query vector and it outputs a single vector. So mathematically what this is doing is you start with the query vector. I'm going to multiply a matrix to reduce its dimensionality, in this case from 6 to 3. And the attention is going to process y by comparing it to each of these x's. OK. So these types of functions where the input and output have the same type signature are really handy because then you can compose them with each other and get multiple steps of computation. Here is one of the input vectors. x1, x2, x3, x4. I'm going to reduce its dimensionality to also 3 dimensions. And now I can take the dot product between these x's and y's. So that's going to give me a four-dimensional vector of dot products intuitively measuring the similarity between the x and the y. So now I have a distribution over the input Vector x1. I can use those probabilities, those weights, when I multiply by x to take away the combination of the columns of x. multifaceted thing. So one thing that the transformer does is it allows us to use multiple attention heads. The transformer uses something called self attention, which means that the query vector is actually going to be the input vectors. So I'm selecting out the input vector and I multiply it by a matrix to reduce the dimensionality. I've done this twice, but in general you can do this any, 4 or 16. So now I concatenate these vectors. I have a four-dimensional vector from this computation. themselves. So if self attention takes a sequence of input vectors and then it's going to output the same sequence of output vectors where the first vector is, I'm going to stick x1 into the query vector for y and compute the attention, and then x2 and x3 and x4. So each of these vectors is comparing a particular input vector with the rest of the input vector and doing some processing. So in contrast with the RNN, you have representations that have to kind of proceed step by step. And the number of steps is the length of a sequence which causes these long chains. be done once the parameters are learned from data. You can think about this as a sequence model that just takes input sequence and contextualizes the input vectors into output vectors. There's two other pieces I need to talk about before I can fully define the transformer. Layer normalization and residual connections. These are really kind of technical devices to make the final neural network easier to train. I'm going to package them up into something called AddNorm and it also has a type signature of a sequences model. processing each xi in context. So there's only one line here. We've done actually most of the hard work. So the transformer block on a sequence of vectors, is going to be x and you apply attention that allows all the vectors to talk to each other, and then you want to normalize and to do this safely. And finally you apply FeedForward to each individual resulting vector independently. So that's it for a TransformerBlock. So now we have enough that we can actually build up to BERT which was this complicated thing that I mentioned at the beginning. Building on top of GenerateToken, we can do language modeling where the input is a sequence of words and the output is the next word. So this is actually fairly simple since we already have essentially all the tools. We apply the softmax to get a distribution over possible words and then we can generate from that probability function. The last vector that's closest to the word that you want to generate next. And then that gives you just one vector and you can use that to generate a token. Translated sentence, given the input sentence or a document summarization or semantic parsing. Each of these sequence can be framed as sequence-to-sequence tasks based on, usually these days, basically BERT and Transformers. So we started with-- Now in hindsight, it seems kind of very simple, FeedForward networks. And we looked at images and looked at convolutional neural networks which were built on Conv layers and MaxPool layers and also FeedForward. So the nice thing about packaging this in a module is that now this is used in transformers and different places as well. encourage you to consult the original source if you want kind of the actual, the full gory details. Another thing I haven't talked about is learning any of these models. It's going to be using some variant of stochastic gradient descent, but there's often various tricks that are needed to get it to work. But maybe the final thing I'll leave you with is the idea that all of differentiable programming is built out of modules. Even if you kind of don't understand or I didn't explain the details, I think it's really important to pay attention to the type signature of these functions.

ROUGE-1: 57.93, ROUGE-2: 56.44, ROUGE-L: 54.72
BERTScore: 75.03

==============================================
==================== [88/100] ====================
Summary:
Professor Amy Hungerford: Today it is my very great privilege and pleasure to introduce Andrew Goldstone, a TF in this course. Andrew is a fourth-year student in the Ph.D. program in English, and he is writing a dissertation on the autonomy of the work of art in modernism. In preparation for that, for next week I'd like you to finish the novel and then read his essay, "On a Novel Entitled Lolita." It should be bound at the back of your book. we had three main themes that were used to introduce this novel to you. First is the idea that the novel invites ethical questions but also holds them off through parody. We looked at Humbert's techniques of rhetorical seduction and related that to a kind of intellectual problem that Nabokov sets himself of trying to make you identify with this villainous character. And that leads to the third big question we looked at, which is the place of Nabokovsky in this novel amidst the many layers. Humbert: "I discussed Soviet movies with expatriates. I sat with uranists in the Deux Magots. I published tortuous essays in obscure journals" "I composed pastiches: "Fraulein von Kulp may turn her hand upon the door. / I will not follow her. / Nor Fresca / Nor / that Gull." "I'm just going to read a little bit of this so that you have the flavor of the thing. I'm going to try to connect that to Nabokov's exile" that Nabokov is burlesquing: Here I am, an old man in a dry month, Being read to by a boy, waiting for rain. And it comes to a moment where the possibility of rejuvenation is described as devoured by a series of caricatures of Europeans. So: By Hakagawa, bowing among the Titians; By Madame de Tornquist, in the dark roomShifting the candles; Fräulein von Kulp--[There she is--] these terrifying figures in Eliot--Fraulein von Kulp--are just some of Humbert's nymphets. So, I called this a burlesque of Eliot's modernism. It takes something meant to be really serious, and turns it in to a dirty joke. Nabokov will say in that afterword you're going to read, "the novel has as its only purpose to afford aesthetic bliss." So, the parody is of something very close to home. sense that civilization itself is being overturned. Third, the idea that the paradigm of experience is artistic experience. Fourth--and this goes along with that--a rejection of convention, especially sexual convention, sexual morality. Sixth, this is a term from the critic Joseph Frank: spatial form. In place of a linear narrative you have a system of cross-references and repeated motifs that give the structure of works. And then, this anticipates my last points: Modernism is self-consciously international. For Nabokov, the highest value is originality. He says this in his last Russian novel, The Gift. "Any genuinely new trend in art is a knight's move, a change of shadows, a shift that shift that all. for all" "I had a teacher who used to compare Lolita to Huck Finn. They are two novels about traveling across America and an unconventional couple. Right? So, anyway. Okay. But now, that modernist tradition is something that Nabokova owes a lot to, but he always tries to distinguish himself from it" displaces the mirror." Okay. Any genuinely new trend is a knight's move. In chess the knight doesn't move in a straight line. Unlike any other piece, it skips over pieces in the way. So the knight, far from going on a straight course, surprises you. You might think of walking in here expecting Professor Hungerford on censorship and getting me instead. But this is a very important idea for Nabokov. And I want to show you that way of writing very early in the book on page 10 now. from traumatic event of the mother's death--should be the center of the sentence; it's just dismissed--hopped beyond into this stylistic wash, a golden haze. So, the strategy of the knight's move is to frustrate your expectations, to leap over the apparently important events into something else characterized by a kind of aesthetic play, and these parentheses are a real icon of that. A critic has counted 450 sets of them in this novel, the parentheses, an important example of the knights's move. is, The Metamorphosis--"Bely's St. Petersburg," a pretty obscure Russian avant-garde novel. Proust is himself gay. One of his big subjects is homosexuality, and Nabokov's reaction to this is really homophobic. It's about a relationship to predecessors who are seen as too similar. This should cue you to think about the theme of doubling in this novel, to think of the possibility of desire between men here, says David Bianculli. he's attractive to all women, about his supposed virility. And it should just make you wonder whether pedophilia is in itself a kind of knight's move from homosexuality. In other words, is there another form of perverted desire hiding behind the one that's in front of us? Just a suggestion: look on page 20, still in Humbert's early life, near the bottom. It happened for instance that from my balcony I would notice a lighted window across the street and what looked like a nymphet in the act of undressing before a co-operative mirror. turns out to be an adult male. And I just want you to ask yourself why that could be. But, Nabokov's relationship to this modernist past is not just the burlesque that he visits on Eliot. It's not just this complicated attraction and dis-identification that he works on with Proust. An element of admiration is also present, and that's really part of his relationship to Joyce. Remember that he names Joyce as the greatest master of twentieth-century prose. kind of suggestion that that banal reality is redeemed by the artist's activity. Fourthly, Joyce loves puns. So does Nabokov. This is incredibly important, and there's a direct glance at that just ahead of where you read. I don't want to spoil what's coming up, but on page 221 there is a reference to--don't look, don't look--to a writer named Vivian Darkbloom plagiarizing from Joyce. That's the anagram of Vladimir Nabokovsky. Eliot's poem describes the hero, Stephen Dedalus, as a young boy trying to write a poem. And eventually in the novel he will succeed in writing a poem, but here he doesn't manage to. And so, this is a kind of forecast of what will happen later on. The further complication is that here he's writing a poems and then he remembers an earlier attempt; that layering of memory, and that kind of layering, is actually a prototype for the layering in Lolita. in the collected poems of Lord Byron. When he had written this title and drawn an ornamental line underneath, he fell into a daydream and began to draw diagrams on the cover of the book. The version of this that comes up in the novel is in the midst of Humbert's diary. And I've given you a piece of that diary to look at on your own on the handout. But this is the moment that directly alludes to Portrait, and it's really very important for understanding Nabokov's technique. Young People's Encyclopedia I found a map of the States that a child's pencil had started copying out on a sheet of lightweight paper. On the other side of the map was a mimeographed list of names referring, evidently, to her class at the Ramsdale School. A poem, a poem forsooth! So strange and sweet was it to discover this Haze Dolores: she, in its special bower of names with its bodyguard of roses, a fairy princess between her two maids of honor. ordinary materials of life become the basis for a kind of artistic achievement. However, obviously this is not like the Joyce, where there is a realistic depiction of a young boy trying to write, getting bored and failing. There is that bower of roses. That refers to Mary Rose Hamilton; Haze, Dolores; Hanek, Rosaline. And then there's Emile Rosado and Carmine Rose--a red rose--Angel, Grace-- really--Stella Fantasia. Lolita is a kind of artificial, processed, bland, easily consumable version of fate. You might think of it as having the same relation to real fate as Chicken McNuggets do to chicken. There is a short circuit between the Joycean idea of taking ordinary life and transforming it into an aesthetic order. In other words, chance is already fated. The ordinary is already aesthetic in the book. The randomness. of life is the same as chance.randomness.of life. thing that stands for randomness in this book, the thing that looks like ordinary detail, has already been arranged to give you artistic pleasure. So, the artificial has taken the place of the real here, and this novel really reminds you of that all the time. This is the, kind of, hand of Nabokov, taking a narrative of real events and twisting it into something that makes a kind of sense, taking fate and making it McFate. And I want to show you one more example of that, in the scene where Humbert and Lolita have reached the hotel, the Enchanted Hunter. 118 near the bottom. "In the slow, clear hand of crime, I wrote 'Dr. Edgar H. Humbert and daughter, 342 Lawn Street, Ramsdale' A key, 342, was half shown to me, magician showing object he is about to palm and hand it over to Uncle Tom." The coincidence--normally, in real life, it would be a delightful coincidence to go to a hotel room that has the same number as your street address. Here it's a kind of too-easy icon of the correspondence between the place where HumberT meets Lolita and the placewhere he rapes her. foreign country, lives in a kind of denaturalized world, a world where, instead of everything making instant sense everything has to be decoded. In that afterword to this book, Nabokov says he had to invent America. That's because he didn't know it already; it wasn't given to him. In a way this is a terrible state, a state of discontinuity with the world you exist in. But it has a payoff, kind of, a payoff which is the possibility precisely of inventing. because Humbert is a foreigner--into something you can laugh at, something youCan enjoy, something that you can apply the knight's move to. Gaston Godin says about the school that Lolita's going to go to, the girls are taught "not to spell very well, but to smell very well" The foreigner's love for this kind of move is a response to this denaturalized world of the exile. It's important, in this connection, to remember that the Knight's move as a way of avoiding obstacles keeps skipping over forms of violence. turn of the staircase was glazed with ruby, and that raw wound among the unstained rectangles and its asymmetrical position--a knight's move from the top--always extremely disturbed me. Nabokov will say that his private tragedy is that, let's see: [His] private tragedy, which cannot, and indeed should not, be anybody's concern, is that I had to abandon my natural idiom, my untrammeled, rich, and infinitely docile Russian tongue for a second-rate brand of English. the fear that it's too like what he wants to do. But the main point here to think about is that feeling of damage. On page 152, Nabokov's wife, Vera, drove him on thousands of miles of trips around the country while he was writing this novel and hunting butterflies. These techniques are really I think the source of the most appealing writing in this book, and so let's look now at one of those evocations of the American landscape which I just think maybe are the closest the book comes just to pure beauty. evocation of the landscape. "By a paradox of pictorial thought, the average lowland North American countryside had at first seemed to me something I accepted with a shock of amused recognition" Nabokov: "beyond the tilled plain, there would be a slow suffusion of inutile loveliness, a low sun in a platinum haze with a warm, peeled-peach tinge pervading the upper edge of a two-dimensional, dove-gray cloud fusing with the distant amorous mist" Humbert says the novel has as its only purpose to provide aesthetic bliss. So, a European artist actually appears again there, with Claude Lorrain, but kind of made strange: given that knight's move, given a new twist. So--instead of familiar, incorporated into this profoundly strange, vast landscape that gets Humbert's most appealing rhetoric--the rhetoric of an exile. But, I don't want you to think that this just means everything's okay. Of course, everything is not okay. Humbert Humbert: "We had been everywhere. We had really seen nothing" "I catch myself thinking today that our long journey had only defiled with a sinuous trail of slime the lovely, trustful, dreamy, enormous country" "We have to pair that with that other evocation of the landscape to see this alternate idea, that actually this distanced criss-crossing of the landscapes could be damaging" "There's another version, yet another, that relates back to that funny figure of Gaston Godin" There he was, in priggish New England, crooned over by the old and caressed by the young, oh, having a grand time and fooling everybody, and here was I. And the contrast here is between someone who has remained tied to that European past, remained comfortably alienated--and by that very means been able to fit into society. And in fact it's more than that: he translated Lolita back in to Russian later on, and he added a second afterword where he said this: That wondrous Russian tongue that, it seemed to me, was waiting for me somewhere. in safekeeping for so many years, proved to be nonexistent. And there is nothing behind the gate but charred stumps and a hopeless autumnal distance, and the key in my hand is more like a skeleton key. So, there's a kind of lost paradise of European culture which he can't get back, even with this spectacular effort in English. That suggests that it's not all to the good; it hasn't been saved by taking up these knight's move techniques, the defamiliarizing techniques; there's still a record of damage. element of violence that keeps coming back, the trail of slime across this dream of transforming reality, in this Joycean way, into something saved. Could it be that all of this modernist technique that Humbert succeeds in putting to his own ends is not an unambiguous good, but a record of a kind of damage? On Monday you're going to hear about this novel's confrontation with the idea that art could be saving, that it could somehow be redemptive, but here I think is a hint that it's something that the novel simply laughs at hollowly. the admirable way foreigners, or at least naturalized Americans, use our rich language. In other words, that the aesthetic discovery of English is something that just kind of fits comfortably into this prejudice of the dull suburban American. So, I'll just end there with this thought, this doubt, about Nabokov's own use of modernist technique in this novel. Whether it could be--not just that triumph of the imagination that Humbert sees in the list of the names--but a mark of a wound that can't be healed.

ROUGE-1: 57.66, ROUGE-2: 55.42, ROUGE-L: 55.14
BERTScore: 69.19

==============================================
==================== [89/100] ====================
Summary:
NORVIN RICHARDS: Today is phonetics, which means that today we begin making funny sounds at each other. Let's see. I'm trying to remember if there's anything that I ought to announce. You remember, maybe, that problem set 1, which confusingly is your second problem set, is due on Thursday. Normally, it would be due on Tuesday. But because I am technologically challenged, it's due Thursday. I just figured out how to get the projector to project over there instead of in the middle. When we speak, if we're speaking an oral language, what we are typically doing is producing a flow of air. And it gets obstructed in various ways in the vocal tract. One way of categorizing the various things that your vocal tract does to the airflow is by what's called place of articulation. So for example, there are what are called bilabial sounds. These are sounds which are made with both lips. And that's what we're going to do. This picture over here on the right is the old technique. And we'll go back to the old days. right is what's called the sagittal section. That is, it's a picture of someone's head cut in half so that you can see the stuff that's inside. Those arrows are meant to get you to imagine that this person is making a sound by putting their two lips together. So that's what you do for the sounds that are at the beginnings of words like "paint" and "bath," and "mouth," and well, "wipe" where your lips don't touch, but they both move. letters of the English alphabet. There are also what are called labiodental sounds. Labiodentals are made with your bottom teeth and your upper lip. We'll talk about other kinds of articulation that English doesn't use, but I think that one just doesn't exist. And again, two symbols of the IPA, which again, are not going to be used. And so that's a symbol of the International Phonetic Alphabet. As we go along, we will be seeing weirder and weierder symbols from the International phonetic alphabet. Interdental sounds are linguistically not hugely common. We have them in English. There are various dialects of Arabic that have them. But they're not all that common. These are the sounds of the beginnings of words like "thistle" and "this" The symbol for the sound of the beginning of "face" is an f, and the symbol for "vase" is a v. The International Phonetic Alphabet is there so that we can unambiguously talk about what we're talking about. There are two different IPA symbols for them. The Greek letter theta is used for the sound at the beginning of "thistle" And that second letter is an old English letter, still used in Icelandic. It's sometimes called "edh," and it stands for thesound at the start of "this" Then there are what are called alveolar sounds. If you put your tongue at the top of your mouth and drag it-- so put it first against your front teeth and then drag it backwards along the top. another new symbol. That's the symbol for the sound of the beginning of a "ship," and another new symbol that's the sound in the middle of "azure," the "zh" sound. Both of those are postalveolar sounds. A little further back, there are what are called palatal sounds. These are either even further behind the alveolar ridge, back where the roof of your mouth gets as high as it's going to get. And the one palatal sound that we have in English is the "y" sound at the start of "year" The IPA symbol for that sound is a "j" Continuing our tour of the mouth, there are what are called velar sounds. In the velar sound, the body of your tongue is up against what's called the velum. The velum is responsible for partitioning your mouth from your nose through your oral cavity. And then further down, further down in your throat, you've got the vocal cords, the glottis, this space that's down there inyour throat around your larynx, and your vocal folds. English doesn't make a huge amount of use of the glottal stop. But it's what shows up at the beginnings of words like "uh-uh" That catch that you're getting in your throat-- that's a glottan stop. The way you make that is by basically slamming your vocal folds together to close off the flow of air. That's how you make an "h," right? As in, what's my word up there-- "help," yeah. I think your tongue is in motion as you are making that sound. So it makes one-- it completely stops the flow of air. And then it gradually peels back and allows the air to flow out. You can think of that first thing it's doing as-- I'm on completely the wrong slide-- as being like an alveolar stop, right? So it's like a "t." And then as it peelsback, "ch," you end up with something like a 'shuh,' like a postalveolar. "Puh" is not an English word for me. There are dialects of English in which that's something you would say, right? "Puh." There are places in English where things that we write as other kinds of sounds actually are, in fact, glottal stops, at least in my English. "Can't" is really just "can" plus aglottal stop. I'm not saying "can't," usually, unless I'm being very emphatic. in mind? STUDENT: No. So we haven't gotten yet to "r." We'll get to " r," eventually. But actually, people discovered at a certain point-- so people investigate this kind of thing in all kinds of ways. These days, people do a lot of MRIs. I'm going to put on the website a couple of websites that have charts of all of the sounds that we're going to talk about plus many more together with MRIs of the insides of people's mouths making these sounds. "r" is one of the kinds of sounds that people classically have trouble with. If you've been around small children, for example, it's standard for them to not quite get "r" right and to say something that sounds more like a "w" at a certain stage. So a place of articulation is obviously not the whole story. Here's another part of the story. It's what's called voicing. So if you think about an "s" and a "z," those are both alveolar sounds. Your tongue is reaching toward the alveolars. "Cat" and "dog" end in sounds that differ in voicing. We say that "z" is voiced and that "s" is voiceless. It's like whistling with a blade of grass, or playing a reed instrument, right? It's getting something to vibrate really fast. And that's what you're hearing and feeling if you put your hand right here when you're doing a "z." That's that buzzing sound that you're seeing and feeling. or-- what's my other example here-- "th" [pronounced as in "thistle"] and "th," right? If you whisper "safe" and "save"-- (WHISPERING) "safe," "save,"-- (SPEAKING NORMALLY) you have the feeling that you can hear the difference between them, yeah? I think if you were to whisper one of these-- so do a controlled experiment. Go back to your dorm. Whisper toyour dorm mate, (WHispering) " safe." And then find out what they think you said. [LAUGHS] Oh, boy. The complaints. f, v, f, f,. v, v. f, v,. v. Does anybody feel a difference between "f" and "v"? Not here, right? Yeah? STUDENT: I guess the "v" is more-- there's more air [INAUDIBLE] NORVIN RICHARDS: So yes? STUDent: Also, my mouth is opening slower, I think. NORVin RICHards: Ah, there might be a difference in the aperture of your mouth. Student: I actually have the opposite of your feeling. what it means is that your vocal cords are vibrating. But I think maybe what we're learning is that you do some other things, too, to optimize the flow of air so that you will get a good vibration going. There's experimental work on this. This is the kind of thing people try to figure out. Yeah, really good question. OK. So when you whisper, you're not engaging your vocal cord, but you're doing all of the other stuff. And that's what you're using to hear the difference. or they can not be vibrating. So you have voiced sounds and you have voiceless sounds. "s" and "t" are voiceless. And "z" and 'd' are voiced. Does that all sound right? Is anyone upset by any of that? Disturbed? Alarmed? Hungry? Yeah, anything? OK, good. So it's back to the Polish plurals. We saw before, we convinced ourselves, or I convinced myself-- and I tried to take the rest of you with me as collateral damage. end in "p" when you add the "e," the suffix, like corpse. Voiced "b" becomes the voiceless version, which is "p," yeah? Those are both bilabial sounds. They involve both your lips. There's a reason that I started with sounds like "s" and "d" and not "s," "c," "d," "b," "u," "a," "f," "g," "m," "n" "z," and "f" and "v" Because you can go s, z, s, Z for as long as you have, breath right? Whereas buh-- there's a limit to how long you can "b," yeah? We just said the way voicing works is that you've got air flowing across your vocal folds and making them vibrate, right? And for a "z," you can see how that would work. So the air just flows. For a "B," well, the air only has so far to go, yeah? That's one reason you can't keep a "b" going for very long. voiced sounds are becoming voiceless. So "z" becomes "s" "d" become "t" "b" becomes 'p" and 'g' becomes 'k' "n" is voiced in the sense that you are stopping the air from flowing through your mouth. "zh" and "sh" are the postalveolar fricatives. And the "zh," is the voiced one, and the sh is the voiceless one. OK. So now we have these three ways of categorizing these kinds of speech sounds-- place, and manner, and voicing. doing an "n," you've stopped the flow of air in your mouth. By lowering the velum, you're allowing air to flow through your nose. This is a nasal stop, a voiced alveolar nasal-- people often just call them nasals because nasal fricatives. For "t" and "d," the airflow is stopped at theAlveolar ridge. For 'n,' the airflow also is stopped. It's stopped right there. It can't go through the mouth. But it goes through the nose. English doesn't allow words to begin with velar nasals. But there are languages that do. Tagalog, for example, the word for now is [TAGALOG]. So it starts with a velar nasal. One of the entertaining things about learning Tagalog is learning how to make sounds that start with velars. If you're an English speaker, you're not used to it. So we've got stops and fricatives and nasals, nasal stops. Things can be voiced or voiceless. about any of this? Is anybody looking at this and saying, whoa, this table has grown out of my ability to keep up? Yeah? STUDENT: Question about the [INAUDIBLE].. NORVIN RICHARDS: Yeah. English doesn't allow words to begin with velar nasals. We don't have any words that start with a sound that's at the end of words like "song" or "year" There are plenty of languages that do. system for categorizing sounds. Why isn't there anything there or there? And what would it be like if it were there? We'll do a little bit of that in a second. But yeah, you're right. So we haven't yet talked about the kind of sound that the IPA symbol "j"-- the sound we usually write with "y" in English, the sound of the beginning of "year"-- we haven's put that on the table yet. We'll get to it. English doesn't have a bilabial fricative. But there are languages that do. In Japanese, you must learn to pronounce the "f" bilabially rather than labiodentally. In English, we have a labiodental "f," with our lower lip against our teeth. In Japan, your teeth are not involved. It is only your lips, yeah? Yeah? What would a buh bilabials sound like? Vh, vh. And that exists, too. There are dialects of Spanish where if you have a "g" between vowels, it'll get this kind of sound, in words like "agua" English doesn't have that. But there are languages out there that do, languages like Hmong, for example, which is a minority language spoken in Vietnam. Let's skip palatal and do velar. We've got velar stops in English-- "k" and "g," kuh and guh. And we'veGot velar nasals, nnnn. What would a velar fricative sound like? Kh. in your vocal tract. But you're allowing the air to flow through your nasal cavity, right? That's what a nasal stop is. Or velar nasal, "ng," like at the end of "king," you're also lowering the volume and letting the air flow through. A glottal nasal-- you'd have to stop the flow of air down there at the vocal folds and let the air go through your velum. So you would need, again, as I say, probably there are unethical surgeons who would modify you so that you could makeglottal nasals. English has interdental fricatives-- thuh and thuh. There are languages out there that have what are called dental stops. Part of your job, if you're learning Tagalog, for example, is to learn to make dental "t"s instead of alveolar "t," because that's what they've got. If you're studying another language, this is the kind of thing to think about because sometimes, your teacher will not be thinking about this. But you should. out what's going on in your vocal tract exactly as you do this stuff. There's all this work on what people do to compensate for various kinds of obstructions in the vocal tract. So yeah, that's another set of IPA symbols. These are your first IPA diacritics, I guess, those little square doohickeys under the "t" and the "d" there. Those indicate that that particular "t," those are dental. There are even languages out there that have both dental and alveolar "t's. The languages of Australia often don't make voicing distinctions. So they have stops, but they don't distinguish voiced from voiceless. They have places of articulation and lots of them, and nasals in all those places as well. But there is no distinction between voiced and voiceless in Australian languages. OK, any other questions about this chart before we zoom past it? Like I say, there will be a link to charts that will look, hopefully, like this, more official charts by the IPA, which will have sound files so that you can listen to trained phonologists making the sounds. English just does not use. what are called retroflex sounds. These are sounds in which the tip of your tongue is on your palate. Instead of a tuh, you're making a cuh-- [NON-ENGLISH]. Retroflex sounds are very popular in India, and Australia, and Indonesia. They're all over the place. And there's a retroflex lateral, too, right? NORVIN RICHARDS: Yeah, mm-hmm. Yeah. uvula, which is the little doohickey that hangs down there at the back. That's your uvula. We do not have these in English, at least when we're feeling well. But there are languages out there the do. Inupiaq has a uvular stop. It has one at the end of the name. The Inu at the beginning means people. And piaq is a suffix meaning something like real, or normal, or regular. German, right? So if you're pronouncing the French word for "red," one of the ways to do it is with this fricative, to say "rouge"-- "rgh". That "rGH" sound is a voiced uvular fricatives. And then there are also pharyngeals. Pharyngeal. involve constriction near the pharyn.geal wall. Arabic has these. The Berber languages have these. You're getting the back of your tongue to get against the back. of your vocal tract. uvulars, retroflexes. And for some reason, the dental stops are still red. I don't know why. Have to fix that. OK. Now people keep asking me about sounds that I've been carefully avoiding, so let's talk about them. There are what are called approximants. Approximants are not stops, and they're not fricatives. They're not nasals. They involve your articulators vaguely gesturing towards each other in some part of your vocal tract. A "w" is like an "oo" sped up. A "y" sound, yuh, is a sped-up version of an "e" as opposed to an "r" or an "l," which are just something else. So why don't we just use the letter "u" for the bilabial glide, for the "w"? And let me see if I can come up with a good answer to that. Eventually, we're going to get to-- so far, all we're doing is talking about sounds individually. There are rules for the distribution of sounds for which it's useful to have that distinction. We make that distinction as long as it turns out to be useful for explaining stuff. Sounds like chuh and juh-- I think I said you could think of chuh as a stop, a "t" followed by a fricative, shuh, or juh. There's a little bit of a debate about whether what I just just said is true or not. But that's the prima facie reason for distinguishing them. said is the right way to think about this or not. What people do is say, yeah, there's this package deal, an affricate. When you're trying to figure out what sequences of sounds are allowed in a syllable in a given language, sometimes it's useful to be able to say this is a language that doesn't ever, ever allow, say, a stop followed by a fricative. Oh, but it's OK for it to end with chuh. That's the move people make, yeah. There are glides like wuh and yuh. There are some other glides there which I can try to read to you. What would a labiodental glide sound like? Vuh, right? Like a "v" sound. English doesn't have those. I believe Hindi does. Similarly, there are velar glides, [NON-ENGLISH],, where your tongue is just vaguely gesturing in the direction of your velum. It looks like something out of Tolkien. English has a very large number of vowels and a not-very-good system for writing them. This is one of the things that makes English spelling so difficult that we can actually have competitions where you watch people spell. In Finnish, the spelling bee would just never end because every word is pronounced exactly the way it's spelled. We don't do that in English. So here are two vowels. And those are their IPA symbols. The vowel in "bead" and the vowels in "bad" For "ee," your tongue is tense. And it's up there at the top of your mouth. And then for "ah" your tongue drops, right? And in fact, it drops so far that it drags your jaw down with it. So one way of classifying vowels is in terms of height. And there are vowels in-between, like the vowel in "hate" That vowel is called mid. So we have high vowels and we have mid vowels, and then we have low vowels. For "ooh," my tongue curls backward. And it avoids my molars. I think that's the thing you were saying just now. Is that the experience people are having? Everybody do some more ee,. ooh, ee, ooh. Feel your tongue moving back and forth. Ignore your lips, right? And think about your tongue. Yep. OK, so we have high, mid, and low vowels, but we also have front and back vowels. Back vowels are vowels like the vowel in "who" and the vowel of "hoed" English is supposed to have five vowels. It does not have five. It has 14. Why do we only have five letters for vowels? Who gave us this alphabet? The Romans, right? Yeah. And in Latin, there in fact are five vowel, which can be either long or short. And so we've ended up with 12, 14 vowels, different dialects of English are different. And we have 5 letters to spell them with. And this is why we have spelling bees. yeah-- one of the reasons. OK, so I've written six of our five vowels here on this chart. And then we have more. So think about "ooh" and "uh," in "who'd" and 'hood," or "ee," and 'ih" in 'heed' and 'hid," or 'ay' and'eh' in 'raid' and "red" or 'oh' and '' in 'coat,' 'caught' There are various ways of talking about this distinction. We say that there's a distinction between what are called tense vowels. English doesn't have words that end in "ih," "uh," or "eh," with the possible exception of "meh" English doesn't even have monosyllables that start with these vowels. The first vowel in "machine" is a schwa. It's not higher back. It is not front. It isn't high. It doesn't stop. It stops. It just stops. There are more vowels in English. Anybody want to attempt to pronounce them? Yeah. English monosyllables can't end in lax vowels that are either front or high. Not all speakers of English distinguish schwa from wedge. Not every dialect of English has all of these vowels or has them all in the same places. "caught" and "cot" are different, have different vowels in them. "dove" [the bird] is pretty similar to schwa and is sometimes represented with that wedge shape there, which is called a wedge. people who pronounce "caught" and "cot" the same. For me, those are two different vowels. I pronounce those three words-- "merry," "marry," and "Mary" The vowel in the last one is more of an ash. I associate that with New Jersey, where-- you're from New Jersey. OK, yeah. We're just about out of time. Let me just give this to you as an exercise. And then we'll stop. Anybody want to try to pronounce the first of those? this exercise next time. As we go along, I'm going to be asking you to read things in IPA. So I'll start putting IPA on the slides more and more. So start trying to familiarize yourself with it and get to where you're familiar with at least the symbols for sounds that we use in English. Do you want me to read the rest of them? I'll do some more IPA. OK, so what's the second one? STUDENT: "Sue says he's a bad egg."

ROUGE-1: 50.07, ROUGE-2: 47.38, ROUGE-L: 46.60
BERTScore: 69.85

==============================================
==================== [90/100] ====================
Summary:
So we're imagining n independent flips of a coin with bias p. So the coins might not be fair. The probability of heads is p. It would be biased in favor of heads if p is greater than 1/2. And we want to know how many heads are expected. This is a basic question that will come up again and again when we look at random variables and probability theory. So what's the expected number of heads? Well, we already know-- we've examined the binomial distribution B n,p. of getting k heads, which we've worked out previously. n choose k times p to the k, 1 minus p toThe n minus k. Well, let's introduce an abbreviation, a standard abbreviation. Let's replace 1minus p by q, where-- so p plus q equals 1, and they're both not negative and between 0 and 1. And when I express the expectation this way, it starts to look like something a little bit familiar. So what I'm going to wind up with is that n is equal to 1/p times the expectation of B n,p.

ROUGE-1: 39.22, ROUGE-2: 38.28, ROUGE-L: 39.22
BERTScore: 80.13

==============================================
==================== [91/100] ====================
Summary:
Aristotle was born 384,15 years after the trial of Socrates. He was sent by his father to go to college in Athens. He spent his life thinking and then he died. There is, obviously, more to his life than that. But, to some degree, this captures some of the way in which Aristotle has been perceived over the centuries. That is to say, the ultimate philosopher. It's time to move on to the next chapter in the history of political philosophy. Aristotle spent four years at the Platonic Academy. He remained attached to it for the next 20, until the death of Plato. He left Athens, first for Asia Minor and then to return to his home in Macedonia. He had been summoned by King Phillip to establish a school for the children of the Macedonian ruling class. It was here that Aristotle met and taught Phillip of Macedonia's son, Alexander. You all remember the recent movie of a year or two ago about Troy with Colin Farrell about Alexander. Who played Aristotle in that film, do you remember? Aristotle wrote disciplined and thematic treatises on virtually every topic, from biology to ethics to metaphysics. Unlike his intellectual godfather, Socrates, he wrote nothing but conversed endlessly. Unlike Socrates, rather in staying to drink the hemlock, Aristotle left Athens and was reported to have said he did not wish to see the Athenians sin against philosophy for a second time. In any case, Aristotle returned to Athens later on and established a school of his own, a rival to the Platonic Academy. Aristotle appears from the beginning to look more like what we would think of as a political scientist. He collected constitutions, 158 of them in all, from throughout the ancient world. Above all, Aristotle's works, like the Politics and the Nicomachean Ethics, were explicitly intended as works of political instruction, political education. Unlike Socrates, who famously in his image in Book VII of the Republic, compared political life to a cave, Aristotle takes seriously the dignity of the city and showed the way that philosophy might be useful. Aristotle's extreme reluctance, his hesitance to speak to the issues of his time, are perhaps the result of his foreignness to Athens. Yet, for a man as notoriously secretive and reluctant as Aristotle, his works acquired over the centuries virtual canonical status. For centuries, Aristotle's authority seemed to go virtually unchallenged. Others would have known came to an end. What did Aristotle think of these changes? What did he think was going on? He is silent. Are you? The authority of Aristotle no longer has quite the power that it once did. The attack began not all that long ago, really only as late as the seventeenth century. A man, who we will read later this semester, named Thomas Hobbes, was one who led the pack, led the charge. In the forty-sixth chapter of Leviathan, Hobbes wrote, "I believe that scarce anything can be more repugnant to government than much of what Aristotle has said in his Politics" man is a political animal, Hobbes believed, could only result and did result, in fact, in regicide, the murder of kings. There are certainly echoes of this reading of Aristotle as a teacher of participatory republican government in the later writings of democratic thinkers from Tocqueville to Hannah Arendt. Who was this strange and elusive man whose writings seem to have been enlisted both for the support of monarchy and for republics, even for a universal monarchy and a smaller participatory democratic kind of government? animal. "That man" he says "is much more a political animal than any kind of bee or herd animal is clear" Why is it clear? "For we assert," he says, "nature does nothing in vain and man alone among the animals has speech" In other words, he seems to be saying that it is speech or reason, logos, that is able to both distinguish and create certain moral categories, such as the advantageous, the harmful, the just and unjust, and things of this kind. Aristotle appears to give two different accounts in the opening pages of the book that you might pay attention to. In the literal opening, he gives what looks like a kind of natural history of the polis. The polis is natural in the sense that it is an outgrowth, the most developed form of human association. In what sense, we could ask ourselves and I think you probably will be asking in your sections, in what sense is the city by nature? InWhat sense are we political animals by nature?" Aristotle says that man is a political animal by nature. He says participation in the life of the city is necessary for the achievement of human excellence. A person who is without a city, he says, who is apolis--without a city--must either be a beast or a god. In many ways he is advancing civilization in some way, says David Frum, author of "The Art of War," published by Simon & Schuster, $24.99. To order a copy of the book, call the National Gallery of Art in Washington, D.C. on 08/05/2014. He isn't saying that man is political by nature. To say it's natural for us to do so is not to say we engage in political life spontaneously and avidly, as you might say spiders spin webs or ants build anthills. He is not a kind of socio-biologist of politics, although he sometimes appears this way. In some ways, to the contrary, he says we are possessed of the power of speech. It is speech that makes us political, he writes. Aristotle says reason or speech, not instinct, is what makes us political. He makes his argument, he says, because logos entails two fundamentally human attributes. The power to know is our ability to recognize, by sight, members of the same polis or city. It is speech that allows a sharing in these qualities that make us fully human, he writes. But to say, of course, that man is political by nature is not just to say that we become fully human by participating with others in a city. The form of association that leads to our perfection is necessarily something particularistic. A society based simply on the mutual calculation of interests could not be a real political society for Aristotle. We cannot trust all people, Aristotle seems to say. Trust can only be extended to a fairly small circle of friends and fellow citizens. Only a small city, small enough to be governed by relations of trust, can be political, in Aristotle's sense of the term. The alternative to the city, the empire, canonly be ruled despotically. There can be no relations ofTrust in a large, imperial despotism. Aristotle argues that freedom does not mean living as we like. It is informed by a sense of restraint and awareness that not all things are permitted. In many ways Aristotle there offers, as does Plato, a certain kind of critique of the modern or even the ancient democratic theory of freedom, which is living as one likes. You can see these opening pages of the book, dense argument being made.about that when you have your sections or when you talk about this text with your friends. What is Aristotle saying about us? condensed in very deep ways, carry a great deal of freight. There's a lot in there that needs to be unpacked. We need to avoid the temptation, in many ways understandable as it might be, to airbrush or sanitize Aristotle, to make him seem more politically correct for modern readers. The question is what did Aristotle mean by slavery? Who or what did he think was the slave by nature? Until we understand what he meant, we have no reason to either accept or reject his argument. Aristotle asks: How is it that some people came to acquire this capacity for rational self-control that is necessary for freedom and others seem to lack it? Is this hierarchy, again, a genetic quality? Is it something we're born with? Or is that distinction something that is created by nurture and education, what we would call today maybe socialization? If the latter, if this hierarchy of intelligence or of the rational is the result of upbringing, then how can slavery be defended as natural? kind of egalitarianism, so to speak, built in to the conception of rational animal and political animal? Yet, at the same time, Aristotle seems to regard education as the preserve of the few. The kind of discipline and self-restraint necessary for an educated mind appears, for him, to be unequally divided among human beings. It follows, I think, that the regime according to nature, that is to say the best regime, would be what we might think of as an aristocracy of the educated. the preserve of the few, of a minority capable of sharing in the administration of justice and in the offices of a city. Would you agree? Unappealing to us, perhaps, for that reason, very contrary to our intuitions and the way we have been brought up. But before we dismiss Aristotle's account as insufferably inegalitarian and elitist, we have to ask a difficult question. What else is Yale, but an elite institution intended to educate, morally and intellectually, potential members of a leadership class? Think about that. Aristotle might, as a natural aristocracy? I leave you with this question to think about. Before we reject Aristotle as an antidemocratic elitist, take a look at yourselves. So are you, or you wouldn't be sitting here today. Think about that and I'll see you next week. Back to Mail Online home. back to the page you came from. Follow us on Twitter @dailymailonline and @jennifer_newton. Back To The Daily Mail home.

ROUGE-1: 47.77, ROUGE-2: 44.72, ROUGE-L: 42.27
BERTScore: 67.06

==============================================
==================== [92/100] ====================
Summary:
Mathematically, a consumer is trying to maximize his utility. And this utility maximization has to be done with respect to some constraint and the constraint the budget constraint we take P 1 x 1; P 2 x 2 should be less than or equal to I. In real life, it is possible that a person derives some satisfaction from having some money left in his pocket, but the way this problem has been framed here the person’s satisfaction depends only on his level of consumption of good 1, and good 2. are taking u naught here. So, what is happening P 1 and P 2 these are market determined that so we are taking because we are talking about consumer P 1, P 2 is its from the market and individual. Now, let us turn this problem little bit you know in the opposite direction; we say that this person wants to achieve this uNaught level of utility which is the same as this u Naught ok. How much what is the minimum level of income he needs to get, this unaught level. And what we are trying to say that this has to be minimized. And how can we what is the idea to minimize the expenditure I should achieve let us say if I am that consumer I should be able to reach to this utility level by spending as less as possible. So, I will write the earlier problem this side. What we are saying minimize P 1, x 1 plus P 2, x 2 such that u of x 1 comma x 2 is 0.1. And what we have here is x 2 here is X 3 ok. P 1 plus x 1 plus P 2 plus x 2 is equal to let us take K, where K is any number. So, for different numbers of K, if we try to draw this because this is a line how did it look like? Student: Downward sloping. Downward-sloping, slope is again going to be equal to minus P 1 by P 2 here also. And similarly, we can draw for different values of K and this is the optimal position. bundle, this is the bundle; let us say x star and here is let us call it also x star in the old problem. What we have done here is take the indifference map and then we have taken the budget constraint. We have started checking with the what is the highest level of indifference curve that can be achieved under this budget constraint and we have figured out that x does not or x naught 0 x star 0 is the optimal bundle. Now what we are doing we are drawing a set of a family of this line P 1 x 1 plus P 2 x 2. Different line corresponds to different value of K. are also expenditure lines I can say. We take any bundle here the expenditure is going to be the same in both of these cases, that is what it represents. In fact, we can overlap what we are doing here we are varying the indifference curve and keeping the budget line fixed. So, basically, these two are dual of one another. If we solve these two, we reach to the solution of the problem of how to get the budget to be fixed and the expenditure to be different. same consumption bundle; it is clear. So, if we solve it what do we get? Here let us say for x 1 instead of using star let me use term M I will explain what does this M, this is x 1 m. What are the parameters P 1 P 2 and I so x 1 the optimal level of consumption of good 1 should be given as a function of parameters in this system and the parameters are P 1, P2 and I is it clear? Similarly, let me write here x 1 H again, I will explains what is H. I is P 1 x 1 plus P 2 x 2. What is e? E is nothing. We are checking we have set up the problem such that this I is equal to this u naught and what we have learned is that x 1 m P 1, P 2 I is. equal to x 1 h P 1 P 2 uNaught. This is an identity. not just equal to. this is always true. I can write it further if you pay attention to this that x1 m P1 comma P 2 and I is e of P 1 comma P2.

ROUGE-1: 56.04, ROUGE-2: 53.29, ROUGE-L: 52.45
BERTScore: 67.98

==============================================
==================== [93/100] ====================
Summary:
The definition is a cylindrical container containing a date covered with a [? basic ?] substance that can be deployed in order to attract and capture insects. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu.The following content is provided under a Creative Commons license. For more information about MIT Open CourseWare, visit opencourseWare.org. i3. A transportation system responsible for moving people and products with an enclosed metal frame equipped with various safety devices using electrically-powered control and locomotion subsystems. A concept for an all-electric vehicle. The i3 and EPFL? Anybody do the i3? Nobody. Anybody else here? Yeah, Veronica. Thank you. There's a lot there. OLIVIER DE WECK: OK. That's pretty good. I would throw a question. Justice. defined could almost apply to a Tramway as well. If this was like a streetcar, don't you think it would apply to that as well? So I think the fact that it's a personal vehicle, I think it's important. So the key in this is, describe the concept using few words precisely, but to set it apart from neighboring concepts. What about Rolex Center? It's a single-layer building with multiple straw used as a library for people to meet and study. bank, a cafeteria, student services. But you could encompass it in a meeting area. You meet and you do some stuff like eating, going to the bank. So in that sense, it's pretty similar. But I think the Rolex Center is such an iconic building that it also serve a kind of a prestige function, to put the institution on the map in terms of it's a statement. Whereas, I would argue our MIT student center, it has very similar functions to theRolex Center, but I wouldn't call it an iconicBuilding. built. So we could spend a lot of time on these, but really crisply refining and thinking about the concept is very, very important. So let me very quickly go through the refrigerator case study to show how do we transition from concept to design. So the first thing you do is understand where is the value-- the stakeholders and the stakeholder analysis and the requirements definition. And then you interpret and incorporate some of the needs into goals, which become requirements. And so the goals then are an instrument of the primary delivery value delivering process. deliver that value you need to design the product, the product system and the product object. And there is a recipe for doing this. So first you start examining the operand associated with value. What's really the thing that generates the value that the user, the beneficiaries care about? Next you say, this is the attribute link. And so the attribute-transforming process is where the value is generated. So the refrigerator effectively becomes a food spoilage rate reduction device. and I. EPFL's Olivier de WECK explains how to reduce the spoilage rate of food. De WECK: Food is pretty essential for humans, this is one of the areas where humans have been very creative. So irradiating, drying, chilling. There's a lot of ways to do this. So keep going. EPFL, how else can we do it? Spoilage rate reduction? AUDIENCE: Using chemicals? OLIVIER DE WACH: Yeah. That's chemical. wine, which is a process to conserve this wonderful [INAUDIBLE].. OLIVIER DE WECK: Please keep some wine for us too, please. AUDIENCE: Beer is the same. So marinating it, vacuum packing, smoking, on and on and. on. My favorite is actually eating it. What do bears do? How do bears conserve food? AUDience: Fat. Right? So bears, they actually consume it and then transform it into fat, into a different storage form, store it inside their bodies. going to operate the system. The element of form and then the specialized element ofform, in this case the cooler, that combination is what we call concept. So once we have that, we can start managing complexity, decomposing function and form, so our system operating process gets decomposed into the primary supporting processes like interfacing, powering, controlling. And then our system object, you can decompose it into different elements, supporting systems, the operand, the operator, and so forth. external heat load, ambient light, and the operator. So exchanging heat means, essentially, the ice itself acts as a heat exchanger. So the speed at which the ice will melt for the same given external temperature is going to be different. So there's an attribute of the ice, which is essentially its quantity, but also it's surface area. And if you put the same quantity of ice, but you put a block of ice,. you put little chips, what will be the difference? Will there be a difference? form that will influence the-- but that's the heat exchanger function. The powering function is pretty clear. That's essentially the energy storage right there. And then the third one is regulation. How does that work? How does the ice provide a thermal regulation in the cooler? Physics 101. And you can go very detailed here, even if you think of a cooler as being something super simple and trivial, once you start listing its internal functions and how the top, the bottom the ice itself, how they interact and support those functions, it's pretty complex. for something very simple like a cooler. One question and then we'll talk about the refrigerator and how it's different in a minute. So architecture selects the concept, the decomposition, mapping of function to form. Design, then, given that, selects the actual values for those design variables, and then you can optimize. So when you look at the example of the cooler here, we have our cooler with the box in the bottom and then the ice, and we can decompose the attributes of that. Swiss refrigerators are much smaller than those in the U.S. That's a big difference between the US and Switzerland. People in the US, we like to have big refrigerators, big gallon of milk. But here we have essentially the decomposition of the refrigerator. We have racks, we have the air. And freon is banned now, so we should use some other. This is a very important distinction. It's the form function mapping for refrigerators. It has a bottom and a top and it's hinged and it uses this phase transition. is a refrigerant, a working fluid, the insulation, the feet and rollers, the frame, the electric motor, sensors, controller doors, lights. And then we have those functions, essentially, the same functions we had for the cooler, holding the food, exchanging the heat, powering, regulating. But the difference is that we have much more of a one-to-one mapping. So the form function mapping in the refrigerator is actually much simpler. It's a much simpler formfunction mapping than the cooler. is concept generation. So take the requirements and think creatively about how these requirements could be fulfilled. That's concept generation, finding systems that do the right thing. And then once you have several concepts, you've got to select among them, which we'll talk about next week. Do you do you see the difference? What do you think? Share your thoughts in the comments below or post a video on our Facebook and Twitter pages. Follow us on Twitter @CNNOpinion and @CNBCOpinions. The NASA approach is basically described in the system engineering handbook in the SE engine as step 3 called logical decomposition. It's about starting with the operand. What is the thing that the beneficiary, the stakeholder cares about and how do we transform that? Concept then elaborate these into architectures that have form function and structural complexity. And then the goodness of an architecture is really a pretty complex concept where we have multiple objectives to satisfy, including performance, resource utilization, cost, operability, safety, capacity, and so forth. The logical decomposition process, as described in the NASA standard, is used to improve the understanding of the technical requirements and the relationship among those. So the idea that we need to partition the system and then derive lower-level technical requirements based on that. That's what's called architecting. Getting back to our high-level system design process, this is, again, that diagram that we've looked at several times already. You can see the red box is where this happened. So we started with mission authority, stakeholder expectation, and then defining those high- level requirements. safe? Is it reliable? And if yes, then you can select that as a baseline, if not, you might have to go back to the red box, which means that architecture didn't work. So you can see this relates very strongly to the system modeling languages that we talked about. And in terms of the logical decomposition flow diagram, you start with your basic high-level requirements and measures of performance. And then on the right side, you come out with the lower-level derived technical requirements. and the logical decomposition work products, which are essentially lower-level definitions of what these subsystems look like. And then you can go off and do the detailed design and then the testing verification and so forth. So it's essentially focused on decomposition, which is an important part of architecting, but it's not the only thing you do. So let me talk about methods and tools for concept generation. So what are different ways of stimulating or organizing creativity? And what I'm showing you here is-- that's essentially a mind map of how to think about the creativity space. which I'm going to mention, but we're not going to do as part of the class, which is stimulants. So this is the idea that somehow people are more creative when their brain, when you put yourself into some other state. So bio-inspired design would be you go in nature, or you read books about seashells and animals and you really try to understand from nature. It's pretty serious. You put yourself in nature and be inspired by what you see. Random inputs, provocations, challenges, and then things like alcohol, and even drugs. is from a student that took the system architecture class. The idea of a mind map is that you look inside yourself and you try to put down on a map different ideas and concepts. In this case, it's system architecture, and then you have these branches coming off. And in order to really make it memorable, you draw it by hand even though there is software for doing this. But I really like this, drawing it byhand the old style. And then you add icons and symbols and colors to make it sticky and memorable. industry almost. Brainstorming. So by the way, who has done brainstorming and organized brainstorming? Who's been part of a brainstorming exercise? Do you want to describe it, how that worked? Make sure you use the mic. AUDIENCE: So we started with our problem, and if I remember it right, it was to redesign a coffee mug. And then basically, for the first part, any idea could go. And the only role was you couldn't criticize anyone else's idea. some rules for how to properly do brainstorming, and some of them are listed here. And then I have another on the next chart, there's sort of a step by step. So it's really try to remove creativity barriers, stimulate each other. There's an ideal group size, and it says 5 to 10 here, but I should probably revise this to be-- what do you think? 7 plus minus 2. It's not going to be that productive with 30 people in the room. So use of intuition, associations. in this book in 1957. There's why is brainstorming useful. A lot of it has to do with this group dynamics. How to organize and host a brainstorming session. And then there's this killer sentences you should never say during a brainstormed. Some of these are pretty funny. How do you actually then take the brainstorming results and use them for further refining or down-selecting concepts? So here's a six-step process for doing a brainstormings session. So you send out invitations a few days ahead of time. take turns expressing thoughts, suggestions, ideas. You should take notes. These big whiteboards are great for that, with idea paint, the whole wall. Or you can do flip charts. You can do different ways of capturing these ideas. And then the idea there is produce a large amount and diversity of ideas. It's called the principle of delayed judgment. So you're not allowed to criticize or particularly praise. Even though it's praise, it actually implicitly is criticism of the other ideas. Leonardo sketching is more important than writing. He didn't build a lot of his ideas. But he was a head of his time in many ways. So he's really been identified as an exceptional individual. Here's a book called How to Think Like Leonardo, Seven Steps to Genius. And what's been extracted from this is the seven da Vincian principles of creativity. And they're here in Italian. And I'm just going to go through them. I'm not a big fan of these popular books, but this one is pretty interesting. very quickly. So curiosita, lifelong quest for learning. Dimostratzione, testing your knowledge through experience, trying things out. Sensazione, continual refinement of the senses. Mastering ambiguity, paradox, uncertainty. Arte/Scienza is the whole brain thinking, left-right brain. Corporalita, balance of body and mind, so a healthy mind and a healthy body. Connessione is interesting. That gets close to system architecture, which is the appreciation of patterns, relationships, connections, and systems. All right. Let's move to some of the structured processes for creativity. or an architecture. So the key decisions are the rows. There are factors in the rows, and then for each row you think about what are the number of possible alternatives for doing this. And then you enumerate all possible combinations. And I find this to be very, very helpful. When the table gets too big, very quickly because of this being a product, this can really explode on you. It can be very large. And the big challenge with this, of course, is if you have many factors, you could generate many infeasible architectures. Not all these combinations are actually feasible. through creativity, expert knowledge, and analysis you're going to define your components, which are essentially the rows in the morphological matrix. But you're also going to establish rules that tell you which combinations are actually valid combinations and which ones are not. And that, in fact, is [? Narek's ?] PhD topic is, how do you increase the number of physics-based rules rather than just empirical rules. So that's architecture enumeration, and there's different ways of doing this at different layers of abstraction. like 12 different tail geometries here. At that higher abstraction layer, it's just a single tail. So how do you combine these using compositional rules? That's architecture enumeration. So here's also an example from [? Narek's ?] work. So at an engine, a turbo prop engine at a high level of abstraction, that's basically a propeller, an intake, a core, and a core nozzle. And then to break that concept in further detail, the core itself gets shown at a lower level of detail. of this can be done in Excel, for example, where you essentially list your components. This is your library of components. And then on a different sheet, you define all the different rules that allow you to combine different number of instances of these components into architectures. And we'll post some information on this if you want to try this out for your concepts. So let me summarize. So system architecture is definitely very abstract, but it's also, potentially, the most influential activity that we do in system architecting. A3 assignment A3 asks students to come up with new ways of brainstorming. Students must use mind maps, morphological matrices, and architecture enumeration. The assignment is due in two weeks and will be graded on a scale of 1-10. The final assignment will be given to students at the end of the month and the results will be published in the next few days. For more information on the assignment, visit the assignment website. It is open to students from all over the world and can be downloaded from the assignment site.

ROUGE-1: 57.75, ROUGE-2: 54.03, ROUGE-L: 51.99
BERTScore: 67.70

==============================================
==================== [94/100] ====================
Summary:
then we are going to continue with the second part of the lecture today which focuses on the problem what actually happens if the gaussian assumption that i have about my constraints doesn't hold. Then we will see in some small examples having this outliers in your optimization problem is something which hurts dramatically which actually screw up your solution. Already a few outliers can lead to a environment model which is completely unusable for doing any navigation task so where the geometry of what you computed doesn't fit to the real world geometry anymore. of the questions actually how to handle that so as we said what we are doing here we are minimizing the sum of the squared errors terms and as we have seen so far this is the same or strongly related depending on how you formulate that to a maximum likelihood estimation in the gaussian case. So if you're taking to account your prior and all the things correctly what you're doing you're estimating the mode of the gal of the high dimensional gaussian distribution about the poses of the robot and the landmarks. a corner so either my my laser beam hits one of those walls over there or goes out through the glass pane to the next building so i'm either measuring here two meters or measuring 200 meters it would be nice if i could say to the system as either 1 meter or 2 meter or 200 meter i simply don't know take into account a distribution which is not a gaussian with a single mode but why not taking account a multi-modal distribution. If we would have the possibility to integrate aMulti-Modal distribution here that would actually be a nice beneficiary and what i want to talk about here today is um ways for oops okay ways for doing that. they look very very similar it may be very hard for a robot to distinguish that we are here whatever in room 18 and all in room 16. Other things is if you have structures in the environment and there's a lot of clutter in the scene the clutter even if it has a repetitive pattern may lead to a multimodal belief about what the relative transformation between two poses let's say or you walk along whatever a corridor with very little feature every few features you only have say some pillars. can we actually take that into account it's not always easy to get this information out of your gps because typically it runs the kalman filter internally or most of the gps devices do that so they get a gaussian belief is screwed up. If you get the raw measurements you may be able to do better by allowing for multimodal distributions in here. There's one small example so there's a small robot which moved through the 3d board and this is what was similar to this repetitive structure that i was talking before. have also experienced and if you look to those poses over here in the poses down here how those individual structures match um if you just apply let's say scan alignment you may say this may match so maybe someone has opened the door which was closed before or here is a door now closed which was open all the other scans map actually quite well the same holds here. Even as a humanism you say okay there is definitely a misalignment between the skin so they don't fit perfectly but that's something which actually can result from small changes in the environment. over here so this is a single constraint you can already see that you don't have a straight wall over here anymore so it's kind of bended a little bit like this due to the single constraint which obviously has a really really large error so the least square error minimization at the error is squared error term tries actually to minimize that. If we add two three four five i think there were 10 constraints 10 wrong constraints the map actually gets so distorted that is unusable for navigation at least down here here you still may be able to navigate within. will actually end up in dramatic mapping errors so the system is unusable so having good data cessations is really important so already screwing up a small number of places is something which can hurt your optimization if you don't take that into account. How can we deal with the problem that we have places which look identical we have cluttered scenes uh we have may have gps multi-pass problems so the signal gets reflected for example at tall buildings and in this case screwed up the measurement how can we incorporate that into the graph based slam approach? the first attempt to to solve this problem this would be our probability distribution what is the problem with this probability distribution so i say okay some of my constraints are these multiple multimodal constraints i will simply go ahead and implement that. What's the problem that you're going to experience if you make this is some so this is we know how to solve that right this is what you know howto solve that that's what we did so far. If you do it exactly that way you start coding your stuff at some point i say hmm something doesn't work here what's what is that. don't have a single constraint we have a number of constraints right hundred thousand millions of constraints how do we combine those constraints if we minimize the squared error what are we actually doing? If we go to the log like negative log likelihood we're going to optimize here this term here minus a constant and here we can't go further than that that's a problem. There's where it fails do you see what is the dirtiest way for you to fix this let's say you started implementing that you have your implementation is. done you know he said oh damn i can't do that what would be the ugliest trick that you can do in order to make that work even worse no that's not quite what you're going to do i mean the sum is kind of the the the bad thing what can i do with the sum instead of the sum i can i can get rid of thesum in some nice way sorry oh the integral of some to the integral actually makes our life typically worth um so that's that's going to fly. The key trick is to simply say uh i just say where am right now is this actually the approximation error is actually kind of small if the gaussians are quite separated from each other. If one mode would be 2 meters and the other one 2 meter 5 then this may not be a good approximation but what we're going to do is we say okay just select the cave mode which is currently the best one so it's a maximization operation again. If you move the max operation in here if you're maximizing a function or you're maximize a lock of that function is equivalent so we can move the lock. into in there and then have uh have our problem solved that's kind of a nice thing so if you compare that so let's say we have two two possibilities here which may look like this and we go for the max mixture so taking exactly this expression over here this would be our distribution so it's always the max of these two functions therefore you have kind of this uh not those smooth position over here. If you compared that to the sum of gauss it looks like this so the approximation error that we do is in reality we have this situation. sum anymore we don't have we only have the mux in here and so then the the log if you go for for the log term i can move the log inside so when you see i just have this constant factor which i had before as well or negative log like i'm minimizing negative log likelihood this is exactly my expression so i stick with exactly the same operation here. The only thing i need to do whenever i compute the error function ineed to pick the mode of the gaussian which gives me the best performance. exactly the same in my code the nice thing is that actually between iterations you can the system can swap between different modes and therefore although the optimization in one iteration takes into account only one mode of the gaussian as you can switch the modes it is you still have the ability to deal with multimodal constraints if i do that that's what the result looks like so this was the original stuff you have seen before one wrong constraint 10 and 100 if i go for max mixtures let's say either it's a perfect fit or it'sa very very very flat gaussian this can be in layer or outlier. kind of in the system swaps to this other one if it is an outlier there's a very high likelihood this will swap to that. If you have a bad initial guess and the bad initial guessing is in line with the outlier then you may run into problems. Those are constraints which simply swap to the other mode and don't harm the optimization much. The solution may be still a little bit different than the one which is done completely without constraints because you still have this very very tiny error but it's actually kind of within the noise. individual constraints so when you evaluate the error the evaluation of the error is somewhat more expensive because every constraint can have can be multimodal or bimodal in this case. There's not no big difference in the operation of those systems when you um if you use the red or the. or the or the blue plot this is exactly the trick that is used um so if you just want to deal with outliers so the the red one is kind of the inlier and the blue function is the one which is the outlier. robot and the ground is muddy the wheels may slip before you get grip and the and the robot starts starts driving if this is the case although you're executing command you're standing and then you start moving so you may get this kind of distribution. In most cases actually the vehicle executes what you tell the vehicle to do but in some cases simply doesn't move. This max mixture idea is actually a pretty easy idea pretty simple idea just reply funny no one has done that in robotics until recently a few years ago. that's actually a nice thing so um another thing is it can handle both things at the same time data station errors as well as multimodal constraints. So the combination of outlier rejection and dealing with wrong data associations is actually kind of nice we also can do this obviously in 3d so this is again this data set with the sphere that we have seen before robot moving in a virtual sphere with constraints. This is gauss newton and this is the max mixture gaussnewton and um so you can see here there's a non-perfect alignment in here because you don't see the regular structure. if he increases to 100 outliers this is just whatever a big mess whereas this one still is able to solve those things quite nicely. The key idea the intuition behind that is if i have a constraint which has a large error so where the um the current configuration is far away from what the constraint tells me just reduce the uh or increase the uncertainty that is associated to that so decrease um the the information matrix so scale down the information Matrix. The question is still how do we get to that point. actually compute these so the main changes we go to this formulation we have the scaling factor over here and we need a good way to compute the scaling Factor so how can we actually do that and there's actually closed form you can derive that under certain properties. So what you do is you compute the original error then you compute this sij and just multiply your information matrix with this this leads to the case that constraints which are far away from what we expect have a smaller influence on the optimization so we can actually visualize this. in this area kind of the the core center of attraction both both perform equally well because there's no scaling involved. The further you move out the more the red curve gets scaled so it gets kind of fatter andfatter and better. If the error increases if you're further away from the mode this is what your error function looks like so the further away the more you down weight the influence of this constraint because you increase the uncertainty of the constraint through the gaussian distribution you can generate a flatter error function. and flatter and flatter gaussian distribution the further the point is actually away there's also one technique which you can find which is also quite easy to implement because you just need to compute the scaling factor and multiply that with your information matrix for every constraint also something you can do quite efficiently okay if we look a little bit more into kind of what is there an overall framework which brings this together the standard optimization and what i've shown you here is that um the problem that we have in this gaussian Distribution. actually screw up the optimization um when computing the minimal error configuration so one way you can do is or fits into the framework of its so-called robust m estimators which intuitively say okay we don't assume a gaussian distribution we assume non-gaussian noise especially we have a bigger tails of this distribution. So this is something which is a little bit problematic for or doesn't the max mixture framework doesn't perfectly fit in there because um we replaced this with this we have this still this mux or main operation in there. now you get different properties in the optimization so if you use um if r is just the quadratic function then we exactly have the original problem that's what we minimized x of minus uh squared error so if we have this one we have we examine exactly in the gaussian world and now there are different techniques how we can actually address that one thing is we could take simply the absolute value so we don't square it just take theabsolute value of the error that's not the parabola that we have. there are a large number of those so-called kernels which are introduced in the system in order to get a better behavior or meet certain error characteristics that your system actually reveals so this is an example for for the huber cost function i said we have this parabola close to the um so in the uh around the the zero error configuration so if my the current configuration is close to zero i have the parabolas and here it goes into the tooth so these straight lines and this is just an example of different ones. similar to this corrupted gaussian so if you plot both of them together so this is the the the corrupted Gaussian the blue one over here and the red one over this z max mixture i still have this max operation when i switch so it's kind of the max mixture for a bimodal distribution for dealing with outliers. The frame actually also holds for the dynamic covariance scaling it can actually show that dynamic covariance scaling is a special especially of these robust m estimators so and in this robot's estimation the choice of this this function raw kind of encodes the noise properties that you expect if you take a quadratic function. When you change your row function that means you're leaving the gaussian world and so the system optimized according to a different cost function. This allows you to take into account for example these these heavier tails so that outliers still are not weighted that dramatically and impact your solution so much because they completely disagree with the solution that you actually have before the um so the huber cost function some cost functions is often used this is the parabola close to the mean and the linear function outside and then there's max mixture which is quite similar to a corrupted gaussian it still has the advantage that it can can handle multimodal distribution which is which is kind of a very nice property. do a lot of really really bad things in order to deal with outliers of course we are leaving the gaussian gold if we do that. This simply means we have a different assumption about the noise that we're going to experience but i can quite nicely integrate that here. A lot of those kernels can be quite nicely integrated into this least squares framework where you just change your error function in a certain way so you still have your exponential function but you only change this row function in the exponent to still be able to optimize the log likelihood. of the kernels which which came from computer vision and they are quite attractive framework to deal with outliers. In most realistic data sets and situations when you deal with robotics there's a non-zero probability that there will be a datasization error in there. The more likely this data association error the the worse it gets if you optimize without taking these outliers into account. That's actually an easy way to integrate that and often actually requires not that many code changes so you can actually adapt a current system which cannot deal with outlier to systems that do. here that by changing this function you can't get much better behaviors kind of deciding which function to use for the underlying optimization problem is not on it's not always an easy and easy choice so this requires some expert knowledge some good intuition on coming up with the way with one of those functions. Next week which is the last week of the term i will briefly talk about front ends and give kind of a short summary on what typical front ends exist obviously we're not going to all the details as we did that here. setup to another sensor setup can be quite tricky on but the back end itself which sits here doesn't really change that much therefore the focus in this course which was much more on the backEnd. At least i would tell you a little bit about what typical front desk exists and how you could realize a front end if you want to build a slam system. Well that's something we are going to do next week that's it from my side thank you very much and hope to see all of you next week.

ROUGE-1: 67.43, ROUGE-2: 65.95, ROUGE-L: 67.16
BERTScore: 74.58

==============================================
==================== [95/100] ====================
Summary:
John Stuart Mill was the principle expositor of neoclassical utilitarianism. The rights-utility synthesis signals that we're looking for an attempt to put together both a commitment to utilitarian efficiency that's grounded in science on the one hand, and respect for individual rights on the other. We're not going to actually get to the rights-UTility synthesis as it's expressed in politics by John Stuart Mill until next Monday. What instead I'm going to do today is explain how the transition for classical to neoclassicals utilitarianism really went on in all fields of thinking about the human sciences. in philosophy that are going to be my principle focus in today's lecture. What you're also going to get is everything you ever needed to know about neoclassical economics in 45 minutes. At the same time, more or less, there were very important developments in moral philosophy that I just want to alert you to, that we're going to return to later when we come to consider Alasdair MacIntyre's book, After Virtue. And this movement that I'm mentioning here is the doctrine that would come to be called emotivism. It was associated with a man by the name of Stevenson who wrote several books advocating the emotivist doctrine when he was an untenured professor in the Yale Philosophy Department. His doctrine was that when we make claims like murder is wrong, we're making claims that express our emotions, our emotive reactions to propositions. All we're doing is expressing our tastes, our emotional reactions and that there is nothing more to say about ethics than that, he says. He says it's an endpoint in a philosophical evolution that really begins in the seventeenth century. Hume's famous for the idea that an ought cannot be derived from an is; that there's a fact-value problem. But he thought, nonetheless, people are pretty much the same, and so if you can figure out what makes one of them tick, you can find what makes all of themtick. And that was most emphatically Jeremy Bentham's view. It's presupposed in everything we discussed last time. If you think about the idea of doing interpersonal comparisons of utility, and making the judgment that taking that dollar from Donald Trump and giving it to me would be better, that's what Bentham would have said. it to the bag lady increases her utility more than it decrease his, you're assuming that they basically all have the same kinds of utility functions. Stevenson questioned that idea radically. He said, "We don't actually know. We should take Hobbes much more seriously in his critique of Aristotle than he was willing to take himself" And so that was thought to be a radically relativist doctrine because it seemed to undermine the possibility of making ethical judgments of any sort across people. That is a doctrine to which we will return, as I said, when we get to the anti-Enlightenment and, in particular, Alasdair MacIntyre's book, After Virtue. But today we're going to focus for the rest of our time on the economics of the transition from classical to neoclassical utilitarianism. And I'm going to ask you to suspend your disbelief and just follow me through the ABC's of neoclassicals price theory. And it's not until the end of this narrative that you'll start to see why the transition in economics was essential for the Transition in political theory. by-product is, you're going to get the whole of ECON 101 reduced to a single lecture. Because indeed it is true that enormously complex and subtle, and as sophisticated as the neoclassical theory of microeconomics is. It's all built out of the three ideas that I'm going to spell out for you in what some of you might initially regard as laborious detail. But I think you'll see what I'm getting at once we get towards the end of today's discussion. lot of wine to get a second loaf of bread. If, on the other hand, you were choking on your six loaves of bread and dying of thirst the reverse would be true. And these are what are called indifference curves in neoclassical economics. And indifference curves basically imply exactly as the name suggests that you would be indifferent among the mixes of Bread and Wine anywhere on this curve. And this curve is always shaped that way, concave toward the origin. Anybody want to tell us why? What is it reflecting?  neoclassical economists didn't want to do that for a different reason than anything I've talked about in these lectures. The problem they wanted to solve was to understand the behavior of markets. They wanted to be able to more precisely to predict what prices were going to be in markets. I'm going to elaborate to you much later on when we come and talk about Marx, and the labor theory of value and its limitations, but that's for a future lecture. For today's lecture all you need to know is that in Bentham's system we had cardinal scales. Pareto, Marshall, and Edgeworth thought you could do this just with ordinal utility. For Bentham's system to work, for example, the government would have to have a kind of utilitometer and run around sticking it under people's tongues to measure their utility. So moving from cardinal to Ordinal utility is going to turn out to have huge ideological consequences, which I'm going to unpack for you towards the end of today's lecture. All you need to concern yourself with is the fact that they wanted to be able to understand the nature of markets of how market prices move. we would know about this person A, as I said, is that they prefer four to three, three to two, two to one, one to zero. But we can't say anything about how much they prefer those things because these distances don't actually mean anything. All we get is an ordered ranking. One other thing we can say is, that this is a no-no. These indifference curves cannot cross. Can anybody tell us why? Why can't they cross? Wait for the mic. Student: Because at the intersection they should have the same utility. The preferences are assumed to be transitive. So if you prefer A to B and B to C, you must prefer a to C. So we cannot have these indifference curves crossing one another. Now, instead of one person and two commodities, we're going to think about two people, okay? We're creating a diagram with two people on it. As I promised you earlier in the semester, anything I do with a diagram I will also do verbally, so if you find this in any way confusing just listen to the narrative and then we'll see whether you find it confusing. you get it that way. But so now we have a diagram with two people on it, okay? So this is person A, and this isperson B. And these axes, the X-axis, here, is A's utility function. We don't know that A's happier than B from what I just said, right? These distances don't mean anything,right? So it looks like A's happiest than B, but that's misleading. If the different distances are taken to imply in your mind, disabuse yourself of that thought right away. he said, "Let's draw a line north-south through the status quo," okay? And we'll imagine that there's a finite source of utility. One thing we can say is if you can anywhere into the northeast quadrant both of them are better off, right? So if we go from X to Y we know A's utility has gone up. We don't know by how much, but we know it's gone up so they're both better off. On the other hand, if we went anywhere in here, this quadrant, southwest as it were, obviously they's both worse off. use, yeah, let's use J. If I put a point here, J, we would say that A's gone down and B's gone up. Now, to make this a bit more real imagine in here this is the sphere of market transactions. This is where A and B will go voluntarily, right? So A will say to B, "Well, I have all this wine, and you have all that bread, how about I swap you a bottle of wine for a loaf of bread?" And you say, "Okay." can say that's Pareto inferior because they both don't want it, and both of them would resist it if the government tried to do it. So that's all well and good. Well, that leaves these two other quadrants. We can say nothing at all, at least nothing scientific. And then he says in his famous 700-page book called The Manual of Political Economy, he says, "People are going to misinterpret me" "We will never have a scientific reason for moving into either of these quadrants," he says. just have no way of knowing because we don't allow interpersonal comparisons of utility. Perhaps they are, perhaps they aren't, but we just don't know, okay? So that is the Pareto principle. The whole of neoclassical economic theory was constructed depends on this idea of indifference curves. A is trying to get up on those indifference curves, and B is try to get along on these indifference curves and there's no scientific way to tell whether B's loss is as big as A's gain or the reverse. A proposes to B swapping a loaf of bread for a bottle of wine and B agrees. They go to Y, and then A says, "Well, I'll give you another loaf of Bread for a Bottle of Wine" And B says, 'Forget it," and then they go to Z. When no transaction occurs, you know they've hit that frontier. So, the Pareto principle says that in a market system they'll move toward the frontier and when they get there, they'll stop. of course, they may have gotten there some way else. They might have gone from X to G over here, and then they would have done a new one. And that would just reflect shrewdness in bargaining, or how much people cared lower down their indifference curves. But once they wind up anywhere on this indifference curve they're not going to move off of it because now there is no way of improving one person's utility without diminishing the next person's. That's it. That is neoclassical economic theory in a nutshell. diagrammatically, and then if anybody doesn't get it we'll wait up and I'll go through it more slowly. But basically now we're putting the two previous diagrams together. And so you'll see why this is helpful once we get to the end of it. So A is here, and A has indifference curves. This is our first picture, right? We have wine. We have bread. A's indifference curves are the dotted lines, okay? A is trying to get that way,. that way, that way and to keep going all that way. B is looking at bottles of wine, loaves of bread, and B has now got the solid indifference curves. So B wants to go this way, as I said, southwest; A wants to going northeast. So this is an indifference curve for B. Now, it's going southwest instead of northeast just because it's looking in the mirror. So A would improve if he went this way. And B would improved if she went this. way, okay? So this shaded area here, this big football, is the Pareto superior set on the previous diagram. The Edgeworth box diagram just puts all of the pictures together. There's nothing conceptually new in it at all. It only becomes relevant to our purposes because it will enable us to start thinking about distributive questions, which is what we're trying to do in this case. The only way that A can go this way would move B off his or her indifference curve, and this one coming this way, okay? So at Z, A wants to go thisway, but the only way A can move B is to move B this way. I will get to in a minute. All you have to do is take the previous, the Pareto principle diagram and imagine it with a mirror and think of B as upside down coming toward A, and then it just all fits together. Very clever. Okay and the one thing I would say, this line here is what on the previous diagram was the P Hareto possibility frontier, right? This line is all the points of tangency between--like there is one, there isOne, there's one. a harder bargain early on, they might have gone by a different path and would have wound up at a different point. This is the Pareto possibility frontier which Edgeworth called the contract curve. It's where they will make a contract to get to. They will agree to transactions that get them onto that curve, but once they're on it they stay there, okay? That's the basic intuition. So market transactions into the Parareto superior zone, and eventually they stop when things are Pare to optimal. that. All I'm saying is if the government chooses to redistribute, there's not going to be a scientific principle to tell them how. So just to make the point dramatic, let's suppose--we're going back to the Edgeworth diagram. Let's suppose this is the status quo, and A has nothing and B has all the wine and all the bread. We know they're on the contract curve because B has nothing that A wants, right? So the Pareto efficient outcome is for the bag lady to starve. John Rawls says utilitarianism doesn't take seriously the differences among persons. But neoclassical utilitarianism takes the differences between individuals hyper-seriously, so Rawls' point doesn't actually apply. When you allow interpersonal judgments of utility and interpersonal comparisons you get the radically redistributive doctrine that Bentham then tries to fend off with his distinction between absolute and practical equality that we talked about last time.bag lady starves to death. The trouble with utilitarianism, says John Rawls in His Theory of Justice, is that is doesn't takes seriously the Differences among Persons. We don't care who has the utility. The bag lady should starve in this example rather than have something redistributed to her by the state, forcibly taken from Trump. So classical utilitarianism ignores the differences among individuals; neoclassical utilitarianism fetishizes the differences between people to an incredible extreme. But notice from the point of view of the history of ideologies what has happened in this transition from classical to neoclassicals utilitarianism. We've gone from a world in which the doctrine of classical. utilitarianism was a very radical idea that would legitimate huge redistribution. which the radical fangs of classical utilitarianism have been ripped out and it is now a doctrine that is very friendly to whatever status quo happens to be generated in a market system. So it ceases to be this radically redistributive doctrine, and in the process imports into utilitarianism a very robust, some would say, hyper-robust doctrine of individual rights. We'll see how that played out in political theory when we come to look at John Stuart Mills' harm principle next Monday.

ROUGE-1: 58.55, ROUGE-2: 56.09, ROUGE-L: 54.11
BERTScore: 71.88

==============================================
==================== [96/100] ====================
Summary:
HONG LIU: So, first, we talk about chiral fermions. So, say, under Lorentz transformation, lambda, the Dirac spinor fields transform as S. S is given by omega mu nu, sigma, mu, nu, OK? And the sigmamu, nu is driven by the commutator of the gamma matrices. OK? So, one natural question is whether you can actually restrict to a smaller part-- say, to a subset of psi-- whether they still have well-defined LorentZ transformation. And the answer is yes. turns out to be, no, you actually don't need to have four complex components to have well-defined Lorentz transformation. Actually, you can reduce it, OK? And so there are two ways to reduce it. One is called chiral fermion, and the other is called the Majorana fermions. So we first talk about the chiralfermion and one way to do it. So, for this purpose, we will look at the specific representation of gamma matrices. i 0, 0 sigma i-- again, the small sigmai is always the Pauli matrices. And then you can also work out the sigma Ij. Then you find the is given by minus 1/2, epsilon ijk, then sigma k. So do you see something? Yes? AUDIENCE: They're block diagonal. HONG LIU: Yes, they are. So if sigma is block diagonal, then that means this S is also block. So that means, if I write psi x into two component vector, HONG LIU: You don't need four components to be able to transform under Lorentz transformation. At least two components can already transform. So this tells you, in a sense that the LorentZ covariance only requires two component spinors. But that doesn't say it's a Lorentt transformation. Yeah. To write down to write down. The upper two components by psi L and lower two componentsby psi R-- are two component complex vector. That means, under S. Lambda, psiL and psi R do not mix. So they just transform among themselves. HONG LIU: We already said before, if you have a massless case when m equal to 0, and the Dirac equation reduces to the two components, and it's enough to do two components. And so that means that, actually, you should be able to do it with two component. So it is not a Lorentz symmetry, actually. It is not Dirac theory to have four component, it is. It's the massless particle. So the hint from before is that the Massless only require two components and that's what we're talking about. The property that you can reduce to two components should exist for all choice of gamma matrices. So, now, let me tell you how to do it for the general gamma matrix. So if we can do it in this choice of Gamma matrices, then we should be able toDo it in any choice ofGamma matrices and so on. Any questions on this? You can ask me any questions on any of these points, and I'll try to answer them. I'll be back in a few minutes. to separate the psi into psi L and psi R is more subtle. You no longer-- is just simple the upper two component or lower two component. So we have to do a little bit of work, OK? Actually, we don't need to do much work if you actually find the right trick. And so the beautiful trick to do this for any choice of gamma matrices is that you can introduce the following object-- what is called gamma 5. So gamma 5 is defined to be i gamma 0, gamma 1, gamma 2, gamma 3. So the i there is for the purpose that if you-- you can check yourself-- that the gamma5 is actually Hermitian.  gamma matrices whose indices are not the same, they anticommute. So you multiply them together, in the end, they can be either 1 or minus 1. Just turns out, for this choice of i, it's 1, OK? So yeah. And then you can also check the gamma 5 anticommutes with any gamma matrix. Gamma 5 actually have 0 trace, OK?" "Yeah, because this runs over all gamma matrics," he says. "So the one in which-- yeah, so if you take with some gamma mu, and that particular one, which is the same as gamma mu" HONG LIU: gamma 5 squared, squared to 1, is Hermitian, which means its eigenvalue is either plus or minus 1, OK? So have eigenvalues plus, minus 1. And then from the property that this is traceless, they tell you the number of the eigen Values, which is plus 1. They should be the same. Otherwise, they won't cancel. So I can introduce a projector which, for historical reasons, is called PL. It's defined to be 1/2 1 plus gamma 5. And this will project into an eigenspace with aminus 1. I was dreaming. So PL squared equal to PL, PR squared. Yeah, thank you. So, indeed, you see-- so, from here, from this definition, you can check this is true, OK? This is a one-second check. So then, by definition-- OK, so now this psi L, psi R, which is now defined for any choice of gamma matrices -- so, again, they have to two independent complex component. And so they call the chiral spinors-- sometimes also called Weyl spinors. So this is the analog of psi L and psi R here for the general choice of Gamma matrices. The sigma mu, nu is just the sum of two-- the product of two gamma mus-- have even gamma mus. So the gamma 5 will compete with them, OK? So Gamma 5 will commute with them. And then that means-- so we commute with S. That means, under transformation, S will not change the eigenvalues of gamma 5. And, similarly, we say-- OK, so that tells you that psi L and psi R-- they transform separately because the gamma 5 commutes with Lorentz transformation. And so each eigenspace, they transform separately from each other. In that case, it's very simple, OK? But in other representation, gamma 5 can be more complicated. Good. Any questions on this? Yes, you have a question? Yes? AUDIENCE: Another way to do that, as you said, would be to try to find the unitary matrix that shows-- under which this arbitrary representation is equivalent to the chiral representation. by a similar transformation. And, indeed, the gamma 5-- gamma 5 in the other representation are related to this one just by a similar transformed, too. Yeah, so I will use that language when I talk about Majorana spinor. So, in this case, it's sufficiently simple. So you can write it as psi dagger partial sub 0, plus i sigma i, partial i, psi L. OK? And then you can just write this in terms of psi L and psi R. sorry. Yeah, actually, psi R dagger. So in the chiral representation of gamma star-- in this space of star, and then we have two components. Then I can write this psi and the psi L and psi R into two components, OK? And then, yeah. So this is just ordinary sigma matrices. And so this is the expression you get. And this behavior is actually general. You can write it in arbitrary representations. But, of course, in arbitrary representation, I can no longer use this sigma i. you don't have coupling between the psi L and psi R. So, again, this is reduced to our previous statement that if you have a massless case, you can describe using a two- component spinor. So here, indeed. But, here, there's also something extra. So what do you see-- something extra here? Yeah. Did somebody raise your-- yes. AUDIENCE: Why are we now taking the psi equals psi L plus psi R instead of before we had it as psiL and Psi R? basis but apply for the general.basis. So here, actually, something profound happens because, when m equal to 0, when you don't have coupling between psi L and psi R, you actually get the extra symmetry, OK? So, now, I can actually transform psi L and psi R separately. So these are called chiral symmetries because they transform the left and the right separately. Yes? AUDIENCE: I'm a little bit confused why you can't write psi. HONG LIU: In the general case, I can write psi equal to psi L and psi R. But in these spaces, using this notation, I cannot. So, now, you have a new symmetry equal to-- which you can transform them separately. And the chiral symmetry actually has also very important effect in particle physics-- for example, the pions. The pions has to do with-- I don't know what it is, but it's a very important part of physics. Without the chiral symmetries, there's no pion. Symmetry is only present in the classical level but not in the quantum level. And, again, that plays a very important role in particle physics, actually. It's also important in many condensed matter systems, like liquid helium, et cetera. Will not go into detail. The pions-- they essentially come from the Chiral symmeetries. And actually understanding how the pions come from them was a Nobel Prize to Nambu. HONG LIU: If tilde is just some other constant, then you multiply gamma 5. So, here, we can rewrite a little bit differently. We can consider rewrite this alpha L and alpha R in terms of the following. Let's consider the two transformation-- one transformation, psi L, and psi R transform the same. And the other transformation is that they transform oppositely. They transform in the opposite phase, OK? So I write the alpha-- and this writing is like that. HONG LIU: In physics, actually, the massless case actually gives you very much richer structure, normally, than the massive particle. Mathematically, it's because the representation of the Lorentz group is very different from the massive case. In Euclidean space, you continue gamma 0 to gamma 4. And then you reserve gamma 4 for that. Then the gamma 5 is the next one you take.this? Yes. Other questions? Yes, I'm happy to answer. HONG LIU: In the Dirac spinor, which we have talked about so far, is four components. In the chiral spinor we talked about, you have two complex components. The next one I'm going to talk about is the Majorana, in which case, I would argue, we have 4 times 1 real component. And, now, let's talk about the last case-- this case, which is-- you have four real components, OK? So what do you do? Again, we follow the similar strategy to see whether it's possible to have fourreal components. not compatible with Lorentz transmission, then we were finished, OK? So this shows that this remains real. So such a spinor is called a Majorana spinor. So it has four real components. So you can quantize it, which, I think I will give it as an exercise for you to do. And then, in this case, then the fermions are its own antiparticle. You have particle and antiparticle, so this is the analog of the real scalar in the spinor case. HONG LIU: We have chosen a very specific representation for gamma matrices, which psi can be chosen to be real, OK? But how about for the general representation? So now we talk about the general Majorana spinor-- yeah. AUDIENCE: This doesn't really feel equivalent. It is still equivalent to the other representations? HONG LIu: Yeah, yeah. We will talk about that. Majoranaspinor also plays a very important role in modern-day physics. People suspect a neutrino could be a Majorana spinner. real in the general basis, OK? Because when gamma mu is generally complex, clearly, you cannot set the psi equal to psi star. That does not make sense. You have to find another equivalent equation to do, essentially, the same thing. So you have to introduce this C. So if you find that the transformation between the general gamma mu and the gamma mu m, and then you can use that to find the B. And once you find the A, you can then impose the Majorana condition. complex conjugate of this equation because gamma mu m is real. So that means that, since gammamu m equal to gamma Mu m star, but if we take complex conjugates of that equation, means that the C star gamma mu, C minus 1 star is equal to C gamma mu. So, now, we see that B-- this actually makes sense. This is actually the matrix we take gamma mu to gamma mu star. So B is the matrix to take star, OK? Good. Any questions on this? But, in principle, you don't have to choose them to be unitary. OK, so, now, let's double check. So let's check that star star-- so we show that, here, in this representation, this is compatible with Lorentz transformation, OK? So we still need to check star, star is compatible. So it means that the psi prime star should be equal to the same as B psi prime. So that means this iscompatible with LoreNTz transformation. B when you act on sigma mu B minus 1. So that gives you minus sigmaMu, nu, star, OK? So this is obvious because sigmamu, nu has i there. So the minus sign comes from the i. And, otherwise, the B takes each gamma matrices there into star. And then that means that the S star, lambda, which is given by exponential 1/2 omega mu, nu. Now this is equal to-- yeah, you can just plug this in. we get a very nice relation that, under Lorentz transformation, is generated by this B. And, now, it's just immediate, OK? And now, when you have the psi prime equal to that, let's just take the star of this equation. So that is equal to B S Lambda B minus 1 and B S-- B psi. So this isequal to B psi prime-- precisely what we were trying to show. Good. Any questions on this? OK, so,now, let me give you an explicit example of this matrix B in the Majorana representation. I wrote down before, so if you stare at that expression, you find that gamma 0, gamma 1, and gamma 2 are imaginary, pure imaginary. And the gamma 2 is real, OK? So this pure imaginary means, when you take the star of them, you get the minus sign. So, now, if we look at this equation,. so if this is pure imaginary, youget the star. You get theminus itself. And then, essentially, youGet the minus self means the B actually anticommutes with gamma mu. But this is real. It means B needs to commute with this guy. Then what is B? AUDIENCE: Gamma 2. HONG LIU: Exactly. So B, in this case, can only be gamma 2, OK? And then we can work out, what is the Majorana condition in this basis-- so, essentially, this condition. So that means that the psi star should be equal to gamma 2 psi, OK?!? So that's the majorana condition here. And this is now independent of massless or massive particles. psi, and there should be another one, right? So is that one? HONG LIU: I don't quite understand your question. Say it again-- what? AUDIENCE: OK, [INAUDIBLE]. HONGLIU:OK, OK. Other questions? Good. OK, good. So let's now go to the next topic. We only have a few minutes, so we can only just make some general comments. So so far, mostly, we have been talking about continuous symmetries. But there are also discrete symmetry, OK? we have-- so this real scalar theory-- we can see that before. So this theory has a discrete symmetry because this is invariant under phi. It goes to minus phi, OK? So this is often called the Z2 symmetry. There are also spacetime discrete symmetries. So you can have t goes tominus t. You can also have the so-called parity. You take t. Then you revert all the spatial direction. So comment that you can ask why we actually reverse all three directions. just reverse one direction or reverse two directions, OK? That seems also to be a discrete symmetry. And indeed. So if you just change the directions, say, in the x direction, that's also a discrete symmetries. But if you change-- if you do the reflection in two directions,. that's equivalent to a 90-degree rotation. And so it's part of the continuous symmetry, so it'm not independent. And now, when you change all three. directions compared to change one direction, you differ only by changing two directions. So that means changing all three directions and changing one direction-- they differ by 180-degree rotated. you take that phase to be pi-- say, exponential i pi-- and then you take to be minus phi. And so, in that case, this is part of the continuous symmetry. But, here, there's, nevertheless, another discrete symmetry. Can you see what is the other independent discrete symmetry here? Yes? Good. You can exchange phi to phi star, OK? It's a complex conjugation. And this is often called charge conjugated.

ROUGE-1: 50.39, ROUGE-2: 47.48, ROUGE-L: 46.32
BERTScore: 75.25

==============================================
==================== [97/100] ====================
Summary:
The best-case scenario for expansionary fiscal policy is when there are lots of underemployed resources in the economy. By increasing spending, the federal government can try to counteract falling aggregate demand. In one scenario, government spending doesn't have to be as large as the fall in "C," or consumption, to counteract the recession. That's because of the multiplier effect. But, as always, shifting lines on a graph is much more important than the long-run effects. easier than shifting around real resources in a multi-trillion dollar economy. Fiscal policy has many implementation challenges, and we'll turn to these next. You're on your way to mastering economics. Make sure this video sticks by taking a few practice questions. Or, if you're ready for more macroeconomics, click for the next video. Check out Marginal Revolution University's other popular videos, including the one about the U.S. debt ceiling and the next one on the debt ceiling.

ROUGE-1: 47.04, ROUGE-2: 42.19, ROUGE-L: 42.99
BERTScore: 63.85

==============================================
==================== [98/100] ====================
Summary:
Sarah thread sterner shows you how to wear and take off a mask. She explains how to determine which part of the mask is the front versus the back. She also shows how to mold the nose piece of the face mask with the finger tips of both hands. Finally, she shows you the best way to remove the mask by placing it over your ears and pulling it under your chin when removing the mask it's important to remember that the front is considered contaminated so remove it with the fingertip and then perform hand hygiene.

ROUGE-1: 29.04, ROUGE-2: 20.29, ROUGE-L: 23.82
BERTScore: 64.55

==============================================
==================== [99/100] ====================
Summary:
Adam Martin: In this video, researchers are shining light into a mouse's brain to activate specific neurons in order to test whether they function in arousal. In today's lecture, we're going to work towards understanding how this experiment works. We're also going to talk about how neurons function and how researchers are able to control that function to modify behavior-- in this case, the arousal of this mouse. And here, you see the mouse is going to wake up. There it goes. It's awake now. The sciatic nerve extends from the base of your spine all the way down into your foot, OK? So that's an extremely long distance to transmit information along a single cell. And so we're going to go from thinking about how signals are transmitted in single cells, and this will evolve electrical signaling. Then we'll talk about synapses and how synapses function to help us understand the function of a single neuron, and how they communicate with each other, and so on and so forth. Communicate between neurons. And this is going to involve also sort of understanding how certain antidepressants, like Prozac, work. And then we'll end by talking about how researchers did this experiment to wake up the mouse. And it all starts with something that I told you about at the beginning of the semester, which is that the plasma membrane separates distinct compartments the outside of the cell from the cytoplasm. And there are distinct ion concentrations on either side of this boundary. So we're starting now talking about a single neuron cell. This is thermodynamically not favored, right? These ions would prefer, by diffusion, to be equal concentrations on both sides of this plasma membrane. So the cell to shift this from equilibrium has to expend energy to set up this situation. And it pumps potassium ions into the cytoplasm such that there's a higher concentration of potassium ions in the cy toplasm. So these neurons expend a huge-- a quarter of their ATP is used by pumping ions like this. This voltage difference is known as a membrane. potential. So this is a membrane potential. And it's an electrical potential across the membrane. If the cell is not getting stimulated by something like a neurotransmitter, the resting potential is negative 70 millivolts. So the resting state of the side is there's a polarized-- it's polarized. However, the cell can lose this polarity and not have a charge differential, or it can flip and be positive on the side that has the negative inside potential. The cell can also be polarized and have a positive inside potential, or a negative outside potential. Inside a cell, if there's either zero or positive inside potential, this is referred to as depolarized. Anyone have an idea as to how the cell would flip the potential? What would have to happen in the plasma membrane to flip this potential and depolarize the cell? Yes, Stephen? You could open the ion channels. Which ion channels would you open? The sodium channels. Because remember, sodium is high on the outside, out here. And so if you open these channels, positive ions are going to flow in. And that's going to make this less negative. An action potential is a transient depolarization of the nerve cell. It doesn't just depolarize and stay depolarized, but it depolarizes and then restores itself back to the resting polarity. So it's a transient process. When we think about the neuron at higher resolution, what you're going to see is also a traveling wave that propagates along the entire length of the cell. And so this illustrates a key property of neurons, in that the level of sodium doesn't have to do any work to do this. activity of a neuron is not determined by the size of this action potential. This action potential is an all-or-nothing event. It either happens or it doesn't. And when it happens, it depolarizes to the same level. You can think of it as a binary signal. So now we're going to unpack how it is a nerve cell fires an action potential and how it propagates along the entire cell length. In the case of the sciatic nerve, this has to happen across an entire meter, OK? That's a very long distance to propagate this change in electrical signal, at least for a cell. How is it that this nerve cell is told to start depolarizing at the dendrites? Because there's going to be another neuron here, which is going to communicate to this neuron over here. It does this at the location known as the synapse. And the way this process is initiated is similar to the type of signaling that you saw in the past few lectures, where you have a ligand and a receptor, OK? In this case, the ligand isgoing to be what's known as a neurotransmitter. In this case, it's a sodium channel. So it's going to be-- whether or not it's open depends on the presence of the ligand. So if we take a neurotransmitter like serotonin, if it's not bound to the receptor, the receptor is closed. But if serotonin binds to the receptors, it opens up the channel, which can selectively let in a type of ion. In this case,. this is an activating channel, because letting in sodium is going to depolarize the cell. sodium channel? This is a voltage-gated sodium channel here. And you can see, in the resting state of the cell, this channel is closed. And it's closed because of this red rod structure that's positively charged. That's a positively charged alpha helix that is a part of this protein and is embedded in the membrane. When there is depolarization, that shifts the position of thisalpha helix, such that now it shifts up towards the exterior face of the plasma membrane. And that opens the channel, which lets sodium ions rush in. neuron, how do you get it such that this electrical signal moves unidirectionally along the neuron? So what leads to uniddirectionality? Who's been to a sporting event lately? OK, good. So we're going to do the wave. Once you to stand up, you're going. to be tired, and you'll have to sit down for a while. And so these voltage-gated sodium channels have a similar property. Once the sodium channel opens, after about a millisecond, that ball sticks in the channel pore and blocks it, OK? channel which prevents the action potential from moving backwards. If you have a voltage-gated potassium channel, that's going to cause a rush of positive ions out of the cell. And that will be able to restore the net negative potential on the inside of thecell. So this termination or repolarization is the result of the opening of voltage gated, in this case, not sodium channels, but potassium channels. When would these have to open relative to sodium channels? Yeah, Carmen? Rachel? AUDIENCE: Move the potassium ions. The depolarization is going to be high where the sodium channels are only entering. And then following that, you would have potassium ions getting pumped out and basically repolarizing the cell. So here, you have a spike, and you complete the cycle. It can even get hyperpolarized, where it gets even more negative than it normally does. It eventually gets back to this resting potential of around negative 60 or negative 70 millivolts. And I want to tell you about one process or property of neurons and another helpful cell that enables this to go extremely fast. tape for neurons, OK? So they are these-- there's electrical insulation around the axons of these neurons. And this is provided by another specialized cell type called a glial cell. And that insulates the plasma membrane of the axon such that-- so here is an axon. You have glial cells that are wrapped around, and it sort of forms like beads on a string. And so there are these gaps between the myelin sheath that are known as the nodes of Ranvier. ones, localize to these nodes. And that allows the action potential to travel about 100-fold faster along the axon. And one important reason to bring this up is because there is an important human disease that affects the electrical insulation in the myelin sheath here, and that's multiple sclerosis. This is an autoimmune disorder. And so we're going to talk about immunity later in the semester, and we'll talk about how that happens. But for now, I just want to point out that multiple sclerosis happens when the immune system attacks this myelinSheath. if you damage this electrical insulation, you greatly slow down these action potentials, and that has a significant impact on nerve impulses in the brain and throughout the entire body. And that's why multiple sclerosis is such a devastating disease. All right, I'm going to start moving now to consider more than one neuron. And so if we consider this connection right here, there's a synapse right here. Here's a cell that's sending information and a Cell that is receiving that information. but you might have another neuron sending a signal to a synapse on this part of the cell. And you could have another signal coming in here. And so this neuron will then have to decide whether or not to fire an action potential down its axon. And the way that the neuron decides this is to integrate the signals. So there's a signal integration process. And what's important for signal integration in a neuron is whether the cell body-- whether the voltage increases above a certain threshold potential. result in depolarization. What might be a type of receptor that would inhibit this process of sending an action potential? What might an inhibitory receptor be to lower the chance that this action potential will be fired? What if I told you it's an ion channel? What ion would you expect it might pass? Udo? AUDIENCE: Potassium. If it passes potassium, then it's going to make the inside more negative. And that's what's known as hyperpolarization, right? influences whether or not it will send the signal to a downstream cell. So there's a signal initiation process at the synapse. And this involves the presynaptic neuron secreting a neurotransmitter. So the signal, in this case, signals between neurons are called neurotransmitters. They're often derived from amino acids, and so they're small molecules. So one example is serotonin. Here, you can see it's a derivative of tryptophan, and it's able to bind to a receptor. on the postsynaptic cell and induce depolarization. And so neurons are-- the way that they communicate is-- neurons are a case of where luck favors the prepared. Neurons are totally prepared to send signals to each other. They have everything ready to go when they get word from upstream. And that's because if we look at the synapse prior to an action potential, everything isready to go. The cell has neurotransmitter, and it's packaged in these vesicles, and they're tethered to the plasma membrane, ready to be released. with the plasma membrane? What should trigger the fusion process? Yes, Miles? AUDIENCE: So after [INAUDIBLE] axon when it's time for the [INAudIBLE] that's when the vesicles fuse. ADAM MARTIN: Yeah, so Miles is exactly right. If serotonin is inside my vesicle here, it's going to need to exocytose. And now the serotonin is going to be outside the cell, ready to bind to the receptor. now on the outside of the cell, where it can travel across the synaptic cleft and bind to a receptor on the postsynaptic neuron. So this fusion is when neurotransmitter is released. And the way that this increasing calcium has to happen, when the action potential arrives at the axon terminus, there's depolarization of that part of thecell. And then there's a mechanism that links calcium entry to vesicle fusion. And that's going to be shown here. the plasma membrane of the cell, thus releasing the neurotransmitter into the synaptic cleft. So this is what starts the signal. Now, you probably know that these neurons are not active or on all the time. So something has to terminate the signal, usually quite rapidly. So now I want to talk about that. So like all signaling pathways, signaling is useless if you can just turn it on. You have to be able to toggle it on and off in order for biological systems to function properly. And that's the case with neurons. Prozac, Zoloft, these are a class of drugs that are known as selective serotonin reuptake inhibitors. This is abbreviated SSRIs. But the way they function is to leave the neurotransmitter in the synaptic cleft for longer so that you enhance signaling, even if you have low levels of the neurotransmitters. All the machinery on this vesicle is recycled by endocytosis such that it can be reused again, OK? So cells are really good at recycling stuff. If this is sort of the membrane, youendocytose and then you can use it again later on.  optogenetics is an approach to control the activity of a cell with light. In this case, we're going to have light inducing depolarization. And the way this is done is there's a protein discovered from photosynthetic algae that's responsive to light. And this protein is called channelrhodopsin, specifically ChR2. And if that's expressed specifically in the neurons that you're trying to test, you can then shine a light into the brain of the organism and activate this type of neuron. you to test the function of the neuron in the behavior of an organism. So, in this case, this mouse, the light is shined into its brain, and they're testing a specific type of neuron that is involved in arousal of the mouse. And it's going to wake up right now. There it goes. It woke up. You see now its muscle activity is going, OK? So you can test thefunction of specific nerve cells using this approach, and it's because you have a light-sensitive sodium channel.

ROUGE-1: 54.74, ROUGE-2: 52.73, ROUGE-L: 52.95
BERTScore: 74.05

==============================================
==================== [100/100] ====================
Summary:
In this problem, we're going to be dealing with a variation of the usual coin-flipping problem. But in this case, the bias itself of the coin is going toBe random. And we're told that the expectation of this bias is mu and that the variance of the bias is some sigma squared. So how do we go about calculating what this is? Well, the problem gives us a int. It tells us to try using the law of iterated expectations, but in order to use it, you need to figure out what you need the condition on. The problem also defines the random variable x. X is the total number of heads within the n tosses. Or you can think of it as a sum of all these individual xi Bernoulli random variables. And now, remember that we're flipping the same coin. And so each of these expectations of xi should be the same, no matter what xi is. And each one of them is mu. We already calculated that earlier. And there's 10 of them, so the answer would be n times mu. different scenarios, one where i and j are different indices, different tosses. So we have to consider both of these cases separately. Let's first do the case where x and i are different. So i does not equal j. In this case, we can just apply the formula that we talked about in the beginning. So this covariance is just equal to the expectation of xi times xj. All right, well, how can we simplify this inner-conditional expectation? Well, we could use the fact that the problem tells us that, conditioned on Q, the tosses are independent. we're told is sigma squared. All right, so what we found is that for i not equal to j, the coherence of xi and xj is exactly equal to sigma. And so, because they're correlated, they can't be independent. The second case is when i actually does equal j. And in that case, well, the covariance of x i and xi is just another way of writing the variance of Xi. And again, we know what the second term is. part A is just mu, right? So that's just second term is justmu squared. But what is the expectation of xi squared? Well, we can think about this a little bit more. And you can realize that x i squared is actually exactly the same thing as just xi. And this is just a special case because xi is a Bernoulli random variable. So the answer isjust mu minus mu squared. OK, so this completes part B. And the answer that we wanted was that xi and xj are in fact not independent. Right. of xi is mu. And we also want to remember what this covariance is. The covariance of xi and xj is equal to sigma squared when i does not equal j. So we'll be using these facts again later. And the variance of x i is equal  to mu minus mu squared. So now let's move on to the last part, part C, which asks us to calculate the variance of x in two different ways. So the law of total variance will tell us that we can write the variety of x as a sum of two different parts. of these Bernoulli random variables. And now what we'll do was, well, use the important fact that the x's, we're told, are conditionally independent, conditional on Q. And in fact, all these are the same, right? So we just have n copies of the variance of, say, x1 given Q. Now, what is the Variance of x1given Q? Well, x 1 is just a Bernoully random variable. But the difference is that for x, we don't know what the bias or what the Q is. Because it's some random bias Q. were i is not equal to j. Well, there are actually n squared minus n of them. So we've use two different methods to calculate the variance, one using this summation and one using the law of total variance. All right, and now if we compare these two, we'll see that they are proportionally exactly the same. So what do we learn from this problem? Well, we saw that first of all, in order to find some expectations, it's very useful to use law of iterated expectations. But the trick is to figure out what you should condition on. An art that you learn through more practice. But one good rule of thumb is, when you have kind of a hierarchy or layers of randomness, it's useful to condition on the layer above where that is, in this case, the random bias of the coin itself. Once you condition on that layer above, that makes the next level much simpler. Because you kind of assume that you know what all the previous levels ofrandomness are, and that helps you calculate what the expectation for this current level.

ROUGE-1: 43.29, ROUGE-2: 41.79, ROUGE-L: 41.76
BERTScore: 71.82

==============================================
