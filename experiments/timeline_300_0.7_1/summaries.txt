==================== [1/100] ====================
Summary:
John ESSIGMANN: I measure my blood sugar at different times during the day. Gluconeogenesis technically means new synthesis of glucose from non-carbohydrate precursors. The medicine I take is called Metformin. It has a number of targets, but one of them is one of the enzymes, called PEPCK, Pyruvate Carboxykinase, that's in the gluconeogenic pathway. It's pretty reasonable by the time I go to bed, but then at night, when I stop moving around a lot, this gluconeogenesis process continues. body, the brain, our red blood cells, that require glucose. They can't work with anything else. So gluconeogenesis, by principally the liver, provides a constant stream of glucose to these organs that absolutely require it, like our brain. What I do, during the night, is to take this drug that will prevent the switch to produce more and more sugar by gluc oneogenesis. And I do it to keep my blood glucose level at about 100 while we're not eating.

ROUGE-1: 54.12, ROUGE-2: 50.25, ROUGE-L: 40.67
BERTScore: 76.12

==============================================
==================== [2/100] ====================
Summary:
In this lecture, we introduce and develop the concept of independence between events. If I tell you that a certain event A has occurred, this will generally change the probability of some other event B. In such a case, we say that events A and B are independent. We will then proceed to define the independence of a collection of more than two events. Finally, we will close with an application in reliability analysis and with a nice puzzle that will serve as a word of caution about putting together probabilistic models.

ROUGE-1: 62.59, ROUGE-2: 60.96, ROUGE-L: 62.59
BERTScore: 82.29

==============================================
==================== [3/100] ====================
Summary:
As the dough ferments it fills up with carbon dioxide expelled by the yeast which is feeding on simple sugars which are broken down by enzymes from the starch in the flour. The gas accumulates in pockets inside the dough held together by the gluten structure. No matter how gentle you try to handle your dough you will always de-gas it if only a little bit in today's comparison video we'll make 4 breads they will be made from the same dough but they will all be treated differently it is a 65 hydration dough containing only flour water yeast and salt. Four breads will be left alone from the beginning of fermentation until it's baked. The first one won't be touched at all and the final one will be folded shaped and degassed three times. It is up to the requirements of the recipe how many times is going to get folded or degassed. understanding these principles will give you the power to create any recipe you like in your style. We will be fermenting them to the same volume this test is not to show what is better or worse it is to show you the differences. the dough will start cooling down and adjusting to the temperature of the kitchen while the middle may still stay warm so as we fold the dough we fold those outside layers into the middle distributing that temperature evenly throughout it and that is folding in short. There are different folding methods for different breads it all depends on what the dough is like but let's get back to de-gassing why would we want to knock the fermentation gases out of the dough why don't we leave it alone and let it rise and it would never punch you so why are you punching it? proof i tried to shape them similarly as i could so that the main difference between these breads would be the steps that we took or skipped now degassing folding and shaping is not just about what the crumb will be like it's also a way of controlling fermentation the loft on the left is almost ready to be baked while the other three they still need about an hour until they go in the oven as we know fermentation builds flavor and it helps develop texture of the crumbs and the crust by degassing the dough we are forcing it to rise back up again it basically has to start over.

ROUGE-1: 37.73, ROUGE-2: 36.96, ROUGE-L: 36.84
BERTScore: 71.08

==============================================
==================== [4/100] ====================
Summary:
Of the nearly 11,000 amendments proposed in the centuries since, only 27 have succeeded as of 2016. The founders of the United States were trying to create a unified country from thirteen different colonies. For an amendment to even be proposed, it must receive a two-thirds vote of approval in both houses of Congress. To actually change the Constitution, the amendment must be ratified by three-quarters of all states. The result of such high thresholds is that, today, the American Constitution is quite static.

ROUGE-1: 24.96, ROUGE-2: 23.60, ROUGE-L: 24.96
BERTScore: 67.92

==============================================
==================== [5/100] ====================
Summary:
50 years ago, John McCarthy and Marvin Minsky coined the term artificial intelligence. The idea of merging brain research and computer science in the quest to understand intelligence. This was the people that we put together from different labs, from neuroscience, from computer science, from cognitive science, and from a number of institutions in the US. Let me tell you a bit more about the background here. Part of the reason for this was progress and convergence we saw between different disciplines. And one of them was progress in AI. And this started, really, with Deep Blue, I guess it was called. We are still very far from understanding how people can answer questions about images. We would like to know to have a system that does that. But also, to know how our brain does it. It's not enough to pass the Turing Test. There have been, there are, and there will be a lot of significant advances in AI. I think it's a golden age for intelligent applications. But this is kind of engineering. Interesting one, but engineering. And we are not there yet. We want to have a system that does it in the same way as our brain. And we want to compare your model, our system, with measurements on the brain of people, or monkeys, also during the same task. So that's what we call Turing plus, plus questions. And would like to be able to answer how people do understand images. We start with vision. We are not limited, eventually, to vision. But in the first five years of the center, that's the main focus. Those kind of questions at all these different levels. But some, we are. One example is, who is there? It's essentially face recognition. And this is an interesting problem. We know from work, originally in the monkeys, and then with fMRI in humans. Shown here, parts of the brains of cortex, which are involved in face recognition and face perception. And then, it's possible to identify analog regions in the monkey. And look at their properties when the monkeys is looking at the face. And make models of what's going on.

ROUGE-1: 47.04, ROUGE-2: 44.67, ROUGE-L: 41.17
BERTScore: 64.03

==============================================
==================== [6/100] ====================
Summary:
Chef Todd Moore shares with you the seven basic skills that I think everyone should have to cook food consistently in the kitchen and be proud of the results. If you already have all seven of these skills and cooking techniques great you can work for me on the other hand if you only have one or two of these Skills that's still fantastic why because I know you'll want to add other skills and learn to cook basic methods know the methods behind all written recipes then you'll be making your cooking a winner every single time. To pass this test well the result should be three items that are precisely twice or half the size of the others consistency of cut is consistency of cook so knife skills are very important for excellence results you have failed this test if you give me items of a wide variety of shapes and sizes are all the items cut into the same size. If I see a chef using two hands on their chef's knife the metaluna thing back and forth I just know they're mashing up onions and creating inconsistent Cuts I want to see correct proportion of cuts when you learn how to use the chef's knives you'll love doing it you'll be looking for things to cut up. skill down when I can give someone three different oils types of oils put them in a pan and they can tell me where the variable smoke points are so you pass this test when the chef notices the oil starting to change from being perfectly smooth to beginning a convection process then adds the protein product to the pan just before there's visible smoke. Brown foods are attractive F Foods this is what attracts the eye and to develop golden color in the sauté pan you have to get the sugars in your product to caramelize at 320° fah. one that's lost moisture one that's burned one that shows the lack of involvement in the preliminary steps of the sauté process Chef test number four here's the answer thicken a liquid to make a sauce. Rue flour and cornstarch are fantastic thickening agents but you need to have an understanding of how much to use and this can only happen with controlling the process of gelatinization of starches Chef that can show me that they pass they take a cup of milk they turn it into a thickened sauce that's shiny that's velvety. control heat in a moist convective process is an important Chef's skill number six was to roast something delicate like fish. There's a very fine line between the coagulation of proteins the stiffening and shrinking of what you're cooking at 165° F and the 212° fah when moisture starts evaporating. The key to cooking with dry heat is being able to live in this temperature zone between 165 and 212 where the food Cooks for drying out so you pass the chef test if you give me a nice piece of flounder or tilapia even Cod or Whitefish catfish anything that's fully cooked and it retains its moisture without drying out. and it's dry it's much smaller in its uh cooked State than it was in its raw State because of the drying effect of the oven this Chef doesn't know how to retain moisture in a dry cooking process Chef test number seven how to tell when a grilled steak is done. If you can Master this you are a master griller most people just burn stuff you fail this test if you give me three St Stakes all cooked to the same temperature or if you can't tell which steak is rare medium well done if you're taking them off the grill guest atam the chef that can that can't control direct to Source conductive heat would create waste in my restaurant waste over sales for Stakes being sent back to the kitchen. I don't want this this is a chef's level skill so this is what's going on in my kitchen. If you want to cook great food more consistently you'll want to pay attention to the cooking techniques and have repeatable methods. These are the same methods I'm going to reveal in my webinar it's discover the three secrets to making your cooking a winner every single time.

ROUGE-1: 48.49, ROUGE-2: 47.56, ROUGE-L: 48.49
BERTScore: 64.39

==============================================
==================== [7/100] ====================
Summary:
as a nurse you want to be familiar with heart blocks and in this review i'm going to be talking about third degree heart blocks also known as a complete heart block. The reason is occurring is because electrical signal from the atria isn't making it to the ventricles. The person could be born with it so it could be congenital or the person has severe heart disease or they have a myocardial infarction or they're taking some type of medication that they become toxic on like digoxin. block and if you'd like to watch more videos about heart blocks in this series you can access the link in the youtube description below. Click here to read the first video in the series about a heart block. Read the second video to learn more about the heart block and how to block it. Click the third video to see the next video about the block and learn about the different types of block that can be used to block a person's heart. The third video is the final video of the series and is about the blocking of a heart valve.

ROUGE-1: 39.81, ROUGE-2: 29.93, ROUGE-L: 27.96
BERTScore: 64.02

==============================================
==================== [8/100] ====================
Summary:
The final contest, which is due tonight, is to design an agent that plays together with another agent to try to collect food pellets while not getting eaten by ghosts. Submissions for that, your last chance to submit are tonight at midnight. And on Thursday in lecture, we'll discuss the results. The idea behind these two lectures is to look at advanced applications. We will not quiz you on these application lectures, on the final exam, or anything like that. It's more meant to give you more perspective rather than extra study materials. Search is very prevalent in language processing, and we'll cover some of that on Thursday. Adversarial games. Learning to acquire behaviors. We'll look at some real robot behaviors in flight and in legged locomotion. And dealing with uncertainty. So AlphaGo. Today's state-of-the-art in Go is that there are computer players better than the best human players. But actually, if you went back to March 2016, that was not the case yet. So how do you make an AI for Go? For a game like Tic-Tac-Toe, you will find out that you can force a draw, and that means fully solving the game. For Go, this is actually pretty hard to do, and it's even much harder than chess. Let's take a look at chess. The branching factor is enormous. So if you tried to run an exhaustive search through this kind of game tree, it's not going to work. And the ideal expansion scenario can reduce the size of the tree by square rooting it. Still too much. to think two deep instead of all the way till the end of the game. After two deep, you look at the evaluation function and it might be good enough. But many of the moves are not that useful. And so policy network can be trained, which assigns probabilities to all possible moves. And then you might only consider the moves with high probability when running your search, or you might just sample from that distribution to run your search. For AlphaGo, there was a bunch of data collected from human play. Then a supervised learning was run, so a deep neural network was trained. DeepMind's AlphaGo is a computer program that can learn to play Go without human input. It uses deep neural networks and tree search to learn how to play the game. AlphaGo Zero, which learns at a level beyond human level, was used to defeat the strongest player in the world at Go. The program is now being used to learn chess, Shogi, and other board games, as well as other complex games such as chess and checkers. For more on the AlphaGo program, visit the DeepMind website. AlphaGo Zero has no prior knowledge. It starts at a pretty, actually, negative elo rating. Loses all the time initially. It's playing itself, but then gets tested against a set of players. After 21 days, it goes past where AlphaGo Lee Sedol was. And then it was still creeping up after 40 days. It was still climbing, but let me see if I can pull something up that might showcase it. OK, so here's AlphaGo Zero. The cursor's somewhere here, yep. knows, from every situation, who's guaranteed to win or whether it's guaranteed. to be a draw, and then knows how to play that. Once you reach that level, essentially, there's no further to go, because you solved the game. With reasonable compute power, it traverses the whole tree. Even with alpha beta pruning, I don't think that'll happen anytime soon. It's a really big tree. And that'll add up to a very large number. If you do a more kind of brute force style approach-- not 100% brute force. even longer. It could be that by using human knowledge, you're in some kind of based enough attraction. I don't know if that would be the case or not, but that's a possibility. It also depends on how much randomness you have in your exploration. If you have enough randomness, then initialization will have much less effect than if you have limited randomness. Is it even possible to learn good Go players by just playing against yourself? That's something people did not have an answer. CNN's John Defterios: How do you get a helicopter to do something like this? He says it's hard to stabilize a helicopter when you only know where you are up to a couple meters. So how do we track the helicopter? None of these measurements are super precise, he says. Defterio: We set up a hidden Markov model, where we considered the state unknown, then the three angles, the velocity, and the angle rates. And the measurements are the measurements I just described. in angle from back and left right as the blade goes around. So that way, you can generate a torque that allows your helicopter to roll or pitch based on how much differential thrust you have from back, left to right. The tail rotor has a variable pitch also, and that pitch allows you to modulate how much thrust you get from the tail rotor. So you can build a model for this from collecting data from your helicopter, let's say, and learning a bunch of parameters that predict the next state. A helicopter can learn to flip and repeat by following a trajectory. But in the real world, the helicopter deviates from the path it learned in a simulator. The helicopter doesn't know how to control around that path. It started overcompensating. That's why you get a half flip, half spin and repeat. It's not easy. Exactly how much do you push up? How fast do you spin? Difficult things to decide. A few years ago as a PhD student, I tried to design this kind of thing. saw it making these wild motions, overcompensating. It pushed the controls so hard that the engine died. The engine just couldn't push it, died. At that moment, the blades stopped spinning, or they slowed down. Then what happened is our human pilot took back control to try to save the helicopter. And believe it or not, they actually saved this. It landed a little harder than you want to land, but it landed on its feet and it could be recovered from that, which was pretty crazy. that point, was much better than our autonomous controller. So we started looking at some human pilots. We said, well, clearly, the issue was that we asked the helicopter to follow a path that's not flyable. But it turns out, when we collect paths from a human pilot, they tend to be noisy. So how do we, from, this get a specification of what we should be flying? Well, we could learn the trajectory from these as noisy observations. What methodology do we have for that? Hidden Markov models. have something we don't know that evolves over time, but we have some noisy measurements of it, we can run an HMM to recover what we actually want. We use something called dynamic time warping. So what does that do? You can align two trajectories. Let's say you have many demonstrations. Then you have a hit injectory, which is just initialized with one of them. Then, you run dynamic time Warping, which aligns each trajectory with the hidden one-- which was just a guess. We have collected data to learn a dynamics model for the helicopter. We can now penalize our award, penalized for deviating from the target. And then we can run reinforcement learning in simulation, let's say, in this learn simulator to find a good controller and run it on the real helicopter. The controller we learn in simulation is still a little optimistic about really following that path. So while we fly the helicopter, we'll do depth-limited search to improve what we have. able to look ahead only two seconds, rather than needing to look further. A value function tells us, OK, how good is it to end up here? We also have a reward at each time tick. And our search over those two seconds is what results in the control we apply. The fastest we flew this helicopter was close to 55 miles per hour. The algorithm's only this big, so it's pretty fast for something of this size. And then now are actually some of the hardest maneuvers to execute on. Professor: With this methodology, it was possible to fly this helicopter at the level of the best human pilots. Professor: The hardest maneuver in this air show, the reason this is so hard, is that you're maneuvering in airflow. We did not push that further to flying those maneuvers. There is some work. If you look at Woody, Woody was shutting things off. He was able to have it learn to hover reliably with the only human input being shut it off when it looks like it might start doing something dangerous. at OpenEye, there's been some work on robots learning to do back flips. And that was kind of one step further. It wasn't just shutting it off. You would watch your robot try things. And human input would be not specifying a reward function, which is very hard to do for things like back flips, just like it was hard here. But what they did is they said, the human watches it and says, which one is better or worse among a set of them? And then from that, it learns a Reward function. The helicopter uses roughly a fixed amount of fuel, anyway, per time. So it's more that it has less weight to carry as it has used more fuel. This helicopter had inverted slide, where it has more power, 3 Gs. It can generate three times the power of gravity. OK, let's take a short break here. And after the break,. let's do legged locomotion and manipulation. All right, let't restart. Any questions about the first half? Yes? is a separate linear feedback controller for each time slice. So essentially, value iteration, but in a continuous space. If there is no wind, you can actually just run the linear feedback control. It will be fine. But if there's some wind gusts that could throw you off, you want to use the value functions and the two second look ahead. If you have a locally linear dynamics and quadratic reward function, it turns out that's the one continuous state action space scenario where you can run exact value iteration. against those value functions to do the controls. Can it be done with one unified network? Likely, it can. It might take some work, exactly, figuring out how to do it. Here's an example of how hard this can be. This is a video from 2015, there was the Doppler Robotics Challenge, which was held in Pomona, just east of Los Angeles. It's called the "Doppler Challenge" and it's a competition for roboticists. It was won by a team from the University of California, San Diego. of Los Angeles. People had two years to work on this. And what did the robot have to do? It had to, essentially, drive a car or walk, but driving the car was recommended. Then get out of the car, walk a little bit, open a door, grab a drill, drill a hole, walk some more. So doesn't sound that complicated. But actually, it turned it's very complex to get a robot to do that. And it's indicative of how hard it is to do walking with robots. build a model of the world. The thing is modeling these situations proved even harder than modeling helicopters, because your sensing needs to understand whether or not you're already making contact, and making contact or not. Now, what's changed recently in the past few years is that through advances in deep learning, it's been possible to better map from raw sensory information to controls you might want to apply. And so actually, you've seen this video before. It's in simulation, but this robot is, over time, learning to control itself to do walking. And ultimately, it learns to walk. The reinforcement learning algorithm can be reused directly onto other robots and can learn to control these other robots. The reward function is the closer your head is to standing head height, the better. This can work directly for building video games. You build video games, you want your main character to move in a realistic way. You can have it sequence together motions like these and dynamically simulate how they interact with the world, rather than key frame every little detail. But it shows, in simulation, at least, a lot of progress towards learning intelligent locomotion behaviors. There are two levels of control: low level and high level. Low level control is about placing your feet in the right next position. High level control problem is actually a star search. If you have a cost function for this terrain, what would the cost function be? Well, you maybe don't want to be next to a big cliff. Because if you're right next to it, then you slip a little bit, you'll slide your foot down and that's not good. So there's a bunch of considerations you might have. When you run the search, or the value iteration, which is, more or less, equivalent to find a path across this terrain. But if you choose the trade-off between the features differently, you'll find different paths. So reward learning. How you do reward learning, you demonstrate a path. Demonstrating doesn't mean just drawing a line. It actually means choosing a sequence of footsteps that it executes on, and assuming it does well. It assumes you have a low level controller, but that's well understood how to do that. Self-driving cars take part in Dartmouth Grand Challenge. First time autonomous vehicles have been used in a race. No robot has ever gone more than three miles in the race. The winner of the race will be crowned the winner of this year's MIT Robotics Competition. The final race will take place in May. The winners will be announced in May 2015. The prize money will be $1 million, with the winner taking home $500,000. The competition will be held every year until the winner is crowned. Stanley is about to become the first vehicle in history to drive 132 miles by itself. Cameras, radar, control screen, steering motor. Lasers, where you shoot out laser beams. The steering control, usually, you would have a high level planner choosing a path and then a low level controller that is good at following that path. And based on how long it takes them to get back, you know how far away the nearest obstacle is in that direction, assuming it's an obstacle that reflects back to where the laser came from. With a camera, you can often look further ahead. LIDAR sends out a laser beam, measures how long it takes to get back. With HMM, you get 0.02% false positives of where there might be obstacles. An HMM can de-noise those readings into a more reliable estimate of the geometry of the world around you. It would see that the readings are different and decide it needs to steer around that.an obstacle. If you're an urban environment, there'll be a lot more obstacles. A camera will be better at that than a LIDar. Self-supervision is a trick that's very widely used to reduce labeling efforts. So the camera now knows all the red here is road. In urban environments, there's even more need to recognize, not just road versus not road. A lot of progress has been made this is video from 2013. This was before deep neural networks were heavily used for this kind of thing. It's only getting better to recognize what's in scenes, thanks toDeep neural networks. Instead of classifying into which categories in the image, you would classify each pixel, as to what is in each pixel. tail of special events that can happen when you're driving. You can measure progress by just demo videos, which is one way, and it gives you some kind of feel for what's going on. Another way to measure progress is to see how are these cars doing relative to human drivers. If you test in California, you have to report this data to the DMV to see if your car is doing well or not. It's a number of events per 1,000 miles driven. Red there is human fatalities. Then yellow is human injuries. In green is the Google slash [? wave ?] mode disengagement. doing this. Early on, they were the only ones, as far as I know, but there's more companies now. And you can look at them on these plots and see which companies, how far along, in terms of how many disengagements they need per 1,000 miles driven. Still, so far, quite far removed from human accident rate levels. Another thing people have been pushing, as a consequence of all this, is lower power neural networks. So for example, Kurt Kuetzer at Berkeley has projects on this called SqueezeNet. If they're gigantic, use a lot of power. That's a problem. Let's see what we can do to build smaller networks to make decisions.

ROUGE-1: 40.44, ROUGE-2: 37.28, ROUGE-L: 35.71
BERTScore: 67.20

==============================================
==================== [9/100] ====================
Summary:
So let me say here just the repetition, normal, inferior. Let us say we are talking about price of good 1 has gone up substitution, income these are the effects and overall. When P 1 goes up subs because of substitution effect x 1 will. Come down. And for income also because of income effect it will come down. So, overall it comes down. While inferior goods substitution effect quantity demanded would come down while income effect is Up. Up. Can you give me an example its very very difficult to find Giffen good in real life why? Luxury goods are not Giffen goods. Luxury goods can't be termed as good if prices come down by significant amount. Income effect has to be larger than substitution effect. It means significant portion of your income is gone in buying these items so that is not true. We have very-very hard time getting finding out, figuring out GIFFen good in an economy. Sir, like if Gucci is a brand and it is. Prices comes down bysignificant amount. No one could buy a Gucci, it is at that level only because of it is prices.

ROUGE-1: 35.67, ROUGE-2: 33.68, ROUGE-L: 29.32
BERTScore: 78.72

==============================================
==================== [10/100] ====================
Summary:
which we are to for next week and here and I'll talk about that actually week from today because it's callay on Monday so it will get behind but if we get any further behind I'll have to make it up sometime. If you don't have that you be copies available upstairs is it c um come to my office okay to dany's office he doesn't have copies of it there that's six six upstairs in the first floor immediately after CL and then on the next Friday I will talk about the parts in the in the inquiry that were assigned and also a that essay of of the oral concept well last time you call. not about political jurisdiction that it must be possible through this series of agreements to Contracting it without being irrational putting noone's life anywh in Jeopardy or without viting any of the duties that one has. The way in which he described absolutism of the kind of he's objecting to is going to be thrown out um and the has if his premises are correct more arguments than he needs that is he's uh believes that today the nature is worse than being subject to an abolute mind. Loot's view is that although of course one is bound I'm sorry one is Born Into into society as a matter of social fact biological fact and so on one is not obligated through the political institutions until one gives at the Age of Reason some form of consent. It's unclear the form in which is tast whether it's an oath of fidelity to the crown upon inher say the family property or whatever it's not expressly said. There's a distinction between express consent and P consent Express consent incorporates us into society and as a Perpetual or presumably taxic consent does not. of the original contract he gives arguments against unlocks View and you have to ask yourself how effective is K's argument against each of these two parts of lock view as you might think that it's not very effective against the Criterion of the general form of regime but yet think it is effective and highly effective against how indidual become bound to particular regime. So that's why I had gone over this question in order to distinguish the two parts or the two things that are discussed namely the just and right and legitimate form of regimes and the other is the conditions under which particular individuals become bound. exclusion crisis of 1679 and 81 um the original part of the second CH was written it believe about 79 and 880 and then other chapters that were were added in 81 83 and two chapters added after. Now by definition a mixed Constitution is a constitution in which two or more constitutionally defined agents let's say share in and each have a part in What L calls the legislative power that is the supreme power in the constitution is the legislativepower. In the English case of course it's the crown and Parliament so we're only actually dealing with two agents in this case and neither is supreme so we want to say that they are coordinate powers. Filmer had argued against anyone's a denying crowns complete Supremacy precisely on the grounds that if there were conflict there would be no way to settle it so MK is granting filmer point on this there's no way around it. In paragraph 168 he says if there is a conflict of the sort then the people have the right to appeal to Heaven which is a euphemism for for go to war that is Civil War and uh the power then refs to them and they have theright of resistance. of Andrew Johnson although didn't past and it tends to make it politically impossible for president to persist over a period of time and a long drawn that conflict of with Congress so I might say that today checks then has this effect and comparable things were not available in the 17th century you had not yet institutionalized these various devices. Mar's problem is to justify existence of the crown in this kind of situ situation now now the source of Lock's constitutional Doctrine the source and thought is a book where at least is belied to be. you see granting uh certainment to we sensibilities and also holds this view of the English Constitution also to sensibility but they're not claiming parliamentary Supremacy that's the I say crucial is that. No such contract contacted government in LW and there isn't in h either but other contract doctrines some sometimes as a talk with a both but here there's only the one contact the concept of power as a fiduciary power the point of that I think is to emphasize the constituent power of the people. all the Clauses it might contain and it would be an useful exercise I think to do that um to find out explicitly all the things that we have gone over. We might say read the people and give some description of who we are perhaps list of names I do here by Compact and we think it just as AAL and express uh consent we hereby compact with one another each with all and all each it's better to unite into more non political Community or political society and we thereby put ourselves each put ourselves under obligation to comply with the loss of political power. changed his mind he thought perhaps it was not all together safe never knew in England the English were regarded in those days as very unstable people. Mark says nothing about the details of of this process that is how does he Enis that this constition power is actually to take place he doesn't give any institutional account of how he supposes actually might be done laon is also vague on this he says something has been done and something has happened to change the form of the Constitution and the government was dissolved against to power of the Comm brought into play. the idea that it would begin in the county courts and they organized there and would then they presented Des sent from there to a parliament now acting in another way now it's sort of something like what we would call the Constitutional Convention but again the details are extremely big I think the reason for that is obvious you want to be pre in some sense to act in accordance with some politically organized party so we don't find inlock what is supposed to happen in that case but the implications are quite are quite uh obvious in somesense this is inly radical U Democratic Doctrine or it could be. Nation than the other now why did L refuse to alter his view I think we have to assume that he didn't change his mind and he persisted in the doctrine that he formed earlier in 79 and 880 I think partly because his views are more radical than the standard view of his college that that would be one reason but also because he felt I think that it was inconsistent now there isn't this view in the trus but if one sort of HS it through perhaps one can see that it is any rate in danger of being insistent. A small percentage of it is able to vote on this view uh now Mar is not arguing that point one way or the other taking it for granted and also when he talks about property he's not attempting to justify property in the sense of explaining it and justifying it to those who don't think there should be part of father. He's trying to give an account of the institution how much it come about an institution which politically Tak from point of view everyone accepts D's argument had been that MOX or any social compact view or contract view the earlier agreements could not account for prodate property. This scheme uh or show that that could happen without violating some of these other conditions now presumably the answer is something like or at least would be one answer that one might get. Given the hazards the defects and the lacks of the data nature given the benefits to be expected under government and very thing it's rational even for those who lack efficient land to agree to social Compact and for the majority to vote or to place the legislative in the form of a regime that excludes most people from actually voting. It would be rational to do that and given the circumstances it would not violate any of the other conditions which are consequence of the fundamental law of nature. and who does not have the right to vote and what the conditions on it are maybe we want to free it from that of course what I'm thinking of eventually um is that that that would be one motivation for introducing an idea like the origal position that say it's a way of conceiving how con power might be exercised. No point in criticizing someone for something they didn't intend to do okay well I think it's stop so remember there's no class here Monday so the next class here will be next Friday.

ROUGE-1: 40.56, ROUGE-2: 39.56, ROUGE-L: 39.83
BERTScore: 74.49

==============================================
==================== [11/100] ====================
Summary:
David Kaiser: Today we're going to be talking about the kind of invention or the hybridization of a whole new subfield within physics that now is often called particle cosmology. It studies the smallest units of matter, the fundamental forces and elementary constituents of matter. It asks about what role they might have in shaping, really, the fate of the entire universe. Kaiser: We'll talk about institutions, and politics, and some broader shifts in the field, out of which come this new now quite flourishing subfield. Quantum theory and elementary particle physics didn't even exist 45 years ago. Today, its annual budget just within the United States is on the order of $1 billion a year. There are on average two new physics papers, two new preprints posted to the central preprint server archive. every hour of every day just in this subfield. So it is really a booming, booming subject of study, and I find that all the more astonishing since it's a fairly recent vintage in terms of the kinds of time scales. or particle physics and that it somehow this set of ideas that bubbled up in the mid-1970s of that we'll look at today. And so there's a lot going for that explanation, but it's also, I think, really, really quite incomplete. So if we start using the kinds of tools that we've been working on together this whole semester, we can dig in a bit more and try to uncover some of the additional factors that really were at play in especially in the early years of this field. to focus on the question of mass. How did physicists in different subfields in the 1950s and '60s think about this. And that helps us trace the precursors for this overlap field of particle cosmology. Then we'll take a look at some of the broader institutional shifts that were also coming to be very dramatic, and some of them quite unexpected, by the late ' 60s and early 1970s. And then we'll zoom back in to see what were some examples of the kinds of research questions that now seemed obvious or natural to ask for members of this new hybrid area. Einstein was inspired by some of Mach's writings on this. Mach himself didn't call it Mach's principle. But it was attributed to Mach by Einstein as early as 1918. The idea was should we be constantly paying attention to the global distribution of matter and energy when we try to make sense of local phenomena associated with mass? So that was a very challenging question, and we'll say more about it soon. But that was one of the ways that the problem of mass took form, was given a concrete form. and '60s. There was quite a different set of conversations happening around the same time. This had nothing to do, at least on the surface, with Mach's principle or even with Einstein's general theory of relativity. But the challenge became very clear very quickly. These nuclear forces are somehow mediated was what arose from particles exchanging certain kinds of force-carrying particles. The point is there were new kinds of matter. And then when particles tossed these back and forth, that would give rise to things like radioactive decay. Self-evidently of short range, unlike gravitation or electromagnetism, the nuclear forces really exert themselves across nuclear dimensions, very tiny fraction of the size even of a single atom. The idea was could have finite range nuclear forces if these force-carrying particles had a very large mass. That will make it very unlikely for that force to be felt across a large distance because of the whole set of ideas about virtual particles and the uncertainty principle. So that broke half of the motivation for it. This was a pretty substantial challenge. It got lots of theorists very exercised over the 1950s and especially 1960s. Can we account for mass of these elementary particles in a self-consistent way? Because there's other set of puzzles that didn't seem to fit together. So the question of mass turns out to have been on many specialists minds in the '50s and '60s, but as embedded in quite different-sounding conversations. So let's look a bit more at some of the proposed solutions to this question ofmass. In Einstein's theory, the unit strength of gravity is set by some universal constant, the same constant G. Brans and Dicke wanted to modify Einstein's general theory of relativity in a very specific way. Their idea was to introduce a whole new kind of matter, a newkind of particle in nature. They labeled it with the Greek letter phi. And they put in an extra dimensionless constant, a fudge factor, that they labeled by theGreek letter omega. And this was basically to control how much mass there was in the universe. Their version would depart from the ordinary behavior from general relativity. As omega becomes larger and larger, the field is much less likely to vary either over space or time. And in the limit that omega becomes arbitrarily large, then phi, in a sense, can't afford to vary at all. The kinetic energy cost is too high. So you get back to the Einstein-like limit. So they had this very clever fudge factor, a coupling constant, so that, in principle, the local strength of gravity could be changing all the time. As omega becomes large, the behavior reduces to the kind of constant strength of gravity of the original Einstein theory. The idea is that this new form of matter, this new field phi, is extended throughout all of the universe through every nook and cranny of space. All of matter interacts with phi. So this would be a way to incorporate Mach's principle going beyond even just Einstein's version of the theory. It's almost like a new ether, you might say, It's everywhere. certain elementary particles have a short range if we can't accommodate a mass while keeping this symmetry? This is now they're back in this question of things like the nuclear forces. Could you have nuclear forces mediated by the exchange of particles? Could those particles themselves be very massive? So they don't go very far-- so a short-range force-- and yet, still be respecting the very symmetries for which people had invented those particles in the first place. So here was, again, a very clever suggestion coming first actually from Jeffrey Goldstone. The Higgs field isn't responsible for the nuclear forces. It's responsible for giving everything else the masses that we measure, including those force-carrying particles. The equations for the governing nuclear forces could retain all the fancy symmetries for which these new particles were introduced to reinforce that symmetry at each point in space and time. However, this is a dynamical field. At some point, it will settle into a local minimum. The system will minimize its energy. That's how it will work. seek its equilibrium. The governing equations maintain the symmetry, but the symmetry is broken spontaneously when the system relaxes to some lowest energy state. When the scalar field gets anchored to some energy-minimizing value, that changes the interactions of the effective dynamics of all the fields that coupled to it. And now they number across space as if they have a very large mass. It's a 50/50 chance that the solutions to this dynamical system will break the symmetries that govern the equations themselves. An induced mass coming from this spontaneous symmetry breaking. So now, again, you can have your symmetries and your short range. So fascinating, a lovely idea being introduced right around the same time as Brans-Dicke also as one way to try to get to this question of why do objects have mass. It got a lot of attention, as I'll say more about in a moment, because it offered the first really concrete quantitative alternative to Einstein's general theory of relativity in nearly 50 years. No one suggested, at least in print, that these two scalar fields with the same Greek letter might be similar or even worth considering side by side for nearly 20 years, until the later 1970s. The sets of ideas were published to very wide acclaim in their own separate fields as early as 1961. It took more than 15 years until people began to say, hey, these two Scalar fields are meant to pervade all of nature. All of other forms of matter interact with them. They give rise to what we measure as local inertial effects. Each of these papers-- the Brans-Dicke paper and the Higgs papers-- became technically renowned within fewer than 20 years. So you can see more than 500 each. In fact, it's 1,083 distinct papers doing the citing if you add up all the ones between these two plots. And yet, only six of those-- so less than 1%-- cited both the BrANS-DICke paper. and theHiggs papers in the same article during this whole 20-year period. on these two fields being literally the same field-- only one new field of nature, not two. So it's not that they're somehow intrinsically totally separate or different from each other. So instead, their status, really, is historical. How people assess them or what they thought they were good for was changing over time. And so what had changed? That's what we'll pick up in the next part. Let me pause here and ask for any questions. So Alex asks, was it an accident that both parties chose phi? Not really. more than just the letter that they chose. There was a lot of what we might have considered similarities. And yet, the two sets of ideas really were treated so separately. So we might wonder, well, was it changes in data? Did experiments force a new evaluation? No, not really. Let's look at the gravity side first. So I mentioned that part of what got the gravitation community so excited about Brans-Dicke gravity was it now gave them something very tangible, very specific to try to test for. By the end of the '70s, things did not look very good for Brans-Dicke gravity experimentally. That is, all the tests were easily consistent with the predictions from Einstein's theory within experimental errors. To match all of these increasingly precise new experimental measurements, Brans' Dicke theory was not highly favored. So that's on the gravity side. Meanwhile, there was literally zero experimental evidence, a big fat goose egg nothing in favor of the Higgs-Boson until July of 2012. two sets of ideas consider them side by side. The main story that's mostly given-- I alluded to this in the very beginning of today's class-- is actually hearkens to changes in ideas and, in particular, on the particle physics or particle theory side. These ideas are well worth appreciating. And they came in rapid fire in 1973 and 1974. The first of them is called asymptotic freedom. And actually, it's the reason why our friend and colleague here at MIT, Frank Wilczek, received the Nobel Prize. The US budget for high-energy particle physics fell in half in just four years. That's a very sudden drop. So even as the whole field starts going through some pretty dramatic changes, particle physics feels the brunt of it in the most extreme way. So that leads to an interesting set of internal migrations within the discipline. And that's where the people who stay within physics at all that you have a net outflow by a factor of 2 just within the field of people fleeing particle physics. was cut most dramatically. And the job scene was most hard hit, and experiments looked like they'd be on hold and so on. And so in some of these reports that tried to make sense of the crash, like this 1972 report commissioned by the National Academy of Sciences, they single out particle theory. They say it's not coincidental that these young theoretical physicists in particle theory had the hardest time when the trouble came because this report claimed, at least, they'd been poorly trained. A blue-ribbon committee recommended that young physicists be trained in particle theory. The idea is to formalize their exposure to more and more parts of the discipline, including explicitly more focus on gravitation and cosmology. More and more departments, including very elite trend-setting departments across the country, start rushing to offer new graduate courses in general relativity. Questions on that field, really for the first time in the United States, start showing up regularly on the general exams for physicists across all fields. vast majority of those came really in the later '70s, in the wake of these pedagogical reforms. So remember that big report comes out in 1972. You start seeing curricular changes as early as '73, '74. By '75, '76, '77, you start seeing, in some sense, the market respond with many textbooks being really rushed into print. Some of these textbooks were basically mimeographed lecture notes. And now there's very, very fancy books published in a more typical way. GUTs, or GUTHs-- I'll throw him a bone-- are the symmetry groups associated with the different kinds of forces. Each of those three symmetry groups are actually sub-- you think about it. You can represent any of them as matrices. And there is the smallest group that includes those three as subgroups is an SU5. So that led to new phenomena that were predicted that turned out not to be measured, but that was the idea at least. And that's super cool and fun and lots more to be said about that but that is, indeed, where that nomenclature came from. In 1979, two separate theorists introduced a whole new model where they didn't only cite Brans-Dicke and Higgs, they literally united them. They wanted to ask why gravity appears to be so weak compared to all the other forces. The idea was that this local strength of gravity, Newton's constant, would get anchored to a very small value when phi gets stuck at a relatively large value. So why is gravity so weak? They suggested maybe it's because it's arising from some broken symmetry. He wandered into this field really accidentally. He finished his PhD at Harvard in 1970. His work was squarely in particle physics, the fancy new symmetries and new nuclear forces. That's what he studied for his thesis. He then had a sabbatical early on in his faculty career, and he happened to go to Paris. He swapped apartments with a Parisian physicist who was about to come to the United States. And as Tony recalls, he found these stacks of preprints all around the apartment that looked interesting. Lee Smolin was the other person who independently introduced that broken-symmetric theory in 1979-- same year as Tony Zee. He was actually, from the start, combining the two fields, both in the courses he took and eventually with his advising team for his thesis and for his dissertation itself. So unlike this accident of trading apartments in Paris and reading a few preprints, more and more members of Lee Smolin's generation were going through a training like his, partly by design, in the wake of the National Academies report. Few physicists today think that Brans-Dicke theory of gravity best describes our. Universe. But the theory hardly died off by his experiments. In fact, arguably, interest in the field grew even as it was getting experimentally less and less favored. The training of people like Lee Smolin and his generation just was importantly different from the very excellent training that people like Tony Zee had had even just a mere 10 years earlier. And so the idea that we're picking single theories and that they replace each other, I think, just misses this fine structure. in turn, these new folks, especially people like Mike Turner and Rocky Kolb, went on to become real institution builders in their own right. So in fact, they were accelerates. Not only had they been trained to think carefully at this new interface, they helped really accelerate the trend. Turner and Kolb became the directors of the very first institutional center devoted to particle cosmology. It was called the Center for Particle Astrophysics at Fermilab when they were still relatively young in their careers. And so they were actively working to perpetuate this new hybrid area. counts as natural can shift in a pretty short time scale. And as we've been seeing throughout the whole term and including today, those shifts can be driven as much by things well outside of the physicist's control, geopolitics, and national scale budgets. So that's where I'll actually pause. And we have time for a few more questions or comments. Any other thoughts on that? With my last moment here, I'll say, before the construction for the new Center for Theoretical Physics, I had an office just down the hall from Alan's. And by a quirk of the old building 6, we had the same key. soon, everyone. Soon, everyone will be able to play together again. Soon. Everyone will be playing together.soon. Everyone. Will be. Playing together again soon.soon,everyone. Everyone, playing together againsoon.soon,. everyone. soon, everyone, will be. playing together once again. soon.everyone. will be Playing Together again.soon! everyone. will. be.playing together soon. soon! Everyone. will play together soon! everyone will.be. playing again soon! soon.

ROUGE-1: 35.52, ROUGE-2: 33.73, ROUGE-L: 33.47
BERTScore: 67.93

==============================================
==================== [12/100] ====================
Summary:
The "Victoria" made the first circumnavigation of the globe in 1522. But this story really begins in 1494, two years after Columbus's voyage on behalf of Spain. At the time, these nations had their eyes on the same prize: trade routes to the Spice Islands. The spices found there were used as seasonings, food preservatives, and aphrodisiacs, and were worth many times their weight in gold in 1520s and '30s. After 98 days at sea, dozens of sailors had succumbed to scurvy and famine. Magellan pressed forward, and on October 21, he started exploring a navigable sea way. 27 freezing days later, the three remaining ships emerged from what we now call the Strait of Magellan into the Mar Pacifico. Overconfident and severely outnumbered, Magellan's force was overwhelmed, and the native's bamboo spears ended the captain's life. When they finally reached land again, Enrique, the young slave, proved able to communicate with the natives. actually circumnavigate the globe. Magellan's legacy lingers. He had galaxies and space programs named after him. The "Victoria" continued west, piloted by Juan Sebastián Elcano, one of the pardoned mutineers. The small vessel made it back to Spain with a full cargo of cloves and cinnamon, enough to cover the expedition and turn a profit. An obsessive chronicler, Pigafetta described the lands and people they encountered. With the help of a humble slave, he also compiled the first phrase book of native languages.

ROUGE-1: 46.39, ROUGE-2: 42.43, ROUGE-L: 39.46
BERTScore: 66.22

==============================================
==================== [13/100] ====================
Summary:
Ani was a real person, a scribe from the Egyptian city of Thebes who lived in the 13th century BCE. His Book of the Dead was a 78-foot papyrus scroll designed to help him attain immortality. Ani's epic journey begins with his death. His body is mummified by a team of priests who remove every organ except the heart, the seat of emotion, memory, and intelligence. It's then stuffed with a salt called natron and wrapped in resin-soaked linen. The wrappings are woven with charms for protection and topped with a heart scarab amulet. can imagine him happily tending his crops for all eternity. Can't imagine him being happier than when he was tending to his crops. Can imagine him growing his crops all day and all night. Couldn't imagine a better way to spend the rest of his life than in the fields. Can picture him growing crops all night and all day long. Could imagine him tending his crop all day, all night, all day. Could he be happier than he was right now? Could he ever be happier?

ROUGE-1: 34.15, ROUGE-2: 25.37, ROUGE-L: 29.48
BERTScore: 63.27

==============================================
==================== [14/100] ====================
Summary:
JUDY HOYT: We're going to begin this lecture on handout number 14. We'll be moving now to chapter 7. This will be our first lecture on chapter 7 on the topic of dopant diffusion and profile measurement. The placement of those regions determines many of the so-called short channel characteristics of MOSFETs that we'll talk about. And finally, the doping of other materials, not just the silicon itself, but of the polysilicon gate affects things like things like point defects in silicon. gate depletion and limits how well the gate voltage controls the channel potential. So we really need to understand the placement of these atoms. Let's go on to slide 3. Since we just talked about the idea of the resistance of these different regions, I just want to remind people what the general form for how one calculates the resistance. We know that the resistance in ohms can be calculated by the product of rho, the resistivity of the material, which has the units of ohm centimeters. your text. Here, again, I'm picturing that same MOSFET structure with the resistance of the different regions. We'd like the sum of those terms to be less than or equal to 1/10 the channel resistance. To reduce those resistances, we would like to increase, in general, the junction depth xj. However, there's a problem that if we make the junctions deeper, it will make it easier for voltages at the drain to affect the current flow in the channel. that also scales down with time to thicknesses by 2009 on the order of 15 to 30 nanometers-- quite shallow. We really need to up the dopant concentration. And there's a fundamental physical limit on how much dopant we can put in the silicon and how much it will be electrically active. So this is becoming a real problem. We need to find new ways to activate dopants to higher levels if we're going to be able to manage this design tradeoff. And what I'm going to spend some time in the next few slides is giving you some sense of how these doping profiles need to be controlled and what their impact is on device performance. detailed device physics, but it's just to give you a flavor for why studying dopant diffusion is such an important topic. So let's go on to slide number 8 and talk about a topic called the short-channel effect. This basically takes place when the distance between the source and drain-- that is the channel length L-- becomes comparable to the MOS depletion width in the vertical direction. And then that the source-drain potentials themselves from theSource and drain regions end up having a strong effect on the control of the current in the device. is not that sensitive to the vertical junction depth, as you can see by comparing the diamonds to the stars. So this lower variation of the Vt with L effective or with channel length allows a larger design window, which we need because there's always going to be some process variations in the channel length across the wafer. And this enables the technologists to push the channellength down to smaller dimensions. So it's not so much a fundamental improvement in device performance, but it really enables you to manufacture circuits with these shorter channel devices. In silicon IC processing, there are two different steps that we refer to in diffusion historically. The first step was so-called predeposition. And what this refers to is that you had an initial step in which the dopants were introduced into the silicon wafer. In the more modern technology, it's usually done by ion implantation, which is a process that we're going to discuss later and is covered in detail in chapter 8. The second process in creating a region of the wafer with a certain doping is typically referred to as the drive-in. This is a subsequent anneal after the pre-dep that then diffuses and redistributes the dopant. get of these dopants if you did a predeposition at that temperature. At 1,000 degrees, you can get something like 3 to 4 times 10 to the 20 electrons per cubic centimeter by introducing arsenic into the lattice. If you introduce more arsenic than that, it may still be below the solid solubility, but you won't get any more electrons. It's not electrically active. It may not precipitate until you get up into the 10 to 21 range. out for a couple of reasons, mainly because it points to the fact that as we increase doping, we don't always get an increase in the electron concentration, and therefore a decrease in resistance. OK, so let's go on to slide number 21. And we're going to consider macroscopic models for diffusion. Later on, we'll talk about the more atomistic diffusion mechanisms and effects. And hopefully, you've read part of chapter 7, and you know that Fick's first law, which describes how the flux or the flow of dopant depends upon the doping gradient. The proportionality constant is called the diffusivity D. It has units of length squared per time or centimeter squared per second. D is related to the atomic hop rate or the jump frequency over some kind of energy barrier. And this energy barrier is associated with the formation of migration energies of mobile species. In the silicon lattice, by symmetry D is isotropic. So it doesn't depend on which direction you're diffusing. And of course, the negative sign in this Fick's first law indicates that the flow is down the concentration gradient. that says the change in the concentration delta C in the time period delta t is just equal to the difference in these two fluxes-- the incoming flux minus the outgoing flux-- divided by the distance, delta x. Mathematically, instead of writing it in terms of these differences, we can write it mathematically as partial derivatives. We can write delta C by delta t as partial C by partial t. So the time rate of change of the concentration isequal to the partial of the flux divided by x. which it's possible to write down or to derive relatively simple analytic solutions to the diffusion equation. In all the other cases and most of the cases we'll end up using in this course, we'll have to do numerical solutions. But for now, let's look at a couple of special cases where we can solve this equation by hand. The first case is pictured on slide 24, which is called the steady state. And what that refers to is that, in fact, we have a profile that is not varying in time, in which case we write partial C partial t. profile of the oxygen through the oxide during thermal oxidation. And again, in that case it's a concentration profile that's not changing with time. So let's go on to slide number 25 and do the first solution of a case that's a little more complicated than that, which is called the limited source case. And we find that the solution that satisfies Fick's second law is written down by this equation. The concentration is a function of x and time can be given by that constant dose Q divided by 2 times the square root of pi Dt times the exponential of minus x squared over 4 Dt. In semiconductor processing, linear scales for dopants are not all that useful. We often care about how the dopant falls off over many, many orders of magnitude of concentration. If we can assume that there's no dopant loss through evaporation or segregation at the surface, then we can essentially solve it by assuming that we have virtual diffusion. So, in fact, if we go on to slide number 27, that same the graph is.see many order of magnitude down below the peak what the broadening actually looks like. shown at the top. Effectively, what this means is that we have a dose of 2Q introduced into a virtual infinite medium by symmetry so that the concentration profile is given, again, just by the same Gaussian we had last time. But instead in that formula wherever we had Q, we replace it with 2Q from the prior solution. So the surface concentration now goes Q over the square root of pi Dt. And so this is what the equation looks like for diffusing with a fixed dose into a surface where we have no loss. the square root of Dt, where the second equation and third gives you the definition of what we mean by the error function. Error function of z is just equal to 2 over the squareroot of pi times the integral from 0 to z of this exponential-- it's integral of a Gaussian, basically. The complementary error function is 1 minus that. And then these error functions and complementary error functions have been tabulated. So in that sense, it can be calculated analytically. In the predeposition case, at the surface of the silicon wafer, the concentration of the dopant is fixed at the solid solubility. The longer you would do the pre-dep, the more dose you would deposit into this silicon surface. Let's go on to slide number 35 and talk a little bit about dopant diffusion coefficients themselves. And we'll talk about some interesting Fermi level effects that come into play as the dopants become modulated by the carrier concentrations of the species. of cases where there are analytic solutions. We talked about the diffusion of a Gaussian profile with a fixed dose. We apply this diffusion to a constant surface concentration. And finally -- we talk about the diffusion of a complementary error function, which we apply for a constant level of surface concentration. The diffusion of this error function can be applied to a fixed level of surface concentration, or a constant level of substance on the surface, for example.

ROUGE-1: 30.56, ROUGE-2: 29.44, ROUGE-L: 29.42
BERTScore: 76.95

==============================================
==================== [15/100] ====================
Summary:
Atas model shows what happens if aggregate demand increases and prices go up. As wages fall firms respond to this by saying we want to make more output. As people demand these higher wages shortening our supply curve decreases. It just takes more green pieces of paper to buy the same goods and services at C as it did at a let's see what happens with a decrease in aggregate demand. It's the same employment falls back to where it is normally unemployment increases back to the natural rate of unemployment. firms are seeing here here they're seeing output prices decline and input prices stay the same. What are they seeing in terms of profits exactly here we're seeing profits actually decrease. What's happening to people's real wages they've gone up alright if input prices are staying the same and output prices are declining real wages are actually increasing. firms respond to that increase in the price of labor by doing the same thing that they do for everything they use less of it right and so we see output begins to decline we see unemployment increase and we see employment decrease. The Keynesian model in this framework its alphabet soup right that's where it's gonna be trust me I've been doing this for 20 years questions on the AAAS wanna yes. The reason that we have these two different models is because we got to this model where you're at this point right here. Eventually whenever whatever it was that caused a short-run aggregate supply curve to decline is done then we'll move back to a right and that will eventually happen it really will it might take a long time. Keynesian model has problems too it doesn't work perfectly either so that's why we have these changes in aggregate demand. We'll get to that when we look at fiscal and monetary policy okay so I will see you guys on Wednesday we only have the exam. We only had the exam we only has the exam so we will be back on Wednesday to talk about fiscal and Monetary Policy. We will be talking about the impact of the stimulus package on the U.S. economy and the global economy.

ROUGE-1: 17.32, ROUGE-2: 15.18, ROUGE-L: 14.86
BERTScore: 66.11

==============================================
==================== [16/100] ====================
Summary:
As a nurse you play an important role in teaching the parents about car seat safety and this education actually starts at birth before the child even goes home from the hospital in their first car ride. In this lecture we're going to concentrate on the main concepts that you need to know as a nurse and for exams first let's talk about the four types of car safety restraints that you can use in a motor vehicle. Whenever you get done watching this youtube video you can access the free quiz that will test you on this content. When selecting a car seat safety restraint you want to educate the parent that they don't want to solely go by the child's age especially whenever it's time to upgrade the restraint. There's some signs that you can tell if your child actually fits in that restraint which we're going to talk about here in a moment plus they want to make sure that they're within those limits set by that car seat manufacturer. It's important to remember that the back seat of the car is actually the safest place for a child 12 and under.

ROUGE-1: 14.30, ROUGE-2: 13.96, ROUGE-L: 13.25
BERTScore: 75.00

==============================================
==================== [17/100] ====================
Summary:
Machine learning is about how to acquire a model from data and experience. In the next few lectures, we're going to work through a sequence of different takes on machine learning that are going to highlight different subsets of the big ideas on this topic. We'll start with model-based classification, and, as an example of that, we'll work through some details of how the Naive Bayes models work. And we'll see more in-depth examples and more structured examples of these kinds of problems later on when we talk about applications. an output. And the whole point is to automate the prediction of the output on the basis of the input. So the input might be an email, and the output is the decision. Is this spam or is this a good email, which people who work on spam call ham. In practice, in the real world, getting the right kind of data is often one of the hardest parts of building and deploying a machine learning system. And we'll see today exactly how data kind of goes through the mill and gets turned into a model. The boundary between what is actually spam, unsolicited commercial email, and emails you just don't want, can be a fuzzy boundary. Machine learning is going to do some amount of work, but something has to power this. There has to be something about those first emails that's going to give you the clues that something's fishy here. And so, what kinds of features can you include? Defining these features is a big part of deploying machine learning systems. For example, maybe any dollar sign followed by some numbers is a bad sign, and that's a feature that abstracts over individual words. Machine learning can be used to make predictions about spam or ham. The training set for machine learning is very noisy, so it can be hard to label. Machine learning is not perfect, and some inputs are just really, really hard, and they're going to look like this and we're just not all even going to agree on what that's supposed to be. The goal is to be able to predict labels of new images that are not the ones we've already seen, OK? So that's actually subtle, but it's super-important. representations that if the thing gets tilted or it's a little bit lighter. We could look at how many connected components of ink there are. What's the aspect ratio? How many loops are there? It's increasingly the case, especially for problems like this, that we feed in low-level features like pixels, and higher level features like edges, tend to get induced increasingly more as our machine learning methods get better at doing that. We'll talk about that in a couple weeks when we talk about narrow nets. In this lecture, we're going to talk about model-based classification. In model- based classification, rather than directly learning from errors that you make in the world from experience, think like reinforcement learning model-free. After today we'll look at the model- free methods. In this case, we'll build a Bayes net called a Naive Bayes model. You build a model where the output label and the input features are random variables. There's going to be some connections between them, and maybe some other variables too. representations be more compact, or because that's data that's easier for you to elicit. What structure should the Bayes net have? Today, we're going to give it the simplest structure that could possibly work, and it turns out it often does. How should we learn the parameters of a model from data once we've decided it's structure? So here's what a Naive Bayes model would look like for digits. It's in fact super-simple as Bayes nets go. The Naive Bayes assumption is an extremely radical assumption as far as probabilistic models go, but for classification, it turns out to be really effective. So if we have a single digit recognition version of this, we might have a feature for each position of the grid. They'll all be binary valued. That means this number one here maps to this feature. But if my features were instead, how much ink because they're on the left side? How many loops are there? Then there would be zeros and ones as well, but they would no longer correspond to the raw image. There's a lot of features. A general Naive Bayes model places a joint distribution over the following variables, y, which is your class, and some number of features, which you get to define. You're going to have to write code which extracts them from your input. So if your spam feature is, have more than 10 people received this email in the past hour? The machine learning will do the work to connect the probability of that taking on a certain value up to the class. And that means when you go to make a prediction, it decomposes into a product of a bunch of different feature conditional probabilities. The Bayes net is a model that assumes all the features are conditionally independent, given the label. For each feature-- which is each kind of evidence-- we're going to need to compute a bunch of conditional probabilities for each class. These things collectively, all these probabilities that we use to plug and chug and get our numbers out, are called the parameters of the model. It's the product. of a prior probability of the class, which says whether or not before you see the evidence, this is a class that's common or not. In a Naive Bayes model, each class 1 to 0 is equally likely. The product of-- across each position in the document, the probability of the word at that position given the class. In real, if I went to like a real collection of data, I could get 1,000 examples of the number 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 68, 70, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 94. to learn is for each class, what is the histogram of words? What is the probability distribution over words in that class? These are tied distributions. This is called a bag of words model, and this is different than the standard case because in the standard cases, each feature gets its own distribution. Here, we assume the features are all identically distributed, but there are multiple copies of that feature for the different positions. And this is nice, because when the document is longer or shorter, you don't really need to change your model. In this example, we're the spam classifier. We're going to produce a joint probability by multiplying in evidence terms as the words come in. In spam, the most likely word is the. Somewhere far down that list is the word free. For ham, it's the too. All right, so far, we think it's ham because the log of that product is higher than the probability of the given word. Gary, remember, this is a generative model, and that means that we have the features that we want to use. It's actually very common when you're multiplying probabilities to just add log probabilities instead. In the end, when you want to turn it into probabilities, you do need to sum them. And summing the logs won't do that. You need to do a sort of log sum, which one way to do that is to convert them back to probabilities by taking exponentials. That's actually not the way you would do it. You would sort of shift them by their minimum or their maximum as appropriate so that you don't get underflow. word depends on the class and also the previous word. This Is a better model of language. If you started, if you did prediction in this, and you cranked out a pretend document, it would look significantly more like a real email than if you just did a bag of words. However, will it be more accurate for classification? It really depends. In general, it will be a little more accurate, but at a cost of having significantly more complicated conditional probabilities to estimate. If I take a spam document, and I permute all the words randomly, Ive definitely, like it is no longer syntactically-valid English. class which is not kind of strongly connected to the actual ordering, Naive Bayes is really good. Otherwise, you add other correlations like this to fix it. OK? Other questions? Good questions. All right. A couple more general slides, and then, we'll take a break. We are now into the machine learning section which means we are done with the spooky Halloween time ghost-busting section. But I have candy. So during the break, everybody get up and come grab candy if you would like. The basic principle of machine learning is something called empirical risk minimization. We would like to find the model, classifier, whatever, that does the best-- whatever the best means-- on our true test distribution. So maybe we would like, get the Naive Bayes spam classifier which is most accurate at finding spam in real people's inboxes today. We don't actually know that true distribution. Like, we don'tactually know what it's going to see at test time, in the same way that when you go to your final exam, you don't know what questions you're going to get. Find the best model on your training set is usually phrased, at some level, as an optimization problem. The main worry is that you over-fit. You can have not enough training data, and there's just no way to have sort of seen the whole space. And then, you can have tons of data drawn from the wrong distribution. The problem might not be with the training set, though, the problem is that the learning over-fits to the trainingSet. We'll see some examples of that even today. for CS189, and then you walk into the CS188 final. You're like, something's wrong here. I understand the concepts, but it's just not lining up. OK, that's a drift in distribution. That's where your training examples were plentiful, but they were drawn from a distribution which does not match the one that you're going to see at test time. This idea of the test distribution sort of being not stationary against the training distribution is something that's really important in the real world. to have a test set, which is not the real future test use that it's going to be put once it's deployed, but you need something that is not in your training data to check. In practice, there's usually other little shards of the data that you're going to want to have. So, for example, one common one is held-out data. We'll see today and in future lectures what that's for. And so we take our data and we break into training, where we learn our parameters, and tests,where we check our accuracy. your training data, and after one or more passes through, you're going to know your parameters. Then you'll-- and you usually select those on the basis of some held-out data. And then finally, once you're ready to see how your experiment turned out, you take that model and you test it on the test data. You don't want to test your classifiers on the data that was used to train them, because they will do surprisingly well. But you as a researcher, are going to be tempted to grab that test data and look at it in great detail and be like, ah, I see. we have held-out data, which gives you something you can peek at. I ran 20 experiments. How did they go? Am I doing well? Is this thing good enough to release? You need to have some metric, and there's a lot of possible metrics. An easy one is accuracy. For how many of these emails did I make the correct decision? Fraction of instances predicted correctly, but actually, that's actually not a great metric for spam detection. Any ideas why? What's wrong with accuracy? different metrics people have for different kinds of tasks. We want a classifier which does well on the test data. And then we try to come up with methods where the training accuracy is going to mean something about the test accuracy. Over-fitting means fitting the training data very closely, but not generalizing well. There's also the opposite, which is under-fitting, where you're just like, I don't know what's going on. That's not over-fit. It's not going to work very well. Spam is being generated by people who are trying to defeat spam filters. Spammers are going to double down on what's working. And so in that sense, over time, spam classification doesn't actually look like a standard classification problem because it's adversarial. In general, we're going to do discrete classification. But for this example, let's imagine that we're looking for language, but then suddenly, you start using methods like primarily looking at sender information. And now you have spammers who want to buy contact information so that they can spoof that. the thing we're trying to do is to fit a curve to this data. So you say, what is the fit? Is the fit getting as close as possible to the last dot? So what is my constant approximation to this? Does anybody want to hazard a guess? Let's call it five. OK, did I fit something about this data? Yeah, I felt something about the data. I fit basically it's mean. Did I capture the major trends? No. All right, let's try again. Let's fit a linear function. It's close, right? It's a better fit than the constant function. than the quadratic. It's about fitting your data to the point where the patterns that you are capturing are ones which generalize to test, and that's a tricky balance. Over-fitting shows up not just on these continuous functions. It also shows up, for example, let's imagine in a hypothetical digit classification, we might say, here is an image I've never seen before. Let's use Naive Bayes to classify it. So what would we do? We'd do our running total. We'd say, all right. Well, before I look at any features, the numbers are the numbers two and three. a 3 than a 2, let's imagine. So, so far, a three is winning. But eventually, I'm going to get to some pixel, maybe like this one here. And in my training data, this is almost never on. This is in a corner where there's no number. And maybe it turns out that this number, that this pixel happened to be on once or twice in the data for the digit two, but zero times in theData for digit three. the ratio is one, it means it's equally likely. Whether it's common or uncommon, it doesn't affect the competition. It's things that are more common in one than the other that have a big impact on these odds ratios. So let's look at words. What do you think, in my training data for ham versus spam, things with the highest odds ratio for ham would be? These are things that're significantly more likely for ham than for spam. It turns out, there are a bunch of words in this data which occur in spam once, and it could occur in once and occurs in spam zero. over-fitting usually shows up as sampling variance. To do better, we need to smooth, or regularize, our estimates. We can use elicitation, right? You can ask a human. You can go to a doctor and say, hey, I'm building a classifier. What fraction of people with meningitis will present with a fever? And a doctor can give you a guess. It may be qualitative. You could also do that empirically. You Could go collect a bunch of records. The maximum likelihood estimate, or relative frequency estimate, is a way to estimate the likelihood of an outcome. The more samples you draw, the more accurate your estimate will be. But in practice, you need some smoothing to make your model more accurate. We want our model to assign probability to events it's never seen, so that one errant pixel or word that is rare doesn't completely torpedo an otherwise very nuanced balancing of evidence. It's basically the same thing, and it almost is, except for one term. This is actually, due to Laplace, hundreds of years ago now, who's a philosopher who kind of worried about things like, well, how do I estimate the probability? Like, what is the probability the sun will rise in the morning? Every morning so far it's risen, so probability one. But I know that can't be right. So I need some way of mechanically incorporating the fact that there are events which I haven't seen, but which I know to be possible, or at least that I'd like to model as being possible. good idea to take into account the probabilities in your observation, but you should hold out an extra observation for everything you didn't see to reflect it potentially happening at some point in the future. So basically, add one to all your counts, including the ones that are zero. So the maximum likelihood estimate for red, red, blue, if I say, what's the probability of red, comma, probability of blue? 2/3, 1/3. Laplace plus would say, instead of saying there's two of one and one of the other, adding one to each. there's 100 blues. Now how many reds do I have? Well, I do my computations as if I had 102 reds and 101 blues. And suddenly, even though there are still more reds than blues, in my posterior estimate here, it's pretty close to 50-50. So as I crank up k, I have a stronger prior, and I fit less. If I crank down k,. I fit more, and so I now I have. a dial which can trade off the amount of fitting against generalization. probably in there somewhere. If you see money, that's a good sign that it's spam. There are some things that indicate ham. This looks like general English text. What is going on there? Helvetica vs. Verdana. This reflects the default fonts that were in use at this time across different platforms. And so one of the things you find in machine learning is, you know what you think the features are going to be, or rather, which features areGoing to be useful. But you might be wrong. In general, your model is going to make errors. We're talking a bit more about this starting next lecture. Here's some examples of errors that the quick Naive Bayes system I whipped up makes on this training set. One was spam that should have been ham, one was ham that should've been spam. These are tricky cases, and it's actually very hard to tell from the words which one's which. And then there's this other one that's also an error, which is, to receive your $30 Amazon promotional certificate, click on this. In spam classification, we found out that it wasn't enough to just look at words, you've got to look at other sort of metadata from the ecosystem. For digit recognition, you do sort of more advanced things than just looking at pixels. Try to do things that are invariant to rotation and scale and all of that the vision folks think about. You can add these as sources of information by just adding variables into your Naive Bayes model, but we'll also talk in the next few classes about ways to add these more flexibly, and also ways to induce these.

ROUGE-1: 37.15, ROUGE-2: 35.73, ROUGE-L: 34.67
BERTScore: 64.03

==============================================
==================== [18/100] ====================
Summary:
in this video we're gonna talk about how a country can gain from exporting goods or services through international trade. We're gonna look at how consumer surplus producer surplus and total surplus are going to change when we introduced the idea of trade in allowing Chile's copper manufacturer producers to trade on the global market. The world price of copper is five thousand four hundred and forty dollars a ton. Because the world price is higher than the price in Chile Chile will export copper. There is a shift of some of the consumer surplus is going to go to the producer surplus.

ROUGE-1: 14.64, ROUGE-2: 13.69, ROUGE-L: 13.40
BERTScore: 67.04

==============================================
==================== [19/100] ====================
Summary:
Thiazide tells us that this medication works in the early part of the distal convoluted tubule that's found within this nephron. This transporter is called the sodium chloride co-transporter and it is considered a cyanide sensitive transporter so hence why this drug works so well. While loop diuretics are a lot more effective than a thiazide diuretic but the thiazid does provide a nice diuresis effect. They're less effective in patients who have a compromised GFR a go merrill ER filtration rate. on digoxin and their potassium level goes too low it can increase the risk of digoxin toxicity. A normal lithium level is about 0.5 to 1.2 millimoles per liter so remember these two drugs if we go into these hypo conditions either hyponatremia or hypokalemia with those it can cause toxicity. No exams love to ask about the hyper conditions that these drugs can cause our hyper hyper Cal C Mia the high calcium level hyperuricemia the high uric acid level and hyperglycemia. bathroom all the time so make sure you're not doing that and orthostatic hypotension this is where the when the patients maybe they've been sitting or lying down they get up they can fall they become dizzy. You want to teach them to change position slowly because we're altering the fluid status in their body. As a nurse you want to make sure that this medication is being effective is it doing its job how do their lungs sound is their blood pressure coming down maybe they're getting this drug for hypertension how is their weights are they gaining weight or losing weight so we play a huge role with that as well okay so that wraps up this review over thighs I diuretics.

ROUGE-1: 15.46, ROUGE-2: 15.01, ROUGE-L: 15.46
BERTScore: 61.65

==============================================
==================== [20/100] ====================
Summary:
CrashCourse U.S. history will be won by - Harry Styles in 2020. Future John Green tells you that in a stunning turn of events, Harry Styles will win the 2020 presidential election. We're going to change the constitution to make it possible. Because… that’s how much we love Harry Styles. The Wall Street Wamboozle, the Financial Fartstorm. The Major Recession of 2008 - 2012. The 2nd worst economic crises in the past 150 years. A mixture of public and private activities that tilted towards short-term economic thinking. many millions of Americans, including certain Crash Course US History hosts, bought real estate assuming that its value would increase rapidly and forever. It turns out this was essentially a pyramid scheme and, my friends, I was not at the top of the pyramid. So back then you could buy a house with a so-called NINJA loan which sadly this did not involve mutant ninja turtles or pizza. Ninja stands for No Income, No Job, and No Assets. All this created a classic housing bubble, which was doomed to burst. When the mortgages turned bad, these securities became toxic assets. When banks stop lending, business can’t function. The stock market collapsed, with the Dow Jones Industrial Average dropping from above 14,000 to around 8,000. By mid-2009 more women than men held paying jobs for the first time in American history. And World Trade cratered and that led to unemployment and misery worldwide. The event that triggered the chaos was the failure of the investment bank Lehman Brothers in September, just 2 months before the presidential election. In 2008 Obama’s election seemed a political watershed and not just because he was the first African American president. He appealed to young people and minorities, and he harnessed the power of social media to communicate with supporters. He appeared to break Republicans’ solid hold on the south, and also raise TONS of money. Also, he was on the cover of US Weekly. You didn’t see Martin Van Buren on the. cover ofUS Weekly. It didn't exist? Of course it existed! Crash Course Literature is a weekly, offbeat look at what's happening in the news. This week we look at Barack Obama's first inaugural address. The winner of the mystery document will be announced at the end of the show. For the rest of the week, we'll be reading from the book of the same name, written by the author of the Mystery Document, if I’m wrong I get shocked. No more shocks. The getting shocked part of my life has come to an end. Hopefully in Crash Course Literature when I get things right I'll get a puppy. And when I got things wrong I'llget a rainbow! He also wanted to end the wars in Iraq and Afghanistan and reverse global warming. A lot of this was more rhetoric than action, as in his verbal support for the revolution that overthrew Hosni Mubarak in Egypt. He did keep some of his campaign promises, for instance he signed into law the Lily Ledbetter Fair Pay Act, which made it easier for women to sue when they had been systemically underpaid. He also appointed two of them to the Supreme Court, Elena Kagan and Sonia Sotomayor. Obama has been criticized internationally for backing off his promise to close the Guantanamo Bay detention camp. But the Obama administration has deployed far more unmanned drones to kill suspected militants around the world. Despite provoking outrage on the left and the right, Americans generally appear to support the use of drones and extra-legal assassination of accused terrorists. Obama was fortunate to have a Democratic Congress for his first term in office, so he could push through a lot of legislation. This included a sweeping stimulus package with nearly $800 Billion in new spending, most of it on infrastructure. The Affordable Care Act is arguably the most significant piece of social legislation since Medicare. Obamacare aims to reduce the number of Americans without health insurance by making it easier and less expensive for the uninsured to buy it privately. In 2012 the core of the law was upheld by the Supreme Court when they ruled that thiants was a constitutional use of the government’s taxing power. Not one Congressional Republican voted for Obamacare, and many used it to campaign against Democrats in the 2010 mid-term elections. The 111th congress was one of the least productive in American history. Unwillingness to compromise precipitated a series of mini-fiscal crises over things like the budget and raising the debt ceiling. Meanwhile, the economy has slowly added jobs and looks halfway decent at the moment mostly because Europe looks so bad. The particular brands of ideological certainty that we see today may seem new but if you look at American history you realize that this has been going on for a long time. The Tea Party is right that the founding fathers would be astonished by the extend of the American government and the extent to which it’s involved in the lives of Americans. We have to ask ourselves again, “What does freedom really mean?’ Can you be free when the government can go to a secret court to read your text messages? We know that you can’t be free if you’re dead, so is the government’S job to protect you not only by having a standing army but also making you wear your seat belt? Crash Course World History has been on the air for two years. The show celebrates two successful years of teaching history. This has been one of the great professional joys of my life and I’m so grateful to everyone that has helped make the show and everyone who has watched it. Thank you again for watching, and as we say in my hometown, “Don’t forget to be awesome.” You can find a full list of your reading for Crash Course Literature in the doobly-doo.rolling.

ROUGE-1: 47.20, ROUGE-2: 43.53, ROUGE-L: 42.65
BERTScore: 68.01

==============================================
==================== [21/100] ====================
Summary:
Simple graphs don't have direction. They just correspond to a mutual connection, which is symmetric. A directed graph might have a self loop, an edge that starts and begins at the-- starts and ends at the same vertices. Those are also disallowed in simple graphs. There's a thing called multi-graphs where there are multiple edges between vertices and there could also be self loops, but we don't need those. Let's not complicate matters. We're talking about simple graphs, not directed graphs. A basic concept in graph theory, which is what we're going to make a little bit of in this video segment, is the idea of the degree of a vertex. The degree is simply the number of incident edges, the number. of edges, that touch it. So let's examine some properties of vertex degrees that are motivated by a simple example. Let's see what it looks like. If I'm going to have a graph with vertices of 2, 2, and 1, implicitly it's a 3 vertices graph. to have a vertex of degree 1, then I know what it looks like. There can't be a degree 3 graph with this spectrum of degrees 2, 2, 1. It's impossible. Well, we could have reasoned more generally. And there's a very elementary property of degrees that we're going to actually make something of in a minute. It says that the sum of the degrees summed over all the vertices is equal to twice the number of edges. So that's the cardinality symbol. Absolute value of a set means the size of the set. vertex gets numerated twice. So the sum is twice the number of vertices. And by the way, since 2 plus 2 plus 1 is odd, we could have without that ad hoc analysis figured out that the sum of the degrees can't be odd, because it's twice something. All right, so here's the applications designed to get your attention. It is an application of graph theory to sex. And we ask the question, are men more promiscuous than women? And there have been repeated studies that are cited in the notes that show again and again that when they survey collections of men and women and ask them how many sexual partners they have. to model the relationships between men and women by having a graph that comes in two parts. It's going to be called a so-called bipartite graph. So looking back at this graph, this edge from that blue M to that orange F indicates that they had a sexual liaison. They were partners. And what we've just figured out then is that there's a fixed relationship between the average number of partners of men, the average degree of the M vertices. And these two average degree, these average numbers of partners, is simply related by the ratio of the populations. 3 and 1/2 percent more partners than women per man. But this has nothing to do with their behavior, or promiscuity, or lack of it. It's simply a reflection of the ratio of the populations. One explanation would be that men exaggerate their number of partners. But the truth is that nobody knows exactly why we get these consistently false numbers. But we do get them consistently in one survey after another. You will no longer be fooled by such nonsense. It is time to stop this nonsense.

ROUGE-1: 45.45, ROUGE-2: 43.47, ROUGE-L: 43.90
BERTScore: 67.16

==============================================
==================== [22/100] ====================
Summary:
Robotics is a really cool and important direction for the future. We are moving towards a world where so many routine tasks are taken off your plate. I really believe that in the future we will have AI assistance whether they are embodied or not to act as our guardian angels to ensure that we maximize and optimize our lives to live well and work effectively. And so today we can say that with AI we we will see such a wide breadth of applications for instance these technologies have the potential to reduce and eliminate car accidents. The future is really enabled by three interconnected fields and on one hand we have robots now robots I like to think of robots as as the machines that put computing in motion. We have artificial intelligence which enables machines to see to hear and to communicate and to make decisions like humans and then we have machine learning. In the context of robots we have three types of learning and you have seen different aspects of these methodologies throughout the course we have supervised learning, unsupervised learning and reinforcement learning. all objects on roads including Ducks cars people is really critical uh for autonomous driving and um so how does this work well let me let me give you a high level view of how a robot car can actually recognize the scene. In order to in order to use deep learning for the perception task of robots we use data this is manually labeled data that gets fed into a convolutional neural network and then the labels are used to classify what the data is so for instance for this image we may have classifications like car duck Road and we do this so that when the system when the car sees a new image the car could say oh this is a this is ducks on road now. kinds of extreme errors um or um the way um we we denote them Corner cases that we need to pay attention to when we train machine learning for safety critical applications like driving. MIT researchers led by George Tannenbaum and Boris Katz did an experiment a few years ago where they took regular objects and they put them in a different context. With this significant change in context the performance of the top performing imagenet algorithms dropped by as much as 40 to 50 percent. So keep this in mind as you think about deploying or building and deploying deep neural network Solutions. The images that get fed from the camera streams of cars are fed to the decision-making engine of the car. With all small perturbations you can turn the stop sign into a yield sign and you can imagine what kind of chaos this would create on a on a physical Road. Machine learning is very powerful for building perception systems for robots but as we employ machine learning in the context of robots it's important to keep in mind the scope when they work and when they don't work. agents ought to take action in an environment in order to maximize the notion of a cumulative reward and so um reinforcement learning is really about learning to act. This differs from supervised learning and not needing a labeled input or in not needing labeled input output pairs so in this example the agent has to learn to avoid fire and it's very simple it gets a negative reward if it goes to Fire and a positive reward when it gets to water and that's essentially what what what this approach is like you do trial and error and and eventually the positive rewards dominate the negative rewards. years ago and so these techniques that did not do so well back then all of a sudden are creating extraordinary possibilities and capabilities in our agents now this is a simple simulation in order to get the simulation to drive a real robot we actually need to think about the Dynamics of the robot and so in other words we have to take into account what the vehicle looks like what are its kinematics what are Its Dynamics and so here is a vehicle that is running the policy learned in simulation so it's really cool because really we are able to train in simulation. In 1995 a Carnegie Mellon project called nav lab built a car that was driven by a machine learning engine called Alvin and Alvin drove this car all the way from Washington DC to Los Angeles. The car was in autonomous mode for a large part of the highway driving but there was always a student there right ready to um to take control and the car did not did not drive inonomous mode when there were when it was raining or when there was a lot of congestion or when the car had to had to take exits. In 1986 German engineer Ernst Dickman started thinking about how he could turn his van into an autonomous vehicle. Dickman put computers and cameras on the van and began running tests on an empty section of the German Autobahn. computers needed about 10 minutes to analyze an image and they assumed that there were no obstacles in the world which made the problem much easier because all the car had to do was to stay on on the road so they developed some very fast solutions for paring down the image to only the the aspects that they needed to look at. It's really super interesting to think about how visual processing improved from one frame per 10 minutes to 100 frames per second and this has been a game changer for autonomous cars. The other thing that happened in autonomous driving was that the lidar sensors decreased the uncertainty and increased safety and today we have many companies and groups that are deploying self-driving cars. It's really exciting um okay now when we think about autonomous driving there are several key parameters that emerge as we Think about what the capabilities are. of these systems are one one question how complex is the environment where the car t Road like in the German case then the problem is much easier then we have to ask ourselves how how complex are the interactions between the car and the environment. We have very effective and Deployable solutions for robot cars that move safely in Easy environments where there aren't many static nor moving obstacles and you can you can see from this example this is this is an example of the MIT car and it'sYou can see this this car operating autonomously without any issues at Fort Devens. Many companies and research teams are deploying and developing self-driving cars and many of them follow a very simple solution which you can adopt and turn your car into a self- driving car. Here's what you have to do you take your car you extend it to drive by wires so that your computer can talk to um to the steering and the acceleration the throttle controls. Then you'll further extend this car with sensors and most of the sensors we use are cameras and lidars and then there are Suite of software models modules. computational units that you have to make you. There are so many works that address each of these subtasks that are involved in autonomous navigation. Alexander's PhD thesis his idea was to utilize a large data set to learn a representation of what humans did in similar situations and develop autonomous driving solutions that drive more like humans than than the traditional pipeline which is much more roboticy if you if so um so then the question is. If you if you don't if you do then the car is not going to work. how can we use machine learning to go directly from sensors to actuation in other words can we compress all the stuff in the middle and use learning to connect directly perception and action so the solutions that we employed build on things we have already talked about we can use deep learning and reinforcement learning to take us from from images of ofroads onto steering and and throttle onto what to do so this is really great because you can train on certain kinds of Roads and and you can then take your vehicle and put the vehicle in completely different driving environments and driving situations and you don't need new parameters. Alexander developed the Vista simulator. The Vista simulator can model multiple agents. It can simulate different physical sensing modalities that means including 2D cameras 3D lidar event cameras and and so forth. It's from this data we can learn to maximize the likelihood of particular control signals for particular situations. The solution also allows us to to localize the the vehicle so it's really super exciting okay so we can we can get this human-like control but assuming light control requires a lot of data. happens in the existing simulators in the state of the art so the Top Line shows crash locations in red and the bottom line shows mean trajectory variation in color. Here's the vehicle that is executing the learning based control and here's Alexander with his vehicle that was trained using data from Urban driving and now he's driving to the soccer field and you can see that he he's able to drive to to get this car to drive him without doing any training without ever having seen this road and explicitly providing data about this road. Liquid networks are Dynamic causal models and I want to show you some examples of how these models explain task of inside a wooded environment. Ramin introduced liquid networks and introduced neural circuit policies and so I just want to drill down a little bit more into this area because you can now compare you cannot understand how the the original engine worked and you can compare that against what we get from liquid Networks. The attention map is so much cleaner right the vehicle is looking at the road Horizon and at the sides of the road which is what we all do when we drive a vehicle. standard deep neural network and we have asked this network to solve this problem and the attention map of the network is really all over the place you can see that the network the the Deep neural network solution is very confused but check out something else the data that we collected was summertime data and now it's fall so the background is no longer green we have we don't have as many leaves on trees and so the context for this task has completely changed by comparison the the liquid network is able to focus on the task and is not confused. This kind of this kind of ability to transfer from one set of training data to completely different environments is truly transformational for the capabilities of machine learning. that yields models that generalize to unseen scenarios essentially addressing a challenge with today's neural networks that do not generalize well to unseen test scenarios because the models are so fast and and compact you can train them online. We in in our lab here at C cell we have one project that is looking at whether we can understand the lives of whales and so what do I mean by this so here is an example where we have used a robotic drone to find whales and look at what they do and track them. and mysterious creatures and so if we can use our Technologies to get better insights into their lives we will be able to to understand more about about other animals and other other creatures we share this beautiful planet with so we can study these whales from above from the air we can also study the whales from from within from from inside the uh the Ocean and here's a here's Sophie our soft robotic fish um which Joseph who is with us today has participated in in building and here is this beautiful beautiful very natural moving robot that can get close to aquatic creatures. friends and we would like to know what it's saying we have no idea but we can use machine learning to make progress. We are trying to understand the phonetics the semantics and the syntax and the discourse for whales. We have a big data set consisting of about 22 000 clicks uh the clicks get grouped into codas the codas are like the phonemes and using machine learning we can identify coded types. We can identify patterns for Coda exchanges and we can we can begin to really ask ourselves how is it that that that Wales Wales. There is so much opportunity for developing improved machine learning using existing models and inventing new models. If we can do this we can create an exciting work world where machines will really Empower us will really augment us and and enhance us in our cognitive abilities and in our physical abilities. If you're interested in this problem please come see us because we have a lot of projects that are very very exciting and important towards reverse engineering what this really extraordinary and majestic animal is capable of doing so let me close by saying that in this class you have looked at a number of really exciting machine learning algorithms. your dimensions and can create a bespoke shoe just for you and then all the all the clothing all the items in our environment can kind of awaken our clothing could become robots. Just-in-time Holograms could be used to make the virtual world much more much more realistic much more connected and so here they're discussing the the design of a new flying car and let's say we have these flying cars and then we can integrate these cars with the it infrastructure and the cars will know your needs so that they can tell you. the kind of future that machine learning artificial intelligence and robots are enabling. I'm personally very excited about this future with robots helping us with cognitive and physical work. This future is really dependent on very important new advancements that will come from all of you and so I'm so excited to see what you'll be doing in the next years in the years ahead so thank you very much and uh come come work with us. "Thank you verymuch and uhcome come work for us," he said.

ROUGE-1: 43.36, ROUGE-2: 41.82, ROUGE-L: 40.83
BERTScore: 67.31

==============================================
==================== [23/100] ====================
Summary:
Tatiana and her team eagerly learned a few of the new recipes last night. Chef Ramsey is ready to unveil an entirely revamped menu. "I just can't wait to get to work and prove to my mom and my sister that I can do this," said Tatiana. "The message is clear nobody scared to walk through that door and get their hands dirty in that kitchen," said Chef Ramsey. "Tomorrow is a big day let me tell you I need everyone on their game," he said. Danielle: "I am thrilled this is amazing this is like the menu of my dream" "I know I'm excited for the new menu I mean it's beautiful it's delicious cheff ramsy" "If the restaurant goes your hous is going go wow um and how much money did you put in um probably like 1,000 bucks" "We have a massive asset there in that pizza Cen and we're going to take advantage of that yeah dig in let's go oh my gosh this is so beautiful m"

ROUGE-1: 46.22, ROUGE-2: 42.88, ROUGE-L: 32.14
BERTScore: 61.58

==============================================
==================== [24/100] ====================
Summary:
HONG LIU: This is a key relation between the bulk and the boundary theories. The more you go to the interior of the space time, then corresponding to the lower energy process when viewed form the field theory. This actual dimension can be considered as a geometrization of the energy scale. It's called the normalization group flow, how physics evolves when you change the energy or length scale. So you can also view that the evolution in the gravity side, in the field theories. say from the boundary to the interior, and that this flow in the z direction can be considered, again, to geometrize the normalization group flow of the field theory. So now let's talk about some further aspects of the duality. The duality is that once you realize there's such relation, since the two sides are completely different objects, so the game is that you really have to do lots of guess work. Essentially, you have two sides if you want to relate things on two sides. How does this quantity translate into that quantity? And then check the consistency. together, you have eight [INAUDIBLE] four-dimensional supercharges. But the interesting thing is that by definition, the supersymmetry on the gravity side is actually local. So you actually have the same amount of local supersymmetries. So if you look at this correspondence between each other, then you actually see a pattern. So now let me make some remarks. On this side, all these symmetries are global. But on the field theory side, the global symmetry is mapped on thegravity side into the local symmetrie. For each global symmetry in the field theory side, there's a corresponding local symmetry on the gravity side. The isometry is important for the following reason. Even though this is a subgroup, when we talk about quantum gravity, the AdS5 times S5 specifies the asymptotic geometry of the space time. So-called large transformations is that they don't go to the Identity at infinity. These large gauge transformations can be considered as the global part of the diffeomorphism. The gauge symmetry is just redundant freedom. You never see it on the other side. translate into the flux. So the flux N. And then here is corresponding to you have SU(N). So this R, this curvature radius is related to the alpha prime squared and the gs. And so on this side, the dimension parameter is given by R squared divided by alpha prime. From this relation, 4 pi GS is equal just to G Yang-Mills square. And the N is N. This is the relation between the parameters. So on the gravity side, we said these are the two parameters. And of course, you also have this N. expanding 1 over N squared. So as we said before, we often do dimensional reduction on S5. Let me get a five dimensional Newton constant. And the difference is the volume of S5, which is equal to pi cubed R to the power fifth. And then from here, you can just work out. G5 has dimension 3. Then G5 divided by R cubed, again only related to N given by pi divided by 2N squared. And here, when I write these relations, I have all set h bar equal to 1. The classical gravity limit is the same as QFT, Quantum Field Theory in curved space time. So gravity does not fluctuate. But your matter field can fluctuate, h bar equal to 1. In type IIB super gravity, there are many, many such kind of matter fields, and they all should be treated quantum mechanically. Just don't treat the gravity as quantum, but those matter fields should be treating as quantum. And now, we see that the decoupling of the string effect requires on the field. theory side the strong coupling. This is also something roughly we said before. The strong coupling, then the diagram with many, many vertices will dominate. And then the most dominated diagrams are those diagrams with not a lot of vertices. And they essentially are going to continue to limits. So that means that we can actually use classical gravity to, in principle, solve problems which are strongly coupled. So also, of course, there are corrections beyond this. So this is a classical gravity limit on this side. HONG LIU: In principle, the corrections beyond this limit can again be studied on the gravity side. In the classical string limit, still you can see the N go to infinity, which corresponds to GN. But here, the alpha prime can be arbitrary. And here the [INAUDIBLE] coupling can be arbitrarily. So let me just say alpha prime finite no longer zero. And then this is just corresponding to Lambda finite, which is no longer infinite. So this is a standard t Hooft limit. a general correspondence between some conformal field theory and some AdS gravity theory. HONG LIU: Yang-Mills theory lives on Minkowski space. And then you say you can imagine that this is the boundary, this relation is related to the bulk and the boundary. And this is a postulate based on that fact. AUDIENCE: So if it's a sort of postulate that's just thinking about it, it's not required that the theory live on the boundary of AdS. HONG LIU: In the representation line, so if you have the massless [INAUDIBLE] field on the right, what does it map to on the left? We are going to talk about it. So if there are other symmetries, then everything should match. So now, as an immediate check, you can now just open your old papers. And if you load them, you will immediately see they actually map to certain representation of operators on the N equal to 4 super Yang-Mills theory. Then you can immediately check them. a few minutes. So now, given this mapping, any operator is due to a bulk field. Then you can ask some immediate questions. For example, the quantum numbers of these operators will map to the quantum number of the bulk fields. And that's something I said you can check their symmetries. So for local operator on the field theory side, so once we have this mapping we can immediately ask questions related to operators on this side, and try to ask what's the counterpart on the other side. And ask the story about the field on the gravity side. When phi 0 is equal to constant, then this corresponding to a change in the coupling for this operator. So if your Lagrangian previously already included this operator, and then if you add such a term, then you are just changing the coupling. And if this operator is not there, thenyou just add the new coupling. But in general, you can make it space time dependent. And the immediate question is, what does this operation-- so in the field theory point of view,you can always do this operation. guesswork is based on some very small clues. Good physicists do is that they can see non-ordinary things from ordinary things. So here, I will try to deduce the answer to this question by starting from this relation. Related to the GS. GS string coupling can be considered as the expectation value of the dilaton field. Let me actually call it capital Phi. In principle, phi in principle can fluctuate. And its expectation may also be. And so this is the value of AdS, value of phi at the boundary. able to fluctuate in the space time. But the only sensible way to talk about expectation value is to. talk about its value at the boundary because we assume the boundary conditions don't fluctuate. And in the AdS, which is also space time with a boundary, than we can associate the constant parts of the expectation value as the value at. the boundary. This is the coupling or source for the Lagrangian of N equals to 4 super Yang-Mills theory. And this corresponding to you essentially change the boundary value of dilaton. phi 0 O in the boundary theory must be related-- now I'm generalizing this story. The bulk field phi due to O has a boundary value phi 0. In principle, you can choose any O. You can break the symmetry if you want. Impose this kind of boundary conditions. Then you may break AdS symmetry too. So in the end, what we will describe is a self consistent story. I will not contradict myself in my later discussion. So if we assume this, I can also use this to argue. N equals 4 super Yang-Mills theory and this type IIB gravity. Any conserved curve in the boundary theory must be equal to some gauge field in the gravity side, and the stress tensor should always be due to the metric. I can use this identification to make star and star star natural for any duality. So this does not prove it, but makes it more natural. The fact that the boundary value of A has such kind of gauge symmetry. So in some sense, this must generalize to some Gauge symmetry in the full gravity side. The mass corresponding to the boundary value of the metric in the gravity side for the following reason. When we consider the information, we always consider the source is small. But now, we can argue this thing, mass corresponds to the boundaries of the AdS metric. So this tells you that the stress tensor must be due to the metric perturbations in thegravity side. So, this is a very general statement valid for any correspondence between the gravity. and the bulk. metric. and the field theory. And that also tells you that if you have a theory which due into a higher dimensional theory, and then that theory has a stress tensor, then this bulk theory must have gravity. So you can say, if any field theory is due to a theory of one higher dimension, that theory must involve gravity-- nothing about quantum gravity. Let's stop here. We're not going to get into quantum gravity right now, we're just going to talk about the theory of gravity.

ROUGE-1: 32.92, ROUGE-2: 31.50, ROUGE-L: 31.44
BERTScore: 73.40

==============================================
==================== [25/100] ====================
Summary:
Bolek Wyslouch: How do you convert a given physical system with all the forces, et cetera, into some sort of fixed form, fixed type of notation? Bolek: Once we understand two, we will then generalize to infinite number of oscillators, which is actually-- so this model, which consists of weights hanging under the influence of gravity plus the springs will be then used for many applications of the concepts later in this course. MIT OpenCourseWare offers free, online courses. Everything is in Earth's gravitational field, g. We assume that this is an ideal system, highly idealized. We only consider motion with small angle approximation, only small displacement. There's no drag force assumed. Of course, this thing here is very far from being ideal, but hopefully basic behaviors are similar. It's approximately ideal. To study the motion of this thing, to understand how it works, let's try to parameterize it, and displace it from equilibrium, and look at the forces. is-- if it's displaced from a vertical position. Let's say this mass, mass 1, has moved by some distance away from thing Temporarily, let's introduce an angle here to characterize this displacement from vertical. And let's write down all the forces acting on this - force diagram acting on the mass. So there is a tension in the string or the rod. There is a force of spring acting in a horizontal direction. And there is an effect of gravity acting in the vertical direction. for mass 1 in our coupled system. And I could say most of the terms have to do with a motion of mass 1 itself. Mass 1 is its own pendulum. And mass 1 is feeling the effect of the spring force. But because the force of theSpring depends on the difference between positions, there is this coupling. So the motion ofMass 1 knows of where mass 2 is. And motion ofmass 2 influences the motionof mass 1. That's how the coupling shows up. there. This is a two by two matrix. And then we need a third matrix, mass matrix, which simply says that masses are mass of first object is m and the other one is also m, right? So these are three matrices that basically contains exactly the same information as out there. I probably need another matrix. I need an inverse matrix for mass, which basically is 1 over m, 1 overm, 0 and 0. OK, and it turns out that after I introduced these matrices, this set of equations can be written simply as X. But hold on. OK, all kinds of complex numbers can write, but any particular-- AUDIENCE: [INAUDIBLE] BOLESLAW WYSLOUCH: That's the physics answer, all right? Complex notation is a mathematical answer, how to solve a mathematical equation. The physics answer is to find fixed frequency modes us such that the system, the complete system, oscillates at one frequency. Everybody moves together. This is so-called normal mode. It turns out that every of the system will have a certain number of frequencies. Real-world examples of how to find the oscillating frequency of a system. The system has been built. The only variable which we have to change is the spring constant and the mass this affects is given. We need to find a parameter which sets this to 0, and then I can put the two identical terms so I can solve this equation. So this is the equation which we need to solve to obtain the solutions to at least one normal mode. We expect that there will be two normal modes, because we have two masses. is basically equivalent to the following equation g over l plus k over m minus omega squared must be equal either to plus or minus. Right? I took a square root of both sides. There are two solutions which corresponds to plus here. The other one corresponds to minus here. So there is one solution, one oscillation, that does not depend on the spring constant. And this is interesting. This is a frequency. It does not depends on the strength of the spring. How is it possible? Somehow spring is irrelevant for this motion. their own natural frequency. So the force of spring is irrelevant. This is a normal mode. And it can go forever at this particular frequency. OK? The other option is usually symmetrically. I move them away from each other. And this is the motion where, again, it's not exactly ideal small angle oscillation, but let me try again, I guess with less. All right, so that's the first step in understanding the system. We now know that there are two oscillations and two normal frequencies. The question is what sort of thing can you put here to get 0. What kind of vector you can plug into those two places such that the matrix times vector will end up with 0? One example is that basically amplitude is the same. Both of them move together. So you plug 1 here and 1 here. Right? So this is a good solution. And every other solution is a linear multiplication of this one for this frequency. There is k over m times 1 minus k overm gives you 0. minus k over m. OK? And then again, for this second possible normal frequency, I have to find the vector A, which corresponds to that frequency motion. And it turns out that they are the same, but the sign changes. So one possible solution is 1 and minus 1. If I plug in 1 minus 1, then this matrix times the vector gives you automatically 0. All right? So this is a systematic way to solve equations. You plug in all the information you know about the system into a two by two matrix. And then you calculate the normal mode. In general, the shape always has to be simple. They either go together, or they go opposite. So the omega 1 and omega 2 are fixed given by the construction of the two coupled oscillators. This shape, 1 and 1, and 1 minus 1 is fixed, because these are the shape of normal modes, which corresponds to those frequencies. And the superposition of x1 plus x2 gives you the most general combination of possible motion. So if I write this down now in terms of position of number 1 and number 2, so I have a position of X1 as a function of time. arbitrary mode-- this is the most general motion of the two coupled oscillator systems. To describe it in specifically-- defined for a specific configuration, you will have to determine the values of alphas and phis. So what you see here is the following-- you have the green is the normal mode, number 1. They are all stationary. This one is at position 0. This is not the ideal decoupled oscillator, right? OK, and then you see the things start moving. The magenta is normal mode number 2. And blue and the red are the actual pendula. And the motion of blue and red is simply a linear sum of the two. And this is exactly what-- this is the computer simulation that shows you that one of them is going up, the other one down, et cetera. But whatever happens, I would be able to-- it will always be a combination of thetwo motions. Now, is there a way to disable one of the normal modes? do it in my program? I don't know. I can, for example, set one of the initial conditions to-- this is still running. The old one is stillrunning. So what I did is I just changed the initial condition. And you see, this is the type of motion where one of. the modes has stopped, just you switched it off, and the other. one is going on, and then, of course, the total motion is equal to that. And both of them happily go with a constant amplitude. could put it with me some spaceship, and go to a place where the gravity is different, right? Why not? So what would happen? So if gravity changes, then basically what will happen is both this term and that term will change. So what do you think will happen when we go to Jupiter? Jupiter, g, is much larger. So the frequency would be larger. Things will be faster. And what happens when the difference in frequency is smaller? You saw that there's the fact that the energy was moving from one to the other. BoleslAW WYSLOUCH: The exact shape, the exact motion, we know that can always be decomposed into simple motions. If you put them together, things may get really interesting and complicated, depending on what sort of frequencies we are running, he says. "Beat phenomenon" is a study of how two objects' motion can be extracted for those with different frequencies. " Beat phenomenon" was first published in the Proceedings of the Royal Society of London in 1903. equations. Let's look at these equations here. This is mass 1 and mass 2. So I can rewrite those solutions a little bit different. And what you get is x1-- x1 of t is equal to minus x0 sine of omega 1 plus omega 2 divided by 2 times sine omega 1 minus omega 2 divide by t. So again, we did zero physics here. We just rewrote the simple trigonometric equations. But there is-- we have those two frequencies which are playing a role. 2 is like omega, right? 100 plus 105 divided by 2 is about 100. Whereas this one here carries information about the difference of frequencies-- 100, 102, the difference is 2, which is very small. So we have-- so this term here-- it basically oscillates at the frequency of omega. And the other term is much, much smaller. How does this look? Well, it turns out that if you make a sketch of this, if you do signs, it looks like this. Two speakers go on very, very similar frequencies, all right? So they both work at similar frequencies. And so when I switched on, you should hear-- hear the sound. So if you have two, and I can adjust the frequency, and the frequency is close, then this frequency of changing is very slow. So you can actually hear it. So this is the effect of beats. I can maybe show you another simulation of this works. Let's see what it is. OK, so this is just a single frequency. BOLESLAW WYSLOUCH: I don't have to go to Jupiter to modify it, because this one is just a little mass here, right? [TONE] Ah, cool. AUDIENCE: Should both of those sine and cosines have Ts in their arguments? BOLesLAW: Of course always. They are both time dependent, yeah. This is the fast thing, and this is this time-dependent modulation. All right, so where are my notes? So this is the-- this is how the-- so we were able to set up the system. simply x1 plus x2, and I define u2, which is x1 minus x2. So instead of talking about x1 and x2 independently, I have a sum of them and difference. So if I add and subtract the two original equations of motion, which I don't know if I have them somewhere, and you can look back, then you end up having those crossed terms drop out. And you have one, which has only this coefficient, the other one which has that coefficient. The determinants needed no matrices, no nothing. We just added and subtracted the two equations, and things magically separated. So you can always have a linear combination of parameters for arbitrary size coupled oscillators system where you combine different coordinates, and you basically force the system to behave in a way in which it induces the single oscillation, single frequency. So this is, again, a very powerful trick, but usually for most cases, you can do that only after you have solved it, after you've found out normal modes, et cetera.

ROUGE-1: 33.37, ROUGE-2: 31.96, ROUGE-L: 32.07
BERTScore: 60.77

==============================================
==================== [26/100] ====================
Summary:
GILBERT STRANG: The heat equation is the second of the three basic partial differential equations. He says the dependence on t is fast decay, and if K, as K gets larger, later terms in this sum, the decay is really fast. Strang: The term that decays most slowly, k equal 1, there'll be a B1, an e to the minus, pi squared t. The heat is flowing around in the bar, and where is it going? The bar is approaching freezing. ends are kept at freezing, and the inside of the bar, whatever heat is there at the beginning, is going to flow out the ends. So I have an ordinary heated bar, and I put it in the freezer. I insulate the sides so the heat is escaping out the two ends, out the end x equals 0. And the solution will be, let me remember what the general solution looked like. And from that, I find the Bk's, and then the final solution. T greater than 0 uses those Bks. And we're again faced with a Fourier series problem. differential equation. We have a whole function to match, so we need all of those. And Fourier series tells us how to do that matching, how to find these Bk's. So that's a separate and important question, Fourierseries. Thank you for your time. Back to Mail Online home. Back To the page you came from. Back into the article you came From. The story behind the story: Click here to read the full transcript of this article. Back onto the page of the story you come from.

ROUGE-1: 31.71, ROUGE-2: 28.02, ROUGE-L: 28.37
BERTScore: 59.25

==============================================
==================== [27/100] ====================
Summary:
James Swan: I hope everybody saw the correction to a typo in homework 1 that was posted on Stellar last night and sent out to you. The TAs gave a hint that would have let you solve the problem as written. But that's more difficult than what we had intended for you guys. So maybe you'll see the distinction between those things and understand why one version of the problem is much easier than another. So we've got two lectures left discussing linear algebra before we move on to other topics. We ran out of time a little bit at the end of lecture on Wednesday. There were a lot of good questions that came up during class. We saw that reordering is important. In fact, it's essential for solving certain problems via Gaussian elimination. If you don't, well-- my PC had-- I don't know-- like, 192 gigabytes of RAM. The elimination on that matrix will fill the memory of that PC up in 20 minutes. And you'll have to reorder in order to minimize fill-in. be stuck. It won't proceed after that. So it's the difference between getting a solution and writing a publication about the research problem you're interested in and not. So how do you do reordering? Well, we use a process called permutation. There's a certain class of matrix called a permutation matrix that can swap rows or columns. So if I want to swap columns, I multiply my matrix from the right, IP transpose. If I swap the rows and then I swap them back, I get back what I had before. This is a form of preconditioning. We discussed sparse matrices and a little bit about reordering and now permutation. There are lots of variants on Gaussian elimination that we can utilize. There's a sparse matrix that describes how the probability of finding the Plinko chip in a certain cell evolves from level to level. It works the same way the cellular automata do. It's always done via Gaussian Elimination if we want an exact solution. But you don't do elimination on an entire full matrix. You do it on a sparse Matrix whose structure you understand. model I showed you last time works. If the chip is in a particular cell, then at the next level, there's a 50/50 chance that I'll go to the left or I'll going to the right. And there's some sparse matrix A which spreads that probability out. And we'll see the simulation that tells us how probable it is to find the Plinko chip. Yes? AUDIENCE: [INAUDIBLE] JAMES W. SWAN: Yeah. So in diffusion in general? Eigenvectors of a matrix are special vectors that are stretched on multiplication by the matrix. So they're transformed. But they're only transformed into a stretched form of whatever they were before. For a real N-by-N matrix, there will be eigenvector and eigenvalues, which are the amount of stretch. And finding the eigenvalue of a complex number is the subject of today's lecture. The lecture will be on the topic of complex numbers, or complex matrices, and how they relate to each other. eigenvectors and eigenvalues are non-linear because they depend on both the value and the vector, the product of the two, for N plus 1 unknowns. We can never say what an eigen vector is uniquely. We just care about its direction. The amount of stretch, however, is unique. It's associated with that direction. And you have a direction. That describes the eigenvector-eigenvalue pair. Let's go with this idea that w belongs to the null space of A minus Lambda I. do an example. Here's a matrix, minus 2, 1, 3. And it's 0's everywhere else. Can you work out the eigenvalues of this matrix? Let's take 90 seconds. You can work with your neighbors. See if you can figure out that matrix. Nobody's collaborating today. I'm going to do it myself. OK. What are you finding? Anyone want to guess what are the eigevalues? AUDIENCE: [INAUDIBLE] JAMES W. SWAN: It's OK. roots of the secular characteristic polynomial. They are the eigenvalues. It turns out the diagonal elements of a triangular matrix are eigen values, too. If there is a complex eigenvalue, then necessarily its complex conjugate is also an eigen value. So the determinant of a matrix is the product of the eigenevalues and the trace of the matrix, which is the sum of its diagonal elements. We'll come back to that idea in a second. a matrix is also the sum of the eigenvalues. These can sometimes come in handy-- not often, but sometimes. Here's an example I talked about before-- so a series of chemical reactions. We want to know how the concentrations of A, B, C, and D vary as a function of time. And our conservation equation for material is here. This is a rate matrix. The eigen values of that matrix are going to tell us something about how different rate processes evolve in time. eigenvalues of the rate matrix? AUDIENCE: 0. JAMES W. SWAN: 0's an eigenvalue. Lambda equals 0 is a solution. Minus k1 is another solution. What is this eigen Value 0 correspond to? What's that? What physical process does that represent? It's something evolving in time now, right? So that's the transformation of A into B. And the eigenvector should reflect that transformation. We'll see what those eigenvectors are in a minute. We want to know the eigenvector of the rate matrix having eigenvalue 0. This should correspond to the steady state solution of our ordinary differential equation. Can you do that? Can you find this eigen vector? Try it out with your neighbor. See if you can do it. And then we'll compare results. Are you guys able to do this? Sort of, maybe? Here's the answer, or an answer, for the eigenector. It's not unique, right? It's got some constant out in front of it. James Swan: Can you find the eigenvalues and some linearly independent eigenvectors of this matrix? And if you find them, what are the algebraic and geometric multiplicity? Well, you guys must had a rough week, you're usually much more talkative and energetic than this. JAMES W. SWAN: OK. Can you give me eigenavectors of the matrix? Can you Give me linearlyindependent-- yeah? AUDIENCE: [INAUDIBLE] JAMESW. SWan: Good. So this is a very ambiguous sort of problem or question, right? The problem of finding the eigenvectors is as hard as the problem of solving a system of equations. We want to be able to do a type of transformation called an eigendecomposition. It's useful for solving systems of equations or for transforming systems of ordinary differential equations. The Lanczos algorithm is a method that takes products of your matrix with certain vectors and from those products, infer what eigenvalues are. That's the way a computer's going to be going to do it. W lambda W inverse-- and I define a new unknown y instead of x, then I can diagonalize that system of equations. Each of them satisfies their own ordinary differential equation that's not coupled to any of the others, right? And it has a simple first-order rate constant, which is the eigenvalue associated with that particular eigendirection. So this system of ODEs is decoupled. And it's easy to solve. It's an exponential. And that can be quite handy when we're looking at different sorts of chemical rate processes. triangular form for this matrix. We'll talk next time about the singular value decomposition, which is another sort of transformation one can do when we don't have these complete sets of eigenvectors. You'll get a chance to practice these things on your next two homework assignments, actually. So it'll come up in a couple of different circumstances. I would really encourage you to try to solve some of these example problems that were in here. Solving by hand can be useful.

ROUGE-1: 30.13, ROUGE-2: 28.15, ROUGE-L: 27.21
BERTScore: 63.14

==============================================
==================== [28/100] ====================
Summary:
A random variable is a number that's produced by a random process. Number of faulty pixels in a monitor is also produced from an unpredictable randomness. The number of alpha particles that are detected by a Geiger counter in a second is believed to be a random number. And finally, we'll look at the standard abstract example of flipping coins. And if I flip coins then the number of heads in a given number of flips-- let's say I flip five heads in one second. That's a random variable. flip a coin n times. The number of heads is a number that comes out of this random process of flipping the three coins. C is greater than or equal to 1 when there is at least 1 head. M greater than 0 means all the coins match. This is an obscure way of describing the event all heads, and it has a course probability 1/8. So formally, a random variable is not a variable. Or it's a function that maps the sample space to the real numbers. the real numbers. Might be a subset of the real numbers like the integer valued random variables. Occasionally we'll use complex valued random variable. Actually, that happens in physics a good deal in quantum mechanics, but not for our purposes. We're just going to mean real value from now on when we talk aboutrandom variables. So for every possible real number, if I look at the event that R is equal to a, that's an interesting event. And if you knew the answer to all of these R equals a's, then you really know a lot about R. could say explicitly where it comes from as an equation. It means that the probability that R1 is equal to a1 and R2 isequal to a2 and Rn is. equal to an. And the definition then of mutual independence of the random variables R1 through n, Rn holds is that this equation it holds for all possible values, little a1 through little an. So let's just practice. Are the variables C, which is the count of the number of heads when you flip three coins, and M, [? the 0-1 ?] valued random variable that tells you whether there's a match, are they independent? Well certainly not. R to R, total function. R is independent of f of S, any transformation of S by a fixed non-random function. If I have k random-- if I have a bunch of random variables, a large number much more than k, they're k-way independent. If we have k coins and Hi is the indicator variable for how coin I came out, whether or not there's a head, now O can be nicely expressed. The notion that there's an odd number of heads is simply the mod 2 sum of the Hi's. makes the k plus 1-- k plus first. And the reason why any k of them were independent was discussed in the previous slide when we were looking at the events of there being an odd number of heads and a head coming up on the i flip. For a bunch of major applications this pairwise independence is sufficient. It's harder to check mutual independence. You've got a lot more equations to check. We'll be making use of it in an application later when we look at sampling and the law of large numbers.

ROUGE-1: 36.34, ROUGE-2: 34.87, ROUGE-L: 35.91
BERTScore: 66.76

==============================================
==================== [29/100] ====================
Summary:
s gawan and the Green Knight um I believe this is the last piece where we don't know who the author is where it's unknown um I find the background interesting and that through textual Clues they're able to figure out who wrote it. It's interesting when they talk about some writer character character character is whatever that word is SAR Gowan as a ruthless bloodthirsty Warrior um we really don't see him in that regard. Throughout the story of seral when we again come back to what a knight truly is. if you look down at the bottom of uh uh uh well it's actually on 176 now he comes in and addresses everybody and everybody gets kind of kind of quiet uh because this is a huge monstrous man with a monstrous Axe. He saysi come to uh speak to the person in charge and off Arthur King Arthur says that would be I and he goes I've come to search you based on reputation remember how we talked about the the honor okay people don't do you know if the knights do something it's a reflection of Arthur and Arthur as we know from all of our you know illusions of movies and cartoons and stuff that you know he is a good guy. own land and look for no further trial so if after the deal I'll tell you where you can find me I will give you my name there are no tricks here. If for some reason I am unable to or I choose not to tell you myname then the agreement's done and you don't have to come andLook for me okay it's kind of like those things where be careful what you wish for that type of thing make sure you understand exactly what agreement you're getting into the night from the wife of bath he didn't know that he was going to have to marry that woman did he no would he have still done it. his Steed snatched the bridal stepped into the sturup and swung a loft holding his head in his hand by the hair he settled himself in the saddle as steadily as if nothing had happened to him though he had no head. Then the head will obviously have to tell him his name and where you can find him are you envisioning this cut the head off the body walks over. Here's where you come to find me come or else be called coward accordingly line 232 233 come or be called a coward and it's not just. sir GNE being called a coward we've got to understand that mindset who would that be calling a coward Arthur and everybody else the Knight came here specifically to challenge the best that Earth has ever bred is what he was saying and so this is the moment and now GNE has a year to think about his impending doom is he going to go do we think he's going to take the axe shot is this all a test is he Going to trick something I mean these are all thoughts that should be going through your mind. you receive the the hunter the owner of the house the husband says whatever you receive you must give to me that seems kind of weird what possibly could he receive while he's there well we find out that the wife really kind of starts to come on to him over time okay real flirty she's she's a temptress okay very seductive uh she gives him a kiss what does he do when the husband comes home that day cuz the husband's going to share his his food share his everything with him as long as GNE you share with me and so he gets kissed. comes home and GNE does not give up the girdle because why would I give this this is going to save my life I'm not going to so he breaks his word okay he becomes a coward. He is selfish and coward about his life about hey you gave me a this is a wild card he doesn't know I'm going to have an ace up my sleeve come time to get that shot in the head um and so he does leave and he keeps that GLE for himself um and doesn't give that away page 185. thing and so he hears it you know happening and um so he screams out and the and the um and the Green Knight comes he says by there said one on the bank above his head and you shall swiftly receive what I once swore to give you. He chastises him and tells him take off your helmet and offer no more argument or action than I did when you whipped off my head with one stroke no s GNE by God who gave me a soul the Grievous gash to come I Grudge you not at all strike but the one stroke and I shall stand still and offer you no hindrance. a little Flinch shoulders shrank slightly from the sharp edge could you hear it when we went through this all of those alliterations I mean it's almost hard to say you almost have to slow down but that's those are great examples of alliteration um you are not gain said the Gallant whose greatness is such that by Hill or Hollow no army ever frightened him for now you Flinch for fear before you feel harm I never did know that Knight to be so coward I didn't know the Knights of Arthur were so cowardly that you flinched. take his head off like he did with the like what happened to the Knight he just dinged them and so there was some blood and we find out all along that sir gain was never really intended to get any Nick at all if he stayed true to what his words were. If he never violated his oath the most he was ever going to do was scare him and probably wasn't even going to hurt him. Since you lied that's why you got the Nick the Snick on the neck sir Gowan happy that he still alive relieved angry sad. them say that they were angry at you they can get over the anger I'm sure they'll get over. the disappointment but yet that they just thought so highly of that person then not So Much Anymore okay and that crushed him. The wife was a culprit in this and the Green Knight pushed her along hey try to seduce him see what happens we're testing him to see what's uh if he's truly a good uh a good person or a coward as it turns out. 510 curses on both cowardice and Covetous. Celebrate was it New Year's is that what it is we'll come back and celebrate this cold New Year I'm not mad at you so now we need to go back and look remember the archetypes we talked about. What was the purpose of the Green Knight simply to challenge challenge King Arthurs and his crew and see if they truly are as honorable as they say as legendary as Legend has as the stories have it. Can we really call him a villain probably not but yet isn't he that antagonist early on? good person away with the forbidden fruit you know something similar we could maybe connect uh down the road but it's very similar to to those so um so go and the green. I hopefully you enjoyed it um really story-wise we're done with knights uh. It's a very similar story to the one we did with the knights. It was a very different story but it was very similar. I hope you enjoyed the book. I'm glad you read it. I'll see you next week.

ROUGE-1: 45.06, ROUGE-2: 43.30, ROUGE-L: 43.74
BERTScore: 63.64

==============================================
==================== [30/100] ====================
Summary:
hey what's going on YouTube boy Robert and my mission is to teach you everything in the kitchen now earlier this week at work I learned and I was wondering what are the fruits and vegetables I can turn in the salt as well. Today we have blueberries strawberries Kiwis red beets yellow beets pineapples right in fruit and cucumber this is the equipment you'll need for today you don't need one blender sheet trays mason jars parchment paper aluminum foil a spice grinder a bowl with a strainer and a plastic spatula.

ROUGE-1: 27.87, ROUGE-2: 27.37, ROUGE-L: 27.87
BERTScore: 66.38

==============================================
==================== [31/100] ====================
Summary:
Sarah with register nurse rn.com goes over how to check Vital Signs. Vital Signs are pain oxygen saturation temperature heart rate respirations and blood pressure. You want to provide privacy to the patient and tell them what you're going to be doing. If they do have pain ask them the quality what does it feel like and where it is at. There's several ways you can take a temperature every facility has a different system set up so use what you want. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org. they have but you can take it orally you can taken it axillary you cantake it tanic in the ear or you can takes it temporally or rect um rect is the preferred route usually on your pediatric patients but in adult patients normally we do it orally. axillary and temporally the readings are going to run about one degree lower than oral. For tanic and rectal temperatures it's going to usually run about 1 degree higher than your oral reading. A normal temperature is about 97° fit to 99° F okay and take the thermometer out and read it and his temperature is 98.2 and then clean it properly. The reading on the top it's read as spo2 and then on the bottom you will see his heart rate which is 64 but here in a second I'm going to show you how to actually count the heart rate using the radial artery. While I'm counting the heart rates I count that for 30 seconds if it's regular and then the next 30 seconds I count the respirations which I look at the rise and the fall of the chest and that equals one breath. If you tell a patient you're going to count their respirations they change the rate of breathing so it's good to conglomerate those two together so you can get a more accurate reading. A normal pulse rate in an adult is 60 to 100 beats per minute okay the heart rate I got 60 and his respiration were 16 now we are going to get his blood pressure now whenever you're getting blood pressure you want to make sure that you get the right size cuff in most settings they have the automatic blood pressure cuffs where you don't have to blow it up yourself so you're really blessed with that but a lot of times you may have to learn how to do a manual one now my previous video and a card should be popping up. blood pressure cuff you have these little arrows and it says left arm right arm and this is his left arm so we're going to make sure that we put this Arrow about 1 to two inches above that artery so let's slide it up and then make sure our cff it properly. Put our stethoscope in her ears and you're just going to place it over where you have heard that brachial artery and then you'regoing to blow the cuff up to about 180 to 200 mm of mercury or until you don't hear that braak your artery anymore. Mark now we're listening for whenever it stops and whenever it stopped that's our diastolic okay it stopped right at 65 so his blood pressure is 114 over 65 so that is how you check bottle signs now whenever you're done remember to let the patient know what their bottle signs were and um do hand hygiene and clean your equipment before you go to the next patient so be sure to check out all my other videos on nursing skills and thank you so much for watching and for all your support.

ROUGE-1: 54.72, ROUGE-2: 51.99, ROUGE-L: 53.59
BERTScore: 69.22

==============================================
==================== [32/100] ====================
Summary:
The grenade algorithm uses a minimal set of three-point correspondences to solve the camera pose estimation problem. The disadvantage of this particular formulation is that it ends up with a four degree polynomial which means that it could give up to a total of four possible solutions. The solution that gives the minimal reprojection error would be considered as the correct solution. The question becomes whether can we find the solution directly from any four point correspondences or more than four point Correspondences such that the solution is unique. s1 s2 and s3 are the unknown depth of the three points so we have uh three point correspondences here which is uh intersects at the camera center. For every equation here it's only a function of our two unknowns so uh we'll get this system of uh polynomial equation written as f12 that is dependent on s1 and s 2 and f13 depending on s 1 and s 3 as well as f23 dependent on s2 and s3. or equation and to over constrain the system uh so as a result we'll first get six polynomials in terms of uh s i and s j. Since we have four points and each pair gives one polynomial so we have to do four choose two. This is going to give us three polynomic equations three fourth degree polynomal equations. There's no guarantee that all this are going to be the same solution due to noisy data and probably the most important part is that we cannot profit from this data redundancy. any of the unknowns in the the depth where we simply write it as s i square over here so this can be derived in in this way so here i wrote out all the six combinations of the polynomial equations f i j over here we can see that each one of this equation it's a just a function of two unknowns. The unknowns which are x 4 x 3 x 2 x and 1 can be written as a vector over here 0 0 and as a result we'll get a three by five matrix and a five by one vector. have a rank of uh three this is the same as solving ax equals to zero where now a here has arank of three the rank of a is at max going to be equals to uh just three so but we have a vector so x here is actually a vector of uh 5 by 1 which means that this has to live in a five-dimensional subspace but a has a only three constraints which means the system of homogeneous linear equations is under constraint but what we can do here is that we can take the svd of a which is uh given by this guy over here. s1 we know that t5 here is actually a vector that is made up of the same entry but of different order so x4 x3 x2 x and 1 of different entry. We know that by observation any two elements the product of tij is going to be equal to tk and tl for this constraint to be valid where i plus j must equal to k plus l we can verify this suppose that i here equals to 1 and if k here for example equals to 3 we can substitute this in. here so uh this simply means that because t5 here earlier on we found the solution here it's spanned by the two right singular vector so we can write the components of this parameterized by lambda rho and v4 v5. If we look at all the combinations we are in total get seven such equation that is given by this table over here that fulfills the constraint of i plus j equals to k plus l and within this particular range that is written here so as a result we'll get seven of these equations over here. The solution would be the one that corresponds the last column of v over here. This is actually an over determinant system because b here is seven by three so this means that we have seven equations over here but only three unknowns that we want to solve. Taking svd of b we get the left singular factors multiplied by the singular values as well as the right singular vector matrix over here so once we have solved for the null space vector y using the svd what we can do is to proceed on to solve for lambdas and rho. basis vectors e4 and v5 respectively earlier on when we solve for t5 so we can see that the first row of t over here is actually equals to one 1 and this equates to Lambda multiplied by the first component of v4 plus rho multiplied by v5. Together with this equation over here you can call this equation 1 and then with equation 2 over here that provides a constraint on Lambda and rho we have two equations and two unknowns and we can solve for lambda and Rho uniquely here. where we can solve for since we know that x equals to s1 squared we can solved for the final depth by taking the square root of x. Once s1 is solved we can back substitute s1 into the polynomial equation of f i j s i and s j equals to zero. After we have gotten all the unknown depths we can do the same thing to to apply absolute orientation to recover the camera pose as in the grenade algorithm and here what's interesting here is that because we have four point correspondences and we can see that because rho and lambda here can be determined in a unique way. there will still be two degenerate cases where uh if the four points are collinear because in this case we are the camera center is still going to lie on a plane with these four points and this will give us degenerate solutions. In the other case would be if all theFour points uh and they are coplanar together with the camera Center. This is also going to be degenerate as what we have seen earlier on now. It happens that the linear four-point algorithm can also be applied to more than four points so for example when n equals to five when there are five point correspondences. equation we can stack them all up so one two all the way to six equations and we end up with a coefficient matrix with an a matrix of of dimension 6 by 5. in order for non-trivial solution to exist then this guy here better be of a maximum of rank four so what we can do here is that we can take the svd of a and this will give us u sigma v transpose where we simply the vector that corresponds to the least singular value in sigma. to the solution of s1 over here now it turns out that the same algorithm that we use to solve the linear four point and the linear five point can be applied to any number of point correspondences that is four or uh more points. Here we just need to solve for the svd of a m minus 1 multiplied by m minus 2 divided by 2 by 5 uh matrix of a to get the solution for the vector t 5 but the problem here is that the overall complexity is a cubic in the order of the number of points that is used to form a. proposed by lapati in the year 2006 is that instead of using every single point correspondences that is given to us the the core idea is that here we'll make use of all these points to define four control points. Even for a very large n the number of control points still stay constant as uh fall. So now this control point becomes our unknown so that we also need to solve for in addition to the camera rotation and translation where these 3d points they are given and they are known. As alpha i4 for one of the 3d point which we denote as pi over here and this this can be easily solved because we know that uh p i over here is a four by one factor in homogeneous uh frame. We can solve for alpha 1 alpha 2 alpha 3 alpha 4 for every single point and it's interesting to note that we do not have to take this constraint here where alpha sums up to 1 explicitly because this is explicitly or implicitly expressed in the last row of this equation over here. in total so uh since each point correspondence gives us two independent equations what this simply means is that we need to stack them up into 2n by 12 matrix which we call m over here to solve for the 12 by 1 unknown of the control points in this homogeneous linear equation. The number of basis solutions that we can get from solving the equation mx equals to zero over here depends on the size of m and which in turn depends upon the number of point correspondences that we have and uh so one way of solving for the basis equation from this uh mx equal to 0 would be to take the svd of the matrix m. have only one basis solution where capital n here equals to 1. what this means is that the rank of m must be equals to 11 and means that there are 11 unique constraints that forms the metric of m. Since we know that each point correspondence is going to give us two constraints this simply means that we need a total of 5.5 point correspondences in order to form a uh m with rank of 11 and that would equate to be six point. Since there are three null space vectors this means that the solution is formed a linear combination of 3 null space basis v1 v2 v3 which is parameterized by 2 and beta 3 here. camera reference frame we can substitute it back into this equation to recover the 3d points that is defined in the camera frame. Once we know this we will be able to solve for the rotation and translation between this two sets of points. We can solve r and t between these two frames using the absolute orientation algorithm. And then finally we look at the efficient pmp algorithm which is a on complexity algorithm that solves the camera post estimation problem using the efficient orientation algorithm and the efficient perspective endpoint problem. for the camera pose using a set of control points using four control points in particular and we saw that this uh it's uh the complexity is a linear in terms of the number of points which is much easier to compute then we also saw the degeneracy cases for the camera post estimation problem in particular. If all the points plus the camera center forms a plane then this is also a degenerate case and that's the end of today's lecture thank you mx equals to zero. Mx equals zero.

ROUGE-1: 36.09, ROUGE-2: 34.92, ROUGE-L: 35.27
BERTScore: 72.99

==============================================
==================== [33/100] ====================
Summary:
Markus Klute: If there is a time dilation effect due to gravitational fields, then there's also a redshift which is of gravitational fields. He asks you to estimate the magnitude of this effect. You want to use the example of a 22 and 1/2-meter-tall tower. He says the speed of light is pretty fast, 3 times 10 to the 9 meter per second. And this distance is only 22 and1/2 meters, so we find that this is a tiny, tiny,tiny effect. to know more about this, you can, for example, look up a small description in Wikipedia here. But there's quite some literature on those experimental tests [INAUDIBLE] There's a lot of information on the subject on Wikipedia. It's a very interesting area of research. There's quite a bit of literature on it. It can be a very exciting area of study. It could lead to some very interesting results. But it's a little bit of a mystery as to how it works.

ROUGE-1: 52.65, ROUGE-2: 40.63, ROUGE-L: 43.22
BERTScore: 72.58

==============================================
==================== [34/100] ====================
Summary:
During the semester we have a few recitation instructors they help with the students during the recitation section. During those sections your the the instructor will solve a similar problem like what is actually covered during the same during the lecture and that give the students another chance to look at more example and to get for media will get used to the calculation which we carry how for the first time during the the lecture. We did not record the Recitation sections during the fall semester in 2016 on the other hand we included problem-solving videos from Professor with Busha.

ROUGE-1: 67.77, ROUGE-2: 66.22, ROUGE-L: 67.77
BERTScore: 85.45

==============================================
==================== [35/100] ====================
Summary:
In this video, we're going to compute some useful quantities for the exponential random variable. The CDF of x is the probability that X is less than or equal to little x. We use the standard formula, which is minus infinity to infinity t times fx of t dt. For this, if you evaluate the balance, 0 makes this 0, and 0 to get 1 over. And so the expectation is 1 over lambda, and so the variance is part c, so OK, so far so good. rule, 3 times 1 minus e to the minus Lambda z squared. Then the derivative of negative e to  the minus lambda z, that's just Lambda e to z. This is the PDF we were looking for. We're looking for the PDF of w, which is the min of x1 and x2. So let's try this as a similar approach. Try the same thing, actually. See if it works. So w, w,. w, W, w, min, less than or equal to w. So it's going to be-- Notice the similarity between this and this. The only difference is this has a 2 lambda in there. That means that w is an exponential random variable with rate 2 Lambda. You can also take the derivative of this and find that you get this. OK, so we're done with the problems. We computed some interesting quantities for the exponentialRandom variable in this. So then the PDF isgoing to be an exponential, whatever it is for an exponential.

ROUGE-1: 22.99, ROUGE-2: 21.47, ROUGE-L: 21.54
BERTScore: 70.42

==============================================
==================== [36/100] ====================
Summary:
Professor: Can you explain the physical significance of the crystal momentum? Professor: Let me answer that in a slightly backward way. Professor: If you have a wave function, sine of x, such that, the expectation value in the state SI of x is equal to x naught, and the expectationvalue of p in SI is p naught. Then if you want to change the momentum, increase momentum by h bar k, the way to do that is to take SI and build a new wave function. the wave function is complex content we give the inner product. But the expectation value, the momentum is shifted in state SI tilda, is shifted by each h bar k. So all the intuition you have about momentum, you can translate into intuition about the spatial variation of the phase of the wave function. Oh, and one last thing, a last defining property of the momentum, a central property from the Schrodinger equation is at the time variation d dt of p is equal to the expectationvalue of minus d the potential of x d x. The crystal momentum is defined from beginning, from the following property. Ehrenfest's Theorem tells us that the classical equations of motion are realized as expectation values. So in precisely this sense, the momentum difference is space of the wave function. Here, in the case of a periodic potential, the crystal momentum q is governing the spatial variation of the phase of thewave function. So q is the thing the governs the phase as a function of x. Well what about-- another fact about the crystal. momentum which you show in your problems set, is that if you impose an external force d q, is equal to the minus d v d x. d t, and really d h bar q, is equal to the expectation value of the force. So the central value of your wave packet varies in time according to the external force. If the force is zero, we turn no external driving force, your wave. packet maintains its crystal momentum. So it carries many of the same properties. It governs the phase. It's time independent unless there's an external force applied. It is not the eigenvalue p on five sub e q. the momentum commutes with the energy when you have no external force. When you have a constant potential. So developing an intuition for the crystal momentum, I think, is best done by just playing with examples. And you'll do that more in the course on solids, which I encourage you all to take. Because it's really beautiful stuff. But for our purposes, this is going to be the full set of ideas we'll need for 8.04. Yeah? AUDIENCE: [INAUDIBLE] PROFESSOR: Ah. So good. So thank you. equal to alpha, then acting on u sub q, by translate by l, on U sub q of x, is equal to-- well, if we act on Phi sub q we pick up a phase e d i alpha. What happens to e to the minus i q x? x goes to x plus l. So if q l is equalto alpha, those two phases cancel, and we just get u back. u subq of x. If we want u to be always real, we can't impose this periodicity on different wave functions. the imaginary part, h bar over 2 m i. Well, hbar over m times the imaginary part of SI complex conjugate derivative, with respect to x, which is the current, in the x direction of SI. And we need this to be imaginary, or we will get no current. You show this in a problem set, if you have a pure, real wave function, for example. A single real exponential, that's decaying, as on the wrong side of a barrier. can always write it as some q naught plus n pi over l. And this fits nicely into this story, because now all we're going to get here is q. So the current depends on both the part defined mod 2pi over l, and the integer, which tells you how many factors of 2 pi over. l did you have to subtract off to get into that fundamental domain. So let's think back to our band structure. In ourband structure, we had something that looks like this. And here's the value of q. But am I plotting q? No. I'm plotting here q Naught. There isn't a single energy for a given value of q. In fact, there are as many as there are integers. To specify a state, I don't just have to. specify q NAUGHT, I also have to specify N. Which one of these guys I'm hitting. When you unfold this into the parabola picture, remember where these came from. These came from shifting over. And the higher up you go, the more you had to shift over. That's exactly the integer piece in n pi over l. function of q, not q naught, but so here's pi over l. Here's 2pi over l, Here's 3Pi over L. And I need to do this carefully, because it's incredibly difficult to get the straight. OK. So here's the parabola that would have been, if we had not turned on a periodic potential. As we turn on the periodic potential, we know that the energies change. And so in the first band it's easy to see. We don't have to do anything. E as a function of k is always going to look like that. But k is not a well-- so what is k? K is just defined as h bar squared, k squared upon 2 m is equal to e. So this doesn't tell you anything about which states you're at. It just that given an e, there's some quantity that could define k. This is a definition of k, in terms of e. Only some values of e are allowed, right? There are no energy eigenstates with energy in between here and here. Professor: When you have a perfect lattice, there is actually no current flowing in response to an applied electromagnetic field. Professor: You can build a system that has exactly a periodic potential. He says it's very difficult to do this with quantum systems, but you can do it with lattices not of atoms, but lattices of dielectric. Professor says you can build system which incredibly, cleanly, has. a system which has a periodic Dielectric constant. a periodic dielectric constant and no disorder. And then you can put light into the system, and you can ask what happens to this system. So literally what you have, is you have glass, glass with a different index. And you shine your light that's reasonably well localized, in both position, and in phase variation, or crystal momentum. Because you can control the phase of the light. Well not a whole lot happens. It's a wave packet, but we haven't implemented an electric field. To handle an electric fields, you need the potential to be constantly varying. beautiful block oscillations. And this has been proved in a very small number of real honest quantum mechanical systems. The most elegant experiment that I know of was done by Wolfgang Ketterle, who's here at MIT. And he got three data points because it was preposterously difficult and declared victory. But it really needs to be done well. So one of the interesting questions in this part of the field right now is we know that it's true. But we want to see it. We want to feel it. situation, it depends on the system. And exactly how it depends is something that is an active area of research. So don't throw away the model. Observe that you've modeled the wrong system. If you find a system that fits your-- that is-- that shares the assumptions of your model, that's when you ask did it work. And it worked like a champ. OK. So now let's talk about real materials. This is going to close up our discussion bands and solids. talk about the 1 d potential. This state, this single state turns into a band of allowed energy eigenstates. And similarly, this state is going to lead to another band with some width. In 1 d, do these bands ever overlap? No. By the node theorem. Right? OK. Now let's take a single electron, and let's put in-- let's taken a single electrons. What will happen? Well if we put it in the system, what state will this single electron fall into? But which state? have to do? What kind of state corresponds to the position changing in time? Yes. Right? From the superpositions we'll get interference terms. If we put it in a superposition of these guys, then it's meaningfully moving. So in order to induce the current, I must put the electron into a higher energy state. So it's in the next band. The next allowed energy eigenstate. Is anything moving? This system is in a completely antisymmetrized configuration. So, nothing is moving. macroscopic amount of energy. Well, it's not macroscopic. it's large. It's not infinitesimally small. That means that there's a minimum amount of. energy that that incident light must have in order to excite the. electron in the first place. Crystals are transparent unless you look at sufficiently high frequencies. If you looked at low frequencies, your crystal should be transparent. Well that's really interesting. In particular, we immediately learn something cool about two different materials. Consider diamond and copper. These are both crystals.  spin in one dimension is little-- I'm lying about spin. If we include spin, then there are two states for every allowed energy eigenstate of the potential. Electrons spin up, and electrons spin down, will generically have different energies. In 3D, this isn't such a big deal, because those splittings are tiny, and so the states can sort of overlap. But in 1D they can't. So I mean, that's also not exactly true, but it depends on exactly the details of the system. rotor. And when you studied the rigid rotor, you found that you had energy eigenstates and they were degenerate with degeneracy 2 l plus 1. And then we turned on an interaction which was the energy costs, the energy penalty for having angle momentum in z direction. Which added an l z term to the energy. And what you found is that as a function of the coefficient, which I think we called epsilon, of that perturbation of the energies of the energy, these guys split. we add in a lattice we get bands again. The structure's a little more intricate because it depends on the momentum. But these bands now can overlap. OK. Everybody see that? Because there's nothing preventing states from different-- in different multiplates from having the same energy in three dimensions. There's no nodes here that tells you have to keep the ordering constant as you turn on the potential. Now we turned on the multiple particle potential, and they can interact, they can overlapped. As a consequence, when we fill up, let's say we two electrons per potential. the induced electric field? Nothing. Any electric field that you send in will be opposed by an induced current. This behaves like a classical conductor. You turn on an electric field, and the charges will flow to oppose that externally imposed electric field. You get charges then building up on the walls of your capacitor plates. So, this is where we have a conductor. Because there's an unfilled band. And back here , we had an insulator because we had filled bands separated by gap. The gap between the filled band and the next available band. This is actually called a band insulator. could have all sorts of different crystallographic structures. So that's going to go into it, in the same way that l went into it. So different materials for example, diamond versus copper, are going to give you different bands allowed energies. And so when you solve the problem for the energy eigenvalues is a function of now the three different components of the crystal momentum, you'll just get a different set of equations. And working those out is not terribly hard. But it's a computation that must be done, and it is not trivial. yeah. There aren't [INAUDIBLE]. But what would we need? What we need is one of two things. We need either the band gap coincidentally is ridiculously small. What's a good example of that? A free particle. In the case of a free particle, these band gaps go to 0. Right? And so that's a conductor. Just an electron. It conducts, right? OK. So that can certainly happen. But that's sort of stupid. I mean, it's not totally stupid. But it's sortof stupid. The temperature controls an energy scale for a real material. If you have a hot piece of copper, then the lattice is wiggling around. Every once in a while, an ion can hit one of the electrons and excite it, give it some momentum. So at a high temperature, a material with a small gap is basically a conductor. At low temperatures, it's basically an insulator. This is called a semiconductor. And there are notes on the Stellar web page that discuss in a little more detail what I just went through. Photonic crystals have bands of allowed energy and gaps of disallowed energies where no waves propagate through. Photonic crystals form exact crystals that reflect at very specific wavelengths. So why would a butterfly put a photonic crystal on its surface? Well it's extremely light. It's fairly rigid. And it's like the best thing you could ever do if you wanted to be a shiny, fluttery, flying thing. OK. So that's it for band gaps. And I want to move on to the remainder, the last topic of our course. Which is going to be entanglement and quantum computation. The probability of finding the particle at point A is given by chi a squared. And similarly, the probability that we find the second particle at b is this thing norm squared. But we also studied the symmetric configuration, which was equal to 1 over root phi, root 2. Chi of a Phi of b. Symmetric, plus chi of b phi of a. And this tells us something totally awesome. So there's a factor of one half. We either find it at chi of a or chi. So it's fine. If we integrate over all phi b, this is the norm squared integrates to 1. "This should be yet another moment of serious discomfort," he says. "How can something here dramatically change the state, the configuration, the initial configuration, of a particle arbitrarily far away?" "If you think about relativity, this should be all the more deeply disconcerting," he adds. "We've run into a bunch of these over the semester. But this one should be troubling to you," he concludes. "It's a problem that should be deeply concerning to all of us" that's kind of amazing is that he created a thought experiment which we're going to study in detail next week called the EPR experiment. And there's a beautiful historical story about the setting and the meaning and the particular person. And unfortunately, I'm not a historian so I can't tell you that story. It sure would be nice if we had someone who wrote a biography of Einstein to tell you a little bit about that. Oh look, it's Tom Levenson. Tom is-- The physicist Bell came to Princeton in '33. He stayed for the rest of his life. He worked with a lot of different, mostly younger physicists. Bell had a lovely way to describe-- I'm trying to find. I had this marked and then I lost my piece of paper. I have already lost it. That's terrible. So Bell has this wonderful way of describing the problem. And I want to share with you, actually, a really lovely description of the way the problem was represented in a way by. of describing this problem of entanglement. And it's based on his description of an actual person. Bell used to say, if you saw Bartelstein and you could only see one leg and that sock was pink, you knew to a certainty that the other sock was not pink. Same thing. If you have a coin and you cut it in half down the-- so you've got two coin shape disks. And they're separated. They get handed to two different gamblers. And one gambler tries to cheat the gambling establishment by tossing in his half coin. And you see the head that you know somebody-- somebody at some other casino is cheating. Einstein argued that the EPR paradox suggested that quantum mechanics was incomplete. Niels Bohr responded that there's no description of reality that excludes the measuring apparatus. Once you know one part of the picture, you know some other part the picture. And that's just the nature of the quantum world, David Frum says. He says it's important to go back to the pre-history of all this, and then speculate on why Einstein reached the position he did. And what that might tell you about the practice of science as a whole. a lived experience as opposed to one reflected in your textbooks. The experiments were done, and I imagine are still being done, as sort of demonstrations. And they showed that Bohr's interpretation was correct and that yes, quantum mechanics produces results that are non-local just as Allan described to you. And that the world really is as strange as people first glimpsed in 1925, '26, and '27. But the question whether or not the framework of quantum mechanics is somehow unsatisfactory in any kind of formal a technical sense is one that's at least partly dependent on your scientific temperament. Einstein's role in the creation of the quantum theory is not widely known. Heisenberg, Schrodinger, maybe Bohr. Maybe Born. Maybe a couple of others. There's no one more important to theQuantum Theory than Einstein. Without Einstein, without quantum theory, there would be no quantum theory. It's a complaint. You know, it's a memo to the Flying Spaghetti Monster that the universe shouldn't be this way if, in fact, experiments turn out to show that it is. In 1905, he publishes The Quantum Theory Of Light. In June he publishes Special Relativity, which treats light as a wave. He's the first person to suggest there might be a problem with causality in quantum mechanics. He nominated Schrodinger and Heisenberg for Nobel Prizes twice. There's a reason that year is called the annus mirabilis, the year of miracles. And in part it's because Einstein is able to actually really focus on these things. And he's capable of doing excellent things. stupid. He was Albert Einstein. But he was aesthetically incapable of pursuing this new physics in ways that were possible under the research possibilities of the time. And that is what I would leave you with. Physics is an aesthetic as well as an intellectual pursuit. So thank you all. [APPLAUSE] Back to Mail Online home. Back to the page you came from. Follow us on Twitter @dailymailonline and @MailOnlineernews. Back To the pageyou came from, back to the Daily Mail home.

ROUGE-1: 37.34, ROUGE-2: 35.63, ROUGE-L: 34.92
BERTScore: 68.48

==============================================
==================== [37/100] ====================
Summary:
First up the proper way to chop fresh herbs to get maximum flavor. The secret is to chop them not bruised them now basil this is a soft herb so treat it with some respect. If you have fruit that's not perfectly ripe the tip is to put a banana in a pot of water. The best way to cook parsnips is to cook them in the same pot as the parsnip. The most important thing to do when you're chopping herbs is not to cut your finger. Paper bag then add your unripe fruit put it in a dark place and the banana will speed up the ripening process of the other fruit you can't appeal. Cut a mango the easy way homey you stalk end up cook either side of the stone cut all the way into the flesh making squares without cutting through the skin then turn it inside out and carefully cut your pieces off. A great tip to prevent burning sensitive skin when working with chilies to get rid of that spice and that heat on your fingers a little bit of lemon squeeze a little amount of lemon juice and that instantly gets rid of the heat. Julienne is a chef's word for strips these are absolutely perfect for sewing and that's what we're looking for they're crunchy delicious and more importantly no seeds deed for a great tip to check if a pineapple is ripe is to pull a leaf out from the top if it comes away easily it's ripe and ready for slicing. A great tip for getting meat or fish to cook faster is to score it which allows the heat to penetrate quicker this also allows mayonnaise to be absorbed more deeply.

ROUGE-1: 53.21, ROUGE-2: 47.87, ROUGE-L: 47.78
BERTScore: 68.44

==============================================
==================== [38/100] ====================
Summary:
hey everyone it's sth register nurse rn.com and in this video we're going to be going over our weekly inlex practice question. Don't forget to check out the other practice questions in this series. Let's see what our question says a patient who has a health history of uncontrolled hypertension coronary artery disease and diabetes militis is prescribed to take propanolol. You have provided the patient with education about this new medication which statement by the patient indicates your teaching was effective. An ool these are our beta blockers so propanolol is a beta blocker. There's several groups of beta blockers you have ones that act on just that heart tissue specifically their beta 1 receptor blockers and then you have these which act on both the beta 1 and beta 2 receptors. Whenever you take this drug it acts on those neurotransmitters specifically norepinephrine and epinephrine so those will be blocked and in the heart and what will happen is that you will get a slower heart rate instead of that tacac cardia.  Beta receptors do they increase a process called glycogenolysis. When a patient has hypoglycemia the body tries to correct that so it will do glycogenolyssis which is going to break down glycogen to glucose. However this is being blocked in this patient this process it's slowing it down. If they're taking a beta blocker that is blocking that response they're not going to have that classic Tac of cardia. Later on their sugar will drop so much and it may be too late before they can treat it. Grapefruit juice contains chemicals that can slow the absorption of the medication. If a patient misses a dose of their beta blockers they don't need to double the dose they need to take it as soon as they remember unless that next dose is due. If you're taking double the doses they are at high risk of a cardiac event. If the patient is already diabetic taking insulin probably that's what we assume and um so they have to monitor their blood sugar especially with these non-selective beta blockers. look and see why D is wrong this patient says that they're going to stop their beta blocker immediately if they experience cold hands and feet well this is a normal side effect with these non-selective beta blockers. You would never just immediately stop taking a beta blocker they need to be tapered off of this because if they just all of a sudden quit taking that medication they can go have cardiac death or something worse can happen so that answer is wrong for that reason okay so that wraps up this inlex practice question.

ROUGE-1: 48.53, ROUGE-2: 46.58, ROUGE-L: 45.79
BERTScore: 71.52

==============================================
==================== [39/100] ====================
Summary:
This is part 2 of a guide to clinical reasoning or how to create an accurate differential diagnosis from a patient's presentation. The patient is a 75 year old woman presenting with epigastric pain for four hours. She was in her usual state of health until four hours prior to presentation at which time she developed the onset of abdominal pain. The pain is relatively well localized to the midline in the region between her humble ankus and xiphoid process. There did not seem to be any particular trigger and the duration from initial to final pain was relatively short. onset to its maximal intensity of 8 out of 10 was about 45 minutes the pain is constant does not radiate is not exacerbated by anything including nor alleviated by anything she had moderate nausea it has refused to attempt to eat or drink anything since the pains onset because she is concerned that it will concert a vomit which she has not yet done. She denies changes in her bowel habits shortness of breath chest pain changes her skin or eye color her past medical history is notable for hypertension and diabetes she has had no surgeries. exam reveals normal oral pharynx but poor dentition her neck is supple without breweries and without lymph adenopathy her chest is clear to percussion and auscultation bilaterally her cardiac exam has a regular tachycardia hypertension her jbp is undetectable at either 45 degrees or when she's completely sipping on abdominal exam she has non distended and there are no scars. bowel sounds are unusually quiet but present rectal exam with normal tone no tenderness and minimal guaiac negative brown stool musculoskeletal exam revealed full range of motion in all joints without bony abnormalities. The problem representation is a one to two-sentence summary using precise medical terminology of the most highly relevant aspects of the patient's history exam and diagnostic tests. The primary symptom using semantic qualifiers might sound something like acute constant epigastric pain. The soft abdomen and lack of rebound would be grouped into the collective descriptor of absent peritoneal signs. The elevated lipase would also be included in the summary of the highly relevant diagnostic data. The organization of a particular framework may just appeal more to some people than others in general when the primary problem is some form of abdominal pain most people most people will have pain. The epigastrium would obviously be the most critical anatomic region to include organs that physically lie directly underneath it. Pancreas and small bowel diseases of the stomach which caused acute abdominal pain are many but most commonly are gastritis and peptic ulcer disease in the pancreas. The major structures are of course the liver and gallbladder along with other components of the extra hepatic biliary system the liver can cause pain with either hepatitis or hepatic abscess. The spleen is the only unaccounted organ. included the transverse colon which crosses through the epigastrium though pain more typically is localized to the periumbilical region also because structures in the lower quadrants and retroperitoneal space can on rare occasion radiate to the upper abdomen. If one wanted to be unusually thorough with the framework one could also include structures and diagnosis such as appendicitis in the right lower quadrant diverticulitis in the left lower Quadrant and even a dissection of the dominoe aorta in the retro peritoneum though the presentation does not really suggest any of these in the framework stage. and what that impact was that is obviously very tedious and time-consuming an expert clinician would probably start with the key features focusing on the ones that were either most prominent most unusual or those which clearly clustered together. I'm going to take an approach here somewhere in between by going through each diagnosis one at a time but only mentioning those key features would seem particularly relevant so first up is gastritis the patient has some risk factors for gastritis with our alcohol use in smoking so these increase the probability of this diagnosis. There is PUD in the absence of an ulcer perforation there is not a very reliable means of distinguishing PUD from gastritis on clinical grounds. severe nausea at that so the presence of knowledge here definitely argues in favor of the diagnosis arguing just modestly against pancreatitis is the fact that the pain had no exacerbating or alleviating factors the pain from pancreatitis classically improves with setting up or leaning forward which this patient does not describe. The sensitivity and specificity of this symptom feature to the best of my knowledge has never been studied therefore we don't know exactly how much to weigh this in our assessment of the probability of pancreatitis there using my experience and Gestalt I would place relatively little weight on the lack of positional component to the symptom. Wiles certainly can become contaminated with enteric bacteria but for this to happen with a brand new well it would imply that they literally drilled it into a patch of pre-inoculated earth. Her severity of illness could certainly be consistent with a severe form of this but as with most diagnosis on here gastroenteritis is not thought to typically cause a high lipase for a bowel infarction. Her cardiovascular risk factors put her at risk of this this would definitely result in constant pain appearance of distress. particularly right upper quadrant tenderness along with elevated alkaline phosphatase although it's not enough to make the diagnosis likely enough to seriously consider at this point acute cholecystitis has been described as a cause of elevated lipase. The patient is simply too sick appearing for this to be biliary colic plus as it's very name implies the pain from this usually waxes and wanes instead of being constant the patient has risk factors for a splenic infarct though this usually does not radiate to the epigastric area. any key features which have not yet been incorporated into the framework that is are there any key features that don't seem to impact the likelihood of any of the diagnosis in the framework in this case there are essentially three. The first is the normal troponin and CK so why was this piece of information not incorporated into our framework discussion it's because they were actually miss identified as key features. The second unused key feature is the guaiac negative stool this key feature was critical in establishing the problem representation in step three. element does not fit into the framework yet still seems to be a key feature the framework must be incomplete in this case I would add another category of diagnosis to our four existing categories. That fifth category is acute abdominal pain secondary to systemic toxic metabolic problems. The four major members of this group are heavy-metal poisoning a rare genetic disorder called acute intermittent porphyria another virgin etic disorder called familial Mediterranean fever and finally angioedema for any of these to be the final diagnosis this patient would need to have an atypical presentation of a rare disease and thus it would be a highly unlikely diagnosis. of diabetic ketoacidosis which can definitely present with acute abdominal pain and nausea in a diabetic however the normal metabolic panel which implies a normal glucose completely rules out this possibility. In my opinion the most likely diagnosis for this patient is acute pancreatitis. pancreatitis is associated with her heavy alcohol use it explains her nausea her distress the vital signs her tenderness on exam leukocytosis and is the best explanation for the elevated lipase the only key feature arguing against it is the fact that the pain is not made better or worse with changes in position. atypical presentation those diagnoses which are rapidly fatal if missed for which this could plausibly be a presentation. Finally any diagnosis that is specifically suggested by an unusual element of the presentation even if the diagnosis itself is rare common disorders which could be a typical or atypical Presentation include gastroenteritis food poisoning and either gastritis or peptic ulcer disease which I have grouped together because I think it's very difficult to tell the difference between them without endoscopy don't miss diagnosis for this presentation would include a bowel infarction and acute coronary syndrome. that will increase the likelihood of. establishing the correct diagnosis sooner in outpatient hospital course you. That will. increase the chance of establishing the right diagnosis sooner. that will increase. the likelihood that you will be seen by a doctor sooner in hospital. that you. will be more likely to be admitted to hospital for treatment. that. will increase your likelihood of being seen by doctors sooner in the hospital. and that. you will have a better chance of being treated. of being diagnosed with a condition that is more serious.

ROUGE-1: 48.39, ROUGE-2: 45.42, ROUGE-L: 46.14
BERTScore: 66.26

==============================================
==================== [40/100] ====================
Summary:
Week 6 of CS224N is now past the halfway point. Today is the day that you have to have done the mid-quarter survey by. If you haven't, this is your last chance to get the half-point for that. Final project proposals are due. We really encourage you to try and hand them in on-time. And then today, delighted to have our first invited speaker. Danqi Chen, one of the foremost researchers in question answering, and she's particularly well known in recent work. here to give this lecture on question answering. The goal of question answering is to build systems that can automatically answer questions posed by humans in our natural language. Question answering, or, let's say QA in short, is one of the earliest NLP tasks, and the early systems can even date back to the 1960s. The question and answer has enabled a lot of really useful real world applications. For example, today today we can answer questions like, "What do worms eat?" and they'll finally retrieve the answer, that's the grass. if you just put your question in a search engine like Google. And those kind of systems are also able to handle more complex questions like how-to questions. So the question is, how can I protect myself from COVID-19? So there isn't really a simple and short answer to this question. So you can see that the system actually returns a very long paragraph, including the best way to prevent illness is to avoid being exposed to this virus. So actually this paragraph is actually a summary from CDC article. So this is also one type of question answering problems. In 2011, this IBM Watson QA system has been shown to beat two national Jeopardy champions. So this is a part of a historical event, at least in the NLP history. The system is built on both the unstructured text and also the structured data. And it's actually, there are really lots of NLP modules that have included.timer. So we know that this class is about deep learning. So today different has completely really transformed the landscape of the question answering systems. Question answering is probably one of those fields that we have seen the most remarkable progress in the last couple of years driven by deep learning. So in this lecture, I will be mostly focusing on the text based, or textual question answering problems. And another class, bigger class of the question answering problem is called visual question answering. So if you have interest in these type of problems, I encourage you to check out those problems, but I'm not going to go into them. Back to the page you came from. dig into these problems today. So next, I'm going to start with a part 2, reading comprehension. So reading comprehension is a basic problem that we want to comprehend a passage of text and answer questions about the content. So basically to answer this question, so you need to find this sentence, like, in 1861, Tesla attended this school where he studied German, arithmetic, and religion, and only German is a language. So this is really just similar to how we humans actually test the reading comprehension test to evaluate how well we actually understand one language. personal subject, Barack Obama. So we want to fill in what is-- fill in this question mark and figure out, OK, where Barack Obama was educated at. So one way to solve this problem is basically trying to convert this relation into a question. So where did Barack Obama graduate from? And taking all of that relevant piece of text and then by applying a reading comprehension problem. Then basically, we can find out-- the correct answer should be Columbia University. That is also the output of this information extraction system. for the final projects, you will need to use this dataset. Stanford Question Answering Dataset is actually a supervised reading comprehension dataset, which consists of 100K annotated passage question and answer triples. So for these datasets-- so the passages is like a single paragraph selected from the English Wikipedia. And the questions are crowd-sourced, basically like from Mechanical Turking. And this kind of a large scale supervised dataset are also very key ingredient for training the effective neural models for reading comprehension. Stanford, so it's called Stanford Question Answering Dataset. Today, after four or five years now, so SQuAD still remains the most popular reading comprehension data set. So the state-of-the-art AER systems still have time to just train or sequence tagger on top of the word. Danqi, one question you might answer is, so if you can do other tasks like named entity recognition or relation extraction by sticking something ontop of BERT and fine tuning for it or do it as a question answering, does one or the other method work better? answer to that. So next, I'm going to talk about how to build neural models for reading comprehension, and in particular, how we can build a model to solve the Stanford Question Answering Dataset. So let's first formulate this problem. So the input of this problem is let's take a context or paragraph. And also we take our question, Q. And the question consists of n tokens q1 to qN. And because the answer has these constraints, the answer must be a section of text in the passage. during that period between 2016 and 2018. So this was a family of models, basically LSTM-based models with attention. And then we need to fine-tunel this model for the reading comprehension task. So I'm going to spend a little bit more time on this part because I know that for the default final project, you will need to implement this model from the scratch. And so I'm just going to briefly tell about how to build this BER-- use the BERT models for theReading comprehension. comprehension problem because they really share a lot of similarities. In the reading comprehension problem, we need to model which words in the passage are most relevant to the question. And if they are relevant to question, so these are also relevant to which set of the question words. So this is a very key important thing that we actually need to models. And that is actually very similar to the machine translation model. But in this reading comprehension Problem, we don't need to really generate anything. So we just take the path into question. BiDAF stands for Bidirectional Attention Flow for Machine Comprehension. It was proposed by Minjoon Seo and other folks in 2017. It remains one of the most popular reading comprehension models and achieved a very good performance at that time, at least on the SQuAD data set. So next, I'm going to just dissect this model layer by layer and talk about what this layer is actually doing and how we can really build this model from the bottom layer to the top layer. care about the generation, so we can just use two bidirectional LSTMs to represent the representations. The next component is our next layer. It's called the attention flow layer. So the idea of attention is trying to capture the interactions between the context and the query. So for each context word, we need to find our alignment because we find which words in the question can be actually aligned with this context word. So this is actually just an intuition of these two types of attention.  query-to-context attention is trying to measure the importance of these context words with respect to some question words. So by taking the max for each row in this matrix, so it's basically trying to see, OK, which question word is actually most relevant to this context word? And then you can just apply your softmax. And then this will give you a probability that OK, what is the probability of this condition i, would be based on the start position of the final answer string. the dot product between w end and this vector, and this can produce all the probability over all the conditions which predict how likely this position will be the end the position of the answer. So by passing the mi to another bedirectional LSTM, their reasoning is that they're trying to capture some kind of dependence between the choice of the start and end. OK, so this model is actually achieved-- like on SQuAD data set, it achieved a 77.3 F1 score. If you remove the context-to-query attention, the performance will drop to 67.7 F1 score. And then if you remove this part, it will drop a 4-point F 1 score. So basically this theory tells us that these kind of attention scores can actually capture the similarity between the question words and the context words. And now here is our attention visualization to show that how this smorgasbord of attention actually can capture the similarities between the questions and the contexts. those negative scores pretty well, yeah. OK, so next, I'm going to talk about BERT, how to use the BERT model to solve this problem. So BERT is basically a deep bidirectional transformer encoder pre-trained on large amounts of text. And it is trained on the two training objectives, including masked language modeling and the next sentence prediction. So, OK, we can actually use BERT for our reading comprehension. So it's actually very easy and very straightforward. BERT models are pre-trained while BiDAF models only builtd on top of the GloVe vectors. Pre-training basically can just change everything and it also gives you a very, very large boost in terms of the performance. And even if you use a stronger pre-training models or modern, like a-- stronger models than the BERT models, they can even lead to better performance on SQuAD. And then finally, if you see even the latest pre- trained language models, including the XLNet or RoBERTa or Albert. These models are either bigger or these models are trained on bigger corpus. BiDAF models essentially are trying to model the interactions between the question and the passage. BERT model essentially, they're trying to use a self-attention on top of the concatenation of question and passage. And actually after the BiDAF cannot. This is also before the BERT can add. So we can see that these two models, you can really just trying to. model the attention between the passage and question. And this is actually was exactly the Bert model is doing. proposed in SpanBERT. Instead of using only the masking of individual words, we propose that we want to mask a contiguous spans of words in the passage. So we are trying to mask out all these possible answer spans from the passage as our training objective. And the second idea proposed in SpanberT is-- because at the end of it, it goes around to predict an answer span. So essentially, we're actually essentially try to predict two endpoints as well as the answer. SpanBERT greatly outperformed Google BERT and other BERT basically across all of the datasets. This number has already exceeded even the human performance on SQuAD. So that really tells us that OK, even if we are not going to increase the model size or increase the data, by designing better pre-training objectives can also go a long way and do a much better job at least in the question answering and the reading comprehension datasets. OK. So so far, we've demonstrated that by using BiDAF model and by using BERT models, we can get a very good performance on the SQuad dataset. The performance of a BiDAF model drops from 75.5 to even like 30%. So for you, like this kind of attack, the performance level just dropped to very low, like 4.8%. So here is another paper that actually just came out in 2020. So there has to be a lot of evidence showing the similar things. So today we compute a very good reading comprehension data set on the individual data sets. But these systems trained on one dataset basically cannot really generalize to other datasets. So it basically really cannot generalize from one dataset to another dataset. Open-domain question answering is a problem that-- so it's different from reading comprehension that we don't assume a given passage. So this problem, there isn't any single passage, so we have to answer questions against a very large collection of documents or even the whole web documents. So if you look at the example of Google example I showed at the beginning, so these techniques will be used. Chris, is there any question I should answer at this point here? I think you can go on. very useful in the practical applications. Open domains is just in contrast to closed domains that deal with questions under a specific domain. So the idea is that let's take a question-- OK, so here, the article is trying to answer questions using a very large collection of documents such as the Wikipedia. So we can just decompose this problem into, as I just mentioned, in our retrieval and the reader component. And finally the reader basically takes the question and takes this type of the passages and finally returns the answer. are 20 million passages in Wikipedia, so it's actually very hard to model this part. The idea is that we can also really just train the retrieval part by using two BERT models using only the question and answer pairs. And this model kind of works really well, and it can largely outperform the traditional IR retrieval models. So here is actually a really nice demo. So again, the database ferries the whole Wikipedia. And you can see that if you ask a question of who tells Harry Potter that he is a wizard in the Harry Potter series, the system had really found out the correct article. answer, which is exactly what you have seen here from the Google example here. So the answer would be the Rubeus Hagrid, who is actually the person who told tells Harry Potter that he's a wizard. OK, I'm going to skip this slide. And then finally, very quick. Some researchers have demonstrated that maybe you don't even need this retrieval stage. If you just use a very large language model, you can also just use all open-domain questions answering. DensePhrases.dense vectors. So what you just need to do is just to do this kind of nearest neighbor search in the answer space. You just encode all the phrases in Wikipedia, encode them using vectors. And by taking a question, you can just encode this question in a single vector. And then we can just do the nearest neighbors search and then it can directly give you the answer. So this could be very fast and they can even run on the CPUs without needing to run a very expensive deep neural network. Danqi can stay for a bit to answer questions, but not forever. Because she doesn't have a Stanford login, we're going to do questions inside Zoom. So if you'd like to ask a question, if you use the raise hand button, we can promote you so that you appear in the regular Zoom window and can just ask questions and see each other. If you hang around and don't leave the Zoom for more than a few minutes, maybe we'll just promote everybody who's still there into people in theregular Zoom for some bits of discussion. showed that if you only use a very few examples, you can also do open-domain question answering pretty well. But this kind of model is huge, like what number? How many parameters I forgot in the GPT Stream model, yeah. So this is my answer, is that if we can leverage a very large and very powerful pre-trained language model, there is a possibility that we can actually do the question answering well with only a small number of examples. And also there are some other promising directions, including unsupervised question answering. Most existing question answering datasets or reading comprehension datasets have been collected from Mechanical Turk. So it is very difficult to avoid some kind of artifact though, like a simple clues or superficial clues. So that's the reason that more specialized models that have been trained very well in one data set, it's very easy to pick up these kind of clues, and is very hard to generalize this kind of thing to another data set. What about the natural questions data set? Doesn't that avoid that objection? Yeah. Natural questions will be much better, but there are some other issues. Real questions that are asked by users. So it kind of avoids this kind of superficial artifact between the question and the passage. But there's some other issues that people like to ask some common questions. So this model basically performs on par with the dense passage retrieval model. But it is actually-- so I skipped one slide. So using a T5 model has a better data retrieval. This actually performed really well. So I will just say dense phrases work basically similar in this block. But compared to this generative model, we're still a few points behind. The goal of this project is trying to ingest all the phrases in the Wikipedia. So these conversations are built using the training set of the question answering datasets. So the model is definitely able to generalize from theTraining set to all the Wikipedia phrases. So it doesn't have to have seen the phrase then. Is Iskind of the intuition behind the dense phrases apart from the answers will probably be in close proximity? And what if the datasets has answers to a specific question like very far from the actual information? Say, the answers to your question may not resided inclose proximity to the words in the question. This is similar to the retrieval or the dense passage retrieval. So you still try to train on passage representation, here is the phrase representation. But the representation is only using the training set of the question answering datasets. But by taking the encoder and then we are going to encode all the representation, all the passages of phrases in Wikipedia. And then we can use text as the representation and can actually generalize well for the unseen questions. Yeah. So the question is what if the nearest neighbor search doesn't return the answer? while asking a question if you want. Next person is [AUDIO OUT]. All right. Thank you for taking the time to teach this. My question is kind of quick. So you mentioned work, they brought up a set of relatively simple questions that show how brittle or poor the current models can be. Did that kind of change the community to improve how to evaluate the models? Because they're actually doing pretty poorly on some of those, right? Yes. OK. Next is-- Hey, how is it going? Thanks so much for the lecture. solve the easy problems. Do you think that the current sort of benchmark data sets are maybe a little bit too easy for- [INTERPOSING VOICES] Or just like that. Just try to break the current system, come up with some harder questions. So we actually really need some kind of dynamic evaluation and also introduce more just kind of adverse examples, harder questions also, things like that, yeah. Are you still game for a couple more questions? Sure. I did want to mention it is 9:10 PM on the East Coast. sure if I really have the answer, but I also want to quickly mention that quantization has been definitely a very useful technique to make the model smaller. So we have been also exploring the quantization in the DensePhrases project recently because the storage has been still very large. Yeah, I'm not sure about the question about the connection between quantization and also pre-training. I am not sure. Thank you. Next question is-- Hi Danqi. Danqi is too modest to mention that she was one of the co-organizers of the EfficientQA task. OK. yeah, I guess I'm just a little worried about who comes up with the test cases? Who determines what the right answer is? I mean, we will have more discussion of toxicity and bias coming up very soon, including actually Thursday's lecture as well as a later lecture, not specifically about QA though. OK. Next person is-- Thank you for the lecture. Yeah, my question is also related to the open domain question answering. So I was just wondering how much of the learning side of domain sort of generalization or domain alignment techniques can be combined with language level, like question answering? on the same page. So I have seem some work sort of trying to learn some kind of disentangled representations that can better generalize to the different domains on adversarial examples. And the question is whether this technique can be generally applied to question answering or? Yeah, I'm just wondering to what extent will they work. Because I think language has a lot of specific things like dependency and other sorts like these techniques does not actually take care of. But it's definitely an interesting point. The key difference between the generative model and the extractive model is that for generative models, you can actually leverage more input passage together and do the generation. So the RAG model actually doesn't perform as well as this model. By the way, I also want to mention R AG model is actually not doing better than DPR because it's base model, this is large model. So these numbers are a little bit confusing. So it's actually basically really on par. Their base perform similarity. can you use generative models to generate the span? You can. You can definitely do that. The model is very large, like 11 billion parameters. So the parameters are basically trying to memorize a lot of information that has been. Because the model has been pre-trained on the text and also has been fine-tuned. All right, thanks. Do you want to call it a night or do you want one more question? Either way, yeah. It's up to you. There is a lot of interest in extending these question answering techniques or just encoding techniques, embedding techniques to recommender systems. The first question is whether these techniques can be generalized to other languages. If we have, actually, I think that the techniques could be generally applied to other language. There has been a lot. of work trying to do cross-lingual question answering and stuff like that. But there has been some constraints that a. lot of models or systems that I described here actually require very strong pre-trained language model. and also requires lots of training examples for the Pure-DSS.

ROUGE-1: 37.51, ROUGE-2: 36.33, ROUGE-L: 35.41
BERTScore: 64.96

==============================================
==================== [41/100] ====================
Summary:
 homework two is out now. This weekend sessions will be having some more background on deep learning. We're also gonna be reaching, uh, releasing by the end of tomorrow, what the default projects will be for this class. Um, and those proposals will be due, um, very soon, er, in a little over a week. Are there any other questions that people have right now? Yeah. The assignments, [inaudible] are they limited to TensorFlow? asked the question if, if the assignment is limited toTensorFlow. out on Piazza and double-check that, but I'm pretty sure any Oliver auto-graders is just set up for TensorFlow. We also released a tutorial for how to just sort of set up your machine last week. So, if you're having any questions with that, that's a great place to get started. Um, I'll believe you guys also should have access to the Azure credit. If you have any questions about getting setup without feel free to use the Piazzas channel. "We wanna be able to deal with really complex, um, information about customers, or patients, or students, where we might have enormous state and our actions spaces. And so, when we started talking about those, I was arguing that we either need representations of models. T, T or R or a state-action values Q, or V, or our policies," he says. "With the idea being that we may in fact never encountered the exact same state again. You might never see the exactsame image of the world again, um" as, um, a mean squared error. So, we can define our loss j, and we can use gradient descent on that to try to find the parameters w that optimize. And just as a reminder stochastic gradient descent was useful because when we could just slowly update our parameters as we get more information. And that information now could be [NOise] in the form of episodes or it [NOISE] could be individual tuples. When I say a tuple, I generally mean a state-action reward next state tuple. otherwise we wouldn't have to be doing all of this learning. And so, the two ways we talked about last time was inspired by a work on Monte Carlo, or on TD learning is we could either plug-in the return from the full episode. Or we could put in a bootstrapped return. So, now we're doing bootstrapping. Where we look at the reward, the next state, and the value of our next state. And in this case we're using a linear value function approximators for everything, which gave us a really simple form of what the derivative is. the last layer being a linear combination of those features. For most of the time when we're talking about deep RL with, um, a deep neural networks represent the Q function. So, linear value function is often really works very well if you're the right set of features, but is this challenge of what is the rightSet of features. Um, and there are all sorts of implications about whether or not we're even gonna be able to write down the true p- um, value function. to linear value function approximators. The intuition is that if you want to have sort of an accurate representation of your value function, um, and you're representing it by say, uh, local points around it. For example, with the k-nearest neighbor approach. then the number of points you need to have everything be close like in an epsilon ball scales with the- the dimensionality. Um, but they haven't far been used for in a very widespread way. is sort of by their name. Um, when you use this type of approximation, you don't- they're guaranteed to be- to be a non-expansion, which means that when you combine them with a bellman backup it's guaranteed it'd still be a contraction. So, that means these sort of approximators are guaranteed to converge compared to a lot of other ones. All right, but they're not gonna scale very well and in practice youdon't tend to see them. Deep neural networks are artificial connections with artificial neural networks inside our brain. They are used in unsupervised learning like predicting whether or not something is a cat or not or, you know, an image, uh, of a particular object, um, or for regression. They combine both linear and non-linear transformations, and they need to be differentiable if gradient descent is to be used to fit them. In the last 5 to 8 years, there's auto differentiation. So, you don't have to derive all of these gradients by hand instead. The question is about how for- for ReLU, there's a lot of it where it's flat. If your gradient is zero then your gradients can vanish there. We're not gonna talk about this at all in class but there's certainly a problem is you start having very deep neural networks. Um, but because of some of these functions you can sometimes end up sort of having, um, almost no signal going back to the- the earlier layers. We'll talk- we'll talk some about that in sessions. about what we're doing with linear value function approximators, it was clearly the case sometimes that you might have too limited features and you just wouldn't be able to express the true value function for some states. That will not occur for, um, uh, deep neural network if it is sufficiently rich. Another benefit is that potentially you can use exponentially less nodes or parameters compared to using a shallow net which means not as many of those compositions to represent the same function. Then the final thing is that you can learn the parameters using stochastic gradient descent. use similar sorts of input on our- our robots in our artificial agents. So, if you think about this, um, think about there being an image, in this case, of Einstein. Um, and there's a whole bunch of different pixels on Einstein. Let's say it's1,000 by 1,000. So,. we have 10 to the 6 pixels. This standard is often called feedforward deep neural network. Um,. you would have all of those pixels,Um, and then they would be going as input to another layer and so you can get a huge number of weights. Convolutional neural networks try to have a particular form of deep neural network that tries to think about the properties of images. So, in particular, images often have structure, um, in the way that our- our brain promises images also has structure and this sort of distinctive features in space and frequency. Having so operators again here are like our functions, h1 and hn, which I said before could either be linear or nonlinear and then convolutional network learn a particular structures for those. instead of saying, "I'm going to have totally different parameters each taking in all of the pixels," I'm gonna end up having sort of local parameters that are identical and then I apply them to different parts of the image. Because ultimately, the point of doing this is gonna be trying to extracting features that we think are gonna be useful for either predicting things like whether or not, you know, a face isn't an image or that are gonna help us in terms of understanding what the Q function should be. this case, if you have an input of 28 by 28 and you have a little five-by-five patch that you're going to slide over the entire image, then you're gonna end up with a 24 by 24 layer next. So, one thing is instead of having our full x input, we're just gonna take in- we're gonna direct different parts of the x input to different neurons which you can think of just different functions. Um, but the other nice idea here is that we'regoing to have the same weights for everything. of different parts of the image. So, this is sort of what that would look like. You sort of have this input, you go to the hi- um, the hidden layer and, yeah, you're sort of do- also down-sampling the image, um. Why would you want to do this? Well, we think that often, the brain is doing this. It's trying to pick up different sort of features. In fact, a lot of computer vision before deep learning was, um, trying to construct these special sorts of features, things like sift features or other features. then you could apply these different filters on top of it, which you can think of as trying to detect different features, and then you move them around your image, and see whether or not that feature is present anywhere. So you can do that with multiple different fype- types of filters. These give you different features essentially that are been extracted. The other really important thing in CNNs, is what are known as pooling layers. They are often used as a way to sort of down-sample the image. So, the final layer is typically fully connected. In 1994, we had TD backgammon which used Deep Neural Networks. And then we had the results that were kind of happening around like 1995 to maybe like 1998, which said that, "Function approximation plus offline off policy control, plus bootstrapping can be bad, can fail to converge" And so I think for a long time after that, the, the community was quite cautious about using them because they were clearly, even simple cases where things started to go really badly with function approximation. And so, perhaps it was natural that, like, around in like 2014, DeepMind and DeepMind combined them and had some really amazing successes with Atari. In practice, we can still get pretty good policies out. Now, we often don't know if they're optimal. Often, we know they're not optimal because we know that people can play better, but that doesn't mean that they might not be pretty good. Um, I think that some of the issues that were coming up in 1995 to 1998 in terms of convergence, there are some algorithms now that are more true stochastic gradient algorithms. They may not be guaranteed to converge to the optimal policy, um, so there's still lot of work to be done. I think there's also a couple algorithmic ideas that we're gonna see later in this lecture, that help the performance kind of avoid some of those convergence problems. Um, ah, they are doing deep learning in, in this case, Deep-Q Learning. And so it can still be very unstable, but they're gonna do something about how they do with the frequency of updates to the networks, to try to make it more stable. We'll see how it works here. Anyone else? Okay, cool. An Atari game generally, doesn't have a really high dimensional action space. It's normally somewhere between like four to 18, depends on the game. In these games, you typically need to have velocity. So, because you need velocity, you need more than just the current image. So what they chose to do is, you'd need to use four previous frames. So this at least allows you to catch for a velocity and position, observe the balls and things like that. But it's not always sufficient. Can anybody think of an example where maybe an Atari game, I don't know how many people played Atari. In a paper from 2015, a group of researchers used the same architecture and hyperparameters across all 50 games. They didn't have to use totally different architectures, do totally different hyperparameter tuning for every single game separately. It really was the sort of general, um, architecture and setup was sufficient for them to be able to learn to make good decisions for all of the games. And the nice thing is that, I think this is actually required by nature. They, they released the source code as well. that if you have s, a, r, s prime, a prime, r prime, double prime. If this is a deterministic system, the only difference between them will be R. So, so these are highly correlated, this is not IID samples when we're doing updates, there's a lot of correlations. Um, and also this issue with non-stationary targets. What does that mean? It means that when you're trying to do your supervised learning and train your value function predictor, um, it's not like you always have the same v pi oracle. standard approach, just uses a data point. In the simplest way of TD Learning or Q-learning, you use that once and you throw it away. Even though we're treating the target as a scalar, the weights will get updated the next round which means our target value changes. So, even though it's the same data point as before, it's gonna cause a different weight update. So this is nice because basically it means that you reuse your data instead of just using each data point once, you can reuse it. learn to model, a dynamics model, and then the planning for that which is pretty cool. So, this is getting us closer to that. But we don't wanna do that all the time because there's a computation trade-off and particularly here because we're in games. There's a directtrade-off between computation and getting more experience. Um, and if it's a fixed size buffer, how do you pick what's in it? Um, is it the most recent and- and how do we get things out? It's a really interesting question. Different people do different things. strike the right balance between continuing experience like new data points versus re-flagging it. Can we use something similar to like exploitation versus exploration. Um, essentially like with random probability just decide to re-flag [inaudible]. The question is about how would we choose between, like, what, um, you know, getting new data and how much to replay et cetera, and could we do that sort of as an exploration-exploitation trade-off. Could certainly imagine trying to optimally figure this out but that also requires computation. use in that value of S prime for several rounds. So, instead of always update- taking whatever the most recent one is, we're just gonna fix it for awhile and that's basically like making this more stable. Because this, in general, is an approximation of the oracle of V star. What this is saying is, don't do that, keep the weights fixed that used to compute VS prime for a little while and that just makes the target, the sort of the thing that you're trying to minimize your loss with respect to, morestable. our w minus, and then we use stochastic gradient descent to update the network weights. So, uh, I guess two questions like intuitively, why does this is help and, like, why do it make it more stable? And then, beyond the stability, is there any other benefits? In terms of stability, it helps because you're basically reducing the noise in your target. If you think back to Monte Carlo, um, there instead of using this target like this bootstrap target where we're using GT. This is just reducing the noise and the target that we're trying to sort of, um, if you think of this as a supervised learning problem, we have an input x and output y. The challenge in RL is that our y is changing. If you make it that you're- so your y is not changing, it's much easier to fit. Uh, assuming we want to do [inaudible] approximator. Is there something that's specific to the deep neural networks?. In practice, do people have some cyclical pattern and how can they refresh the- the gradient that's used to compute, uh, the gradients? Yes, yeah there's often particular patterns or- or hyper- it's a hyperparameter choice of how quickly and how frequently you update this. This has no guarantees of convergence still. This is hopefully gonna help but we have no guarantees. It will trade-off between propagating and not propagating. It's a great question, and these sort of Q learning are not true gradient descent methods. information fester, um, and possibly being less stable. If n is infinity, that means you've never updated it. There's a- there's a smooth continuum there. William? Uh, we notice, like, for w, there are better initializations than just like zero, uh, if you take into account, I guess like the mean and variance. Uh, would you initialize w minus just two w or is there like an even better initialization for w minus? Yeah, his questions is about, you know, the- the impact of how we, um,. uh, initialize w ca- can matter. E-greedy. So, this is what it looks like. You sort of go in and you do multiple different convolutions. They have the images, um, and they do some fully connected layers and then the output a Q value for each action. As you'd hope, as it gets more and more data, it learns to make better decisions. But one of the things people like about this a lot is that, uh, you can learn to exploit the reward function. Uh, so in this case, it figures out that if you really just want me to maximize the expected reward, what the best thing for me to do is to just kind of get a hole through there. the reward, it'll- it'll learn the right way to maximize the reward given enough data. When they did this, they then showed, um, some pretty amazing performance on a lot of different games. Many games they could do as well as humans. Um, and so this is really cool that sort of it could discover things that maybe are strategies that people take a little while to learn when they're first learning the game as well. Yeah? This might become a little bit of [inaudible] but is there a reason to introduce a pulling layer? Puling layer? There might be one in there. architecture, um. The question is whether or not there's a pulling layer in there. There has- they have to be going from images all the way up. But they have the complete architecture. So, the next thing that you can see here is that, um, they got sort of human level performance on a number of different Atari games. There's about 50 games up here. Um, there's been a lot of interest in these sort of games on the bottom end of the tail which often known as those hard exploration games. Replay is hugely important and it just gives us a much better way to use the data. Using that fixed Q here means you seem like a fixed target. You do replay and suddenly you're at 241. Okay, so throwing away each data point what- after you use it once is not a very good thing to do. But you could certainly imagine trying linear plus replay and it seems like you might do very well here, it might depend on which features you're using. There's some cool work, um, over the last few years looking also at, uh, whether you can combine these two. like Bayesian linear regression which is useful for uncertainty. Other people have just done linear regression where the idea is you- you sort of, um, uh, deep neural network up to a certain point. So, that can be much more efficient, but you still have a complicated representation. Some of the immediate improvements that we're going to go through really quickly here is, um,. Doubled DQN, prioritize replay, and dueling DQn. These are some of the early really big big big improvements. double DQN is kind of like double Q learning, which we covered very briefly at the end of a couple of classes ago. The thing that we discussed there was this sort of maximization bias, is that, um, the max of estimated state action values can be a biased estimator of the true max. So, this is a pretty small change, it means you have to maintain two different networks or two different sets of weights, and it can be pretty helpful. It's a fairly small change. change, it's very similar to what we were doing already for the target network, network weights. It turns out that it gives you a huge benefit in many, many cases for the Atari games. The second thing is prioritized replay. In Mars Rover we had this really small domain, we are talking about tabular setting through just seven states, and we're talking about a policy that just always took action a1 which turned out to mostly go left. That's one idea, and that's sort of a direct lift up from sort of, you know, double Q learning. So, let's say you get to choose two replay backups to do. Maybe it doesn't matter if you can just pick any of these, you're going to get the same value function no matter what you do. So, are there two- two updates that are particularly good, and if so, why and what order would you do them in? [NOISE] Hopefully you had a chance to think about that for a second. First of all, does it matter? So, I'm going to first ask you guys, uh, the question. Vote if you think it matters which ones you pick. All right. You've got to back-propagate from the information you're already [NOISE] have on step one to step two. So, if you pick, um, backup three, so what's backup three? It is, S2, A1, 0, S1. So that means now you're gonna get to backup and so now your V of S2 is gonna be equal to one. So it definitely matters. It matters the order in which you did, do it. have changed. Um, so ordering can make a big difference. Uh, so not only do we wanna think about like, what, um, was being brought up before but I think to say like what should we be putting in our replay buffer. What order should be in a replay buffer but also what order do we sampled them can makea big difference in terms of convergence rates. There's some really cool work from a couple of years ago looking at this formally of like how, at what the ordering, matters. might wanna be careful about the order that we do it and- so, their, intuition, for this, was, let's try to prioritize a tuple for replay according to its DQN error. So, if you have a really really big error, that we're gonna prioritize, updating that more. One method basically takes these priorities, raises them to some power alpha, um, and then normalizes And then that's the probability, of selecting that tuple. So you prioritize more things that are weights. prioritise replay versus, um, I think this is prioritise replay plus D, Um, double DQN versus just double D QN. Most of the time,Um, this is zero would be, they're both the same underneath. Above means that prioritize replay is better. Most, the time prioritize Replay is better and there's some hyper parameters here to play with. And it's certainly useful to think about, you know, we're order might matter. All right. We don't have very much time left so I'm just gonna do, short through this just so you're aware of it. could be super tempting to try to start, by like implementing Q learning directly on the ATARI. Highly encourage you to first go through, sort of the order of the assignment and like, do the linear case. Even with the smaller games, like Pong which we're working on, um, it is enormously time consuming. It's way better to make sure that you know your Q Learning method is working, before you wait, 12 hours to see whether or not, oh it didn't learn anything on Pogge.

ROUGE-1: 40.85, ROUGE-2: 39.40, ROUGE-L: 39.12
BERTScore: 70.39

==============================================
==================== [42/100] ====================
Summary:
 salt makes up a tiny part of any bread though which has a huge effect on it and most bread is made with salt nowadays. salt has a tightening effect on the gluten it strengthens the dough and makes it more cohesive as yeast consumes the sugars in the dough. salt helps with controlling fermentation it draws moisture through the cell walls of yeast in a process called osmosis. salt can help with preserving the color and flavor of flour unbleached flour has carotenoid pigments which give the crumb of our bread the creamy color and a wheaty aroma.  salt really slows down the enzymatic activity it prevents amylase from breaking down starch into maltose that's why the loaf on the right is completely white there is no sugar in it and whilst too much salt prevents the enzymes from making the sugar not enough salt will make the yeast eat through all the sugar that will also not leave much to caramelize the crust. The bread in the middle with right amount of salt has the rightamount of caramelization so the bread with no salt gained less volume than one wood salt and instead of rising vertically it has spread out more sideways. is quite dry and spongy and it's a little bit rough it almost feels like a dishwashing sponge and taste wise it's pretty bland it's not offensive but it doesn't have any character to it of course the sander loaf is nice and soft it is exactly what you would expect from a regular white bread. Soakers are a great way of adding seeds and grains to your bread often these Seeds and grains are quite hard you don't want to bite down on a piece of barley and break a tooth. starter or yeast you would mix your flour water yeast or starter and then leave to ferment for several hours ahead of time before making the final dough pre-ferments add a great deal of flavor improve the texture and the keeping quality of your bread. Normally brief mints don't contain any salt that's why in hot kitchens or hot climates they can ferment too rapidly. There are ways of controlling this you can lower the temperature of the briefment you can place it in a cooler area or even lower the hydration of it by adding salt.

ROUGE-1: 31.54, ROUGE-2: 30.70, ROUGE-L: 31.46
BERTScore: 60.37

==============================================
==================== [43/100] ====================
Summary:
In this section, we're going to talk about the relativistic Doppler effect. And we make good use of our space-time diagrams, which we discussed earlier. So the question is not how this observed-- how this is seen by the source but how it is being seen by an observer. So we have to apply Lorentz transformation. So in the last section of Special Relativity, we'll look at the effect on the speed of light, and how it relates to space and time. We find delta t prime is equal to gamma delta t minus v over c squared delta x. Tau prime is then gamma times c tau over c minus v times 1 minus v square over c square. And we find then-- this is a little bit of an algebra exercise here-- that the period now is given by 1 plus beta over 1 minus beta square root of that times tau. And the frequency is the inverse. So we just calculated relativistically how the period and the frequency of a wave is Lorentz transformed.

ROUGE-1: 52.24, ROUGE-2: 47.44, ROUGE-L: 47.91
BERTScore: 75.45

==============================================
==================== [44/100] ====================
Summary:
The all new E1 racing series aims to prove the potential of electric power in the Marine industry. The boats can reach 50 knots that's around 93 km per hour so how do they reach those speeds? Will Smith is here he is who owns our team and uh we're looking to throw down hopefully some good times to get our first win all right have fun all right yeah you did hear right Will Smith owns this team and he isn't the only celebrity backer before the main event tomorrow. above the water to have the speed that's right yeah exactly if you're on the edge of the foil and you're as high as possible it's less drag in the water so you're getting the more the most kph um but you know there's some techniques that are coming into play as we learn these boats on what's fast it's really tough to stay on the foil. Will Smith had a bit of a hard time getting into there can we fire it up of course we can yeah we we can't go to the full full load because we're in the garage. drawing too much power while and while they're lift and that lifts them up onto the foils. The lift is on the left hand side of the of the wheel and the trim on the right hand side and it's we're just altering that by a few points depending on wave conditions or whether we're going into the corner this sport is still in the very early stages the nine teams have the same boat but they're working out how to push the tech and try to get ahead of the competition. bad as he does and so we're doing everything we possibly can to make that happen doing everything means working late into the night to make sure the boats are in the best condition for tomorrow's races. E1 is a brand new racing concept um it's foiling boats with an electric motor in a format that's never been done before course here is basically a big figure of eight but it's a little bit more complicated with the long wrap and the stars and things like that so you'll see a series of single point turns and then turns that have larger apexes. attracted some big name investors despite only being in his first year. There are challenges ahead can it keep those celebrity backers and can it build a big audience for this high-tech reing. I think the ground workor for this Championship is amazing you know the names behind it now are incredible. I've heard some good rumors of teams coming in for next year as well so I Think the format is really exciting I think a lot of people are really interested in excited about the new technology and also the sustainability message.

ROUGE-1: 46.15, ROUGE-2: 44.92, ROUGE-L: 44.70
BERTScore: 68.95

==============================================
==================== [45/100] ====================
Summary:
Marginal rate of substitution of good 1 with respect to good 2 is infinity. When we are talking about marginal rate of. substitution of milk and cola, it would still be infinity, but marginal rate. of substitution. of cola withrespect to milk is 0.75. So, when we do not say when we say just MRS, we are not using any particular term, you can use both way. Instead of getting x you get 1 by x, and why? Let us see what do we mean by marginal rates of substitution mathematically. To get 1 good you will have to give up the other good, both what we are assuming that both these items are good, means they give certain satisfaction or certain you know utility to the person, and what we want. We want this person to have the same level of utility by consuming one of these two bundles. So, of course, when we are increasing the amount of 1 good to bring what will happen using this, if we use the monotonicity what will happening. If more of 1Good what is happening let us see. From here you are moving here in this direction. see, that MRS is given as a positive number, that only means that the author has introduced a negative sign here to convert the MRS into apositive number. So, it does not matter. Is it clear? Do you know the answer to this question? If so, please email us at jennifer.smith@mailonline.co.uk. If you don't, we would like to hear from you. Please send us a photo of your MRS and we will send it to you.

ROUGE-1: 33.95, ROUGE-2: 29.12, ROUGE-L: 29.87
BERTScore: 65.60

==============================================
==================== [46/100] ====================
Summary:
in this video we're going to discuss what externalities are in economics. An externality is when you do something that affects the well-being or the good of another person or a company but you're neither harmed or rewarded for what you did to that person so the externalities can be positive they can be negative. A negative externability is whenyou've harmed someone you've done something to somehow impose a cost on someone or some some company or something and you haven't reimbursed that person. of the wall really loves to play Britney Spears music at 3:00 in the morning. They're creating cost they're doing harm to you but they haven't reimbursed you now. A positive externality is where you are doing something that doesn't harm someone it actually benefits that other person you're doing something good that just as a side test like it's as a tangent it's actually helping some other person or people and so but those people aren't turning around and compensating you for it right. If you're not receiving the full social benefit you're just getting your own private benefit basically things where there's a positive externality the good is going to be under supplied. If you were actually paid if people said hey I really like what you did you might be more likely to get a flu shot. If your neighbor is trying to sell their house they have a for sale sign up they might appreciate if you went out and really did a great job maintaining your home they would really just love that because then when people come to see their house which is for sale that would increase the value of their home. would help them sell their home because the neighborhood would look great but you don't have an incentive to do that why because you're only considering your own private benefit. If you do something nice and for your home then that would help their their home's value but they wouldn't turn around and compensate you necessarily. So that's a positive extra ality and for that reason these type of goods that have a positive externality would be undersupplied in situations where you have a negative externally like pollution or something like that.

ROUGE-1: 52.79, ROUGE-2: 51.66, ROUGE-L: 52.79
BERTScore: 70.80

==============================================
==================== [47/100] ====================
Summary:
Political philosophy is the oldest and most fundamental part of political science. Its purpose is to lay bare the fundamental problems, the fundamental concepts and categories which frame the study of politics. Political philosophy can boast a wealth of heavy hitters from Plato and Aristotle to Machiavelli, Hobbes, Hegel, Tocqueville, Nietzsche, and so on. The study of political philosophy often begins as this course will do also, with theStudy of the great books of our field. The best way to learn what political philosophy is is to study and read the works of those who have shaped the field. Yale professor: Study of great thinkers of the past can degenerate into a kind of antiquarianism, into a sort of pedantry. The great works provide us with a repository of fundamental or permanent questions that political scientists still continue to rely on in their work, he says. "The ideas of economists and political philosophers, both when they are right and when they're wrong, are more powerful than is commonly understood," John Maynard Keynes wrote in 1935. "We are called to read and listen to the greatest thinkers, and then enter into a conversation with one that makes it possible for the readers to disagree with one another," he adds. What is justice? What are the goals of a decent society? How should a citizen be educated? Why should I obey the law, and what are the limits, if any, to my obligation? And of course, the all important question, even though political philosophers and political scientists rarely pronounce it, namely, quid sit deus, what is God? Does he exist? And what does that imply for our obligations as human beings and citizens? Those are some of the most basic and fundamental problems of the study of politics. A regime indicates a form of government, whether it is ruled by the one, a few, the many, or as more common, some mixture of these three ruling powers. Regimes are necessarily partisan, that is to say they instill certain loyalties and passions in the same way that one may feel partisanship to the New York Yankees or the Boston Red Sox. The regime is always something particular. It stands in a relation of opposition to other regime types, and as a consequence the possibility of conflict, of tension, and war is built in to the very structure of politics. Fierce loyalty, partisanship: it is inseparable from the character of regime politics. Henry Adams once cynically reflected that politics is simply the "organization of hatreds" This raises the question whether it is possible to transform politics, to replace enmity and factional conflict with friendship, he says. Is such a thing possible? It can't be ruled out, but such a world administered by international courts of law, by judges and judicial tribunals, would no longer be a political world. The study of regime politics is in part a study of the distinctive national character types that constitutes a citizen body. You can't understand a regime unless you understand, so to speak, what it stands for, what a people stand for. This raises a further set of questions that we will consider over the term. How are regimes founded, the founding of regimes? What brings them into being and sustains them over time? For thinkers like Tocqueville, for example, regimes are embedded in the deep structures of human history. Political philosophy is an imminently practical discipline, a practical field. Its purpose is not simply contemplation alone: it is advice giving. None of the people we will study this semester were cloistered scholars detached from the world. But the great thinkers were very far from being just, so to speak, detached intellectuals, writes David Frum, a professor of political philosophy at the University of California, San Diego, and author of "The Politics of Statecraft: A History of Political Philosophy" The study of political philosophy is in many ways a kind of immersion into what we might call today comparative politics. A regime, as I've said, constitutes a people's way of life, what they believe makes their life worth living. What has or ought to have a claim on our loyalty and rational consent? What is the best regime? Even to raise such a question seems to pose insuperable obstacles. But the good citizen, Aristotle goes on to say, is not the same as the good human being, right? Philosophy will never feel fully or truly at home in any particular society. The philosopher can never be truly loyal to anyone or anything but what is best. In the best regime, if we were to inhabit such, political philosophy would be unnecessary or redundant. This is why political philosophy is always and necessarily a potentially disturbing undertaking. Those who embark on the quest for knowledge of thebest regime may not return the same people that they were before. You may not have realized it when you walked in to this class today, but the study of political philosophy may be the highest tribute we pay to love. see you back, and have a very good but thoughtful September 11^(th). See you back on 9/11/11. I'll see you back in a week or so. Thanks for your support and good wishes. I love you all, and see you on 11/11 /11. Back to Mail Online home. back to the page you came from. See you in a month or so, and I'll be back to see you in the U.S.

ROUGE-1: 34.40, ROUGE-2: 30.44, ROUGE-L: 28.69
BERTScore: 64.95

==============================================
==================== [48/100] ====================
Summary:
Ahern: I have never had an exam where I had fewer questions. There were maybe 10 questions I got on the exam and that was for a class of this side. So I hope that's a good sign. I don't like to have exams out too long before you get a chance to look at them. Ahern: Why do I videotape my exams? I find it decreases the looking around factor by a factor of about 100. [student laughs] It does, Ahern says. Professor Ahern videotapes students' answers to questions. He says he finds most students are honest. But he has had a handful of situations where dishonesty has been an issue. Ahern: "There's just too many eyes here and not enough of our eyes" to see what's going on. "I will post the key outside my door after we give the exams back," he says. "That's something that you should know. I know I will get some answers on that that don't say none" Ahern: How can you have two apparent Kcats? and the answer is it depends on how you calculate the concentration of the enzyme. If you take Vmax and divide it by the total concentration of enzyme, you will see a reduced Kcat compared to the uninhibited enzyme. The fewer the questions I have, the more points each question is worth. And so people are always worried about that. So I have to try to strike a balance. And this balance, I think works fairly well. at least who indicated time problems. Next term, the format of the exam changes in 451. Most people like 451 better because the maximum number of points on a question I think is 3. Professor: We have a lot of shorter answer questions. But we're working problems, we have to work through problems and that's why. If you're going to spend a fair amount of time on something, it should be worth more points. But literally, I rarely have much of an issue with the other two exams. Ahern: I hope everybody got how I start my lecture. The first thing I say is "Okay folks, let's get started." I don't live consciously, I just blurt it out. Alright, well let's turn our attention. Thank you for your feedback. That's not a lot of feedback, but I do appreciate feedback and I'm always happy to listen to what you have to say about exam formats. And I do take suggestions. The suggestion about having other possible choices is one, as I said, I've done and I won't rule out. Last time I talked about, in some detail, mechanisms by which these S1 proteases worked. And I hope you've had a chance to look through those mechanisms and sort of lay things out. Because you're going to see when you do that, you will see similarities in mechanisms that other enzymes use to catalyze reactions. And so using genetic techniques today, it's very easy to alter the genetic code for any of these proteases and change which amino acid is presence in the active site. at any given place. Researchers have changed, for example, a serine residue of 221, which is the serine, gives it its name, to an alanine. Or changing the histidine position 64 to anAlanine or changing aspartic acid at position 32 to analine. And when they do that, and they compare the activity, so this is the log of Kcat. So Kcat of course is a good measure of velocity and the wild type enzyme has an activity up here. One 10 millionth as active when that serine is changed to analanine. Aspartic acid residue is not as important as the other two. The other 2 are much more important. The question is A, would I see activity? and B, might it even be better? and the answer is it's all possible, of course, but my question is what if I mean if I go from serine to alanine, at least they look similar, but they're not chemically similar. What if I change theserine to a threonine for example? Threonine also has an hydroxyl group. production would be, in this case, that it would not be, because we're thinking about very precise orientations inside of that active site and threonine is going to have a slightly different configuration. It's possible it will be better but my suspicion is it will probably be somewhere in here. And his question is also good because when we think about the process that gave rise to this proteases in the first place, they were mutation and selection. We think of mutation as mostly being detrimental because most mutations give rise to things that aren't functional, kind of like what these individual ones are here. Ahern: There are other types of proteases that behave very much like S1, well like serine proteases. One of these classes is known as cysteine proteased. Ahern: This class of protease is essentially identical to that of theserine protease, at least for our level of understanding. He says the aspartyl proteases, at first glance, look somewhat different. But those similarities aren't all the way through like we see with the cystine prote enzymes, he says. Business of creating nucleophiles is not unique to proteases. One of these is an enzyme we've been talking about some already, that's the carbonic anhydrase. Students: Would you like a joke? Ahern: Yeah. Okay, so let's stretch. So this my, this is my magic genie joke, alright? This is not a computer joke. Depends on where you lean, I suppose. "This is really awesome, "I'm a really powerful guy. "I want every woman to love me." and poof, he turns into a box of chocolates. Carbonic anhydrase can catalyze the conversion of a million molecules of substrate into product per second, per enzyme. Most enzymes have a fairly narrow pH range where they work that's ideal. But this guy tops out at about pH 9, where we get up to a million per second. Why is this enzyme odd in this respect? Why is it so fast under the right conditions? It's a pretty amazing enzyme, I hope I've connived you it's apretty amazing enzyme. is its Kcat so high at such a high pH that it really doesn't encounter in the body. If we go to pH 9, we could imagine that it's going to be a lot easier to remove protons off of water than if we're at pH 7. The rate of formation of the nucleophile is the critical step in this process. If the enzyme structure is stable at pH 10, the enzyme will be way better at 10 than it is at 7. There is a lot of interest in manipulating enzymes to infact increase their activity. They use water to break the bond. And that should give you some hint about the mechanism that they use. One of the things that magnesium helps to do is it does help to position the water so that it can lose a proton and make an attack on, in this case, a phosphodiester bond. We're not breaking peptide bonds, obviously. But we're breaking phosphodiesters because those are the bonds between the adjacent nucleotides in a DNA molecule. Now I'll show you something that's really cool and interesting. Let's take a look at this enzyme. common features of sites that restriction endonucleases recognize. It means that we can cut right in the middle of this guy and we've cut both of them. We just cut this guy right in. the middle. Not all of them work in the. middle, but this particular guy works in themiddle. Now I want to explain to you just physically how a restriction enzyme works and then I'll show you very briefly a little bit of mechanism. A restriction enzyme is a protein. That protein grabs a hold of DNA. alkoxide ion. In the case of the restriction endonucleases, that shape change is more dramatic. What it does is it actually causes a bend to occur in the DNA. So we think of the DNA molecules of being straight and linear, but when the enzyme is bound to that proper site, the enzyme goes "oh, whoa!" and it bends. The DNA molecule is physically bent at that point. It's physically bent. Now that bending turns out to be critical for the catalytic action.

ROUGE-1: 31.27, ROUGE-2: 29.42, ROUGE-L: 28.81
BERTScore: 66.83

==============================================
==================== [49/100] ====================
Summary:
AA and I are going to show you how to make vanilla extract so easy so yummy so good for all the things that you would use it for cakes whatever really really good isn't it so let's go [Music] simple now all you want for this is about 1 oz or roughly 30 G of vanilla beans so they'll be you know long Dobby whacker things and just cut them up into I don't know a couple of cenm you may maybe maybe qu an inch half an inch or so Chuck them in now you don't have to worry about scraping out the seeds. leave it the more flavor you'll have want something you can put it in for now you can use a cheesecloth for this or it works really well with one of these. If you've got a coffee machine that'll work excellent now open that and let it strain through. Oh yummmy do you want to try no no I'll see you next time for my next [Music] meal. I hope you like this no no you don't want totry it oh it smells so good do I smell this no youDon't want you to even smell it no you sure no it's really good can I smell it.

ROUGE-1: 62.29, ROUGE-2: 59.66, ROUGE-L: 57.54
BERTScore: 76.76

==============================================
==================== [50/100] ====================
Summary:
RAFAEL JARAMILLO: All right, let's talk about intermediate phases and line compounds. So I want you to recall intermediate phase in a three-phase system. And I'm going to recall it visually, and we're going to remember what the free-energy composition diagram looked like in such a case. And it looked-- let's say an alpha phase and the beta phase. We had some intermediate phase. So the common tangents are to look like this with a common tangency there. is something that's really narrow. So the solution model becomes very narrowly shaped, like a pin. All possible common tangents are going to converge at the same point. That point is x of B equals n. That's that one composition that we find in nature. So I no longer need a solution model. All I need is that one point, that point, is one free energy point and one composition. OK. So here, I can't help myself. I got to draw the mouse-face plot. Magnesium nickel has a number of different phases. At high temperature, this Laves phase develops some width. But when you drop down to low temperature, both of these intermediate phases appear as line compounds. So you can kind of see how these are not-- you don't reach this hexagonal magnesium 2 nickel phase just by individually substituting our atoms from the HTP magnesium phase. And they're really fundamentally different structure. mouse.mouse. mouse-face plot. But the point here is that these whiskers are all the common tangents kind of coming together at one point. Magnesium nickel-- actually, magnesium nickel system, right? So, for instance, at some low temperature, we have here this is going to be x nickel. And these vertical distances are related to formation-- related to the formation of free energies. So instead of being like a taut rope, it's just now like-- well, it'm just sort of a string held up between needles, needle points. There's no more curvature apparent. All right. So now let's talk about the size of these vertical segments. of compound from the elements in their reference states. So, for example, I might have 2 moles of magnesium in. its alpha phase plus alpha-- let's say HTP-- plus a mole of nickel in its alpha FCC. phase. And these can react to form magnesium 2 nickel. And there's a normalization that you need to apply in order to use formation free energies in free-energy composition diagrams. So that is kind of a algebraically-simple point, but it's a conceptual point that it's easy to mess up.  silicon tends to be a pretty useful additive for copper-based alloys. There are silicon bronzes and silicon brasses-- that is, bronze and brass alloyed with silicon. There's an infinity of examples of line compounds, so I just want to show you some of different types.have some examples here. So here is a copper silicon system. So you can see that you can get a fair amount of silicon into copper. That's 10%. That's this kind of purple region. Those are ternary systems. solid solution phases. There's this little guy here and this little guys here and then, of course, the big liquid phase. But how many line compounds are there? Trick question. Somebody, please, how many lines are there in this system? Is it three? RAFAEL JARAMILLO: It's not three. that's why it's a trick question. somebody else? AUDIENCE: Four. RAFAel JARamillo: Four Yeah. It's four. the parts-per-billion level. Doping semiconductors is why we're able to talk to each other over Zoom. Without doping, there is no semiconductor devices, no electronics revolution. So the fact that you can dope some metals into silicon is as important as it gets. The transmitters and receivers of all modern telecommunication devices, including your phones, are based on what's called III-V semiconductor, such as gallium arsenide. So there, the transistors and diodes and so forth are just made out of a gallium. Gallium arsenide and alloys, thereof, are the basis for all optoelectronics and photonic technology. Silicon carbide is a refractory-- some people will say it's a ceramic. Some people say no because it doesn't contain oxygen. It's used for grinding, so it's of enormous industrial importance. It also is an emerging semiconductor material for high-power electronics. The idea that you could replace discrete, bulky, power-handling equipment with integrated power- handling equipment. field of power electronics. And the thing is, you can't do it with silicon because silicon doesn't perform well at very, very high voltages. So in 50 years from now, if the idea of a power substation is a thing of the past, it will be due to silicon carbide and similar high-power electronics that are being developed today. And this last one, this is the titanium-sulfur system. This is a neat system because, first of all, it has everything in it. It eutectics. It has peritectics. RAFAEL JARAMILLO: Let's look at the silicon-carbon system at low temperature. Carbon here is a line compound. Silicon is an element that actually does have a pretty wide, solid solution, great range. At low temperature, similarly to gallium arsenide, it's going to be a really boring free-energy composition diagram. It's just a triangle. So it's simplified a lot. Any other questions on the meaning or importance of this stuff? And then if there are no more questions, I'll finish up on the board. tie line there, alpha liquid equilibrium. Just an example, this is no system in particular. We know that, along that line, dG equals mu 1 alpha minus mu 1 liquid. And that means I had a congruent melter. And then I drew as this and then like this, peritectic, and something like this. I had this complicated thing which I do. And the point is not the complicated thing. It's really, I have some two-phase region down here at. low temperature where I have two line compounds coexisting. There are no internal composition variables. That's a key point. Before, we had composition variables because the composition of the phases was variable. Now, we don't have that. What that means is that the equilibrium condition dG equals 0 is satisfied trivially, trivially. There's no need to do common tangents. The compositions aren't changing. And that's what's led to everything we've been enjoying over the last month and a half, is the fact that solution phase is the compositions are variable. RAFAEL JARAMILLO: I want to introduce this and get this in your minds. Let's imagine reacting metal M with 1 mole of oxygen to form an oxide. So zM plus O2 gas reacting to form MzO2. What's z? How do I determine z? Anybody? Does anyone know some oxides? Name for me a common oxide that you know. What is rock? What's the main component of rock? JARamillo: Silicon oxide, OK. z is an integer or a rational fraction, and it's fixed-- SiO2, magnesium oxide, Al2O3, so forth. So when we return on Wednesday, we're going to talk about the thermodynamics of this reaction. We'll use this property of being line compounds, and we're also going to use a bunch of other things as well. Back to the page you came from. Follow us on Twitter @CNNOpinion and @cnnopin.

ROUGE-1: 39.49, ROUGE-2: 37.73, ROUGE-L: 37.68
BERTScore: 70.24

==============================================
==================== [51/100] ====================
Summary:
A random variable can take different numerical values depending on the outcome of the experiment. Some outcomes are more likely than others, and similarly some of the possible numerical values of a random variable will be more likely. We will describe these relative likelihoods in terms of the so-called probability mass function, or PMF. The PMF is also sometimes called the probability law or the probability distribution of a discrete random variable. The argument of the PMF ranges over the possible values of the random variable, X. The probability mass function is a function of an argument x. For any x, it specifies the probability that the random variable takes on this particular value. Since the total probability of all outcomes is equal to 1, the probabilities of the different possible values should also add to 1. Let us now go through a simple example to illustrate the general method for calculating the PMF of a discrete random variable. We will revisit our familiar example involving two rolls of the tetrahedral die. And let X be the result of the first roll of the die. roll, Y be the result of the second roll. In order to do any probability calculations, we also need the probability law. We will concentrate on a particular random variable defined to be the sum of the random variables, X and Y. What we want to do now is to calculate the PMF of this random variable. We need to find this value for all choices of z, that is for all possible values in the range of our random variables. And we can continue this way by marking, for each particular outcome, the corresponding value of therandom variable of interest.

ROUGE-1: 32.83, ROUGE-2: 31.71, ROUGE-L: 31.79
BERTScore: 72.32

==============================================
==================== [52/100] ====================
Summary:
Protein three-dimensional structure, how you get at it experimentally and computationally. implications for the binding of small molecules such as drugs. We will in short order get to the scary pumpkin-like molecule. The connection to last week was this diagram showing palindromicity in three cases and a direct repeat in the fourth case. And I offered that this might reflect the symmetry of the proteins and the three dimensional structure of the nucleic acid and these symmetry elements would align. In order to get at this issue of where there is a code-- and I just take this as one of the ways of dealing with the incredible complexity. of proteins is to give this a theme that connects it to the last class and connects, I think, to many of the sentiments of people in this sort of audience interested in computational biology is ways of having simple codes. And of course, one way of breaking up proteins and thinking about them is these ABCs-- the alpha helix, the beta sheet, and the coil. Each of these can be characterized by the hydrogen bonds that hold it together. OK, now how can we use these basic motifs? These are the smallest meaningful units of protein three dimensional structure. How can we used these to recognize other macromolecules, other proteins and nucleic acids? The binding constant is measured in the molarity, roughly where you get half maximal or equilibrium binding. This is not going to be by staring at long sequence alignments where we're going to get the weight matrices. We can get them by actual experimental measures of the binding in vitro. Then I'll show you a little math how we got those apparent binding constants, which means you can get the binding constant at a lower concentration. Instead of being a single stranded nucleic acid, it's ready to bind to double stranded. It's not the only way, but this is a way. sequence that you're interested in is present. And what you do is quantitate the fluorescence of the zinc finger protein indirectly by the binding of the covalently-attached phage to the antibodies, which are fluorescently labeled by [INAUDIBLE] fluorescence. But how you relate that to the binding constant we had in the previous slide is the subject of this slide number eight. Now we call this the apparent equilibrium association constant because these experiments, just like many binding in living cells is not at equilibrium. that the helix that causes the dimerization of proteins-- you can think of this as your really most elementary protein-protein interaction code. A very fundamental one that comes again and again, so-called coil-coil, two alpha helices interacting. Can we extend this to RNA? This is a much more complicated situation with RNA because you don't have these long perfect double helices anymore. You have these very short RNA helices that I I think I can predict new regulatory protein DNA interactions with double-stranded DNA. showed in the last couple of classes. This is transfer RNA, one of our favorite molecules here, with the anticodon at the bottom of each of the pink structures. And the amino acid acceptor three prime end of that 70-some nucleotide-- 70 to 80 nucleotide nucleic acid. So the pinks are all the tRNAs, and there are at least 20 different types of amino acid and has 20 types of-- at least20 types of transfer RNAs. for the real world of interacting with input and output from various devices. The topic today is proteins, and this really is the main contact between the exquisite regulatory mechanisms. Here, we need sensors to sense the environment. We need actuators to then deliver back into the environment what the cell wants to do or to interact with other cells. You have to have feedback, synchrony, so on that you can basically program the almost digital nucleic acid world inside the cell but via clearly analog inputs and outputs. not inside the cell. But the whole complex gets internalized. Still, topologically, it's as if it were outside the cell when it's inside this little vesicle. But now the pH change that happens when this vesicles goes in the cell, part of the natural cell biological processes causes some act. The seven-mer complex of proteins does yet another conformational change and turns into this hairy beast that allows the lethal factor to get into your cell and kill it. of the constant for that process is around 50 nucleotides per second. These are important numbers, because a typical gene size piece, say, after RNA splicing in higher organisms or naturally, it might be a kilobase. So that's about a half a minute to transcribe and translate. That could be used as a timer in a circuit of these longer time frames, like cell cycle, circadian rhythm, very long time frames in ecological systems with bamboo and various pests, and then development and aging. your accuracy, as you can get from NMR and X-ray crystallography, you now are in a position to study catalytic mechanism and design and improve ligands, such as drugs. This is really where we want to be. There may be a day where we can do this all from ab initio prediction or modeling at very great distances. But for now, modeling atvery short, say, 80% to 90% amino acid similarity, is important. We will contrast this, or show the interplay of the computational biology, that can be aided by actual measurements of drug binding. the AIDS virus changes. And that causes a drug resistance in the HIV, with unfortunate consequences for the patient. We can take-- now, making mutations in polymerases is not entirely of negative consequences. And I'm going to show you a really beautiful example where a DNA polymerase-- a very similar kind of dynamic, where you want to change it so that it can now handle what would normally be an inhibitor of DNA polymer enzyme. And so one of the things that was noticed as the sequences of some of these polymerases were being studied, and some of the resistance mutants, and so on, was that the complex between the nucleotide, whether it's a deoxynucleotide with a 3 prime hydroxyl, which could then be extended by bringing in the next 5 phosphate. space to the position on a phenylalanine or a tyrosine, position 762 of this polymerase. If you now put in a dideoxy inhibitor, you now have too much space in there. And basically, the binding constant, it becomes much less favorable binding when you're lacking both oxygens. This has an 8,000-fold effect on the specificity of the polymerase, and a big impact on the Genome Project. Now, that's how we program a particular atom to achieve an important goal. There are ways that you can program, and conditional, meaning you can regulate under what conditions the protein is expressed or not or active or not with an entire domain, or with single nucleotide polymorphisms. Another way is by modulating the activity of the proteins from the outside with drugs or drug-like molecules and chemical kinetics. And under the subheadings for that, you can make these by combinatorial synthesis, which can be based on design principles, not just completely random. It can take into account what you know about the nature of the interaction of similar proteins. that we didn't discuss before. But it's related to what we've been talking about. In the case of the zinc finger, we made an altered specificity. We made new zinc fingers with bind to completely new trinucleotides. With the DNA polymerase, by changing one amino acid, we could make it now accept almost four logs better an inhibitor is very useful. And here, many different-- many of these are enzymes, where you can not just knock out the enzyme, but actually make it recognize a new substrate. eat a lot more fatty things. We live long enough to get Alzheimer's. And so maybe this was something that was-- this bad allele, E4, was good in chimpanzees that have different diets or lifespans. But the other possibility-- and I can't really distinguish between these right now-- is you no longer just think about single nucleotides. You think about haplotypes. Everything insists on that DNA strand has a chance of affecting either the expression level of the protein or insists, on the protein strand, to fall back. think of these things in terms of proteins. You can have-- a disulfide is a very important thing to lose. They tend to be highly conserved. If you introduce a proline into what would normally be an alpha helix, this is something where knowledge of the three-dimensional structure would say, oh, that proline, this a priori, without any knowledge of conservation, could be a huge change. And then these multi-sequence profiles are a good way of looking at the conservation. That's a way of prioritizing single-nucleotide polymorphisms. Solid phase comes up again and again in arrays. It's very obvious why you have a solid phase. You want to be able to address it by its positions in x and y on the array. But the other reason-- technical reasons are, it's a fantastic way of getting purification of your products simply by washing. And it allows you to, in the case of beads, there now-- you can think of it as an ultimate and flexible array. You can move the beads around and put them in new arrays, and identify them later. This is a completely synthetic way of getting short peptides. You can think of these as drug-like molecules. These are naturally related-- they can be analogs of nucleic acids and proteins, not just straight ones. And we'll talk about opportunities for making these analogs. We'll talk more about protein synthesis as part of quantitation next time, and aspart of networks in the last three lectures. And the process is cyclic in the sense that each cycle, you return, and the polymer gets a little bit longer. capping step that can soak up any excess that was left over. After you're done with all of these cycles, then there'll be a step where you remove the protecting groups altogether and remove the polymer from the solid phase if you so choose. Or you leave it there, if you have an array. These are other examples of protecting groups. Some bases don't need protection, like thiamines. If you have a exocyclic amine, then you typically need a benzyl or an isobutyryl group. A large class of pharmaceuticals, including most of the antibiotics, are made by a fairly small set of organisms, such as streptomyces in certain plants. The process by which it's made, which will be illustrated in more detail in the next slide, is very akin to fatty acid synthesis. Another way of biologically making a very compact structure, which actually uses ribosomes, but it uses them to make very tight short peptides and a precursor that then folds with lots of disulfides. they have to have a lot of rigidity. And the thing that you lock in rigidly has to be the correct structure. It does you no good to having a rigid structure that isn't really perfectly complementary to that surface. The immune receptors, B and T cell receptors, the antibodies, and cell-mediated immunity. These use recombination machinery to program various combinations of nucleic acid motifs that encode protein motifs. And as they do that recombination, they have further diversification that occurs due to a template-independent polymerase. where the acyl carrier protein, ACP in the box, binds to the first monomer, and it starts transferring it from protein to protein along this multi-domain huge protein. And there's actually three proteins in a row here. And each of the steps are taken in order along the protein, and they involve things like a synthase step, where you bring in another monomer. But you can see each of these has a substrate specificity. And by changing the order of substrate specificities, you can build up a huge combinatorial collection. You can either collect a big data set of proteins that interact from a proteomic scale experiment, or from molecules that inhibit one or more of those interactions. Now, if you look at the top right-hand part of slide 34 here, you can see this huge diversity of all of these different colored shapes. And if you wanted to use these in a combinatorial assay, you'd connect them in every pairwise combination and try them against your target by some bioassay. However, if that library is too large either to make or to screen, then what you can do is to study a part of the molecule and see-- and then take the subset of the diversity that can bind. if each one has a very low binding constant, then it will be roughly the square of that. And you get some point of diminishing returns, eventually. If they are homologous to previous interesting targets, then that puts them high on the short list. And in fact, a very large class of drugs is aimed at surface-accessible membrane proteins. And so very often, those are prioritized high. There are also-- the surface-acceptable proteins are important if you're talking about vaccines, which is an increasingly important. Once you have a regulated gene, getting the protein sequence is easy. Getting from the sequence to secondary structure is easy in the context of some of these other things. But still, the accuracy is only around 77% for secondary structure and about 25% for ab initio three-dimensional structure. We'll pick up this thread right after a break and carry on to actually how we get the three- dimensional structure, whether it's predictive or experimental, and the computational tasks there. Take a break.

ROUGE-1: 41.77, ROUGE-2: 40.31, ROUGE-L: 40.69
BERTScore: 71.95

==============================================
==================== [53/100] ====================
Summary:
 AI is replacing human tasks faster than you might think according to a CNN business article more than half of large US firms plan to use AI within the next year to automate tasks. The New York Times reports that generative AI could automate activities equivalent to 300 million full-time jobs around the world open ai's chief executive that's Sam mman says governments will need to assume the bulk of responsibility in supporting workers AI labor market disruptions and the question will employees just end up training AI systems only to them be replaced by them.  AI is now serving up predictive insights so that if you're a new hire it will say hey did you know this is where you should look to go for your first day. Instead of spending you know 10% of your time looking for information the information to do your job is coming to you. I think it's been a massive massive value ad for our our teams and they give us a lot of feedback on it around the globe as well yeah um it's such an interesting point isn't it you know if it freezes up time it makes us more productive but yeah possibly doesn't. Chintan: There's a danger that we focus on all of this and on what it can deliver but frankly it needs people that understand it. There is no AI without data without the network to actually connect the you know act as the connective tissue to to the algorithms that are answering our questions and giving us our responses. If you can't secure that end to end then that's where that trust issue really comes into as you mentioned around cyber security. Chintan says we have to train the Next Generation in both these Advanced AI skills but also some of the fundamental essential digital skills that we need you. We've got an increasing sort of divide between those who have the topend skills but actually perhaps people who don't have some of the more basic digital skills that we need. And so that's a sort of skills Gap isn't it and and Stephanie I wonder whether firms are ready because I'm looking at numbers here 97% of companies say that yes they know they need to do this but I think what 14% say they're actually ready to do it that's quite the Gap yeah and we just saw yesterday here in the United Kingdom the Prime Minister was discussing this sort of plan for The King's Speech. Stephanie: What can we do to make it so that AI is valuable for everybody and not just the usual people who profit from technology yeah um Natalie let's throw that to you first of all because you've been nodding along here what do you make of of what Stephanie asking it is? Natalie: For us equality inclusion how do we make sure that to your exact point AI is used to democratize access to jobs access to different experiences we're really focused on that even in our hiring organization right now we've been leveraging AI to Source the planet for talent.  AI decoded is our weekly look at the impact of AI in the world workplace. This week we'll focus on the threat posed to workers and how some are fighting back. We'll also speak to one reporter who's been researching the threat to workers. And we'll talk about the case study of a call center worker who was subject to AI training. All this and more on AI decoding on BBC News tonight at 10pm. Click here for the first episode of AI Decoded. Emma asks Emma if we will actually see an increase in Union membership for private sector workers in the United States. She says a lot of workers want to feel that their voices are part of the process in deciding how AI is going to be used. Emma says the model for unions needs to be updated for the 21st century too. Emma: I think we're looking at lower level jobs as a result of AI it's like we're flipping it on its head and maybe we could actually replace CEOs or Executives. were most at risk because of automation. People are realizing you have to throw out the door any ideas you had about who is really at risk and say every job is going to be changed. We just hope that the workers whose jobs are changing have a voice in saying how yeah it's turkeyy is not going to vote for Christmas are they if those are the ones that could find their jobs being replaced but there's so much in there and Stephanie just a final thought from you in all of this about briefly if you will. this and now Emma thank you so much we'll be reading closely uh as your investigations continue uh that is it we're out of time we'll do it at the same time next week bye-bye. This and Now Emma is on CNN at 10pm ET on Monday, November 14. For more, go to CNN.com/This and Now Emmett, or click here for more information on the CNN iReport app. The app is available in the UK and the U.S. and costs £3.99.

ROUGE-1: 35.96, ROUGE-2: 32.17, ROUGE-L: 32.36
BERTScore: 63.55

==============================================
==================== [54/100] ====================
Summary:
Sadhana sadhana is a machine learning scientist at Themis Ai and the lead TA of the course intro to deep learning at MIT. She'll be teaching us more about specifically the bias and the uncertainty of AI algorithms which are really two key or critical components towards achieving this Mission or this vision of safe and trustworthy deployment of AI all around us. Sadhana will talk about how we can build very modular and flexible methods for AI and building what we call asafe and trustworthy Ai. behalf of Themis so over the past decade we've seen some tremendous growth in artificial intelligence across safety critical domains in the Spheres of autonomy and Robotics. We now have models that can make critical decisions about things like self-driving at a second's notice and these are Paving the way for fully autonomous vehicles and robots. But there's another question that we need to ask which is where are these models in real life a lot of these Technologies were innovated five ten years ago but you and I don't see them in our daily lives. Themis believes that all of the problems on this slide are underlaid by two key Notions the first is bias bias is what happens when machine learning models do better on some demographics than others. The second notion that underlies a lot of these problems today is unmitigated and uncommunicated uncertainty. This is when models don't know when they can or can't be trusted and this results in scenarios such as self-driving cars continuing to operate in environments when they're not 100 confident. Themis is innovating in these areas in order to bring new algorithms in this space to Industries around the world. in the real world because American English is highly overrepresented as opposed to other demographics but that's not where bias and data stops. These biases can be propagated towards models training Cycles themselves which is what we'll focus on in the second half of this lecture. Once the model is actually deployed we may see further biases perpetuated that we haven't seen before. The distribution that the data is coming from would shift significantly across this decade and if we don't continue to update our models with this input stream of data we're going to have Obsolete and incorrect predictions. Commercial facial detection systems are everywhere you actually played around with some of them in lab two when you trained your vae on a facial detection data set. The biases in these models were only uncovered once an independent study actually constructed a data set that is specifically designed to uncover these sorts of biases by balancing across race and gender. There are other ways that data sets can be biased that we haven't yet talked about so so far we've assumed a pretty key assumption in our data set which is that the number of faces in ourData is the exact same as theNumber of non-faces in our Data set. accurate class boundary between the two classes so how can we mitigate this this is a really big problem. The first way that we can try to mitigate class imbalance is using sample re-weighting which is when instead of uniformly sampling from our data set we instead sample at a rate that is inversely proportional to the incidence of a class in the data set. The second way we can mitigate class and balance is through loss re- weightsing which means that samples from underrepresented classes contribute more to the loss function. yet is latent features so if you remember from Lab 2 and the last lecture latent features are the actual represent is the actual representation of this image according to the model. The bias present right now is in our latent features all of these images are labeled with the exact same label. We can't apply any of the previous approaches that we used to mitigate class imbalance because our classes are balanced but we have feature imbalance now. However we can adapt the previous methods to account for bias in latent features which we'll do in just a few slides. our biased features and then apply resampling so let's say in reality that this data set was biased on hair color most of the data set is made up of people with blonde hair with faces with black hair and red hair underrepresented. If we knew this information we could label the hair color of every single person in thisData set and we could apply either sample re-weading or loss relating just as we did previously. The question is what if we had a way to automatically learn latent features and use this learn feature representation to dbias a model. Reconstruction loss between the inputs and the outputs and continue to update their representation of the latent space. A de-biasing algorithm that automatically uses the latent features learned by a variational autoencoder to under sample and oversample from regions in our data set. We want samples that are similar to each other in the input to decode to latent vectors that are very close to eachOther in this latent space and samples that're far from each other or samples that's dissimilar to each each other should decode to should encode to latent vector that are far from Each other. good representation of what a face actually is so now that we have our latent structure we can use it to calculate a distribution of the inputs across every latent variable and we can estimate a probability distribution depending on that's based on the features of every item in this data set. This allows us to train in a fair and unbiased manner to dig in a little bit more into the math behind how this resampling works this approach basically approximates the latent space and then we can over sample denser or sparser areas of the data set and under sample from denser areas. via a joint histogram over the individual latent variables so we have a histogram for every latent variable Z sub I and what the histogram essentially does is it discretizes the continuous distribution. As Alpha increases this probability will tend to the uniform distribution and if Alpha decreases we tend to de-bias more strongly. This gives us the final weight of the sample in our data set that we can calculate on the Fly and use it to adaptively resample while training. Once we apply these this debiasing we have pretty remarkable results. lecture so so far we've been focusing mainly on facial recognition systems and a couple of other systems as canonical examples of bias however bias is actually far more widespread in machine learning. Consider the example of autonomous driving many data sets are comprised mainly of cars driving down straight and sunny roads in really good weather conditions with very high visibility. In some specific cases you're going to face adverse weather bad um bad visibility near Collision scenarios and these are actually the samples that are the most important for the model to learn. tend to amplify racial biases a paper from a couple years ago showed that black patients need to be significantly sicker than their white counterparts to get the same level of care. That's because of inherent bias in the data set of this model. In all of these examples we can use the above algorithmic bias mitigation method to try and solve these problems and more so we just went through how to mitigate some forms of bias in artificial intelligence and where these Solutions may be applied. We talked about a foundational algorithm that Themis uses that UL will also be developing today. the core idea behind uncertainty estimation so in the real world uncertainty estimation is useful for scenarios like this this is an example of a Tesla car driving behind a horse-drawn buggy which are very common in some parts of the United States. The exact same problem that resulted in that video has also resulted in numerous autonomous car crashes so let's go through why something like this might have happened there are multiple different types of uncertainty in neural networks which may cause incidents like the ones that we just saw we'll go through a simple example that illustrates the two main type of uncertainty that we'll focus on. model won't be able to compute outputs for the air points in this region accurately because very similar inputs have extremely different outputs which is the definition of data uncertainty we also have regions in this data set where we have no data so if we queried the model for a prediction in this part of the data set we should not really expect to see an accurate result because the model's never seen anything like this before and this is what is called Model uncertainty when the model hasn't seen enough data points or cannot estimate that area of the input distribution accurately enough to Output a correct prediction. names to the types of uncertainty that we just talked about the blue area or the area of high data uncertainty is known as aliatoric uncertainty. The goal of out estimating alliatoric uncertainty is to learn a set of variances that correspond to the input keep in mind that we are not looking at a data distribution and we are as humans are not estimating the variance we're training the model to do this task. The crucial thing to remember here is that this variance is not constant it depends on the value of x. with very low variance so our variance cannot be independent of the input and it depends on our input X so now that we have this model we have an extra layer attached to it in addition to predicting y hat we also predict a sigma squared how do we train this model our current loss function does not take into account variance at any point this is your typical mean squared error loss function that is used to train regression models. We want to generalize this loss function to when we don't have constant variance and the way we do this is by changing the lossfunction to the negative log likelihood. a data set called cityscapes and the inputs are RGB images of scenes the labels are pixel wise annotations of this entire image of which label every pixel belongs to and the outputs try to mimic the labels they're also predicted pixel wise masks. Why would we expect that this data set has high natural alliatoric uncertainty and which parts of this dataSet do you think would have aliatoric uncertainty? Because labeling every single Pixel of an image is such a labor-intensive task and it's also very hard to do accurately. An ensemble of networks can be used to estimate epistemic uncertainty. The key insight for ensembles is that by introducing some method of Randomness or stochasticity into our networks we're able to estimate epistemic uncertainty. To implement this what we have is a model with the exact one model. We add Dropout layers with a specific probability and then we run multiple forward passes and at every forward pass different layers get dropped different nodes in a layer get dropped out. We use the mean of these samples as the new prediction. epistemic uncertainty let's go back to our real world example let's say the again the input is the same as before it's a RGB image of some scene in a city. We can see why the areas of the sidewalk that are discolored have high levels of epistemic uncertainty. Once we're actually training a model if it's already been trained on a bias data set we can de-bias it adaptively during training using the methods that we talked about today and afterwards we can also verify or certify deployed machine learning models. guardian and that's essentially a layer between the artificial intelligence algorithm and the user and the way this works is this is the type of algorithm that if you're driving an autonomous vehicle would say hey the model doesn't actually know what is happening in the world around it right now as the user you should take control of this autonomous vehicle. We can apply this to spheres outside autonomy as well so you'll notice that I skipped one part of the cycle I skipped the part about building the model. We're going to focus a little bit on themes ai's product called capsa which is a model agnostic framework for risk estimation. then further analyze and so this is the one line that I've been talking about um after you build your model you can just create a wrapper or you can call a wrapper that capsa has a an extensive library of. Capsa wraps models for every uncertainty metric that we want to estimate we can apply and create the minimal model modifications as necessary while preserving the initial architecture and predictive capabilities. This could be adding a new layer in the case of a variational autoencoder this could be creating and training the decoder and calculating the Reconstruction loss on the Fly. Themis is a company that develops and deploys trustworthy AI across Industries and around the world. We're hiring for the upcoming summer and for full-time roles so if you're interested please send an email to careers themesai.io or apply by submitting your resume to the Deep learning resume drop and we'll see those resumes and get back to you thank you foreign thank you for joining us today. We'll use capsa in today's lab to thoroughly analyze a common facial detection data set that we've perturbed.

ROUGE-1: 40.63, ROUGE-2: 39.18, ROUGE-L: 38.76
BERTScore: 56.47

==============================================
==================== [55/100] ====================
Summary:
HONG LIU: So if you want to compute, say, some scattering amplitude from alpha to beta-- so alpha's some initial state and beta's some final state. Say alpha consists of momentum p1 and PN-- or pm, and beta, say momentum p m plus 1 and pn. And then you can get this scattering amplitude just by taking your momentum-space correlation function, OK, for the n points. So this is the relation, and here I have stripped out the momentum conservation on both sides. I will explain a few things. OK, so remember this Gn, so let's go back to the definition of this Gn. So this is obtained by doing a Fourier transform. Say-- I think it would be minus sign. By doing the Fourier transforms, the coordinate-space correlation function can be written as the following. So-- yes? AUDIENCE: Right, so time-ordering of x1 to xn right here? HONG LIU: Yeah. It doesn't matter. It just has to act to the right. HONG LIU: To derive that theorem, the time-order matters. So we mentioned that if you have a diagram like this, say minus P1, minus P2, to P3, P4, and then the square root and amplitude are just given by minus i lambda, because you need to throw away all the external propagators. OK, you just need to-- you have to truncate all the External propagators, so that means you also throw away diagrams like this. So all these diagrams, you can ignore them, OK. HONG LIU: Z is the same for different processes, but it's different for different particles. Z is a constant for all of them, yeah. If it depended on momentum, then it would be kind of useless, right? So for our purpose, actually, it's not important. So we will not go into details of the Z. And that is in the QFT2. But the leading order, they don't matter, and so we will start with 1. single particle, and you can have such a diagram like this and all these diagrams. Correspondingly, you have a particle propagating, but that particle can interact with the virtual particle, its own virtual particle. And so that, this kind of interaction, will affect the property of the propagation but can have the most effect by prefactor, but actually can change the mass, too. But for the-- oh, it can correct for the mass-- and also, that's the subject of the QFT2. The Dirac equation is one of the most beautiful equations in mathematical physics. It's actually describing electrons, so it's not only beautiful, but it's actually useful. The Dirac theory is a prime example of how people make great discoveries often for the wrong motivations. But the key is that if you are good enough, you will find something new and that something new will be useful. We'll talk about fermions in the next section of the lecture. We're going to talk about the Dirac equations and its covariance. go to a different frame. OK, yeah, that's what we mean by-- just when you go to adifferent Lorentz frame, the equation, the form of the equation looks the same. Just different observers in different laboratory, they see the same equation, OK? OK, so but for this to be Lorent z covariant, remember, LorentZ transformation transform t to x, so immediately, you conclude that H must be first-order in spatial derivatives. OK. So the only-- then the most general way you can write it is alpha minus i.  Dirac came up with the idea of Lorentz covariant equations. He reasoned, OK, if this is constant which does not work, and then let's make alpha and beta to be matrices. Then in order for that equation to make sense, then psi has to be a n- component vector. OK, it's really, say, a stroke of genius. It's really a strokes of genius because there was nothing like this before. Just even from a mathematical point of view, it is purely, purely imaginative, OK? They're just some constant Hermitian matrices. And then, so then he reasoned that for this equation, if we want this equation to be Lorentz covariant, then at least it should have the relativistic plane wave as its solution. If it does not even have that type of solution, then you, yeah, of course cannot be covariant. So this will be satisfied-- can be satisfied if square of star, OK, satisfies reduced to the Klein-Gordon equation. equation, then you just get partial partial t square psi equal to H square psi. OK, and then we try to make this of this Klein-Gordon form. So the right-hand side, we just have the form minus i with alpha dot with this. And then plus beta m square psi plus cross term. But now remember, beta and alpha, they are not constant. They are matrices, OK, so they don't necessarily commute. So you have to be careful about the orders. with that kind of dispersion relation. So now we just compare the both sides, so for this to be true, we just need to have-- so let's compare the second-order derivative term. And then we need alpha i, so we need-- first, when i not equal to j, the off-diagonal terms, they all should vanish, OK, because here there's only diagonal terms. So that means that the alpha i alpha j plus alpha j alpha i should equal to 0. OK, that should have the plane-wave solution. HONG LIU: To satisfy them needs at least a 4-by-4 matrix, so n has to be 4. And so you can also check 2- by-2 matrices. It's not enough to do this. When you go to 4-By-4, then you finally find the solutions. OK? Good? So now, good, you say we have an equation, OK, so psi-- so alpha is a 4 -by -4 matrix. And alpha acts on different components of psi, and this just acts on-- the derivative acts on all components. alpha 2, alpha 3, they are all-- they are three matrices. Wouldn't we want each alpha i to be diagonal? Is that what you're saying, that each matrix in alpha should be a diagonal matrix? HONG LIU: No, alpha are just matrices, so this means that alpha 1 alpha 2 plus alpha 2 alpha 1, as a matrix product, should give you zero. So that's why I say this was really genius, because just nobody could have thought of this. HONG LIU: If we take a n by n matrix where n is not so small, then we can use that --? HONG LIu: No, you get-- just we are not using those matrices in the efficient way. Yeah, this become-- you can reduce always-- yeah, just from physical purpose, you can always reduce it to 4, yeah. OK? Good? OK, so for later convenience, let's introduce a slightly different notation, so now we have this equation. form of this. So now we have the form of this partial t psi equal to minus alpha plus beta m psi, so now let's multiply both sides by a factor-- by beta. OK, so beta is a matrix, so this is a Matrix equation. So due to different conventions of the Minkowski metric signature you use, different books or different places, you will see i in different places. Some equations have i-- yeah, some books have i here. In my version, there's no i, OK? [LAUGHTER] most simplest in terms of notation anyway, so that's the convention we use. Now let me just write it in the component form. I have gamma mu, which-- each of them is a matrix, alpha, beta, so alpha and beta, they're always run. OK, so this is a little bit intricate equation, but once you get used to it, it's not that difficult. Yes? AUDIENCE: There's no meaning to the upstairsness or downstairsness of alpha andbeta, right? HONG LIU: Yeah, these two indices are not symmetric. HONG LIU: 1, 2, 3 can be written as-- in terms of gamma matrices gamma mu gamma nu plus gamma nu gamma mu. So mu nu is always from 0 to 3, OK, equal to 0, or mu not equal to nu, and then gamma 0 squared is equal to minus 1. And you can write this further in a more compact form. You can also write this together in the more-- or equivalently write it as gamma mu dagger gamma 0 gamma mu Gamma 0. are just good-- so these are two different representations of this algebra. OK. So now let me make some remarks. So before I proceed further, do you have questions? Yes? AUDIENCE: For 2, shouldn't the Pauli matrices be-- oh, nevermind. HONG LIU: Oh. Other questions? OK? Good? So nowLet's talk about spinor space. Yeah, so this is a new space, and so that's called-- this is calledspinor space, yeah. same story just here, you just forget about beta. OK, the same story, you forget the beta, and then you only need alpha i alpha j the commutator to be 0 for i not equal to j, essentially just that equation 1 there. And then also, you'd want the alpha i square equal to 1, OK, so for any i. So now these are the conditions for the alphas, and now you can actually satisfy by 2-by-2 matrices. positive definite classically. You will-- later, you will see why, OK? And this, I will leave it to your pset, OK, so this is very similar to the derivation of such occurrence in the case of the just non-relativistic Schrodinger equation. So as I mentioned, you can have infinite number of solutions. What's the meaning of them? So first, let's imagine when we look at this equation-- so as I said, this is a matrix equation. to 0, and the gamma mu prime is equal to B gamma mu B minus 1. So yeah, so this easily can be shown. So then we conclude, any sets, since we can make a basis transformation as you want, OK, that the-- except the basis transformation should not change physics, OK? So any sets of gamma mu related by a similarity transformation are equivalent. OK, and because they should not give you new physics just because one is going to change the basis. they're all physically equivalent. They're just corresponding to a change of basis. So but different forms of the gamma, they may be useful for different purposes. For example, this I, solution I we wrote down before, it's convenient for if you want to take the nonrelativistic limit. OK, they make your algebra a bit more convenient. But still we haven't showed that the Dirac equation is covariant. So we, of course, won't have time to do that today, but let me just remind you how this Lorentz covariance works for the scalar case. Consider such a Lorentz transformation, OK, so and then phi transforms as following, phi prime x prime phiprime. New phi evaluated at the new position should be the same as phi evaluation at the old position. So the phi-- yeah, just equal to phi lambda minus 1 x. So now if you look at the Klein-Gordon equation, let's see how this is covariant. OK, it's the same in any frame. Now we want to show that the Dirac equation has the same property.

ROUGE-1: 35.71, ROUGE-2: 34.32, ROUGE-L: 33.75
BERTScore: 69.49

==============================================
==================== [56/100] ====================
Summary:
The US Supreme Court is the highest federal court in the United States. The president can nominate any individual to serve. So far, six justices have been foreign-born, at least one never graduated from high school, and another was only 32 years old when he joined the bench. Most presidents nominate individuals who broadly share their ideological view, so a president with a liberal ideology will tend to appoint liberals to the court. For example, when President Eisenhower, a Republican, nominated Earl Warren for Chief Justice, Eisenhower expected him to make conservative decisions. Since the Nixon administration, these hearings have averaged 60 days. This job is for life, barring resignation, retirement, or removal from the court by impeachment. Of the 112 justices who have held the position, not one has yet been removed from office as a result of an impeachment. One of their roles is to protect the fundamental rights of all Americans, even as different parties take power, writes Julian Zelizer, a professor at the University of California, Los Angeles, and a former Supreme Court justice. to be debated and dissected by the ultimate judges, time and history. To be debated, dissected and debated, we need to look to the past, present and future. We need to see how far we have come and what we can learn from the past. We also need to learn from our mistakes and learn from each other. We want to be the best we can be, and we want to do it in a way that honors the past and the present. We hope you will join us in this quest.

ROUGE-1: 49.72, ROUGE-2: 38.44, ROUGE-L: 39.69
BERTScore: 62.97

==============================================
==================== [57/100] ====================
Summary:
This is the second time we are having this class. We had it last year in a smaller version. That was for six units of a credit, and we had it once a week. And mostly practitioners from the industry, from Morgan Stanley, talking about examples how math is applied in modern finance. And so we got some good response last year. So, with the support of the math department, we decided to expand this class to be 12 units of credit and have twice a week, as you know. "Hopefully, this will give you enough information to decide this is a field you would like to pursue in your future career," he says. "Last year when we finished the class, we had a few students coming to work in the industry" "Some work at Morgan Stanley, some work at elsewhere. So that's really the goal. And at the same time, obviously, you will further solidify your math knowledge and learn new content," he adds. "Some terminologies will be used, which you may not have heard before" and the Sloan school here. So anyway, thanks for that. We will be doing a bit more polling along the way, mainly to get feedback of how you feel about the class. Last year we had it online, so if you feel the class is going too fast, or the math part is. going too slow or the finance part is a bit confusing, the easiest way is really just to send us. emails, which you will find from the class website. So Anyway, I will start today's lecture with a story, and a quiz at the end. Don't worry, it's not a real quiz. Just going to ask you some questions you can raise your hand and give your answer. you the story of Pi or "Life of Pi." That's not a financial story. The rest of the story, alpha, beta, delta, gamma, theta, which you will learn from Peter and Choongbum and Vasily's classes. So I'm going to talk about vega. What is vega? It's a measurement about a book or portfolio or position's sensitivity to volatility. That's all you need to know right now. I'm not going to ask you questions later. called kappa at Morgan Stanley. Kappa is also called vega by some uneducated traders at the Salomon Brothers. They have mistaken vega as a Greek letter after gambling at Vegas. So anyway, so that was my first day. So obviously, I learned how to call kappa very quickly. And I called it kappa in the last 17 years, but you will hear people calling it vega. Obviously, I have probably more people call it the vega, but anyway. But why did I tell you the story? What point I try to make? I did that in the last 20 years. So the point I'm trying to tell you is, before you dive into any details of mathematics or any concept in finance in this class, just bear in mind, this is a field developed in. the last mostly 30 years, or even shorter. And what you really need to ask questions is-- it's not really is it right or wrong in mathematics, is it wrong in physics? So, how the concepts are established and defined and verified. typically specialize in local products, local company stocks, local bonds, and local currencies. So again, what's in common? That's the question you need to ask. And the currencies, money itself, are also traded. So, there are different products. How the stock get listed on the stock exchange? It goes through IPO-- Initial Public Offering process. When a company changes from private to public, it goes through this IPO process. It's called primary market, primary listing. And once the stock is listed and it becomes traded in the market, we call it secondary trading. endowment support, some will come from some other form of research budget. Just borrow from the public-- local governments, states, counties, even. So, that's debt product. Commodities, actually, you know. Metal, energy, agriculture products are traded, mostly in the futures format. When you actually buying and sell, you build a warehouse to take them. You ship a tank to store above the ocean. And the real estate, you're buying and selling houses. type of player is really bank. After 1933 Glass-Steagall legislation, there were two main types of banks. One is called commercial bank, the other is investment bank. Some people blame that, and probably for a very good reason, for the cause of 2008 financial crisis. But why do we need financial markets? This comes back to what I described before. There's a need for it. It's really the need to bridge between the lenders and the borrowers. That's really coming down to the essential relationship. Investors who have money need to have better yield or better return, better interest. When you have a savings account, you don't really earn much at all. And so you would have to take more risk to generate more return, or you have longer horizon CDs, other type of products, or trade the stocks. So the trade between lenders and the borrowers, is again, essentially the main driver of the financial markets. So, banks and so-called dealers play the role of market making. brokers. Mutual funds, who actually manage public investors' money, typically in the long-only format. Insurance companies has large asset. They need to generate a return, generate cash flow to meet their liability needs. And the pension funds, same thing. As inflation goes higher, they need to pay out more to the retirees, so where do you get the return? Sovereign wealth fund, similarly, endowment funds-- they all have this same situation, have capital and needs to deploy and to make better return. Government always have a very large impact on the market, because they are the policymakers. They decide the interest rate and interest rate curve. And the different policies they push out, obviously, will generate different outlook for the future markets. Then the corporate hedges and the liabilities. When corporates borrow money, they create some risk, so they need to be sensitive to the market. So, to summarize the types of trading. The first type is really just hedging. That means you're not proactively adding risk to what you have. In the new regulation, obviously, proprietary trading is banned, right? And so the third type is really the proprietary trader, the risk taker. These are the hedge funds or some portfolio managers. They need to focus on generating return and control the risk. So, that's where the beta and alpha, the concept comes in. It's a format. You want to beat S&P 500, so you want to basically have certain tracking of this index, but you Want to return more on top of that. I mentioned the currency example. Let me give you another example. There are a lot of people issue bonds, or issue debt. So this example I'm going to give you is, let's think about Australian corporate. Because interest rate in Australia is higher than in Japan, so typically, people like to borrow money in Japan. And they invest it in Australia. You earn higher interest rate. So let me ask you a question. Who can tell me, why don't people just do that all day long, just borrow from Japan and invest in Australia? Even if you are not a finance guy, you work in a corporate, you just do you import, export, or building a factory, you have to know, actually, what the exposure is. Risk management, nowadays, becomes pretty widespread responsibility. So, that's on the hedging side. If you're entering in a merger deal, and one company is buying another, you need to hedge your potential currency exposure and your interest rate exposure. And whatever is on the assets or the liability, or the balance sheet, you must hedge your exposure. that liquidity, and then takes the risk. They manage the book by balancing those Greeks, which I mentioned earlier. Delta, which describes the relationship of this whole book to the underlying stock, or underlying whatever currency. That's called delta. Gamma is really the change of the portfolio. Take the derivative to the delta, or the underlying spot. So, that's second-order derivative. Delta is the first order. So gamma, now you have curvature or convexity coming in. And theta is really-- nothing changes in the market. Nothing changes in your position. Trading is really to find the relationships between prices, and try to profit from those relationship mispricing. Not many people focus on arbitrage, because lot of people are gut traders. If you trade gold in the States, the gold price happen in Asia and in Europe matters, right, because you're trading the same thing. If they are not priced the same way, you can profit from the difference. The other type is called a value trader, or relative value strategies. Think there's a deterministic, temporary mathematical relationship. the same thing, that becomes much less effective. Stat arb, finding statistical relationship among large number of stocks, then trade at the higher frequency. And fundamental analysis, you're really trying to understand what's going on in the world. So it goes through those fundamental analysis. And there are special situations. Some companies are going through particular difficulties, assets are priced very cheaply. So, there are firms out there -- you probably heard Bain Capital and many others -- where they focus on these private equity and special situation opportunities. adjust to your assumptions to fit into the market. So, pricing model, which Vasily and many of his colleagues can tell you more-- which is very much a very interesting and challenging area. Risk management itself is very challenging. It's not a purely mathematical question, but yet, math plays a very important role to quantify how much exposure you have. Then, the third is trading strategies. Again, I think a lot of people with math background, or in general, people are looking for the so-called holy grail Trading strategies. Prof. Jake Xia: "I just want to give you the sense how math and intuition and judgment can come into the same place" "When you go to the market, you buy a stock. When the stock goes up, makes bit of money, the natural tendency is to let's take profit," he says. "If you have the discipline to get out, that's great. Trading is really all about how do you risk manage," he adds. "I'm not trying to tell you which one is right or wrong, but think about it" your bank account balance is-- let's say you are a freshman student. Your bank account is $800. Your choice will be very different from someone has $100,000 in his bank account. And also, your risk tolerance, how much you can tolerate. I'm not going to give you say, this is right or wrong. But with that, let me move on and give you some homework. So, before I give you the homework, I want to make a few more comments. Do people always learn from their experiences? In science, we collect evidence, we build models. Learn the math, learn the finance first, but keep those questions along the way when you are learning during this class. Go to the course website, read what we have put up for the financial glossary. If you still have things you don't understand, compile your own list of financial concepts, which you can search on the web or even ask us. So, that's really-- and read other materials on the course work. So we got maybe-- how about this? We still got about 15 minutes or 12 minutes left, so I'll pass it to Vasily. every time. So, if you want to differentiate this functions and get a derivative, then this derivative will be quite noisy. And so, instead of getting the true derivative, you might obtain something quite different from true derivative just because there is a confidence interval around any point. So obviously, there is somewhere balance, and the question was, is there an optimal shift size to get the derivative? And that's what-- uh oh, the slide got corrupted. There was an answer. And we are implementing it in our systems and plan to use it in practice. what we had, we had the noisy observation of broker data and it was coming out at different non-uniform times. So, we decided to use Kalman filter and to study how it can predict. And that's one of the nice graphs [INAUDIBLE] produced, which again, we will use this strategy and the Kalman filters which he constructed in our e-trading platform in Moscow. Just to remind, the website is fully functional. We will be posting a lot of materials there. Probably most lectures will be published there.

ROUGE-1: 43.20, ROUGE-2: 41.75, ROUGE-L: 42.98
BERTScore: 68.13

==============================================
==================== [58/100] ====================
Summary:
Climate change is changing us from the inside out in the UK one in four adults and one in 10 children experience mental illness and there's growing evidence that dealing with a changing climate is adding to that burden. In 2022 we had the hottest year on record where daytime temperatures soed over 40° for the first time in history the past hour or so we've had the UK Met Office issuing its first ever red warning for extreme heat after the 2022 heat wave. Charles and a team of researchers set out to study how the extreme heat affected people's well-being over half of the the people they spoke to experienced negative impacts on their mental health. Clayton and Charles's Rec search has shown that there are things you can do to support your wellbeing engaging with nature. Spending more time in Green Space people use that as a way to cope with stress. We are not separate from our environment we are connected not just to the world around us but of course to one another and it and it is only in working with one another that we're going to be able to move forward [Music]"These effects are real they're they're serious and and they can be scary"

ROUGE-1: 33.28, ROUGE-2: 32.27, ROUGE-L: 31.01
BERTScore: 66.19

==============================================
==================== [59/100] ====================
Summary:
Adam Martin: I want to show you how you can go from being interested in some property of an organism, or even its behavior. How would you go from there to identifying genes and mechanisms that are responsible for that type of behavior or appearance? And on my title slide here, I have three fruit fly mutant phenotypes that you can see, and each of these mutants defined genes that were subsequently found to be present-- or homologous genes were present in humans and were shown to play important roles in human biology. The roundworm, Caenorhabditis elegans, and the fruit fly, Drosophila melanogaster, are heroes of today's lecture. Bacteria are also extremely important for elucidating the initial mechanisms of gene regulation. The mouse is our lab mascot, but it's also an important genetic model. Human cell lines are important, but you have to understand they're sort of an in-vitro system, that they're not functioning in the context of an entire organism. Most of them are fairly small, and they're easy to house large numbers of them in a lab. They're often cheap to house in the lab and work with. Also, they develop fast. 75% of the human-disease causing genes have a homologous gene in the fruit fly. So we're similar to these model organisms, in particular, genes that are important for understanding human disease. "Genetic approaches are as fundamental to biology as math is to physics," John Rinn said. Genetics really plays a fundamental role in biology and the discovery of new biological mechanisms. I'm going to take you through a type of approach that's called a "forward genetic screen" You don't need a genome sequence in order to do a forward genetic screen because you don't know the genes, but you're interested in a particular aspect of development, or of organismal function, and you want to identify the genes that are important for that. So the mantra of geneticists is that we are going to break genes and then look at the result. regulator of this orchestra, if you will? And so conceptually, what a genetic screen would involve is taking hundreds, maybe thousands, of orchestras like this one, and just shooting an individual in this orchestra. And rather than taking a gun and shooting members of the orchestra, in genetics, you try to identify mutations. So we're looking for mutations. And these mutations could be spontaneous mutations, meaning you didn't do anything to induce it, but they just appear as a variant in the population. mutations. The process of mutagenizing an organism isn't specific to genes. You're just inducing random mutations across the genome of the individual. You don't know which are the ones that you want until you look at their phenotypes and try to find the needle in the haystack. "What kind of a mutant might you look for? Anyone? Rachel?" asks Adam Martin. "A mutant with his head in his ass," says Rachel. "That's what I'm looking for." In model organisms, we can actually find these types of mutations. Maybe you have like a leg where your arm should be coming out, or maybe you have two heads, or something like that. So you look for some sort of defect in the pattern formation. And so this would be, obviously, unethical to do in humans, but in model organisms we can find these.body parts in the wrong place. But now, I want to talk to you about how one might find the needle in the haystack. Haystack: How can you identify genes that have that function in a given process? Haystack: Eric Wieschaus and Christiane Nusslein-Volhard did one of the more famous genetic screens that had been done, and they won the Nobel Prize for their results in 1995. How do you look for incorrect body patterning in flies at some stage of development that are defective in patterning? Yes, what's your name again? And so I'll show you how to do it. Drosophila larvae looks like. And you can see it has a segmental pattern here. But you see there are these segments that alternate between smooth cuticle and hairy cuticle. And because there's a lot of hairlike projections here, it reminded the researchers of a hedgehog, and so this mutant became known as "hedgehog" The hedgehog gene was the founding member of an entire signaling pathway that plays important roles in human development and also, human cancer. There are now a number of drugs that are being developed to target the hedgehog pathway. Robert Horvitz won the Nobel Prize for his work on how cells decide what fates they give rise to. His lab at MIT studied the worm Caenorhabditis elegans, which has 947 somatic cells. 131 cells, during the development of this animal, underwent programmed cell death. This is not random cell death; it's the same cells every time. A mutation that affected cell death that blocked this process is called ced-1. And what you see in this worm is a bubble-like structures that are dead cells but haven't been engulfed. Ced-1 is homozygous, in this case. And the worms are hermaphrodites, meaning they are both male and female sex organs. And therefore, they can self-fertilize. So this is a self-cross. And so ced- 1 remains homozygOUS mutant throughout all these crosses. And because a single worm has just one of these chromosomes, when it undergoes aSelf-cross, a quarter of the progeny will be recessive for the mutation. have these bubble-like structures in the adult world. So they identified a mutant, and thus, a gene, that's called "ced-3," which causes a failure of the cells to undergo cell death. If this is a bona-fide cell-death mutant, then you should have extra cells. And it turns out the ced-3 mutant blocks all 131 of these cell deaths. And this shows that the cell death is an active process. It's not just some random event that's happening. Adam Martin: Researchers looked for flies that didn't have a robust wake-sleep cycle. He says they identified mutations that cause this to happen. Martin: They wanted to mutate the X chromosome and then have the fathers pass on their X chromosome to their sons because there's only one copy of the X chromosomes. The researchers crossed these males to attached X females, and half of the progeny died because you can't have three X chromosomes, Martin says. "This is a really elegant way to look for genes that are important for circadian rhythm," he says.  defects in the genes that were identified in Drosophila actually are relevant to human sleep disorders. So this screen identified a gene called "period" This is a gene. And there's a hammer log of the period gene in humans. And the gene in human is associated with familial advanced sleep-phase syndrome. So these mutants that the Benzer Lab identified had altered period of the sleep-wake cycle, and therefore, the gene was named "period." All right, I'm all set.

ROUGE-1: 33.07, ROUGE-2: 30.65, ROUGE-L: 29.54
BERTScore: 68.70

==============================================
==================== [60/100] ====================
Summary:
In this chapter we will discuss two applications, one price control and second taxation, so right. Sir, does this slope of this graph denote anything price demand upon, some price upon some quantity. So, wait little later we will talk about that that topic, right now we are not, we are just talking about movement and shifts. We are not talking about the slope. Slope is also very important very good question but little later, we you have to wait little bit to get the idea about the slopes. Price ceiling is the maximum price for a unit of good established by law or by government. Price floor typically is minimum support price. Excess supply means there will be a downward pressure on the sellers to decrease their price. Government of India buys a lot of grains and what happens to that grain? It gets wasted because not only if you, let us say when market can support 5 rupees per kg and you promise that you will pay 6 rupee per kg you are producing more than what is required in the market. Price ceiling is below the market equilibrium level and this is the price ceiling. Excess demand and when we have excess demand what happens there. There is an upward pressure, but by law sellers cannot increase the rent or buyers cannot pay more. So, then what do we observe in the market. Role of government. Black marketing. Black market you know under the table payment, what else. Nothing will change. If market is operating at the equilibrium price and let us say the price of 1000 rupees per month. this country would like to have gas connection, but the suppliers cannot afford to give those many gas connections at the government-determined price. So, what they say you go to, you go for gas connection if it is your turn if somehow you are getting gas connection. What the seller would say that you want gas connection you will also have to buy gas burner from me then well you will get the gas connection ok. And that is also quite common. You are not interested in buying gas burner at really at the price which is much higher than the price that you will you have to pay in the market for a gas burner. Let us look at what happens when we have a price floor. Here you get excess supply then you have non-market rationing mechanism. Like the payment is not done at the time of buy, it is done after year or after few months. That can be one, again it is very difficult to discern it because of some other reason. And one more thing we have to pay a minimum wage to the laborers. So, to escape from that thing we include child labor. That is stretching too far. we have price control. It is to incentivize the production for a few like for wheat or if we talk if there is a new production of potato and if we put price floor on potato. So, it will incentivize production and they can serve the market better. That is also one more reason now that we do not have a proper distribution system by which we can distribute like some people with like below poverty line people, they are dying because of hunger, and we are throwing a lot of grains as surplus.

ROUGE-1: 30.72, ROUGE-2: 29.61, ROUGE-L: 30.45
BERTScore: 71.16

==============================================
==================== [61/100] ====================
Summary:
The size of the ribosome is similar to that of the rhinovirus, a little smaller than the hepatitis virus. In order to make proteins like hemoglobin and antibodies, we need large entities that are made up of either nucleic acids alone or nucleic acid plus proteins. The transfer RNAs are a large entity in the cell. They're big enough to see, whereas the small catalysts are out of view right now. The size of this molecular machine. This is we're getting pretty large now. Proteins themselves are not big enough to see. So that's what you're destined for today. All right, OK, so I've started to place on this board some of the molecular players, the messenger RNA, the transfer RNA, and the ribosomes, which are made up of ribosomal RNA plus protein. And I want to just remind you about the structure of the mature messenger RNA just for a minute because, in the last class, we talked about a lot of manipulations of that pre-messenger RNA. acids that might be designated as the so-called 21st, 22nd amino acid. We have selenocysteine in just very, very few proteins. There are other organisms, for example, in archaea, that have another amino acid known as pyrrolysine. So it turns out that the genetic code, which forms the basis of this entire concept, has some features to it where it does have some degeneracy. But we'll go through the degeneracy, and we'll take a look at the Genetic code because it will tell us exactly how the words made of three bases encode everything we need for translation. have the ideas, but, really, the definition by doing a process known as cell-free translation where they could very carefully add components to understand how the code, the genetic code, was formulated. So that's the work that Khorana and others did. And that was awarded them a Nobel Prize for that work. Later on, things started to get-- you know, these are decades of work I want to point out to you. The ribosomes were discovered. That was a decade later, the sort of details of the structure, but not the structure itself. And it was really exciting in the 2000s when Ramakrishnan, Steitz, and Yonath solved the structure of the prokaryotic ribosome. The ribosome is an important structure in the mechanisms of protein translation and synthesis. The 3 prime hydroxyl group of the last ribose within this ribosomal sequence is where the amino acid that's going to be loaded into your protein is attached. One of the loops has a special name. It's called the anticodon loop. It comprises three nucleotides that are complementary to the nucleotide in your messenger sequence. So this really is a decoder because, at one end, it's carrying an amino acid, but it's also carrying the aminoacid that corresponds to the code that's in the messenger via that anticodon loops. The genetic code gives you the identities of what are known as the codons, which is how we designate the triplet of nucleotides. So you can read, for each amino acid, what three-letter codon would correspond to it. And we'll generally tend to just stick with this one table and stick with it. So, if I'm going here, here, it's going to be starting UU. And then, within each block, there are the four alternatives for the other four bases. In bacteria, methionine equals a modified version of the amino acid. Methionine is fairly rare. There may only be one or two more in the protein. Some organisms might prefer two or three of the degenerate codons, and others may prefer a couple of the others. Some companies now will fix the codons in a gene for you to make them compatible with a different organism for expression. It's at its most extreme with residues such as leucine where there are six codons that specifyLeucine. The genetic code is the code that's going to be embedded within the messenger RNA. When you're looking to read what your amino acids that get put in may be, you're going to look at the codon. And it will tell you exactly the amino acid. A long time ago, I used to be confused because I thought I should be looking at the anticodon. And I was trying to translate everything, and it was a real mess. But it's the genetic code in that box that I just showed you is written down. need to be able to do that quite readily. All right, next portion, those monster-- loading the amino acid. The ATP makes this chemistry feasible, but there's one more player here. And that's the enzyme that brings them all together, which is known as an aminoacyl-tRNA synthetase. And it synthetases it. So that's how its name gets subtracted. So, with reference to an earlier question, what I'm showing you here are different. synthetases for different amino acids that show you that there's a recognition not just for the amino acid that's being loaded, but, rather, for the entire transfer RNA. So some of these look quite different. The isoleucine one interacts in one way. The valine one is a little different. And the glutamine one is different again. So they vary in the way they interact with the transfer RNAs. And, on those synthetases, there will also be specificity for the acids side chain. That's how you get the specificity. The small and large subunit is the messenger, the transfer RNAs, and the ribosomal all to scale in such a way that it can really explain it. What happens, first of all, is that the small subunit kind of floats along, looking like a fish. And so here's the messenger. It's being read 5 prime to 3 prime. And there's one more unit on here that I won't describe too much. Generally, it's thought to help the loaded tRNA come to theribosome, get it in place, and then go away. In each step, you're bringing in a tRNA that's loaded with an amino acid where the anticodon of the amino acid is complementary to the codon that's within the messenger RNA. Methionine is the first amino acid. And it's always at the N-terminus. Then there's another amino acid comes in. And then the next thing that happens is there's a movement such that a new bond gets-- a new amide bond is formed between the methionine and the phenylalanine. That's how that comes together. When proteins are made on the ribosome, they have a bit of a choice. They can get made and fold beautifully into active proteins. Those proteins could be modified. They could go to different places in the cell. Occasionally, proteins misfold. Maybe the rate of synthesis is too fast, or the environment isn't right. So there will need to be mechanisms whereby proteins get degraded if they're not folded properly. It's not always perfect, but what is known now is that they're starting to fold almost immediately from that N-terminus to, ultimately, attain their compact shape. fix errors is editing when you've loaded the wrong amino acid onto a tRNA. But what happens when the DNA message, the DNA starting point, is wrong, which means the messenger is wrong? So I'm just going to give you a couple of terms here. First of all, this entire chunk would be called the reading frame. It's the portion of DNA that's going to be read and transcribed into the messenger RNA. And, when you look at the two strands, you're going to have to figure out which one is the template strand. an error in the DNA that then causes anerror in the messenger RNA. So we have what's known as a frame-shift mutation. And what we've done by doing that is introduce wrong codons. The next types of mistakes are ones that are what are called silent mutations. Then the last ones are the ones where we start to encounter errors in DNA that result in errors in proteins that may cause genetically inherited diseases. The last one is a missense mutation where we've got an error in DNA, which has resulted in an error. quite what we would call conservative. Nonsense mutations are not so bad because you probably just truncate the protein. The missense mutations are the more serious ones because you end up with a full length protein that might have a mistake in it. And then that would affect the function. Am I being clear enough to everyone? Yeah? Good. OK, I am going to tell you that I'm handing over the baton to my colleague, Professor Martin. He'll take over on Monday. He's keen on genetics, yeah. "I think this field is fascinating. Once you get used to the mechanics of it, it's really cool to think of how you go from DNA to RNA to folded proteins," he says. "Don't forget my office hours on Monday if you need them," he adds. "I'll be in the lab all day, every day, if you want to talk to me about it." "I've got a lot of questions for you," she says, "but I'll be happy to answer them."

ROUGE-1: 37.16, ROUGE-2: 35.17, ROUGE-L: 33.29
BERTScore: 71.18

==============================================
==================== [62/100] ====================
Summary:
Professor Donald Kagan: We have been looking at the question of the rise of the polis and the various significant elements that were part of the making of thePolis. He says we are living in the early years of a polis sometime in the eighth century B.C. Kagan says every time we see a colony, learn anything at all about it, it appears to exist in the form of aPolis, which powerfully suggests that that was the typical style of life that had already been established for Greeks. These dates tend to be confirmed in a general way, not in a specific way, by the archaeological discoveries that we find at the sites. So it's that combination, archaeology plus Greek tradition that lies behind the date of any city. But you shouldn't take the date that I give you, the traditional date, as being firm. It's a general thing; it's around that time is the best we can really say. But in fact, the earliest date according to Greek tradition, if my memory is correct, was something like 773. the natural thing to do given the character of life, which was based upon farming, if you leave you lose your farm, and based upon the difficulty of transportation. The Greeks were, even though they went to sea plenty, they were terrified of the sea for very good reason. So, what I'm saying is, when you leave the place you were born, you leave your ancestors as well. All of that means we need to explain why these folks do what they end up doing, and we have some hints, but of course we do not know with any certainty or any confidence. The vast overwhelming majority of people needed to farm land, in order to stay alive. One answer, and it's the one that is most widely believed among Greek scholars, is that the growth of population that we have mentioned in connection with the rise of the polis is still working. But I don't think that's the only answer. I think the desire for commerce would have been also--I agree with the traditional view which is that this would has been at a lesser consideration, but still very important. Some of the places where they settled leave us puzzled, and have left the ancients puzzled. One of my favorite examples is the colony on the south shore of the Bosporus, which is called Chalcedon. They would have had to be damn fools to have settled there without that being in their minds. The Greek word for this is, apoikia, and most literally it would mean a home away, an away home. They are establishing for themselves a household, a home someplace away from where they started. Delphi was thought by the Greeks to be the omphalos, the navel of the universe, the center in every way. There the god Apollo had established an oracle. Gases would escape through this gap in the earth and there were priests who worshipped Apollo there. They would place a young woman there who would sit as these gases came up and she would after a while begin to, I suppose in the biblical languages, she would speak in tongues, which is to say she would rattle off a lot of language. The French School of Archaeology late in the nineteenth century dug everything up and concluded this was baloney; it was a myth. There were no gases coming up from any of this stuff, and so everybody believed for the next century. John Hale of the Yale Class of 1973, who is now an archaeologist at the University of Louisville, decided to investigate this. He took with him a fine geologist from Wesleyan just to go to the place there at Delphi and to see whether it could be true that such gases did come out. In Herodotus, many a story in which an oracle is consulted and gives an answer. King Croesus of Lydia, the richest man in the world, decides it would be a nice thing to conquer the Persian Empire, his neighbor to the east. He goes to the Delphic Oracle too, because you want to know what the gods want. He said, "If I cross the Halys River, that's the boundary between Lydia and Persia, what will happen?" The oracle replied, "A great empire will be destroyed" The Delphic Oracle was the best information gathering and storing device that existed in the Mediterranean world. consulting that oracle was a very rational act indeed. The priests would give a response that would be essentially straight. It would either say something like, yeah that's a good place to go or don't do that, that's an awful mistake. These people knew more than anybody else about these things, and so consulting them was a rational act. It was the navel of the universe; everybody came. will decide whether it's a good idea for him or not. Recruiting is tremendously important because you need to have a certain number of settlers to make the settlement viable. So however many that is, that is what you try to recruit and you recruit typically at a time when it's easy to get people together so you can tell them the story. The best time would be at some great festival. There are festivals held in each city just for its own citizens and my guess is that when you could do that, when you felt that you could recruit a full colony from your fellow citizens in Corinth, that's what you did. Syracuse is an independent polis, autonomous, self-governing, whatever regime it wants, etc. It is not a subject of anybody, not Corinth or anybody else. The most typical, the usual, everything else is an exception is that there are friendly relations between the mother city and the apoikia, but keep in mind that they are always independent. The question really is, so now we know that, what kind of relations did they have? I would say there are three categories that they fall into. The city of Corinth sent out a lot of colonies, which is why we know something about their arrangements. When Potidaea got into trouble with Athens, and found itself besieged, Corinth sent a real army to go in there and fight. At the other end of the spectrum it's again Corinth and they have a colony up in the northwest called Corcyra. The first relationship between them is a navel battle, and thereafter we hear of them quarrelling and fighting with each other just about at least once a century right on down. More time, that the overwhelming normal situation is the first one I described, friendly relations. These guys that have gone out, let us say to Syracuse, they are your people, they have relatives back home. It is natural--oh by the way, they're accustomed to worship the gods in the same way that the Corinthians do. We do know, again, Thucydides is our source, that it was customary for colonies to send representatives back to the mother city for the religious observations that were common to them all. Kagan: The question is who gave permission for a colony to go in the mother city. The best guess and that's the only thing we have. These would have been aristocratic republics at this stage of the game. Kagan: Nobody was compelled to do anything. Everybody--all of this is voluntary on both sides of every agreement. The British practicing mercantilism passed navigation acts, saying what ships could carry what and so on--nothing like that in the Greek world. By the tenth century B.C., we see Greek cities lining the coast of Asia Minor on the west, and even around on the bottom and to some degree on the north, and on the islands in the Aegean. So, there has been a Greek--what's the word I want? There is an expansion of the Greek world already by the 10th century. The way the Greeks did their immigration into Asia Minor actually had a pattern so that you can go from north to south and you will find some consistency. There are no Greek cities as you keep coming down and pass Palestine. You reach Egypt, and of course, Egypt is one of the great empires of antiquity going back into, perhaps, certainly into the fourth millennium. So that is not territory that you can build colonies; you've got powerful empires to deal with. There is one exception. In the sixth century, I think it's around--imagine around 550 or something like that, the Greeks settle a single colony in the Delta. of the Nile of Egypt at a place called Naucratis, and the root of that word is ship. It is a trading post and it's there by permission of and under the protection of the King of Egypt. When you go west, however, it stops in the coast of North Africa--the reason being the rest of North African is dominated by Carthage. Going west, would you believe, when you get into what is now Libya, there was a very important Greek colony of Cyrene. Greek cities are all over the place. Two-thirds of the coast of the island of Sicily is filled with Greek towns. The inland, the Greeks don't move in there. The natives Sicilians inhabit that territory and the Greeks didn't move there. So Greek was that area that when the Romans do come to dominate most of Italy and sort of move up against the southern region they refer to the whole southern portion of that peninsula as Magna Graecia, great Greece because they're all Greeks down there. Greeks are not interested. You will find very rare of the case of a Greek city, which is founded away from the sea; they always wanted to be close to the sea. Miletus, I mentioned to you from Asia Minor; Corinth on the isthmus; Megara right next door to Corinth. Then we turn to the island of Euboea, that long island that's right next to the east coast of Attica. There were two important cities in the northern part of that island. One was Calkis and the other one was Eretria. is easy to see that where there is that kind of conflict and trouble, there would be people who would want to flee that and to go elsewhere. It might well be that the people who won those wars, internal wars, would have been glad to send them away rather than to have these discontented people and these folks who were their enemies hanging around town and making trouble. It is only speculation, but it seems to make sense and we know we don't hear of such troubles within Athens and Thebes, and Sparta. interesting information from their neighbors in the east and the south and there's no question about it. Anybody who looks at the earliest Greek art for quite some time, I'm talking about sculpture and temple building, will see the influence of Egypt enormously powerfully. The Greeks are sopping up tremendously useful information and talent, and skills, and all sorts of things that help explain what's going to be coming. It is inconceivable the Greeks could have developed a civilization that they did without contact with these eastern civilizations and learned a great deal from them. More and more people would be making their living in a way that was not agricultural. They would be in commerce and industry in this small sense and doing all the various things that are not farming. So you now have classes or groups of people who have interests rather different from those of the most primitive polis you could imagine. Some scholars early on in the century, moved by Marxist theories, suggested that you had a capitalist class growing up, there's just no evidence of that. My guess is that the earliest traders of any scope were probably noblemen who also had land and estates back home. way has to be found to fit them in because, as I say, they don't fit. That creates trouble. As we shall see very shortly, that trouble often takes the form of first of factional struggles within the aristocracy, which then after awhile come to involve people outside the aristocracy. So that's the, what you might say, is the negative side of the story. But colonization, especially, some scholars have pointed out, I think persuasively, also for some considerable time provided an answer to that problem. that colonization provided something analogous to that for the Greek people. So now, here we are somewhere in the seventh century, most of these places I've been talking about have been settled, the currents that I have been describing are flowing and the kinds of problems they have give rise to what will be felt in most of the towns. That is the proper introduction to the next topic, which I'll discuss next year. No not--it seems like a year, but it's next Tuesday actually.

ROUGE-1: 36.40, ROUGE-2: 34.97, ROUGE-L: 34.74
BERTScore: 72.59

==============================================
==================== [63/100] ====================
Summary:
Instructor: We are asked, which of the following correctly identifies the areas of consumer surplus, producer surplus, tax revenue, and deadweight loss in this market after the tax? So pause this video, have a go at it. Even if you struggle with it it will make your brain more attuned to when we work through it together. All right, now let's work through this together. And I just want to sort of understand what's going on here before I even try to answer their questions. original total surplus was this entire triangle. Now the total surplus is this trapezoid that's the sum of all of these areas. And so what we lost is this area right over here. So that is the deadweight loss. So T plus W is equal to the dead weight loss. And we're done. Back to Mail Online home.back to the page you came from. Back To the pageyou came from, back to thepage you came From. Back into the page.

ROUGE-1: 26.43, ROUGE-2: 24.39, ROUGE-L: 24.35
BERTScore: 71.33

==============================================
==================== [64/100] ====================
Summary:
Sir Gawain, nephew of King Arthur, was invited to a party at Camelot. A towering knight riding an emerald steed burst into the room and proposed a game. The Green Knight declared he would allow the bravest warrior present to attack him with his own axe. If they could strike him down, they would win his powerful weapon. However, the knight would be allowed to return that blow in one year and one day. In the months that followed, Gawain tried to forget this bizarre vision. But despite the strangeness of the knight’s game, he was determined to act honorably. of Arthur’s knights. He’d planned to spare his neck entirely, until Gawain concealed the sash. Filled with shame, Gawain returned to Camelot. But to his surprise, his companions absolved him of blame and celebrated his valor. Struggling to understand this strange journey, it seemed to Gawain that perhaps the whole world was playing a game. With rules more wild and bewildering than any man could understand, he wondered if the world was a game, too.

ROUGE-1: 39.86, ROUGE-2: 36.03, ROUGE-L: 36.87
BERTScore: 68.79

==============================================
==================== [65/100] ====================
Summary:
well welcome back everybody to uh the last lecture 162. this is kind of a a special lecture um i did get some requests for more information about distributed storage and quantum computing and so i think we're going to do that. i want to make sure that we talk through the chord algorithm since that's a i think relatively simple thing to understand and is very cool and applied pretty much everywhere so if you remember one of the things we talked about last week was basically this cap theorem which was really a conjecture that eric brewer put forth back in the early 2000s. the value that you started with and so this interface is extremely simple it's certainly an interface uh many of you have used in languages on a single machine. If you use this in a global storage system it turns out that the interface is simple enough that you can have some pretty interesting um implementations. So today i want to tell you about the cord uh algorithm which uh has been turned into storage systems of many sorts including those used by amazon et cetera okay facebook so um before we get there i wanted to remind you of this notion of recursive versus iterative lookups so um. The challenge of that central directory is really that it's got many entries that are sort of key value pairs or at least key node mappings and you could have billions of entries in the system and so um i would say that anything that thinks of a directory here like a single server is bound to be a bad server. Here's an example of a recursive lookup which is like routing so basically if i say i want to get uh whatever key 14 has got it goes to the master directory and then that directory forwards it on it routes it to the particular node. idea okay because it's just not going to scale the billions of entries very well all right and back in the early 2000s myself and a bunch of other researchers started looking at how do you deal with peer-to-peer technologies as a way to solve this problem. One solution here is consistent hashing which i'm going to tell you about um we did tellYou about it last time but i want to reemphasize what it is. The chord algorithm lets you get by with only knowing essentially a logarithmic number of nodes in the total system. So imagine you take their i don't know their ip address and their owner and whatever you concatenate all those things together and you hash them and you get a single 256-bit id out of that now we're going to talk more about secure hashes a little bit later in the lecture. Every node has an id and it's going to be in this ring space this unit dimensional space from 0 to 2 to the m minus 1 where m is big okay and so let me just show you the picture here. said in practice m is really something more like 256 and so uh this ring is really big and um these nodes are much more sparsely distributed around the ring okay questions we only have a very small class today so you guys are likely to get your questions answered anybody okay no questions all right should we move on now is a system that was developed uh with a group of researchers at mit and at berkeley um and you can think of it as a distributed look-up service. In my view i like to teach about it because it's the simplest and cleanest algorithm for distributed storage that i have seen. all these nodes but we're looking down from above and you can clearly see that no lookup for a t37 is going to want to get back node 44 because that's what's going to store key 37. so how does this happen well 4 says well i don't know what it is so it routes to 8. it says i don’t knowwhat it is that's 15 rounds to 20 32 35 this point 35 knows that it's uh successor is 44 and so it just responds back and says hey i happen to know that node 44 is responsible for key 37 and at that point uh node4 can talk back to the client and the client now knows just to talk to 44. got a thousand nodes that are storage nodes i may have to take many hops to find out uh what i want here um it turns out that the worst case lookup here is order n so that's probably bad but we're going to show you how to get login in a little bit it's going to be a dynamic performance optimization and so on that'sGoing to be pretty interesting now what I want you to see though is from a correctness standpoint as long as every node knows who its predecessor is and successor then we can always find the server we're looking for. means that no particular part in the in the world here might be a hot spot it means unfortunately though that we don't have the most uh local of look up because if we start at node four it'd be nice if we could just go down to 15 and back okay now this is a really good question here about redundancy how do we get redundancy out of this for the moment uh suspend that question for just a second certainly we could put raid servers or what you know raid storage on each of these nodes and that would be great if the disks fail but uh we would like something even more powerful because i don't know if there's a big earthquake and california falls off into the ocean it'dbe nice to know that key 14 survived somehow. with dns you need to know how to talk to local at least one dns server somewhere before you can start resolving names okay so the first thing i want to talk about is how can we make sure this this ring stays connected even though nodes are failing and coming back okay. How we can make sure it's connected is we're going to have this dynamic stabilization procedure so every node can run stabilize. If it finds a problem it can run notify to help reconnect the ring okay so let's uh these are the kind of things that are a lot easier to see with animations. about this algorithm is all that the ring is going to do is it's going to figure out who is responsible for storing key 50 as if this was just a regular key value lookup. So just by asking the ring where key 50 belongs it now has some information about nodes that it can talk to. If you lose two nodes in a row then what i've just described to you is no longer going to work so there is a way to completely break the ring such that the stabilized procedure won't reconnect. There's a way to do that as long as you have multiple links and what we're going to do right now for performance is going to make that even harder to destroy the connectivity okay. Rather than just keeping track of nodes forward and backward what we'll do is we'll keep track of uh our current position plus uh 1 plus 2 plus 4 plus 8 plus 16 and so on. The question would be what node would store 81 well that would be here at node 80. And if you have a leaf set with more than one node by the way though okay now. Think about this as bit correction. We're going to keep track of a logarithmic number of these pointers. We just query the ring and ask it oh i want to store each of these keys. What will come back from the ring is which node is responsible the power the powerful thing about this is once i've got all these nodes now i can do a really fast routing process to figure out how to find which nodes are responsible for the key i'm interested in. The power of the finger table is that you can view that like i'm correcting the bits from my starting point to my destination. my ending point i'm correcting them one at a time by taking these various hops okay and that's how we end up with logarithmic routing time. This forest of additional pointers plus the extra pointers from the leaf set together make it really hard to be uh unable to reconnect the ring okay and so if you read that chord paper it talks about how you make use of all the information you've got to keep the ring connected okay questions okay we're good now let's think a little bit more about data. The only place for key 14 to be stored as on node 15. If node 15 weren't there key 14 would be stored on 20 right that's just the next node up from 14 since the only copy of key 14 it's currently stored on 15 if 15 dies or goes away we don't have the data. So we can't store it there because we've lost our data so we got to do something else here okay. We're going to store 14 on the successive nodes that we know about because of the leaf set so we'll store it on 20 and 32. algorithm and so what's good about this is like i said you store the data in the cord ring and it it's very hard to destroy okay why are they called leaf sets that's a good question the reason they're called Leaf sets is because in some sense you can view the uh if you take any given um starting node like 58 and you view the set of fingers that’s a tree and so eventually you get to the leaf set and so it's like a tree with leaves so that's where the leaf is coming from and here's an example of that. with our replication but it also serves as uh as part of the last couple of hops we can use the leaf set to basically find who's supposed to have our data all right um now so let's look at replication from a physical standpoint right so if you look again at this ring i showed you a little while ago that ring is mapped physically to things that are spread widely. Now we can see another big advantage of the randomness introduced in chord and that advantage is that these copies are actually stored in geographically separate places. Think of this like a dns built out of cord and so what the client does is the client doesn't know where the data they're interested in is they ask the cord ring. The cord ring tells them who to talk to and then they can talk directly to them and exchange data over the shortest path possible. So you can now get the best of both worlds and that you have very hard to destroy lookup process and then you can choose to replicate that data on close to the client. The cord ring is really about making sure that they can get their performance within a small number of nines okay and so the availability is an important aspect here. You have a service guarantee that says we'll get a response within 300 milliseconds uh for say 99.9 percent of the requests okay. This is very in contrast essentially to what we've been talking about a lot of the rest of the term uh which is focusing on mean response time instead we want to have guaranteed performance okay and this is again thinking i want you to think back to when we were talking about real time scheduling. it adapts automatically which is pretty good okay so what i wanted to do next uh i'm going to talk a little bit about security and then um talk through a couple of things and then i want to uh try to get to quantum computing as well so we can i know there was some of you asked some questions about that so i'mgoing to leave this topic unless there's more questions okay. Security is kind of dealing with actions of a knowledgeable attacker who's really trying to cause harm and we want to make sure that uh they can't really screw us up. about by using new techniques and the distinction between protection and security i think is an important one because protection is the set of mechanisms that we talk about in this class security is basically using those mechanisms to prevent misuse of resources so for instance virtual memory is a mechanism that can be used for protection security policy would be making sure that when we use virtual memory we don't let malicious processes or different processes owned by different people use the same memory and have a potential for screwing each other up so that would be a security policy built with our protection mechanisms. The rise of fake data which is kind of much worse than fake news which is about corrupting the data and making the system behave very badly. We have several security requirements that people talk about so authentication is making sure that a user who's making changes to the system is really who they claim to be data integrity is makes sure that the data hasn't changed okay so that's important confidentiality is make sure the data is read only by authorized users. Non-repudiation is a surprisingly important thing that people don't often talk about which is that if one sender makes a statement and they uh send a message or whatever they can't later claim that well i didn't really send out somebody malicious did. making sure that you can't repudiate things that you've previously said and so i'm hoping that if you haven't taken 161 it's on your list because there's a very interesting set of things that people can talk about. cryptography is one of the central points of many of these mechanisms you just have to use it correctly. This is communication that's in the presence of adversaries uh it's been studied for thousands of years there's actually something called the code book which you should look up. single symmetric key encryption work which symmetric because the same secrets used at both sides is to prevent a adversary from holding on to an old message and sending it later. You have to start adding what are called nonces which are things like timestamps and so on so that every time you send this it's unique and if somebody sends an old version you can detect it. The idea of a secure hash function is one where you take data and you run it through a hash function and you get a bunch of bits. to come up with two different items that you come upwith yourself that have the same hash function okay and so that's why we can kind of use hashes as a proxy for the data itself. So for instance in that firmware problem with the car we could have a key that only came from the manufacturer in a secret way and we could check the integrity of that firmware against the manufacturer and if it was not corrupted then it wasn't corrupted. So we can use hashes to prove later that you know after the transmission has happened that the data is authentic okay so hashing is pretty powerful. it wasn't uh you know if the integrity wasn't high you know it was basically didn't match then we could know that that firmware is probably bogus and we shouldn't be using it okay now the downside of course of everything we've talked about is both sides share the same key and so if you leak the key then you got problems okay and furthermore you have to somehow share the key so that requires you to go in a dark alley and you know hand the key over and so this seems like only part of the solution and um the interesting thing about that is this idea of public private key pairs. A virtual machine that's in modern hardware that allows you to set up a secure channel and do some secure encryption in a way that not even the local operating system can see the data. This is what i like to call as border security rather than data security and so if you think well i'm going to put some firewalls and now i can say look this is a trusted computing base that's secure this is one as well there's one around the cloud and then you know the only thing left is cell phones which i make secure tunnels with. have any breaches inside the trusted computing base then all of a sudden not only is the data breached but somebody who is inside that firewall can produce data that looks authentic uh even though it's not. The real reason we get these data breaches everywhere is because people think that they can put these boundaries up in a way that don't um can't be breached and of course we know that's not true. The problem really is not only are things breached but the integrity and the provenance of that data is not known so what do we do the data centric vision. there'd be people there that would unpack them and then you'd have to figure out how to put them on trucks and so on and it was a mess and basically one person that said well why don't we just make things that are all the same size and shape and then all of a sudden we've got ships trains cranes all of the the infrastructure for handling these things are the same across the planet. Now i can ship something from my house in lafayette to beijing the outskirts of beijing just by calling the right trucks to come pick up a shipping container. Underneath the network is like the ships and trains and cranes and planes that handle this standardized metadata and what is the standardized metadata well it's a hash over an owner key and some other metadata about who created this and that forms a unique address that you can route to in our system. Standardization makes it possible for the infrastructure to be put everywhere and it benefits everyone federation you can actually build a market of service providers the data becomes a first-class entity so your data basically can float pretty much anywhere. is one where you instead of paying for ip service you'd pay for data capsule service and um you'd be able to store your data in a way that was secure okay and could be used anywhere you want and you'd own your data okay so physical view just one last little slide here and then i'll move on to to the uh quantum computing so i want to make sure we cover that but if you think about ip the way we talked about it briefly in a couple of weeks prior if you look at the physical view of ip there's a bunch of routing clouds and there's also transit providers. how we want to be dealing with data all right sorry if that's a lot of information but i wanted to see if there's any questions there before i switch over to some quantum computing all righty give me a second i'll be right back and then we'll see ifthere are any questions that came up one moment okay so good so we have some good questions here so first question is how do we know the data is secured so um just like with a blockchain let me just back up to the picture here which i think is a is a good one to be talking about. The data capsules are cryptographically hardened bundles of data. They are not forgeable and can't be swapped or swapped or whatever. If somebody tries to put garbage in there a legitimate person who's trying to look at this can just throw the garbage out because there's no way that that garbage could have been put in there. If you have a signature only at the end of a chain of data you can essentially check the rest of the chain by checking the hash pointers so these are all of the things you get out of a blockchain by the way. The vision here really is of pretty much everybody using data capsules everywhere okay and if you can get that to happen then you potentially have a very interesting scenario here. If any of you want to come work on this project come talk to me uh separately we have plenty of uh places we can talk to you okay now i'm gonna i promised you some quantum computing i did wanna show you one other interesting slide here potentially which shows you kind of an idea of how we can build things up um here. put their data and their models for grasping and so on inside of data capsules and as a result they can reside securely in uh in the edge in say your robots or whatever in a way that can't be breached okay. This is really targeted at secure edge infrastructure in addition to the cloud so these data capsules can move back and forth but certainly you need something like this on the edge because these pieces of hardware are easily breached and you want to make sure your data is is uh secured and unforgeable all right good.  quantum computing is basically using quantization and superposition to compute. If you could get a shores algorithm running on a quantum computer pretty much all rsa cryptography would be broken because you could factor. material simulation was kind of the original uh the original application of quantum computing that was thought of. If i'm really interested in designing exotic new materials to build interesting things i probably want a quantum computers. There are many other algorithms out there now these days they've been slowly working on them but these are some pretty good ones that give you an idea why this might be interesting.  quantum computing technology is not going to be in your laptop at least not in any laptop i'd want to put on my lap but there are other types of technologies including ion traps that potentially are pretty interesting. These computers by being built by google and ibm have you know maybe have order 100 bits maximum it's very hard to do anything interesting with 100 bits but they're focusing on demonstrations that show that with those 100 bits they could potentially do something a lot better than a classical machine so that's called quantum supremacy. spin one-half particles are particles that can only spin with the axis pointing up or down nowhere in between. A representation called the heisenberg representation looks at this messy physical situation like this which is either a zero or a one in these brackets and that represents spin up and spin down okay or vice versa depending on how you want to look at it. One proposal for building quantum computers from way back when was called the cane proposal and those spins were actually what you got when you embedded phosphorus impurity atoms into silicon. something people were looking at okay but the temperature here was less than one kelvin which is really cool okay but let's suppose now here's where the quantum computiness gets pretty tricky okay. If you think of the zero and the one thing okay this is actually a wave function if you take quantum mechanics representing spin up and spin down. What you see here okay with this psi function isactually a superposition of zeroness and oneness together okay now you know i realize this looks a little weird we don't normally get a wavefunction notation in 162. The way we build a computer is we take a complex state like i just showed you and then we put it through a bunch of adders whatever you want to call it which are really all unitary transformations. If we measure one of them like let's suppose we measure and find that there's a zero back on earth we know instantaneously that we got a zero on the other side okay. So that looks like we had faster than light travel in fact instantaneous travel of information from the earth out to that far planet einstein really didn't like this he called it spooky action at a distance okay. you do a bunch of computing on it such that the probabilities are kept and you measure okay and the way it looks is that you take uh let's say you put an input with all possible combinations of the input input of the inputs being equal values all possible probabilities it looks like you're doing computation on all possible values at once but then when you measure you pick up exactly one and that's the answer you get okay. So basically what we're talking about here looks like a random computation like you get in cs70 or 170 where you randomly pick an input you compute on it you look at the result so that's not very interesting right. The difficulty of factoring rsa is figuring out how to take a large number which is publicly known and factor it into two large factors that are primes. If you can do that you break the cryptography so classically this is an exponential time algorithm and so as long as these are big enough nobody's going to break it quantum computer can do it polynomial time and let me show you how here's how it is in a nutshell you pick a random x between 0 and n that's easy. This out what r makes this equiv equation satisfied and we could do that quickly then um we win and that's something that uh you can't do easily classically but with a quantum computer what we can do. i can set up a situation where my input to my algorithm is all the possible k's uh if i take a bunch of values and i compute uh the the value x to that value and i add them all together as a superposition and i do a fourier transform what i'll find is that x to the r congruent to one as i have r go through all its possible values. question is is this something to worry about the answer is well so far no but it's looking like um it's getting closer and closer okay. We actually investigated ways of optimizing that and we could actually look at performance of different options for the shortest factoring algorithm as quantum circuits. We built a cad tool to do that so um i i don't know i think it's a pretty interesting area right now and there's a lot of interest in it all right so um sorry i kept you guys way over but this is the last lecture i figured if anybody was interested. i think it's it's pretty exciting project we got working on it if anybody's interested in that and then we told you a little bit about quantum computing and uh feel free to come ask me or also look at 151 or 191 excuse me um which is an interesting class on quantum computing all right well thank you everybody sorry for going way over today thank you for those of you that stuck around and uh i hope you have a good uh finalizing of project three andThose of you listening in cyberspace later as well you are all great.

ROUGE-1: 44.54, ROUGE-2: 43.23, ROUGE-L: 42.98
BERTScore: 71.62

==============================================
==================== [66/100] ====================
Summary:
Early astrologists did not recognize the lymphatics so they thought there are only three system there is a branch of portal or this branch of puerto bean. Originally doctors thought that every corner these three things are present and they call it portal triad. But later on of course the new it is not portal Triad it is portal triads. The liver is really working is that right that blood is again there are two input system hepatic arterial input and what was this portal venous input.

ROUGE-1: 14.07, ROUGE-2: 13.44, ROUGE-L: 14.07
BERTScore: 61.32

==============================================
==================== [67/100] ====================
Summary:
Causality is a property that is always true in our universe which is causality causality says that the policy at time t prime can't affect the reward at another time step t if t is less than t prime. This is another way of saying that what you do now is not going to change the reward that you've got in the past. The only way this would not be true is if you had time travel and you could take an action or travel back into the past and change your action. that we're going to see this is we're Going to rewrite the policy grading equation i've i've not changed it anyway i've simply rewritten it and what i've done here is i use the distributive property to distribute the sum over rewards into the sum of grad log pies. At every time step i multiply the grand log probability of the action at that time step t by the sum. of rewards over all time steps in the past present and future. If we generate enough samples eventually we should see that all the rewards at time steps t prime less than t will average out to a multiplier of zero. the proof is somewhat involved so i won't go through it here but once we show that this is true then we can simply change the summation of rewards. Instead of summing from t prime equals one to capital t simply sum from t Prime equals t to capitalt basically discard all the rewards in the past because we know the current policy can't affect them. For a finite sample size removing all those rewards from the past will actually change your estimator but it will still be unbiased so this is the only change that we made. in the previous lecture we will get much more into this in the next lecture when we talk about extra critical algorithms but for now we'll just use a similar symbol with a hat on top to note that it's a single sample estimate all right now the causality trick that i described before you can always use it you'll use it in homework two it reduces your variance there's another slightly more involved trick that we can use that also turns out to be very important to make policy gradients practical and it's something called a baseline. grad log p by r of tau we multiply by r  where b is the average reward this would cause policy gradients to align with our intuition. subtracting a constant b from your rewards in policy gradient will not actually change the gradient in expectation although it will change its variance meaning that for any b doing this trick will keep your grading estimator unbiased. The average reward which is what i'm using here turns out to not actually be the best baseline but it's actually pretty good. In many cases when we just need a quick and dirty baseline we'll use average reward however we can actually derive the optimal baseline. baseline to optimally minimize variance so to start with we're going to write down variance. The variance of the policy gradient is equal to the expected value of the quantity inside the bracket squared minus the whole expected value squared. The first term in the variance doesn't depend on b but the first term does so then in order to find the optimal b i'm going towrite down the derivative d var db and solve for the best b. The baseline actually depends on the gradient which means that if the gradient is a vector with multiple dimensions if you have multiple parameters you like to have a different baseline for every entry in the gradient. different policy parameters you'll have one value of the baseline for parameter one a different value for parameter two. In practice we often don't use the optimal variance we just uh sorry we typically just use the expected reward but if you want the optimal baseline this is how you would get it all right so to review what we've covered so far we talked about the high variance of policy gradients algorithms. We talked about how we can lower that variance by exploiting the fact that present actions don't affect past rewards and we can use baselines which are also unbiased.

ROUGE-1: 43.97, ROUGE-2: 42.71, ROUGE-L: 43.91
BERTScore: 71.63

==============================================
==================== [68/100] ====================
Summary:
Today we're gonna talk about learning in the setting of games. Can you still be optimal if you reveal your strategy? It's actually not the size that matters. It's the type of strategy that you play that matters, so just to give you an idea. And then, er, towards the end of the lecture, we wanna talk a little [NOISE] bit about variations of the game- the games we have talked about. So, uh, how about if you have- how about the cases where we have simultaneous games. going to pick bucket A, bucket B, or bucket C. And then the opponent is going to pick a number from these buckets. They can either pick minus 50 or 50, 1 or 3 or minus 5 or 15. So if you want to maximize your, your utility as an agent, then you can potentially think that your opponent [NOISE] is trying to, trying to minimize your utility, and you can have this minimax game, kind of, playing against each other. game of chess. And if you think about the game of chess, the branching factor is huge. The depth is really large. It's not practical to u- to do the recurrence. So we, we started talking about ways to- for speeding things up, and, and one way to speed things up was this idea of using an evaluation function. So instead of the usual recurrence, what we did was we decided to add this D here, um, this D right here which is the depth that un- until which we are exploring. In chess, you have this evaluation function that can depend on the number of pieces you have, the mobility of your pieces. Maybe the safety of your king, central control, all these various things that you might care about. So, so the hand- like you can actually hand-design these things and, and write down these weights about how much you care about these features.and figure out what is a good evaluation function. So to do that, I can write my evaluation function, eval of S, as, as this V as a function of state parameters. how learning is applied to these game settings. And specifically the way we are using learning for these game. settings is to just get a better sense of what this evaluation function should be from some data. And, and that kind of introduces to this, this, um, temporal difference learning which we're gonna discuss in a second. It's very similar to Q-learning. Uh, and then towards the end of the class, we will talk about simultaneous games and non-zero-sum games. at a simplified version of it. So in this simplified version, I have Player O and player X, and I only have four columns. I have column 0, 1, 2, and 3. And the idea is, we want to come up with features that we would care about in this game of backgammon. So maybe like the location of the X's and O's. The number of them. Maybe fraction of X's or O's that are removed, whose turn it is. these indicator functions. You might ask number of O's on the bar that's equal to 1, fraction of Os that are removed. So, so we have a bunch of features. These features, kind of, explain what the sport looks like or how good this board is. And what we wanna do is we wanna figure out what, what are the weights that we should put for each one of these features and how much we should care about, uh, eachOne ofThese features. In general, you would need to do something like Epsilon-Greedy. But in this particular case, you don't really need to. Because we have to get- we have this die that, that you're actually rolling the dice. So we, kind of, already have this, this element of randomness here that does some of the exploration for us. Yes. And you just mean like unexplored probability? Yes. So, so that's the key idea. We call these policies. We go over them to make things better and better. So, so what you have is you have a piece of experience. Let's call it s, a. You get some reward. Maybe it is 0. And you go to some s prime through that and you have some prediction. Your prediction is your current, like, your current V function. So, so my target the thing that I'm trying to like get to is the reward plus Gamma V of s prime, w. And then we had a target that you're trying to get to. And my target, which is kind of like my label, is going to be equal to my reward. is simple, right? 2 reduced, 2 gets canceled. Gradient is just this guy, prediction of w, minus target, times the gradient of this inner expression. So so far so good. Um, so this is the TD learning algorithm. This is all it does. So temporal difference learning, what it does is it picks like these. pieces of experience; s, a, r, s prime, and then based on that pieces of. experience, it just updates w based on this gradient descent update. This is very similar to Q learning. There are very minor differences that you'll talk about actually at the end of this section, comparing it to Qlearning. All right. So, so I wanna go over an example, it's kind of like a tedious example but I think it helps going over that and kind of seeing why it works. Especially in the case that the reward is just equal to 0 like throughout an episode. So it kinda feels funny to use this algorithm and make it work but it work. Is it that possible to have, an end state and not end state have the same feature vector, or no? If you use like, uh, initialize rates do not be zeros which you update throughout instead of just to the end. To differentiate between S4 and s- S9 to, to differentiate between them, you should pick features that differentiates between them. If there were kind of the same and have same sort of characteristics, it's fine to have feature that gives the same value. So for the second row, I'm not gonna write it up cause that takes time. So, uh, so okay, so let's start wi- with a new episode. We started S1 again but now I'm starting with this new W that I have. Uh, they always have to be the same dimension, and what should we be thinking about that would make a good feature for updating the weights specifically, like- so, so it should be a representation of how good your state is, and then it's- yeah, it's usually like hand designed, right. of 10, uh, if you're using the same feature extraction for both, how does that affect the generalized ability of the model, the agent? Yeah, so, so you might choose two, two different features and one of them might be more like so. So there is kind of a trade-off, right? You might get a feature that actually differentiates between different states very well, but then that makes learning longer, that makes it not as generalizable. So, so picking features, it's, it’s an art, right, so. [LAUGHTER] that we are looking at in Q-learning, but there are some minor differences. So, so the first difference here is that Q- learning operates on the Q function. A Q function is a function over state and actions. Here, we are operating on a value function. On V. And V is only a function of state, right? And, and part of that is, is actually because in the setting of- in setting of a game, you already know the rules of the game. The idea of learning in games is old. People have been using it. In the case of Backgammon, this was around '90s when Tesauro came up with, with an algorithm to solve the game. So, so that's what we've been talking about so far. And the idea of using learning to play games is, is not a new idea actually. Of this idea of, I have this evaluation function, I wanna learn it from data, I'm going to generate data from that generated data I're going to update my W's. In 2016, we had AlphaGo, uh, which was using a lot of expert knowledge in addition to, um, ideas from a Monte Carlo tree search. And then, in 2017, we have AlphaGo Zero, which wasn't using even expert knowledge, it was all, like, based on self-play. Uh, and the idea of TD Learning is, is to look at this error between our prediction and our target and try to minimize that error and, and find better W's as we go through. Minimax sca- strategy seemed to be pretty okay when it comes to solving these turn-based games. But not all games are turn- based, right? Like an example of it is rock-paper-scissors. You're all playing at the same time, everyone is playing simultaneously. The question is, how do we go about solving simultaneously, okay? So let's start with, um, a game that is a simplified version of rock- Paper-Scissors. This is called a two-finger Morra game. So, we have player A and player B. We have these possible actions of showing 1 or 2. And then, we're gonna use this, this payoff matrix which, which represents A's utility. If A chooses action A and B chooses action B. So, so I'm trying to like get good things for A. Yes. In this case it's not at the end [inaudible] ? Uh, yeah. And this is like a one-step game too, right? So like you're just playing and then you see what you get. stochastic policies. So, so pure strategies are just actions a's. And then you can have things that are called mixed strategies and they are probabilities of, of choosing action a, okay? All right. So here is an example. So if, if you say, well, I'm gonna show you 1, I's gonna always show you1. Then the- if you can, you can write that strategy as a pure strategy, that says I'm. gonna always with probability of 1 showYou 1 and with probability 0 show you 2. game. If someone gives me the policy, how do I evaluate how good that is? So, that is going to be the setting where, uh, Pi A chooses action A, Pi B chooses action B times value of choice A and B, summing over all possible a and bs. So, so for this particular case of Two-finger Morra game, let's say someone comes in and says I'm gonna tell you what Pi A is. Policy of agent A is just to always show one, and policy of agent B is this, this mixed strategy which is half the time show one. And then the question is, what is the value of, of these two policies? How do we compute that? [NOISE] Someone tells me it's pi A and pi B, I can evaluate it. I can know how goodpi A andpi B is, from the perspective of agent A. But with the challenge here is we are playing simultaneously, so we can't really use the minimax tree. So right now I'm going to focus only on pure strategies. I will just consider a setting- very limited setting and see what happens. How bad would it be if we were to play sequentially? So that's what I wanna do for now. If we have pure strategies, it looks like if you're going second that should be better. So, ah, so going second is no worse. It's the same or better. And that basically can be represented by this minimax relationship, right? So, so agent A is trying to maximize. Player B wants to minimize. So in the second case, um, we are maximizing second over our actions of V of a and b, and Player B is going first. So this is going to be greater than or equal to the case where Player A is going, uh, first. that's the question we're trying to answer. Okay? So, so let's say Player A comes in, and Player A says, "Well, I'm gonna reveal my strategy to you" So the value of the game, uh, would be, maybe I'll write it here. Pi A is already this mixed strategy of one-half, one- half, right? It's going to be equal to Pi- is this- yeah, actually. All right. So well, that's equal to minus 1 over 2 Pi B of 1, plus minus $3. So, if someone tells me, "Well, this is a thing I wanna do," I should try to minimize value of Agent A, right? So, so what I'm really trying to do as Agent B is to minimize this, right, because I don't want Agent A to get anything. So the best thing that I can do as a Agent 2 is to follow a pure strategy that always shows 1 and never shows 2. So that tells me that never show 2 and always show 1. In this more general case, Player A is playing first, uh, and is following a mixed strategy but doesn't know what p they should choose. They're choosing a p and 1 minus p here. And then Player B has to follow a pure strategy. And by pure strategy, what I mean is you always end up like putting as much possible like 1, like all your probabilities on the negative turn and nothing on the positive turn because you are trying to minimize this. So that's kinda like intuitively why you're getting this pure Strategy. to 7 over 12 here, like these two values end up being equal. Equal, right? [inaudible]. [OVERLAPPING] Uh, none of them are actually equal. The reason that they end up be equal is you are trying to minimize the thing that this guy is trying to maximize. So no matter what your opponent does, like you're gonna get the best thing that you can do. Okay. So I'm player A, I gotta be citing a p. That's not gonna be too bad for me. The key idea here is revealing your optimal mixed strategy does not hurt you. The proof of that is interesting. If you're interested in looking at the notes, you can use linear programming here. The reason, kind of the intuition behind it is, is if you're playing mixed strategy, the next person has to play pure strategy and you have n possible options for that pure strategy. So that creates n constraints that you are putting in for your optimization. You end up with a single optimization with n constraints, and, and. and you can using like linear programming duality to actually solve it. the pay off matrix. So, uh, so you have two players A or B. Each one of you have an option. You can either testify or you can refuse to testify. So you can- B can testify and A can refusal to testify, and I am going to create this payoff matrix. This payoff matrix is going to have two entries now in each one of these, these cells. And, and why is that? Because we have a non-zero-sum game. different players. A Nash equilibrium is setup policies Pi star A and Pi star B so that no player has an incentive to change their strategy. In a collaborative Two-finger Morra game, it's not a zero-sum game anymore and, and you have two Nash equilibria. And Prisoner's dilemma is the case where both of them testify. So we just actually solve that using the minimax- von Neumann's minimax theorem, right? So there would be if you're playing a mixed strategy of 7 over 12 and 5 over 12, you might kind of modify your Two- finger Morragame and make it collaborative. look at them, would be useful for projects. And with that, I'll see you guys next time. Back to the page you came from! Back to Mail Online home. Back into the fold! Back To the pageYou came from: Back To The Page You Came From. Back from the Page you Came From: back to the Page You came from.back to thepage you came From: Back to The Page you cameFrom: The PageYou Came from: ThePageYouComingBack to: ThepageYouComing Back to:

ROUGE-1: 30.87, ROUGE-2: 29.78, ROUGE-L: 28.62
BERTScore: 64.23

==============================================
==================== [69/100] ====================
Summary:
The famous example was posed by Comte de Buffon back in the 18th century. It marks the beginning of a subject that is known as the subject of geometric probability. The problem is pretty simple. We take a needle that has a certain length-- l-- and we throw it at random on the plane. The needle might fall this way, so that it doesn't cross any line, or it might fall that way, and it ends up crossing one of the lines. If the needle is long enough, it might actually end up crossing two of the Lines. The joint PDF is going to be equal to 4 divided by pi times d. We have made some assumptions, which you might even consider arbitrary. But these assumptions are a reasonable attempt at capturing the idea that the needle is thrown completely at random. We just need to consider the event of interest, express it in terms of the random variables that we have in our hands, and then use the probability model to calculate the probability of this particular event. The event can occur with any choice of theta. So theta is free to vary from 0 up to pi over 2. to this number. So the upper limit of this integration is going to be l over 2 times sine theta. And all we need to do now is to evaluate this double integral. Let us pull out the constants, which is this 4 with this 2 give us a 2. We have 2l over pi d. And this is the final answer to the problem that we have been considering. And now, a curious thought. How can you figure out the number pi? Take your needle, throw it at random a million times, and count the frequency with which the needle ends up crossing the line. This is a so-called Monte Carlo method, which uses simulation to evaluate experimentally the value, in this case, of the constant pi. Of course, for pi, we have much better ways of calculating it. But there are many applications in engineering and in physics where certain quantities are hard to calculate, but they can be calculated using a trick of this kind by simulation. Here's a typical situation. Consider the unit cube. Inside that unit cube, there is a complicated subset which is described maybe by some very complicated formulas. And you want to calculate the volume of this complicated subset. that these days, physicists and many engineers use methods of this kind quite often and in many important applications. The method is used in a variety of scientific and engineering applications. For more information, visit: http://www.physicists.org.uk/physicist-methods-of-this-kind-used-in-many-important-applied-technologies-and-practical-practices.html. For information on how to use this method in your own research, visit www.physiologists.org/technology/technological-technology.

ROUGE-1: 34.56, ROUGE-2: 31.85, ROUGE-L: 32.51
BERTScore: 67.78

==============================================
==================== [70/100] ====================
Summary:
Professor: We're describing interaction between the electromagnetic field and atoms. Professor: If you have a perturbative treatment, even if you carry to infinite order, you have, formally, divergences if you have resonant interaction. I want to show you what are the tools to treat those infinity source diverGences in a consistent and a systematic way, professor says. MIT OpenCourseWare is a free, online education resource. To make a donation or view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu. one hint how we have to do it comes by simply taking this energy denominator and expanding it in gamma, simply a Taylor expansion in gamma. But I can reproduce this result by going to infinite order in perturbation theory. And it means to sum up an infinite number of diagrams. Who of you have actually seen those kind of diagrammatic tricks and summation? A few, OK. So it's maybe nice to see it again. I learned it from those examples. And I really like it. It's a very elegant way to combine equations with graphical manipulations. now the starting point for our discussion today. We want to calculate the Fourier transform of the time evolution operator to infinite orders. So unfortunately, [INAUDIBLE]. We should copy this equation. Because we need it. So OK, we want to take this equation, and now we wants to iterate it. The resolving G in 0's order is G0. Now plug G0 into the right hand side of the equation,. and you get the first order, which is. G0VG0. the structure if you sum over intermediate states, or if you introduce intermediate states. So this is just writing it down in basis function of the unperturbed operator H0. But now we can formulate the problem we are encountering and we want to solve. Namely, we have the problem with one state. Our problem is the excited state b. And we have a resonant excitation from the count state a. So we have terms, and actually divergent terms, which are 1 over Z minus Eb. easy part, which has no divergence, we can make any kind of approximation we want without altering the physics. But the resonant part, this needs special attention. Because if I treat it literally in those expressions, they don't make sense mathematically. Because they cause infinities. So we regroup those infinite sums, these algebraic terms, in such a way that we say, OK, which one has the occurrence of this once, twice, three times, four times? equations. We call this the function Rb of Z. And what I've shown in diagrams above is nothing else than the circle Vbb, the matrix element of the interaction. But now we have sums where we're not allowed to go through the resonant state. We have to go from b to an intermediate state. And it's clear how to go to higher terms. So we've just defined this function R by focusing on two occurrences of the straight line. Well, let's look at higher order terms. What happens when Z minus Eb comes to the power n? we ask what happens when we allow more appearances of the state b, for each of them, we obtain another square box. So by looking at the terms which are bothersome and regrouping the infinite terms according to one occurrence, two occurrence, three occurrence of this divergent denominator, we have now found an exact expression for Gb of Z. And since this is now an algebraic equation with a geometric series, we can write it exactly as this minus Rb. Well, like with every exact result, you have to ask, what is the use for it? The structure of the equation accounts for the physics. And the numerical part has become very harmless. But what it does is even if you do now a lowest order approximation to the function R, even those very simple approximations correspond to an infinite number of terms in the original expansion. So that's pretty neat. But the importance comes now when I pull things together, I want to show you what we have exactly done for treating an atom in the excited state and for treating it in the neutral state. light scattering. I just go now and apply to an excited atomic state. So the state we are interested in is the atomic state b and no photons. And the property of the atomic. state is obtained when we know the function Gb of Z. And if you use the lowest second order approach, then diagrammatically-- just give me one second, photon was emitted. Yeah, sorry, so the process we have considered is that we go to second order. We can go through an intermediate state, can say, absorbing it and meeting a virtual photon. Since this appears in the denominator, that means for G, just make a Taylor expansion in R, that it has this process to all orders. So that propagator, the sort of propagation G, involves now all possibilities that we have to end up in state b again. But we can go through intermediate states a or a prime as often as we want. Or actually, we have summed it up. Our results contain those processes to infinite order. So the question is, what have we neglected? I mean, that looks like a lot. This expression has in general a real part and imaginary part. It's a function of the initial energy E. And it has an imaginary part plus or minus eta. And what we're doing here is-- but I'm not really explaining it mathematically-- we have played those tricks here. But I hope it becomes clear if I say what the real and imaginary parts are. It needs a little bit of correct treatment of functions in the complex plane. But yes, thanks for the question. double sum. But what we use is the principle part of it, which is well defined in the theory of complex functions. And it's divergent, but you take a certain symmetric limiting procedure. So that's something which you have seen. So the imaginary part gets us Fermi's golden rule. And the real part has a 1 over [INAUDIBLE] dependence. So this is actually nothing else than the AC Stark shift not due to a laser beam, but due to one photon per mode. we calculate here-- has no resonant structure at the energy Eb. So therefore, we can neglect the energy dependence of that and simply replace the argument E by the energy we are interested in. So this replace, neglect E and set, or replace the dependence by E, by taking the value at Eb. This corresponds to the Markov approximation. And that means in the temporal domain that we have a delta function. I don't want to go further here. But when we talk about the master equation, we will also make a Markov approximation later on. And the two are equivalent here. imaginary part, which we can approximate by Fermi's golden rule. If we now Fourier transform back and obtain the time evolution of this state, it no longer evolves with the energy Eb. It has a shifted energy by this self energy. And this is called the radiative shift. But in addition, because of the imaginary part, it has now an exponential decay. But there are two things you should learn. The first thing is that the exponential decay would be different if we had not made the Markov approximation. around the resonance energy. Then, the density of states of your photon field is pretty much constant around here. And then, this approximation is excellent. So I hope what you have learned from the treatment is number one, where the exponential decay comes from. Of course, an exponential function has a Taylor expansion, which is an infinite sum of polynominal terms. And therefore, we need infinite order to get the exponential. So it's not really profound what I'm saying. It's pretty much an exponentialfunction is non-perturbative. we have an atom in the ground state, and a photon comes along, and it takes the atom to the excited state b. Then we go back to the same state-- could be also another state-- by emitting a photon k prime epsilon prime. And the relevant matrix element of the time evolution operator, which is the T-matrix, involves now the matrix element, the initial energy minus the intermediate energy. The critical part is really-- you can do it mathematically. large detuning delta here, then the small shift in the line widths don't matter. So everything we have done by correcting the naked propagation of the state b by the correct propagation with this infinite emission and reabsorption of virtual photons, this is only needed if the denominator is 0. And then, we have to figure out what else happens. What else happens is obtained in higher order with this non-perturbative treatment. OK, 20 minutes left. So we now change gears. We move onto the optical Bloch equation. many modes. It emits photons and reabsorbs them. And you can often neglect that in the simple description of your experiment. But if you take certain expressions seriously, they would have divergences. And that's what we discussed without this infinite number of processes which happen. Of course, yes, the whole other regime which I should mention is when you can completely neglect the coupling to many modes. If you do Rabi oscillation with resonant interaction, you don't need all that. Because then, you're really looking at discrete states. things which happen in our experiments and in daily life come because the system we are looking at, it follows Schrodinger's equation. But it is coupled to a much bigger system. And so in this section, what I want to address at the most fundamental limit is, what is the step where we go from reversible equation, unitary time evolution, to something which is called relaxation, which is dissipative, where entropy is increased? And the step, of course, is we go to statistical operators. We describe the big system. But then, we focus on the small system. In general, if you write down the total Hamiltonian and do the time evolution, something will come out which, in general, is very complicated, very entangled. So you have to know, to keep track of all the photons, which have been scattered in the lifetime of an atom. But often, what we do is we simply put the photons in a trash can. We trash them. We're not interested in what the photons are doing. The vacuum chamber has taken care of them. So all that we are interested in-- how do we now describe the atomic system? that happens with the environment-- that there's initial state, that it gets entangled, and then we neglect maybe not keeping track of the photons-- we're not interested in all of that. We really want to focus on what happens to the atom. How does an initial state of the atom propagate into a final state? And this is done by optical Bloch equations. This isdone by the master equation. The master equation, you can see, focuses on the relevant part of the system. And we can neglect the million photons which have been emitted. it causes stimulated emission. And it causes absorption described by the Einstein b coefficient. And you have a similar equation for the excited state. So this is clearly the semi-classical limit of what we want to accomplish. We want to know more. We really want to find the full quantum time evolution. We have to be careful. The time evolution as a Hamiltonian, if you now bring in the environment, cannot be simply included by adding an imaginary term. This here violates the unitary time Evolution. This is actually something which is the frontier of our field, both in theory in ion traps and with neutral atoms, that we have some evolution of an atomic system by coupling it to the environment. So can you engineer the environment in such a way that it does something really fancy to your system? Well, you can dream of it. But you dreams are restricted by the mathematical structure of all possible master equations in the world. Because the environment cannot do everything for you. The environment can only do for you what can come out of all Possible Hamiltonians. I will be telling you is also sort of relevant to understand this sort of frontier in our field which is called environment engineering. OK, density matrix-- good, five more minutes. So what we have is we have a system. And we have this environment. And what we are exchanging with the environment is both energy, but also entropy. And so when we transfer energy or heat, there is a corresponding change in energy. And it's a general property of all quantum systems. It's a consequence of the fluctuation dissipation principle. we need, and I just want to remind you, is for all density matrices, you can always unravel it. The density matrix can be written as a probabilistic sum over states. This will actually play a major role. We will make certain models for damping. And it's really beautiful. On Monday, I will give you the beam splitter model for the optical Bloch equation. I really like it. It shows you a lot of fundamental principles. But the important part is whenever we have a way to construct a density matrix by saying, we have certain quantum states k, and we just add them up probabilistically, this kind of microscopic interpretation of the density matrix is called unravelling. processes. OK, any last questions? Well then, let's enjoy the open house with incoming graduate students, and I'll see you on Monday. I'll be back on Monday to talk to you about the classes we'll be teaching next year. Back to Mail Online home. back to the page you came from. Click here to read the full transcript of this interview. Back To the pageyou came from, click here to see the full Transcript of this Interview. Back in the page, please share your questions and comments.

ROUGE-1: 43.45, ROUGE-2: 41.78, ROUGE-L: 41.57
BERTScore: 70.25

==============================================
==================== [71/100] ====================
Summary:
David KAISER: Today, we're going to pick up where we were on the most recent classes. We'll look at the coalescence of what came to be called the Big Bang model. And then we'll see how cosmic inflation emerged from that particular moment to try to address some of the shortcomings while retaining some the successes. And the asterisks are to remind you there's a set of strictly optional lecture notes on the Canvas site which go into a little bit more detail of some of these parts from the lecture. or our own Milky Way galaxy. Or if we zoom in even closer to home with the solar system or even really in human terms, there are concentrations of enormous matter and energy and activity separated by huge voids. One of the questions is, what could account for that structure across these scales from meters or kilometers up to tens of billions of light years? It turns out that ordinary gravity-- even Newtonian gravity, let alone Einstein's fancier version that we looked at in class, general theory of relativity-- is sufficient to help us make sense of this hierarchy of scales. Nowadays people are pretty well convinced consists of things like quarks and gluons and even some more exotic particles like the Higgs particle. So we have these two ingredients of the structure and behavior of space time as governed presumably by Einstein's theory. And then the stuff that's filling that space time, an idea about matter, especially how matter behaves at very high energies and densities. So with those two ingredients, the goal has been, again, for many decades to account for the observational features of our universe even on very large scales. satisfy Einstein's equation. They took three particularly simple forms. Depending on the amount of stuff, depending on the distribution of matter and energy. If you had more than some critical value, a critical value that came from the equations themselves above that, an overdense region, space itself would warp back onto itself like a closed sphere. And if you had less stuff per volume, if the universe were underdense compared to thatcritical value, then, in fact, the universe would open up away from itself. Einstein thought that was horrible. He had a very strong aesthetic and philosophical preference for a universe that had no beginning that was simply static. But other colleagues showed at least it was consistent with his own equations to have universes that would change over time, that could either expand or contract. That was actually a prediction made by some of these colleagues even before some empirical evidence began to come in starting in the late 1920s with some of the largest telescopes of available on the planet. That's when Edwin Hubble in Southern California were able to prove it. to collect information about not just the distribution of distant galaxies, but could also measure how rapidly they were moving with respect to us. And Hubble found this remarkable trend that the further away from us a given galaxy was, the faster it tended to be moving. And the basic trend holds. There's some interesting deviations. But the idea is nonetheless evidence consistent with our universe expanding, not just having a shape to it, but actually stretching and getting larger over time. So you can actually then work backwards and say for how long has our observable universe been stretching? When did this stretching or expanding phase begin? George Lemaitre was an ordained Catholic priest. He was also an MIT trained PhD astrophysicist. He studied briefly in Cambridge, England with one of the first converge to general relativity, Arthur Eddington. Then he came to MIT to finish his PhD and then was finding many of these solutions to Einstein's field equations even before Einstein did. And it's consistent with the beginning of that expansion being not quite 14 billion years ago, billions of years ago. It's also consistent with things moving further apart from each other on average today. Lemaitre was calling it a primeval atom, that there was this initial fireball from a very, very hot, dense state. And he was very eager to understand the early stages of that expansion. That's where things stood really through the 1930s. And then after the Second World War, new groups began coming back to these somewhat old questions. Some of the newer groups had experience with things like the Manhattan Project and in general were much better versed in things like nuclear physics than had been known even in Lemaitre's day. George Gamow was advising two younger physicists, Robert Herman and Ralph Alpher. They realized that if the universe was very hot and dense at early times, then the conditions in which these elementary particles would find themselves should be quite different than what we find commonly around ourselves today. And in a series of really quite ahead of its time farsighted work starting in the late 1940s, this trio and a small number of other colleagues around the world began trying to fill in this picture, this primeval fireball picture. a measure of kinetic energy of motion. At early times in cosmic history, the universe should've been opaque. You literally wouldn't have been able to see anything because the mean free path of any given photon would be very, very short. The photons would each be trapped, kicked like soccer balls between all these loose electric charges. Light can't propagate in a charged plasma because it's always bouncing between these very nearby free electric charge. So they could calculate how the universe would have looked. When the average or ambient temperature fell below the average binding energy of a single hydrogen atom, a new phase in the universe would begin to unfold. At that moment, the average energy per photon or per elementary particle would fall so that you could actually begin to form stable atoms of hydrogen. At around 380,000 years, after the start of that stretch after that primeval atom begins to expand, the ambient or average temperature of all the junk inside that universe should've fallen below this Coulomb attractive energy for neutral hydrogen. filled with neutral atoms of hydrogen. And now you have a mean free path for light that's arbitrarily long. Light can pass through electrically neutral matter. It does so in our own atmosphere, let alone in empty space. So they argue that today, this bath of remnant radiation from that early hot, dense state should be filling the sky in every direction. It should be more or less even distribution, a uniform glow. But instead of it being a very, very high energy X-ray or gamma ray radiation, it should be redshifted all the way down into the low energy microwave band. In the early universe, charged particles had a mean free path to cross the dance floor. Gamov, Alpher, and Herman were putting real numbers to try to make sense of these different phases of the very early universe. Very high temperature, early dense state should be qualitatively different in its behavior than a later lower energy state. They predicted as early as 1948 that there should be this remnant glow from the Big Bang, all those photons that only then at 380,000 years after the Big bang were able to start streaming freely. 20 years later, two radial physicists working at Bell Labs, Robert Wilson and Arno Penzias, were using a new horn antenna sensitive to radial microwave and radial band frequencies. This should've been among the most precise instruments available on the planet for that band of the spectrum. They couldn't get rid of a residual hum. At one point, they climbed inside that huge horn antenna on their hands and knees to scrub out what they graciously called special dielectric materials from pigeons who had made a nest. in Southern Jersey. They were close to Princeton. They all got together. They said, oh, what you found is actually the remnant glow from the Big Bang. This residual hum in your receiver consistent with an energy of about three degrees above zero, three degrees Kelvin, was really the leftover photons. And the average energy per photon had fallen steadily since the time when they were first released in that early dance party. So let me pause there and ask any questions. Any questions on that stuff so far? So far so good? from every part of space, from every single direction in the sky, those photons began to move freely at this single moment in time. So basically, the universe should've been filled with light, originally a very high energy. And then actually the energy of that light should be falling as the container expands, so as the average energy inside that balloon goes down. So the photons aren't coming from that direction of sky the way we think of with point-like sources. There's a galaxy there, a quasar, a particular bright star in our neighborhood. everywhere. So every part of space that we could see today once had been at the Big Bang, so to speak. The Big Bang happened there. It happened at x equals 0, and x equals 1, equals 2. Any place we could put spatial coordinates to on this model, those all experienced it at the same time. But I say all that as if that's obvious. It's not obvious. But that's the kind of reckoning that people like Lemaitre got very comfortable with starting in the '20s and '30s. In his time, Hubble measured a much quicker average rate of expansion than what we have mostly settled on today. The picture was enough to get a small number of people to pay attention to Georges Lemaitre's otherwise quite obscure mathematical solutions. Hubble actually had a number of assistants, and other groups began contributing as well. But it was Hubble's data that got the biggest splash, that made the biggest impact on the community at the time. And regardless of what you think of Einstein, he was not a fan of this early on. whether we agree with the number he inferred of the actual rate, it seemed pretty clear to many people at the time that this was consistent with an actual overall expansion, with the change over time. Friedmann's and especially the follow up work by Georges Lemaitre, that made those mathematical solutions look much, much more curious and interesting than they had prior to Hubble's data. So this is a, I think, safe to say, remarkably successful set of ideas that eventually becomes called the Big Bang model, going all the way back to really Einstein. what we call conformal time, often labeled by the Greek letter tau, is basically a variable tick rate that is really convenient because then we can start making a dynamical changing spacetime look just like the spacetime of special relativity. In these special, very simple fine coordinates, light just travels on 45 degree diagonals. And then light comes to us at 145 degrees. That sounds very abstract. We do that all the time. This is just an example in space time of a conformal mapping of a sort that we all use every day like a Mercator projection. stretching our time coordinate so time gets more and more stretched out towards earlier times. We can take that into account. We know how to use a Mercator projection. And it makes other relationships remarkably easy. Likewise our conformal maps here make the paths of light, for example, very easy to follow. When people begin using these convenient coordinates, they also go back to some questions about or features of the Big Bang model, and they start having new questions. It's the same Robert Dicke. So he introduced this conundrum in 1969, so soon after the discovery of the cosmic microwave background radiation. stuff per volume, the actual density of matter and energy per volume. It became common after Dicke to just introduce the Greek letter capital omega simply to refer to that ratio. And only for that Goldilocks solution, we have exactly the balanced amount of stuff per volume would you expect to have space obey Euclidean geometry on large scales. If omega is larger than 1, you have more stuff for volume. You expect it's open or hyperbolic geometry. So far so good. Then Dicske plugged this quantity into Einstein's own equations. universe should generically become more and more different from flat over time. If a universe started out being close to but not identically equal to flat at early times, it should look nothing like spatially flat at later times. The universe has been stretching for 14 billion years, what set it to be so exponentially arbitrarily close to spatiallyflat given that is an unstable equilibrium point? That was introduced by Bob Dicke in 1969. And 10 years later, Dicske and Peebles introduced the second big conundrum. And this one's called the horizon problem. direction in the sky. Light travels on these lovely, convenient 45 degree diagonals. From this corner of the sky, looking in the opposite direction, we receive this uniform bath of photons that have been traveling towards us this whole time. We received this remarkably uniform signal on the sky today from opposite sides. However, those photons were emitted at a finite age when the universe was only a short portion of its current age. It was only 380,000 years old as opposed to nearly 14 billion years old. at a fixed speed at least according to Einstein's theory. So if the universe has only been around for so long, then light could only have traveled so far. That's called the horizon distance. What's the furthest possible distance that a light beam could've traveled traveling at that constant speed of light for as long as it was able to? So even though an actual physical light beam couldn't have traveled because the universe was optically opaque, any information, any physical signal, any force, anything that is limited by Einstein's speed limit should only be able to travel up to and limited by the speed oflight. or even exchange a single tweet, to have absolutely no information of this part of the sky about what the average conditions are. That became known as the horizon problem. And this was heightened as more and more data came in. It became clear that signal really is uniform to one part in 100,000. It's remarkably uniform to a tiny fraction of a percent. It was at 1,000th of 1%. That signal is uniform across every direction we look in the sky today, even though it's coming from all these regions that couldn't have possibly had any physical interaction with each other. The Big Bang model had some amazing successes but some pretty stubborn quandaries as well. Fisher asks, is it useful to think of the universe as spherical still? Yeah. These pictures get pretty hard. Fisher: Any questions on the shortcomings of the Big Bang as people began articulating them throughout the '60s and '70s? Feel free to jump in or use the chat or either way. And again, there's more on the quantitative details of that in that optional primer you can find on the Canvas site. we can imagine choosing some point of interest and drawing some sphere around it and asking what's happening in that region? Is that region itself will grow over time? And is that region representative of some larger sample from which it's taken? So we can still ask about the behavior of some randomly drawn sphere even if the global shape of space might not be spherical. Now, it could be that the entire universe has a global shape to it. We could be living in a closed universe where on the largest scales it actually looks like a sphere. But we could, again, do the same trick. like circa 1980. He was not originally asking questions about the cosmos, but he was haphazardly encountering some of those questions, again, very much like Tony Zee around the same time. What Alan was interested in was in things like spontaneous symmetry breaking and the Higgs mechanism. That was all the rage for a lot of particle theorists in the early and mid '70s by then. And he was wondering about shapes for the potential energy function of that Higgs field that might have a extra structure. There might be a kind of dimple to that energy function. the origin of its own potential energy function where there's a barrier in any direction, but it's not an infinitely high barrier. According to quantum theory, that Higgs field should eventually decay to the genuine global state of lowest energy, anywhere along this so-called vacuum circle. Alan was realizing upon hearing Bob Dicke's lecture that that could have remarkable cosmological implications. And he calls this a spectacular realization. So my request number 3 to you scientists is both write things down, use neat handwriting. Alan Guth's notebook is now on display in the Adler Planetarium in Chicago. He realized that this kind of feature could actually lead to a cosmologically distinct kind of evolution. If the energy density, the stuff per volume, remains constant, then very counterintuitively, you have a runaway growth in the size of space. That stretch function, the scale factor going back just to Einstein's equations, will grow exponentially quickly, will have a period of accelerated expansion during which universe won't just get bigger. Einstein was worried about exotic features from these Higgs fields that can get twisted up in some topological shape. He was really just wondering what happens if the universe gets stuck even temporarily such that the matter that dominates it, fills it, can't release or relax its potential energy arbitrarily quickly. That's called a metastable state. And as Alan and others were quick to confirm, this happens very naturally, or at least it's a kind of feature that one stumbles upon readily, if when studying these exotic Higgs-like fields. in a stretching space time, if you take that stretching of space seriously, then you don't even need to cook up those exotic Higgs-like potentials that Alan was first thinking about. Quite generically, you'll have a damped oscillator behavior. This comes from the fact that space itself is stretching. And that alone it turns out is enough to find these self-consistent solutions in which the field moves very slowly. You can imagine it rolling down this hill, rolling down-- sorry-- rolling down slowly as a function of time. grows very fast in time-- while the energy density remains nearly constant. Now you'd see this expression, the deviation of the universe from spatially flat. That deviation should rapidly fall to 0. The universe today should look indistinguishable from a flat universe because the difference from flatness was driven to 0 dynamically. By having even a very brief phase of exponentially rapid accelerating expansion, you drive the universe towards a flat shape rather than having it flow away from aflat shape. So the latest measurement from the Planck collaboration using a satellite is that this parameter in our actual universe today is 1. If inflation happened, there should've been a very brief period before what had previously been called the Big Bang. So we're adding more real estate along our time axis. We're unfurling a little bit extra time that hadn't been taken into account in the standard Big Bang model. So therefore, you could have the horizon distance, the maximum causal distance, becomes much larger. In fact, it could be much, much larger, exponentially larger than the smoothness scale we observed. distance and conformal time. You can see that as you trace backwards from today, instead of going back to saying the universe at early times should've been on the order of 1 meter, you say at those early times, the universe was actually exponentially tinier than you had thought. It grew exponentially quickly to map onto where we see today. And so the universe could very easily have been in a kind of equilibrium or at least a causally self-connected state. And this became clear to people about a year or so after Alan and Paul and Andy and all those folks began writing the first papers on inflation. The universe was filled with quantum fields. At any given moment, that field would be subject to slight, slight quantum fluctuations. That starts to yield this tiny little fluctuation in why there's slightly more matter and energy in this region of space than the other one. So now those very tiny quantum scale fluctuations get stretched as the whole universe stretches. As the scale factor grows exponentially, you have the average length between the distance between crests of those tiny wiggles get stretched to galactic and even super galactic scales. higher energy photons in the CMB and slightly lower energy photons. And the idea now is that the regions of the sky from which these photons were emitted are telling us about the very, very tiny unevenness in the distribution of matter and energy. They have been mapped by three generations of satellites above the ground with increasingly precise ground based measurements as well. Each of these came out 10 years apart with an increase of about a factor of 30 in the angular resolution of thesky. I was a senior in college when the first of these released their data in September 1992. to measure these tiny, tiny fluctuations on the order of about one part in 100,000 but over huge scales. It was like they had very poor eyeglasses. Roughly 10 years later, another NASA mission called WMAP was able to increase the resolution by a factor of 30. So now not only do we know do we live in a universe that is indistinguishable from flat as inflation suggests we should, but the actual pattern of those wiggles, the pattern of the very slight early unevenness in the sky matches predictions to better than a percent level accuracy. Inflation says similar kinds of things should've been happening in the earliest moments everywhere in space through this very violent, rapid stretching of space. At the moment when the electrically neutral atoms start to form, if there were this sea or bath of gravitational waves, then the high school auditorium-- imagine where this dance is happening. These are mathematically more complicated structure. You should have this periodic squeezing, stretching, and then inverted by 90 degrees. So a version of these were found by the LIGO collaboration and announced early in 2016. March of 2014, a team using the BICEP satellite at the South Pole announced they had actually measured exactly that corkscrew pattern. Unfortunately, pretty soon after that, it turned out the BiceP team had measured data consistent with local noise. So basically, the signal they had hoped to measure was actually swamped by foregrounds they had not yet been able to control. And this was found by a number of very sophisticated analyzes soon afterwards. So it remains an open question to this day whether these primordial curling, twisting patterns really can be detected. Maybe there's such small magnitude, it'll evade our detection. makes specific predictions for what we should see on the sky today, including very minute statistical predictions for things like the cosmic microwave background radiation. The simplest models fit to unbelievable accuracy despite what my mean dormmates used to say in the mid '90s. Now we have extraordinary agreement with many, many of these predictions, albeit not the final one. So why is the universe lumpy? Why is this cascade of scales? Because space time is wiggly, and matter is jiggly.

ROUGE-1: 43.50, ROUGE-2: 42.02, ROUGE-L: 41.92
BERTScore: 61.93

==============================================
==================== [72/100] ====================
Summary:
The Peloponnesian War was fought in 431 BC. After the war, Spartan power had grown to an unprecedented degree. For the first time there were lots of Spartans, who had lots of money. The Spartans had choices that they could take. They could either stay in the Pelop onnesus, or they could contest it in their power to control the entire Greek world in the east. Or they could have some control of the Aegean and the Hellespont. Lysander was the great victor of the Peloponnesian War. His policy was the extreme policy, the "let's conquer it all" He was not a legitimate Spartiate, he was a pure Spartiate. The Spartans disagreed among themselves as to what was necessary, even if you were going to take that path. The most aggressive, overseas, let's conquer and control everything in the Aegean was Lysander. There were great arguments against the Lysander approach, for one thing, the number of Spartans was pretty small. Lysander was a general and the very best general of all, and the man who was put in command of the forces. He was a man of extraordinary ambition, and ancient writers tell us that he had developed the notion of actually bringing about a revolution in Sparta. This newly founded Spartan Empire was different from the Athenian Empire in a variety of ways. The Spartans had simply betrayed the Asiatic Greeks whom they had engaged in the rebellion against the Athenians and instead of liberating them, put them under Spartan rule. Law of Epitadeus allowed people to buy influence and power in Sparta. This money, of course, allowed for corruption. So, there was jealousy and resentment and fear at Sparta that something bad was going to happen to the Spartan way of life. Pausanias and his tradionalists bided their time for the opportunity to put a spike into this development. It was as obvious as it could be. It seems reasonable to me that most scholars would like to place this period in this period. Sparta had been reduced to total defeat, absolutely at the mercy of the Spartans. Athens, which had been the greatest empire that the Greeks had ever seen, feared the same fate they had visited upon some states that had defied them. The Spartans didn't do that. Instead, with Lysander in charge of the settlement that was going to be imposed on the Athenians, they placed in a small group of oligarchic Athenians just as he had in the rest of the empire. should be no democracy in Athens. It was an easy point of view to arrive at in 404. People who were not friendly to the democracy could simply point to the fact that the democracy had just lost this great war. And it was exactly the kind of idiotic idea that a democracy would come up with so that democracy itself was seen to be inherently wicked. The Greeks thought a division into two kinds was the right kind, the most important kind, a division between the high and the low, between the good and the bad. guys and therefore you shouldn't have anything to do with ruling anybody. So, that was the basic widespread view of what was natural in the Greek world. Now, you add to that that they've just lost this terrible war and you could point to what seemed to you to be both a wickedness and foolishness. How in the world could anybody think democracy was a good thing after that? Lest you think there's something special about that, that's such a characteristic of the human race. Critias, in any case, was determined that Athens in the future would not be a democracy. In fact, it looks like he was very much taken--again, this is typical, with the virtues of Sparta, because Sparta had won the war. So, he had in mind a very narrow oligarchy. But Athens, of course, was also inhabited at that time by all of the exiles who had been sent into exile during the democracy, and they were bitter enemies of the democrats, at least lots of them were. Thirty--just to make the case that--actually a man named Peter Krentz, and he is an old Yalie, so, we ought to give him credit. Ultimately, in the course of these months, the Thirty limited citizenship, active participation in the government of any kind to only 3,000 Athenians out of what would have been at least 21,000 and probably more. Only these had citizen rights. The rest of the Athenians did not. Well, pretty soon people objected to what the Thirty was doing, made complaints, and the Thirty began to go after them. When things got really bad, when the Thirty needed money they actually put people to death just because they were rich. as much as they could in collaborating with the Germans just to make their--the fate of the Frenchman less hard and to help France in the future in that way. That's the way it was with most Athenians; most Frenchman and most Athenian didn't do either of those things. They kept their heads down and tried to live their lives as best they could. I think what you need to understand is happening and this all puts what Thrasybulus and Anytus, and their friends did in a very special kind of a light. Spanish Armada was heading for England trying to gain control of the island for the Pope and Catholicism and one thing and another. Great wind came up and it blew the ships out of their path and wrecked many of them. From that day forward there sprang up the legend in England of the Protestant Wind, which had come along to save the new English faith against the forces of the Pope. Well, if they can invent a Protestant Wind I think it's okay for me to speak about the democratic snow that fell on Phyle that went. forces in the state had come, and we might mention also that the ancient sources estimate that something like 1,500 Athenians may have been killed by the Thirty tyrants. When the Thirty brought an army out to try to defeat him there he defeated them. They were forced to flee to Eleusis on the northwestern frontier of Attica, and the democrats were in position to take control of the city again. The Thirty were deposed by the 3,000, because it was obvious they were losers. Cornelius Nepos, a Roman historian of the first century B.C., wrote the following about Thrasybulus: "If excellence were to be weighed by itself, apart from luck, I believe I would rank this man first of all" A few years before 180 A.D., Pausanias the great travel writer of antiquity, wrote his guide to the famous and historic places of ancient Greece. In the section on Athens, he described the graves of the heroes and men that lined the roads outside the city. of him. I mean, the best answer I can give you is there must have been lost histories, and we know there are of the period, and they must have given Thrasybulus the kind of credit for his remarkable achievements that don't show up in Xenophon and Diodorus and the orators. But we at last, and you have an obligation to future generations, must not let the name of Thrasy Bulus lie in obscurity again, and just so that you don't forget him, remember he is the only Greek I know whose name fits a Yale fight song.

ROUGE-1: 23.41, ROUGE-2: 22.25, ROUGE-L: 22.36
BERTScore: 57.99

==============================================
==================== [73/100] ====================
Summary:
The coherent state has a simple definition, simple but subtle. It's an eigenstate of the annihilation operator, and it has a complex eigenvalue alpha. The person who popularized those states was Glauber, and he got amply rewarded for that. We are now using the coherent states to look at any other quantum state of the electromagnetic field, any statistical operator which describes photons by forming the diagram matrix element of the statistical operator with alpha. Q: What was the purpose of-- whoever discovered eigenstates? The vacuum state is sort of an area. It's a Gaussian. And the area is -- it's an area on the order of 1 or 1/2. We realize that thermal states are also aGaussian centered at the origin. But it is a much wider distribution. So thermal states have much more uncertainty in the electric field than the vacuum state. And now, of course, when we looked at the coherent state, we realize that coherent states are maybe not as wonderful as I tried to make you believe. They have some nasty properties. you have some homework assignment to look at it. In an harmonic oscillator, if you have a plane of x and p, symmetric and anti-symmetric combination of a and a dagger, the quantum state is just rotating circle, a rotation with omega. And indeed we showed that when we apply the time evolution operator-- and some of you were right, of course, with a minus sign-- it moves with e to the minus i omega t. And I want to say something about that in a second. In the analogy with the harmonic oscillator, the electric field was a minus a dagger. In those quasi-probabilities-- and we will see more about it-- something which is sharp in momentum is a sliver parallel to the x-axis. And therefore everything rotates in a clockwise way. Now, there are two things we want to continue. One is I want to show you that the coherent state is a minimum uncertainty state. The product of delta x delta p is just-- is it h-bar or h- bar over two? One of the two. which is less fuzzy than the coherent state. So this fuzziness here is the intrinsic uncertainty of quantum physics. But then we will immediately start with non-classical states. And that is, well, if this area is determined by Heisenberg's uncertainty relation, what can be maybe deform the circle into an ellipse, and these are three states of light. That's what you're going to do in the second half of the class. But before I do that, I want to be a little bit more accurate about quasi-probabilities. have a product which is fully symmetric i in the ordering of x p, which is anti-normal or normal. In an operator product, you can have symmetric ordering, which means not x p but x p plus p x, then it's over 2. That's symmetric. You can have an ordering which is normal and one which is called anti- normal. All three have their advantages and disadvantages. So they all have pluses and minuses. The reason why I picked for the course Q of alpha is that it's a real probability, it's always positive. it is sharp. It's actually worse than a delta function. But at least here, in the probability P, you get the delta function, which may be very natural for certain purposes. The Wigner distribution has the advantage that the projection on the x- and y-axes are indeed psi of x squared, psi of p squared. So you get actually the x wave function and the p wave function. It is closest to the classic phase space distribution, as close as you come without violating commutators. But of course it has a disadvantage that it has negative values. Using elementary commutator, we can calculate what are the expectation values in a coherent state for P, P squared, Q, and Q squared. For P, it is-- the P operator is a dagger minus a. If we act with a on alpha, we get alpha, because alpha-- the coherent state-- is an eigenstate of alpha. With P squared and Q, you have to use one or two more steps to get rid of the products. But ultimately, you can express space all that just in powers of alpha, alpha squared, alpha star. In other words, the coherent state is the solution to the following question. If you plot the quasi-probability distribution, you give yourself an uncertainty area. The fluctuations of the intensity are usually expressed by the second order temporal coherence function. That's what we want to introduce now. What I'm always encountering in this course is I would just like to immediately tell you how it is defined in terms of a's and a daggers. It's simple. It is quantum mechanical. The second order coherence function for classical light, which has a classic description, is always larger than 1. But quantum mechanically, we will see that the g2 function is not necessarily larger than1. And that's actually an interesting-- you can see-- litmus test for the quantumness. And then you have a final state of your harmonic oscillator, and your zero-point fluctuations has zero squared fluctuations. So what is more closely related to an experiment is how you measure the correlation function. single mode-- and what is a single mode? It's just a sine wave. And nothing happens as a function of time. It's constant. So the time evolution of the system you're describing right now is completely boring. And if you would rotate your head at omega, nothing will happen. And this is exactly what you see here. So you find everything you want to for coherence time. Coherence time is the time for the time of the quantum state of light. The g2 function is related to number fluctuations. It's related to an average and an n-squared average. The classical fluctuation-- well, I say classical, classical in the simplest case-- are Poissonian fluctuations. If you use-- kind of pluck together-- the results we obtained with the Fano factor, you have a super-Poissonian fluctuation. The thermal state is quite different. The most interesting from the perspective of non-classical light is the state of thermal light. I'm not sure if it's right, but it's consistent. By the way, if there is a question, I sometimes make a question mark in my notes. And when I post the notes, the question marks are eliminated. So this is now drawing our attention to the single photon. And this is our next subsection. This shouldn't come unexpected. It comes from the quantization of light. And that only happens when you go down to similar photons. This is when certain fluctuations are most pronounced, because the energy is dependant on a singular photon. me first address one misconception. You can say, Well, let's just use a coherent state. Coherent states, as I've just shown you, are very classical. They've always Poissonian distribution. And attenuation is not changing it. Attenuation is preserving that. So you can now say that you take your coherent state and you attenuate it down that there is only one photon left. Is that a single photon state? The answer is no. It is an attenuated coherentState. And I will prove that to you very soon. Even, on first sight, a surprisingly large probability to find 3 and 4 photons. The creation of single photons has been sort of a small cottage industry. Single photons are often needed for protocols in quantum computation. One of the leaders in this field is Professor Vladan Vuletic here at MIT. And the idea is the following photons are now heralded-- they are announced now -- in the singleness in which you have an excited state and you have a single photon. But no longer have several photons, you can get several photons. I don't want to go into details-- but those who have an understanding of that-- is the following. If you n atoms and you prepare one atom here in state 2, you do not know which of your n atoms is prepared. And if you have n indistinguishable probabilities which atom you have prepared, the emission of the photon back is n times enhanced. So having n atoms makes it much, much easier to construct a high finesse cavity. You get this super radiance increase of the strong coupling for free. study. The idea behind an Hanbury Brown Twiss experiment is that you have a light source and you want to characterize it. The first photon is observed by the first detector, and the second photon is detected by the second detector. We are looking that in a very small temporal window, 2 photons are detected. But in principle, you can now find 2 photons which are only a few picoseconds apart. And this is what we are asking here when we measure the g2 function. simultaneously. In the classic limit, you don't have to worry about it. The classical limit is always a limit of high intensity. So at any given time, you have a ton of photons. And then, at beam splitter, half of the photons go left. You have an equal splitting. So there is no problem at all with the quantization, because this is the classical limit. And if you do the measurement with the coincidence detector, you find the difference between the g2 function, which I discussed earlier. a very narrow spectral filter or Fabry-Perot cavity, the light becomes single mode in frequency domain. In the quantum version, especially when we have a single photon, the photon can go to only one detector. And that means, for this extreme case of a single photons, the g2 function is 0. Anyway, you will look at those situations in more detail in you homework assignment. Yes? Audience: Sir, if you know that different for tau non-zero, then even the single modes in the function would have a final g2. Laser beam is always replenishing the coherent state. The experiment how it is done is often done as in an open system. The only property which distinguishes a laser from the thermal light source-- we're not taking advantage of it. All the laser cooling, all the absorption imaging-- all that would work if you had a single mode thermal source, says Prof. Rieckhoff. "I think you've got the taste. Your homework is a really simple. You just deal with a closed system. You look at a quantum state" course practically, if you take a thermal source and filter it down to a single mode, you will be left with only a few photons. You cannot create an intense enough single mode light source unless you use stimulated emission. And that's a laser. So anyway, what Colin says is there are actually more different light sources that just the laser and the thermal light source. There are LEDs or semiconductor devices, which provide photons with interesting statistical properties. OK. We have to stop. I'll see you on Wednesday.

ROUGE-1: 31.63, ROUGE-2: 30.28, ROUGE-L: 29.63
BERTScore: 63.87

==============================================
==================== [74/100] ====================
Summary:
This lesson will first dive into some signal Theory and then move on into things that we're more familiar with things like deconvolutions and using Transformers for next note prediction. The first thing we want to talk about is how can we sample and quantize a continuous time signal. We'll also talk about the different kinds of models that we've been talking about and how they can be used for generative audio. The last part of the lesson will be on how we can use Transformers to generate sounds using these models. periods and two by quantizing our level so instead of dealing with A continuous scale we can quantize at certain levels for example a frequency of like 2 4 6 8 Hertz what this allows us to do is come up with discrete points. The analog to digital converter uses something called the sample and hold circuit the details of which aren't incredibly important. If you guys do want to learn more about Dax and adcs you can take 16b as well as signals classes at Berkeley I would highly recommend those. signal to an analog output we can kind of start by talking about the ADC circuit. This uses something called the SARS ADC algorithm essentially what this is is a binary search to figure out what is my best digital approximation of my analog signal. From here we take in our our input and our output is based on the amount of bits of precision that we want to have so depending on whether we want a two-bit approximation a three bit approximation this highly depends on the level of precision we want. Stars ADC algorithm. The level of quantization here correlates very directly to the dynamic range of the signal that you're quantizing. With a bit depth of two our approximation isn't very great with a big depth of three um it's definitely getting better our errors reduce significantly and our quantization is uh a lot more indicative of our sample bit Depth of five we're really adhering to our our curve now our error is almost zero and a bitdepth of 16 you have an almost perfect approximation um there is a trade-off though thetrade-off is compute power how much time do you have to process this if this is something where a lot of musicians they want to sample their. voice and Pitch it up very fast right what quantization level do we do we want there. Can we do a lossy pitch up with a uh with by filling in the the blanks in some intelligent way through prediction or kind of note fitting which is an interesting consideration I think given the fact that audio is a continuous time signal um the digitization process and the choices you make matter a lot and because of that this field is so interesting and there's a lot of really didactic work around how we can take these continuous signals discretize them. is less than double of the highest frequency present aliasing will happen. This asserts that you need at least two samples per period. aliasing is the byproduct of poor sampling right so a lower wave resolution will result in a modified output signal as compared to the original input that we're trying to process. Different frequencies approximate our input wave differently right this wave you wouldn't really think is indicative of uh the actual wave that we's trying toprocess this wave is one could argue even less indicative we're skipping a lot of points. from we take our low frequency and that becomes a product from taking our original frequency that's above half of the sampling rate and subtracting half of it from it so essentially you can think of it as down sampling and contributing to information loss by transforming higher signals into lower frequencies. There's a lot of literature out about aliasing um it's a problem that's very prevalent um in in any signals problem and something that a lot. Academia is is covering um so I'd highly recommend checking out some of these links. um this is is kind of uh and and add add-on um to this presentation it uh doesn't uh really contribute exactly to what we're talking about but I thought this was incredibly cool um with one line in C you're able to to generate Melodies um which is incredibly coolUm yeah so please check it out if you if you guys have a chance uh the next thing we're going to talk about briefly is geometric signal Theory um and specifically you know what a projection is how it can be used to reconstruct signals and finally how that can tie in to reconstructing signals. The idea behind the the last two sections here was to give you motivation for for how signals work and how kind of classical reconstruction can occur using math that we're all familiar with. This really covers any Vector in R2 um e0 uh we can Define as one zero so a horizontal Vector E1 is zero one a vertical Vector if we look at where we we're trying to project some Vector X onto uh the the e0 space right we can kind of see how the math works out here. familiar with perhaps in terms of how we can use those to reconstruct signals and ultimately how we Can use Those to generate audio right predict the best uh kind of next node um so looking at the next the next step here we want to use deep learning for reconstruction right where we are are reconstructing a low quality audio to high resolution audio right um and this is this is the kind of uh model framework um that we can used for this um you might notice it really closely resembles a unit which is something that we talked about during image segmentation. after this restacking step um and the the loss function used throughout this process specifically was was kind of a mean squared error loss function so by playing around with different kinds of loss functions you might be able to yield better performance. We're going to kind of uh kind of transition now into Transformers for audio generation right how can we use Transformers to predict the next note for example. We can use the Transformer architecture to predict music notes our goal is to build a sequence model for music where we take an input sequence and predict a given Target sequence. music realm does provide a different issue than it did for our other two representations um of of image and text we want to then build the model and train it to predict the next token right the first step takes the form of converting data which is music files into a token sequence which is individual notes. We can approximate this which is a series of notes in a piano roll right or a graph that has our offsets and our pitches right so our pitches span you know a certain uh pitch set um and we want our our information to be captured in multiple Dimensions. see here um this kind of adheres to you have you know two quarter notes and a half note and the tokenized form of this is you have C and then quarter D quarter e half right but the problem with this is that you have a large vocabulary size where you have to keep keep track of all of these sub tokens. And you have less control over predictions given that your vocabulary size will grow as you add nodes right um the other kind of thing is polyphony right taking many notes and mapping it for one specific kind of tokenized set where you play note sequentially. Transformers can be transformed into 12 songs of different Keys which can help increase our sample of training data and generalize key scales and beats throughout a data set. Data augmentation provides an amazing data sub multiplier to to get more data. Transformers will far outperform classical methods of of both computer vision and natural language processing the more information you have and the more generalizability you have in your Transformer the better it'll perform. The next thing to consider is positional beat encoding to give it a better sense of musical timing. zero is a token you can see one is atoken you can't see um which is a little backwards I know um but you're you're essentially masking the every token except for yourself right here. By the last step you're able to see everything right by applying an another mask a window of size 2 here at the first step you only see yourself right at the Second Step you don't even see what token you're on. You only see the previous token at the third step and you're getting more information about the the current token. hidden state memory Transformer memory specifically to this model enables very fast inference for music prediction right we've done a lot of things to optimize for for our prediction we're including a beat embedding so that's not something it has to learn. We're able to get a sense of of relative position with Transformer XL whereas vanilla Transformers will use Absolution absolute position only. It's important for music models to know the position of each token relative to one another because positionality matters right the order that you're playing the notes really is is what matters the most. are the original Pachelbel's Canon um as you can see this does deviate a bit but honestly it sounds pretty good. The Transformer model is able to do this next note next sequence prediction pretty pretty well. So yeah there's a a lot to do in this field um a lot of really cool things happening um and yeah I hope you guys learned something about uh about generative audio today and are inspired to kind of give some of these things a try yourself. thank you guys for tuning in have a good one.

ROUGE-1: 36.21, ROUGE-2: 34.79, ROUGE-L: 34.78
BERTScore: 67.36

==============================================
==================== [75/100] ====================
Summary:
Professor: The amygdala is closely connected to the basal forebrain. Professor: The abnormal brain connections that we know occur, at least many types of schizophrenia. He says the earlier the lesion, the greater the plasticity, the more chances of sprouting the connections that are the basis for this idea. In green, there are the very widespread catechol-oligosynaptic projections, which show the extent of the brain's plasticity. In blue, the acetylcholine containing neurons that you see in the medial septum, which we mentioned last time. All right? And this is just to show you binding to receptors for these different transmitters of the various anti-psychotic drugs. The blue shows the D2 dopamine receptor binding drugs. And you can see very commonly that these drugs have a high affinity for those receptors. But there's an affinity for the receptors for the other type of dopamine [? receptor. ?] And that could be a reason. Just saying that it does [INAUDIBLE].. Let's talk about the other part of the basal ganglia, the larger part, the corpus striatum. In mammals and other amniotes, the birds and reptiles, the skates and the rays-- sharks, skates, and rays comes from the ventral tegmental area. And we know that, especially if you look in fish, that a major input to the hypothalamus in those animals is from the taste [? cyst. ?] In mammals it's never been emphasized, but we know taste can be very rewarding and influences the te segmental area cells. The studies of rats have indicated yes, there are some projections, even in mammals, from that system. unique in that way. And it's critical for the balance of this system. So anything that goes wrong with the subthalamic nucleus can cause major problems with movement. OK, so let's stop there today. We're going to take a break from talking about the human body. We'll be back next week with a look at some of the other animals in the animal kingdom. Back to Mail Online home.Back to the page you came from. Back To the pageYou come from.

ROUGE-1: 11.95, ROUGE-2: 10.25, ROUGE-L: 10.10
BERTScore: 60.16

==============================================
==================== [76/100] ====================
Summary:
Learn how the solar cell device converts sunlight, the input energy, to some usable output energy, which is in the form of electricity, typically, from a solar panel. Learn how to minimize the amount of light reflected or not absorbed into maximizing amount of life that's actually absorbed. Learn about the duality of light, or how to think about light as a particle, or alternatively, as a quantified particle. Use the weekly Newsquiz to test your knowledge of stories you saw on MIT OpenCourseWare. photon has a certain wavelength, a certain frequency and a certain wave length associated with it-- frequency and wavelength related, of course, by the speed of light, Planck's constant, and so forth. The visible photon wavelengths are usually in the hundreds of nanometers. And the solar spectrum peaks somewhere around 550, just good numbers to have in mind. So this was that solar spectrum, the integrated solar radiance versus wavelength. The second point that is equally valid, we can describe the wavelengths of the incoming light. you can have, for example, in the visible range, a decreasing depth of penetration of the light with increasing energy, whereas with x-rays, it's the exact opposite. It's because you're dealing with different types of electrons and the material. The real component of the refractive index is material-specific property. And it is related to the attenuation of light intensity as it travels through that material. And so here what I've done for you is placed the equation that describes the complex index of refraction of a material. the interaction of light inside of a medium, inside ofa material. And we use that information to calculate engineering relevant parameters such as reflectance of light off of a surface. So I have an equation here that describes the reflectance. Let me dive a little deeper into it and try to understand what exactly that equation is telling me. So if you have a tinted window, what is typically happening at that tinting window? Why can't you see inside? What would you imagine is going on? With normal incident light, there is a beautiful symmetry involved. If I add a coating, for instance, to a window that increases the reflectivity, then the amount of light that is able to escape from the inside to my eyes decreases. So just the same way that I'm losing the ability to see inside, the folks inside are also losing the able to see out. Why is it that with the same reflectivity they're able tosee outside and I'm not able to seeing in through that tinted window? We need to understand how light gets absorbed inside of matter. We apply a very simple formulation inside of this class, which is called Beer-Lambert's Law. So let's imagine that through the techniques that we're going to be discussing later on in lecture, we manage to minimize the amount of reflectance off the front surface. And now the light that's incident on the material is actually going to go inside and get absorbed by the material inside. We're happy to walk through that perhaps during recitation. very simple yet very powerful formulation that describes not only the interaction of light with the solar cell material but also light through the atmosphere. And for that, I'd like to call Joe up for a quick demo that will allow us to actually plot out Beer-Lambert's Law. And let's see if the hypothesis is correct. It's not. But we're going to test it. And it's a logical thing you might assume. And then we'll walk through a derivation that will correct our missed logic. So go ahead, Joe. Take it away. A laser pointed and a photodiode are used to measure the power of a laser. The current out of this photodiodes is directly proportional to the light hitting it. As we keep increasing and put one layer of polyethylene, that drops to 0.75. So you'd expect the intensity to drop by another factor of 2. Why not? There's kind of this sense that it should be exponential. What don't we add some more filter in front, and we'll see what exactly this comes out to be. to curve down. Exponential. It looks like one at least. And we can test whether or not the hypothesis is correct by an exponential fit, which happens to match pretty well. The amount that's absorbed is following another trend, which is just 1 minus that. And so right now we're ignoring this is 1 minus r component. But it's so small that it really doesn't matter for this experiment. These things don't reflect a lot of light. But we notice that we have some exponential character to be decay of the intensity of the transmitted light. in some function to that medium and a certain amount of light is transmitted, we know, of course, from our little experiment that it follows some exponential function. So if we assume that the change of intensity within that medium in each little delta thickness is going to be affected by some sort of scattering intensity within the medium-- and this sigma here can refer to a variety of processes. So the s Sigma here is independent of thickness throughout. And then as you integrate through, you wind up with that beautiful exponential function at the end, the sigma l times n. a geometric parameter. It's an intrinsic material parameter. This alpha will vary as a function of wavelength inside of a material. The resonances with different electronic states within the material, that light, depends on the energy of the light. So there's a wavelength dependence. That general equation is the same one that drives the reduction of light intensity as it travels through the atmosphere. So if we increase the atmospheric path length, we'll be reducing the amount of light that actually reaches the surface of the earth. for our atmosphere than it was for these little polyethylene sheets. Because the nature of the scattering and absorption processes are very different for the atmosphere. So this alpha here is, I would say, density neutral. What we've done is we have the alpha encapsulating the physical parameters of the material and the absorption processes all in one variable, very nicely and succinctly. And the only geometric parameter that is of essence is really our l. Any questions? Yes? AUDIENCE: What was n? TONIO BUONASSISI: So the n, there's a certain scattering intensity, and then a certain number density. The energy range of light ranges from about 6.2 eV to 0.62 eV. The visible wavelengths range would be somewhere in this regime right here. The infrared out here, ultraviolet over here, and we can see for a variety of different types of materials what the absorption coefficient is. The red would be crystalline silicon, gallium arsenide, indium phosphide, and amorphous silicon. And we're going to calculate the thickness necessary to absorb 90% of the incoming light at 550 nanometers. absorption coefficient and order of magnitude less than gallium arsenide. Most of these solar cells that you see of crystalline silicon are on the order of 100 microns, typically a little thicker for some technological reasons, which we'll get to. At 800 nanometers wavelength light, the optical absorption coefficient is dropped by about an orders of magnitude relative to the peak of the solar spectrum. What could you do to your solar cell device to increase the total amount of light absorbed inside of it? 10% of the light that didn't make it, that's going to get reflected back. The first thing that we can do is texturize our front surface. If we don't have texture, if it's absolutely flat, what we call specular surface-- specular coming from the root mirror. So a flat silicon substrate, a specularsurface, would reflect some finite amount of light. And we can calculate that now because we know that it relates to the real component of the refractive index of the solar cell. As the material goes from one medium to another, the refractive index changes. Texturization increases the probability that light will enter the device. It also increases the path length, the effective path length of the incoming light. The way to understand that particular phenomena is called Snell's Law. So the way in which the electromagnetic wave oscillates the. So we have a texturized front surface. We discussed this right at the beginning of lecture. We're just focusing on the lights, the rays that get reflected. electrons instead of the system is changing from one medium to another, let's say from air into the solar cell device. The light path will obey what is called Snell's Law, which is the product of the refractive index and sine of that angle, the angle relative to the surface normal. So there are two benefits to texturizing your front surface. One is you have an additional pass, additional bounce, an additional encounter with the material. So that reflected light gets more energy. The record efficiency solar cell that was announced this past year in gallium arsenide was achieved because of good light management. To engineer front and back surface reflectances, you really have to carefully select your refractive indices and your materials if you put on either side. So which of these two do you think is which? Why don't you turn to your neighbor quickly and chat about it without peeking at your lecture notes. The answers here are shown, for this particular system, through the equations right here. our reflection condition. I'm going to come back to Snell's Law in a minute. But for the time being, I want to move on to the next concept here, which is Lambertian reflector. Often in the solar industry you'll hear people, probably because of a lack of optics background, just call any randomly reflecting surface a Lambertian scatter. It's a very loosely used term. And it is wrong by the book, but nevertheless, it's one of these things that live on in our industry. the backsides of solar cell devices. We wouldn't want necessarily specular reflectance. We might want to maximize the amount of light reflected off at particular angles. And there is, of course, research being done to figure out how to make light do that. And you don't only have to texture your back skin. You can also texture the bus bars. The bus bars are these little metal wires right here that are collecting the charge from each of the solar cells. And they're connecting essentially the front side of one cell to the backside of the next. There is a limit to how much we can trap light simply by modifying or corrugating the surfaces. The Yablonovitch limit to this day is a pretty good litmus test for the ability of a material to trap light. If you have silicon, for instance, with a refractive index of, let's say, in the infrared some around 3.6, your limit is around 50. You can increase probably in the order of 20 the optical path length inside of the material through texturization. In most solar cells, we want to suppress reflection. We go to great lengths to make sure that this thickness as well as the refractive index of the material is optimized for a particular system. If you add these two together, due to the wave nature of light, you get suppressed reflectance. That's a really interesting property. You can constructively interfere if you like and enhance the amount of reflected light as a result of this interference effect. The anti-reflective coating is not absorbing the light, which is really important. expressions that we just walked through. It's really important to understand the fundamentals behind any simulation software because you will get out of it what you put into it. You will not be able to pick up on obvious things that you might of-- for example, double clicked on this little material here and find the real component of the refractive index completely wrong. And you might not notice it if you don't have some good intuition which is grounded in the fundamentals. And so it's important that you understand what we've presented today. fancier ways of light management as well that don't involve light trapping necessarily but light manipulation or even semiconductor manipulation. You can, for instance, change the wave length of the incoming light. If we can eliminate the longer wavelength stuff out here, which is heat, performance of most solar cell suffers when they get hot. And so if we manage to do spectral up converting or reflect that long wavelength light away from our device, we can improve performance there as well. So again, I wanted to really emphasize that light management is necessary devices. a coating on the back to reflect the light back so that it gets a second bounce through the material. I've engineered the front surface, texturized it so that we have not only the benefit of two bounces, double the chance of light going in. And so all told, the one reason why this boost is so big right here is because I'm increasing the optical path length, the effective Optical path length. And as a result, I'm getting a much larger current output. I'm generating many more free carriers instead of my material. lecture today talking about light management is because of this plot right here. Snell's Law assumes that there's no phase shift of the light as it transfers from one medium to another. If you introduce a phase shift, now you can start doing some fun things. In the lab, 24.2%, in commercial production, 22% and change. 22.4%, I think. The device design can get pretty complicated for these super high efficiency devices. And they're worried quite a bit about trapping, other things as well. surface of a material, let's say right here, then you can cause each node, each point within your material, to lag by an increasing amount, so that your wave front now bends. And that will cause the light, essentially, if you trace through the points of maximum intensity, say the pink, you'll see that the light is bent. And so it's really exciting. There's stuff coming up every day on light trapping and light management. Mostly it's for photonic devices, but they can be transferred over into solar cells. today in class, don't let that constrain your thinking. That's my final message. Thanks. Back to Mail Online home. back to the page you came from. Click here to read the rest of the article. Back To the pageYou came from: Back to thepage you camefrom. Click HERE to see the full transcript of this week's episode of "This Is Life With Lisa Ling" with Lisa Ling, Lisa Ling and Lisa Ling on "Lisa Ling: The Next Generation"

ROUGE-1: 33.00, ROUGE-2: 31.28, ROUGE-L: 29.53
BERTScore: 60.02

==============================================
==================== [77/100] ====================
Summary:
Professor Steven Smith: I want to look at two sets of issues. One is Locke's theory of the constitutional state, particularly focusing on the role of the executive, vis-a-vis the legislative branch of government. The other is thinking about Locke and the American regime and the current state of political philosophy, modern contemporary American political philosophy. Smith: Locke doesn't endorse necessarily one particular form of government from any other. He is an advocate of what we have come to call limited government, of constitutional government. John Locke says in his day it was sometimes necessary for the fire department to tear down the house of an innocent person to prevent the fire from spreading to other houses. He understands this as a piece of prerogative power acting for the public good. But the question for Locke, as for any constitutional lawyer, is what are the limits of this power? What check, if any, is there on this power to prevent their abuse? Locke doesn't exactly say. He raises this question to be sure, of fundamental importance for constitutional government. LZ Granderson: John Locke gave the modern constitutional state its definitive form of expression. He says Locke's doctrine of consent and legislative supremacy should make him a hero to Democrats, to radical Democrats. LZ: A judgment on America is very much a judgment on the philosophy of Locke and vice versa. In many ways, if anyone is, I think Locke has the title to be considered America's philosopher-king, LZ says. of Lockean first principles for many other readers of American history. John Rawls' "difference principle" says natural endowments are not ours in any strong sense of the term. They do not belong to us but are the result of a random or arbitrary genetic lottery or social lottery, he says. According to Rawls, justice requires that social arrangements be structured for the benefits of the least advantaged in society. John Locke's theory of self-ownership justifies his conception of limited government in the constitutional state, says David Frum. John Rawls and John Locke represent two radically different visions of the liberal state. Rawls: We never really have ownership in ourselves but are always part of a larger social "we" Locke: Government should reshape and redistribute the products of our individual endeavors for the common interests. The question for you is which of these two views is more valid or which of the two strikes you as more powerful or plausible? We will turn to that problem emphatically on Wednesday when we look at Jean-Jacques Rousseau's Essay on Inequality. satisfy the deepest longings of the human soul? Can a regime, devoted to the rational accumulation of property answer those higher order needs or higher order virtues, like honor, nobility and sacrifice? Can the avoidance of pain, discomfort and anxiety produce anything more than contemporary forms of Epicureanism and Nihilism? In any case, I'm suggesting no more than any other land could America insulate itself from the great heights as well as the great depths of later forms of modernity. We are but a moment in the kind of comprehensive self-dissatisfaction that is modernity so that a return to Lockeanism, in many ways, is not so much a cure for the pathologies ofmodernity.

ROUGE-1: 17.52, ROUGE-2: 16.14, ROUGE-L: 16.17
BERTScore: 64.65

==============================================
==================== [78/100] ====================
Summary:
JACK HARE: Let's do a little recap on electron cyclotron emission, and then we will go on to a few other things. We didn't actually derive the emissivity of it, but we gave ourselves a hand-wavy reason why there may be multiple peaks here. And these peaks are going to be occurring at frequencies-- I'm going to switch into angular frequency units, omega m. And they're evenly spaced. And this is just for a single particle. that, the frequency depends only on the magnetic field. And so, if you see some emission at some certain frequency, then you know that it's been emitted by a region of plasma. And that was particularly useful when we considered a tokamak because, if we have some magnetic field that goes 1 upon R, then different regions of our toroidal device are going to be emitting electron cyclotron emission with different frequencies. And this is a technique which will give us, by looking at the spectrum for lowish frequencies, we can work out what the temperature is as a function of space. This is correlation ECE, often called CECE. We want to measure temperature fluctuations within the plasma that are maybe on the order of 1% of the baseline temperature, delta T upon T about 0.01. And that 1% is actually extremely hard to measure. And this is because the noise is just too high on these systems. There are lots of different contributions to the noise. But, in general, they all add up to make it very hard toMeasure these very small fluctuations. want to understand in plasmas so that we can build an economically viable fusion reactor. So it'd be very nice to be able to know. Now, the fact that the noise is too high does seem like a big limitation. But there are some clever tricks that we play where we use correlations. And I'll talk now about what exactly these correlations are and how they provide us with information that allows us to get a signal out despite the overwhelming [INAUDIBLE]. So our setup here is borrowed from ASDEX Upgrade. The ASDEX Upgrade system has a band pass filter. This is applying some filter to it that in frequency space looks a little bit like this, some sort of top hat. It's centered around the frequency where most of the electron cyclotron emission is. And this has a bandwidth of 10 gigahertz. So we've cut out an awful lot of the radiation in bands that we're not interested in. We are no longer going to study those, any bremsstrahlung, any higher order things. frequency range. Once we've got our bandpass filtered signal here, 110 kilohertz is still too fast for us to digitize. This would be an extremely expensive digitizer. So, what we actually do is we downmix it with the signal at 100 gigahertz. And so, then we get out our beat signal, which we can digitize, which is at 10 gig ahertz here. So this is-- actually, I will write this as 0 to 10 giga hertz. This is the sort of signal that we can actually digitize now. region. And you can tell that these regions are very small because we're dealing with 100 megahertz bandwidth. And we originally started with 110 gigahertz here. And so, you see we've gone down by a factor of 1,000. And that's how we're able to get down to this 100 microns or so. We digitize these signals. And, just for reference, the reason why we downsampled these is that digitized is now much less expensive. We're doing it something like 4 mega samples a second. Many oscillations. And so, it will average out to 1 or something like that. So it's some DC offset that we can subtract off after. So all this is doing here is mixing the signal down so it gets to a regime that we could effectively digitize. Yeah, another question. STUDENT: [INAUDIBLE] JACK HARE: So if we were doing geometric optics, which we're not, then you would have a lens like this. That lens could collimate your beam. And if it collimated that beam, that would mean there'd be a focus point at some distance f away. very small region on the order of 100 microns. Anyone know how micro splitters work? Looking at you? STUDENT: RF. JACK HARE: The answer I got was RF, which I don't think is much more satisfying than my answer. But, you're right, you could come up with some clever analog way of doing the splitting. But this is getting way beyond what I was hoping to talk about on this. So let's get on to correlation ECE see what that does. we're going to write this little tilde here to remind us that this signal is some oscillating quantity or time varying quantity. And that signal has two components to it. It's got some fluctuation, which is due to temperature fluctuation. And then, it's also got some noise. This is the thing that we don't want to measure here. And so, the signal, as a function of time, is going to look like, again, our temperature signal, which might be some nice and smooth function like this corresponding to some turbulent eddy. The size of a turbulent eddy, the size of one of these swirls, is larger than the separation between these two points. We are going to correlate these two signals. And we're going to find that the noise is uncorrelated at random, but these two signal will correlate together, and we'll be able to measure it. And, again, these are really, really closely spaced, 100 microns or so apart. But, the nice thing is now that these two. signals are carrying the same components that we're trying to measure. do correlations, and I'm not going to go into them, but I will give you a citation at the moment. We get out a term here that looks like the temperature term squared, the thing we want. And because this noise is just random, when we do some sort of averaging, this could be in time or best to think of it is a short time integral, then these terms are all going to drop out. And we'll just be left with a correlation signal that is proportional to the temperature squared here. fluctuations in a tokamak. And this is something that has revolutionized our understanding of turbulence. Now we can finally characterize it. That was a lot. Any questions? We're going to move on from ECE [INAUDIBLE]. Yes. Any other questions? Anything online? Now we are going to go to the next segment, which is about turbulence in the Earth's atmosphere. The next segment is about the atmosphere in the atmosphere of the Earth, and how turbulence affects the atmosphere. Bremsstrahlung is a term used to refer to a type of radiation in the universe. It involves electrons being deflected and breaking and emitting these photons. There are lots of different ways to deal with bremsstahlung to do the actual calculation. The main thing we can say in a classical treatment is that the bremstahlt is going to be isotropic in every direction. That's actually quite different from electron cyclotron emission, even though we didn't really look at the anisotropy of that in any detail. here with the ions and electrons as point particles. There's a semi-classical approach where you start bringing in some quantum physics and treat, I think, the electron as a wave. And then there's a full quantum approach. What's remarkable about all of these approaches is they all give the same answer with just a very slightly different coefficient. So we get a small change in coefficient. The scalings are the same. So in some sense, although it's important to get the exact coefficient, it doesn't matter exactly which one of these techniques you use. This is equation 5.3.40 in Hutchinson. This is ne, ni, z squared, T to the minus 1/2 e to minus h nu upon T. And then, there's a factor called G bar, the Gaunt factor, which we'll talk about in a moment. And these constants are things like e, the electron charge, and the electron mass, and epsilon 0, and h bar, and c, all arranged in some way to make all the dimensions work. magnitude. And so, in general, it's reasonable to just treat G as being a constant and then, for this calculations we're doing, where we're going to drop the absolute intensity, we can just drop G with all the other constants as well. So we can drop [INAUDIBLE]. But if you want to go back and do this properly for some measurement that you're doing,. then you'd have to include this. And that is all you need to do Problem Set 3. have any recombination, which we'll talk about next. This is still going to be there. So if I'm doing my ECE and I zoom in on this region here, I'm going to have i frequency here. And, on top of that, I'd have my black body ECE spectrum or something like that. But this bremsstrahlung may be quite small. But even if it's not quite small, it is constant because it varies only slowly as a function of a frequency. There is no mode in a plasma which propagates below the plasma frequency. So it goes back to being optically thin here for the high energy photons. But the low energy photons will get absorbed as well. There's actually another effect, which is in Hutchinson's book, which I haven't covered here. But we're skipping over that this year. But it's in there if you're interested. Yeah. Yeah, I think someone told me that maybe for a high field tokamaks synchrotron could start being significant. But I actually have no idea how big a deal it is. mostly on the magnetic field and the radius. And those are two things in a tokamak you already know. But maybe there's a really clever diagnostic you can do, like fast particles or something like that. So worth thinking about. JACK HARE: Right, but I'm not interested in [INAUDIBLE]. This is a diagnostics course. Any questions online while we pause? So this is bremsstrahlung radiation, and often people call this free-free. Professor Jack HARE: We're going to switch to a slightly quantum model of the atom. We have a range of different discrete energy levels that the electrons can occupy. These energy levels are labeled by the principal quantum number n. And, up here, infinity, this is ionization. If your electron gets this much energy, it becomes free again, HARE says. But, of course, there's another case where this photon takes away so much energy that this starts, I guess it becomes imaginary. a forbidden transition. If I put in some velocity v and I occupy some principle quantum number n, then I will get out a photon here. There's no forbidden solution to this. And if you get up to a point where your energy is so high that you can then access the next level, then that becomes very favorable and, in fact, there are some-- these ones down here, it might continue from the 2 level or it might start occupying this level instead. It's not the condition that there are photons that are released with greater than 12 mv squared the kinetic energy. you would know what the velocity of your electron is, I don't know. But if you're in this single particle picture, if you see a photon that's released with less than 1/2 mv squared, then the electron still has some residual kinetic energy left. And so, therefore, it must be free. And the only way it could have done that is if it fell down into one of these principles. So this long tail here is due to the fact that we have electrons not just with v equal 0 but much more than that. related to the overlap integral between those with a dipole operator, the dipole operators being the thing that emits the photon in between them. So, yeah, you're right, there are inverse processes. We're going to get to that and the idea of detailed balance and thermodynamic equilibrium and things of that ilk. But these are the two simplest ones, free-free and free-bound, that I wanted to discuss before we did some diagnostics. Any other questions? We'll go into some ways of actually making some use out of all this stuff in a moment. processes for all of these that will affect the spectra that you get. So one use of this is a diagnostic called bolometry. It cares not at all about the detailed spectrum of what the emission is. It just wants to know how much power is being radiated by the plasma. And so, that is going to be the integral d nu of j of nu. But, of course, the detail matters because you can see the recombination increases the amount of emission above that baseline bremsstrahlung value. So there'll be more emission here. do bolometry is we have some radiation coming out of the plasma. We have a little sensor sitting at the wall of our vacuum vessel. And we'll call this resistor M. It has a resistance M. And that resistance M is a function of temperature here. And so, as this resistor heats up from absorbing the radiation, its resistance is going to change. So by measuring this voltage VR, by knowing the voltage V0, and knowing the reference resistor R, we can measure the voltage M. We're dividing V0 between M and R. And we're measuring the voltage across R, which then, of course, tells us what resistance M has here. And so, this is also a function of time and temperature. And, from that temperature, we can make an estimate of the radiation power incident upon it. We'll talk a little bit more about how to do that in the next step. But this, effectively, serves as a very, very simple system. And you can be digitizing this as a functionof time. radiation can affect this. And so, by measuring delta T up here, the change in temperature in our resistance, we can invert this equation and we can back out the radiation power. So this is just a really simple way of using a resistor to measure the power coming out of the plasma. And bolometry was one of the first diagnostics that we had on many MCF devices. Questions on this? STUDENT: [INAUDIBLE] JACK HARE: [inaUDIBLE], we'll talk about that in a moment. R2. I think I'm just going to call these R2 and R1. And, in a Wheatstone bridge, what we now do is we still have a potential drop, V0, over the entire bridge. But we now measure the potential difference across these pairs here. And that is called V bridge. So these measurement resistors, they see the radiated power P rad, and their temperature is equal to the temperature of the reference resistors plus a change in temperature due to radiation. The Wheatstone bridge is used to measure a voltage which is proportional to a small quantity. The voltage is entirely due to the change in temperature. So we're now able to isolate the temperature very, very precisely. We also use a phase locked loop measurement, which is a form of heterodyning again, my favorite technique. And so, we actually have V0 is oscillating at around 50 kilohertz or so. So, we can see that our signal, delta T, is a slowly varying signal which is embedded on top of this. have a thick block some distance in front of it so it can't see the plasma. It's the heat transport kappa grad T that gives us the time constant for thermal conduction through the substrate from the absorber to the resistor. And, effectively, this tau here sets the timescale at which we can measure. So the larger tau is the slower our measurement of the radiated power is going to be. And if tau gets very large, because we've got a very thick substrate here, or it doesn't have very good heat transport, then we're going to have a very poor time resolution. difference between those. neutron damage leads us to use much thicker substrates, which gives us a longer time response and so, therefore, a worse bolometer. So, ironically, the bolometers that will be used on [INAUDIBLE] are significantly worse than the bolometer used on existing devices. And I'm sure that [? Spark ?] will have exactly the same problem. Almost everyone in the world uses this design of bolometer that they pioneered on ASDEX Upgrade in the '80s. No one has come up with a better system yet.

ROUGE-1: 40.53, ROUGE-2: 39.00, ROUGE-L: 38.67
BERTScore: 70.37

==============================================
==================== [79/100] ====================
Summary:
Reinforcement learning involves the idea of a model, a value, and a policy. A policy is a mapping from the state you're in to what is the action, um, to take. A model is a representation of the world and how that changes in response to agent's accident. A value is the expected discounted sum of rewards from being in a state and/or an action, and then following a particular policy. Markov Decision Processes is where we think about an agent interacting with the world. world. So the agent gets to take actions, typically denoted by a, those affect the state of the world in some way, um, and then the agent receives back a state and a reward. The Markov process is to say that the state that the agent is using to make their decisions, is the sufficient [NOISE] statistic of the history. And next states that we have seen up until the current time point. And so essentially, it allows us to say, the future is independent of the past given some current aggregate statistic about the present. The definition of a return is just the discounted sum of rewards you get from the current time step to a horizon and that horizon could be infinite. If Gamma is equal to one, then that means that your future rewards are exactly as beneficial to you as the immediate rewards. If you're only using discount factors for mathematical convenience, um, if your horizon is always guaranteed to be finite, it's fine to use gamma equal to 1 in terms of from a perspective mathematical convenience. Any other questions about discount factors? Yeah. The Markov Reward Process is a way to estimate sums of returns- sums up rewards. You could estimate it by simulation. There are mathematical bounds you can use to say how many simulations would you need to do in order for your empirical average to be close to the true expected value. The accuracy roughly goes down on the order of one over square root of N where N is the number of roll-outs you've done. And that would asymptotically converge to what the value function is. roll out in the world then you can get these sort of nice estimates of really how the process is working. But it doesn't leverage anything about the fact that if the world really is Markov, um, there's additional structure we could do in order to get better estimates. So, the value function of a mark forward process is simply the immediate reward the agent gets from the current state it's in plus the discounted sum of future rewards weighed by the discount factor times the transition model. State and multiplying that by the value function there. So, in this case we can express it just using a matrix notation. Um, and the nice thing is that once we've done that we can just analytically solve for thevalue function. And if you have N states, it's fine if some of the states that you might transition back to the same state there's no problem. You do need that this matrix is well-defined. That you can take that and take the inverse of it. so let's say you have N states there's generally on the order of somewhere between N squared and N cubed depending on which matrix inversion you're using. Is it ever actually possible for, uh, that matrix not to have an inverse or does like the property that like column sum to one or something make it not possible? Question was is it ever possible for this not to has an inverse? It's a good question. Um, but I'll double-check then send a note on a Piazza. the value of a state is exactly equal to the immediate reward we get plus the discounted sum of future rewards. And in this case, we can simply use that to derive an iterative equation. The advantage of this is that each of the iteration updates are cheaper and they'd also will be some benefits later when we start to think about actions. So, here are two different ways to try to compute the value of Markov Reward Process or three really one is simulation, the second is analytically and the third one is dynamic programming. A Markov Decision Process is typically described as a tuple which is just the set of states, actions, rewards, dynamics, model, and discount factor. So, the agent is in a state they take an action, they get immediate reward, and then they transition to the next state. Now we have a dynamics model that is specified for each action separately and we also have a reward function. And as was asked before by Camilla I think, the reward can either be a function of the immediate state, the state and action to the state action and next state for most of the rest of today we'll be using that. A lot of this class we'll be thinking about deterministic policies but later on when we get into policy search we'll talk a lot more about stochastic policies. So, if you have an MDP plus a policy then that immediately specifies a Markov Reward Process. Because you're only ever taking you've specified your distribution over actions for your state and so then you can think of sort of what is the reward, the expected reward you get under that policy for any state. And similarly you can define your transition model for Markov reward Process by averaging across your transition models according to the weight at which you would take those different actions. The Markov Decision Process for the Mars Rover is based on the Markov chain. The reward function is still that you either have for any action if you're in state one you get plus one and in any state any action for state s_7 you gets plus 10. Everything else is zero. And the reward for all actions and all other states is zero except for in state s-7 where it's always 10 no matter which action you take. So, in this case, what is the value of the policy and this is just to remind you of what like the iteration way of computing it would be. you do this computation. Just to quickly check that the Bellman equation make sense. So the immediate reward of this is zero plus gamma times [NOISE] 0.5. And that's just an example of, um, how you would compute one Bellman backup. So that's back to my original question which is you seem to be using V_k without the superscript pi to evaluate it. Oh, sorry this should, yes. This should have been pi. That's just a typo. to be pi up there. Yes it was, thanks for catching. All right, so now we can start to talk about Markov Decision Process control. Control here is going to be the fact that ultimately we don't care about just evaluating policies, typically we want our agent actually be learning policies. So the important thing is that there exists a unique optimal value function. So that's one really good reason why it's sufficient for us to just focus on deterministic policies, with a finite state MDPs in infinite horizons. There are two choices for every state and there are seven states. The number of policies is |A| to the |S| so we can be large, its exponential and the state-space but it's finite. Um, any one want to take a guess of whether or not the optimal policy is always unique? I told you the value function is unique. Is the policy unique? Yeah. I think there might be cases where it's not. It's not always unique but if there may be ties. So no. Depends on the process. In policy iteration what we do is we basically keep track of a guess of what the optimal policy might be. We evaluate its value and then we try to improve it. If we can't improve it any more, um then we can halt. In policy improvement we define something new which is the state action value. We're talking about like V^pi(s) which says if you start in state s and you follow policy pi what is the expected discounted sum of rewards. So, remember right now we're in the model where we know the reward model and we know what we can do. policy from then onwards. We are going to follow this new policy for all time. So, it should be at least a little unclear that this is a good thing to do [LAUGHTER]. Should be like, okay, so you're, you're saying that if I were to take this one different action and then follow my old policy, then I know that my value would be better than before. But what you really want is that thisnew policy is just better overall. And so the cool thing is that you can show that by doing this policy improvement it is monotonically better than the old policy. strict inequality if the old policy was suboptimal. So, why does this work? So, it works for the following reasons. And the next questions that might come up is so we know we're gonna get this monotonic improvement, um, so the questions would be if the policy doesn't change, can it ever change again? And is there a maximum number of iterations of policy iteration? Here iterations is i. It's a kind of how many policies could we step through? different, right? Because policy says you always have a policy and you know what its value is. It just might not be very good. Value iteration says youalways know what the optimal value in policy is, but only if you're gonna get to act for say k time steps. So they're just- they're computing different things, um, and they both will converge to the same thing eventually. So how does value iteration work? We're taking this max a over th- the best immediate already credit plus the discounted sum of future rewards. work? The algorithm can be summarized as follows. You start off, you caninitial your value function to zero for all states. And then you loop until you converge, um, or if you're doing a finite horizon, which we might not have time to get to today. And basically, for each state, you do this Bellman backup operator. So you'd say, my value at k plus one time steps for that state is if I get to pick the best immediate action plus the discounted sum of future rewards. So, if you see sort of a B with, um, ah, pi on top and saying, well, instead of taking that max over actions, you're specifying what is the action you get to take. So policy evaluation you can think of as basically just computing a fixed point of repeatedly applying this Bellman backup until V stops converging and stops changing. So, if an operator is a contraction it means that if you apply it to two different things, you can Think of these as value functions, then the distance between them shrinks after. doesn't get bigger and can shrink after you apply this operator. So, the key question of whether or not value iteration will converge is because the Bellman backup is a contraction operator. And it's a contraction operators as long as gamma is less than one. Which means that if you do- if let's say have two different Bell- er, two different value functions and then you did the Bell man backup on both of them. Then the distance between them would shrink. So how do we prove this? Um, we prove it- for interest of time I'll show you the proof. then the next thing we can do is we can bound and say the difference between these two value functions is diff- is, um, bounded by the maximum of the distance between those two. So you can pick the places at which those value functions most differ. And then you can move it out of the sum. And now you're summing over a probability distribution that has to sum to one. And so that means that the Bellman backup as long as this is less than one has to be a contraction operator.

ROUGE-1: 26.61, ROUGE-2: 25.88, ROUGE-L: 25.68
BERTScore: 64.84

==============================================
==================== [80/100] ====================
Summary:
 angular momentum is a set of operators that provided observables, things we can measure. We found that they satisfy a series of commutators in which lx with ly gave ih bar lz. We showed that any component of angular momentum, be it lx, ly, or lz, commutes with l squared. And therefore, we set up for the search of those wave functions that are simultaneous eigenstates of one of the three components of angularmomentum. wanted single valued wave functions-- wave functions would be the same at phi, and at Phi plus 2 pi, which is the same point. You must choose m to be an integer. For the l squared operator we also explained that the eigenvalue of this operator should be positive. That is achieved when l, whatever it is, is greater than 0. And the discussion that led to the quantization of l was a little longer, took a bit more work. Happily we have this operator, and operator we can diagonalize, or we can find eigenstates for it. are the Legendre polynomials. Solve this equation for m equals 0. Are there any questions? Anything about the definitions or? Yes? AUDIENCE: Why do we care about simultaneous eigenstates? Professor: If you have a system you want to figure out what are the properties of the states. In general, you will be led in any physical problem to look for the maximal set of commuting operators. The most number of operators that you could possibly measure. If there is no property that distinguishes them, they should be the same state. most important question to try to enlarge the set of commuting observables. Leading finally to what is initially called a complete set of commuter observable. We'll begin the hydrogen atom and this task why? Having a proton and an electron we can reduce this system to as if we had one particle in a central potential. So that will be also very important physically. And here there is a simple observation that one can make. The differential equation for p l m depends on m squared. We expect to need values of m that are positive and negative. definition solves the differential equation star. This takes a little work to check. I will not check it, nor the notes will check it. It's probably something you can find the calculation in some books. But it's not all that important. The important thing to note here is the following. That this provides solutions. And there's no great honor in finding zero solution of this equation. These are no solutions. So this produces solutions for absolute value of m less or equal to l. And therefore m in between l and minus l. The spherical harmonicas are going to be those wave functions. And they have a normalization, n l m, an exponention, and all that. So let me write, just for the record, what a y l m looks like with all the constants. Well, the normalization constant is complicated. And it's kind of a thing you can never remember by heart. So you could plug this whole mess here. I don't advise it. It's It's all valid for 0 less 0 m positive m. The specific forms of these polynomials we can find them. The only one I really remember is that y 0 0 is a constant. It's 1 over 4 pi. Here is another one. y1 plus minus 1 is minus plus square root of 3 over 8 pi e to the plus minus i phi sine theta. And the last one, so we're giving all the spherical harmonics with l equals 1. Here they are. Plus or minus 1 and 0.

ROUGE-1: 47.98, ROUGE-2: 46.25, ROUGE-L: 47.21
BERTScore: 74.57

==============================================
==================== [81/100] ====================
Summary:
In order to do that, I basically have to do the integral. So here it is. We have psi of x and t. It's integral dk phi of k e to the ikx minus omega of kt. If you want to see the distortion, you have to keep that [INAUDIBLE]. We'll do that in a week from now. And then, you say, look. There's lots of things making it look like a difficult integral, but it's not as difficult as it looks. is equal to zero, it will have a peak. And that corresponds to x equals to d omega dk times t, showing again that the wave has moved to the right. So I've given two presentations, basically, of this very important result about wave packets that we need to understand. It's called the wave function at time equals 0, and it has a peak when this thing is 0, the argument. And it's called a wave packet, and we can use it to understand wave packets.

ROUGE-1: 28.79, ROUGE-2: 25.30, ROUGE-L: 23.06
BERTScore: 66.18

==============================================
==================== [82/100] ====================
Summary:
There are three common uses of a rotation matrix. The first is to represent an orientation. The second is to change the frame of reference of a vector. And the third is to rotate a vector or frame. To demonstrate these, I will use these three coordinate frames, representing the same space with different orientations. To help you visualize these frames in 3 dimensions, I’ll use my handy tinkertoy frame. This is the z-axis, this is the x-axis and the y-axis. we will learn how to represent the angular velocity of a frame. We will also learn about how to use the frame to represent a frame's angular velocity. We'll also look at how the frame is used to represent an object's speed. We hope you will join us for the next few weeks of classes on how to work with a frame in this class. The next class will be on the physics of the frame in which we are working. The final class will take place in the next week or so.

ROUGE-1: 35.22, ROUGE-2: 26.36, ROUGE-L: 29.92
BERTScore: 66.09

==============================================
==================== [83/100] ====================
Summary:
Today, we'll talk about coded imaging. It's a form of a co-design between how you take a photo and how you recover the sharp detail afterwards in software. We'll see how-- we already have some projects that are inspired by biological vision. And I believe Santiago-- where's Santiago? Oh, yeah, his triangle-- the piston, kind of-- so some really great ideas. So I'm glad a lot of these concepts are coming together in the final projects. It is going to be very popular. capture the image and how you process the image. In a typical film camera, or even it is digital camera, you take the picture, and that's basically the end of the story. So when you try to recover this information, you start getting this banding artifacts. And we'll see it in the next slide, why that happens, and how to get rid of the banding and noise in the image you're trying to capture. Back to Mail Online home. back to the page you came from. have basically a 1D convolution that's converting this image into this image. But the Fourier transform has some zeros, so you cannot divide those frequencies by 0 and recover an image. So the culprit here is really this box function, which is equivalent to-- when you release the shutter, opening the-- release your shutter button-- opening the shutter and keeping it open for exposure duration and closing it. But that's not the most effective. So what if you change that? What if you open and close it in a carefully chosen binary sequence? frequencies-- they're all preserved. Of course, they're attenuated. It's not as high as-- it's not 1.0.0, it's reduced. Maybe it's 0.1 or so. So there is still some hope to recover this photo back from this because, in the denominator, we will not have seen. The problem is each of the frame will be extremely dark. So you are basically adding up a lot of noise. Every frame is dominated by noise. that's your 1010 inquiry. Instead of keeping the shutter open for the entire duration and getting a well-exposed photo, the shutter is open for only half of the time. The support for the representation of the Fourier domain of that function that you describe there is infinite, right? So you actually truncate this in order to-- RAMESH RASKAR: It's not infinite because you still have some width. AUDIENCE: Right, but you have infinite high frequencies there by the sharp conditions. but not 0. If you invert the process-- RAMESH RASKAR: From here, this is what you get. If your toy is moving or your taxi's moving really slow, then there is no need to-- in this case, the sequence was about 51-- actually, 52 vector long. So your 52 vector is going to stretch or shrink based on how fast the object is moving. And you're saying that it also depends on how far theobject is in space because faster-moving objects. think about image space motion because the speed in the real world and-- the distance are they get-- you divide to normalize by the distance. If you're in a dark room, you can just strobe the light, rather than opening and closing the shutter. So you get a reasonable result. But going back, what are the limitations of this method? Yes. You need to know the motion or the direction of the motion. If the car is moving from left to right versus right to left, the way your point spread function will be imposed on the scene will be different. If we did 100 milliseconds, it picks up speed, then your assumption that the 52-length vector will map to some stretched or shrunk version of 52 is not valid. Some parts will go faster and slower. You can either go to object space or you can come back to image space to make sure there is no acceleration. It's all linear. If two cars are partially overlapping during the exposure, it's possible, but it's more challenging because you don't know exactly how fast the two car are moving. your shutter? RAMESH RASKAR: No, when you're setting up your shutter, if the car is moving really slow, and you don't expect it to blur by 52 pixels, then using a 52 sequence is overkill. Maybe you should use a new sequence that's only about 10 long or 11 long, right? So it's just like-- AUDIENCE: OK, but that's just so you can get more light. RAMESHRASKar: No. That's so that it's most optimal for that setting. during that 52 window. In general, the technique works well when things are moving naturally. But if somebody wants to do this kind of an experiment, or move things behind an occluder and move out, those are very challenging scenarios. The basic assumption is that if you take any point in the scene, it's moving in a straight line, let's say. And if you have an object, and every point of that object moves in astraight line, OK. It doesn't matter which direction and what speed. blurred function is very critical. And this is what we want to study about half of the class. And the concept is very, very,very interesting because light is linear. So eventually, it's very linear. What happens to a point happens to the rest of the object. So if I have a car that's moving, and I tell you how exactly one point of the car is behaving in the image, I can tell you automatically how the other cars are behaving. All of it is going to have the same spread image. to engineer activity of the camera. So in this particular case, a point that was moving created a blur like this. And by engineering the time point spread function, it stops looking a bit like that. And then it just turns out that this one is easier to deal with than this one. So that that's why a computational camera is doing the computation not just in Silicon but also in optics. And the circuit is very, very simple. You just take the hot shoe of the flash, and it triggers. When you lose the shutter, it triggers the circuit. would you apply spatial coding? AUDIENCE: Coded aperture? RAMESH RASKAR: C coded aperture. So this is coded exposure, coded aperture-- very easy. And all you're going to do is put some kind of a code in the aperture of the lens. And this is how, actually, it started in the days of-- in scientific imaging, especially in astronomy, coded apertures are very well known. And so I thought, it must be useful for something in photography. An alligator came out of the water, and he lost his balance, and the boat flipped upside down. He managed to flip back in. But it completely damaged his camera that was with him, and it just wouldn't work. So he just took out his lens, which is a standard Canon lens. And he said, let's open it all the way. It had all the mud in it and so on. And then he just showed me this thing as is. And it was very fascinating because it was a standard film lens. When you think about a visual camera, you make this very simplistic assumption. That is a pinhole, and there's a sensor. And when you put a lens, we assume that the center of the lens is the central projection, that this always can be assumed to go to that point. So finding that plane is actually a tricky problem. And in retrospect, it's very easy. If the lens makers are putting everything there, we should put a recorded aperture also in the same plane. in the back. We tried all those things. But that creates a blur that's not constant all over the image. And it has a lot of issues. But placing it over there, it turns out you get the same blur. So what exactly happens if you take a picture of a point light, and everything is a sharp focus? Nothing changes. If you start moving away, the code will shrink. And eventually, when you put it here, we get another code. That's exactly what's happening here. When it's auto focus, we just see the code. digitally. In 1D, this is what we saw, right? Its Fourier transform is flat. So there are 52 entries here, and almost all of them are the same. Now we're saying, think about the problem in 2D. And what's the Fourier transforms of this? So first, for this one, the Fouriers transform is-- as we see, it's black. And then if you take that in 2 D-- so how is the code? I'll give you a hint. the values will be constant. So if we're placing a broadband code, certainly we have an opportunity to recover all the information. It's much easier to think about convolution and deconvolution in frequency domain than in primal domain. In communication theory, everything is [INAUDIBLE].. We think about carrier frequencies of radio stations in frequencies. And we think about guard bands and audio bands. And that's the same thing that's going on here. And convolution, deconvolved-- much easier than frequency domain. At the end, the solution is very easy-- just flutter the shutter. don't know whether this matters. But you're right. If you're looking at something that's-- we have bright lights in the scene. At a distance, take our false photo. They will all look like this. Or you could put hearts in it, or, like-- AUDIENCE: Right, yeah, I was thinking maybe, that's totally possibly. [LAUGHTER] RAMESH RASKAR: So an interesting art problem is how do you create-- how do we create a mask that visually looks aesthetic but is mathematically also invertible? the depth. When it comes into sharp focus, my edges, that must be the right depth. Unfortunately, it doesn't work out in this case. The main reason is that, because it's coded aperture, no matter where you refocus, it still looks like it has very high frequencies. So you need to find this 7-by-7 pattern or even the previous case, the 52 pattern. Take a Fourier transform to see if it's flat. If it's not flat, you go to the next one. code and do a gradient descent and so on. There's no good solutions for 2D. But for 1D, there are some really good solutions to come up with that. For 2D, for certain dimensions, they call it one more 4 or three more 4. Basically, when you divide by 4, the remainder can be 1 or 3. And there are certain sequences that are beautiful mathematical properties, of which sequences could have broadband properties and which may not. So it turns out you cannot-- there's a little bit of cheating going on here. filter to the beginning of the signal. This particular filter is actually not circular, but it's linear. So when you apply the filter here, when you start applying the filter at the end of the image, you don't go back to the front. It turns out, for circular convolution, the match is very clean and beautiful and smoother course work. Or for linear convolution,. there is no good mechanism. So we came up with our own code called RAT code, R-A-T, which is after three quarters. In astronomy, you have circular convolution because they use either two mirror tiles and one sensor or one mirror tile and two sensors. If you're tiling the mask at aperture, but you are using single-tiled aperture, you'll get horrible frequency response. In this photo, those frequencies are not lost because all the frequencies are preserved. But that's because our eyes are not very good at thinking about what the original image could be, given either this one or the previous one. It's just pure x equals b, x equals a backslash b. Ramesh Raskar: There's just one way of engineering the point spread function, one in motion and one in focus. He says for any continuous code, there is a corresponding binary code that will do an equally good job. RaskAR: Eventually, it's going to have a 2D projection. "It's amazing because motion is time, and the focus is space. They're completely orthogonal. So you can play with it," he says of motion and focus. A lot of it is actually being used in cell phone cameras. The wavefront coding, as they call it, preserves the spatial frequencies. It has the benefit that, no matter which steps you are at, you have the same defocus blur. The disadvantage of coded aperture was that you need to know what the depth was to be able to deblur. But now, because it's independent of depth, you can just apply the same deconvolution and get back a sharper image. has a short focus lens. But within this region, the thickness will be a bonus. So you can either think of it as adding small matchsticks on top of the main lens. And a face mask basically means you are changing the face of incoming light. That's why, as we learned about at the beginning, if you have something very far away, this slows down a little bit. And everything just works out with operations. But [INAUDIBLE] this extra piece of glass, you're saying, I'm going to speed up and slow down. the name. The solution is very similar. I'm sure they're fighting out in court right now. Same solution. Instead of putting this particular guy, that's just going to add some extra glass, but mostly in a minor form. It's just [INAUDIBLE] on that one. So basically the same solution but creating different focal length for different [? partners. ?] AUDIENCE: Yeah. Although you said, I mean, there's this portion there, where if you have another blur [INAudIBLE],, right? RAMESH RASKAR: Right. we're painting the rays, but the colors are, for all practical purposes, that'd be the same. RAMESH RASKAR: The effect is very low, though, remember. So maybe you have a pixel and get blurred by 10 pixels or [INAUDIBLE]. It's not a global effect. And then we also saw this one very early on, where the point spread function-- typically when something goes in and out of focus, it looks like a point. If it goes out offocus other ways, it still lookslike a disc. of this? AUDIENCE: Does [INAUDIBLE]? [LAUGHTER] RAMESH RASKAR: She would have used it by now. The goal here is exactly opposite. If you go slightly out of focus, you get a very different point spread function. So when you're looking with a microscope, depending on what the depth of your tagged particle is, the point spreadfunction will look very different. So you can estimate the depth by looking at the orientation of those two dots. These concepts.these concepts. OK? So let's very briefly look at compressed sensing because it's something you should be familiar with. OK, so here's an idea that received a lot of publicity. It was even "The 10 Emerging Technologies" by a very reputable magazine. It's a very cool idea, by the way. As a scientist, I really like it. But when somebody like Technology Review or Wired Magazine says, Top 50, Top 10, of course, I wish I'm listed among them. But at the same time, it has good side effects. Raskar: If you're on 2 megapixels, then you need to take 2 million [? pics] All right? So the claim this group made at Rice University was that if I wanted a million-pixel image, I don't have to really take a million readings. And that's where the concept of compressive sensing or compressed imaging comes up. You want to take something that is much higher resolution but recover it in a compressed way, where it's taking the picture and compressing the software. can transform the image and measure in [? your ?] measurements. And there are certain cases where it is really true. You have signals that can be compressed very easily. A very classic example is in communication, where, if you have a huge band of frequencies, and software radio-- instead of tuning it with electromagnetics, you just capture the whole signal. And by doing that, they're able to sample this effect of a software radio with a detector that doesn't have to measure 100-megahertz-wide signal. Rohit: Compressive sensing allows you to represent an image with fewer coefficients. Rohit: In general, this scheme doesn't work. But you will continue to see people who come to you and say, you know, I have this magical thing I just heard or compressive image something, and that will just solve a problem. Tom: The secret of success for film, of film photography, is that if somebody had given you this problem before the invention of film, that there is a scene. looks just like a cartoon does-- some whites clothes, some black clothes. And that's why compressive sensing works very well there. Compressive sensing allows you to take less measurements. But the problem is you need to actually have more information about the scene before you take the measurement, which is another measurement. But advantages are, at the time of capture, I just use this random basis or Fourier basis-- I mean, kind of a modified [INAUDIBLE] basis. of captures, that you're limiting yourself in what kind of scenes will be compatible with that capture. So for example, if I just had a scene that's all white, then just one captured would be enough. But that's because you know something about the scene. RAMESH RASKAR: No, the claim is that even if you don't know anything about theScene, you take very few measurements. All you know about the Scene is that once you take its transform, some transform, it's very sparse. which is how to write a paper and wishlist for photography. Which isHow to Write a Paper and Wishlist for Photography: How to Write A Paper and Write A Wishlist For The Camera. For more information on writing a paper or wishlist, go to: http://www.cnn.com/2013/01/30/photography/how-to-write-a-paper-and-wishlist-for-photography-how- to- Write-A-Paper-And-Wishlist.html.

ROUGE-1: 37.00, ROUGE-2: 35.19, ROUGE-L: 35.86
BERTScore: 67.96

==============================================
==================== [84/100] ====================
Summary:
Prof: You know why I am dressed up? When I do this course and when I do the first half of the French course I do a lecture on the bourgeoisie, the middle classes. Middle class was a form of self-identity that was constructed in the way being a worker was constructed, or being a noble. So, as a result, look at this. I wear this about once a year. Unfortunately, I wear it to funerals. The last time I wore it was something Bill Clinton had, some mutual friends. The middle classes started dressing like this in the nineteenth century, dark with a little bit of color. When you see Daumier or you see Delacroix's famous Liberty Leading the People, and you see the bourgeois, there with his top hat, he's dressed in a bourgeois uniform like this. That emerges out of the bourgeois century. The French Revolution, and here's an important point, opened the way by removing legal blocks in very many places to the open talents of each soldier. It was always in the nineteenth century sort of classic to poke fun at bourgeois culture, and in some cases the lack of it. Of course, this is a caricature of middle class self-absorption, of narcissism, of this inveterate cruelty to the classes below them. But there's been an awful lot of good work done on the middle classes. Among them my dear friend Peter Gay, his five volumes of the Bourgeois Century, take on the idea that the middle class are philistine. class lived without passion, and were philistines, and that sort of thing. Aristocrats didn't form voluntary associations. They didn't need to. The middle class formed voluntary associations, and many of these were for extremely charitable purposes, particularly in Britain. The Society for the Protection of Cruelty to Animals, these sorts of organizations really are one of the classic examples of bourgeois voluntary associations doing good things. They get together for social reasons in the coffeehouses of England, and in the clubs, circles you call them in France, and their equivalents. in Germany, and Italy, and Spain. One of the more ludicrous kind of mottos, we call it a devise, a motto, of the Society for the Protection of Cruelty to Animals was in one of the organizations in France. You can see how, in places in which bullfighting over the long run in the nineteenth and twentieth century, such as the very south of France and in Spain. There were always movements to try to protect the bulls, which seems like a reasonable thing to do. church. They found to their horror that it was less than they thought. They also discovered that if everybody who had wanted to go to church had gone to various churches, Anglican, Catholic for the Irish and for a certain minority of British citizens, that they couldn't have accommodated all these people. So there's a massive kind of church building campaign that has its counterpart in almost every country as well. Certainly in France after the Paris Commune of 1871 they start building churches in the working class districts perched on the edge of cities. the 1970s on what they used to call the new urban history, which is counting people up and deciding who might well have considered themselves middle-class. Inevitably I have to talk some about Paris because the work is so rich there. A woman called Adeline Daumard wrote a dissertation that was subsequently published called Les Bourgeois de Paris. She determined that somewhere between 17 and 19 percent of the Parisian population in the first half of the nineteenth century would have been considered bourgeois. you'd find a sizeable middle class, but it would be nothing that you would have if you compared Madrid to Barcelona. Lyon would be a good example. Lyon has the most tightly closed middle class that you can imagine and still is. In Russia, the estimates are about two percent of the population were middle class. And, of course, they are clustered in Moscow and in St. Petersburg, and in Kiev, now Ukraine, always Ukraine but then part of Russia, in the large cities. At the very top there are the great bourgeoisie, the big bourgeoisie. These are people who are big financiers. The nineteenth century bankers will become much more important for perfectly obvious reasons. What also makes them the high bourgeoisie, a small percentage, it doesn't really matter where this line goes, is that they have access to political power. Even if they're in Prussia, a place that's dominated by the nobles who are called the Junkers, they will still have access by virtue of their wealth topolitical power. rule from 1830 to 1848. In the portraits of him, the paintings that he had done to represent who he was are very different than those of the Bourbon kings. The Bourbon kings are all looking like, even the pathetic successors of Louis XIV, they're looking like big people in chateaus. Here we have smaller bankers, not in size but in money, industrialists, merchants, these kinds of people. Lawyers rise up rapidly in popular esteem and usefulness. You find lawyers reaching in there and, slowly, doctors. Notaries know all of the secrets of people with money. Schoolteachers were a way of social mobility for peasant families. The petty bourgeoisie had a self-identity. Can you imagine going to a conference like the World Congress of the Petty Bourgeoisie? They all had their little nametags. It's really pathetic. They do is they start up your body and look at your nameteags, and see if it's worth looking at your face. It was a very pathetic time. good job, even though often they were undereducated and it was kind of hard for them to do that. Schoolteachers you'd find here, and also café or tavern owners, weinstube owners. These are the petty bourgeoisie. When things are going pretty well they do pretty well themselves. But when things aren't going well, they don't do well. That's why they're on the barricades all these times, as you know, in the French Revolution. as a jungle. Then you have to imagine this as a ladder, like this. Social mobility is the goal. You want to have enough money to leave to your 2.2 children. Then to really make this go you'd have to have vines up here like the jungle. And then you would have to grease this pole through bad economic times. Let's say in Europe 1816-17--don't write this down, if you do, you're compulsive--I'm compulsive. If you can't get credit because people withdraw the credit, same thing. Then here you go. Look out. "This is how the people on the bottom part of this ladder viewed the demands of the working class. They want to vote, too. What if they vote and somebody wants to raise your taxes or something like that? Boy, that's scary. But what's down here? This is ordinary people. This is your jungle and you're trying to make it up there to the big time. The chances are that in these bad years you're going to fall down. But yet lots of people get up and the ranks of the middle class increases everywhere" man doing? He's counting his money. That's a very nineteenth-century profession, as it is for every subject. They still had arranged marriages. Love could count for something, but marriages were still essentially, less so for the middle classes than for ordinary people, but economic relationships. They were economic relationships, wrangling over the dowry and that kind of thing. The bourgeoisie didn't kiss and hug a lot. But he's got his hand draped rather daintily on the old guy's arm. He's not about to embrace him and give him a big kiss on each cheek. of thing. Look at our guy on the left. He's working very hard there. He'll work very hard and he's educated. He had probably not secondary education. Most people didn't go to high school, secondary, lycée in France or gymnasium in Germany. It represents this world. By the way, we also know that this takes place in the center of Paris, right behind a big department store, subsequently the Hotel de Ville, but right near the town hall. The more you go up there, you're still within the middle class. You've got an artist up here with not much money, but he still has a little bit of furniture, not much, his nosey neighbor looking at his painting. Then on the top you've got the poorest of them all, besides the cat who's on the roof up there. This is your classic Hamburg financier's apartment. There's more than one room. You'll see in a minute there's even more than two rooms. There are lots of rooms. The middle class arguably helps create the notion of childhood. What the middle class wants, besides social mobility and access to political power, is they want space. Children come into their own in the nineteenth century. To be a middle class person is to want privacy and to be able to look after your own.household. There again you see the trees. We're in the same apartment there. You have real, real copper pots. Back before the Bush dollar, people would buy, bring back from Paris and from Europe these enormously heavy Copper pots. Ordinary people did not cook with things like that. There we go. sure, nobles had children, but it was a different way of bringing up your children. Nobles did not send their children to public schools or even to private schools. They were educated, to some extent at least, by private tutors. Even the notion of the children's hour was inconceivable for the majority of Europeans. The whole salon, the idea of going to see art shows. It really starts in the eighteenth century. The middle class wants to be seen rather like the Dutch middle class that we talked about in the seventeenth century. I was trying to explain how people on the top rung were trying to beat down people at the bottom. I ended up smashing this umbrella, sort of the imaginary of somebody smashing their guitar onstage. But the point is that the umbrellas come with the middle class. They're not these big colored things you have now. It was the idea of protecting that one suit. I'm from Oregon. We didn't carry umbrella, because it rained all the time anyway and I'd just lose it. until you have universal male suffrage, by how much taxes you paid and how much property you own. No longer was it the worth of blood. So, they formed these national guards, particularly after revolutions and after 1848, or after 1830. For a while they go march around. But these are mainly there to protect them against the workers. Should one day all of these people try to rise up, climb up this ladder, you'll be down there to stomp on their fingers or to shoot them down. these bourgeois panicked and start going into a house full of very ordinary people and simply shooting them all. The light lines disappear with Daumier. He did another one of these after a massacre in 1848 in Rouen and it's been lost. We don't have it. The rue Transnonain, where this happened in the center of Paris, simply disappeared. It didn't quite disappear from the collective memory of people thinking about Parisian things. In conclusion, the middle classes extremely vary. They share much. They have a common material culture. They want to vote.

ROUGE-1: 39.61, ROUGE-2: 38.17, ROUGE-L: 37.50
BERTScore: 66.59

==============================================
==================== [85/100] ====================
Summary:
Researchers have confirmed a second smaller space Rock smashed into the sea off the coast of West Africa creating a large crater during the same era. It would have been a catastrophic event and scientists say it would have caused a tsunami at least 800 M High to tear across the Atlantic Ocean. It's exciting that it happens to be potentially close to the same time as the chicku event 66 million years ago known to be the the main cause of the extinction event that killed the dinosaurs and 75% of life on Earth absolutely fascinating. meters of water it hit would have generated a pretty significant tsunami. It may not have been a global event however it wouldn't have been large enough to have say caused a global catastrophe in the way that chicks Loop did. It's worth saying we don't know the exact timing because it hasn't yet been drilled H really interesting. It could have occurred at a similar time and and it's worth say weDon't know exactly when it happened. It was in the early hours of the morning on the morning of September 11, 2001.

ROUGE-1: 60.69, ROUGE-2: 55.65, ROUGE-L: 52.53
BERTScore: 72.05

==============================================
==================== [86/100] ====================
Summary:
In automotive design Dynamics plays a very important part. In Dynamics there two sides to it one is here's the system what is its trajectory going to be in other words how will its various degrees of freedom behave over time. The Yang is you here's a system how do you modify it so that it behaves in a way that that's analysis so that's the first kind of the yin. The yin and the Yang are the same thing, they're just different ways of looking at it. that you want all right and that is called it starts with a C control so control is given a dynamic system how do you put an actuators Motors Rockets Etc so that the trajectory is what you wanted to be. So we're doing Dynamics end of the course we're going to solve the dynamical equations dou4 is controls where you actually try and put in extra things like cruise control so to make the system behave in a way you want it to behave so if you have a rocket open loop right it's called open loop and open loop system is a system that is not where you don't close the loop. AJ: I'm a little woozy today uh I had some serious drugs this morning prescription drugs and the result is that I might start babbling but you won't notice because I Babble anyway right so all right Sam didn't say that I said that I bet but anyway s was very respectful okay so uh in the last class we did uh uh we did a problem essentially the whole Pro class was we looked at you know the skier situation and there's a handout AJ's published right on the web where we do the energy formulation and we solve the problem. class but he also solves the problem the direct way and by coincidence the problem not comes out to be the same is it a coincidence no I'm joking it's not a coincidence the answer is the same both ways. Today we're going to do angular momentums we're still in points Point masses but this is the stepping stone the link to rigid bodies then we'll do a problem we're very problem oriented in this class and then we'reGoing to do yet another problem but we'regoing to do multi- particle. There's no class next Monday and um we posted the solution to that problem from class uh just one last thing I won't have officers today only because you don't want to hear me Babel I'm really sick um but I'm also going to change my officers um several people suggest so the timing isn't right um so we'll talk about the end of class but I I might go to like a Monday off M um like later on a Monday or maybe Wednesday later or something like that okay does it make sense would you prefer it not be midday Wednesday? I'm referring to something with no Dimensions but with a finite Mass you know that someone asked me the other day and I just want to be sure to say this. Let's say that you have a particle Point Mass heading that way some direction and let's define its velocity we'll call it a v p okay so I have um two questions both of which you probably know the answers to the first is what is the angular momentum of that particle just from your memory go ahead say it aha. to define the torque caused by let's assume this particle is moving because there's a force on it I'm going to call this Force F Vector P it's the force in particle Peak right so can anyone Define to me what the torque is going to be just from memory from stuff you've seen before you know it just say it R cross F done right nothing new I'm just writing it there by definition two definitions and now I'm ready to go okay and torque is something I made up too right you guys have an intuitive feeling about it I just made it up I could have called it a sanj but I'mGoing to call it a torque right so now let's examine the relationship between angular momentum and torque yep it's a vector sorry uhuh uhhuh that's good I didn't write it so what else do I need to say about torque by the way I'mgoing to write torque on a particle with a tow because Little T looks like time so I write as a tow torque on an system write to the capital T going forward okay now I missed something there what elseDo I need a frame no and why is that anybody say againe that's right we assume we do it from inertial frame and if you look at the definition the a doesn't show up anywhere right so it's same the torque are torque is a torque all right okay no raised hands so nowlet's try and relate these two things right and the analog is this is like momentum this islike force except this is kind of this. rotational R cross thing right how do you think they're related just now intuition just taking the analog a little further. torque is not always equal to rate of change of angular momentum there's a correction term. There are conditions under which it's a rate of angular rate ofChange of angular. momentum but not always you understand because you know it's an analogy so it all kind of makes sense. The MIT way is to do it exactly right using all the mechanisms we've used and guess what you're going to find a stray correction term which you can only ignore. this this this thing acceleration right so this is going to come out to be M or in fact I can re you know I can just kind of write the terms simply like this R QP cross m a acceleration of Point P right that's that term H that's right we'll write it yeah we'll get there that's exactly right okay exactly you're getting but you're you're exactly right so give me I'll write in The Next Step all right let's write this what do we do with this guy it's an ugly term right what do you do withthis guy here's what we're going to do. be clear this whole thing is this term and this is thisterm now let's let's write this The Next Step what is this what this m a acceleration of P or acceleration of p with respect to a hm H it's the force on particle P right cross product rqp yes now so I'm just going to put a dotted line so you know that that's what this is is this I don't think you'll disagree let me just write some draw some lines I'm trying to save space as I said. The term vanishes in many situations but it's key that you know see for Force f is equal to D by DT of P momentum completely coer Crystal Clear when you come to angular momentum it's say artifice yeah there's this funky term which vanishes let's identify the conditions but you need to know it exists when do you think this vanishes so what is this? The reason this will become important is that when you look at rigid bodies it it actually you will end up doing something so this is a silly term but these are the two conditions yeah Q is fixed uh if Q isfixed right now it just so happens that we often take angular momenta momenta about things like this point of this. door about this point so AQ is z everything's good right or you know we're parallel so it vanishes but you know often it's not parallel so you need to be careful that's the point I want to make okay this term will crop up later uh and we'll we'll it's a pesky term so way account for it or we get rid of it yep can you your absolutely absolutely you could right see the problem here is we're calculating the velocity with respect to reference frame a right but Q is moving withrespect to a so let's say there's a car right. it's not Kosher can't do it if I do I need to include that term right and you you've got a figure that a simple thing like my a robot is a very typical Dynamics application okay common mistake okay now that we've done this let's try and figure out why angular momentum is useful let's solve a problem any questions about this any questions bottom line if you're taking angle momenta about moving points be careful bottom line many conditions it'll be okay we'll elucidate we'll Express we'll we'll nail this conditions. she helps Congressional uh you know Congress analyze things from a physics point of view so you know when Katrina occurred someone asked if it would be possible to change the temperature in the when when a hurricane approaches to dissipate the temperature. She did some analysis and showed that you need something like a nuclear weapon but like you know the most the largest nuclear weapon ever conceived to even you know impact it by like 2% because the energy in a in a hurricane all right I told you I'd Babble all right let's do a problem here's a problem so imagine a um a table right. call this Theta the initial length is L one and the initial velocity is we'll call it a scalar because this is how I'm defining the problem of V1 when we actually solve it we might have to define a vector okay. As the thing's going around this person is going to pull the string down and as it kind of goes around it's going to spiral in and end up it's a new length L2 and the question is what is V2 going to be okay. an acceleration in this direction what else is happening maybe there's a potentially a tangential acceleration kind of an Oiler acceleration as well potentially right kind of thing okay maybe it's a drag slowing down slowing down speeding up we don't know right so in that direction there might be some acceleration okay so there's going to be a you know a net Acceleration kind of this way do you think we do right so what is the force on this in 2D where is the Force coming from on from this is.  linear momentum conservation is a vector equation which is the vector linear momentum is conserved right. If if it's not conserved in One Direction but there's no force in the other it's still conserve in the the other direction understand so there's no force on this guy in this direction so instantaneously the velocity stays the same but then it goes to this new position the force is changed now it's pointing towards its Center again so it's a slightly different tangential direction right so linear momentum is conserved instantaneously but not continuously. P right torque of Point Q about Point p is equal to going to be r p R QP cross F and FP is pointing inwards so what is going to happen to that zero right so there is no torque on this particle at any point in time it's just a very long way to say listen things going in circles and the only force is radial if we take a cross product it's going to vanish which is why this is such a convenient formalism. Works in things where Works in situations where the force or something always points to the center. would have to do one of two things I would have had to either calculate this term or calculate or make you know make my frame attach it to the truck. The whole point is to show you they could be surprises but be careful any questions about this all right snap quiz in the next 3 minutes I want you to calculate for me the final velocity literally 3 minutes because I have toDo the dumbbell problem now you know the irony is this problem you could have done before you took this class the only difference is you know all the ways you can do it wrong. you the initial velocity I'll give you the initial angle of veloc angle of speed Theta dot Theta one dot so I'm solving a slightly different problem here with the ma is but it's the same same problem in terms of math. If I have the length of the cord the angular speed is going to double and the reason it's more interesting it could because when you watch a skater you know do the uh what's what's it called the twirl you know when figure skaters kind of rotate.  angular momentum is a vector out of plane in 2D. Energy is not conserved so where did the energy come come from yeah that's because you were doing work by pulling it right potential energy is constant so the can energies because you can also do this with energy by the way right but for that you need to formulate the problem differently. You need to figure out what the forces what work was done and so on so there half there three three ways to solve this problem right you could have done it using Newton just directly without using angular momentum. and state it very clearly and I said it fast when I talking about energy so great question if the particle has an inward velocity when I look at that V2 State the L2 State then I missed some terms if however I State you which I I did not state I screwed up I made a mistake if I state to you that listen you start at length L1 is just going in a circle right and then I pull it in and thenI bring it to an length L2 and I stop pulling. Two particle masses basically a dumbbell and they're attached rigidly by a massless bar massless and I scoot them across and it's rotating it's hurling through through you know across this rink. I'm going to try and identify understand the behavior in fact I'll make it even more complicated by attaching two rockets get it Rockets right to this thing. The Rockets are designed such that they always Point North all right so they always point in in the horizontal Direction in the on the Whiteboard right. p and particle Q is that reasonable it's perfectly reasonable. What would the kinematic constraint be H yeah it's a they connected by a rigid body so they can do whatever they want as long as the length between the two of them remains constant right by the way. If instead of a rigid bar if I had a string connecting them what would the  constraint be less than equal to to R right but in this case it's  a rigid bar so it's equal to R to R all right. Is there a better coordinate system General a non-standard coordinate system you can think about anybody clao. The center of the bar as the kind of the XY location of the dumbbell and then we use the angle of the Dumbbell. How many non-standard dimens do I have non- Standard coordinates do I need to consider a kinematic constraint no because it's implicit in that assumption. The same mass doesn't make any much it doesn't makes a difference the problem just makes our lives easier later yep claudo if they had been different would you have placed them the point in the center of mass for reasons that are not clear yet. different you'll find out later I would have picked the center of mass which would not have been the geometric Center Center okay but you don't know why so I can't tell you why. I just did some slate of hand and I made the masses equal all right a lot of terms cancel out that's the only difference I could still have by the way I could have picked a point on that line anywhere there would still be reasonable generaliz coordinates there wouldStill be three just the math is easier that's it okay. then I'll redraw it there but if I had drawn the dumbbells like this and if I did this right then I would have said this is B1 and this isB2 like we usually do right. Then that's how we're going to do find this R OC which is some component this way and an angle that we know the configuration of this dumbbell at any point in time. Then we'll solve the differential equations to solve it right and you'll see that they come out to be very beautiful. from a free body diagram point of view I'm not going to do it right now but very simply there are each bar applies a force on the part on the particle. I want to figure out the accelerations of the particles I can actually just use the ultra super cool magic formula here directly I need you need have done that but we can do it brute force and just figure it out so um actually let's use the um the uh super cool formula and what we will get is the acceleration of particle p is equal to. stick if I have something at the end of a stick can I apply like a you know does it only have to be a force inwards right. Next week we'll pick up on this and essentially what we'll do is I'll do the three body diagram. Define angular acceleration and moment of inertia and a more General sense okay so let's stop here because we are over time. CL you I mean you're getting that's right so there are a couple of ways to interpret this okay it's a massless rod and I'm invoking the strong form of Newton's third law.

ROUGE-1: 47.00, ROUGE-2: 45.73, ROUGE-L: 45.49
BERTScore: 64.83

==============================================
==================== [87/100] ====================
Summary:
In this module, I'm going to briefly introduce the idea of differentiable programming. Differentiable programming is closely related to deep learning. I've adopted the former term as an attempt to be more precise in terms of highlighting the mechanics of writing models as you would code. There's really enough to say here, to fill up an entire course at least. So I'll try to keep things pretty high level but I will try to highlight the power of composition. So let's begin with our familiar example, the three layer neural network. example, the ReLU or logistic. Now I have a vector and now I can do the same thing again. I apply a matrix, add a bias term, apply an activation function. Apply a matrix which happens to be a vector. And I get a score which then I can happily drive regression or take the sign to drive classification. So what I want to do now is to factor out this kind of complex looking expression into a reusable component which I'm going to call FeedForward. But we're going to see a lot of these box diagrams which are going to represent functions that we can reuse. you want to do image classification. We need some way of representing images. The FeedForward function that we just introduced, takes a vector as input and we can represent an image as a long vector by, for example, adding all the rows. But then we would have this huge matrix that we would need to be able to transform this vector resulting in a lot of parameters which may make life difficult. To fix this problem, we introduce convolutional neural networks which is a refinement of a fully connected neural network. first is Conv. Conv takes an image and the image is going to be represented as a volume which is a collection of matrices, one for each channel, red, green, blue. Each matrix has the same dimensionality as the image, height by width. The way that Conv is. going to compute this volume is via a sequence of filters, and intuitively. what it's going to do is try to detect local patterns with [AUDIO OUT] So here is one filter and how it works is I'm going to slide this filter across the image. going to slide a little max operation over every 2x2 or 3x3 region. So the max over these four numbers is going to be used to build this [INAUDIBLE] and so on. That's all I'm going to say about MaxPool. If you want to go into the details, you can check out this demo or you can learn more in 231. But again, I want to highlight that there's these two modules. One for detecting patterns and one for aggregating. And with these two functions along with FeedForward, now we can define AlexNet. In NLP, words are discrete objects and neural networks speak vectors. So whenever you're doing NLP with neural nets, you first have to embed words, or more generally, tokens. We're going to define an EmbedToken function that takes a word or a token x and maps it into a vector. And all this function is going to do is it's going to look up vector in a dictionary that has a static set of vectors associated with particular tokens. So this representation of the sentence is not going to be a particularly sophisticated one. is something that has an interface but not an implementation. So a SequenceModel is going to be something that takes a sequence of input vectors and produces a corresponding sequence of output vectors. I'm going to talk about two implementations of the sequence models. One is recurrent neural networks and one is transformers. So an RNN, or a recurrent neural network, can be thought of as reading a sentence left to right. So the intuition again is reading left-to-right, updating the hidden state as you go along. Collapse takes a sequence of vectors and returns a single vector. There's three common things you can do. If you're doing text classification, you probably want to pick the average to not privilege any individual word. But as we'll see later if you're trying to do language modeling, you want to take the last. These types of functions where the input and output have the same type signature are really handy because then you can compose them with each other and get multiple steps of computation. before actually defining it. So the core part of a transformer is the attention mechanism. The attention mechanism takes in a collection of input vectors and a query vector and it outputs a single vector. mathematically what this is doing is you start with the query vector. I'm going to multiply a matrix to reduce its dimensionality, in this case from 6 to 3. And now I can take the dot product between these x's and y's. So that's going to give me a four-dimensional vector of dot products. In contrast with the RNN, you have representations that have to kind of proceed step by step. And the number of steps is the length of a sequence which causes these long chains which prevents kind of fast propagation. So that's an attention mechanism. You can think about this as a sequence model that just takes input sequence and contextualizes the input vectors into output vectors. There's two other pieces I need to talk about before I can fully define the transformer. Layer normalization and residual connections. These are really kind of technical devices to make the final neural network easier to train. was this complicated thing that I mentioned at the beginning. So BERT is this large unsupervised pretrained model which came out in 2018 which has really kind of transformed NLP. Before there were a lot of specialized architectures for different tasks, but BERT was a single model architecture that worked well across the many tasks. So this is the way it works for question answering. You take the question, you concatenate it with the paragraph, that gives you just a sequence of tokens. We can use language models and we can build on top of them to create what is known as a sequence-to-sequence model. This is perhaps one of my kind of favorite interfaces because it's so versatile. So this is by and large how a lot of the state of the art methods for, for example, machine translation works. We're generating a translated sentence, given the input sentence or a document summarization or semantic parsing. Each of these sequence can be framed as sequence- to-sequence tasks based on, usually these days, basically BERT and Transformers. encourage you to consult the original source if you want kind of the actual, the full gory details. Another thing I haven't talked about is learning any of these models. It's going to be using some variant of stochastic gradient descent, but there's often various tricks that are needed to get it to work. But maybe the final thing I'll leave you with is the idea that all of differentiable programming is built out of modules. Even if you kind of don't understand or I didn't explain the details, I think it's really important to pay attention to the type signature of these functions.

ROUGE-1: 39.58, ROUGE-2: 38.40, ROUGE-L: 38.70
BERTScore: 76.02

==============================================
==================== [88/100] ====================
Summary:
Professor Amy Hungerford: Today it is my very great privilege and pleasure to introduce Andrew Goldstone, a TF in this course. Andrew is a fourth-year student in the Ph.D. program in English, and he is writing a dissertation on the autonomy of the work of art in modernism. In preparation for that, for next week I'd like you to finish the novel and then read his essay, "On a Novel Entitled Lolita" It should be bound at the back of your book. amidst the many layers, whether he crosses them or confuses them. I'm going to bracket the ethical question, leave that for Monday's lecture, and the way I want to approach this question of the style in the novel is by placing Nabokov in the context of literary modernism. So, this is a spoof of a poem by T.S. Eliot which I've given you a piece of on your handout, so let's look at that for a second. "Modernism" is the art and literature of the early twentieth century, especially the "high art" In English it begins with the late novels of Henry James around 1900, in poetry with Eliot and with Ezra Pound. In prose its main exemplars in English would be James Joyce, Virginia Woolf. Nabokov will say in that afterword you're going to read, "the novel has as its only purpose to afford aesthetic bliss." So, the parody is of something very close to home. sense that civilization itself is being overturned. The idea that culture itself is the saving, most important activity that people can engage in. A rejection of convention, especially sexual convention, sexual morality, and that's the obvious connection to this book. An idea that the artist is a kind of technician, someone whose values are craft, form and style rather than message, personal expression or wisdom of any kind. And then, this anticipates my last points: Modernism is self-consciously international. For Nabokov, the highest value is originality. He says this in his last Russian novel, The Gift. "Any genuinely new trend in art is a knight's move, a change of shadows, a shift that displaces the mirror," he says. "In chess the knight doesn't move in a straight line. Unlike any other piece, it skips over pieces in the way" The strategy of the knight'smove is to frustrate your expectations, to leap over the apparently important events into something else. The danger for Nabokov is that he will fall too in love with something too like himself. He has to hold off this possibility of being too attracted to these male predecessors who are too similar to him. To think about the word "queer," the treatment of Gaston Godin, that funny French character in Beardsley, to think about Humbert's constant protestations that he's attractive to all women, about his supposed virility. And it should just make you wonder whether pedophilia is in itself a kind of knight's move from homosexuality. Nabokov's relationship to this modernist past is not just the burlesque that he visits on Eliot. An element of admiration is also present, and that's really part of his relationship to Joyce. I'm just going to name for you four features of Joyce's style that are important to Nabokov: stylistic virtuosity, the ability to imitate any style; at the same time, a scrupulous attention to the banality of everyday life and all its detail. Third characteristic, the constant use of a superimposed structure. in the collected poems of Lord Byron. When he had written this title and drawn an ornamental line underneath, he fell into a daydream and began to draw diagrams on the cover of the book. The version of this that comes up in the novel is in the midst of Humbert's diary. And I've given you a piece of that diary to look at on your own on the handout. But this is the moment that directly alludes to Portrait, and it's really very important for understanding Nabokov's technique. MaryBuck, Danielâ€¦ [and so on; I'll come back to this list, actually; just skip to the bottom on page 52] Talbot, EdgarTalbot, EdwinWayne, Lull,--[a lull in the book, right?] Williams, Ralph Windmuller, Louise. So strange and sweet was it to discover this Haze Dolores: she, in its special bower of names with its bodyguard of roses, a fairy princess between her two maids of honor. The artificial has taken the place of the real here, and this novel really reminds you of that all the time. There is a kind of short circuit between the Joycean idea of taking ordinary life and transforming it into an aesthetic order. In other words, chance is already fated. The thing that stands for randomness in this book, the thing that looks like ordinary detail, has already been arranged to give you artistic pleasure. That's why Humbert can be instantly delighted in the list of names. Nabokov takes a narrative of real events and twists it into something that makes a kind of sense, taking fate and making it McFate. Charlotte Haze dies as if by a total accident, but we're aware that the accident is so perfect that it was arranged. In one of those parentheses--"the magician showing the object he is about to palm"-- the ordinary event which is really trickery. This kind of transformation of arbitrary, real fated events into conspicuously artificial tricks is a response in particular to exile. foreign country, lives in a kind of denaturalized world, a world where, instead of everything making instant sense everything has to be decoded. In that afterword to this book, Nabokov says he had to invent America. That's because he didn't know it already; it wasn't given to him. Now, in a way this is a terrible state, a state of discontinuity with the world you exist in. But it has a payoff, kind of, a payoff which is the possibility precisely of inventing. This connection, to remember that the knight's move as a way of avoiding obstacles, in particular, keeps skipping over forms of violence. Nabokov will say that his private tragedy is that, let's see: I had to abandon my natural idiom, my untrammeled, rich, and infinitely docile Russian tongue for a second-rate brand of English devoid of any of those apparatuses. And you might think about that homophobic attitude to a Proustian past. the fear that it's too like what he wants to do. But the main point here to think about is that feeling of damage. On page 152--oh, and by the way, this book was written on road trips. Nabokov's wife, Vera, drove him on thousands of miles of trips around the country while he was writing this novel and hunting butterflies, so think about that--but here is 152, evocation of the landscape. By a paradox of pictorial thought, the average lowland North American countryside had at first seemed to me something I accepted. American landscape is already a work of art, already part of a European memory. "Inutile loveliness" is kind of the key word of Nabokov's technique. So, a European artist actually appears again there, with Claude Lorrain. But, I don't want you to think that this just means everything's okay. Of course, everything is not okay. Even Humbert will tell us so. Just a few pages later, on page 175, he talks about his Humbert Humbert: "We had been everywhere. We had really seen nothing" "I catch myself thinking today that our long journey had only defiled with a sinuous trail of slime the lovely, trustful, dreamy, enormous country," he writes. "We have to pair that with that other evocation of the landscape to see this alternate idea," he says. "This distanced criss-crossing of the landscapes could be damaging," he adds. "Think of those other violent knight's moves, like skipping past the mother's death" in a much more ambivalent position, someone who's trying to become an American writer, as Nabokov says he's doing. He always finds that English is only a kind of second best. He translated Lolita back in to Russian later on, and he added a second afterword where he said this: That wondrous Russian tongue that, it seemed to me, was waiting for me somewhere, was flowering like a faithful springtime behind a tightly locked gate. And there is nothing behind the gate but charred stumps and a hopeless autumnal distance. element of violence that keeps coming back, the trail of slime across this dream of transforming reality, in this Joycean way, into something saved. Could it be that all of this modernist technique that Humbert succeeds in putting to his own ends is not an unambiguous good, but a record of a kind of damage? On Monday you're going to hear about this novel's confrontation with the idea that art could be saving, but here I think is a hint that it's something that the novel simply laughs at hollowly.

ROUGE-1: 37.84, ROUGE-2: 36.29, ROUGE-L: 35.94
BERTScore: 68.16

==============================================
==================== [89/100] ====================
Summary:
NORVIN RICHARDS: Today is phonetics, which means that today we begin making funny sounds at each other. So everybody limber up your vocal tracts. Let's see. I'm trying to remember if there's anything that I ought to announce. You remember, maybe, that problem set 1, which confusingly is your second problem set, is due on Thursday. Normally, it would be due on Tuesday. But because I am technologically challenged, it's due onThursday. I just figured out how to get the projector to project over there. Linguists have a system for writing sounds down so that we'll all know what kind of sound we're talking about. A lot of the symbols of the International Phonetic Alphabet resemble letters of the English alphabet. The symbol for the sound at the beginning of "paint" is the letter p. And so that's a symbol of theInternational Phonetics Alphabet. As we go along, we will be seeing weirder and weirlier symbols from the InternationalPhoneticphabet. like "thistle" and "this," where you're sticking your tongue between your front teeth and making air flow out. English doesn't spell these differently, at least not reliably, right? So we spell both of these with a "th" That's one of the reasons the International Phonetic Alphabet is there. There are two different IPA symbols for them. The Greek letter theta is used for the sound at the beginning of 'thistle' And that second letter is an old English letter, sometimes called 'edh,' and it stands for 'this' "y" sound at the beginning of "year," yeah? And here's the first IPA symbol that is deliberately designed to confuse you. The IPA symbol for that sound, the "y" at the start of " year," is a "j" This is because the IPA was not invented exclusively by speakers of English, right? So it was invented also by speakers. of languages like German, in which they use this letter for this sound. "Ja," for example, the German word for "yes," spelled J-A, yeah? English doesn't make a huge amount of use of the glottal stop. But it's what shows up at the beginnings of words like "uh-uh" "Uh-uh," meaning "no," right? Or "oh, dear" "Ch" sound at the beginning of a word like "church" is a dynamic sound, right? Ch-- I think your tongue is in motion as you are making that sound,right? So it makes one-- it completely stops the flow of air, and then it gradually peels back. in mind? STUDENT: No. NORVIN RICHARDS: Oh, OK. We'll get to "r," eventually. But actually, people discovered at a certain point-- so people investigate this kind of thing in all kinds of ways. These days, people do a lot of MRIs. I'm going to put on the website a couple of websites that have charts of all of the sounds that we're going to talk about plus many more together with MRIs of the insides of people's mouths making these sounds. "Whisper to dorm" is a controlled experiment to see if you can hear the difference between "r" and "v" "T" at the end of "cat" is voiced or voiceless, and the "g" in "dog" is voicing. "Z" is voiceless and "s" isvoiceless, so it's a distinction in voicing. If you whisper "safe" or "save," you have the feeling that you're hearing the difference. dorm mate, (WHISPERING) "safe." (SPEAKING NORMALLY) And then find out what they think you said. If we go back and forth between "f" and "v," which of them is voiced? The "v" is voiced. OK. Now do it again, but whisper-- f, v, f,. v,f, v. Does anybody feel a difference between " f" and 'v"? Not here, right? Yeah? STUDENT: I guess the 'v' is more-- there's more air. what it means is that your vocal cords are vibrating. But I think maybe what we're learning is that you do some other things, too, to optimize the flow of air so that you will get a good vibration going. There's experimental work on this. This is the kind of thing people try to figure out. OK. So you have voiced sounds and you have voiceless sounds. So "s" and "z" are voiced. And "z," "d," and "t" are voiceless. Polish has a rule that changes "g" to "k" at the ends of words. Voiced "b" becomes voiceless at the end of words in Polish. Some nouns that end in "p" still end in 'p' when you add the 'e' suffix, like corpse. But some change the 'p" to a 'b' and the 'g' to 'k' Joseph: There's a reason that I started with sounds like "s" and 's' "z," and "f" and "v" because you can go s, z, s, Z for as long as you have, breath right? Whereas buh-- there's a limit to how long you can "b," yeah? We just said the way voicing works is that you've got air flowing across your vocal folds and making them vibrate, right? And for a "z," you can see how that would work. So the air just flows. For a " b," well, the air only has so far to go, yeah? That's one reason you can't keep a "b" going for very long. OK. Now we need to talk about another dimension for categorizing sounds, which is called manner of articulation. about any of this? Is anybody looking at this and saying, whoa, this table has grown out of my ability to keep up? Yeah? STUDENT: Question about the [INAUDIBLE].. NORVIN RICHARDS: Yeah. English doesn't allow words to begin with velar nasals. We don't have any words that start with a sound that's at the end of words like "song" or "year" We haven't yet gotten to the kind of sound that that "j"- the sound of the beginning of "year." English doesn't have a bilabial fricative, but there are languages that do. In Japanese, you must learn to pronounce the "f" bilabially rather than labiodentally. There are dialects of Spanish where you have a "g" between vowels, in words like "agua," in words such as "abuela" In Russian, this sound shows up in the names of authors like Chekhov, that kh has a velar fricatives. The way nasal stops work is you're stopping the flow of air somewhere in your vocal tract, but you're allowing the air to flow through your nasal cavity. You can have an alveolar nasal, right? "n," or a velar nasal, "ng" What would a glottal nasal sound like? Trick question. You would need surgery. So you would need, again, as I say, probably there are unethical surgeons who would modify you so that you could makeglottal nasals. English has interdental fricatives and alveolar stops, "t" and "d" There are languages out there that have what are called dental stops. Part of your job, if you're learning Tagalog, for example, is to learn to make dental 't's instead of alveolars. There's all this work on what people do to compensate for various kinds of obstructions in the vocal tract. And on the website, there will be a link to charts that will have more official charts by the IPA. Uvulars are kind of like "k" except more so. Pharyngeals involve constriction near the pharyngeal wall. Arabic has these. The Berber languages have these. Appants are not stops, and they're not nasals. They involve gesturing towards each other in some part of your vocal tract, not enough to make enough to cause any turbulence in the airflow. And for some reason, the dental stops are still red. I don't know why. "w," let's say, in the middle of a word like "away," that's not a stop. "y" sound at the beginning of "year" or "yard," and "l" and the "r" are all approximants, yeah. They are sometimes divided into glides and liquids. And I'm hoping that nobody will ask me how you know whether something is a glide or a liquid. But that's the prima facie reason for distinguishing them because there are rules for the distribution of sounds for which it's useful to have that distinction. distinction as long as it turns out to be useful for explaining stuff. Yeah? Good, all right. So those are glides and liquids, OK. And then I recall we were asking about this before. Sounds like chuh and juh-- I think I said you could think of chuh as a stop, a "t" followed by a fricative, shuh, or juh. There's a little bit of a debate about whether what I just said is the right way to think about this or not. English has a very large number of vowels and a not-very-good system for writing them. This is one of the things that makes English spelling so difficult that we can actually have competitions where you watch people spell. English doesn't have those. There are languages out there that have labiodental glides. Similarly, there are velar glides, where your tongue is just vaguely gesturing in the direction of your velum. I like the IPA symbol for the velar glide. It looks like something out of Tolkien. is pronounced exactly the way it's spelled. We don't do that in English. So here are two vowels. And those are their IPA symbols. The vowel in "bead" and the vowels in "bad"-- and now so everybody joined me in transitioning from one of those vowels to the other. Go ee-ah, eo-ah,. ee, ooh. Feel your tongue moving back and forth. Ignore your lips, right? And think about your tongue. English only has five vowels, but Latin had 12, 14. English doesn't have words that end in monosyllables that are either front or high. "ooh" is a high back rounded tense vowel. "oh" and "uh" are lax vowels that relax the tongue. "schwa" is the first vowel in "machine" It's not higher or lower than "hoed" or "ah," but it's not front or low, either. Student: "Sue says he's a bad egg." Student: "Top chopstick shops stock top chopsticks" Student: [INAUDIBLE] Student: "[INAUDITED] Top chopsticks. Top chopstick. shops stockTop chopsticks." Got that from a book of tongue twisters. Student: ["INAUDible] Top Chopstick. Shops stock top Chopsticks." Student. "Top Chopstick shops. stock top. chopsticks". Student: "Top chop stick shops stock. top chop sticks." Student.: " top chop stick shop stock top chops" Student."Top Chop Stick Shop Stock Top Chopsticks"

ROUGE-1: 25.79, ROUGE-2: 23.81, ROUGE-L: 23.72
BERTScore: 60.32

==============================================
==================== [90/100] ====================
Summary:
The probability of heads is p. It would be biased in favor of heads if p is greater than 1/2. And we want to know how many heads are expected. This is a basic question that will come up again and again when we look at random variables and probability theory. And our strategy is going to be to use the binomial theorem, and then the trick of differentiating it isgoing to wind up giving us the expected number of heads in n coin flips. It starts to look like something a little bit familiar. us a closed formula for this expression for the expectation of the binomial random variable. The binomial theorem says that the nth power of x plus y is the sum all from k equals 0 to n of n of k times n choose k, x to the k, y to the n minus k. So what I'm going to do is replace p and q-- replace x and y in this general formula. And what happens? So I just plug in the p andq. Now, the left hand side is going to become n.

ROUGE-1: 38.89, ROUGE-2: 36.72, ROUGE-L: 34.80
BERTScore: 78.03

==============================================
==================== [91/100] ====================
Summary:
Aristotle was born 384,15 years after the trial of Socrates. He was sent by his father to go to college. Unlike most of you, Aristotle did not spend four years at the Platonic Academy. He remained attached to it for the next 20, until the death of Plato. Unlike his intellectual godfather, Socrates, who wrote nothing but conversed endlessly, Aristotle wrote disciplined and thematic treatises on virtually every topic, from biology to ethics to metaphysics to literary criticism and politics. Aristotle appears from the beginning to look more like what we would think of as a political scientist. He collected constitutions, 158 of them in all, from throughout the ancient world. He was the first to give some kind of conceptual rigor to the vocabulary of political life. Aristotle lived at the virtual cusp of the world of the autonomous city-state of the Greek polis, he says. He is silent because of his foreignness to Athens, and his reluctance to speak to the issues of his time. The authority of Aristotle no longer has quite the power that it once did. The attack began not all that long ago, really only as late as the seventeenth century. Who was this strange and elusive man whose writings seem to have been enlisted both for the support of monarchy and for republics? Who was these man and how did he come to be so controversial? We will read later this semester, named Thomas Hobbes, was one who led the pack, led the charge against Aristotle. Aristotle says man is, by nature, the political animal. He says participation in the life of the city is necessary for the achievement of human excellence. A person who is without a city, he says, who is apolis--without a city--must either be a beast or a god. The city is natural in that it allows human beings to achieve and perfect what he calls their telos, that is to say their end, their purpose. But there is a second sense for him, in some ways, in which he says the polis is by nature. condensed in very deep ways, carry a great deal of freight. There's a lot in there that needs to be unpacked. We need to avoid the temptation, in many ways understandable as it might be, to airbrush or sanitize Aristotle, to make him seem more politically correct for modern readers. The question is what did Aristotle mean by slavery? Who or what did he think was the slave by nature? Until we understand what he meant, we have no reason to either accept or reject his argument. the preserve of the few, of a minority capable of sharing in the administration of justice and in the offices of a city. It seems to be a very elite teaching. Would you agree? Unappealing to us, perhaps, for that reason, very contrary to our intuitions and the way we have been brought up. But before we dismiss Aristotle's account as insufferably inegalitarian and elitist, we have to ask a difficult question. What else is Yale, but an elite institution intended to educate, morally and intellectually, potential members of a leadership class?

ROUGE-1: 18.77, ROUGE-2: 17.72, ROUGE-L: 17.22
BERTScore: 58.24

==============================================
==================== [92/100] ====================
Summary:
Mathematically, a consumer is trying to maximize his utility. And this utility maximization has to be done with respect to some constraint and the constraint the budget constraint we take P 1 x 1; P 2 x 2 should be less than or equal to I. In real life, it is possible that a person derives some satisfaction from having some money left in his pocket, but the way this problem has been framed here the person’s satisfaction depends only on his level of consumption of good 1, and good 2. bundle, this is the bundle; let us say x star and here is let us call it also x star in the old problem. What we have done here we have taken the indifference map and then we have took the budget constraint. We have figured out that x does not or x naught 0 x star 0 is the optimal bundle. We take any bundle here the expenditure is going to be the same in both of these cases, that is what it represents. If we solve these two, we reach to the same consumption bundle; it is clear. I is P 1 x 1 plus P 2 x 2. What is e? E is nothing. We are checking we have set up the problem such that this I is equal to this u naught and what we have learned is that x 1 m P 1, P 2 I is. equal to x 1 h P 1 P 2 uNaught. This is an identity. not just equal to. this is always true. I can write it further if you pay attention to this that x1 m P1 comma P 2 and I is e of P 1 comma P2.

ROUGE-1: 25.58, ROUGE-2: 24.44, ROUGE-L: 25.58
BERTScore: 67.79

==============================================
==================== [93/100] ====================
Summary:
MIT OpenCourseWare offers high-quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourse Ware at ocw.mit.edu.The following content is provided under a Creative Commons license. Your support will help MIT Open courseWare continue to offer high- quality educational resources. The i3 is an efficiency and urban-optimized transport vehicle made by BMW. It's an all-electric, the fact that it's fundamentally an electric vehicle is key to the i3. like the smart car. And so architecturally, distinguishing feature is definitely the electric drive. So I think it's good, but I think you're just missing a little bit on the technology there. What about i3 and EPFL? Anybody do the i3? Nobody. Anybody else here? Yeah, Veronica. AUDIENCE: Thank you. OLIVIER DE WECK: OK. There's a lot there. I would throw a question. A concept you defined could almost apply to a Tramway as well. If this was like a streetcar, don't you think it would apply to that as well? bank, a cafeteria, student services. But you could encompass it in a meeting area. You meet and you do some stuff like eating, going to the bank. In that sense, it's pretty similar. But I think the Rolex Center is such an iconic building that it also serve a kind of a prestige function, to put the institution on the map in terms of it's a statement. It's not just a utilitarian building. Whereas, I would argue our MIT student center, it has very similar functions to theRolex Center. It doesn't have that wow factor. is the beneficiary? That's a stakeholder. The stakeholder has needs. And then this is a funny thing here. The needs have these little bumps. This is meant to indicate a cloud. So this means that the needs are somewhat vaporous. They're not very well defined. And so you interpret and incorporate some of the needs into goals, which become requirements. The goals then are an instrument of the primary delivery value delivering process, which is your value proposition. To then actually deliver that value you need to design the product. EPFL's Olivier De WECK explains how to reduce the spoilage rate of food. He says there are a number of ways to do it, including irradiating, drying, chilling and preserving. He also explains how bears use fat to transform it into fat and store it inside their bodies. The full interview is available on CNN.com and on the CNN iReport app for iOS and Android. For the full interview, visit CNN.co.uk or the CNN YouTube channel. For more, go to www.cnn.com/news. a very different way, but it's essentially the same function. So the chilling part is not enough. And then you say, well, we need a chiller. And it's the combination of this specific way you're going to operate the system. The element of form and then the specialized element ofform, in this case the cooler, that combination is what we call concept. Once we have that, we can start managing complexity, decomposing function and form, so our system operating process gets decomposed into the primary supporting processes. external heat load, ambient light, and the operator. What's surprising here is when you map the two, there's a surprising amount of complexity. So there's an attribute of the ice, which is essentially its quantity, but also it's form that will influence the-- but that's the heat exchanger function. The powering function is pretty clear. That's essentially the energy storage right there. And then the third one is regulation. How does the ice provide a thermal regulation in the cooler? Physics 101. Celsius. As long as you have ice left, this is the phase transformation, you're at that point. As soon as the ice is all melting, the temperature will rise. The phase transformation of the ice from solid to liquid is what, in fact, is the regulation mechanism inside the cooler. So even though you think of a cooler as being something super simple and trivial, once you start listing its internal functions and how the top, the bottom the ice itself, how they interact and support those functions, it's pretty complex. Swiss refrigerators are much smaller than those in the U.S. That's a big difference between the US and Switzerland. In the refrigerator, each of these elements supports, essentially, one of the primary sub-functions. So the form function mapping in the refrigerator is actually much simpler. It's a much simplerform function mapping than the cooler. But the fact that it has a bottom and a top and it's hinged and it uses this phase transition as the regulation mechanism, that's conceptual design. a refrigerator is much more complex. How can that be? Well, the real complexity comes in when you look at the form form mapping. So this is then the decomposition of the refrigerator in terms of all the elements of form and then how they relate to each other. And I'm not showing here all the sub-processes, but you can see that the mapping and the relationships are more complex than in the case of the cooler. That's concept generation, finding systems that do the right thing. And then once you have several concepts, you've got to select among them, which we'll talk about next week. System architecture requires consideration of both function and form related through concept. It's about starting with the operand. What is the thing that the beneficiary, the stakeholder cares about, and how do we transform that? Concept then elaborate these into architectures that have form function and structural complexity. And then the goodness of an architecture is really a pretty complex concept where we have multiple objectives to satisfy, including performance, resource utilization, cost, operability, safety, capacity, and so forth. And we'll defer that to next week. and then defining those high-level requirements. Level 0, level 1 requirements, but then you get stuck. You get stuck because you have to make some decisions before you can go to lower level requirements definition. And that's what's known here as functional and logical decomposition. Once you've decided on a composition and you can carry several compositions with you for a while, then you can do the lower-level trade studies. And then do functional and performance analysis to see whether you have enough detail. and the logical decomposition work products, which are essentially lower-level definitions of what these subsystems look like. And then you can go off and do the detailed design and then the testing verification and so forth. So let me talk about methods and tools for concept generation. This is another really fun thing we do in the system design and management program, which is a full-year program, is the creativity workshop. So what are different ways of stimulating or organizing creativity? And what I'm showing you here is-- that's essentially a mind map of how to think about the creativity space. There's an ideal group size, and it says 5 to 10 here, but I should probably revise this to be-- what do you think? 7 plus minus 2. If you try to do brainstorming session with 30 people in the room, it's not going to be that productive. What's important is that you have a clear idea of why you're doing the brainstorming sessions. There's this killer sentences you should never say during a brainstorming. Some of these are pretty funny. And then what do we do with the results. How do you actually then take the brainstormed results and use them for further refining. How to Think Like Leonardo, Seven Steps to Genius. The seven da Vincian principles of creativity in Italian. Avoid the killer phrases. Creativity killer sentences. This will never work. We don't even need to talk about this. Everybody does it this way. I've already studied this problem for years. Don't worry, I know I'm right. How long have you been with this company? Anyway, so that's the idea. All right Leonardo. Who's been to Italy or tour in France, or who's seen one of the exhibits know where his notebooks are on display? very quickly. So curiosita, lifelong quest for learning. Dimostratzione, testing your knowledge through experience, trying things out. Sensazione, continual refinement of the senses. Mastering ambiguity, paradox, uncertainty. Arte/Scienza is the whole brain thinking, left-right brain. Corporalita, balance of body and mind, so a healthy mind and a healthy body. Connessione is interesting. That gets close to system architecture, which is the appreciation of patterns, relationships, connections, and systems. So the idea is that, this from Leonardo, his work, his way of thinking, these seven principles have been extracted. on this morphological matrix. And I find this to be very, very helpful. When the table gets too big, very quickly because of this being a product, this can really explode on you. And the big challenge with this, of course, is if you have many factors, you could generate many infeasible architectures. So the question then is, how do you prevent that, and that's where so-called architecture enumeration comes in. But the idea is that through creativity, expert knowledge, and analysis you're going to define your components. like 12 different tail geometries here. But at that higher abstraction layer, it's just a single tail. So how do you combine these using compositional rules? That's architecture enumeration. And we'll post some information on this if you want to try this out for your concepts. So let me summarize. So system architecture is definitely very abstract, but it's also, potentially, the most influential activity that we do in system architecting. The concept is mapping function to form. conceptual design, don't do all the details. We just go down two levels of abstraction. And then the really cool part, the exciting part in concept generation is the one that it's really a creative activity. And when you look at the set of creativity techniques, you can think of group dynamics like the brainstorming. That's used very heavily, but you have to do it the right way. If you organize a brainstorming session, and there's some wiggle room, but if you violate some fundamental principles of brainstorming you're not going to get the full benefit.

ROUGE-1: 40.74, ROUGE-2: 38.42, ROUGE-L: 38.48
BERTScore: 69.92

==============================================
==================== [94/100] ====================
Summary:
then we are going to continue with the second part of the lecture today which focuses on the problem what actually happens if the gaussian assumption that i have about my constraints doesn't hold. You will get so called outlier observation which is far away from what the real observation would be and as you will see in some small examples having this outliers in your optimization problem is something which hurts dramatically which actually screw up your solution. Already a few outliers can lead to a environment model which is completely unusable for doing any navigation task. a gaussian the problem is if you have outliers so let's say i measure always. one meter one meter 10 99 centimeters one meters one meter now an outlier 100 meters that's actually something which screws up my solution dramatically. they get a completely wrong estimate on what the environment looks like. If we would have the possibility to integrate a multi-modal distribution here that would actually be a nice beneficiary and what i want to talk about here today is how to integrate first multimodal distributions and second having the ability to deal with outliers. If you have structures in the environment and there's a lot of clutter in the scene the clutter even if it has a repetitive pattern may lead to a multimodal belief about what the relative transformation between two poses let's say. Other things is gps can even be problematic if you have this called gps multi-pass problems you have reflections of the gps signal based on larger buildings. You may get beliefs or you may get outlier measurements and the question is how can we actually take that into account. a corridor through what can be actually sit here or here and his local perception will actually match quite well so you may get one of those multimodal beliefs where you say i mean the mode is roughly where the mean of that gaussian would be if i would approximate this function by a gaussian but maybe i'm ending up here in another mode. Having the ability to take into account multi-modal beliefs is actually helpful there's another real world example so this is the intel research lab data set that you have also experienced. over here so this is a single constraint you can already see that you don't have a straight wall over here anymore so it's kind of bended a little bit like this due to the single constraint which obviously has a really really large error so the least square error minimization at the error is squared error term tries actually to minimize that if we add i think whatever and two three four five i think there were 10 constraints 10 wrong constraints the map actually gets so distorted that is unusable for navigation. and in this case screwed up the measurement how can we incorporate that into the graph based slam approach? So the problem that we actually have is if we look to our um an individual constraint so the lack of an observation given the given the current configuration of the nodes was a gaussian distribution. So that's what we had before if we now say okay we would like to have simply a sum of gaussians in order to have a multimodal constraint. So we assume we have normalized this the sum is a pretty good starting point for the for when searching for problems. don't have a single constraint we have a number of constraints right hundred thousand millions of constraints how do we combine those constraints if we minimize the squared error what are we actually doing if you're minimizing the squarederror we are minimizing this expression over here. If we go to the log like negative log likelihood we're going to optimize here this term here minus a constant and here we can't go further than that that's a problem there's where it fails do you see what is the dirtiest way for you to fix this? The key trick is to simply ignore all of them except the most prominent one. If the if the means of these gaussians are far apart from each other the approximation error isn't that big if they are near each other disaster or disaster but may have big errors. If you move the max operation in here if you're maximizing a function or you're minimizing a lock of that function is equivalent so we can move the lock into in there and then have our problem solved that's kind of a nice thing. a really nice way to handle this problem quite practical because if i need to integrate that into a current optimization system i can actually do that very very easily. The only thing i need. to do whenever i experience one of those multimodal constraints i don't compute the error i have to compute the. error for every mode and simply select the one which has the best performance. The nice thing is that actually between iterations you can the system can swap between different modes and therefore the optimization in one iteration takes into account only one mode of the gaussian. kind of in the system swaps to this other one if it is an outlier there's a very high likelihood this will swap to that unless it's an outliest which you have a bad initial guess. If you do this you can actually add 1 10 100 constraints and those are constraints which simply swap to the other mode and don't harm the optimization much. Even if you look to the to the runtime error if you do the red one are the multimodal ones and the other one the regular solution here with this telescopy composition. is a bimodal distribution for the inline and the other one for the outliers the red is in leia blue's outlier you can also handle those cases say i'm either there or there or somewhere else. In most cases actually the vehicle executes what you tell the vehicle to do but in some cases simply doesn't move so this max mixture idea is actually a pretty easy idea pretty simple idea just reply funny no one has done that in robotics until recently a few years ago the first one was edwin olsen and pratik. that's actually a nice thing so um another thing is it can handle both things at the same time data station errors as well as multimodal constraints. So the combination of outlier rejection and dealing with wrong data associations is actually kind of nice we also can do this obviously in 3d. So this is again this data set with the sphere that we have seen before robot moving in a virtual sphere with constraints so this is gauss newton and this is the max mixture gaussNewton and um so you can see here there's a non-perfect alignment in here. Just replace this information matrix here with a variant which has a scaling factor so a constraint dependent scaling factor added to that. This leads to the case that constraints which are far away from what we expect have a smaller influence on the optimization. There's actually closed form you can derive that under certain properties where you end up with this operation. The key idea the intuition behind that is if i have a constraint which have a large error so where the um the current configuration is far from what the constraint tells me just reduce the uh or increase the uncertainty that is associated to that so decrease the information matrix. in this area kind of the the core center of attraction both both perform equally well because there's no scaling involved but the further you move out the more the red curve gets scaled. So the the error is weighted down the further i'm away however we still have a linearization point. So if i compute the jacobian over here i still has a jacoobian which drags the system into the right direction so even if i initialize that quite far away i still get kind of pushed into theright direction if you have a small video. Max mixture as well as for dcs is that kind of the tails of this gaussian distributions contain too few probability mass they're too close to zero. Outlier which is really far away from the current estimate the whole mole is tracked in this direction. If you have constraint which introduce large errors these are these outliers. This can actually screw up the optimization when computing the minimal error configuration so one way you can do is or fits into the framework of its so-called robust m estimators which intuitively say we don't assume a gaussian distribution. now you get different properties in the optimization so if you use um if r is just the quadratic function then we exactly have the original problem that's what we minimized x of minus uh squared error so if we have this one we have we examine exactly in the gaussian world and now there are different techniques how we can actually address that one thing is we could take simply the absolute value so we don't square it just take theabsolute value of the error that's not the parabola that we have but the absolute function. There are different ways of uh kind of row function that we can actually plug in there and um that we're then trying to minimize. The choice of this this function raw kind of encodes the noise properties that you expect if you take a quadratic function you live in the gaussian world. The system optimized according to a different cost function but this allows you to take into account for example these these heavier tails so that outliers still are not weighted that dramatically and impact your solution so much. optimize the log likelihood so this row function goes into the log likely but you still can do compute the logarithm which is something you need to do in order to come up with an effective minimization procedure. In most realistic data sets and situations when you deal with robotics there's a non-zero probability that there will be a datasization error in there. The more likely this data association error the the worse it gets if you optimize without taking these outliers into account and that's actually an easy way to integrate that. here that by changing this function you can't get much better behaviors kind of deciding which function to use for the underlying optimization problem is not on it's not always an easy and easy choice so this requires some expert knowledge some good intuition on coming up with the way with one of those functions. Next week which is the last week of the term i will briefly talk about front ends and give kind of a short summary on what typical front ends exist obviously we're not going to all the details as we did that here.

ROUGE-1: 45.10, ROUGE-2: 43.97, ROUGE-L: 43.98
BERTScore: 71.37

==============================================
==================== [95/100] ====================
Summary:
John Stuart Mill is the principle expositor of neoclassical utilitarianism. The rights-utility synthesis signals that we're looking for an attempt to put together both a commitment to utilitarian efficiency and respect for individual rights. The transition for classical to neoclassicals utilitarianism really went on in all fields of thinking about the human sciences at more or less the same time. What you're also going to get as a by-product of today's lecture is everything you ever needed to know about neocassical economics in 45 minutes. system of thinking about economics and the theory of value that was going to be tremendously influential. At the same time, more or less, there were very important developments in moral philosophy that I just want to alert you to, that we're going to return to later when we come to consider Alasdair MacIntyre's book, After Virtue. And this movement that I'm mentioning here is the doctrine that would come to be called emotivism. It was associated with a man by the name of Stevenson who wrote several books advocating the emotivist doctrine. Hume thought we could derive an ought statement from an is. Bentham thought people are pretty much the same. Stevenson questioned that idea radically. We should take Hobbes much more seriously in his critique of Aristotle than he was willing to take himself. We don't know whether or not what makes some people happy will make others happy as well, says Hobbes. And so Stevenson was thought to be a proponent of a kind of moral relativism. It's presupposed in everything we discussed last time. If you think about the idea of doing interpersonal comparisons of utility. relativism because he linked ethics to our desires, and preferences, and emotions, and nothing else. Stevenson was criticizing Hume on this point, but he might as well have been criticizing Hobbes or Bentham. That is a doctrine to which we will return, as I said, when we get to the anti-Enlightenment and Alasdair MacIntyre's book, After Virtue. But today we're going to focus for the rest of our time on the economics of the transition from classical to neoclassical utilitarianism. by-product is, you're going to get the whole of ECON 101 reduced to a single lecture. Because indeed it is true that enormously complex and subtle, and as sophisticated as the neoclassical theory of microeconomics is. It's all built out of three ideas that I'm going to spell out for you in what some of you might initially regard as laborious detail. But I think you'll see what I'm getting at once we get towards the end of today's discussion. So imagine a world in which there are just two commodities; in this case wine and bread. than anything I've talked about in these lectures. They didn't want to do that because they were actually concerned with quite another problem. The problem they wanted to solve was to understand the behavior of markets. They wanted to be able to more precisely to predict what prices were going to be in markets. So moving from cardinal to ordinal utility is going to turn out to have huge ideological consequences, which I'm going to unpack for you towards the end of today's lecture. But as an analytic matter, looking at this from the inside, it had the great virtue of providing the building blocks for a theory of price behavior. we would know about this person A, as I said, is that they prefer four to three, three to two, two to one, one to zero. But we can't say anything about how much they prefer those things because these distances don't actually mean anything. All we get is an ordered ranking. One other thing we can say is, that this is a no-no. These indifference curves cannot cross. Can anybody tell us why? Why can't they cross? Wait for the mic. C, it must be the case that you also prefer A to C, otherwise you're contradicting the principle of transitivity, okay? So we cannot have these indifference curves crossing one another. Now, instead of one person and two commodities, we're going to think about two people. We're creating a diagram with two people on it. And these axes, the X-axis, here, is A's utility function. So it looks like A's happier than B, but that's misleading. Pareto said there's not an infinite source of utility. He said if you can anywhere into the northeast quadrant both of them are better off. On the other hand, if we went anywhere in this quadrant, southwest as it were, obviously they're both worse off. And about those two quadrants Pareto says we can say nothing at all. We can't assume with Bentham and Hume, with Sedgwick, we can't assumption that everybody's basically the same, perhaps they aren't. diagrammatically, and then if anybody doesn't get it we'll wait up and I'll go through it more slowly. But think about the diagram we just did, okay? Think about A is here in the corner,Okay? But basically now we're putting the two previous diagrams together. We're putting this diagram, where we have two commodities and one person, and this diagram where we've got two people and just utility. And so you'll see why this is helpful once we get to the end of it. With Bentham's utility we said that anything in this whole area, the first shaded area, maximizes the greatest happiness of the greatest number. The Pareto principle, we now know, singles out this Pare to superior area as unambiguously better because people will go there voluntarily. But now the interesting stuff, which is where all of redistributive politics goes on, and all the battles in politics go on, are in the two PareTo undecidable quadrants. which the radical fangs of classical utilitarianism have been ripped out and it is now a doctrine that is very friendly to whatever status quo happens to be generated in a market system. So it ceases to be this radically redistributive doctrine, and in the process imports into utilitarianism a very robust, some would say, hyper-robust doctrine of individual rights. We'll see how that played out in political theory when we come to look at John Stuart Mills' harm principle next Monday.

ROUGE-1: 29.04, ROUGE-2: 27.85, ROUGE-L: 28.27
BERTScore: 71.51

==============================================
==================== [96/100] ====================
Summary:
HONG LIU: So, first, we talk about chiral fermions. So, previously, we showed that the Dirac equation requires, actually, psi to have four components. And so there are two ways to reduce it, and one is called the Majorana fermion. So we first talk about the chiralfermion and one way to do it. And then, we will look at the specific representation of gamma matrices, OK? Consider-- so now I will use a representation which is different from what you-- so i divided by 4. HONG LIU: Let's look at this choice of gamma matrices, OK? So I will call this choice to be star. And so you can also work it out. So you find that they have the following form. So do you see something? Yes? AUDIENCE: They're block diagonal. HONG LIu: Yes, they are. So if sigma is block diagonal, then that means this S is also block. So when S is block, that means, if I write psi x into two component vector, they transform within themselves. HONG LIU: You don't need four components to be able to transform under Lorentz transformation. At least two components can already transform. This property that you can reduce to two components should exist for all choice of gamma matrices. So if we can do it in this choice of Gamma matrices, then we should be able. to do it with any choice ofGammaMatrices, OK? So, now, let me tell you how toDo it for the general gamma matrix. to separate the psi into psi L and psi R is more subtle. You no longer-- is just simple the upper two component or lower two component. So we have to do a little bit of work, OK? Actually, we don't need to do much work if you actually find the right trick. And so the beautiful trick to do this for any choice of gamma matrices is that you can introduce the following object-- what is called gamma 5. So gamma 5 is defined to be i gamma 0, gamma 1, gamma 2, gamma 3. HONG LIU: Gamma 5 actually have 0 trace, OK? So, this, I will leave as an exercise for yourself, what you can do is you did before with other-- yeah, in your homework. So, now, from this properties-- now we can say the following things about the gamma 5 matrix. And so each eigenspace is two-dimensional. So there's 2 plus 1, 2 minus 1. It must be. So then, by definition-- OK, so now this psi L, psi R, which is now defined for any choice of gamma matrices-- so they have to two independent complex component. sometimes also called Weyl spinors. So, now, we will check this actually, indeed. psi L and psi R defined this way will transform under themselves under the Lorentz transformation. They will not mix with each other, OK? So you can check the gamma 5 actually commutes with sigma mu, nu. So that means, under transformation, S will not change the eigenvalues of gamma 5. That means that psi L prime, S lambda, psi L, and gamma 5 acting on psi Lprime is still gamma L. Dirac equation have the following form of Dirac Lagrangian density. And then since psi is just equal to the sum of the-- so psi-- psi R, OK? And then you can just write this in terms of psi L and psi R. Write this interms psi L and psi R, and then you find that the cross term vanish. You can write it as psi dagger partial sub 0, plus i sigma i, partial i, psi L. And this behavior is actually general. HONG LIU: Symmetry is only present in the classical level but not in the quantum level. Without the chiral symmetries, there's no pion. It's also important in many condensed matter systems, like liquid helium, et cetera. The way to understand that these two are related-- so think about the transformation here. And then, now, you have a new symmetry. Gamma 5-- OK. And now you can put the gamma 5 in the exponents. Any questions on this? HONG LIU: In physics, the massless case actually gives you very much richer structure, normally, than the massive particle. Mathematically, it's because the representation of the Lorentz group is very different from the massive case. Why is it called gamma 5 rather than, say, gamma 4? It's a historical reason, so people often like to go to Euclidean space, you continue gamma 0 to gamma 4, and then the gamma 5 is the next one. HONG LIU: In the Dirac spinor, which we have talked about so far, is four components. In the chiral spinor we talked about, you have two complex components. The next one I'm going to talk about is the Majorana, in which case, I would argue, we have 4 times 1 real component. And, now, let's talk about the last case-- this case, which is-- you have four real components, OK? So what do you do? Again, we follow the similar strategy to see whether it's possible to have fourreal components. HONG LIU: We have chosen a very specific representation for gamma matrices, which psi can be chosen to be real. But how about for the general representation? So now we talk about the general Majorana spinor. Majorana is, like, half electron. It has very stable topological properties, which a single electron does not have. And whether you can engineer in your condensed matter systems, Majoranaspinor then became a Holy Grail. If you can do it, you can achieve more stable quantum computation, et cetera. HONG LIU: For this Majorana representation, the B is just equal to identity. And, now, let's try to give you an example of the B in the other representation. So suppose, in the chiral representation, which I wrote down before, that gamma 0, gamma 1, and gamma 2 are imaginary, pure imaginary. And the gamma 2 is real, OK? So this pure imaginary means, when you take the star of them, you get the minus sign. to impose in this basis. And this is now independent of massless or massive particles? HONG LIU: Yeah, yeah, yeah. Yeah, this is-- yeah. Good? So this concludes our discussion of the Majorana spinor. Do you have any questions on this? Yes? AUDIENCE: So is the orthogonal component of psi-- the Majoran fermion [INAUDIBLE]?? HONGLIU: Sorry. The orthogona component of this Majorana species-- like, possible-- in the chiral one, like, psi L. we have-- so this real scalar theory-- we can see that before. So this theory has a discrete symmetry because this is invariant under phi. It goes to minus phi, OK? So this is-- if you do it twice, you go back to itself. OK, so this is called the Z2 symmetry. And there are also spacetime discrete symmetries. So you can have so-called time reversal, which corresponding to your t, x goes to plus t. And so, altogether, they are called CPT symmetry. Yeah.

ROUGE-1: 24.18, ROUGE-2: 22.87, ROUGE-L: 22.87
BERTScore: 72.84

==============================================
==================== [97/100] ====================
Summary:
The best-case scenario for expansionary fiscal policy is when there are lots of underemployed resources in the economy. By increasing spending, the federal government can try to counteract falling aggregate demand. In one scenario, government spending doesn't have to be as large as the fall in "C," or consumption, to counteract the recession, and that's because of the multiplier effect. But, as always, shifting lines on a graph is much easier than shifting around real resources in a multi-trillion dollar economy.

ROUGE-1: 30.09, ROUGE-2: 28.77, ROUGE-L: 30.09
BERTScore: 67.40

==============================================
==================== [98/100] ====================
Summary:
Sarah thread sterner shows you how to wear and take off a mask. She explains how to determine which part of the mask is the front versus the back. She also shows how to mold the nose piece of the face mask with the finger tips of both hands. Finally, she shows you the best way to remove the mask by placing it over your ears and pulling it under your chin when removing the mask it's important to remember that the front is considered contaminated so remove it with the fingertip and then perform hand hygiene.

ROUGE-1: 29.04, ROUGE-2: 20.29, ROUGE-L: 23.82
BERTScore: 64.55

==============================================
==================== [99/100] ====================
Summary:
In this lecture, we're going to talk about how neurons function and how researchers are able to control that function in order to modify behavior. Then we'll talk about synapses and how synapses function to communicate between neurons. And this is going to involve also sort of understanding how certain antidepressants, like Prozac, work. And then we'll end by talking about how researchers did this experiment to wake up the mouse. And it all starts with something that I told you about at the beginning of the semester, which is the plasma membrane. Sodium ions are concentrated on the outside of the cell and potassium ions on the inside. These ions would prefer, by diffusion, to be equal concentrations on both sides of this plasma membrane. The cell to shift this from equilibrium has to expend energy to set up this situation. This is going against the flow that sodium would normally like to take, which would be going downstream. And it pumps potassium ions into the cytoplasm such that there's a higher concentration of potassium ions in the cy toplasm. In a resting state, the cell's resting potential is negative 70 millivolts. If you open these channels, positive ions are going to flow in, and that's going to make this less negative and this less positive, OK? So this is the situation here, where these sodium channels open, and the sodium channels-- or the sodium ions rushing in is going to create a depolarization, where you now flip the potential. And there's a greater positive charge on the inside of the plasma membrane. restored to its resting state, OK? So it's a transient process. When we think about the neuron at higher resolution, what you're going to see is not only is it transient, but it's also a traveling wave that propagates along the entire length of the cell. And one thing that you can notice about these neurons, or the action potentials here, is that they all depolarize to the same extent. So this illustrates a key property of neurons, in that the level of activity of a neuron is not determined by the size of this action potential. How is it that this nerve cell is told to start depolarizing at the dendrites? Because there's going to be another neuron here, which is going to communicate to this neuron over here. It does this at the location known as the synapse. And the way this process is initiated is similar to the type of signaling that you saw in the past few lectures, where you have a ligand and a receptor. And these receptors are what are known as ligand-gated ion channels. In this case, it's a sodium channel. Whether or not it's open depends on the presence of the ligand. have a spike, and you complete the cycle. It can even get hyperpolarized, where it gets even more negative than it normally does. And then it eventually gets back to this resting potential of around negative 60 or negative 70 millivolts. OK, so this has to happen fast. And I want to tell you about one process or property of neurons and another helpful cell that enables this to go extremely fast. There are these glial cells in your body and your brain that wrap around the axons of the neurons and basically function like electrical tape for neurons. ones, localize to these nodes. And when the action potential is traveling along the axon, because. these regions where the myelin sheath is are electrically insulated, the. axon potential doesn't just move continuously, but jumps from node to node. And if you damage this electrical insulation, you greatly slow down these action potentials, and that has a significant impact on nerve impulses in the brain and throughout the entire body. And that's why multiple sclerosis is such a devastating disease. There are different types of signals that nerve cells can send. Signals can be excitatory, meaning it will tend to depolarize the neuron. There are other signals that bind to different type of receptors that are inhibitory. Neurons are prepared to send signals to each other. They have everything ready to go when they get the word from the next cell that they're ready to send a signal to. The way that multiple neurons communicate with each other are through a type of signal known as a neurotransmitter. in all of the ions outside the cell. It's selective to sodium. And this case, this voltage-gated calcium channel is just going to let in calcium. And then there's a mechanism that links calcium entry to vesicle fusion. And that's going to be shown here. What you see on this docked synaptic vesicles is this calcium-binding protein called synaptotagmin. And so when calcium goes into the cytoplasm, that protein binds to calcium, and it activates the fusion machinery. Prozac and Zoloft affect this reuptake process. And what that does is it keeps the neurotransmitter in the synaptic cleft for longer. And so the idea behind these drugs is that if you are suffering depression from a lack of serotonin, then you can rescue that by preventing the rapid reuptaking of the neurotransmitters. The way they function is to leave the neurotransmitted in the. synaptic clefts for longer so that you enhance signaling, even if you have low levels of the. neurotransmitter to begin with. optogenetics is an approach to control the activity of a cell with light. In this case, we're going to have light inducing depolarization. And the way this is done is there's a protein discovered from photosynthetic algae that's responsive to light, and it is a sodium channel. And if that's expressed specifically in the neurons that you're trying to test, you can then shine a light into the brain of the organism and activate, specifically, this type of neuron. you to test the function of the neuron in the behavior of an organism. So, in this case, this mouse, the light is shined into its brain, and they're testing a specific type of neuron that is involved in arousal of the mouse. And it's going to wake up right now. There it goes. It woke up. You see now its muscle activity is going, OK? So you can test thefunction of specific nerve cells using this approach, and it's because you have a light-sensitive sodium channel.

ROUGE-1: 29.12, ROUGE-2: 28.30, ROUGE-L: 28.66
BERTScore: 65.42

==============================================
==================== [100/100] ====================
Summary:
In this problem, we're going to be dealing with a variation of the usual coin-flipping problem. But in this case, the bias itself of the coin is going toBe random. And we're told that the expectation of this bias is some mu and that the variance of the bias isSome sigma squared. And what we'll be asked is find a bunch of different expectations, covariances, and variances. We'll see that this problem gives us some good exercise in a few concepts, a lot of iterated expectations. Expectation of xi given Q, we already argued earlier here that it should just be Q. And then the same thing for xj. That should also be Q, so this is just expectation of Q squared minus mu squared. All right, well, how can we simplify this inner-conditional expectation? Well, we can use the fact that the problem tells us that, conditioned on Q, the tosses are independent. So this is, in fact, exactly equal to the variance of Q. we're told is sigma squared. All right, so what we found is that for i not equal to j, the coherence of xi and xj is exactly equal to s Sigma squared. So what does that tell us? That tells us that these two random variables are correlated. And so, because they're correlated, they can't be independent. And the answer that we wanted was that in fact, xi, xj are in fact not independent. Right. So now let's move on to the last part, part C, which asks us to calculate the variance of x. not equal to j, we also calculated in part B. That's just sigma squared. All right, and now if we compare these two, we'll see that they are proportionally exactly the same. So what do we learn from this problem? Well, we saw that first of all, it's very useful to use law of iterated expectations. But the trick is to figure out what you should condition on. And that's kind of an art that you learn through more practice.

ROUGE-1: 20.63, ROUGE-2: 19.94, ROUGE-L: 19.70
BERTScore: 71.99

==============================================
