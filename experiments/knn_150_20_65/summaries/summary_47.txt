PhilipPE RIGOLLET: I want to have a small bias, hopefully a 0 bias. If this thing is 0, then we see that the estimator is unbiased. So am I planning-- yeah. So if I do, for example, X1, Xn, there are iid Bernoulli. And I'm going to write it theta so that we keep the same notation. Then theta hat is the average of Xi's. So what is the bias of this guy? Well, to know the bias, I just have to remove theta from the expectation. that we are going to be looking for in an estimator, trying to find them to be unbiased. But we'll see that it's actually maybe not enough. So unbiasedness should not be something you lose your sleep over. Something that's slightly better is the risk, really the quadratics risk, which is expectation of-- so if I have an estimators, I'm going to look at the expectation of theta hat n minus theta squared. And so for example, if the quadratic risk goes to 0, then that means that theta hats converges to theta in the L2 sense. for sum of independent random variables, now it's time to wake up. So we have the variance of something that looks like 1 over n, the sum from i equal 1 to n of Xi. So it's of the form variance of a constant times a random variable. But we know that the variance leaves on the square scale, so when I pull out a constant outside of the variance, it comes out with a square. We would like somehow to say that this is the sum of the random variables. Theta is the probability that I contains theta. You want 1 minus alpha to be very close to 1, because it's really telling you that whatever random variable I'm giving you, my error bars are actually covering the right theta and I want this to be true. So regardless of the value of theta that I'm getting, I want that the. probability that it contains the theta is actually larger than 1 minus. alpha. And so in particular, if it's equal, then I can put some larger than or equal to, which guarantees my asymptotic confidence level. what a confidence interval is. And so we fixed a statistical model for n observations, X1 to Xn. The parameter theta here is one-dimensional. Theta is a subset of the real line, and that's why I talk about intervals. A confidence interval of level 1 minus alpha-- so we refer to the quality of a confidence intervals is actually called it's level. The closer to 1 it is, the better the confidence interval. The goal is to estimate a true theta star, the one that generated some data. One of the properties that we wanted. Strongly consistent means that as n goes to infinity, it converges almost surely to the true parameter. That's the strong law of large number. It is consistent also, because it's strongly consistent, so it also converges in probability, which makes it consistent. We've actually computed its quadratic risk. We built a confidence interval at level 1 minus alpha. And we know that this is just the probability that the absolute value of sum not Slutsky, right? Two ways of getting rid of this. Since we only need this thing-- so this thing, as we said, is really equal. Every time I'm going to make this guy smaller and this guy larger, I'm only going to increase the probability. And so what we do is we actually just take the largest possible value for p1 minus p, which makes the interval as large as possible. And by Slutsky, we know that this is actually converging to be-- if I want this to hold for all possible A's, I have all possible events. about maximum likelihood estimation. If I give you a function, you need to know how to maximize this function. Sometimes, you have closed-form solutions. You can take the derivative and set it equal to 0 and solve it. But sometimes, you actually need to resort to algorithms to do that. And we'll briefly touch upon it, but this is definitely not the focus of this class. OK. So what are the properties? The KL divergence between P theta and P thena prime is different. In a way, what does it mean to have two distributions that are close? It means that when you compute probabilities on one distribution, you should have the same probability on the other distribution pretty much. So what we can do is say, well, now I have two candidate distributions. So if theta hat leads to a candidate distribution P theta. And this is the true theta star, it leads to the true distribution. According to which my data was drawn. That's my candidate. And so really what I want is that if I compute what it is doing for you. It's controlling the difference of probabilities you can compute on any event. The total variation distance is actually called the Kullback-Leibler divergence. It has some roots coming from information theory, which I will not delve into. The KL divergence between two probability measures is not going to be symmetric to start with. And I go from discrete to continuous using an integral. Everybody can read this. Everybody's fine with this. Is there any uncertainty about the actual definition here? So here I go straight to the definition, which is just plugging the functions into some integral and compute. So I don't bother with maxima or anything. The total variation distance-- the KL divergence, sorry, is actually an expectation of something. If this thing being small implied that P theta could be all over the place, that would not help very much. The divergence is doing a pretty good thing for us. And this is what will allow us to estimate it and basically overcome what we could not do with the total variation. The fact that you need two definitions of the [INAUDIBLE],, is it something obvious or is it complete? PHILIPPE RIGOLLET: I'll do it for you. PhilipPE RIGOLLET: The set A star is the set of X's such that f of X is larger than g of X. That's the set on which the difference is going to be positive or negative, he says. He shows that if he takes any other A in this integral than this guy A star, it's actually got to decrease its value. Rigollet: The first one has to be larger, because this thing is actually equal to a non-negative number. when I take A to be the set where it's positive. Just need to make sure that there is someplace where it is, but that's about it. So it's a distance. It's symmetric, non-negative, equal to 0, if and only if the two arguments are equal, then it satisfies the triangle compared to the convex function of the expectation of a random variable. If it's not satisfying this thing, it's called pseudo-distance or quasi- distance or just metric or nothing at all. But here, one of the arguments is not known to us, so we need to estimate it. And so here is the strategy. Just build an estimator of the total variation distance between P theta and P theTA star for all candidate theta, all possible theta in capital theta. Now, if this is a good estimate, then when I minimize it, I should get something that's close to P thena star. That's a pretty good estimation strategy. But it's very unclear how you would build this estimator. it is. And that's now where the log plays a role. If you actually pay attention, I said you can use Jensen to prove all this stuff. You could actually replace the log by any concave function. That would be f divergent. That's called an f divergence. But the log itself is a very, very specific property, which allows us to say that the log of the ratio is the ratio of the log. If I change theta, this thing is never going to change. It depends only on theta.