In week four, we take a break from learning more and more on neural network topics, and talk about final projects, but also some practical tips for building neural network systems. Today's lecture is the primary content for what you'll be using for building your assignment 4 systems. In the early 1950s, there started to be work on machine translation. Claims were made that the computer would replace most human translators. When you go in for full scale production what will the capacity be? We should be able to do about with a modern commercial computer about one to two million words an hour. that can sometimes improve performance. And we actually have that trick in the assignment 4 system. And you can try it out. So we generate along and generate our whole sentence in this manner. And that's proven to be a very effective way of getting more information from the source sentence more flexibly to allow us to generate a good translation. I'll stop here for now and at the start of next time. I will finish this off by going through the actual equations for how attention works. One French word gets translated as several English words. You can get the reverse, where you can have several French words that get translated as one English word. So mis en application is getting translated as implemented. And you can get even more complicated ones. So here we sort of have four English words being translated as two French words. But they don't really break down and translate each other well. I mean, these things don't only happen across languages. They also happen within the language when you have different ways of saying the same thing. And so even are somewhat flimsy terms.