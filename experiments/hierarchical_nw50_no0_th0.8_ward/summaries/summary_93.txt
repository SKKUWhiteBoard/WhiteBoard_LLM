The Full Count Review program was designed to rapidly examine, rectify if possible. The bureau conducted a number of quality assurance programs throughout the course of the census. It will be important for the bureau to explore how to make better use of the program for correcting potential errors in census data in the future. To help ensure the accuracy and completeness of census data and take full advantage of the Full Count review program and FSCPE members’ support, visit www.census.gov. participation, we recommend that the Secretary of Commerce direct the bureau to develop ways to resolve a larger number of data issues. consideration should be given to planning the Full Count Review program early in the census cycle and data issues in the field prior to the release of public law data. To ensure no expectation gaps develop between the bureau and FSCPE members, the secretary of Commerce should also ensure that the bureau clarifies and consistently communicates to participants the objectives of the full count review program, the authors say. members’ local demographic knowledge. According to bureau officials, the bureau plans to include a Full Count Review program in census tests it expects to conduct later in the decade. Foremost among the areas in need of improvement is resolving a larger number of data issues prior to the release of apportionment. The bureau’s decision came after the 1998 dress rehearsal for the 2000 Census, which meant that the bureau had no opportunity to test the Full Count review program in an operational environment, officials said. that works with the bureau to ensure accurate state and local population estimates. The bureau contracted with 53 FSCPE members who reviewed data for 39 states and Puerto Rico. Bureau employees reviewedData for the 11 remaining states and the District of Columbia without FSC PE representation in Full Count Review on any one particular state or locality. A separate set of employees from the bureau’s Population Division assessed issues identified by Full Count review analysts based on the adequacy of the documentation supporting each issue, and (2) the quality of the analysis. The Full Count Review program ran from June 2000 through March 2001. According to bureau officials, some of the analysts’ work was contracted to members of the FSCPE, an organization composed of state demographers. The results suggest that most FSC PE members were satisfied with their Full Count review experience, the authors say. They say the bureau could not complete the Full Countreview workload without a costly staff increase, so it contracted the work to the F SCPE to be completed on time. We examined bureau training manuals, statements of work, submissions based on the quality of the documentation. Better guidance on documenting issues for the Full Count Review program could make the bureau’s follow-up investigations more efficient. Another area where there is room for improvement concerns the consistency and clarity in which the bureau communicated the objectives of the Full. Count Review.program. We did not independently verify the information contained in the Count Review Information System, a database used to track issues flagged during the review process. participation appear to be mixed. On the one hand, the bureau reported that the Full Count Review program was successful in that it met a number of performance goals. For example, the program was comprehensive in its review of geography and content, and it met its goals in terms of content and content review. The bureau also reported that it was successful in its review of the program's performance goals, such as the review of its content and geography, and that it met its performance goals in other areas. The remaining 1,457 issues referred to CQR did not meet the bureau’s documentation requirements and consequently, the bureau took no further action on them. The overall results of the Full Count Review program and FSCPE members’ from the fact that the bureau had no mechanism for managing the Full count Review workload. Unlike the CQr program, where the bureau required local governments to provide specific documentation before it would commit resources to investigate local data issues, the Fullcount review program had no filter for screening. Bureau officials told us that they used the Full Count Review program to identify systemic errors such as those that could be produced by software problems. Officials who noted that resolving individual issues was beyond the scope of the program. None of the bureau’s documentation or training manuals that we reviewed explicitly stated that the bureau would only check for systemic errors. Because of the inconsistent message on the purpose, the bureau may have set up the expectation that a larger number of issues would be resolved during Full Count review. U.S. General Accounting Office. 2000 Census: Coverage Evaluation Matching Implemented As Planned, but Census Bureau Should Evaluate Lessons Learned. 2000 census: Better Productivity Data Needed for Future Planning and Budgeting. Census Bureau: Significant Increase in Cost Per Housing Unit Compared to 1990 Census. Census bureau: Historical Data on Enumerator Productivity Are Limited. Census agency: Information on Short- and Long-Form Response Rates. Census office: Data on Long- and Short-form Response Rates are not available. Our work was done in accordance with generally accepted government auditing standards. On April 26, 2002, we requested comments on a draft of this report from the Secretary of Commerce. The Secretary forwarded the bureau’s written comments on June 11, 2002 (see app. II). We address them in the “Agency” section of the report. We address the comments we received in the report in the section “Comments’’ We also addressed the comments in the appendix to this report. and how the bureau plans to use the information derived from it. The Secretary of Commerce forwarded written comments from the Bureau of the Census on a draft of this report (see app. II). The bureau concurred with all of our recommendations and had no comments on them. The bureau had no comment on any of the recommendations made in this report. The report was published by the Center for American Progress on October 31, 2013. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org. also provided minor technical corrections that we incorporated in our report as appropriate. As agreed with your office, unless you publicly announce its contents earlier, we plan no further distribution of this report until 30 days from its issue date. At that time, we will send copies to other interested parties. We will also send copies of the report to other news outlets if they choose to publish it. We apologize for any inconvenience caused by the delay in releasing the report. We are happy to make any corrections or additions to the report as necessary. congressional committees, the Secretary of Commerce, and the Director of the Bureau of the Census. Copies will be made available to others upon request. In addition, the report will be available at no charge on the GAO Web site at http://www.gao.gov. Corinna Wengryn, Ty Mitchell, and Robert Goldenkoff made major changes to the Census Bureau's data collection system. The changes were made in response to a request for information from Congress. particular census tract of a large midwestern city appeared to be too high, while a neighboring tract had a correspondingly low group quarters population count. By comparing state administrative records to information obtained from bureau resources, analysts determined that bureau data had placed college dormitories in the wrong tract. Housing was not the problem, however, and the city was actually too low in group quarters. The city was too high in housing, but it was also too low on group quarters, analysts said. An urban area had a large amount of redevelopment since the 1990 census. As part of this, several condominiums and apartment complexes were built which substantially increased the number of housing units in a particular census tract. However, when the analyst compared population data from the 1990 Census, they found that the increase in housing units was much smaller than they had thought. The analyst compared the population data to the population figures from the 1980 Census. The results were more in line with the 1980 census figures. Data from the 2000 Census appeared to accurately reflect the large amount of new house construction that had taken place within a specific census tract. However, because the population count differed from the 1999 Census.and 2000 Census, the2000 Census did not appear to reflect this increase, and it was flagged. It was flagged because of the large number of new homes built in a single census tract in the past decade. It has since been fixed. It is not known if the new homes will be counted in the 2015 Census. noted that the bureau generally did not use the Full Count Review program to resolve individual issues. According to bureau officials, the bureau corrected data for 5 of the 4,809 issues prior to the December 31, 2000, release of reapportionment data. data by December 31 of the census year, and redistricting data by April 1 of the following year. We found three factors that limited the bureau’s ability to do so. First, according to Bureau officials, resolving individual issues was outside the scope of the Full count review program. just 14 months before Census Day, April 1, 2000. The timing of the decision stemmed from the Supreme Court’s January 1999 ruling that prohibited the bureau from using statistical sampling for purposes of congressional apportionment. The bureau originally planned a ‘one-number’ census that would have integrated the results of a “one- number” census with the results from a general population survey. The decision to use statistical sampling was a result of that ruling, the Census Bureau says. Census data remain an important element in allocating federal aid to state and local governments. Accurate census results are critical because the data are used to reapportion seats in the House of Representatives and for congressional redistricting. With billions of dollars at stake, the apportionment and redistricting data were released with more than 4,800 unresolved issues. Until these issues are resolved, uncertainties will surround the accuracy of the census data for the affected localities. Some of the issues might be resolved under the CQR program, which the bureau designed to respond. clear census data files and products for subsequent processing or public release. The bureau expected data analysts to identify data discrepancies, anomalies, and other data “issues” by checking the data for its overall reasonableness. This process alerted bureau officials that there were data discrepancies but did released with around 4,800 unresolved data issues of unknown validity, magnitude, and impact. Given the importance of accurate census data, the bureau missed an opportunity to verify and possibly improve the quality of the public law data. Bureau data show that after reviewing census data for 39 states and Puerto Rico, FSCPE members identified a total of 1,402 issues, or about 29 percent of the 4,809 issues collectively flagged during Full Count Review. bureau was unable to classify 2,060 issues (43 percent) Bureau officials told us that in these cases, analysts did not provide sufficient documentation for the bureau to determine the nature of the issue. According to bureau officials, bureau analysts identified a larger number of issues than FSC PE members. FSCPE members identified the five issues, all of which involved group quarters that were placed in the wrong locations. They included (1) a military base in Nevada, (2) 10 facilities at a college in Wisconsin, and (3) 9 facilities at the University of Wisconsin. The population counts were correct, FSCPE officials said, but the group quarters were not in the correct locations. The group quarters had been moved to the wrong location. The issues were resolved. The bureau is investigating the matter. was processing a key geographic data file and was thus able to incorporate the corrections before the data were finalized. Second, the FSCPE analysts had thoroughly documented the issues and recommended how the bureau should correct the errors. The five errors did not require additional research or field verification. Bureau that he expected FSC PE members would identify any geographic discrepancies that contrasted with preliminary census data, and the bureau would investigate and make the necessary changes. He noted that both he and his staff were very “dismayed” to find out that certain discrepancies involving group quarters were not resolved prior. FSCPE members’ participation, and specifically their expertise and knowledge of local geography, demographics, and housing arrangements, had the potential to identify data issues that the bureau might have otherwise missed. However, the fact that the apportionment and redistricting data were.adjusted and unadjusted helped ensure the bureau released accurate data. Also, census.sample survey with the traditional census to provide one adjusted set of census numbers. The bureau decided to enlist the help of FSC PE members in order to meet the deadlines for releasing the public law data. Bureau and FSCPE analysts were to ensure that (1) group quarters were correctly placed or “geocoded” on census maps. They were to describe each issue flagged and to explain why it had been flagged and why it was being dealt with in the way it was. They also were to make sure population counts in other areas were in line with population estimates in the census maps, and that demographic characteristics appeared reasonable. The results were published in the U.S. census for the first time on Tuesday. prison in New York City, (4) 14 facilities at a Washington prison, and (5) a federal medical center in Massachusetts. Bureau officials said that the bureau was able to correct these issues for two reasons. First, FSCPE analysts found them early in the Full Count Review program. Second, while the bureau found the problems, it was not aware of them until later in the program. The bureau is now aware of the problems and is working to correct them. The full report is available on the bureau's website. officials told us that they lacked the time to research the remaining issues, as well as field staff to inspect purported discrepancies prior to the release of the public law data. As a result, the bureau missed an important opportunity to verify and possibly improve the quality of the data, they said. The data was released to the public on Wednesday. The public can view the data online at: http://www.dailymail.co.uk/news/article-263852/Public-law-data-released-to-the-public-on-Wednesday. a larger number of issues was that the bureau’s requirements for documenting data issues were not clearly defined. For example, the training materials did not provide any specific guidance on the type of evidence analysts needed to support data issues. Instead, theTraining materials told analysts to supply evidence. Instead of providing specific guidance, analysts were told to supply the evidence they needed. The training materials also said analysts should supply the data they needed to make a decision on a data issue. For more information, visit the Bureau of Labor Statistics website. to correct a larger number of individual issues prior to the release of the public law data. Field staff would be needed to help verify issues, and the effort would require close coordination with several bureau units. A second factor that affected the bureau’s ability to correct by government and tribal officials, such officials must first supply specific information. The guidance then details the information needed to support boundary corrections, geocoding and coverage corrections, and group quarters population corrections. A third, and related factor that affect the bureau's ability to resolve a largerNumber of issues. as much supporting information as necessary. This could help explain the variation that we observed in the quality of the documentation analysts provided. Some analysts provided only minimal data, others supported issues with state and local administrative records, historical data, photographs, and maps. In some cases, the bureau bureau to investigate individual data issues, (4) categorizing issues on the basis of the quality and precision of documentation, and (5) exploring the feasibility of using staff from the bureau’s regional offices to help investigate. provide supporting documentation derived from bureau resources and/or resources of the respective state government. Staff from the regional offices reviewed demographic data from the 50 states, Puerto Rico, and the District of Columbia. They focused on identifying inconsistent demographic characteristics and did not necessarily concentrate on specific states or areas of the U.S. The report was released to the public on Wednesday, October 17. The full report will be released on Thursday, October 18, at 10:30 a.m. ET. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or click here. to challenges to housing unit and group quarters population counts received from state, local, or tribal governments. Of the 4,804 issues remaining after Full Count Review, 1,994 (42 percent) were referred to CQR, and of these, 537 (11 percent), were accepted for further investigation. Of these, of the issues still to be resolved, only 11 percent of them were to be referred to the CQr for further review. The remaining issues were to do with housing units, group quarters, and single-family homes. had difficulty determining the precise nature of an issue or if in fact an issue even existed. In contrast, the CQR program provides comprehensive guidelines on the documentation required for making submissions. The guidance available on the bureau’s CQr web site notes that before the bureau will investigate concerns raised, it will first need to receive the proper documentation. The CQS program is free and open to the public, with a fee of up to $1,000 per person. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or click here for details. whether or not they believed the issue to be resolvable through follow-up research by the bureau. Those issues deemed to have adequate documentation were classified as a “group quarters,’ “housing unit,” or “household’ or ‘other’ issue. Since the bureau has yet to resolve most of these issues, it is not known whether they are necessarily errors. Group quarters issues were those most frequently identified, accounting for 1,599 of the 4,809 issues. to suspected discrepancies in the population counts and locations of prisons, dormitories, nursing homes, and similar group living arrangements. Analysts also identified 479 housing unit issues (10 percent of the total), and 288 household issues (6 percent) There were also 383 issues (8 percent) that the bureau classified as “other” They contained questions concerning the demographic characteristics of the data such as age, race, and gender. The count of occupied housing units differed from what analysts expected while household issues had population data for occupied residences that differed.