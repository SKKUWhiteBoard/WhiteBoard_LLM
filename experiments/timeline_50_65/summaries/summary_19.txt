The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation or view additional materials from hundreds of MIT courses, visit MIT Open CourseWare at ocw.mit.edu. For confidential support call the Samaritans on 08457 90 90 90 or visit a local Samaritans branch, see www.samaritans.org for details. For support in the U.S., call the National Suicide Prevention Line on 1-800-273-8255. to do is we're just start with a short review problem on rugged landscapes, just so that you get some sense of the kind of thing that I would expect you to be able to do a week from today. And then we'll get into the core topic of the week, which is how do we get to the top of the mountain in a week or so? We'll be back next week to talk about how we got to this point in the story. We'll also talk about some of the challenges that we've faced. class, which is evolutionary game theory. And we'll discuss why it is that you don't need to invoke any notion of rationality. Then we'll try to understand this difference to human decision making, and why it's important to have an evolutionary view of decision making in the first place. We'll also discuss the role of rationality in game theory, and how it can be applied to decision-making in the real world. Back to Mail Online home. back to the page you came from. know what a Nash equilibrium is in the context of game theory versus an evolutionary stable strategy in this context. And we'll say something about the evolution of cooperation and experiments that one can do with microbial populations in the laboratory. Are there any questions before I get started? All are welcome to ask them in the comments below. Back to Mail Online home. back to the page you came from. Click here to read the rest of the interview with Dr. Andrew Keen. Back into the page. right, so just on this question of evolutionary paths, on Tuesday we discussed the Weinreich paper where he talked about sort of different models that you might use to try to make estimates of the path that evolution might take on that fitness landscape that he measured. So he measured the fitness landscape, and then he measured how evolutionary paths might play out in that landscape. And that's what we're going to be looking at in the next few years. We'll be trying to figure out what the evolutionary path might be. this MIC, the minimum inhibitory concentration, on all 2 to the 5 or 32 different states, and then tried to say something about the probability that different paths will be taken. So I just want to explore this question about paths in a simpler landscape, where by construction here, I'm talking about the MIC. I'm just trying to say that there are different paths that can be taken, and I'm trying to think about what the probability is of each of those paths being taken. "I'm going to give you some fitness values just so that we can be clear about why it is that there might be different paths, or what determines the probability that different paths are taken," he says. "So what we want to do is assume that we are in a population that is in a state of fitness. We want to be able to say, 'I'm in a position where I can do this,' and so on," he adds. "We want to make sure that we don't have a population of people who are not able to do this." is experiencing this Moran process or Moran model. Each time that an individual divides, it has a 1 in a million probability of mutating. The mutation rate is 10 to the minus 6 per cent, according to the study. The population size N is equal to, in this case, we'll say 1,000, and let's say that the mutation rates is 10-to-the-plus-6 per cent. The result is a population with a constant population size of N equal to N. And that's a per base pair mutation rate. And in particular, we're going to have genotypes. Originally when we discussed this, we were talking about just mutations, maybe A's and B's. But now, what we're Going to Have is just a Genotype. And I'll show you what I mean by that. I'll give you a few examples of what I'm talking about. I'm going to give you some examples of how we'll be able to do it. short genome that's string length 2. So we might have 0,0, which has relative fitness 1, 0, 1. We're going to start in the 0, 0 state with 1,000 isogenic individuals. All of them are going to be in a state of relative fitness of 0.0, 0. So they're all going to have relative fitness as compared to the 0,.0 state. They're all in the same state of fitness, so they're in a relative fitness state of 1.0. And the question is, what's going to happen eventually? And in particular, what path will be taken on this landscape here? In particular, we want to know is the probability of taking this path. You can start thinking about it while I write out some possibilities that we can think about. I'll be back in a few hours with a new set of questions for you to answer. Back to Mail Online home. back to the page you came from."What do you think?" you ask. "I want to hear from you." vote for, and I'll give you a minute to think about it. So don't-- Are there any questions about what I'm trying to ask here? AUDIENCE: So this is the long time? So we assume that in the longtime, it will go from 0, 0 to 1, 1? PROFESSOR: Yes, that's what I was trying to say. It's a long time, but it's not the end of the world, it's just the beginning of the future. That's right, yes, so if we wait long enough, the population will get there, and the 1, 1 genotype will fix in the population. We can talk a bit later about how long it's going to take to get there. And we're assuming that from 0, we're going to go from 1 to 1 in a very short period of time. That's what we're hoping for. We're not sure how long that will take, but that's the goal. 1, it can't go back to 0, 0? PROFESSOR: Right. Yeah, so we'll discuss the situations when we have to worry about that, and when we don't, and so forth. But for now, if you'd like, we can say that this is even just mu sub b, the beneficial mutation. That's the way we're going to try to explain it to you. It's a good way to start, but it's not the only way. rate per base pair, assuming that the 0's can only turn into 1s. Then after we think about this, we could figure out if that's important, or when it is important, and so forth. Yes. Audience: [INAUDIBLE]? PROFESSOR: No. All right, so we're starting with all 1,000 individuals being in the base pair. Then we'll see if we can get to the root of the problem, which is how many 0's there are in a pair. 0, 0 state, because now we're allowing some mutation rate. AUDIENCE: But it's not [INAUDIBLE] first mutation, the mutation of one element of that population will go to 0, 1. PROFESSOR: And you also have to think about this first mutation-- will it fix or not? And if that mutation-- are we assuming that that mutation is0, 1 and then figuring out [INAudIBLE]? PROFessor: Well, OK, you're asking kind of what I mean by path here. We'll also discuss whether it somehow is very likely is going to kind of have to go through one or more of these paths. The professor will say path means that that this was the dominant probability trajectory of the population through there. We will also discuss if it is likely that the population will have to travel through one of these pathways in the future. The final segment will air at 8 p.m. ET on Sunday, December 10, on CNN.com and CNN Live. the other of them. The probability of getting both mutations in one generation is going to be 10 to the minus 12. And then there's another question, which is, will 0, 1 actually actually happen? That's a very rare thing, at least given these parameters, and so forth. So that's going-to be a veryRare thing,  given these parameters and so on. That's what we're trying to figure out. We're not sure if we're going to get it. fix in the population before you later fix this population? And actually, I think the answers to all these questions are in principal already on the board. Because there's a question of do we have to worry about clonal interference? Are these things neutral or not? And really, this is really what we're trying to figure out, is what is the best way to fix the population?" she says. "It's a very, very complex question," she adds, "and I think we're getting closer to the answer" in some ways a very simple problem. But in another way, you have to keep track of lots of different things, and which regime we're in and so forth. So that's what makes it such a wonderful exam problem. If you understand what's going on, you can answer it in this way. It's a great way to test your knowledge of a subject, or to learn about a new regime, or a new way of looking at the world, for that matter. I hope you'll find it helpful. a minute. But if you don't understand what's going on, it'll take you an hour. Yes? No? Maybe? Well, I'll give you another 20 seconds. Hopefully, you've been thinking about it while we've been talking. All right, do you need more time? Why don't we go ahead and vote? I'm sorry, I'm going to have to ask you to think about it for a few more seconds. I don't think you're ready to vote yet. think it's very likely that we will not be at the kind of 100% mark, in which case you'll have a chance to talk about it and think about it some more. Ready? Three, two, one. OK, all right, so we do have a fair range of answers. I'd say it'd be a good idea for us to take a few days to think about what we want to do. It would be good for the country to have a little bit of a break from the news. it might be kind of something like 50-50. And that's great. It means that there should be something to talk about. So turn to a neighbor. You should be able to find somebody that disagrees with you. And if everyone around you agrees, you can maybe-- all right, so there's all right. All right. So there's something to discuss. It might be 50/50, but it might be more like 50% or more. That's fine. a group of D's and a group of B's here, which means that everybody-- AUDIENCE: Let's fight. PROFESSOR: All right, so everybody thinks that everybody agrees with them, but you just need to look a little bit more long distance. So turn to a pseudo-neighbor. You should be able to. You shouldn't have to be your neighbor to understand what you're trying to say, professor says. He says, "You're not the only one who thinks this way." find somebody there. It's roughly even here, so you should be able to find someone. So I don't see much in the way of vibrant discussion and argument. You guys should be passionately defending your choice here. Yeah, that's a higher order point. I wouldn't worry about it. I'm not worried about it at all. I just don't think it's a good idea. I think it would be better for the country if we didn't go to the polls. about that. All right, it looks like people are having a nice discussion. But I might still go ahead and cut it short, just so that we can get on to evolutionary game theory. I would like to see where people are. And we'll discuss it as soon as we can. Back to Mail Online home. back to the page you came from. Click here to read the full transcript of this interview. Back To the pageyou came from, click here to Read the full Transcript of this Interview. a group, so don't be too disappointed if you don't get finished there. But I do want to see kind of where we are. Ready? Three, two, one. OK, so it still is, maybe, split roughly equally between D and maybe a B-ish and some C's. All right, does somebody want to take a crack at this one? It's going to be a tough one, but we're going to have to go with it, I think. want to volunteer their explanation? Yes. AUDIENCE: I'm not sure how good it is, but I was thinking about what's the probability of going to 0, 1 instead of 1, 0. And I just took it as the ratio of the extra benefit of0, 1 over the benefit of 0, 0, or 1, 1, or 2, 2, or 3, 3, or 4, 4, or 5, 5, or 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 94. 1, 0.1, D. 1, 0 is somehow more fit than 0, 1. D, D is the same as 0, 0, but with an extra "i" in the middle. The professor asks the audience which answer they want to give. The audience says D, so the professor gives it to them as a "D" The professor says, "All right, all right. So you're saying D, OK, allright. And you've taken that out of the equation." some relative rates or ratios for which reason? AUDIENCE: Well, I took 0.02 and then 0.1, which is 1/5. And then I decided that that should be around what it is, but slightly less, because there's also a chance that [INAUDIBLE]. PROFESSOR: OK, yes. I think the arguments there-- there's. There's also the chance that there's a better way to do it, and I think that's the way to go. a lot of truth to the arguments that you're saying. Yeah, it's a little-- right and another question is exactly why might it be 1/6 instead of 1/5 is, I think, a little bit hazy in this here. It's OK, but it's close. Does somebody want to offer an explanation? Yes, I would like an explanation. I think it would be a good one. It would be good to have an explanation for why it might be 1-5 instead of1-6. So here, that was an argument of roughly maybe why it's D-ish. Because D is very different from B-- order of magnitude different. So can somebody offer why their neighbor thought it was B? Yeah. Audience: So I knew that it was A, because I considered the two paths, both A and B. Both paths are very different. Both are very, very different, and that's what we're going to focus on. We're not going to dwell on that. from 0, 0 to 0, 1. I first checked S, N and it's non-neutral. So probably [INAUDIBLE] S. So the probability for that first path would be the S for 0,. 1, so it's 0.02, which is 1/50, multiplied by the probability that the other [INAudIBLE] 1, 0 would die. The probability for the first path was 0.01, so the probability is 0.03, or 0.04. out [INAUDIBLE]. PROFESSOR: Right, so there are two related questions. And I think that this explanation here is answering a slightly different question. OK, so let me try to explain what the two questions are here. So the question that you're answering is, if you have kind of 998 individuals, what do you do with all of them? And the answer is, you have to find a way to get them to cooperate with each other. And so that's what you do. that are 0, 0 individuals, and you have one that's 0, 1, and one individual that is 1, 0. So this is like these problems that we did a couple weeks ago, where we said, you imagine in the population you have a couple different kinds of mutants. That's like the problem that we were trying to solve a few weeks ago. That was the problem of how do we get rid of the 0s and 0s? That's what we're trying to figure out. that are present maybe in one copy. And then we were asking, well, what's the probability that this individual is going to fix? And what'sThe probability that these guys are going to go extinct, and this one will therefore fix. And I think that's the calculation that you're describing, where you say, Well, in order for this individual to fix, he has to survive stochastic extinction, which happens with the probability of 2%. And the 1, 0 individual has to go endangered, and that happens 90% of the time. And so this is, indeed, answering the question that if you had one copy of each of these two mutant individuals in the population, that's the answer to what is the probability that this 0, 1 mutant would fix. Right? But that's a slightly different question than the one we were trying to answer here. We're trying to find out what the probability is that one of these 2 mutant individuals would fix in a population. We'll have to wait and see how that pans out. if we ask, we're going to start with an entire population at 0, 0, and now these mutations will be occurring randomly at some rate. And then something's going to happen. Somehow the population is going to climb up this fitness landscape. And we're trying to figure out the relative fitness levels of the population. We're not going to know how to get there yet, but we're getting closer to the answer. We'll have to wait and see what the results are. "It's going to end up being D. And now we want to try to figure out what D. is," he says. "Do you see the difference between these two questions? So indeed, this is the correct answer to a different question. And so it'sgoing to endup being D," he adds. "And now we Want to Try to Figure out What D. Is" "D" is CNN Tech's weekly, offbeat look at what's coming next on CNN iReport. how to get there. Because I think it is a bit tricky. We have to make sure we keep track of which parameter regime we're in. So there are a couple of questions we have to ask. First of all, what are the parameters we're looking for? What are the goals we want to achieve? And how do we get there? And what are we going to do about it? I think that's the first thing we need to ask ourselves, and then work out how we're going to get to them. all, we have to remember that we start out with everybody, all 1,000 individuals in the 0, 0 state. So there are initially no mutants in the population. But they're just replicating at some rate. And every now and then, mutation's going to occur. Now one thing we have is to be prepared for it. We have to be able to deal with it. It's a very, very difficult task. But we're getting there. We're getting closer. answer, we have to think about, is whether these are nearly neutral mutations. Verbally yes or no? Ready? Three, two, one. AUDIENCE: No. PROFESSOR: No, right. And that's because we want to ask for, if it's nearly neutral, we wants to ask, is the magnitude of S times N much much? Three times N is the number of times S. Three times S is the amount of S. is N. greater or much less than 1? In particular, if they're much greater than 1, as is the case here, then we're in a nice, simple regime. And it's easy to get paralyzed in this situation, because there's more than one S. But in both cases, S times N is much more than 1. It's a simple equation, but it's not easy to understand. It can be hard to work out how to use it in the first place. larger than 1. We can take the smaller S, which is 2 over 100, and S times N is 20, right? So S for the 0, 1 state times N was 20, which was much greater than 1, and this tells us that if we do get this mutant, it will be much larger than 1 as well. This means that we could get a much larger mutant than 1 if we get it, and it could be much bigger than 1 too. This is a very exciting prospect. appearing in the population, then he or she will have a probability S of surviving stochastic extinction. If the individual appears is equal to S 0, 1, which isequal to 2%. Whereas for the 1, 0 state, that's going to be 0.1. Now, probability of surviving extinction if the individual appears is equal to S 0, 1. So probability of survival if individual appeared is equal to S 0, 1. this is assuming that the mutation appears in the population, that's the probability it will survive stochastic extinction. Surviving stochastically extinction roughly corresponds to this becoming an established idea. And becoming established was what again? PROFESSOR: What's that? AUDIENCE: S1 is [INAUDIBLE]. PROFessor: S2 is S1. S3 is S3. S4 is S5. S6 is S7. S8 is S9. S9 is S10. S10 is S11. It's when S1-- AUDIENCE: [INAUDIBLE]. PROFESSOR: Yeah, that's right. All right, so established-- when we say established, what we mean is that this corresponds to saying that this probability that we talked about before this X sub i is approximately equal to 1. So this question is, how many individuals are there in the world that could do that? And the answer is, there are many. It's just a matter of how many of them do it. do you have to get to in the population before you're very likely to fix? And what we found is that that number established went as 1 over the selection coefficient. So in this case, you would need to have 50 individuals before you were kind of more likely to. fix it than if you started at the beginning of the study. The study was published in the Journal of Personality and Social Psychology, published by the University of California, Los Angeles. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. fix than not. So if you want to be much more likely, you might need twice that or so. Do you guys remember that? This is not important for this question, necessarily, but it might be important at a later date. And so for nearly neutral mutations, the whole is better than half a fix. So that's what we're going to do here. We're just going to try to get it to work as best we can. We'll let you know how it goes. point is that the number needed to become established is equal to the population. OK, so the way that we can think about this is, now we have this population, 1,000 individuals. They're dividing at some rate. Mutations are going to appear. We're going to have to find a way to get them to stop dividing. We'll have to figure out how to get the population to cooperate. We've got to get to a point where we're not dividing at a rate that's too fast. Now we know if they did appear, the probability they would fix. This is assuming there's no clonal interference, right? Because if there's clonal interfered, surviving stochastic extinction is not the same thing as fixing. If they both appear in the population, and they both survive stochastically extinction, then they both would fix, we know. We also know that if they both appeared, they would both fix. We know that this is assuming they both survived the extinction process. this mutant loses to this mutant. That's the clonal interference. Do we have to worry about clonal interfered in this situation? So remember the two time scales. This was comparing the time between successive establishment events, which went as 1 over mu N S. And the other, which was 1 over Mu N S, was the other way around. And that's what we're looking at here. We're not looking at the same time scale, we're just looking at a different time scale. one is the time between the time to fix, which went as 1 over S log of NS, right? So we can ignore clonal interference if this is much larger than that. So noClonal interference corresponds to mu N log NS much less than 1. Noclonal interference, same as 1.1. NoClonalInterference, same. No clonal Interference, no clonal interference and no clonal inference. No Clonal Inference, same. No Clonal Interference , no clonal interference. as this statement. Is that right? Did I do it right? OK. So and once again, there are multiple S's, and it's easy to get kind of upset about this. But you can just use whichever S would be-- which S would you want to use to be kind of-- and you can do it any way you want. You can use whatever S you want, but you can't be upset about it. You just have to use the one you feel like it. Professor: To be on the safe or conservative side, we want to take this to be as big as possible. It's in the log. So details, right? But we can see we have 10. We take S actually asbig as we can. So we take S. actually asBig as We Can Be. We Take S. As Big As We Can be. We Have 10 S. S. Is S. Big Or Small? S. Small Or Large? S Big Or Large. S Big or Small. to the minus 6, 10 to the 3, and then this is the log of maybe 100, which is, like, 4 or 5. Is it closer to 4 or5? I don't know, but it doesn't matter. We'll say 5. This is indeed much less than 1. So indeed, weIndeed, we indeed, will say 5, and we'll say that this is indeed. much more than 1, and that we will say that we are in fact in a better position than we were before. don't have to worry about clonal interference. This is a wonderful simplification. What it's saying is that the population is dividing. Every now and then, a mutation occurs in the population. It could be either the 0, 1 or the 1, 0. But in either case, the fate of that is up to the individual. That's the way it's always going to be. It's not going to happen all the time, of course. But it's a good start. mutation is resolved before the next mutation occurs. So you don't need to worry about them competing in the population. Instead, just at some constant rate they're appearing. And given that they appear, there's some probability that they're going to fix. So that leads to effective rates going to each other, which is what we're seeing in this case. It's not a big deal, but it's a good idea to keep an eye on it, because it could happen again. of those two steps-- going to 0, 1 or 1, 0. And in particular, this is like a chemical reaction, where we have some chemical state here. And what we know is we know the ratio of those rates. And that's everything we need to know to calculate the relative probabilities of taking those states, because the probability of going through to 0,. 1-- we want to go that direction--0, 1, is going to be given by k 0,1 divided. by k 0, 1 plus k 1, 0. So this is how we get 1/6 instead of 1/5. So it's like 1, and then 1, 5. But this is actually, in principle, not quite answering the question that I asked, because this is 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 113. talking about the relative probability of the first state, the first mutant to fix. In principle, it is possible that from there, there's some rate of coming back. Or they might not necessarily move forward on up that hill. Do you guys understand what I'm talking about? Because it goes. Because it's possible that it's not going to be as easy as we think. It could be a lot harder than we think, and it could take a long time to get there. from here to there. Because we really want to know about this next step, going to the 1, 1 state. But in this case do we have to worry about going backwards? No. And why not? It's very unlikely. And in particular, you could think now that you're here you could go back to where you came from. But that's not what we're looking for. We want to get to the next step. We're looking forward to seeing what's next. can talk about the rate of going to the 1, 1 state. And those are going to be exponentially different. Because just as this was a non-neutral beneficial mutation, that means that going from 0, 1 back is going to go from 0 to 1 in a matter of seconds. That's what we're going to see in the next few years, if we're lucky enough to get the mutation back in the first place. It's going to take a long time to get it back to 0, 0. be a non-neutral deleterious mutation. So the probability of fixing it in the back direction is not 0, but it's exponentially suppressed. I think it's very important to understand all the different pieces of this kind of puzzle, because it incorporates many different ideas that we've talked about over the past few years. It's a very complex problem, and it's going to take a lot of work to fix it, but we think we've got a good idea of how to do it. last few weeks. If there are questions, please ask now. Yes. AUDIENCE: What about the [INAUDIBLE]? [INAudIBLE] 0, 0 to 1, 0, 1? Then it seems like the benefit of 1,0 versus 1,1. PROFESSOR: All right, so you're wondering about-- so the fitness of the 1, 1 state was 1.2. So you're pointing out that it's actually easier to go from the 0,. 1 state to the 1,. 1. So if anything, in some ways, this actually provides a bias going towards the 0, 1 state. In practice, it doesn't actually matter, because this acts as a bias. It's saying that if we do get to 0,1, it's actually easier to move forward as compared to this other path. But in the long run, this doesn't matter as much as it would have in the first place, if we were to go straight to the top of the list. a ratchet. Because all these mutations are non-neutral, once you fix this state or this one, you can't go back. So the population will move forward once it gets to one of those two states. Now I mean, it would be a very interesting question to ask if we instead of a ratchet would we instead use a machine that would move the population around? I don't know. It would be very interesting to see how people would react to the idea of a machine moving the population. did a different arrangement. What would the rate of evolution be, and so forth? Yeah, but what you're saying is certainly true, that if this took up all of the benefit going here, then it may not actually be somehow an optimal path in terms of the rates of evolution. It may not be the best way to go, but it may be the most efficient way to get the most out of the resources we have at our disposal. We'll have to wait and see. or something like that. I'll think about that when designing. Problems. AUDIENCE: In this system, 0, 0 eventually becomes 1, 1. PROFESSOR: That's right. So the probability is 1. And we are guaranteed that we will eventually evolve to this peak in the fitness landscape. And so we will reach this peak. And And so on and so on, until we reach the peak of our fitness. And then we will evolve to the next peak. so what we're asking here is which of these two paths is going to be taken. Audience: Yeah, so how to mathematically prove that the system will go from 0, 0 to 1, 1? PROFESSOR: I mean, I feel like I kind of proved it, although I understand that nothing will happen. I'm not sure what the answer is, but I think it's something like 1, 0, 1. I think that's the way it's going to go. I said was rigorous. And of course, there are non-zero probabilities of going backwards. It's just that they are reduced. And actually, you can prove, for those of you who are interested in such things, that over long time scales, there's going to be an equilibrium that distribution over all. That's what I'm trying to prove. I'm not saying it's impossible, but it's not going to happen. I don't think there's any way to get there. these states, where the probability of being in a particular state will-- it goes as the fitness. It scales as the relative fitness to the Nth power. So we talk about these fitness landscapes as energy landscapes. And indeed, in this regime where you have small mutation rates, then it's a very good regime to be in. It's a good regime if you have a small mutation rate, because it's very likely that you will be in a certain state for a long time. going to be a detailed balance. And it's actually a thermodynamic system. So then in that case, you can make a correspondence between everything that we normally talk about, where fitness is like energy and population size is like temperature. So the relative amplitude of being in this peak as well as the peak of the population is the same as being in a peak in fitness. And so you can see that it's a correspondence with fitness and population. It's a very detailed system. compared to the other states is going to be. The ratios of those things is, indeed, described by the ratios of the fitnesses. And it's going to go as kind of like 1.1 to the 1,000th power, which is big. Which means that the population has really been growing very fast in the state of New Hampshire in the last few years. It's been a big change for the state, and for the nation, in the past few years, as a whole. cohered at this peak in the finished landscape. Yeah. So if you want to calculate a problem going from 0, 1 to 0, 0, then [INAUDIBLE] that would just be-- I guess I'm not sure. PROFESSOR: OK. You want to know the rate that that's going to happen. AUDIENCE: Yeah. OK. PRprofessor: OK, you. want to. know the rates that that is going to occur. yeah. Yeah. Let's do that. So for example, let's imagine that we don't have-- so let's Imagine that we just have the 0, 0 and the0, 1 states, just so we don’t have to worry about going up the landscape. And so what we have is a landscape of 0, 1 and 0, 2 states. That's what we call a landscape. That’s what we’re going to call it. We’ll call it the landscape of zero. we have r is relative fitness 1 and 1.02. And times this s, 0.02, is the probability that it'll actually fix in the forward direction. And the probability of fixation is-- there was this thing X1, which was X1. Well, the beginning part's the same, because we have mu N is the rate that you get this deleterious mutant in the population. But then we need to multiply it by the probabilities of fixation. And now what we want to know is the rates of coming back. 1 minus-- now this is r, but it's r in the other direction, so be careful. Because the general equation was 1 over. But now r, instead of being 1.02, is 1/1.02. So which of these terms is going to be dominant? This thing gets up to be some really big number is our problem. So we should be able to figure this out, though. Because this new r is 1-1-1, or 1 minus 1.01 to 1,000. So we end up with 0.02-- AUDIENCE: 200. PROFESSOR: Is it 200? Yeah, you're keeping only the first, which, since it's much larger than 1, it's bigger than 200. Right? I mean do you guys understand what I'm saying? You can't keep just the first term in a series. If you do, you'll get to keep the whole series, right? Right? You'll keep the entire series. Right?" the terms grow with number. AUDIENCE: [INAUDIBLE] squared, 3.98 or something. PROFESSOR: Wait, which one? Audience: 1.02 to the 1,000.PROFESSor: It's 4? OK, all right. OK, so it's 1 minus 4. So it's 2/300. So there's less than a 1% probability of the terms growing with number, right? OK. So this is teamwork. it fixing. Is this believable? AUDIENCE: It's about right. PROFESSOR: 2, 1,000, 50-- I think that you did it 1.02 to the 100 rather than 1.01 to the 1,099. AUDience: No, it's 3-- [INAUDIBLE]. PROFessor: 4 times. It's 3 -- [INAudIBLE]. It's 1.0 to the100. It is 1.1 to the1,000. Professor: 4 times 10 to the 8.10 to the8.10 doesn't make any sense. Audience: Oh, 4 times 8 to 8. 10 doesn't. Professor: Yes, sorry, I was just saying this doesn't-- so this is why I'm saying you always check to make sure that your calculation makes any sense, she says. "I never thought that my calculator would become so controversial," she adds. "It's just a calculator," she says, "but it's a good one." at all. So it's not this, but it's tiny, right? AUDIENCE: Yes, [INAUDIBLE]. PROFESSOR: Yeah, because this didn't make sense. Because this was of the same order as-- well, this would be larger than 1 over N, so it's totally nonsensical. Because 1 over. N would be the probability of winning the World Series, and this was the probability. of losing the World Cup, which was the same as this. fixation of a neutral mutation. This is a deleterious mutation. It's not even nearly neutral. So it has to be much less than 1 over N, right? So this whole thing is 10 to the minus 10, or something like that? OK, 4 times 10 tothe minus 8? Well, OK, whatever. So this times the probability of fixation, which is 10 minus 9-- this is how you would calculate the rate of going backwards. There's some rate that the mutation appears, and you multiply by the probability that it would. Professor: Can we handle a situation where [INAUDIBLE] interference is important at this point? Professor: Yeah, so this is what you do in.fix. And it's tiny. OK? All right, any other questions about how to think about these sorts of evolutionary dynamics with presence of mutation, fixation, everything? Yeah. Yeah. OK, that's a good question. And I'll be back in a few minutes with the next one. I'm looking forward to hearing from you. your problem set with simulations. You could probably imagine that [INAUDIBLE] calculate the probability that 1, 0 doesn't don't. Yeah. It gets really messy with clonal interference, I'll say. But, like, with basic-- I guess I was thinking about it and you couldProbably imagine that you could probably Imagine that you can do that with basic simulations. Yeah, I think that it getsreally messy withclonal interference. Yeah,. I think it gets really messier with clonic interference, but it's not that bad. arise first. In the limit, as you get more and more mutations, when clonal interference is really significant, then you're pretty much just guaranteed to take the 1, 0 path. Because if you have many mutants, the definition of clonal interfered is much more significant. The limit is when you have so many mutations that you can't even tell if you've got a mutant or a non-mutant. That's when you're in danger of losing control of the gene pool. is you have multiple mutations that have established. And if it's established, it's going to win. But the other thing is that as you go up in the mutation, you get more and more mutations. And once you have several mutations, then it's likely that one of them is going to be this. If it's not this, then the other one is likely to be the same thing. And that's what we're trying to find out. It's a very exciting time for us. rate, you don't even do successive fixations. So it may be that neither state ever actually fixes, because it could be that the 1, 0 state is growing exponentially, but is a minority of the population. And it gets another mutation that allows it to go to 1, 1. So you don’t even do consecutive fixations, you just do one after the other. That’s how you get a state that grows exponentially, and then you get another mutation to get it to a different state. as you increase the mutation rate, you don't have to actually take single steps. You can kind of move through states. And there's a whole literature of the rate at which you cross fitness valleys. So this is like tunneling in quantum mechanics or so. And it has a lot of a lot to do with the way we think about the universe. It's a very interesting area of research. I'm looking forward to finding out what the future holds for us in the future. of the same behaviors, in the sense of exponential suppression of probabilities as a function of the depth and the width of the valley you're trying to traverse. And there's some very nice papers, if you're interested in looking at this stuff. And one of them is actually in the Journal of Computer Science and the Social Sciences, which is published by the University of California, San Diego. It's a very interesting journal. It has some very interesting papers on the subject, and it's published in the journal of computer science and the social sciences. syllabus that I mentioned. I'm trying to remember who. It was Journal of Theoretical Biology, but I put it on as optional reading for those of you who are interested. All right, OK. So what I want to do now is I want them to switch gears, so we can think. I want us to think about what we are going to do in the next few weeks. We're going to be working on a new project. We'll be doing a project on the relationship between the human body and the environment. about this evolutionary game theory business. And I think the most important thing to stress when thinking about evolutionary. game theory is just that this point that we don't need to assume anything about rationality. Because the puzzles that we like to give each other in your dorm rooms Friday are just puzzles that you like to play with your friends in the dorm rooms on Friday night. That's just how it is. It's not about rationality, it's just a way of playing with each other, and that's how it works. night, you give these logic puzzles to each other. Is that-- I don't know. OK, let me just say, back when I was in college, that was, like, all the cool kids were doing it. But in these puzzles, you assume that there's hyper-rationality. You assume that if this happens to you, you're going to solve it. You're not going to be able to do it if you're not rational enough. You can't do it. guy knows that I did this, and that, and if I did that, he would do that. And then you end up, and then you have the villagers that are jumping off cliffs on the seventh day. Have you guys done these puzzles? No? OK. All right. Well. [LAUGHTER] So [LAUGHLY] So, [LA laughing] Well. So, well. So. So far, so good, I think. I hope you're having fun. The point was that people assume that when we're talking about game theory, you have to invoke this hyper-rationality even humans don't engage in. And I think that it's just very important to remember that we'retalking about evolutionary game theory in the case of, well, biological evolution. You don't assume anything about rationality. Instead, you simply have mutations that sample different strategies. And then you have differences in fitness that just lead to evolution towards the same solutions of the game. So it's evolution to the game solutions, so the Nash equilibrium, for example. think that the cells are engaging in any sort of weird puzzle solving. Instead, they're just mutations. And the more fit individuals spread in the population. And somehow, you evolve to the same or similar solutions, to these Nash equilibria in the context of game theory. And we'll see how that plays out in the next few weeks as we learn more about how the cells work together in the wild, and how they evolve to find solutions to the puzzle problems they face. We'll have to wait and see. this plays out in a few concrete examples. Now, there are always different ways of looking at these games. One thing I want to stress, though, is that all the selection that we've been talking about in the last few weeks, that all is consistent with game theory in the game of football. It's all consistent with the game theory that we're trying to understand in this game. We're not trying to create a new game, we're just trying to find a new way to play the game. sense that the idea of the game theory is that we allow for the possibility that the fitness of individuals depends upon the rest of the population. Whereas in all these calculations we've been doing, I told you, all right, I just gave you some fitnesses. So I said, here, here. So he said, 'I'm going to show you what the fitnesses are for each individual' And he showed it to you. He said: 'Here. The fitness of each individual is based on the other individuals' And so he did. we have a 0, 0 state that has some fitness. 0, 1 has a higher fitness, and so forth. But in general, these fitness values may depend upon what the population composition is. And in that situation, then you want to use evolutionary game theory. In many cases, people just don't know what their fitness is, so they just think they are not good enough to live in a state of 0 or 1 fitness. That's a mistake. It's a very, very bad mistake. assume that you can do something like this. But you can't do that if there's this frequency-dependent selection. So it's just important. If the fitnesses depend on composition-- this is the case. This is the fitness landscape. And it's important to know how to look at it. It's a very complex system. It can't be described as some fitness landscape, because it's so complex. It has to be described in terms of frequency- dependent selection. And that's what we're looking at. population composition-- then you cannot even define a fitness landscape. For example, you can have situations where the population evolves to lower fitness. If I tell you individual 0, you measure its growth rate, whatnot, its fitness might be lower. Then there is no fitness landscape, just a population that is growing at a lower rate than the population it was designed to grow at in the first place. That is a very different type of fitness landscape than the one we are talking about here in the United States. 1. So this is genome, and this is fitness. Now, if I go and I measure the fitness of some other individual, different genome-- so another strain of bacteria or yeast or whatever-- and you say, oh, well, its fitness is 1.2, that's not true. This strain has higher fitness than this. So that's what I'm trying to get at with genome-to-genome comparisons. That's what we're trying to do with fitness. strain. Now, it would be very natural to assume that this strain will out-compete this strain. And indeed, that's been the assumption in everything we've been talking about. But it's not necessarily true. And that's the basic insight of evolutionary game theory, is that just knowing the fitness of a strain is not enough to predict the success of a new strain. It's not a given that the new strain will succeed the old one. It can be a surprise. pure population is not actually enough information to know that it's going to be selected for. Because it's still possible that in a mixed population, the genome 0 may actually have higher fitness than the genome 1. And once you kind of study these things, it's kind of clear that it is not going to happen, he says. "Once you kind Of Study these Things, It's kind Of Clear That It's Not Going To Happen," he says, adding that the study is just the first of many to come. it can happen. But then it's easy to then go back to the lab and forget that it's true. And so we'll see how this plays out. Audience: On this game theory, [INAUDIBLE]? PROFESSOR: No. That's the other thing, is that I like to just draw these things as graphs, and so I can see what's going on in the real world as well as in the game theory world. It's a little bit of both. because I think it's much easier to see what's happening. And it's clear that things can be non-linear. But the basic insights are all intact. From my standpoint as kind of an experimentalist-- don't forget about the exam-- I think that the more formal evolutionary game theory thing-- these two-player game theory things are much more interesting to look at than the one-on-one game theory. I think they're much more exciting to study. I'm a little bit of a game theorist. games that you guys just read about-- I think they're important because they tell you what are the possible outcomes of measurements or of systems, even in the most simple situation where everything's linear. Now, when things are not linear, of course you can get even richer dynamics. But in in games that are linear, you can't really get a lot of insight into what's going on in the system. It's very hard to get a sense of what's happening in a game that's not linear. practice, you basically get the categories of outcomes that we saw there. So maybe what I'll do is-- so what we're going to do is think about competition between two individuals A and B. And often, we talk about these things in the context of two-player games, where we we play against each other. But in this case, we're playing against ourselves. We're playing ourselves against ourselves, and we're trying to outdo each other in terms of our own performance. have A, B, C, D. And because this is really importing the kind of approach, or the nomenclature, from conventional game theory. And then immediately applying it to populations where you just assume that all the individuals have equal probability of interacting with everybody in the population. So it's what it's like to be in a group of people who are all playing the same game at the same time. It's what we call a 'game of chance' or a game of chance. you would get if you just had some two-player game like they study in game theory, but in a population of 1,000 or whatnot. You just made a bunch of random pairwise interactions. You had them play the game. And then you had them do that again over time. And that's what you get in a game of this kind of game theory. It's a very complex game, but it's a game that you can play with people in any way you want. The payouts that you read about in Chapter Four are kind of what would happen in that sort of situation, where everybody's interacting with everybody else with equal probability. Depending upon the strategy that these guys are following, you get different payouts. And this is telling us about the payout that the A individual gets depending on what he does, and depending upon what his opponent does. Now, we're not explicitly saying what the payout to the B individual is, but we're assuming that this is a symmetric game, so you could figure it out by looking at the opposite entry. a fitness, whereas B also gets little a fitness, because it's a symmetric game. So the case it's different is when we're in the diagonals. And from this framework, you can see that there are going to be already a bunch of kind of non-trivial things that can happen, even if it's just in the first few minutes of the game. That's the kind of stuff that we're going to see in the next few games, I'm sure. in this regime where everything's linear. And the probably best well-known of these is this Prisoner's Dilemma, which is the standard model of cooperation in the field of game theory. So there's a story that goes along with it. It's this idea that-- I'm sure you guys watch these cop shows, right? It's like, "Oh, my God, what's going on here?" And it's like: "Oh my God. What is going on?" shows, where you have the cops bring in the two accomplices. And then they put them in separate rooms. And they tell them that they have to confess to committing the crime, because the guy in the other room is confessing. If he doesn't confess, then he's going to be killed by the other guy. That's what happened in this case. And that's what happens in this one, too. It's a little bit like that, but it's not the same. be in trouble, et cetera. You've seen these cop shows? And incidentally, in these questions, when cops are questioning witnesses, they're actually allowed to lie to the person being questioned, which feels a little bit weird, actually. Doesn't it? I know, I know. This is not relevant. So the idea is to make people think about what they're saying and why they're doing it. It's to make them think about how they're acting and what their motives are. of the prisoner's dilemma is that if you set up these jail sentences in the right way, then it could be the case that each individual has the incentive to confess. Both individuals would be better off if they cooperated. And you can come up with some reasonable sentences for each of them, he says. He adds: "You can come out with somereasonable sentences for both of them. And I think you can do it." He adds that it's possible to set up jail sentences that make sense for both people. payout structure that has that property. And we'll call this-- so this is for individual one, say and individual two. So there are different strategies you can follow. And do you guys remember from the reading slash my explanation how to read these charts? All right, now the question is, what is your strategy for getting the most out of your 401(k) or IRA or 403(b) or 401(K) account? If you have an idea, please send it to iReport.com. just to remind ourselves, what is the Nash equilibrium of this game? And I know that you read about it last night. Well, use your cards. Is it C or is it D? Or is there no Nash equilibrium, you can flash something else. Are those negative or positive? Are thosenegative orpositive? Well, I'm going to ask you to think about that. I'll be back in a few minutes with the next round of the game. Back to Mail Online home. "These are good things, OK? These are positive fitness," she says. "I kind of don't like the Prisoner's Dilemma as a story, because it's not very intuitive, because you have to actually specify the jail terms" "You have to remember that jail terms are bad, not good," she adds. "So these are goodThings" is CNN's weekly, offbeat look at what's happening in the world of television and film. For more, visit CNN.com/soulmatestories. years off that you get as a result of doing one thing or another. So at least we have a majority that are D, but it's not all of them. And I think this is basically a reflection-- and D is a reflection of what you want to do. You want to get big numbers. Ready? Three, two, one. One. Two. Three. Four. Five. Six. Seven. Eight. Nine. Ten. Eleven. Twelve. Thirteen. is indeed the Nash equilibrium. It's to do this strategy D that we're saying here. All right, now the question is why? And part of the challenge here is just understanding how to read these charts. Now, first of all, the payout that everybody gets if everyone follows strategy D is $1,000,000. That's what you get if you do strategy D. And that's what we're trying to do here. We're saying, 'Do you want to get $1.1 million?' And the answer is yes. is what? Verbally, three, two, one. One is just not the biggest number you see here. And indeed, the important point to note here is that 1 is not the most important number. It is just the first one. It's just the beginning. It will get better. It has to. But it's not the end. It can't be the end, because it's the beginning of a new beginning, and it's a beginning that will lead to a better future. if both players had followed this strategy C for cooperate, D for defect, then both individuals would be getting fitness 3, or payout 3. But the problem is that that's not evolutionarily stable. So the idea here is that both people would do better if they both played strategy C, but that's unlikely to happen in the long-term. If both people played strategy D, they would get fitness 3 and payout 3, but not fitness 2 or 3. That's not how evolution works. Or in the context of game theory, that is cheatable in some ways. A Nash equilibrium, what it means, if you recall, is that if everyone's playing that strategy, then nobody has the incentive to play that strategy. And so the reason that this is a Nash equilibrium is that you ask-- so a Nash equilibrium is that if you ask, what is the best strategy to play? And the answer is, it's to play a certain way, and if you play the right way, you win. change strategy. So no incentive to change strategy. The question is whether you as an individual would have the incentive to switch. So now you just imagine, let's say, that you're playing against somebody else, or in the context of biology, it's a population of individuals following the D strategy. It's a question of whether you would want to do that, or if you would be able to do it if you were playing against someone else who was following a different strategy. That's the question. to the other strategy? And the answer is no, because what you have control over is this rows. The column is specified by the rest of the population. So if you're in this state, whatYou have a choice of is to switch to the cooperate strategy, which would be 'Cooperate' instead of 'Coalition' 'Cooperation' would be the strategy used by the majority of people in the state at the time of the game. 'Cooperative' would mean 'cooperate with the majority' rather than 'cooperation' to go up here. So you have a choice to move up to this 0 payout, but that's not to your advantage. Now, it's true that your opponent would get payout 5, so you opponent would actually do wonderfully. But you would do poorly. So, you'd be selected against, if you were to go up to 0 payout here. You would be selected to be the person your opponent was playing against. You'd be playing against your opponent for the first time in the game. you imagine this being in the context of biology-- that you have a genotype that are playing D. If you're a mutant that starts following this strategy C, you have lower fitness, so you're selected against. So that's saying that the strategy D is noninvadable. We can also think about what happens if we're a population of cooperators. Now everybody has high fitness-- fitness 3. Question: What happens if there's a mutation that leads to one individual following the D strategy? Is he selected four or not? really like drawing the graphs of these things, because I think it's just much more clear. And you can either draw the fitness of the two types minus each other, or just the raw fitness. Yes. AUDIENCE: So what if instead of 5, you have 7? Because then the population is 7, too. Yes, that's what it would be like, too, if you had 7 people instead of just 5. Because then, you know, the population would be 7 as well. as a whole's fitness decreases when you [INAUDIBLE]. So how does that-- PROFESSOR: So you're saying if this 5 were a 7 instead? AUDIENCE: Yeah. PROFessor: Right, then what you are saying is that-- so it doesn't change. The Nash equilibrium is still defect. The subtle thing here is that, in in the Nash equilibrium, the fitness of a group doesn't go up or down, it just goes down. general, in terms of game theory, we like it when the mean of these two is smaller than this one. That's why you're asking, right? Exactly, because that's right. So yeah, so that's a slightly more complicated situation, because in that situation, then, if you had two rational people, you would have a rational game. Exactly, right. Exactly. So that's what we're trying to get at here. We want to get to the root of the problem, which is that we don't know how to play the game. agents, say, playing this game, then you could alternate cooperation and defection. And that would actually be the ultimate form of cooperation in such a game, because you could actually get a higher payout by alternating. Right, so we've chosen the numbers as they are so that this is subtlety. We've chosen a number so that it is subtle, and the numbers are chosen so that there is a subtlety to the game. We're not going to reveal the numbers, but we're going to show you how the numbers work. is not an issue. Does everybody understand the issue there? So in the context of evolutionary game theory, what we can do is we can plot as a function of the fraction of the population that's cooperator between 0 and 1, say. We can plot the payout for the person who cooperates the most. And we can use that to work out what the payout should be for the cooperator who cooperated the least, say, in a game of poker. And that's how we work out the payout. Cooperator and defector lines should have y-axes on either ends. "Do you understand? So what should these things look like? I'd like to ask you," he asks. "For example, I'm going to draw a solid line for the cooperator, dashed lines for the defector. Now the question is, what should be the y-axis on either end and so forth? Do you understand?" "Yes, I do," he says. "So what should they look like?" "I'll draw them for you." encourage you to-- I'll give you 30 seconds to try to draw what this should look like. So this is the payout or the expected payout. So we're assuming that you're going to interact randomly with the other members of the population as a function of the fraction cooperator. So I'm going to ask you to draw it for 30 seconds and then I'll show you what it looks like. If you get it right, you get the payout. If not, we'll show it to you again. then 1 minus that will be the fraction defector. Do you understand what I'm trying to ask you to do? AUDIENCE: So the scale on the right-hand side supposed to be for the defectors? [INAUDIBLE]? PROFESSOR: This is just a legend, or key, or something. So I want you to 1 minus 1 to get the defector scale. The scale is based on the number of people who have defected in the past year. draw something over here that's a solid line and a dashed line. AUDIENCE: All right, so it's just one scale. And you don't-- PROFESSOR: It's one scale, sorry. I'm just telling you what's going to be asolid line and what'sGoing to Be A dashed line, and I'm going to show you what it looks like to draw it on a scale. It's a one-to-one scale, and that's what I'm showing you. dashed line. And I'll give you a hint, that up here is number 5. This is going to be the expected payout for a lone individual given the rest of the population is following some fraction of cooperator. Do you guys understand what I'm asking you to do? Because I'm not telling you what to do, I'm just telling you how to do it. You're going to have to do what I say, and I'm going to show you how it's done. a little bit concerned that there are very few plots in front. AUDIENCE: What is fc? PROFESSOR: So this is the fraction of the population that's cooperator. Well, I was giving you a chance to think about it. But from looking around, I think that maybe you're not quite sure about fc. But I'm sure you'll get used to it in a few years. It's just a matter of time before you start using it. what I'm trying to ask you to do. So I'm Trying to plot the expected payout for an individual that is either cooperating or defecting, based on the fact that the rest of the population has some composition between all cooperate or all defect. So it's the evolution game theory. And that's what I'm asking you to try to do as well. And I'll let you know if you succeed or fail to do so. And if you do, I'll give you a prize. extension of this simple model. So first, we can ask, well, if the entire population is cooperating, we want to know the fitness for a cooperator or defector. Well, this is really just saying that we're all the way over on here, and we just choose between the two. And so on. And on. and on and so on, and on until we get to the point where we know what we're doing, and then we can do it. the defector is the 5 one. So this is going to be a dashed line that's going to start from here. And then this is 2 and 1/2, 3. Do you understand what I'm? Now, OK, let's see. So now this is the one where if everybody else is defecting, well, now, the cooperator line goes to what? Verbally, three, two, one. OK, that line, I started going the wrong direction. is an example of what this looks like for the Prisoner's Dilemma. And what you see is the defector fitness is always above the cooperator fitness. So for any population composition, defectors have higher fitness than cooperators. So evolution brings you to the pure defecting state, where you have fitness that is above that of the cooperators, and that's what we're looking for in the Prisoners' Dilemmas. For more information, visit the Prisoner's Dilemma website. 1. And if you want, you could calculate what the mean fitness of the population is, for example. 2. And themean fitness starts out over here, and ends up over here. So the mean Fitness decreases over time. Now, you can imagine that in the simple, two-player models, all these all these mean fitness numbers are the same. But in the real world, they could be very different. For example, in a two-person team, the average player's mean fitness would be lower than in a one-player team. are lines. But you can imagine that the only thing that's important are how these lines cross each other. So for example, there are only a few different things that can happen. You can have one strategy that dominates, which is what occurred here. And surprisingly, that does not mean that it's a good strategy. It's just that it doesn't always work out the way you want it to. That's what happened in this case, and that's what we're going to focus on. that that strategy is higher fitness, in the sense that you may evolve to a state of low fitness. That's what's weird. You can have coexistence, or you can have bi-stability. So now we're just going to have two strategies. The strategies-- The strategies are coexistence and bi-Stability. And that's weird, too, because you can't have either one of them at the same time. So I'll give you another example of this. we'll just call them A and B. And the question is, what is the Nash equilibrium? Is it A, B, or C should be neither, D is both. Do you understand the question? I'll give you 30 seconds to think about it. All right, are we ready to vote? Ready, three, two, one. Allright, so we have a fair distribution. I may not be able to give you the answer you want, but I'll try. have us vote, but yeah, in this case, they're actually both Nash equilibria. So let's see this. If both individuals, or an entire population, say, is playing A, they's getting fitness 5. Question is, as a lone individual, you can choose to switch over and get fitness 3. Do you? Do you want to switch to fitness 2? Do we have to choose fitness 1 or fitness 2 or fitness 3? We'll let you decide. want to do that? No. So that means that A is going to be a Nash equilibrium. Incidentally, the difference between the so-called regular Nash equilibrium and the strict Nash equilibrium is that Nash equilibrium means that no individual has the incentive to change strategy. A strict Nash equilibrium means that no one has the incentive to change strategy in the first place. It's called a strict Nash equilibration and it's the same as a regular Nash equilibrium in that it means no one can change their strategy. that any change in strategy leads to an actual decrease in fitness. So it's a question of whether you can make neutral changes in strategy or not. So A is a Nash equilibrium. What about B? Well, in that case, everybody's getting to fitness 1. Now, as a lone individual, what can you do? All you can do is switch. As an individual, you can only choose rows. So you go up to 0. That's a decrease of fitness. That means that strategy B is also a Nashilibrium. So there are two Nash equilibria in this game. And what does that mean about which regime you're in here, if you convert this into an evolutionary game theory scenario? Ready, three, two, one. OK, so a majority is saying yes. This is indeed a situation in which you have bi-stability. So what does it mean in this case? Well, it means that you have a regime that is bi-stable. And that's a good thing, because that means you have to work together. terms of these lines if we draw them? So this is payout as a function of the fraction that is playing the A strategy. Should the lines cross? Yes or no? Ready, three, two, one. AUDIENCE: Yes. PROFESSOR: Yes, and indeed, in principle, the math that we do in all of this is the same as the math we use in all other situations. We're going to use the same math in this case as we did in the previous one. these situations is kind of super simple. Yet it's easy to get confused about what's going on in all these situations. So the idea here is that if the population is A, that means that the A here is at 5. But then it goes down to 0. Whereas over the years, the population has grown to a level that is above and beyond the A level. So that's what we're trying to get at here. We want to make sure that we don't get to the point where the A is lower than the population. here, B here is 3. And then it goes to 1. Because these two lines cross, does that mean that you have bi-stability? Ready, yes or no, three, two, one, AUDIENCE: No. PROFESSOR: No, and why not? Audience: [INAUDIBLE]. PROFessor: That's right, because you can also do the other thing, that's bi-Stability. And that's what we're looking for. and then that leads to coexistence. Now, in some ways coexistence is the most subtle of the situations. And that's for an interesting reason. Audience: Sorry, sir, you said you can also do the other thing. What is the otherthing here? PROFESSOR: I'm saying that these things can cross. And then that leading to coexist. And I'm not saying that it's always easy, but that it can be possible. And it is possible to do it. in the other orientation. Let me put a matrix out there, and then-- so this is something that, for example, is what's known as a Hawk/Dove game. Or it has many other names. And we can maybe figure out what would be the Hawk strategy, and what's the Dove strategy. It's called a "Hawk-Dove" game, or a "Dove-Hawk" game. It has many different names, but that's what I'm going to call it. Now, we want to ask the same question-- is A a Nash equilibrium? Is B a Nashilibrium? Is it neither? Or is it both? And maybe I shouldn't have covered this up, so you're not influenced, in case you actually did do the reading. Then I don't want to talk about it again, because I'm not sure if you've done the reading, or if you're even aware of it at all. If you are, then I want you to read on. you to be influenced by this. So think about it for 30 seconds. Do you need more time? Let's go see where we are. Ready, three, two, one. All right, so most of the group is agreeing in this case, neither are the Nash equilibrium. So neither are a Nash equilibrium, so neither are we a Nash. So we're not Nash-equilibrium. We're not a Nash- equilibrium, we're just not Nash. We don't know how to get there. equilibrium. Does that mean that this game has no Nash equilibrium? Yes or no, verbally-- ready, three, two, one. Audience: No, it does not mean that. This game has a Nash equilibrium. And indeed, all games like this have Nash equilibria. And this is what Nash won the game of chess over. The game was called "The Game of Life" and was won by George W. Bush in the first game of the World Series of Poker. Nobel Prize for, so this is the famous one-page paper published in PNAS. If you look at it, I have no idea what it says. I mean, he basically just pointed out that this theorem implies this, implies that-- done. And so it's good that somebody knew what he was, because it was good that he was able to say what he wanted to say. It's a good thing he got the Nobel Prize for what he did, because he got it right. saying, otherwise we'd be in trouble, all of us. So what he proved is that such games, even with more players, more options, and so forth, they always have such a solution in this sense. There exists some strategy such as if everybody were playing in, nobody would have the solution, he says. "There exists some Strategy such that if everybody are playing in. nobody would be able to have the answer," he adds. "That's what he did. That's why he won." incentive to change strategy. But you have to include so-called probabilistic or mixed strategies. And we can draw what this thing is. So just like always, so everyone else is following A, then A starts here at 3. And then it goes to 1. Whereas the B individuals start at 2. And so on and so on. But we can see what this is, and it's a very complex thing. It's not just a straight line. It has to be a series of steps. "In this situation, we had bi-stability. So if you look at the direction of evolution, depending upon where you start, you go to either all B or all A. So this looks very similar to that, but they're rather different, in the sense that in this situation,. we hadBi-st stability. and they go to 0.5, and they went to 0,0.5. So it's very similar, but it's not the same thing. Whereas in this situation over here, we have coexistence. Does not matter where you start. So long as you have some members of both A and B in the population, you'll always evolve to the same equilibrium. Now, the important thing here that's, I think, interesting is that in a situation like this, in a population of people, you have to have both sides of the coin. You have to be able to work with both sides to get the best out of each other. population, if you have genetic A's and genetic B's that are each giving birth to their own type, then you evolve to some coexistence of genotypes. So here, this is some fraction. f a star is the equilibrium fraction, fraction of A in the population. So this is a case where this is the case for the A population. The B population is the other side of the same coin, and it's the B population that is the most likely to evolve into A. where you have genetic diversity that leads to phenotypic diversity in the population. Whereas the mixed Nash equilibrium-- this is a situation where you have, in principle, genetic homogeneity. So this is an example of a single genotype that is implementingphenotypic heterogeneity. And indeed, one of the things that we've been excited about is the potential for this to be used in a variety of ways in the future, including in the development of new drugs, for example, or in the design of prosthetics. Isogenic populations of microbes can exhibit a diversity of phenotypes as a result of, for example, stochastic gene expression and bi-stability. So that's a molecular mechanism for how you might get heterogeneity. Another question is how do we get rid of isogenic populations? That's what we're exploring in my group is this distinction here, where it's known that in many cases, isogenic population can exhibit diverse phenotypes. We don't know the answer to that question yet. is, what is the evolution explanation for why that behavior might have evolved? Now in general, we cannot prove why something evolved, but we can make educated guesses that make experimentally testable hypotheses. And for example, in the experiment that we've been doing, we have been looking at bi-modality in expression. We've been looking to see if there is an evolutionary explanation for bi-Modality in Expressions. And we have found that there is, in fact, an evolutionary reason for this. of the galactose genes in yeast. And that was still a problem set in early-- oh, no, we removed that one this year. Well, so experimentally yeast, in some environments, bimodally or stochastically activate the genes required to break down the sugar galact sugar. And what we've demonstrated is that if you do that, you can break down that sugar in a way that makes it more easily available to other organisms. That's what we found. you make the mutants that always turn on or always don't turn on these genes, then they're actually playing game where you actually get this exact thing. So that's saying that maybe the wild type that follows this stochastic, mixed type of evolution is the one that is most likely to be the "wild" type. The wild type is the type that is more likely to evolve towards coexistence of those two strategies. That's the kind of evolution I'm talking about. I think that's the way to go. strategy-- it may be implementing the solution of some game that is a result of such frequency dependence. There are other possible explanations to this. In the coming weeks, we'll talk about this idea of bet hedging-- that given uncertain or fluctuating environments, it might be advantageous for clonal populations to hedge their bets. We'll also talk about the idea of clonal population genetics and how it can be used to predict future population growth or loss of genetic variation in a population. to have a variety of different strategies to cope with that uncertainty. So we'll talk about those models later. But since we're talking about mixed strategies now, I wanted to mention that. Yeah. AUDIENCE: So f a star, just to be sure, is going to converge to this probability [INAUDIBLE]? So we're going to talk about these mixed strategies later. Yeah, we are. We are going to discuss mixed strategies. We will talk about them later. Professor: Heterogeneity can be implemented either way. It's either coexistence of genotypes following different strategies. It could be one genotype implementing both, or it could be a mixture of those, actually. What's interesting is that any genotype can be used to create a population of this kind of population, professor says. The study was published in the Proceedings of the National Academy of Sciences, published by the University of California, Los Angeles, and published by Oxford University Press. individual in the population following any strategy has the same fitness. And of course, that's kind of why this was in equilibrium. This equilibrium is when the two strategies have equal fitness. But the funny thing is, what that means is, it doesn't matter what you do at the equilibrium. It's just that you don't have to do anything at all to get to the same level of fitness as the other strategy. That's what we're trying to achieve here in the study. Depending on how you look at it, it's either super deep or super trivial. But it's a weird thing that if your at the equilibrium, or if the population or the opponent is playing this Nash equilibrium in these games, then it just does not matter what you do. You don't have to do anything. You just have to play the game the way you want to play it. It's either that or it's not very interesting at all. I don't know how to explain it. can do A. You can do B, actually, in any fraction. So since A and B have the same fitness, you can choose between them at any frequency you want. And indeed, indeed, if the rest of the population is playing this mixed Nash equilibrium, you could do both at the same time. You could do A at any time you want, and you would both have same fitness. So you can do A, and B, and A could do B at any times you wanted. in this there are nice conditions for what makes it this Nash equilibrium. And I'm going to just highlight that you should make sense of why it means what it is. So if the payout, the expected fitness or payout-- if you're following the Nash equilibrium against Nash equilibrium-- is is Nash equilibrium, then it's a Nash equilibrium as well. And so that's what we're trying to do here. We're looking for a Nash equilibrium that is Nash-like. And we're going to try to get there. equal to this guy. So that's what I just said-- that it doesn't matter what you do. If everyone else is doing p star, you have the same fitness. That's saying it's a Nash equilibrium. Whereas there's another interesting kind of statement here, that-- AUDIENCE: [INAUDIBLE]? That you can't.equal to that guy. That you don't have to do the same thing as everyone else to be a p star and be a great athlete. unilaterally increase your fitness by switching. It's an equality, which means it is a Nash equilibrium. Because it's saying that you don't have the incentive to change strategy. So it's true that you're not dis-incentivized. But it's not a strict Nash equilibrium, so it's a different kind of Nash equilibrium than the strict one you're used to. And that's what we're trying to get at here. We're not going to get there right away. Well, it has to be greater than/equal to, and it's actually equal to. The condition it's greater than or equal to, but not greater than, is called a Nash equilibrium. So this is the Nash equilibrium for that situation, [INAUDIBLE] strategy. That's right. It's a Nash equilibrium for that situation, and that's what we're trying to get at here. We want to get to the point where it's equal to or greater than what it is greater than. And that's the Nash  equilibrium. not the definition of that. But this thing is true, which means that it's a Nash equilibrium. And this other thing that's interesting is that-- so this tells us that it is actually one of these ESS's. And if you have questions about this, I'm happy to answer it. It's explained. It is true. But it is not thedefinition of that, but it is a Nash equilibrium which means it is one of those ESSs. in the book as well. We are out of time, so I should let you go. But good luck on the exam next Thursday. If you have questions and you want to meet with me, I'm available on Tuesday. So please let me know. Back to Mail Online home. back to the page you came from. Back To the pageYou came from: Back to thepage you came From: Back To The page you Came From: The Story Behind The Story, by David Walliams, is out now.