experiment_name: "cluster_with_dbscan_eps03_min_samples2_segment_150"

mini_batch:
  size: 4
  # N means the number of cluster text in one inference
  # strongly recommend to set N to half ~ two-thirds of your VRAM(GB)

data:
  source: "youtube" # "opensource"
  opensource: "ccdv/govreport-summarization"
  youtube: "WhiteboardLLM/Data"
  index_set: 3

segment:
  args:
    n_word: 150
    n_overlap: 0
    fix_size: False

concat:
  method: "concate_clustering"
  args:
    eps: 0.3
    min_samples: 2

summary:
  args:
    min_length: 100
    max_length: 1024

save_summaries: True