that we are going to be looking for in an estimator, trying to find them to be unbiased. But we'll see that it's actually maybe not enough. So unbiasedness should not be something you lose your sleep over. Something that's slightly better is the risk, really the quadratics risk, which is expectation of-- so if I have an estimators, theta hat, I'm going to look at the expectation of theta n minus theta squared. And so for different thetas, some estimators are better than others. The total variation distance between probability measures is central to probabilistic analysis. If the total variation between theta and theta prime is small, it means that for all possible A's that you give me, then P theta of A is going to be close to P theTA prime of A. The problem is that we don't know what the total variations is to something that weDon't know. The goal was to spit out a theta hat, which was close such that P thena hat was close to theta star. So here's the strategy. Just build an estimator. PhilipPE RIGOLLET: Let me write the set A star as being the set of X's such that f of X is larger than g of X. So that's the set on which the difference is going to be positive or negative. Rigollet: This, again, is equivalent to f ofX minus g ofX is positive. Everybody agrees? So this is the set I'm interested in. So now I'm going to split my integral into two parts, in A, A star. this constant is 0 for my purposes, or 25 if you prefer. All right. So we'll just keep going on this property next time. And we'll see how from here we can move on to-- the likelihood is actually going to come out of this formula. Thanks. Back to Mail Online home. back to the page you came from. Back from the page where you came From. Click here to go to the show page where we'll be talking about the probability of winning the lottery. PhilipPE RIGOLLET: What I want is to have a small bias, hopefully a 0 bias. If this thing is 0, then we see that the estimator is unbiased. So if I were to repeat this 1,000 times, so every one of those 1,.000 times they collect 124 data points and then I'd do it again and again, then in average, the number I should get should be close to the true parameter that I'm looking for. So this is definitely a property examples.