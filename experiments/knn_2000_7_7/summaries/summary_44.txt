Last time we talked about some of the kind of the bigger questions in deep learning theory. And today, we are going to start talking about the optimization perspective in deeplearning for two lectures. The main focus is to analyze what the functions you are optimizing look like so that you can use some trivial or some standard optimization algorithm for it. The bigger question we are trying to address here is that why many optimization algorithm are designed for convex functions. But why they can still work for nonconvex functions? by the users. So let's say suppose this is a matrix that Amazon maintains, and the other side is the item. And each entry is the rating of the user to the item, and every user probably have an opinion about every item. So that's why you have to recover all the rest of the entries to serve the users better in the future. And the most used method to solve this is basically nonconvex optimization to find this ground truth matrix M using the fact that you have a low rank structure.