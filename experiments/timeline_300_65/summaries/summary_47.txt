If I were to repeat this 1,000 times, so every one of those 1,.000 times they collect 124 data points, then in average, the number I should get should be close to the true parameter that I'm looking for. And so what I want is to have a small bias, hopefully a 0 bias. If this thing is 0, then we see that the estimator is unbiased. So this is definitely a property that we are going to be looking for in an estimator, trying to find them to be unbiased. But we'll see that it's actually maybe not enough. for sum of independent random variables, now it's time to wake up. So we have the variance of something that looks like 1 over n, the sum from i equal 1 to n of Xi. And so if I'm interested in the quadratic risk-- and again, I should just say risk, because this is the only risk we're going to be actually looking at. Yeah. This parenthesis should really stop here. I really wanted to putquadratic in parenthesis. So the risk of this guy is what? Well, it's the expectation of x bar n minus theta squared. the order in which I draw those curves. All right. So let's find-- I'm going to give you three candidate estimators, so-- estimators for theta. So the first one is definitely Xn bar. That will be a good candidate estimator. The second one is going to be 0.5, because after all, why should I bother if it's actually going to. be-- right? So for example, if I ask you to predict the score of some candidate in some election, then since you know it's going. to be very close to 0. 5, you might as well just throw0.5 and you're not far from reality. The bias is 0 and the variance is equal to theta, 1 minus theta divided by n. The second number is better for the other guy, so I will definitely go for this guy compared to this guy. The bias is actually-- just for simplicity, I can think of it as being X1 bar, the average of itself. And I have the variance that's actually n times smaller when I use my n observations than when I don't. So this guy is gone. The risk is really telling you how much fluctuations I have around average around the theta. The bias doesn't count in the risk. So if you're sure-- let's say you're talking about presidential election, you know that those things are going to be really close. Maybe you're actually better by predicting 0.5 if you know it's not going to go too far. But that's for one observation. But if I look at the risk of Xn, all I'm doing is just crushing this curve down to 0. can be large. Or you have 0 bias-- you have a bias, but the variance is 0. So you can actually have this trade-off and you can find things that are in the entire range in general. Those things are actually-- those trade-offs between bias and variance are usually much better illustrated if we're talking about multivariate parameters. In this class, it's mostly one-dimensional parameter estimation, so it's going to be a little harder to illustrate that. But if you do, for example, non-parametric estimation, that's all you do. what a confidence interval is. And so we fixed a statistical model for n observations, X1 to Xn. The parameter theta here is one-dimensional. Theta is a subset of the real line, and that's why I talk about intervals. A confidence interval of level 1 minus alpha-- so we refer to the quality of a confidence intervals is actually called it's level. It takes value 1 minusalpha for some positive alpha. The closer to 1 it is, the better the confidence interval. The probability that I contains theta is at least 1 minus alpha. So it better be close to 1, because it's really telling you that whatever random variable I'm giving you, my error bars are actually covering the right theta. If you want this to hold for every n, you actually need to use things such as Hoeffding's inequality that we described at some point. So here is the example that we had. So the sample average, Xn bar, is a strongly consistent estimator of p. also to some standard Gaussian. We've seen that when we saw Slutsky as an example. And so those two things-- actually, just because I'm taking the limit and I'm only caring about the asymptotic confidence level, I can actually just plug in consistent quantities in there, such as Xn bar where I don't have a p. And that gives me another confidence interval. So this by now, hopefully after doing it three times, you should really, really be comfortable with just creating this confidence intervals. is no. The only thing you're losing is the rate of convergence of the central limit theorem. Of course, the price you pay is that your confidence interval is wider than it would be if you were to use Slutsky for this particular problem. So it depends on how comfortable and how critical it is for you to put valid error bars. If they're valid in the asymptotics, then maybe you're actually going to go with Slutky so it actually gives you slightly narrower confidence intervals. how critical it is for you to output valid error bounds or if they're really just here to be indicative of the precision of the estimator you gave from a more qualitative perspective. What is the slope of the function 1 over square root of X1 minus X around the value you're interested in? And so if this function is super-sharp, then small fluctuations of Xn bar around this expectation are going to lead to really high fluctuations of thefunction itself. Its derivative really is what matters. When we do maximum likelihood estimation, likelihood is the function, so we need to maximize a function. And if I give you a function, you need to know how to maximize this function. Sometimes, you have closed-form solutions. You can take the derivative and set it equal to 0 and solve it. But sometimes, you actually need to resort to algorithms to do that. And we'll briefly touch upon it, but this is definitely not the focus of this class. OK. So we'll do a little bit of reminders on those things. When you compute probabilities on one distribution, you should have the same probability on the other distribution pretty much. So what we can do is say, well, now I have two candidate distributions. So if theta hat leads to a candidate distribution, and this is the true theta star, it leads to the true distribution according to which my data was drawn. That's my candidate. As a statistician, I'm supposed to come up with a good candidate. And what I want is that when I'm computing probabilities for this guy, I know what the probabilities for the other guys are. The probability that X is equal to little x is 0 for a continuous random variable, for all possible X's. There's just none of them that actually gets weight. So what we have to do is to describe the fact that it's in some little region. So I have this density, such as the Gaussian one. And the probability of X falling to some subset of the real line A is simply the integral of the density on this set. That's the famous area under the curve thing. The total variation has some properties. So let's keep on the board the definition that involves, say, the densities. So think Gaussian in your mind. And you have two Gaussians, one with mean theta and one withmean theta prime. And I'm looking at the total variation between those two guys. So if I look at P theta minus-- sorry. TV between P thena and P thea prime, this is equal to 1/2 of the integral between f theta, f thena prime. The total variation equal to 0 implies that P theta is equal to P theTA prime. If this thing being small implied that P. theta could be all over the place, that would not help very much. The fact that you need two definitions of the [INAUDIBLE],, is it something obvious or is it complete? PHILIPPE RIGOLLET: I'll do it for you now. Let's just prove that those two things are actually giving me the same definition. PhilipPE RIGOLLET: The set A star is the set of X's such that f of X is larger than g of X. That's the set on which the difference is going to be positive or negative, he says. He shows that if he takes any other A in this integral than this guy A star, it's actually got to decrease its value. Rigollet: The first one has to be larger, because this thing is actually equal to a non-negative number. inequality. And so that means that we have this actual total variation distance between probability distributions. And here is now a statistical strategy to implement our goal. Remember, our goal was to spit out a theta hat, which was close to P theta star. So hopefully, we were trying to minimize the total variationdistance between P thena hat and P thea star. But here, one of the arguments is not known, so we need to estimate it. But it's very unclear how you would build this estimator of TV. The total variation is telling you how far in the worst case the two probabilities can be. This is really the intrinsic notion of closeness between probabilities. The KL divergence is non-negative. Who knows the Jensen's inequality here? That should be a subset of the people who raised their hand when I asked what a convex function is. And actually, if you pay attention, we're actually really throwing out everything else. So they're not symmetric. But it's non- negative and it's 0 if and only if the distributions are the same. of X. I'm just shifting the plot of my function up and down, but the minimizer stays exactly where it is. Every time it's a translation on the y-axis of all these guys. And the value that I translated by depends on theta star. So we'll just keep going on this property next time. And we'll see how from here we can move on to-- the likelihood is actually going to come out of this formula. Thanks. Back to the page you came from.