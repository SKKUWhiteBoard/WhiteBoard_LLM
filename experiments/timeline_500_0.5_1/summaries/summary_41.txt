homework two is out now. What the default projects will be, uh, for this class. Um, and you guys will get to pick whether or not you wanna do your own construction project or the default project. And those proposals will be due, um, very soon, er, in a little over a week. Are there any other questions that people have right now? Yeah. The assignments, [inaudible] are they limited to TensorFlow? asked the question if, if the assignment is limited toTensorFlow. I'm pretty sure that everything relies that you're using Tensor Flow. Last week we discussed value function approximation, particularly linear value function approximations. Today we're gonna start to talk about other forms of valuefunction approximation in particular, um, uh, using deep neural networks. We're mostly not gonna talk so much about enormous action spaces, but we are gonna think a lot about really large state spaces. And so, instead of having a table to represent our value functions, we were gonna use this generic function approximation where we have a W now, which are some parameters. that it does is it has fixed Q targets. Um, so to improve stability, and what we mean by stability here is that we don't want our weights to explode and go to infinity which we saw could happen in linear value function. We're gonna fix the target weights that are used in the target calculation for multiple updates. So, instead of always update- taking whatever the most recent one is, we're just gonna fix it for awhile and that's basically like making this more stable.