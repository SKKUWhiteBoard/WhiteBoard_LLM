okay so welcome to the last lecture of this course here in this winter term and what we discussed so far in the course were mainly the so-called backends or optimization engines or probablistic estimation techniques. Today I would like to give a very very of course brief short overview about front ends and one important aspect inside successful front ends on how to determine if a constraint is likely to be a correct one so we are still interested in avoiding to add roam constraints although we've learned that we there are techniques which can deal with outliers in the data Association. to begin by matching observations so we have different observations depending on what platform that can be whatever stereo camera or laser rangefinder or different types of sensory modalities. Depending on what we see what we assumptions we make about our observations this tarz can be very hard or not that hard. Other approaches use features for example we had those the Victoria Park where trees have been extracted in this case from the laser range data so the trends of trees and every trunk of tree was seen as one feature or one landmark and the robot map those landmarks. Large databases of images using those descriptors so these are three popular techniques or sensor information that front-ends use in order to make the data Association and way we actually look into those who is very short example examples during this course today okay so you can say okay given I'm here at the area of my scanner and say okay say if the robot was sitting standing over here that's the area it may have observed then I can simply check is the current sensor range is there an overlap between the current sends a range and the possible observation that I obtained from b1 on b2. moment and that's my sensor range I can compute where are those other pulses so in this case B 1 and B 2 just two examples could be more obviously and then I can also estimate what is the uncertainty of those poses B 1 or B 2 relative to a do that by eliminating the note a from my linear system and then inverting the resulting Hessian and looking to the main diagonal blocks this gives me the uncertainty here indicated by these dashed lines where b1 isrelative to a and the same here where is b2 relative toa. I reach all the posts I'm interested in looking into but this does is ignores the loop closures so the uncertainty estimates are too big but you can still argue that okay uncertainty estimates I get are toobig but I can compute this extremely efficient and I may inspect a few places too much but I should get all the places which I need to inspect in order to make sure I find the course with whatever 95 percent probability this is what is done. What is done in practice to what inverting this matrix age there so far we really tried to explicitly invert it. ICP is a combination of the iterative closest point algorithm and the initialization so ICP depends on the initial guess and it just finds one solution and may be the right solution but may be wrong solution. P is sensitive to the initial guessing and as a result of that we may end up in a local minima so in something which looks like a match but in reality is not a match. If you have descriptors like feature descriptors it can actually help you to find good estimates where you can be so you don't have to try all camera polls and see if the camera poses match. showing you three different examples of systems that we have built here in Freiburg. Some of the mapping techniques we developed here have been used to at least tested on that car so this is a pioneer a two robot which has a two d-day the rangefinder sitting here and sits on a pencil unit so it moves always like this song so it's called a nodding laser and this way generates 3d data you get 3d information about the scene and then it tries to build sorry a 3d map of the environment using this technique. then we can do is we can take those two local maps and try to align those twoLocal maps it's typically Nanban so depending on how many scans you integrate either you could take these skins so if it's just kind of one 3d scan you would although in practice it's a number of 2d scans for matching. Sometimes it's easier to match full maps like versus individual scans this depends on the data that you have and how many ambiguities you may find your environment so if you have a local blast slightly bigger view so you really match a map against the map that may be easier. darkest stripes these are simply small alignment errors of these individual maps they can they can see kind of small steps over here here that was also probably an alignment error which simply leads to her step which was let's say bigger than and all five centimeters in the ground and therefore it's classified as not reversible anymore and therefore everything is red over here. That's the way you can actually use 3d data to build a map of the environment the next example this is an autonomous car is a parking lot or a 3d model of a parking lots where yellow again means drivable areas and red means non drivable area. done with the grid for 20 by 20 centimeter grid cells and this by lining those grid cells you can actually get maps off and say this quality that's something you can expect to get with this technique. System which was flying on the prototype for a helicopter so never made it to the blimp in the end this was just a self assemble stereo camera system with two webcams assembled in a stereo setup and a small IMU there's an initial inertial measurement unit and one of the advantage of this system is it gives you also the gravity vector this quite accurately. Surf features provide a local description of the scene of a small noise a scene of the small part of the image and so if you see every of those for each of those points here one of those descriptive Alice is computing their computer kind of from a local window around them doing some local operations and returning typically a 128 dimensional vector. So we kind of we take we take a pair of feature out computes the transformation based on them and then take all others in order to evaluate how good this proposed transformation was so super can repeat this process until I am until I let's say happier or a good pose that's been found. stereo camera and the in this case the the camera is looking downward to me of the IMU on top we know the gravity vector and so this eliminates the roll directionally cursus will change the gravity vectors and the pitch direction. So by knowing thegravity vector I kind of get rid of the roll in the pitch and this reduces my problem from six dimensions to four dimensions for every node or for every camera pose which makes my life easier and therefore it is kind of exploited here. Based on that based on that I can buy a triangulation compute where are the points in the 3d space. is a procedure which is very very similar to Rancic it's actually a variant of good sake I think which was used here but this is just you you sample a few parameters that you need in order to compute the solution and then use all other informations to evaluate this solution. Then you try that multiple times and see how often do we find a consistent match. That's the way this works this technique is used in three different ways in this approach the first one is for for visual odometry so there is no wheel encoder on the camera. an existing part of the environment has a good estimate where it is that is what we refer to as localization and the last part which is loop clothing so given I kind of I don't know where I am some a large uncertainty and I you can use this approach to see how well do the features that I see at the moment mattress features have seen in the past and try to find an alignment for this this is a good alignment you may accept that or you may try this for a couple of consecutive frames that not just kind of one bad image screws up everything. Tasker builds a map online and use the map in order to make navigation decisions of where it should actually go. The platform looks for potential loop closures based on the uncertainty and then it tries to find them and collects a few of them groups M sees that there are groups of people in a certain area. The system then tries to close the loops as early as possible so don't let the uncertainty grow so much and the area smaller it's more likely did you find a match the other thing is you could simply cover the whole area. talk which I Neff was more over more whatever like wait overview about how different approaches work was not going to too many details. Second part of the talk today I would like to talk about ambiguities in the environment and what are good ways for dealing with them. How can we actually build accurate maps consistent maps of the environment so they are are so or the main assumption here is not we simply ignore all n big you T's and say the environment has no ambiguisms and I just consider they are none of them. There are multiple hypotheses how it can match inside and they overlap therefore it's local the other ones non-overlapping its global and this is this is our overlapping matches is global so I don't know how this a fits in here so does this guy over here fits this one this one or this one so either here here or here simply something I it's what V is it's just kind of V times a constant C and just to determine this constant so that this expression is maximized but V is already given so that's that can be easily done. hard for me to you to to identify and this is also called what's called the picket fence problem so good offense you seem you don't know which part of the fence matches to what you see so far it's a very very long repetitive structure and these are things where you also don't want to add a constraint the curses simply do not know is this is this locally ambiguous or not if it is just really don't wants toAdd a constraint we say can I say it's either here here or here what you could do is you could use the max mixture approach. The key trick in here is we have a large number of constraints pairwise constraints between nodes. The goal is that among one group within one group they all consistent with each other. This is done with a single graph partitioning approach this was kind of the techniques there the technical - Olson which uses this and yeah again so regarding the the position uncertainty of the platform the higher the uncertainty is in an area the moon bear I need to know the area in order to make the decision easier is this a global is their global. these are those add edges which result from odometry or incremental scan matching if I start from this node over here I can take my little madama tree constrain to go here I take my constraint HJ to jump into the second trajectory for the point in time when I visited the place a second time move along the odometry again and then go back kind of with the inverted H I and go back to the same place. If I have this kind of loop of constraints if they are all perfect and agree and consistent I should add up at an identity transformation if I concatenate all of them. and if you don't understand what the matrix means it will be hard so every entry of this matrix IJ tell us how well do hypothesis hypothesis J agree with each other just looking to this this pair of it's just a pairwise consistency mention the small if they're small Wireless in there I mean they don't agree they are high values and Daisy but they agree that may be good again so the goal is just to find this vector and then later on find a way and how can we determined what V this vector be all right. once once in this vector and I will get a high score if I have ever two groups in there I have I get one. I get scores among the groups but not between each other so we get and I divide by again a large number of apostasy. So we get a small value so I have this function just high values for both elements and low values for bad hypotheses so what can I do again treated as an optimization problem I try to find the vector B which maximizes this fraction that's exactly what is done. that might seem a topological grouping is done in a good in a fair manner and the includes all the relevant constraints but under this assumption that's exactly what I get out here so what I do is I take compute the first eigen value in the second eigenvalue and I compare them. If the solution 1 is locally unambiguous that means there is no picket-fence problem where is the high probability of course still may be the case I made a decision but that's my assumption here what have they need to do it I need to discretize V 1 to 0. Ambiguity or not it's kind of if the uncertainty lips of speakers need to seen all that area to make this is no that's the only place where I actually can match and about the special clustering technique for the original paper where you find all the information here's the work back in also recognizing places using spectral clustered local matches. This is exactly the approach that I presented here and actually a couple of the slides that I use in here or of the images material at least comes from a tin Olsen.