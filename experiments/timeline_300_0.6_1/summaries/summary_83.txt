Today, we'll talk about coded imaging. It's a form of a co-design between how you take a photo and how you recover the sharp detail afterwards in software. We'll see how-- we already have some projects that are inspired by biological vision. And I believe Santiago-- where's Santiago? Oh, yeah, his triangle-- the piston, kind of-- so some really great ideas. So I'm glad a lot of these concepts are coming together in the final projects. It is going to be very popular. capture the image and how you process the image. In a typical film camera, or even it is digital camera, you take the picture, and that's basically the end of the story. So when you try to recover this information, you start getting this banding artifacts. And we'll see it in the next slide, why that happens, and how to get rid of the banding and noise in the image you're trying to capture. Back to Mail Online home. back to the page you came from. have basically a 1D convolution that's converting this image into this image. But the Fourier transform has some zeros, so you cannot divide those frequencies by 0 and recover an image. So the culprit here is really this box function, which is equivalent to-- when you release the shutter, opening the-- release your shutter button-- opening the shutter and keeping it open for exposure duration and closing it. But that's not the most effective. So what if you change that? What if you open and close it in a carefully chosen binary sequence? frequencies-- they're all preserved. Of course, they're attenuated. It's not as high as-- it's not 1.0.0, it's reduced. Maybe it's 0.1 or so. So there is still some hope to recover this photo back from this because, in the denominator, we will not have seen. The problem is each of the frame will be extremely dark. So you are basically adding up a lot of noise. Every frame is dominated by noise. that's your 1010 inquiry. Instead of keeping the shutter open for the entire duration and getting a well-exposed photo, the shutter is open for only half of the time. The support for the representation of the Fourier domain of that function that you describe there is infinite, right? So you actually truncate this in order to-- RAMESH RASKAR: It's not infinite because you still have some width. AUDIENCE: Right, but you have infinite high frequencies there by the sharp conditions. CNN's Ravi Agrawal is a senior producer at CNN.com. He's known for his work on deep learning and artificial intelligence. He recently developed a tool that can detect motion in moving objects. The technique can be used to create a virtual blur in a moving image. It uses a filter that is dependent on distance and speed to create the illusion of motion. The technology is still in its early stages, but it could be used in the future to help with other types of imaging. your shutter? RAMESH RASKAR: When you're-- OK, so when you're setting up your shutter, if the car is moving really slow, and you don't expect it to blur by 52 pixels, then using a 52 sequence is overkill. Maybe you should use a new sequence that's only about 10 long or 11 long, right? So it's just like-- AUDIENCE: OK, but that's just so you can get more light. RAMESH: No, that's so that it's most optimal for that setting. to engineer activity of the camera. So in this particular case, a point that was moving created a blur like this. And by engineering the time point spread function, it stops looking a bit like that. And then it just turns out that this one is easier to deal with than this one. So that that's why a computational camera is doing the computation not just in Silicon but also in optics. And the circuit is very, very simple. You just take the hot shoe of the flash, and it triggers. When you lose the shutter, it triggers the circuit. would you apply spatial coding? AUDIENCE: Coded aperture? RAMESH RASKAR: C coded aperture. So this is coded exposure, coded aperture-- very easy. And all you're going to do is put some kind of a code in the aperture of the lens. And this is how, actually, it started in the days of-- in scientific imaging, especially in astronomy, coded apertures are very well known. And so I thought, it must be useful for something in photography. Lenses are very carefully designed by camera makers to be the same plane where you put your aperture. When you change your f-stop and decrease it and increase it, it's all happening in the center of projection. When it's in focus, it doesn't really matter what the code is, so the photo will be half a square, so you're talking about the light, so half a light, right? And that's why you have some dust on your lens and so on, unless you have the lens on your front. digitally. In 1D, this is what we saw, right? Its Fourier transform is flat. So there are 52 entries here, and almost all of them are the same. Now we're saying, think about the problem in 2D. And what's the Fourier transforms of this? So first, for this one, the Fouriers transform is-- as we see, it's black. And then if you take that in 2 D-- so how is the code? I'll give you a hint. the values will be constant. So if we're placing a broadband code, certainly we have an opportunity to recover all the information. It's much easier to think about convolution and deconvolution in frequency domain than in primal domain. In communication theory, everything is [INAUDIBLE].. We think about carrier frequencies of radio stations in frequencies. And we think about guard bands and audio bands. And that's the same thing that's going on here. And convolution, deconvolved-- much easier than frequency domain. At the end, the solution is very easy-- just flutter the shutter. don't know whether this matters. But you're right. If you're looking at something that's-- we have bright lights in the scene. At a distance, take our false photo. They will all look like this. Or you could put hearts in it, or, like-- AUDIENCE: Right, yeah, I was thinking maybe, that's totally possibly. [LAUGHTER] RAMESH RASKAR: So an interesting art problem is how do you create-- how do we create a mask that visually looks aesthetic but is mathematically also invertible? the depth. When it comes into sharp focus, my edges, that must be the right depth. Unfortunately, it doesn't work out in this case. The main reason is that, because it's coded aperture, no matter where you refocus, it still looks like it has very high frequencies. So you need to find this 7-by-7 pattern or even the previous case, the 52 pattern. Take a Fourier transform to see if it's flat. If it's not flat, you go to the next one. code and do a gradient descent and so on. There's no good solutions for 2D. But for 1D, there are some really good solutions to come up with that. For 2D, for certain dimensions, they call it one more 4 or three more 4. Basically, when you divide by 4, the remainder can be 1 or 3. And there are certain sequences that are beautiful mathematical properties, of which sequences could have broadband properties and which may not. So it turns out you cannot-- there's a little bit of cheating going on here. filter to the beginning of the signal. This particular filter is actually not circular, but it's linear. So when you apply the filter here, when you start applying the filter at the end of the image, you don't go back to the front. It turns out, for circular convolution, the match is very clean and beautiful and smoother course work. Or for linear convolution,. there is no good mechanism. So we came up with our own code called RAT code, R-A-T, which is after three quarters. In astronomy, you have circular convolution because they use either two mirror tiles and one sensor or one mirror tile and two sensors. If you're tiling the mask at aperture, but you are using single-tiled aperture, you'll get horrible frequency response. In this photo, those frequencies are not lost because all the frequencies are preserved. But that's because our eyes are not very good at thinking about what the original image could be, given either this one or the previous one. It's just pure x equals b, x equals a backslash b. Ramesh Raskar: There's just one way of engineering the point spread function, one in motion and one in focus. He says for any continuous code, there is a corresponding binary code that will do an equally good job. RaskAR: Eventually, it's going to have a 2D projection. "It's amazing because motion is time, and the focus is space. They're completely orthogonal. So you can play with it," he says of motion and focus. A lot of it is actually being used in cell phone cameras. They put this face mask between the object-- near the lens so that the image does not come into sharp focus ever. The benefit of that, it turns out, is that it preserves the spatial frequencies, and it has the benefit that, no matter which steps you are at, you have the same defocus blur. So whether if I hold myself on camera, whether I'm here or here or at infinity, I get the same amount of blur. Ramesh Raskar: Compressed sensing is taking a photo and compressing it. He says the idea is to take a single photo and then recover it in a compressed way. Rasksar: If you're on 2 megapixels, then you need to take 2 million [? pics] All right? So the claim this group made at Rice University was that if I wanted a million-pixel image, I don't have to really take a million readings, he says. Rasa: I can take this picture effectively with just 10,000 pixels but recreate a million pixel image. which is how to write a paper and wishlist for photography. Which isHow to Write a Paper and Wishlist for Photography: How to Write A Paper and Write A Wishlist For The Camera. For more information on writing a paper or wishlist, go to: http://www.cnn.com/2013/01/30/photography/how-to-write-a-paper-and-wishlist-for-photography-how- to- Write-A-Paper-And-Wishlist.html.