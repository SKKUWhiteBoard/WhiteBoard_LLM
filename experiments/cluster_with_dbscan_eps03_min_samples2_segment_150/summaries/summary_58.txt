as a function of time. Here is the Fourier transform of a sine wave at 20 hertz. This is phase shifted so the cosine is a symmetric function or an even function. The sine is an odd function. In this case, the real part is 0. And the two peaks are in the imaginary part. If you look at the power spectrum of the square wave, you can see again it's got multiple peaks at regular intervals. It's a series of peaks, because it's a periodic signal. we plot power in log base 10. A difference of an order of magnitude in two peaks corresponds to a unit called a bel, b-e-l. More commonly used unit is called decibels, which are 10 decibel per bel. So decibles are given by 10 times the logbase 10 of the power of the square magnitude of the Fourier transform. Does that make sense? Good question. All right, any questions about this and what the meaning of decibela is? The Fourier transform of a square wave, of this square wave of with 100 milliseconds, is a sinc function. If we take that pulse and we make it narrower, 25 milliseconds, then you can see that the sincfunction, it's the same sinc. function, but it's just stretched out in the frequency domain. As you make the pulse in time longer, the bandwidth gets smaller. And it turns out that the product of the width in time and thewidth in frequency is just a constant. actually reverse the order of integration. We're going to integrate over t first rather than tau. Then we can move the g outside the integral over t, because it's just a function of t Tau. So now, we have an integral dt x of t minus tau e to the minus i omega t. And what do you think that is? What would it be if there were no tau there? If you just cross that out and that, what would that be? Anybody know? What that's? correlation of this function with itself at different time lags. If we do that, you get a 1 at 0 lag and 0 at any other lag. So that's the autocorrelation function of Gaussian noise. All right, now what is the power spectrum? So we can take this thing-- and, remember, when we plot the power [AUDIO OUT] just plot the square magnitude of just the positive frequencies. Why do we only have to plot thesquare magnitude about that? OK. problem with that? Why might that be a bad idea? Yeah. So instead of multiplying this signal by square pulses, we sample the signal by applying it by little things that look like little smooth functions, like maybe a Gaussian, or other functions that we'll talk about do an even better job. OK, so that process is called tapering, multiplying your data by a little [AUDIO OUT] paper that's smooth, unlike a square window. And we're going to come back to that, how to really do that right, on Thursday. of noise. In order to estimate what the spectrum of noise looks like, you have to take many examples of that and average them together. And when you do that, what you find is that the power spectrum of Gaussian noise is a constant. It's flat. The power spectrum, really, you should think about it properly as a power spectral density. So there is a certain amount of power at different frequencies in this signal. And forGaussian noise, that power spectraldensity is flat. Itâ€™s constant as a function of frequency. over the sampling rate and another copy sitting up here. The sampling rate needs to be greater than twice the bandwidth of the signal. These copies of the spectrum are too close to [AUDIO OUT] and they overlap. That overlap is called aliasing-- a-l-i-a-s- i-n-g. Now that's an amazing claim. Right? You have a time. All right, it's wiggling around. What this is saying is that I can sample that signal at regular intervals and completely ignore what's happening between those samples, have no knowledge. sample the signal in the time domain and then add a bunch of zeros to it before you Fourier transform. And that gives you finer samples in the frequency domain. And I'll show you in more detail how to do this after we talk about tapering. And it's very simple code actually. Matlab has built into it the ability to do zero-padding right in the FFT function. OK, let's actually just stop there. I feel like we covered a lot of stuff today. Micheal FEE: Today, we're going to continue with our plan for developing a powerful set of tools for analyzing the temporal structure of signals. We'll talk about the convolution theorem, noise and filtering Shannon-Nyquist sampling theorem and spectral estimation. Next time, we'll move on to spectrograms and an important idea of windowing and tapering, time bandwidth product, and some more advanced filtering methods. And there may be, if there's time, a little trick for removing the line noise from signals.