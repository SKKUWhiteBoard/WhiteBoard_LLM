do this when you have something that sums to 1. It's not more complicated than what I wrote here, but make sure independently you go through it and ask questions. In the next class, as I said, what we're going to see is this notion of factor analysis. And that is going to tell us how to apply EM to a different kind of setting, which, at first glance, will look kind of impossible to do without a latent variable model. And I think that's all I want to say. The EM algorithm is an unsupervised version of k-means GMM. In GMM, you guess randomly an assignment of every point to the cluster, the probability. You guess where they're probabilistically linked, that is, what's the probability of these points belong to cluster one, this point belongs to cluster two. And then once you have that, you then solve some estimation problem that looks like a traditional supervised learning. The decomposition is quite important. And we're going to try and kind of abstract that away.