The 60002 course is the second half of the 600 program. The main topic is computational models. The final exam will be based upon all of the above. The lectures will be a bit faster paced than 60001. The course is really less about programming and more about dipping your toe into the exotic world of data science. It will be taught in Python, but there will be additional bits of Python as well as some comments about software engineering, how to structure your code, more emphasis in using packages. Science is moving out of the wet lab and into the computer. Increasingly, there is an increasing reliance on computation rather than traditional experimentation. We'll talk about three kinds of models-- optimization models, statistical models, and simulation models. An optimization model is a very simple thing. We start with an optimization model and then go on to other types of models, such as statistical models or simulation models, which can be used to predict the future of a given area of science. For example, a climate change model. We can build models that sort of explain how the climate has changed over the millennia. with an objective function that's either to be maximized or minimized. We then often have to layer on top of that objective function a set of constraints, sometimes empty, that we have to obey. So for, example, if I'm going from New York to Boston, I might want to find a route by car or plane or train that minimizes the total travel time. A greedy algorithm, as we'll see, is not guaranteed to give me the best answer. Let's talk about a specific optimization problem called the knapsack problem. There's more stuff than you can carry, and you have to choose which stuff to take and which to leave behind. The 0/1 knapsack problem means you either take the object or you don't. But you can solve it with what's called a greedy algorithm, and we'll talk much more about this as we go forward. There is no algorithm that provides an exact solution to this problem whose worst case running time is not exponential in the number of items it can hold. John Guttrag: brute force can't solve optimization problems where n is something closer to 1,000, sometimes even a million. On Wednesday, we'll talk about how do you actually guarantee finding an optimal solution in a better way than brute force. See you on Wednesday at 9 p.m. ET on "This is Life with John Guttrach" and "This Is Life With John Gut Trach" on CNN.com/ HLN, 8 p. m. ET. Got this class food. I have a getValue, a getCost, density, which is going to be the value divided by the cost, and then a string representation. Then I'm going to have a function called buildMenu, which will take in a list of names. And it will build the menu. And I build each food by giving it its name, its value, and its caloric content. Now comes the fun part. Here is an implementation of a greedy algorithm. I called it a flexible greedy primarily because of this key function over here. actually works? I hope not because I think it does work. Let's ask the next question. How efficient do we think it is? What is the efficiency of this algorithm? Let's see where the time goes. So I deleted the comment, so we'd have a little more room in the slide. Who wants to make a guess? By the way, this is the question. So please go answer it. We'll see how people do. But we can think about it as well together. See who remembers. Lambda is used to create an anonymous function, anonymous in the sense that it has no name. Lambda does is it builds a function that evaluates that expression on those parameters and returns the result of evaluating the expression. So I'm taking the function getCost from the class food, and I'm passing it the parameter x, which is going to be what? What's the type of the argument to getCost? We'll go back and we'll look at it. We do have a tradition in this class that people who answer questions correctly get rewarded with food. The problem with greedy algorithms is that you can get stuck at a local optimal point and not get to the best one. Let's say I'm feeling expansive. I don't want to go down. So I'm here and I'm happy. On the other hand, if I had gone here for my first step, then my next step up would take me up, up,. I'd get to here, and I'd stop and say, OK, no way to go but down. I'm done.