okay so welcome to the last lecture of this course here in this winter term and what we discussed so far in the course were mainly the so-called backends or optimization engines or probablistic estimation techniques. Today I would like to give a very very of course brief short overview about front ends and one important aspect inside successful front ends on how to determine if a constraint is likely to be a correct one. I will introduce three kind of small front end systems on a very abstract level just giving you the idea on how they work with different sensors and then in the second part of this talk today I will like to stress on what kind of conditions should such a constraint fulfill or the the metrics of the local environment fulfill in order to let's say I would say ensure to be out layer free. to begin by matching observations so we have different observations depending on what platform that can be whatever stereo camera or different types of sensory modalities. For every sensor of course there's a different way of obtaining those constraints and those constraints may take into account what the sensor actually sees how kind of unique is the data that the sensor generates for specific area or it's a look all corridors exactly the same. Other approaches use features for example we had those the Victoria Park where trees have been extracted in this case from the laser range data. image you have a typically quite good description of the image so you can just match those descriptors and based on those descriptor identify if two images are recorded from the same place. You can do what's called a visual odometry so based you inspect the images and consecutive frames estimate the positions of features and then estimate the movement of the camera based on the feature that you see and the 3d location of the feature is exactly in the same way. The last part which is loop clothing so given I kind of I don't know where I am some a large uncertainty and I you can use this just consider they are none of them if you say they are. moment and that's my sensor range I can compute where are those other pulses so in this case B 1 and B 2 just two examples could be more obviously and then I can also estimate what is the uncertainty of those poses B 1 or B 2 relative to a do that by eliminating the note a from my linear system and then inverting the resulting Hessian and looking to the main diagonal blocks this gives me the uncertainty here indicated by these dashed lines. Based on this information I know I can never have an estimate of given my current pose where's b1 where's B2 together with The Associated uncertainties certainty estimates. was here indicated with a which can where I could I can obtain by inverting the hessian in practice this is a pretty expensive operation so you actually want to try to avoid inverting this larger matrix you can do an approximation what actually most system in practice do to do that more efficiently. This is a thing by they say okay we simply ignore the loop closures for the moment just for estimating the uncertainty here and you just do what is also called Dijkstra expansion so we expend propagate the uncertainties through the graph. ICP is sensitive to the initial guess and as a result of that we may end up in a local minima so in something which looks like a match but in reality is not a match other things we may identify is how do i sample possible locations where the platform can be. The approach here takes additionally into account it kind of separates areas that such is just a simple say classification or segmentation of the environment like and if I wall think that stick out and first met results against each other and only in the end it does the alignment of all points. showing you three different examples of systems that we have built here in Freiburg. Some of the mapping techniques we developed here have been used to at least tested on that car so this is a pioneer a two robot which has a two d-day the rangefinder sitting here and sits on a pencil unit so it moves always like this song so it's called a nodding laser and this way generates 3d data you get 3d information about the scene and then it tries to build sorry a 3d map of the environment using this technique. take the tree the pole and the walls and match them first you if you can separate those part of the skin reliably he typically are less likely to end up in a local minima and then in the end you get this kind of alignment so this the iterative procedure nice based on ICP which aligns those scans and then I can do this for a large number of individual scans. Then I end up with a map like this so you can see you may observe some of those small stripes over here so these kind of darkest stripes these are simply small alignment errors. is a parking lot or a 3d model of a parking lots where yellow again means drivable areas and red means non drivable area and then you can actually use this this map over here in order to localize the vehicle. This was actually work of China that he built or he realized autonomous parking using this map representation which was built here for that vehicle in that parking lot well it's actually the picture of a garage and so you can see even though it's here three floor building and the corresponding 3D model where the car and how to heal. This is exactly the approach that I presented here and actually a couple of the slides that I use in here or of the images material at least comes from a tin Olsen. This is a procedure which is very very similar to Rancic it's actually a variant of good sake I think which was used here. The technique is used in three different ways in this approach the first one is for for visual odometry so there is no wheel encoder on the camera so if you take the camera on a flying vehicle or we take into our hand and moving it over the ground. Based on the position of my stereo camera I try to build a local model of the surrounding so what we want to estimate is the X Y that and three angles your roll pitch and yaw. By knowing the gravity vector I kind of get rid of the roll in the pitch and this reduces my problem from six dimensions to four dimensions for every node or for every camera pose which makes my life easier and therefore it is kind of exploited here so based on the staring from stare information into account. image and you have a database of all the sort of features that you have seen so far in the past what is the first thing you do is you try to make a nearest neighbor query in the descriptor space to try to find the best matching descriptors over your map or in those areas which are in line with the credit unit. If you have descriptors like feature descriptors it can actually help you to find good estimates where you can be so you don't have to try all camera polls and see if the camera poses match. may see a small bias it's not centered around zero but given kind of this self-made stereo setup just excluding two cameras together that was actually a very nice result then you can use the same system for example on a blimp this was an example where we used it in the end God used here was exactly the same approach but only a single camera and the SONA which was measuring the depth information. Tasker builds a map online and use the map in order to make navigation decisions of where it should actually go. be the same place but there might be something else which looks exactly than in this place a here so it may not be a good idea to add this constraint unless we have seen all this part over here. There may be different places where the system can be which are just which are which do not intersect with the place I'm currently considering and therefore I should not do a match but you could you could. The key trick in here is we have a large number of constraints pairwise constraints between nodes and we want to check in to how many consistent subgroups are there. hard for me to you to to identify and this is also called what's called the picket fence problem so good offense you seem you don't know which part of the fence matches to what you see so far it's a very very long repetitive structure and these are things where you also don't want to add a constraint the curses simply do not know is this is this locally ambiguous or not. If you have more than one solution I can just say okay what the ratio between the largest eigenvalue and the second largesteigenvalue. If this is a value which is let's say 1 or between 1 and 2's again yeah this is very likely to be a picket fences prom. sufficiency it'll be so these two tests I have okay we would like to go through these three steps over here the first one is the topological grouping which is easy to be done so I just take my post graph and I take okay which poses are nearby and then I try to match all of them. The questions how do I identify which one a right image or not wrong again the first thing we do is we want to test for local unambiguous so we take one and then we take another. add up at an identity transformation if I concatenate all of them. Sampson theme aligned because the similarity or how far away from your identity matrix simply depends on how accurate is your dormitory information and how accurate can you actually align your scans. Moodle oh that yeah okay so I have whatever a number of those hypotheses what I can do is I can actually build up my matrix a I J where this simply depends how consistent are the hypothesis using the hype of this I and a hypothesis J together with the odometry. which basically means I'm far away from identity we may use just a Gaussian about how far I am away you're away from the from the identity so what you end up you have a matrix with those values in here and some values are have high well we have some elements with high values inHere and some elements in here. If I have a 1 here at the field I it means that the assumption that H I is correct and if there's a zero of it if AJ is incorrect or it's not correct so I get effect. okay my Lambda is now a function a Lambda as a depends on my variable indicator vector B and I try to maximize this expression. The problem I have in here is that my indicator vector V has a constraint that only allowed to take zeros and ones in under this constraint that is an np-hard problem. I simply don't treat my vector V as discreet I said I just allow continuous variables because then I can actually optimize this and then get a solution and the end I simply round to 0 or 1 it may not be perfect. for determine this I could use the SVD that we discussed for example with the diagonalization in whatever a few months ago when we when we discussed this. The larger the eigen values are the better the score so there's a proof that i get a perfect combination I get a couple of eigen vectors with current putting eigenvalues. If I have multiple solutions for that get MA multiple so if I haveMultiple solutions for this eigenvalue problem this is simply they are multiple maxima in my in my problem.