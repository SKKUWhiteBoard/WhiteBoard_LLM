MIT OpenCourseWare continues to offer high-quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourse Ware at ocw.mit.edu. The following content is provided under a Creative Commons license. Your support will help MIT Open courseWare continue to offer free, high- quality educational resources in the U.S. and around the world. For more information on MIT Open CourseWare, visit opencourseware.org. We've got two lectures left discussing linear algebra before we move on to other topics. We looked at one type of transformation we could utilize for solving systems of equations. Today, we'll look at another one, the eigenvalue decomposition. And on Monday, we will look at a different decomposition called the singular value decomposition, which is a different type of matrix. We want to make sure that we're answering those questions in a timely fashion. We don't want anyone to get left behind. be stuck. It won't proceed after that. So it's the difference between getting a solution and writing a publication about the research problem you're interested in and not. So how do you do reordering? Well, we use a process called permutation. There's a certain class of matrix called a permutation matrix that can swap rows or columns. So if I want to swap columns, I multiply my matrix from the right, IP transpose. If I swap the rows and then I swap them back, I get back what I had before. This is a form of preconditioning. It's always done via Gaussian elimination if we want an exact solution. You're studying one of them in your homework assignment now, where you know the matrix is banded with some bandwidth. So you don't do elimination on an entire full matrix. You do it on a sparse matrix whose structure you understand. We discussed sparse matrices and a little bit about reordering and now permutation. I feel like my diffusion example last time wasn't especially clear. So let me give a different example of diffusion. seen The Price Is Right? This is a game where you drop a chip into a board with pegs in it. It's a model of diffusion. The Plinko chip falls from level to level. It can go left or it can go right with equal probability. So the probability that I'm in a particular cell at level i is this Pi plus one. And there's some sparse matrix A which spreads that probability out. It splits it into my neighbors 50/50. And at the next level it all gets passed down by 50%. For a real N-by-N matrix, there will be eigenvectors and eigenvalues. They're special vectors that are stretched on multiplication by the matrix. The amount of stretch, however, is unique. It's associated with that direction. And that describes the eigenvector-eigenvalue pair. But because there's N equations for N plus 1 unknowns, that means they're not unique. We don't know what an eigen vector is uniquely. We can only prescribe its direction. But we'll find them in a second. We want to know the eigenvector of the rate matrix having eigenvalue 0. This should correspond to the steady state solution of our ordinary differential equation. Can you do that? Can you find this eigen vector? Try it out with your neighbor. See if you can do it. And then we'll compare results. Are you guys able to do this? Sort of, maybe? Here's the answer, or an answer, for the eigenector. It's not unique, right? It's got some constant out in front of it. James W. Swan: Try this example out. See if you can work through the details of it. I think it's useful to be able to do these sorts of things quickly. Here's a matrix. It's not a very good matrix. But it's all 0's. So what are its eigenvalues? It's just 0, right? And they're 0. That eigenvalue has algebraic multiplicity 2. Can you give me the eigenvectors of this matrix? Knowing what those eigenvectors are requires solving systems of equations. If I know the eigenvalues in A, then I can easily diagonalize my system of equations, right? So this is a useful sort of transformation to do. We haven't talked about how it's done in the computer. These are ways you could do it by hand. There's an alternative way of doing it that's beyond the scope of this class called-- it's called the Lanczos algorithm. And it's what's referred to as a Krylov subspace method. triangular form for this matrix. We'll talk next time about the singular value decomposition, which is another sort of transformation one can do when we don't have these complete sets of eigenvectors. You'll get a chance to practice these things on your next two homework assignments, actually. So it'll come up in a couple of different circumstances. I would really encourage you to try to solve some of these example problems that were in here. Solving by hand can be useful.