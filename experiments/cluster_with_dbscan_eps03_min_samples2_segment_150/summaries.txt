==================== [1/100] ====================
Summary:
epsilon positive there, we should be able to find a capital number M, such that if n is bigger than or equal to capital M, 1 over n to the p is less than epsilon. So that proves number one. So number two we'll do-- we really only need to do two cases. One is p. So p equals 1 is fine, because then I just get 1 for the whole sequence. Now let me do p bigger than 1. And if p is bigger. than 1, the absolute value of p to the 1. over n minus 1-- this is just p to. the 1 this thing times n plus 1. Convergent sequences are bounded, so-- and they have convergent subsequences. Limsup and liminf are also two important objects that arise in analysis. If they exist, there are going to be certain limits, so it's not clear that they exist at all to begin with. But we'll show that they always do exist. We define limsup x sub n, and sometimes I'll write n goes to infinity underneath. And the liminf is similar, except it's now with infs. such that the limit as k goes to infinity of x sub n sub k equals liminf of xsub n. And again, this is a subsequence of a convergent sequence, so it's convergent and convergence of the same thing, L. So that implies that this thing is equal to L. And therefore, the limsup and the liminf equal each other, and they also equal the limit of the original sequence. That is the end of the proof of this theorem. CASEY RODRIGUEZ: We proved two theorems last time, and we used them for-- and we had a couple of applications of them. The first was that a sequence converges to x if and only if the limit as n goes to infinity of the absolute value of xn minus x goes to 0. And then we also had the squeeze theorem, that if you have three sequences-- a sub n, b subn, and x sub n.

ROUGE-1: 8.17, ROUGE-2: 7.85, ROUGE-L: 7.31
BERTScore: 68.14

==============================================
==================== [2/100] ====================
Summary:
equally reasonable as wave functions. All states corresponding to reasonable wave functions are equally reasonable as physical states. There's no primacy in wave functions or in states. However, with that said, some wave function are more equal than others. And this is important, and coming up with a good definition of this is going to be an important challenge for us in the next couple of lectures. So in particular, this wave function has a nice simple interpretation. If I tell you this is psi of x, then what can you tell me about the particle whose wave function is the psi of X? What do you know? a definite position? AUDIENCE: Delta. PROFESSOR: A delta function, exactly. So I claim that any function psi of x can be expanded a sum over all states with a definite position. So is this true? Is it true that I can take any function and expand it in a superposition of delta functions? Absolutely. We're going to find this is a general statement that any state can be expressed as a superpositions of states for any observable quantity you want. Professor: Which particle has a larger momentum? Think about it, but don't say it out loud. If it has higher momentum, what do you just intuitively expect to know about its energy? It's probably higher. OK next one. Compared to the wave function psi of x, it's Fourier transform, psi tilde of x contains more information, or less, or the same, or something. So let's vote. A, more information. B, less information. C, same. OK, good you got it. of length l, 0 outside of that region. f has a single well defined wavelengths. Or f is made up of a wide range of wavelengths? Think it to yourself. OK, now before we get talking about it, I want everyone to close their eyes. Or close the eyes of the person next to you. That's fine. And now and I want you to vote. A is f has one well defined wavelength. B isf has a wideRange of wavelengths. It's closer to true. The average value of a squared is equal to the sum over all possible ages of a times the ratio of Na to N. The average of the square of ages is the same thing. The expected value of some function of a is equal-- and this is something you don't usually do-- to the value of f of a, times the probability that you measure that value in the first place. It's a very useful relation. And so, again, does the average have to be measurable? No, it certainly doesn't. average value of a squared is not equal to 0. And that's because the squared has everything positive. So how do we characterize-- this gives us a useful tool for characterizing the width of a distribution? So here we have a distribution where its average value is 0, but its width is non-zero. And then the expectation value of the squared, the expected value of an a squared, isNon-Zero. This is going to be like our uncertainty. Well, I'm not sure. How unsure are you? Well, that should give us a precise measure. In quantum mechanics, the uncertainty is the square root of the standard deviations squared. Different probability distributions are going to give me different delta a's. When you write delta a, there's nothing in the notation that says which distribution you were talking about. In a physical system, the expected value of x depends on what the state of the system is, what the wave function is. So there are a quantum mechanics. And this has a different flavor. It carries different implications, and we'll see what that is later. The probability of having that momentum times momentum, right? Everyone cool with that? This is what you mean by probability. But we need to know if we have a quantum mechanical system described by state psi of x, how do we get the probability that you measure p? Do I want to do this now? Yeah, OK I do. And we need a guess. We made a guess at the end of last lecture that, in quantum mechanics, this should be dp minus infinity to infinity of the Fourier transform. having different values for momentum. They claim that any function can be expressed as a superposition of states with definite momentum, right? Well, among other things a state with definite position, x0, can be written as asuperposition, 1 over 2pi integral dk. But in particular, it's clear that this is not-- this quantity can't be a delta function of k, because, if it were, this would be just e to the ikx. And that's definitely not a deltafunction. This is what we're after. We want some good definition of p given that we're working with a wave function which is a function of x. If I take a state, psi of x, which is equal to e to the ikx, this is a state that has definite momentum h bar k. A state with a definite momentum has the property that, when you hit it with the operation associated with momentum, you get back the same function times a constant, and that constant is exactly the momentum we ascribe to that plane wave. question slightly differently. We've followed the de Broglie relations, and we've been led to the idea that there's some relationship between the momentum, the observable quantity that you measure with sticks, and meters, and stuff. But I didn't derive anything. I gave you no derivation whatsoever of the relationship between d dx and the momentum. Instead, I'm simply going to declare it. In quantum mechanics, p is represented by an operator, it's represented by the specific operator h bar upon I derivative with respect to x. This is a series that you should recognize, a particular Taylor series for a particular function. It's a Taylor expansion for the AUDIENCE: Exponential. e to the minus L derivative with respect to x f of x. Which is kind of awesome. So let's just check to make sure that this makes sense from dimensional grounds. So that's a derivative withrespect to x as units of 1 over 6. But I'm going to write this in the following suggestive way. This is equal to 1 times f of X minus L. your memory. Gainst death and all oblivious enmity shall you pace forth. Your praise shall still find room, even in the eyes of all posterity. So no judgment arise till you yourself judgment arise. You live in this and dwell in lover's eyes. May your day be filled with love and poetry. Whatever state you're in, we will always love you. Signed, Jack Florian, James [INAUDIBLE]. [LAUGHTER] PROFESSOR: Thank you, sir. The configuration of a particle is given by, or described by, a wave function psi of x. In 3D, the wave function would be a function of all three positions x, y and z. If there are two possible configurations the system can be in, it's possible to find the system in a superposition of those two psi. The probability that we find the particle somewhere had better be one. If it's less, then the particle has simply disappeared. All reasonable, or non stupid, functions psi of X are equally reasonable as wave functions.

ROUGE-1: 19.59, ROUGE-2: 18.74, ROUGE-L: 16.50
BERTScore: 58.90

==============================================
==================== [3/100] ====================
Summary:
coming in and the sound will be identical in conclusion at the very end he comes back from talking about all of the size in his love for nature and sums it back that you know and I have loved the ocean so just in case you forgot throughout these short two pages to whom he was speaking or addressing we see once again that it is nature and don't forget what an apostrophe is okay remember I told you when we learned it that's hey you're going to need to remember this and people tend to forget for some strange reason. the Lord Byron George Gordon Lord Byron very interesting very outgoing very flamboyant personality he stood out. The literary celebrity down at the bottom had spoken that he was a you know kind of born into not necessarily nobility like a monarch or anything but he was born into his title he didn't do anything to achieve it okay Hinda and he was an individual that you know probably was a bit of a celebrity to some degree he had the money he was wanting it he it said that he got in trouble because he had a lot of love affairs going on.

ROUGE-1: 16.01, ROUGE-2: 15.87, ROUGE-L: 8.39
BERTScore: 64.75

==============================================
==================== [4/100] ====================
Summary:
There are only two activities on this island. The first activity is catching fish, and second activity is gather coconut. So, they have several options there; devote part of the time to catch fish or devote all the time that they have to catchFish depending on their need. The next is how to produce. So of course, how this allocation involves making this decision what you produce. The third activity, that they can take up is that, they can fabricate net that would help them catch fish. In command economy essential authority typically, government some sort of government determines, how to produce. In market economy, as opposed to command economy, decisions are made by individuals. Third is mixed economy, here it is somewhat a mixture of command and market-based economy. Now think of it how would you categorize Indian economic system? Do we have command economy? Or we have market-Based Economy? Or do we have mixed economy? Also, it is good idea to think about what we had before 1991, and what we have after 1991. the government. So, this is a concept, an extreme concept that we typically do not find, but you would see in newspapers talk about moving towards laissez faire or moving away from laissezes faire. The government. is not a government, it is a body that has the power to decide what happens to people's lives. The. government is not the government. It is a group of people who have the power. to make decisions about people’s lives. It has the ability to make changes to the law. Allocation is nothing but assignment, allotment, share, but in economics we are more technical about this particular term allocation. Allocation here means solving these three fundamental or basic questions of economics, and the first question is what to produce? The second is how to produce and third is for whom to produce. So, let us talk about this question, first what to produced? Let us look at to answer these three questions one by one. Let us imagine a very simple economy. After 1991 after economic liberalization we are slowly moving towards market based economy, but we are not yet there.

ROUGE-1: 53.79, ROUGE-2: 46.51, ROUGE-L: 30.96
BERTScore: 68.73

==============================================
==================== [5/100] ====================
Summary:
The game is that Team 2 wins if they wind up with the larger number. They're going to look at the number on the paper that they expose. And then, based on what that number is, they make a decision, stick with the number they have or switch to the other unknown number. So which team do you think has an advantage here? Course, if you've read the notes, you know. But if you haven't been exposed to this before, it's not really so obvious. picks its larger and smaller cards randomly, it's going to be another example of a number produced by a random process. And likewise, the number of the smaller card. So that's enough examples. This little game has a whole bunch of random variables appearing in it. And in the next segment, we will look again officially, what is the definition of a random variable? We will also look again at the concept of "randomness" in the game of cards and dice. Random variables are an absolutely fundamental concept in probability theory. Let's start off with an example that in fact is a game. In the next segment, we will look again officially, what is the definition of a random variable? We will also look again at the concept of the random variable in the game "The Bigger Number Game" The Biggest Number Game is on BBC2 at 8pm on Monday, November 14. For more information, visit BBC.com/BiggerNumber.

ROUGE-1: 18.60, ROUGE-2: 15.29, ROUGE-L: 11.63
BERTScore: 67.07

==============================================
==================== [6/100] ====================
Summary:
and we also have a bias term that gets added to the output of moving each window on each location of our input we refer to it as a volume simply because it sort of looks like a cube. If you have a whole bunch of filters then you're going to end up stacking up all of the different outputs from taking each one of your different filters and running it over your input and you get something that has a number of channels in the output. Think of it like that I I don't really think of it as like a layer. CNN is where you have like an image like a person in it and you need to Output another image except each pixel has basically been like labeled with a person. In that case your output is the same size as your input which gets a little bit weird and we'll talk about that more later how you because at face value that would be like super inefficient all of your convolutions are on these just huge inputs. If you want to decrease the size of this volume because it can get quite unwieldy you can do pooling simply just looking at each. a little timeline here starting from uh alexnet and moving forward. laneet is something that was created quite a while ago. Alexnet in 2012 was a a big groundbreaking feat in that it proposed stacking layers of convolutions Max poolings following it up by fully connected layers and coming up with not a very deep network. This kind of uh turned a lot of heads when it achieved a around 17 error rate on imagenet. Inception Nets were proposed in 1990 by Yen lacun and he he kind of pioneered that pattern for today. The next slide should have an updated drawing that's hopefully a lot easier to understand than the previous one. This has a convolutional layer followed by a Max pooling layer. Three dense layers are following this last stack of convolutions and Max pooled. The motivation behind this is you want a deeper neural network. It computes a little bit better because computers evolve CPU power is able to handle these high order Matrix computations. The next slide is a visualization of how you have multiple layers that are stacked they're pulled together. so these are some things that these models wanted to optimize over time accuracy performance and model size um model size is something that has a trade-off if you get too big you lose out on other metrics like accuracy. performance is something directly corresponds to depthwise convolutions and mobile nuts for Edge Computing and things like that. You want to drastically reduce the number of computations that you want to do yep that is basically everything for today thank you guys for coming oh and there will also be a quiz. Rohan: I want to start today by sort of recapping what we talked about last Tuesday. I apologize that was kind of a rough introduction that was uh that was me making a couple of last minute edits that probably hurt more than they helped. Rohan: When you have images and a CNN you can simply just do convolutions instead of your normal matrix multiplication on a vector. When we do a convolution operation we treat it like a layer like with standard dense neural networks. We can still take partial derivatives of our loss with respect to our parameters.

ROUGE-1: 13.21, ROUGE-2: 12.52, ROUGE-L: 10.47
BERTScore: 56.69

==============================================
==================== [7/100] ====================
Summary:
The principles of baking show us how to test the theory of cold fermenting. We'll make three breads one with the brief mint and two without one of the breads without the bereavement will be bulk fermented in the fridge for 24 hours. The third one will be made with a brief mint which will be left for 12 hours to ferment then it'll be mixed into the main dough. The main comparison I want to do today is between the two breads which will take the same amount of time to make. when cold fermenting and I'm pretty sure there is is a yes or no question so here we go we got our three loaves they all look pretty much the same on the outside and obviously they have all split open on the side too they were a bit underproofed which doesn't make any difference in this test it is the fermentation time up until the final proof which really counts now cutting them open I can tell you that the crust on all breads is exactly the same next up I smell them all see if they smell any different I did not feel any difference between a 24 hour fermented one and the one with the bereavement. comparison for yourself then tell us of your results you might be surprised. What do you think of my test and my results have you ever tried something like this before do you use preference when cold fermenting let me know down in comments. If you want to see more videos like this one click over here subscribe to the channel click right here that's all I have for you today thank you so much for watching I'll see in the next one and I'll be back in a few days. Callback fermentation beats bereavement in every way it develops far more flavor it makes the crust crispier and the crumb most substantial and it simplifies the process because we don't have to make a separate thing. When it comes to cold fermentation versus brief mint there is no better method what is better is up to the use slightly less yeast in the dough that was made with the bravement and that was to compensate for the amount of yeast coming from the bereavement itself as it rises it multiplies.

ROUGE-1: 46.15, ROUGE-2: 43.87, ROUGE-L: 34.03
BERTScore: 69.27

==============================================
==================== [8/100] ====================
Summary:
Bayard Rustin was the chief organizer of the 1963 March on Washington for Jobs and Freedom. Rustin grew up in a Quaker household, and began peacefully protesting racial segregation in high school. He remained committed to pacifism throughout his life, and was jailed in 1944 as a conscientious objector to World War II. In 1948, he traveled to India to learn the peaceful resistance strategies of the recently assassinated Mahatma Gandhi. He began to work with Martin Luther King Jr in 1955, and shared these ideas with him. As King’s prominence increased, Rustin became his main advisor. are or who we love.” “I’m so proud of you,” she says. “You’re so beautiful.’ ““I love you, too,’ I say. I love you so much.“” I’ll always love you. ”I will never forget you. ””“We’ve been through a lot. We’d rather be here than there. ’’” his peers. Rustin was passed over for several influential roles in the 1960s and 70s, but he never stopped his activism. In the 1980s, he publicly came out as gay, and was instrumental in drawing attention to the AIDS crisis until his death in 1987. In 2013, fifty years after the March On Washington, President Barack Obama posthumously awarded him the Presidential Medal of Freedom, praising Rustin’s “march towards true equality, no matter who we are or who we love”

ROUGE-1: 44.31, ROUGE-2: 39.90, ROUGE-L: 41.00
BERTScore: 62.69

==============================================
==================== [9/100] ====================
Summary:
Professor Christine Hayes: God's choice of Israel, Israel as the chosen one, occurs for the first time in the Book of Deuteronomy. She says the idea that Israel is a holy people entails separation from alien peoples and practices that are inconsistent with the worship of God. Hayes: The ban on intermarriage here is quite specific. It is directed against Canaanites only, not all non-Israelites, for a very specific reason: religious purity. The Israelites are sitting in the sixth century, the time of the final editing of the Deuteronomistic history. Wellhausen: Priestly source represents a late degenerate stage in the evolution of Israelite religion. He argued that in 586, with the destruction of Jerusalem and the people were taken into exile in Babylon, that was when the priests were able to assume control. Wellhausen says the priests built a new identity and religion that stressed the sinfulness of the people, and the need for ritual purity and ritual observance and legalism as the road back to God. And this, according to Wellhauson, was a degeneration. Deuteronomy contains northern traditions from before the fall of Israel, which was in 722. There are many passages that make it clear that it's written from an exilic perspective. The most salient feature of the Deuteronomistic School is the conviction that Israel's residence in the land is a function of its means for us today that it did happen. Another theme that we see in these books is the emphasis on what we call the Yahwist prophets -- prophets like Elijah and Elisha. They are held up as heroes and champions of religious purity. the Bible is divided into two parts we refer to as the "Former Prophets" and then the "Latter Prophets." The Former Prophets will concern us for the next few lectures. The Latter Prophets is a collection of books, each of which bears the name of the individual whose prophecies it purports to contain. These prophets delivered their oracles at critical junctures in Israel's history, in the nation's history. So their words are only going to make sense if we first understand the particular historical crises that they are addressing. In the past 4000 years more wars have been fought for the possession of the tiny strip of land known as Canaan. Canaan is about 150 miles long and 70 miles wide, about the size of Rhode Island. Control of these international highways brought a great deal of wealth to the area. In times of peace it would bring prosperity, but, of course, in times of war the land was perpetually invaded as armies would crisscross the land going off to do battle with the great powers.. priests carry the Ark around the city 13 times, so scholars think there are two different accounts here woven together. Chapter 8 describes the victory at a place called Ai, which is near Jericho. Chapter 9 tells the story of the Gibeonites who join the Israelites; they are a local group that seems to join them. Chapter 11 goes on to stress that Joshua completed the task that had been begun by Moses. The remaining chapters are appendices: 23 is a farewell address, and 24 is a renewal of the covenant at Shechem. According to the Book of Joshua, Israel's tribal structure assumed its classical form at this time. The formation of the nation state, Israel, was much more complicated than the picture that's presented in Joshua 2 through 12. Scholars have proposed three possible models to explain the formation of Israel. The Yahweh cult may have been introduced by people escaping slavery from Egypt. Some elements within this group may have brought with them the story of a miraculous escape from Egypt to become the group that accepted the national god. The Hebrews at this stage were probably not a united people. In Judges, we read that they had not been captured: they were captured later, after Joshua's death. Excavations at Jericho and Ai indicate that both of these towns were laid waste at least 200 years before the probable time of Joshua. Of 20 identifiable sites that were said to be conquered or captured by Joshua and the next generations, only two show destruction layers for this time, Hazor and Beth-el. In Judges 4 and 5, it is still a Canaanite city and Joshua failed to take it. So the conclusion one can draw from all of the Bible is that Joshua was old and advanced in years. of the places from which the Canaanites were not expelled. Also archaeological evidence contradicts the picture in Joshua. Archaeologists have, indeed, found several sites in the central hill country -- which is pretty exciting-- and they were clearly newly established in the thirteenth, twelfth, eleventh centuries. They extend throughout the land, but mostly the central highlands. And these are thought to be Israelite, especially because they appear in places that the Bible identifies as strongholds of Israel. to have been peasant farmers, like other Canaanites. One interesting difference is the absence of any pig bones, which is kind of interesting. But in any event, this suggests that these settlements were established peacefully, not by a group coming in and conquering. Maybe they emerged from within, rather than being established by peoples immigrating from without. The revolt model proposes that Israel began really as a social revolution within Canaan. Some have suggested that Israelites escaping from Egypt may have joined with these disaffected Canaanites in revolt. in exile in Babylon. They are trying to make sense of the tragedy that has befallen them, the loss of their land. Consider how a text like Joshua 23 and Joshua 24 would go a long way towards explaining their fate while retaining faith in Yahweh. We're going to return to this when we reach the conclusion of the Deuteronomistic history in 2 Kings. It would be interesting to see how they would have reacted to the events of the time in which they were living. Deuteronomy seems to be aware of some of the dangers in this idea, the danger of a superiority complex, a moral danger involved in the notion of election. Israel was chosen by Yahweh in an act of spontaneous love--;it does not imply her perfection. God is repeatedly testing and correcting the Israelites until they are ready for the Promised Land. So Deuteronomy's farewell speeches and the death of Moses are fitting to a capstone to the Pentateuch.

ROUGE-1: 21.94, ROUGE-2: 20.60, ROUGE-L: 16.74
BERTScore: 61.18

==============================================
==================== [10/100] ====================
Summary:
we get the product hydroxymethylglutaryl CoA or HMG-CoA, as you notice the initials H, M, and G are part of this name. We are also given an additional hint and that is the acetyl CoA substrate provides the CH2CO2 CO2 minus moiety in the HMG -CoA product. So the hint is telling us that these two carbons, which I'm going to label in blue from acetoacetyl- CoA, are, in fact, these twocarbons, CH2 COO minus in hydroxyl-glut Daryl CoA. Now, let's take a look at the crystal structure and see what information we can gather there. The reaction will start by forming this thioester between the acetoacetyl-CoA carbons and the cysteine in the active site of the enzyme. The reaction first involves activation of the cy Steine, is deprotonated, and then cysteines can attack the thioesters and form a tetrahedral intermediate. Angstrom: The reaction may also be involved in the catalyzing of the reaction with the enzyme serine 307, which is a type of protease. experimental work and evidence. The study of the effects of drugs on the human body was conducted in the 1970s and 1980s. The results of the study were published in a book called "The Effects of Drugs on the Human Body" The book was published by Oxford University Press in 1989. It was the first of its kind to be published in the U.S. and is published by Simon & Schuster, a division of Simon and Schuster Inc. in New York. The book is available in hardback and paperback. Bogdan Fedeles: Today we're going to be talking about Problem 2 of Problem Set 4. HMG-CoA synthase is a key enzyme in central metabolism responsible for making the five carbon building blocks from which all sterols, such as cholesterol and steroid hormones are made. Bogdan: The three general mechanisms by which enzymes accelerate reactions are binding energy, general acid/general base catalysis and covalent catalysis. The binding energy also manifests when we're stabilizing, for example, the transition state of the reaction relative to the binding of the substrates.

ROUGE-1: 16.30, ROUGE-2: 12.88, ROUGE-L: 13.29
BERTScore: 68.45

==============================================
==================== [11/100] ====================
Summary:
There are differences between the DNA of two any human beings. These differences are due to polymorphisms, like single nucleotide polymorphisms. Microsatellites, repeats, insertions, deletions, translocations, these are all things that can happen to your DNA sequence that can modify in ways that, of course, are not enough to turn you into another animal. You're going to find approximately one difference every 1,000 bases. And understanding what these differences do and mean is one of the most interesting problems in current genome research. The typical operations we might be interested in doing are, for example, sequence matching. So to understand if certain stretch of a sequence matches anything else that you've seen before. Homology searches refer to looking for similarities between DNA sequences in different organisms. So if you find a high degree of similarity between the two genes, you can hypothesize that they are also going to have the same function. We will see as we go forward that we're going to encounter very different forms of data, according to what the purpose of our work is. LocusLink is a repository of information about genes, and it collects everything that is known about the genes. No LocusLink assigns a name to each gene, and if you stick to that name, then you're sure that everybody knows what you're talking about. Other resources that we'll mention later use a different way of naming genes. This makes things very difficult when you're trying to build programs to integrate information from different places. It's very, very hard to know exactly how to reconcile different ways of naming gene. If you have enough sequences from the same organism, you can try assembling them, putting them together, and trying to reconstruct the entire genome. This is what was done to assemble the human genome, for example, and all the other genomes that are being sequenced. You start with-- you look at the sequences you have, and if you can find overlaps, then you know that these two sequences are related in some way, and you proceed from there. And in the end you're going to build a map that tells you where all these fragments should be positioned. it gives a graphical view, so you can see it in the next slide, it's very clear. All the information it provides is available in easy to download and to parse formats. It provides arbitrary DNA sequences-- you can ask for any region of any human chromosome, you'll get back the exact DNA sequence for that region. Inside the genetic map, for example, you find information about disease genes, what bands break points. It's extremely detailed, because of course, it can rely on the whole set of NCBI databases. A SNP is a polymorphism that substitutes the nucleotide you should have at one location with a different one. There are ways of calculating the age of the SNP, so when that mutation arose in the history of our genome. Now the largest database of SNPs that we have again, is at NCBI, it's called the dbSNP. It currently contains over 4 million human SNPs-- actually, I think that by now this number is closer to 5 million SNPs. Almost 50% of the SNPs are validated, which is something very important, means that the SNP has been observed independently multiple times. for example, in 80% of individuals. And the alternative allele appears in 20% of the population. Now, knowing this frequency is very important, because it allows you, then, to do association studies. For example, to look for a correlation between a disease and this polymorphism. But in order to be able to do this, you have to know what is the baseline frequency. What is the original frequency in normal, so to speak, human beings. Yes? AUDIENCE: I guess the question then becomes, what's the base population is across base population? SNPs are used for population genetics. If a SNP arises in a population, then it tends to be limited to that population. Alfred at Yale is another very small database, but it has a very high quality, and it focuses on frequency data. SNPper is a resource that tries to integrate information from all the places that I sited so far. So it takes a lot of information about known associations between SNPs and diseases. says next.say next. "It's very important to specify what population you're looking at, because we're going to have an example in two slides" We need to be able to reliably identify which transcription factors bind to a given gene, and where, exactly, in the promoter region of the gene they bind. The ways that people have been using to do this are usually based on pattern matching. The binding site, as I said, is a small stretch of DNA, usually goes from five to about 20 or 25 base pairs. So they're really short. And they're characterized by [? concentric ?] sequences-- in general, they are not very precise. GEO is a database of gene expression and hybridization array data. The Stanford microarray database, again, is a repository of all the-- of a large number of micro experiments performed at Stanford. Other resources for gene expression are found in different PGA projects, PGA are programs for genomic applications, they are are large projects managed by the NIH. The [? tracks ?] PGA, for example, offers 565 microarrays from mouse and rat models of sleep, infection, hypertension, pulmonary disease. is a challenging task, because as we saw, biomedical data covers the whole spectrum of knowledge representation and management techniques that we know about. We are trying to make the most of the data we have, and we hope that it will help us understand more about the human condition. We hope that this article will be of interest to people around the world who are interested in biomedical data and data management techniques. For more information, go to: http://www.bbc.co.uk/news/science-and-biomedical-data/bio-data-measurement-mechanical-data. Alberto Riva: How is all this information represented? What are the different ways that we can store and describe this information? Where does it come from, where is it stored, how do we find retrieve and use it? He says there are some very deep differences between the kind of information you find when you're talking about the genotype, and when we'retalking about phenotypes. He says each one has its own specific nature and function, and needs to be treated with different tools.

ROUGE-1: 18.09, ROUGE-2: 16.73, ROUGE-L: 14.97
BERTScore: 61.06

==============================================
==================== [12/100] ====================
Summary:
to your friends is that you just blab of something, and I understand what you're saying, and, um, what goes on beyond that, is sort of not really accessible to consciousness. But well, to be able to have machines that interpret language correctly, we sort of need to understand the structure of these sentences. Unless we know what words are arguments and modifiers of other words, we can't actually work out what sentences mean. And I'll show some examples of that as to how things go wrong immediately, because a lot of the time there are different possible interpretations you can have. The idea of tree banks is to get human beings to sit around and put grammatical structures over sentences. People started thinking about grammars of languages even in modern times in the fifties, and people started building parses for languages in the 19, early 1960s. So, there was decades of work in the 60s, 70s, 80s, and no one had tree banks. Of course, you can get in touch if you want to talk about tree banks with me. Final issue is whether we want to allow dependencies to cross or not. Most of the time, um, dependencies don't cross each other. But sometimes they do, and this example here is actually an instance for that. So, we actually have another dependency here that crosses that dependency. And that's sort of rare, that doesn't happen a ton in English, but it happens sometimes in some structures like that. You could've said, I'll give a talk on bootstrapping tomorrow, and then a [inaudible] have a projective parse, but if you want to, you can kind of delay that extra modifier. And then the parse becomes non-projective. Parsing the sentence "I ate fish" involves three actions. The first is to shift things onto the stack or to do the equivalent of a Reduce where I build dependencies. The second is to treat the second from top thing on the stack as a dependent of the thing that's on top of the stack. The third is to leave the head on the Stack ate, but I sort of add this dependencies as other dependencies I've built. The finished condition of successfully parsing the sentence is my buffer is empty and I just have root left on my stack. The conventional way to do this is to say well, we want to have features. And well, the kind of features you wanted was so the usually some kind of conjunction or multiple things. And the problems with that, was these features were very sparse. Each of these features matches very few things. Um, they match some configurations but not others so the features tend to be incomplete. And that's not very good if you want to parse the whole web, whereas if you have something that's linear time, that's really getting you places. like this. And so these are the correct arcs and to evaluate our dependency parser, we're simply gonna say, uh, which arcs are correct. So here in my example, my dependency paths, I've got most of the arcs right but it got this one wrong. So I say my unlabeled attachment score is 80 percent or we can also look at the labels and then my parser wasn't very good at getting the labels rights, so I'm only getting 40 percent. And that's in our accuracy. even though at the end of the day, it was sort of looking at weights that went into a support vector machine. So that was kind of cool. And so the secret was we're gonna make use of distributed representations like we've already seen for words. So for each word, we're going to represent it as a word embedding. And in particular, um, we are gonna use word vectors and use them as the represent- the starting representations of words in our Parser. But well, if we're interested in distributed representations, it seem to us like maybe you should only have distributed representation of words. "We trained up our parser, um, and it was then able to predict the sentences" "This work has kind of, you know, deep learning people like to optimize" "It led to ah sort of a new era of sort of better parsers" "We're getting close to 95 percent unlabeled accuracy score from these models" "These models are sort of getting a bit higher again. But, youknow, so this work has continued along in the intervening two years" neural transition based dependency parsers. We sort of have gone down that we've halve that error-error rate. And we're now down to sort of about a five percent error rate. Yeah. I'm basically out of time now but there is further work including, you know, at Stanford. It's more accurate than 95 percent, right? So we- we're still going on but I think I'd better stop here today, um, and that's neural dependency parsing. [NOISE]. This week in week three, we're actually going to have some human language, and so this lecture has no partial derivative signs in it. In assignment three, what you're doing is building a neural dependency parser. And so we hope that you can put together what you learned about neural networks last week and the content of today, and jump straight right in to building the neural dependency parsers. And since I missed my office hours yesterday, I'm gonna have a shortened office hour tomorrow from 1:00 to 2:20.

ROUGE-1: 13.88, ROUGE-2: 13.26, ROUGE-L: 11.41
BERTScore: 59.34

==============================================
==================== [13/100] ====================
Summary:
Glycogen phosphor is U an enzyme that's regulated in several ways. It exists in two forms it exists in the glycogenosphor a form which is the form that has the phosphate on that people describe as the more active and it has the form without the phosphate known as the glycogens phosphor B that is less active. Def phosphorilation involves a kise or phosphatase right the r&t involve allosteric affectors okay all right okay so that's uh where we start now um. has to itself be regulated just like everything else has to be regulated because if we don't regulate it then everything's going to be def phosphorated all the time and cells aren't going to have energy like they need okay so we need to think about that Def phosphorilation and that's the wrong slide okay here's what we're after okay now what you see on the screen is a um a scheme that shows the regulation of phosphoprotein phosphatase that's pp1. put them in the same tube I've got purified pure glycogen phosphor and Pure glycogen synthes I put them together in a tube and I want to see what happens I add glucose and something very odd happens. The first person that answers that gets a free metabolic Melodies calendar for 2012 are they different active sites in the the same nope what' you say def phosphorilation come by and get your a calendar okay this Santa Claus is here okay all right so defosphorilation is happening but I only had two enzymes here. 5m I'll have my car pack with information so I don't have to memorize it and I'll feel like aart with my party just one to go and then ho I'll be all right I think you got it thank you. [Applause] oh yes thank you thank you [Music] sh if if if you're too crowded for the final and I don’t get a chance to say it I hope you have a great holiday and I will see you next time thank you indeed you too study hard. okay folks let's get started how's everybody doing pretty good Santa Claus has come to town and you know Santa does with naughty kids Hees them finals he gives them finals. He gives them very evil finals is what he does okay so look out for Santa Claus he's really a really a bad guy uh let's see let's think about a couple of things in terms of announcements. We have a couple surprises today one of which is standing in front of you with all this on and there's more surprises as well.

ROUGE-1: 13.95, ROUGE-2: 13.54, ROUGE-L: 11.05
BERTScore: 58.44

==============================================
==================== [14/100] ====================
Summary:
In the early days, if this was the drain, it was called a drain. But this is a local interconnect. It only extends over a very small distance. A very short metal wire locally on the chip to do interconnect from, say, one neighboring device-- in this case a transistor-- to another neighboring device, a resistor. Talk a little bit about historically about how contacts were made. And in fact, if you recognize that this is an NPN device, and this little n region right here is the emitter-- this is the P-type base as shown here in red. we want to talk about that is shown here on slide 6 is called the specific contact resistivity. And we usually use the Greek letter rho sub C. It's defined as being equivalent to the derivative of the voltage current density characteristic at a metal semiconductor contacts. And so we usually assume a structure where the current density is uniform across some contact area. Then you can calculate the contact resistance R in ohms, which is just the voltage divided by the current flowing through that contact. in the limit of very, very high doping. So we form these-- you see we still have this barrier, phi B. But the distance, the depletion layer thickness in the semiconductor, is very,very small. And that happens when you make the doping high. So what people do in practice is you dope very heavily above, say, above mid 10 of the 19th, you get quantum mechanical tunneling. That's really what's dominating. So for low contact resistivity, to get this number down, I need a small barrier. So you would choose a particular metal. silicide sheet resistance in ohms per square, it needs to be in this range of 6 to 10 ohmsper square. That's not a problem. None of that-- that's all in white, which means people know how to do that. The real problem is making these really good low resistivity contacts to the silicon. I just want to show an example of how-- so you get a feel for how the numbers work of how one does a contact resistance calculation. This is for a MOSFET. Ti-silicide has a tendency to agglomerate when it's very thin at higher annealing temperature. Cobalt bisilicide does not have that narrow line effect, but it gives you a slightly higher resistivity. The modern silicide that I mentioned here is this nickel silicide, NiSi. It's formed at very low temperatures, 450 or 500. And it's a little bit less than the case of titanium. It consumes 2.2 or 2.3 or so nanometers of silicon per every nanometer of metal. Nickel silicide has the lowest silicon consumption. Nickel is a very fast diffuser, remember, in silicon. Nickel contamination of equipment and of the wafers is has a low consumption, only 1.8 nanometers of silicon consumed per nanometer of metal. So if you're using a nickel silicide process, you're going to be limited to a lower backend temperature. But you can get reasonably low sheet resistance. And we'll go through these calculations at the end of the lecture. Slide 26 shows you some of the different uses of silicide in silicon technology. Silicide are used, as you can see, to strap the poly. It also forms a barrier layer, as we mentioned. And finally, it can be used as a gate material. And here's an example of nickel silicide, fully silicided gate that was published about six months ago by annealing at 450 degrees and using a thick enough layer of nickel. And you get a silicide all the way down to the gate interface. depletion of the polysilicon at very high gate biases. So people are concerned. They want to get rid of poly as the gate material. But poly is an extremely easy material to integrate. People know how to etch it. It's not reactive with SiO2. That's not the case for metals. So it here, what they had to do is put a metal and maybe some other harder material-- no, sorry, sorry. They had to put, yeah, contact material, and then maybe a dielectric. This is a very ultra-thin body device, or reasonably thin body device. This is an SOI, it's only 25 nanometers thick. The point they were trying to make with this was that the nickel did not diffuse in to the silicon. This looks like it's fairly stoichiometric, almost 1 to 1 silicon to nickel. Maybe a little bit nickel-rich. And these are sidewall spacer layers. They've made a very short channel device, only something between 35 and 40 nanometers. about your oral report or whatever, please get back to me. OK, thanks. About your oralReport.com. About. Your oral report. About Your Oral Report. Please get. back tome. about your oralreport or whatever. about. your oral Report or whatever,. please getback to me about.your oral Report. about Your OralReport.org. OK. Thanks, thanks, thanks for your report. You can send it to me via e-mail at jennifer@dailymail.co.uk. JUDY HOYT: Hopefully everybody's recovered from their Thanksgiving feast. What I'm showing up here is the schedule to orient us. This is lecture 22. We'll talk about silicides, device contacts, and I've added in a new material this year on novel gate materials. And then next week we have two class periods scheduled. There'll be four speakers in each. And those will be the oral reports and the student reports given on Tuesday and Thursday. And I just want to remind people, if you're doing an oral report, you're expected to provide handouts.

ROUGE-1: 12.54, ROUGE-2: 11.67, ROUGE-L: 9.74
BERTScore: 53.99

==============================================
==================== [15/100] ====================
Summary:
The cost function and the reward function are really the same thing they're just negatives of one another and the reason that we see both sometimes is the same kind of a cultural distinction that I alluded to before remember I mentioned that we have S a which comes from the study of dynamic programming that's where the reward comes from in optimal control. In optimal control it's it's a bit more common to deal with costs I don't know if there's a cultural commentary here well you know optimal control originated in Russia maybe it's more common in America. thing you actually want like reaching your destination or avoiding a car accident and then use those with more the more powerful reinforcement learning algorithms. In future weeks, we'll cover more of the powerful algorithms that we'll be covering in the next few weeks. We'll also cover how to use these algorithms to help you get what you want in the real world. Back to the page you came from. Follow us on Twitter @CNNOpinion and @cnnOpinION. We'd like to hear from you. The dagger algorithm aims to provide a more principled solution to the imitational and distributional Shi problem. The idea in dagger is to actually run the policy in the real world see which states it visits and ask humans to label those States. The goal is to collect data in such a way that P Pi Theta can actually learn from the data it's trained on. The basic version of dagger works like this and that's the version that you will all be implementing in your homework. It's a very simple algorithm to implement if you can get those labels. It can actually get up to fly pretty reliably through a forest dodging trees.

ROUGE-1: 27.07, ROUGE-2: 22.79, ROUGE-L: 12.35
BERTScore: 60.51

==============================================
==================== [16/100] ====================
Summary:
Jonathon Gruber: What stops people from just bingeing on everything? It's their budget constraint. He says we can use budget constraints and the utility function to describe how consumers make choices. GRUBER: We'll talk about what budget constraints are. We'll then come to talking about how consumers made constrained choices. And then we'll end with an example of food stamp use, which is very different from binge-buying in terms of the amount of food you eat. you as well. We write the budget constraint as saying that your resources, your income Y, can be spent on either pizza or cookies. You can essentially devote your income to some combination of pizza and cookies, but you have to consider how much they actually cost in doing that. Now this class is not alchemy. We are not literally transforming pizza into cookies. That would be kind of cool, but we're not doing that, OK? But it's effectively doing the same thing. your goal is to lose weight. So we're going to give you the budget constraint. We're not going to tell you what to eat. That's why it's better than dieting because, once again, Adam Smith was right. People like to have choices. They like to let choice drive things. So, for example, vegetables are like zero points. Snickers bars are like six points, et cetera. They have various point systems, OK? For example, suppose your budget is 30 points, which would be pretty typical. The poverty line is essentially a measure of what's a minimum level of resources you need to live in America. The poverty line for an individual is about $14,000. For a family of four, it's about $28,000, depending on where you're from. If you're below the poverty line in America, roughly speaking, you get help with buying food. And that comes through a program we now call SNAP, which used to be called food stamps. It's basically a program the government has that provides money for individuals to buy food. Be used to purchase food. So here's the question. Why go through this rigmarole? Why not just give people cash? This fancy thing, if we want to give poor people money, why don't you just give them money? And we're going to-- I don't want the answer yet, OK? What I want to do is show you graphically how we think about the trade-off. So hold your thoughts. Let's go to figure 3-5A. And let's start with a cash transfer. constrained optimization. Jonathan Gruber: People always get to the point that makes them happiest. He says if you force them to spend $500 on food, they must be less happy. GRUBER: Do people-- I don't want-- I just want to know if people understand the graphics here and the conclusions I drew. "This is not normative economics. It's positive. The positive thing is, given their utility function, they move from point y1 to y2," he says. stop there. We will come back on Monday, and we'll talk about how we actually go from this stuff to the demand curves we started the class with. Back to the page you came from. back to CNN.com home. Follow us on Twitter @cnnireport and @CNNOpinion. Follow CNN Living on Facebook and Twitter. For more, go to www.cnn.com/lifestyle and www.dailymail.co.uk/lpin. The median American household has $400 in the bank. The opportunity cost of a slice of pizza is two cookies. We're going to do a lot in this class of what we call comparative statics, which is, essentially, making changes in one thing or another and seeing what it does to the system. We think about a set as a line, but it's just a way of representing the same thing as the line. We care about the area because it represents the area we care about.

ROUGE-1: 13.24, ROUGE-2: 11.95, ROUGE-L: 10.43
BERTScore: 67.43

==============================================
==================== [17/100] ====================
Summary:
How good it is to be alive is a matter of adding up all of the--call it the contents of life. It's as though we've been assuming, and I have been assuming up to this moment, that being alive per se has no value. Life may have value in and of itself, but it's not mere life. What we want is the life of a human. We want a life in which we're accomplishing things, there's agency. The life of somebody who can have an emotional side. The central bad thing about the fact that I'm going to die is that because I'll be dead I will be deprived of the good things in life. But although I've been at pains to say this is the fundamental bad thing, I think it's arguable that this isn't the only bad thing. There are other features of death, as we experience it, that at least add to the way that death occurs for us. Or conceivably for some of these things, perhaps it mitigates it; it minimizes it. different aspect of death worth thinking about. What about the variability of death? After all, it's not just the case that we all die. Some of us make it to the ripe old age of 80,90 a 100 or more. Others of us die at 20, or 15, or 10, or younger. We could imagine a world in which everybody dies--everybody dies at the age of a hundred. Does it make things worse or better that there's this kind of variability? fact that there's variability and so some people get less than average--that extra bad, I suspect, outweighs the extra benefit of some people having more than average. We've had inevitability; we had variability. What about unpredictability? Not only is it inevitable that you're going to die; not only do some people live longer than others, you don't know how much more time you've got. We could imagine a world like this where it's inevitable; everybody's got some date on it. ask--so I'll throw the question out and we'll call it a day, start with this next time--then we have to ask, would it really be better to know? would you want the birthmark? Would you want to know exactly how much time you've got left? All Right. See you next time. Back to the page you came from. Click here for more from CNN iReport. Back To the pageyou came from, back to thepage you were from. Professor Shelly Kagan: Life on the experience machine is perfect as long as you've got the right tape playing. But the vast majority always says, no, there's something missing from that life, she says. Different theories of well-being might answer that in different ways, he says. He says we don't have any kind of accomplishments, we're not in the right kinds of loving relationships, because we want to have explanations as to why we're valuable to be with.

ROUGE-1: 12.37, ROUGE-2: 11.32, ROUGE-L: 10.20
BERTScore: 58.33

==============================================
==================== [18/100] ====================
Summary:
here-- in other words, at a certain distance r away, how much does the area of this sphere-- does this detector take up? And a simple formula for the solid angle is just the surface area of whatever you've got over r squared. This approximate formula-- the blue curve-- is a pretty good approximation of the red curve until you get really, really close to 5 centimeters away, or about this distance right here. But this is actually not that good of an approximation when you put a source very, very up close to a detector. If you were to take this detector and bring the radius down to 0, if that solid angle went to, well, infinity , then the count the sphere or how much tin foil you had to use. Michael Shorter: Counting for longer can decrease your standard deviation. He asks, how long do you have to count in the smoke shop to be 95% percent sure? Shorter says the more error you allow, the shorter time you've got to count for. He says sometimes, do you necessarily have to be95% confident of your result? Depends on what you're doing, he says. But if you can't get within 5% error, there's always some trade-offs you can make. you have to give an answer that will relate two times this standard deviation. And now we know the formula for standard deviation of this net counting experiment. So then we can substitute in our expression for sigma-- our uncertainty in quadrature-- and find out things like, well, it depends on what the information we're given is. And so let's actually look at that on the graph. If we keep on scrolling up just by adding stuff to the y-axis, eventually we see that it gets all straight. The standard deviation is the square root of the count rate over the time. So the standard deviation squared is just count rate overtime time. We've got too many variables, but it's easy to get rid of one of them, either C n or C g. Do you a question? MICHAEL SHORT: No, I was just going to say [INAUDIBLE].. MICHAELSHORT: Great. Now that everything is corrected here, what's next? We've Got Too Many variables. bag. MICHAEL AMES: We're going to let this count until Tuesday. Because, why not? And I don't feel like coming in over the weekend and turning it off. So this is just picking up all the gammas coming out of the bananas, and everything else that happens to get through the [INAUDIBLE],, and all the contamination on the inside of that. And we just let it count. And then you guys can calculate how much potassium 40 is in your ashes. You'll need to do the background subtraction. When you're running NAA, you really want to avoid having all these fast reactions. There's usually an energy threshold for the fast reactions, like 1 meV or so. If you're near the reactor, you're also getting some fast neutrons, which can give you an n p reaction. And that's a pain in the neck, because if you've got iron, you've always got a little cobalt floating around-- you maybe need to do a correction.any questions for Mike on what you've just heard? Well-timed, because we were just talking about this stuff all week. The experiment we're doing is basically change reactor power by half a megawatt. And we're currently at 500 kilowatts. We're going to bring the reactor up to 1 megawatts and then bring it back down. So before we can do this, you have to log into our log book as a trainee on console. We'll show you the proper way to make the entries. As you make those entries, you'll go ahead and then do the actual movement itself. using a regular rod to move the reactor power up. You want to be careful when you raise reactor power. When you get to about 80% of the power level you're going to-- since we're going up to 1 megawatt, that's about 800 kilowatts. You'll drive the regulating rod inwards. It'll slow until it actually starts to go down again. Once it reaches that value and you see it going down, you now know that you could control the reactor and keep it from going away. where it started, the 13.42 inches out of the bottom of the core. It might not make it all the way back up to [INAUDIBLE]. FRANK WARMSLEY: It'll be close. Compensate with the reg rod if you need to. 30.8. OK. And that's the end of the exercise. We'll be back in a few minutes with the results of the test. We hope to see you on "Larry King Live" next week. Michael Short: How do you know what, let's say, your dose distance relationship is? And how do you calculate all this stuff? Short: So I've actually laser-cut out a little Geiger counter jig from a previous class. And you guys can all do this too. And we'll take a look at the solid angle subtended by this detector right here. And what we notice is that except for extremely short distances, this approximate formula for theSolid angle does not compute.

ROUGE-1: 11.42, ROUGE-2: 10.79, ROUGE-L: 8.96
BERTScore: 58.73

==============================================
==================== [19/100] ====================
Summary:
All 1,000 individuals are in the 0, 0 state. There are initially no mutants in the population. But they're just replicating at some rate. Every now and then, mutation's going to occur. Now one thing we have to answer is whether these are nearly neutral mutations. Verbally yes or no? Ready? Three, two, one. AUDIENCE: No. PROFESSOR: No, right. And that's because we want to ask for, if it's nearly neutral, is the magnitude of S times N much greater or much less than 1? If they're much greater than 1, as is the case here, then we're in a nice, simple regime. Professor: If we start out with all 0, 0, and then one mutation [INAUDIBLE]? And if that mutation-- are we assuming that that mutation is 0, 1 and then figuring out how to fix it? Professor: You have to keep track of lots of different things, and which regime we're in and so forth. If you had one copy of each of these two mutant individuals in the population, that's the answer to what is the probability that this0, 1 mutant would fix in thePopulation. syllabus that I mentioned. I think the most important thing to stress when thinking about evolutionary game theory is just that this point that we don't need to assume anything about rationality. Instead, you simply have mutations that sample different strategies. And then you have differences in fitness that just lead to evolution towards the same solutions of the game. So it's evolution to the game solutions, so the Nash equilibrium, for example. And the more fit individuals spread in the population. And somehow, you evolve to the same or similar solutions. is indeed the Nash equilibrium. It's to do this strategy D that we're saying here. All right, now the question is why? And part of the challenge here is just understanding how to read these charts. Now, if you look at this chart, you say, well, gee, that is a shame. Because 1 is just not the biggest number you see here. And indeed, the important point to note here is that if both players had followed this strategy C for cooperate, D for defect, then both individuals would be getting fitness 3. So the problem here is, it's always better to play D. cooperator and for the defector. Do you understand? So what should these things look like? I'd like to encourage you to-- I'll give you 30 seconds to try to draw what this should look like. This is going to be the expected payout for a lone individual given the rest of the population is following some fraction of cooperator. DoYou guys understand what I'm asking you to do? Because I'm a little bit concerned that there are very few plots in front. are lines. But you can imagine that the only thing that's important are how these lines cross each other. So for example, there are only a few different things that can happen. You can have one strategy that dominates, which is what occurred here. And surprisingly, that does not mean that that strategy is higher fitness, in the sense that you may evolve to a state of low fitness. That's what's weird. YouCan have coexistence, or you can have bi-stability. In a population, if you have genetic A's and genetic B's that are each giving birth to their own type, then you evolve to some coexistence of genotypes. Whereas in this situation over here, we have coexistence. Does not matter where you start. So long as you have some members of both A and B in the population, you'll always evolve to the same equilibrium. And indeed, one of the things that we've been excited PROFESSOR: Exactly, so the Nash equilibrium mixed strategy plays A with probability. not the definition of that. But this thing is true, which means that it's a Nash equilibrium. And if you have questions about this, I'm happy to answer it. It's explained in the book as well. We are out of time, so I should let you go. But good luck on the exam next Thursday. If you have Questions and you want to meet with me, I am available on Tuesday. So please let me know. I'll be happy to talk to you. Professor: We're going to start with a short review problem on rugged landscapes. Then we'll get into the core topic of the class, which is evolutionary game theory. We'll discuss why it is that you don't need to invoke any notion of rationality. And we'll say something about the evolution of cooperation and experiments that one can do with microbial populations in the laboratory. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation or view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu.

ROUGE-1: 14.89, ROUGE-2: 14.36, ROUGE-L: 12.24
BERTScore: 58.88

==============================================
==================== [20/100] ====================
Summary:
hey everyone it's sarah with registerednessrn.com and in this video i'm going to be covering sinus tachycardia. Whenever you're done watching this youtube video you can access the free quiz that will test you on this content. Let's get started what is sinus Tachy Cardia? Well sinus tells us that we're dealing with a heart rhythm that originates in the sa node this is also known as a sinoatrial node and it is found here in the upper part of the right atrium. you want to look at those p waves make sure that they are normal. Make sure that there is only one p wave in front of every qrs complex and make sure they're upright. With sinus hack the atrial rate is going to be greater than 100 beats per minute and then whenever you're looking at the p wave take your calipers and go from p wave to p wave and make make sure there's the same distance between those because that means it's occurring at a regular interval. sinus tac because the rate is so fast remember with sauna's bradycardia the qt interval was a little bit longer and then after each qrs complex you should have a t wave present as well. Now let's analyze this rhythm together using this criteria we just went over here we have a six second ecg strip and the first thing what I want to do is i want to look at those p waves and make sure that they're normal if you look at this rhythm with me you can notice that you see these squiggly lines throughout we refer to that as artifact. Sustained sinus tachycardia can actually decrease cardiac output in your patient. As a nurse we want to assess for any potential causes for why our patient is running this rhythm. The patient can wear a halter monitor if they're at home having this and this will monitor their rhythm and then it'll go back to the cardiologist who will read can be ordered to bring down the fever and then the nurse's role is to report the rhythm change to the physician and let them know about it. cool extremities and then you want to teach the patient if you're able to avoid any activities that could further increase their sinus tag like if they're smoking or drinking caffeine or using any other stimulants because we don't want their heart rate to get up any higher okay so that wraps up this review over sonos tachycardia. If you'd like to watch more videos on this topic you can access the link in the youtube description below. Click the link below to access the video. of the electrical conduction system and the whole goal of the electrical Conduction system is to stimulate your heart muscle cells so they will be and pump blood throughout your body so it all starts here with the sa node which again is located in the upper part of the right atrium. If a patient develops sinus tachycardia it could be that their disease is worsening and it's a warning sign that hey this needs to be investigated more so anytime you have a patient and they're going in to sinus tack you want to investigate it you don't want to just write it off.

ROUGE-1: 25.08, ROUGE-2: 24.13, ROUGE-L: 19.82
BERTScore: 66.11

==============================================
==================== [21/100] ====================
Summary:
In this problem, we're given a collection of 10 variables, x1 through x10, where each i, xi, is a uniform random variable between 0 and 1. And we'd like to develop a bound on the probability that some of the 10 variables being greater than 7 using different methods. In part A, we'll be using the Markov's inequality, which says the probability x is greater than a is bounded above by the expected value of x divided by a. For part B, let's see if we can improve the bound we got in part A using the Chebyshev inequality. know how the distribution of a standard normal looks like, we can go to table and look up certain properties of the resulting distribution. So right now, we have about 10 variables. If we believe 10 is a large enough number, then this will be roughly equal to 1 minus the CDF of astandard normal evaluated at 2.19. And we could look up the number in the table, and this gives us number roughly, 0.014. Now let's do a quick summary of what this problem is about. We're asked to compute the probability of x greater or equal to 7. that even with 10 variables, the truth is more like this, which says that the distribution of x concentrates very heavily around 5, and hence, the probability of x being greater or equal to 7 could be much smaller than one might expect. That is, x is more likely to be greater than 7 than it is to be less than 7, and so the probability is much lower than one would expect. It is also more likely that x is greater than or less than 5, rather than equal to 6 or 7. a better bound. To remind you what a central limit theorem is, let's say we have a summation of i equal to 1 to some number n of independent and identically distributed random variables xi. We take the sum right here, and subtract out its means, which is E of the same summation, and further, we'll divide out, what we call normalize, by the standard deviation of the summation. So as the number of terms in the sums going to infinity, we will actually see that this random variable will converge in distribution.

ROUGE-1: 39.18, ROUGE-2: 35.32, ROUGE-L: 25.89
BERTScore: 73.51

==============================================
==================== [22/100] ====================
Summary:
the string, too, were massless. So we have simply mp plus mw a. And so we can now solve for the tension in the string, which is equal to mp plusmw times g plus a divided by 3. And recall that this tension, that the string is pulling, this is what we called the force that the person [? of ?] the string on the person. And by Newton's third law, that's also, on the washer, that’s also the force. So now that we've combined pulley A, string 2, platform, and washer as our system, we can now address our question. If we measure the acceleration of the person, what is the force that the person pulls the rope down with? Well, of course, that will just be the tension in the string. And with this simple system,we can now apply Newton's second law, F equals ma. And so by thinking about how to choose a system, what could be a very complicated problem, with lots of equations, is simply one equation.

ROUGE-1: 75.59, ROUGE-2: 74.19, ROUGE-L: 49.24
BERTScore: 84.87

==============================================
==================== [23/100] ====================
Summary:
In order to be successful whenever you're drawing blood or starting IVs you really have to know a couple things number one you need to know the name of the vein that you're going to use and its location along with what can that vein actually handle. Some veins can only handle about a 20 or a 22 gauge IV cannula versus some of them can handle 18 gages 16 gages. I also like to use accessories cephalic vein along with the median vein of the forearm and of course those hand mains the dorsal venous network.

ROUGE-1: 13.00, ROUGE-2: 12.62, ROUGE-L: 13.00
BERTScore: 67.49

==============================================
==================== [24/100] ====================
Summary:
So, now we have enough knowledge. So that, to talk about the factors affecting the supply schedule or supply function. So, now that we have that knowledge, we can talk about how to get the most out of the resources that are available to us. That's what we're trying to do here. We're going to try and get the best of both worlds. We'll see how it goes from here. It'll be interesting to see how we get on with it. We've got a long way to go, but we're getting there. When we talk about complement and substitute, we have to be clear whether we are talking about the demand side or the supply side. So, what do we mean, when do we say a good is complement in production or complement in supply? Can you give an example, first substitute think about it? Plastic chair to iron chair like. Boeing is a manufacturer of airplanes; it makes civilian airplanes as well as military aircrafts. If there is an increase in price of military aircraft, what would happen? Boeing devote more a space to military. To manufacturing, to manufacture military. aircrafts, it would go down.

ROUGE-1: 40.39, ROUGE-2: 29.58, ROUGE-L: 27.33
BERTScore: 61.96

==============================================
==================== [25/100] ====================
Summary:
Psychologist David Frum: What matters most for the moral blame that we assign is not what happened, but what Grace thought she was doing. He says that in scenarios like the one he gave you, what matters most is not how bad the outcome was, but how much blame Grace deserves. Frum says the scenario isolates one important feature of our moral judgment and also an important feature. of a lot of the rest of our social cognition. He asks: How much blame does Grace deserve for putting the powder in the coffee? And how much do you think she deserves? This ability has been studied all the way to understanding some of the most complex, abstract ideas that we ever encounter. The debate about whether this capacity for thinking about other people's thoughts is or is not shared with which other animals has gone on continuously since the late '70s. That's the origin of this debate, and it's not resolved yet. But it led to the construction of this particular task as a litmus test for what one person knows about somebody else's thoughts, called the false belief task. false belief task looks like. This is being given to a five-year-old human child. Do you know what pirates really like? CHILD: What? REBECCA SAXE: Pirates really like cheese sandwiches. So Ivan puts his sandwich over here on top of the pirate chest. And while Ivan is away, the wind comes, and it blows the sandwich down onto the grass. And now, here comes the other pirate. This pirate is called Joshua. And Joshua also really loves cheese sandwich. So which one do you think Ivan's gonna take? How do we think about other people as containing internal mental lives, mental representations? I'm going to talk about just fMRI, although I do use other methods to study this problem. I think fMRI has been both an incredible gift to our ability to understand the human mind and also imposes a huge number of limitations on what we can discover. And so what I want to tell you about is just a tiny bit of my phase one investigations using the early strategies that fMRI allowed us. And then a more in-depth look at how I'm using more modern techniques in fMRI to try to get further. mind is that, with respect to the representation of other people's thoughts, that doesn't tell us anything about how our brain does it. So the things that would make something a theory of mind-- a representation of who thinks what, why, and with what consequences-- we can't see in the univariate signal. What I think we're starting to make progress on using MVPA, is getting beyond that this brain region is involved in theory ofMind and trying to ask something about what is represented in this brain area. V1 is called V1 because information goes from your eyes to the LGN of your thalamus. It's the first cortical stop of visual information. One way that we know that it's very involved in vision is that if you're seeing visual stimuli, you get a big response in V1. That's a selectivity type measure. What we want to know about V1 is what transformations over the information coming from LGN is V1 implementing. And that's why theories like Marr's theory-- which say that there are receptive fields-- are important. Haxby style analysis is the first form of MVPA introduced, and they were introduced by Jim Haxby in 2001. The idea is, take a region you care about and ask this basic question. For some future that I wonder if it's represented, is the correlation across neural responses more similar when the stimuli share that feature? So that gives you a pretty robust measurement, because you're using all the voxels in the region to get one number out-- the correlation. right TPJ more similar, suggesting that which part of the right TPJ is more or less active contains information about whether or not the person who committed the murder knew what they were doing at the time. This is specific to the rightTPJ. So these are a bunch of the other brain regions involved in theory of mind and social cognition. And none of them contain any information about this dimension at all. So this dimension is represented in theRight TPJ and not represented anywhere else. Some people think that basically what you thought you were doing is all that matters in these stories. it differs across regions. So we could show that this was present in the right TPJ but not present in other regions. That's a whole bunch of extra information than we ever were able to get before. Another way to do this is to build stimulus sets that, for example, have two orthogonal dimensions and ask about both of them. So that's another way that you can use this method-- hypothesize two or three dimensions within the same stimulus set. And then we can get interactions between these to say, OK, the rightTPJ does represent some dimensions, doesn't represent other dimensions-- in principle. stories vary. So here's a bunch of stories. Leslie has just been in a big, important interview. And he sees himself in a mirror, and he sees that his shirt has a big coffee stain down the front. Another one is-- Eric gets to a restaurant to meet his fiance's parents. So that's two completely different stories. And then the third story-- Abigail is painting her dorm room, and she hears somebody's footsteps down the hallway. And the footsteps sound like her beloved boyfriend's. So these stories are all different. more general way of thinking about fMRI data. This particular method, using spatial correlations, is very stable and robust. But it's a special case of a much more general set. It's a very stable, robust method, but it's not a very general way to look at fMRI. It doesn't work for all fMRI patients, but for some, it could be a very useful tool. It could be used in the future to help people understand their brain's responses to stress. When people talk about social cognition they do actually mean all of those things. The scope of tests of our ability to think about other people's thoughts or internal states is very large. I'm almost exclusively going to talk about the first one, so how we think about what other people see, think, and know-- but not want or feel. At the end I'll come back to wanting you watch the video, you see that the knowledge the kid is bringing to bear is a way richer than just his correct prediction.

ROUGE-1: 20.17, ROUGE-2: 18.76, ROUGE-L: 15.87
BERTScore: 57.58

==============================================
==================== [26/100] ====================
Summary:
and do the same chemistry, but they have different metal cofactors depending on where they evolved. The function in all cases is to generate a radical in the active site and then the chemistry is the same in all these things. And the function of the metalcofactors in all case is to create a radical, which is the key to the chemistry in all of these cases, says Dr. Michael Bociurkiw, a professor of chemistry at the University of California, San Diego. Joanne Stubbe's lab works on the only cool enzyme in the world-- ribonucleotide reductase. It's the only way in all organisms that you make the building blocks de novo that are required for DNA biosynthesis and repair. If you inhibit this enzyme, you have no building blocks. You can't survive. So from a practical point of view, it's the target of drugs they use therapeutically in the treatment of cancer. And I think in probably not so distant future in the antibacterials because there are sufficient differences between humans and bacteria reductases.

ROUGE-1: 38.51, ROUGE-2: 33.68, ROUGE-L: 22.17
BERTScore: 66.96

==============================================
==================== [27/100] ====================
Summary:
The fundamental theorem of calculus can be used to solve any differential equation. The product rule says take the derivative of [INAUDIBLE] that is e to the minus t is one. So the two terms from the product rule are the two term in the differential equation, which is dy dt. The derivative of that product is one term will be y and the otherterm will be q. That's a remarkable formula for the solution to a basic differential equation and it's a key example in differential equations. rather I just called the function f. A function at a point a little beyond t, is approximately the function at t plus the correction because it-- plus a delta f, right? A delta f approximately? It's approximately delta t times the derivative at t. Just draw a picture. So let me draw a graph of-- oh there's the graph of e to the t. So it starts up with slope 1. Let me give it a little slope here. OK the tangent line, and of course it comes down here Not below. this isn't so practical. Tangent parabola, quite practical. Higher order terms, less-- much less practical. But the formula is beautiful because you see the pattern, that's really what mathematics is about. They all fit that pattern and when you add up all the terms, if you have a nice function, then the approximation becomes perfect and you would have equality. And those are the best functions of mathematics and exponential is of course one of them. OK that's calculus. Well, part of calculus. GILBERT STRANG: Differential equations is the big application of calculus. He says you really do need to know basic derivatives. Strang: You can create the derivatives of an enormous array of functions using the key rules. He shows how to create the parabola, the Taylor series, the tangent line and the Taylor ratio, among other things, to get a good idea of how to solve a differential equation. He concludes by saying, "I think it's worth thinking about what we know"

ROUGE-1: 31.31, ROUGE-2: 27.50, ROUGE-L: 21.82
BERTScore: 64.74

==============================================
==================== [28/100] ====================
Summary:
area of my scanner and say okay say if the robot was sitting standing over here that's the area it may have observed then I can simply check is the current sensor range is there an overlap between the current sends a range and the possible observation that I obtained from b1 on b2 and if I found places for which this holds then this is the case for b1. In contrast is that if I look to be - I can say okay the uncertainty of b2 extended with the visibility range of my of my sensor by no means overlaps with a so it's extremely unlikely that a can match b2. Based on the position of my stereo camera I try to build a local model of the surrounding so what we want to estimate is the X Y that and three angles your roll pitch and yaw so if you have this your camera looking forward this is roll this is pitch and this is your and so as I said before by adding this IMU to the to the stereo camera and the in this case the the camera is looking downward to me of the IMU on top we know the gravity vector and so this eliminates the roll directionally. Ambiguity or not it's kind of if the uncertainty lips of speakers need to seen all that area to make this is no that's the only place where I actually can match and about the special clustering technique for the original paper where you find all the information here's the work back in also recognizing places using spectral clustered local matches. This is exactly the approach that I presented here and actually a couple of the slides that I use in here or of the images material at least comes from a tin Olsen. okay so welcome to the last lecture of this course here in this winter term and what we discussed so far in the course were mainly the so-called backends or optimization engines or probablistic estimation techniques. Today I would like to give a very very of course brief short overview about front ends and one important aspect inside successful front ends on how to determine if a constraint is likely to be a correct one so we are still interested in avoiding to add roam constraints although we've learned that we there are techniques which can deal with outliers in the data Association.

ROUGE-1: 5.88, ROUGE-2: 5.77, ROUGE-L: 4.78
BERTScore: 64.56

==============================================
==================== [29/100] ====================
Summary:
marketing is about creating communicating delivering and exchanging value the way that we communicate the value is through the brand. The brand is what's wrapped around the product so all products in a given category have the same generic functionality. What makes one car different from another is the brand and we're going to talk more about perceptual maps where our brand is positioned in the marketplace relative to our competitors. It's not a question of whether or not our product is expensive or whether it's a high quality the issue is the perception of the target market the people that we want to buy our product. Chanel: If our target market doesn't think it's high quality then we have a huge problem. Instead of going home crying what we do is what chanel said is develop a compelling advertising campaign to communicate that our product is of a high quality. We need to have pillars of support that means that we need to having proof points we get not enough just to say ourProduct is a highquality we have to support that. We have to provide proof in our commercials in our print ads on our website so think of marketing another way to think about marketing. is that going to cost a hundred and fifty thousand dollars to do more intercept in multiple cities and get approximately 1500 respondents now when we do focus groups we also do multiple rounds of focus groups because each round is iterative so we learn from the first round of focus group and then we incorporate that in the next round before we do the quantitative research. i recommend that do the focus groups then we're going to do quantitative research before that now both of those focus groups and questionnaires qualitative and quantitative research as i describe that. Marketing is about four things creating communicating delivering and exchanging value. Value is a function of the price the quality and the benefits so let's make sure that we don't think that value means low price. For something to be of a good value it doesn't need to be a low price it could be a high price but it's a very high quality and it has a lot of benefits do you agree who could explain that further good tell us your name theresa bad um i mean would you consider that clothing yes.

ROUGE-1: 23.47, ROUGE-2: 22.91, ROUGE-L: 17.76
BERTScore: 61.46

==============================================
==================== [30/100] ====================
Summary:
Jeremy Bentham's principle is "the greatest happiness of the greatest number" He thinks all utility is quantifiable. He allows interpersonal comparisons of utility. Diminishing marginal utility is the principle of diminishing marginal utility. If you don't have a car and somebody gives you a Porsche Turbo, you're going to get less utility from the second Porsche than you had from the first one. If it turns out Leonid Leonid has a vastly superior capacity to anybody else, then we could get a huge increase in total utility. taking a lot from B and C and giving it to Leonid, so that we would say "allow," right? Or we could think of this change from the status quo-- we go to a more inegalitarian society and, again, the greatest happiness of the greatest number has increased. We have a world here where there are eighteen utils and a world in which there are nineteen utils. If the utility that the Aryans gain from practicing genocide and ethnic cleansing against the Jews exceeds the utilities that the Jews lose, there would be no reason under Bentham's doctrine not to do it. Shapiro: utilitarianism was a doctrine that was thought to be profoundly radical and frightening to rich men. He says Bentham completely saw that this was an implication of his doctrine. Shapiro: If you assume diminishing marginal utility, utilitarianism becomes a very radical doctrine. He adds: You're going to get into a very messy world of macroeconomic predictions and counter-predictions about whether and when you reach this point of practical equality, or when the gains from downward redistribution are offset by the losses from shrinking of the pie. Bentham: In principle absolute equality would maximize the greatest happiness of the greatest number, but in fact if a government set out to do that, the rich would rebel. He's saying you have to work with individual motivations. In the transition to democracy in the South maximize utility in the society, individual motivation is vital. The rich will burn their crops before giving them to the poor. You have to see individuals as the basic generators of utility. The great enemies of public peace are the selfish and dissocial passions-- necessary as they are. classical to what we're going to all neoclassical utilitarianism is a subject with which I will begin on Wednesday. See you then for the next installment of this week's Daily Discussion, which will focus on the role of utilitarianism in the development of the modern world. Back to Mail Online home. back to the page you came from. Click here to read the first installment of the Daily Discussion. Follow us on Twitter @CNNOpinion and @jennifer_newton. Econ professor: We say that utility is quantifiable and expressible through money. But related to that, we can work with a doctrine of revealed preference. We can vary the price that we charge admission for the course. We could even influence your behavior without actually changing your preferences, he says. Professor: Any other examples of where this becomes problematic? The next, and the next, the fourteenth, isn't going to be going to some aspirin, or taking an aspirin, isn’t it?

ROUGE-1: 15.92, ROUGE-2: 13.89, ROUGE-L: 10.69
BERTScore: 59.64

==============================================
==================== [31/100] ====================
Summary:
When we write out peptides, we always write them N to C. If you don't always remember to write things in this order, and you tell your friend, oh, go and get this peptide made, they'll make the wrong peptide. When I write the MIT peptide, I write M first, I second, T third. If I wrote TIM, it would be a completely different chemical structure with different chemical properties, so the directionality is important to understand. The process whereby you go from the extended primary sequence to the folded structure is called protein folding. It's not simple because what you're doing is you're solving a massive energy diagram, where as you fold a structure up, you're trying to maximize all those non-covalent forces for maximum thermodynamic stability. What I'm showing you here is what's known as the alpha helix, an ordered structure exclusively made up from the hydrogen-bonding interactions of the peptide backbone. A single amino acid change in the primary sequence of collagen can destabilize the structure, so it is no longer viable. The disease type I'm going to talk to you about is a set of diseases known as collagenopathies, and the particular one is called osteogenesis imperfecta. A lot of babies with this defect can't even be born through the birth canal because it would crush the bones, and many of them don't survive very long at all. Some survive with different kinds of cases, but their lives are greatly impacted. well-aligned as the rest of the structure. And then that defect gets propagated into all the fibrils and results in the weakening of the bones. Either the collagen fails to form properly, or the collagen, when it forms, it has much less mechanical stability. So I think that's a good place to stop and I'll pick up next time with hemoglobin. There's a great link on the website to the Protein Data Bank to see how enzymes work. These slides are posted with these reading assignments, and they're posted in color if you want to look at them again. Lipids are mostly hydrophobic, which can also be referred to as lipophilic. In those fatty acids, they could be fully saturated. This is a very important semi-permeable membranes are made up through the non-covalent, supramolecular association of phospholipid monomer units. If they were fully permeable, anything could come and go and they wouldn't be much use frankly. But because they're semi- permeable, only a few things can come and going without extra help.

ROUGE-1: 10.83, ROUGE-2: 10.41, ROUGE-L: 8.93
BERTScore: 59.49

==============================================
==================== [32/100] ====================
Summary:
. Without using the representation in terms of. derivatives, with respect to a coordinate, without using the representations, in. terms of translations and rotations along the sphere, right? When we just used the commutation relations, and nothing else, what we found was that the states corresponding to these guys, came in a tower. And we quickly deduced that it is impossible to represent the half integer states with a wave function which represents a probability distribution on a sphere. We observed that that was impossible. can measure that angular momentum by measuring the deflection. The bigger the angular momentum, the bigger the magnetic moment. If the electron weren't rotating, it would just go straight through, right? It would have no angular momentum. And thus it would not reflect. If it's rotating, It's gonna deflect. Here's the experiment we do. And here's the experimental results. The experimental results are every electron that gets sent through bends. And it either bends up a fixed amount, or it bends down. over r? PROFESSOR: Oh shoot! Yes, that's supposed to be one of our-- Thank you. Yes, thank you for that typo correction. Thanks OK. So, anytime we have a system which is rotationally. invariant, we can write the energy operator in this fashion. And now, you see something really lovely, which is that this only depends on r, this only. depends on the angular coordinates, but only insofar as it depends on L squared. eigenvalue equation. This is the result of acting on phi with the energy operator, and this is the energy eigenvalue. Cool? So, the upside here is that when we have a central. potential, when the system is rotationally. invariant, the potential energy is invariant under rotations. Then the energy commutes with the angular momentum squared. And so, we can find common eigenfunctions. When we use separation of variable, the resulting energy eigenevalue equation becomes nothing but a 1D energy eigs equation. by multiplying the whole equation by r. If you see this, declare in your mind a brief moment of triumph, because you know what technique to use. You can do this sort of rescaling by a power of r. And more generally, if you have a differential equation that looks like. a derivative with respect to r plus a constant over r times phi, you know how to solve this. OK? Very useful things to have in your back pocket for moments of need. So, let's pick up with this guy. would've got the same equation. And that means that the energy eigenvalue can depend on l, but it can't depend on m, right? So, that means for each m in the allowed possible values, l, l minus 1, [? i ?] minus l-- and this is 2l plus 1 possible values-- for each of these m's, the energy is the same. And so, here we have a degeneracy. And this degeneracy isn't fixed by rotational invariance. And why is this the right thing? Rotational symmetry? they're all wrong. Every single model you ever get from physics is wrong. There are just some that are less stupidly wrong. Some are a better approximation to the data, OK? This is not hydrogen. This is going to be our first pass at hydrogen. OK, so let's solve it. So, if V is minus e over r squared, then the equation for the rescaled wave function, u, becomes minus h bar squared upon 2mu prime prime of r plus the effective potential. The form of this differential equation is, OK, it's not different in any deep way, but it's a little bit easier. As rho goes to infinity, which terms dominate? Well, this is not terribly important. That term is gonna dominate. If l is equal to 0, then this is the only term that survives, so we'd better make sure that that behaves gracefully. So, this tells us, having done this in analysis, we should write that rho to the l plus 1 times e to the minus root epsilon rho times some remaining remaining terms. nice bit of experimental data, but we've discovered the energy is, in fact, not just independent of m, but it's independent of l, too. Why? What symmetry is explaining this extra degeneracy? We'll pick that up next time. Back to Mail Online home. back to the page you came from. Click here to read the rest of the article. Back To the pageyou came from, click here to reads the rest. Back into the pageYou can now read the full article on this site. Professor: Imagine take a magnet, a little, tiny bar magnet. In fact, well, imagine you take a little bar magnet with some little magnetization, and you send it through a region that has a gradient for magnetic field. If there's a gradient-- so you know that a magnet wants to anti-align with the nearby magnet, north-south wants to go to south-north. So, you can't put a force on the magnet, but if you have a gradient of a magnetic field, then one end a dipole can feel a stronger effective torque then the other guy.

ROUGE-1: 12.89, ROUGE-2: 12.21, ROUGE-L: 11.01
BERTScore: 61.85

==============================================
==================== [33/100] ====================
Summary:
The course is really less about programming and more about dipping your toe into the exotic world of data science. The lectures will be-- and maybe I'm speaking euphemistically-- a bit faster paced. There'll be a few additional bits of Python. Today, for example, we'll talk about lambda abstraction. Inevitably, some comments about software engineering, how to structure software engineering. And the final exam will be a final exam based upon all of the above. All right, prerequisites-- experience writing object-oriented programs in Python, preferably Python 3.5. The 0/1 knapsack problem means you either take the object or you don't. You can solve it with what's called a greedy algorithm, and we'll talk much more about this as we go forward. These might be the most valuable items here. So here is in words, written words what I just said orally. There's more stuff than you can carry, and you have to choose which stuff to take and which to leave behind. I should point out that there are two variants of it. that once I take something that's 1,485 calories, I can't take anything else, or maybe 1,200 calories and everything else is more than 300. Once I take one thing, it constrains possible solutions. A greedy algorithm, as we'll see, is not guaranteed to give me the best answer. On Wednesday, we'll talk about how do you actually guarantee finding an optimal solution in a better way than brute force. See you then. you about greedy algorithms. and I'm going to allow myself 1,000 calories. Well, here what we see is the winner will be greedy by value, happens to find a better answer, 424 instead of 413. So there is no way to know in advance. Sometimes this definition of best might work. Sometimes no definition ofbest will work. You can't get to an optimal solution with a greedy algorithm. On Wednesday, we'll talk about how do you actually guarantee finding an optimal Solution in a better way than brute force. John Guttag: The main topic of the course is what I think of as computational models. How do we use computation to understand the world in which we live? What is a model? We'll talk about three kinds of models-- optimization models, statistical models, and simulation models. The first time I talked about the knapsack problem was 10 minutes into the class before I realized it was a class. It's what we old people used to call a backpack, and they used to look more like they do today.

ROUGE-1: 15.73, ROUGE-2: 14.49, ROUGE-L: 10.37
BERTScore: 59.90

==============================================
==================== [34/100] ====================
Summary:
Milton Friedman: What really matters to you in a consumption decision is not so much your current income, but what you expect to get on average during your lifetime. So you don't consume all you have because you know there are many years ahead of you where income will be lower than your consumption needs. So when you start thinking about consumption in those terms, what really matters, then, is total wealth more than income. How wealthy you are will pin down more or less the consumption you have. expect to inherit or whatever, minus the debts you have. So very much as we discussed in the previous lecture in the context of asset pricing, the expected present discounted value of the cash flows of all the assets you have, that's your financial wealth. You have more financial wealth, even if you have no income today, you will probably borrow against that wealth to the extent that you can. And so you're going to fund the consumption, which is above your current income just because you have morefinancial wealth. In fact, the very rich seldom sell assets to fund consumption. not be worth a lot simply because interest rates are very high. The discounting of the future cash flows is very high, and in that environment, investments that give you a return, a quick return, are worth more than things that have a pay-off in the very long run. So the decision, for example, of buying a machine needs to look at the price of the machine right now and then at the expected present discounted value of the cash flows, OK? So let's think a bit more carefully about that decision. If the Fed cuts the interest rate but doesn't persuade anyone that this rate will remain low in the future, then it is going to get very small effect on output. However, if we convince people that there will be future changes, that the rates will remain lower for a long time, that means that this IS now will shift to the right, OK? That's what we have here. So again, expectations mattered quite a bit. If you convince the markets that-- and the markets and consumers, households, and so on-- that you're cutting interest rates, with that, you'll be successful in. Most of the time when you have episodes of fiscal consolidation in environments that are not of very high distress, financial crisis, and so on, it typically sort of-- how successful that is depends a lot on whether people expect to be a sort of implicit deal between the central bank and the Treasury. So, for example, if you have a fiscal contraction that leads to an anticipation of a big cut in interest rates in the future, that may be expansionary. It can offset quite a bit of the fiscal contraction side. was expansionary. That was contractionary. But it was overwhelmed or offset, more than offset by the improvement in the outlook that you had. And that also happens with monetary policy. Countries that have high inflation problems and so on sometimes get-- and they have to go through dramatic tightenings. Yes, most of them get very short-lived recession. But sometimes they are veryshort-lived recessions because eventually the reduction of the instability caused by high and unstable inflation sort of ends up dominating any direct contractionary effect. Expectations play a big role in the decision of all economic actors. We'll look at investors, asset pricing and so on. We will develop a life-cycle theory of consumption, which says people know early in life that they have a lower income than they will have later on. Traders, given the opportunity, will make a difference, that will do a lot with wealth, CABALLERO says. "There is a lot of interesting stuff that is hidden in that autonomous component of consumption," he says.

ROUGE-1: 16.65, ROUGE-2: 15.86, ROUGE-L: 14.01
BERTScore: 59.78

==============================================
==================== [35/100] ====================
Summary:
it doesn't work so let's kind of look at them in the atas model right we have this Keynesian view. We have our kind of a classical view and we have our what would be called supply-side view. There's more views than that obviously but we're just gonna look at these these three stir them the three main ones. We're at some full employment level of output YF and here we are initially we're in some recession right we're at output level say y1 and some price level just call it P l1. change the demand for loanable funds so you have this market right if you're gonna have the government go out and borrow money they're going to borrow the money. There's a market out there for people borrowing and lending the money and that can be for us savings bonds. When you guys put money into your savings account your parents put money aside for college. They're the suppliers you guys are borrowing money to go to school and you're now demanders you're the ones taking money out. F and basically this guy says look we know eventually the short-run aggregate supply curve will increase and we go to the full employment level of output if you guys engage in this type of policy over here. The deficit today means that at some point in time in the future you're going to have to increase taxes so you can kind of think of it as the budget deficit over two different time periods. In fact thanks to interest it won't be 20 that you have to borrow or in raise taxes for it'll actually be like say 30 all right. revenue will we collect how many guys are going to work later today okay what's what's your name again Paige okay what do you do again okay. So here the supply-side view this is called the Laffer curve. It's not what you spend it's what you tax and it's not even necessarily the amount that you tax it's the marginal tax rates that are important. If tax rates are 20% if the government takes 20% of my pay they are in essence taking all of my. their real income they went down right because here it was they had nine thousand nine hundred ninety nine dollars in wages they had a thousand dollars and say food stamps could be anything right so here they have actually ten thousand nine nine nine they go out and they earn two more bucks to go above ten thousand this guy falls to zero. They're actually facing marginal tax rates that are above a hundred percent to see what I'm saying they take not only the dollar that you were earned in welfare not only do you lose that but you also now have to pay taxes. doesn't make any sense I'm not gonna do that I'm gonna goof off. I don't want it because they're facing a marginal tax rate that's really really high so which view is Keynesian new classical supply? I'll write the paper and win the Nobel Prize and I can go to Sweden and get the nice little bitty gold medallion that I couldn't wear around my neck for the rest of life at such a such recession. alright this is the end of test three material I will. CNN's John Defterios takes a look at three different views of fiscal policy. Keynes says we can change aggregate demand in such a way that we can make. Defterius: Once you actually start spending money it becomes difficult to take money away. He says once you start giving people something taking out money now becomes very very difficult. The crowding out problem and the crowded out problem says well when you go out and you borrow all of this money you're gonna bond to your kid all right.

ROUGE-1: 23.14, ROUGE-2: 22.34, ROUGE-L: 20.23
BERTScore: 66.60

==============================================
==================== [36/100] ====================
Summary:
We'll find the Heisenberg equations of motion and solve them for a particular case today. We start with the time evolution. We found that, whenever we declare that states evolve in time in that way, they satisfy a first order time differential equation of the Schrodinger form. We discussed that in recitation on Thursday. This unitary operator you've been seeing that from the beginning of the course in some sense, that you evolve energy eigenstate. It's an interesting thing, and really that will be good enough. The Schrodinger equation is there. OK so now let's solve this. We'll go through three cases. Case one, h is time independent. So H of t is really H like that. So what do we have? ih bar. Let's write dU dt is equal H times whole thing is the same. So this is something very useful and we'll need it. One more comment, expectation values. We just say the expectation value of As is equal to the Heisenberg expectation value. something that makes sense. So here it is. U of t and t0. I'll write the answer and explain how it looks, and then you will see that it's OK. It's interesting. But it probably is not the most practical way you can solve this problem. There's an acronym for this thing. T it's called the time ordered exponential. This operator does something to the exponential function. So I have to say what this time ordering exponential is, and it's the following. You take the exponential and just begin to expand. the Schrodinger operator? PROFESSOR: You have to speak louder. OK, comments. At t equals 0 A Heisenberg becomes identical to A Schrodingers. When t is equal to 0, U of t-- of 0 0 is the operator propagates no state, so it's equal to the identity. So if this is happening, the two Hamiltonians are identical. And we'll have the chance to check this today in a nice example. And this goes Hs of t1 and t2 commute with each other. Solving for the time dependent Heisenberg operators is the same as finding the time evolution of all states. So you have this. And then you write Xh is equal to A cosine omega. t plus B sine omega t where A and B are some time independent operators. At time equals 0, the Heisenburg operators are identical they to the Schrodinger operators. So any expectation value of any power of X and P that you will want to find its time dependence, just put those Heisen Berg operators, and you will calculate things with states at time equals0. variables in, it just becomes identical to the Schrodinger Hamiltonian. All right, so that's all for today. I hope to see in office hours in the coming days. Be here Wednesday 12:30, maybe 12:25 would be better, and we'll see you then. [APPLAUSE] We'll be back at 12:50 on Wednesday, and be here at 1:30 on Thursday. Back to Mail Online home. back to the page you came from. Professor: We're going to look at this unitary time evolution and calculate this operator u, given the Hamiltonian. Then we will look at the Heisenberg picture of quantum mechanics. Professor: If you have a time dependent Hamiltonian that actually commutes with itself, the fact that it's time independent doesn't make it fail to commute at different times. And you will discuss later on as we do the nuclear magnetic resonance, which is more interesting in which it rotates and therefore it's not that time dependent.

ROUGE-1: 13.63, ROUGE-2: 12.64, ROUGE-L: 10.44
BERTScore: 65.22

==============================================
==================== [37/100] ====================
Summary:
Borat: I want to talk about my favorite part of the Second Discourse, a book that never grows old. Borat: Inequality is for Rousseau far more what we might call "the moral and psychological injuries of inequality" than the material aspects of the phenomenon. He says Rousseau very much takes the side of the poor and the dispossessed but it isn't property, or poverty rather, that rouses Rousseau's anger as it is the attitudes and beliefs shaped by inequalities. Rousseau: Amour-propre only arises in society and is the true cause, he believes, for our discontents. He distinguishes it from another disposition that he calls amour de soi-meme, a sort of self-love. "Amour- Propre is merely a sentiment that is relative," he says, "artificial and born in society which moves each individual to value himself more than anyone else" The desire for recognition is at the root of our sense of justice, he says. For Hobbes, and this idea of pride, vanity, what Hobbes called vainglory, was a very important part of Hobbes' political and moral psychology in Leviathan. For Rousseau by contrast amour-propre is something that could only come about after the state of nature, a state that Hobbes had called solitary, poor, nasty, brutish, and short. But how could pride have arisen in such a state? Rousseau speculates about this and, again, this is part of his hypothetical or conjectural history. Rousseau has to say about it, about this kind of issue. To tolerate simply means not to persecute, to leave alone, while respect for something requires that we esteem it. This is a vast topic. I think that amour-propre, the desire to be esteemed, recognized, and to have your values and points of view esteemed by those around you is very different from what Locke talked about. It doesn't require us to censor, self-censor, our own views on the ground that they may be disrespectful or hurtful to others. Only a very few people, Rousseau writes, are capable of finding their way back to nature. He is one of those rare aristocrats of nature, you might say. His claim to superiority is not based on a higher understanding but a superior sensitivity, less on wisdom than on compassion. But it requires you, in some way, to distance yourself severely and psychologically from all of the possibilities of society, to return inward, and it was that inward journey that Rousseau took and that he writes about so powerfully. general will and how Rousseau sees it as a sort of collective answer to the problem of the securing of individual liberty. So meditate on that if you like for the next day. If you like, you can read the rest of the book tomorrow. It's a great read and a great way to start a new day. I hope you'll join me for a cup of tea and a glass of wine in the next few hours. I'm looking forward to seeing you in the morning. Rousseau's Second Discourse is about the origins of inequality. He says the passion of amour-propre is the first and most durable cause. Government is a game that legitimizes the rich and dispossesses the poor, he says. The social contract, as he presents it, is a kind of swindle, says John Rawlinson of the University of California, Los Angeles. The book is available in English, French, German, Spanish, Italian and Danish.

ROUGE-1: 18.70, ROUGE-2: 15.95, ROUGE-L: 15.34
BERTScore: 62.34

==============================================
==================== [38/100] ====================
Summary:
So I think I just spend like five minutes, just briefly review on the backpropagation last time. So I didn't have time to explain this figure, which I think probably would be useful as a high level summary of what's happening. So you start with some example x, and then you have some-- I guess, this is a matrix vector multiplication module, and you take x inner product multiplied with w and b. And then get some activation, the pre-activation. And you get some post activation. New example, x comma y, from some distribution D. And often, this is called test distribution. And then you evaluate what's the expected loss on this new test example. So what's important is that this x and y is not seen in a training. It's a new fresh example. And just to be clear, these test examples, you haven't seen them in aTraining set. They are something you draw. You can draw them in advance, but you cannot let them to be seen in the training process. or is much bigger than 0. So you want this gap to be as small as possible. So this one is something you can control in some sense. This is what you try to optimize for. But the generalization gap is something that is very hard to control. At least, you cannot directly control it. And the point of this lecture is to discuss in what cases you can somewhat know this is not too big? OK. And then before going to do more details, let me also define two notation-- two kind of like commonly used terminology. overfitting is that the training loss, j, is small, but the test loss is big. So you have this big generalization gap. So much worse-- becomes much worse. So this is a typical situation of overfitting. In some sense, you are saying that you fit the data very well, but you are overfitting in the sense that you kind of like forgot about the test performance. I will discuss why this will happen. I guess, you can probably guess, but this is so far, I'm just defining roughly what overfitting means. The bias is a decreasing function as the model complexity. So we say that the bias is large, it's because the model is not expressive enough. So that means that if your model is more expressive, then your bias should decrease. So this is the bias. And now let's think about how do you draw the in some sense. Because for example, suppose you believe that this is a U curve. Then should you try even bigger models, bigger family of models? Because you kind of believe that it will be even worse. So you should just try even more in the middle. bias will be smaller. And your sum of these two functions, which is a test error, will be. something like this. And then the best one will be something in the middle. So this is kind of the quick overview of what we're going to discuss. OK. So now, I'm going to define bias and variance in a little bit more formal ways. And I'll show some examples. So any questions so far? Why is the bias [INAUDIBLE]. Why is bias this crazy? Oh, squared, I mean. fifth-degree polynomial, and then I'm going to try quadratic. So linear model. I guess, you can probably see, guys, what will happen. So you can see that there's a large training error, training loss or training-- let's call it loss just for consistency. So what you really will fit, like if you minimize the error on the training data with this so many training examples, then what you will get is probably something like this. It's not like necessarily matching exactly the ground truth, but you have a small fluctuation. Mathematically, one way to define a bias is that you can say this is the-- So bias is-- I guess, actually, there's some approximation here, depending on what exactly your model is. But roughly speaking, it's the best error or loss, you can get with even infinite data. And you can kind of see that it's probably important for bias to be small because if bias is large, even with infinite data, you cannot do anything. And that's the problem with linear models. what I'm going to talk about. And this is an area of research productive in the last, probably, three or four years. So let me try to find out where should I erase. So this phenomenon that people observe, empirically, and then analyzed theoretically, this phenomenon is called double descent. If you are a historian, then I think actually this phenomenon actually dates back to something like 1990. But I think it just becomes popularized and more relevant these days. And what does this mean is that, so basically, I've told you that this is test error. This is model complexity. stochastic gradient descent for linear models. So the existing algorithms underperform dramatically when it's close to d. So both these two peaks are basically like this. So here, you are changing n, the number of data points. And you found that when n is close to. d, you had to pick. And here,you are changing the. number of parameters. And we realized when d is kind of above n, above the number. ofData points, you have a peak. going to discuss this more next time. So the high level thing is just that something else is driving the norm to be small. Thanks. Going to talk more about this in the next few days. Back to Mail Online home. back to the page you came from. Back To the pageYou came from: Back to thepage you camefrom. Back into the page You came from was from: The Daily Mail. Back onto the pageyou came from, the DailyMail.com page you were from. loss with respect to the output first. And this is often very easy. This is kind of like you are accessing this network in a backward fashion in some sense. But how do you do this, each of this arrow? So this is by the lemma that we discussed. So now in this lecture, and the lecture afterwards, we are talking about, I guess, a few concepts. One concept is called generalization, which is the main point of this lecture. And also, next lecture, we're going to talk about the concept of regularization.

ROUGE-1: 15.20, ROUGE-2: 14.59, ROUGE-L: 12.78
BERTScore: 70.06

==============================================
==================== [39/100] ====================
Summary:
"Remember what happened in 1905 after his troops fired on peaceful petitioners?" "Yes, and the tsar ended the rebellion by introducing a constitution and an elected parliament, the Duma" "While retaining absolute power and dissolving them whenever he wanted." "Perhaps there would've been more reforms in due time if radicals, like Lenin, weren't always stirring up trouble." "Your Honor, Lenin had seen his older brother Aleksandr executed by the previous tsar for revolutionary activity" how would I have sounded?" We can never be sure how things could've unfolded if different people were in power or different decisions were made, but to avoid the mistakes of the past, we must always be willing to put historical figures on trial. We must never forget that history is not an exact copy of the present, but it can be a guide to the future. It can be used to learn from the mistakes made in the past and to make better decisions in the present. It is never too late to put a historical figure on trial for their actions. Vladimir Ilyich Ulyanov, AKA Lenin, helped overthrow the Russian tsar Nicholas II in 1917. He founded the Soviet Union, one of the worst dictatorships of the 20th century. We can never be sure how things could've unfolded if different people were in power or different decisions were made. To avoid the mistakes of the past, we must always be willing to put historical figures on trial, writes Alexei Kuznetsov, author of History vs. Lenin.

ROUGE-1: 34.62, ROUGE-2: 24.98, ROUGE-L: 25.27
BERTScore: 64.77

==============================================
==================== [40/100] ====================
Summary:
able to evaluate these matrix elements is the permutation requirement. And it turns out that there is a really simple way of dealing with the requirements for electron permutation, and that is to write the wave function as a determinant of one-electron orbitals. Now this, because of the properties of the determinant, is anti-symmetric with respect to permutation of any two electrons or any two orbital. But we don't really care about the permutations of the orbitals, because it's really the same thing is permuting the electrons. Well, when we do this, the diagonal matrix elements of the 1 over rij Hamiltonian can be expressed. And we use this notation, J tilde minus K tilde. So for every two-electron thing, we're going to get this kind of-- now these are simple integrals, and some of them are 0. Because this doesn't operate on spins. So this tilde notation is a convenient thing, because you can use any Slater determinant, and you can express it in terms of J's and K's. In order to make an eigenstate of s squared or sz, you sometimes need two or more Slaters. When you have mismatched alpha and beta, the K's are 0. But when you have K, the 1 over rij matrix element between two Slaters, you can fix that. Now if you looked at 100 textbooks, I think 95% of them will have Hund's rules wrong. You're never going to get it right. But some things in life are worth suffering for. shielding arguments are capable of explaining that. OK, so this is the end of atoms. And I've asked you to observe some complicated algebra which you're never going to do. Everything you need to know about atoms, you can tell a computer, and it can do it. Now molecules are much more complicated. And that's we're going to start on next time. We'll start with molecular orbital theory. I'm not going to be presenting the normal textbook approach. I'll present an interpretive approach, where you understand why things happen. The goal of this course is to give you the tools to interpret complicated phenomena. We have electronic structure and the hydrogen atom as a way of understanding what electronic structure is. When we go to molecular orbital theory, we take what we know about atoms, and build a minimally-complex interpretive picture, which is sort of a framework for understanding complicated molecular interactions. The relationship between the effective quantum number and the ionization energy of a state then provides a hydrogen-atom-based structural model for everything you can observe.

ROUGE-1: 14.86, ROUGE-2: 14.33, ROUGE-L: 11.78
BERTScore: 65.09

==============================================
==================== [41/100] ====================
Summary:
Whenever your patient is low on red blood cells they're going to have some side symptoms that can present especially if they're really low they'll be very pail. They can feel very fatigued they can be short of breath any activity they're just like really wore out and they can have an increased heart rate. If they have received a lot of blood transfusions in the past they're at risk for febrile nan hemolytic transfusion reaction where their body has just built up these antibodies from all those previous transfusions. A lot of times physicians like to pre medicate them and you'll want to let the physician know if they do have a history of that and sometimes they're pre-medicated with benadryl or Tylenol acetaminophen before hand orally or when about 30 minutes before you start the transfusion. Look at the health status of your patient are you giving a patient who is in fluid overload or congestive heart failure has renal failure and but they really need blood you need to be looking at that. You typically want an 18-gauge or larger IV site. It takes anywhere between two to four hours for a unit of blood to transfuse. You use special tubing which is called Y tubing with an inline filter which helps filter some of those substances out of the blood before it actually goes to the patient and keep in mind again it depends on hospital protocol a lot of protocols say only one set of Y tubing per unit that you transfuse so you'll have to use multiple sets. Trash now let's talk about transfusing okay done all your prep work the blood bank calls you and says hey your blood is ready let us know whenever you're ready for us to send it to you because they're keeping it refrigerated for you. Some key things you want to remember you will be giving one unit at a time patient needs two units you're gonna give one unit now and then whenever that's done call blood bank and say send me the other unit and then they'll send it. breath headache backache or nausea and vomiting and if this happens you'll immediately want to stop the transfusion okay now it's actually time to start the transfusions so you're gonna have your blood ready hung and it's going to be controlled by an infusion pump which will deliver it to the patient. You want to start  slowly about two milliliters per minute for those first 15 minutes in addition you want to stay with that patient at their bedside looking at them monitoring them. bank who's going to test it look out and see what went wrong. Of course you're going to document you want to document the time it happened. What actions you took what the patient was given if you gave them anything. What labs you drew all that and how the patient is currently doing okay so that wraps up this review over blood transfusion. thank you so much for watching don't forget to take the free quiz and to subscribe to our channel for more videos. Back to the page you came from. As a nurse we will transfuse a patient who is low on red blood cells with new blood cells via a venous access of some type. Red blood cells are very vital for our survival and how our body works. Most hospitals require that you're a registered nurse in order to transfuse the blood so again follow your Hospital protocol with that. Never use dextrose containing solution because it can clump together and we will be using 09% normal saline to prime the blood. Never ever put it in the regular blood bank whenever you're ready to start that transfusion.

ROUGE-1: 24.72, ROUGE-2: 23.59, ROUGE-L: 20.67
BERTScore: 63.48

==============================================
==================== [42/100] ====================
Summary:
always be clear from the problem we're looking at. Always be clear about what you're trying to do. Always show us how you're going to solve a problem. Always. Show us how to get to the solution you're looking for. always. show us the way to get there.always. be clear of the problem you're aiming to solve. always be clear. of the goal you're seeking to achieve.always be. clear of your goal. of getting to the answer you're after. In particle physics and in nuclear physics, use a system called natural units. This system is based on fundamental concepts of quantum mechanics and special relativity. In this class, we'll use natural units in some examples, and SI units in others. This will always be clear from the problem we're looking at, so we're always looking at the problem at hand. We'll use Heaviside-Lorentz units and combine them with some measurable units we discussed in the previous class.

ROUGE-1: 24.34, ROUGE-2: 15.56, ROUGE-L: 15.32
BERTScore: 53.59

==============================================
==================== [43/100] ====================
Summary:
is that electricity, as you know, in an electric car it's not going to be useful if you have to have it plugged in all the time, right. So storage of electricity is clearly really, really important. And so we get to sort of how do you think about storage technologies, and again, I just want to kind of gently introduce us to energy storage and we'll go into batteries. Now so the kind of plot that I'm showing you here, talking about Ashby plots, but this is actually a different kind. It's a special kind because it has to do with energy storage. Theory of electricity was similar to theories for motion of the human body. Galvani wanted to make a connection between things that move and electricity. He hooked up his lightning rod to a frog. The frog was not alive. The motion of a frog, and all motion of all living creatures, generates electricity. That's what he said. He deduced that the motion itself is something that generates electricity, and that's how he came up with the theory. It was like, ah-ha, motion, electricity. lots of metals. That's what he did. And he showed that the frog moved with most of them, so it's the metals. So let's take these two classic metals and show what happens. You've got copper and you've got zinc. Now, in this case, I'm just going to have a zinc. This is the zinc piece of metal, and this is a piece of zinc, and I put it in a solution of copper ions. And we got them sort of bonding. The zinc that goes into solution is 2 plus and 2 electrons. And the copper in the solution plates onto the zinc, plus those 2 electrons goes to copper like that. The zinc is leaving the solid and it's becoming 2 plus. But the thing is that now, you've got to be careful here. What about those two electrons? Where do they go? A zinc atom leaves its metal strip and goes into that beaker of zinc ions. But now you have two charges, two electrons on the strip because it left a zinc 2plus. Just that now we're talking about the metals and whether they're more interested than the other metal in having those two electrons. That's what a potential is. And you know, when you look at this, you might say-- this is from Averill so he actually is missing the f's because this is just taken right from the textbook, but anyway, so that's the potential. Look at this. This is like an energy diagram but these aren't electronics. These are just potentials, but the potential is related to which one wants the 2 electrons more. standard hydrogen electrode. So sometimes you'll see it as the SHE in the battery world. And what it is it's just a very nice platinum electrode that doesn't change. So it doesn't plate or lose atoms. And it's a reaction that on that electrode happens with hydrogen, hydrogen gas. And so what you do is you hook this up on one side, and then you put all the metals against that. And you measure their potential. So hydrogen electrodes gives you that ability to standardize it and create huge tables. renewables at large scales unless you store it. In fact, we're really at essentially the tipping point. If you look at-- this is Germany, now. Huge penetration-- these are these six years, seven years of adding PV. They're now at 7%. 2016 is 7%. This is how much the price of electricity was in Germany when they added. They can sell it for a lot of money. But as they add more of this renewable to the grid, its price goes down when it's available. need. So that's a real challenge for chemistry. I hope you guys have a great Thanksgiving and maybe hook up some different metals. And I'll see you all next week. Back to the page you came from. Follow us on Twitter @CNNOpinion and @cnnireport. Back To the pageyou came from, back to the CNNOpinions page.Back to thepage you came From. Back from the CNN Opinion page. Back in the page, click here for the latest from CNN. The planet is kind of a storage device. It's an energy storage device for that thing over there. Most sort of energy storage needs are going to be around a year or less. Why electricity? Because electricity is more and more important in our lives. We've got a whole lot of limitations as well, just to give you the abbreviations, Superconducting Magnetic Coils and so on. And then we're going to talk about the chemistry of batteries and throw in a couple of, why this matters.

ROUGE-1: 18.17, ROUGE-2: 16.96, ROUGE-L: 15.26
BERTScore: 61.44

==============================================
==================== [44/100] ====================
Summary:
need to know what gradient descent is. The bigger question we are trying to address here is that why many optimization algorithm. are designed for convex functions. But why they can still work for nonconvex functions? So why they still work and actually, pretty well in practice forNonconveX functions in deep learning. Of course, this is not a 100% statement because it depends on which function you are talking about, what you have, and so forth. But I'm just saying, for most of the cases in deep. learning, stochastic gradient descent or gradient descent seems to work pretty well. Strict-saddle condition is basically saying that you assume your function doesn't have this kind of somewhat subtle possible candidate of local minimum, right? So every point, whether it's a local minimum or not, can be told from examine only the first order gradient and the second order gradient, second order directives. So if you certify the condition, then you remove those pathological cases which requires high order derivatives. But there are also-- my bad. One, two doesn't tell you exactly whether a point is local minimum per se if you don't have that assumption. that makes it tricky because then the higher order gradients start to matter. And when you look at this-- and once it becomes about the third order derivative or fourth order derivative, things becomes much more complicated. So that's why local minimum is not only always a property of the first and second order derivative. And there's a theorem, which is the following. So the theorem is that verifying if x is a local minimum without any assumption of the local minimum of f is actually NP-hard. is the definition. So we say f is alpha, beta, gamma strict-saddle if, for every x in RD, it satisfies one of the following. So the first one is that, for some of the x, it just satisfies that fx, the true norm of x is larger than alpha. So if you satisfy this, you cannot be a local minimum because your Hessian is not positive semidefinite. And the second thing is that the Lambda min of the Hessian at x is less than minus beta. So these are not stationary points. They are not local minimum. The eigenvalues are distinct even though we don't have to assume this. Then, basically, all the stationary points are of the form that x is equal to plus minus square root lambda i times the eigenvectors. And now, let's look at which of these is a local minimum. So ideally, we just want to say that only vi, the v1 thing, is the local. So 2 means that the first term goes away. So you get just x2 norm square is bigger than v1 transpose in Mvi. methodology also applies here when you talk about the Hessian. You just iteratively expand it, Taylor expand it into something like g of x plus some epsilon times some vector. And then if you have this, then this basically corresponds to v dot g square gxv. So if you apply these kind of techniques, you can get the. Hessian like this. So the quadratic form of the Hessia is equals to something like this, right? So we have to have this. And we know that the Hessians that are larger than 0 is equivalent to that. In many cases, you only care about a few special v's because some of v's are much more informative than the others. So you want to choose some informative v's to evaluate this formula so that you get some important information about what x can be. So it turns out that the v's that are informative here is the top eigenvector. How do you know this? It requires some intuition, it requires some trials and errors, so and so forth. But I guess it also probably makes sense because theTop eigen vector direction is the global minimum, right? with a recommendation system. So suppose you think of we have a matrix. And in one side, the columns are indexed by the users. And every user probably have an opinion about every item, right? Either they like it or not, so and so forth. But it's not like every user buys every item. So every user only buys a very small subset of the item. And that's why you have to recover all the rest of the entries to serve the users better in the future. assume that the input are linearly separable, then there is a proof for this. And there are a bunch of other cases where you can have some partial results. Next week, in the next lecture, maybe the second half of next lecture,. I'm also going to give another result, which is somewhat more general. It applies to many different architectures, but it has other kind of constraints. First of all, it doesn't really show exactly these kind of landscape properties. It shows that these kinds of properties holds for a region, for a special region in the parameter space. We are going to start talking about the optimization perspective in deep learning for two lectures. In most of the cases, people observe that nonconvex functions in machine learning can be optimized pretty well by gradient descent or stochastic gradient descent. We're going to show some very, actually, simple cases where we can prove this. But I guess, as I mentioned, there is some caveat about whether you can even converge to a local minimum. So I'm not going to prove any of the theorems here.

ROUGE-1: 17.30, ROUGE-2: 16.74, ROUGE-L: 14.18
BERTScore: 63.65

==============================================
==================== [45/100] ====================
Summary:
Iceland is one of the world's most active volcanic hotspots crafer has erupted 30 times in a thousand years and last blue in the 1980s. Scientists are now preparing to drill into it the is to learn more about how volcanoes behave so that we can better predict eruptions and also tap into a super hot source of energy. Residents of grindvik have had their lives appended by a string of eruptions but researchers here hope their work will change that helping to save lives and money. many other locations around the world where we have active volcanoes so this crazy sanding plan may actually have huge potential e. Many other locations in the world. where we has active volcano so thiscrazy sanding plans may actually be a huge potential. e. Back to Mail Online home. Return to the page you came from. Back To the pageyou came from, back to the site you came From. Click here to read the original article on The Daily Mail Online. Back into the Daily Mail home. Scientists are preparing to drill down into a magma chamber starting in 2026 they'll begin work on the first ever underground magma Observatory. The plan is to drill just short of the magma itself possibly poke it a little bit. The geothermal resource which is at just above theMagma body is around 5 to 600° C just two ball holes of this kind could match the output of this entire plant. The drilling will be technically challenging at the University of Iceland lab work is underway testing materials to withstand extreme heat.

ROUGE-1: 45.06, ROUGE-2: 37.52, ROUGE-L: 37.07
BERTScore: 67.31

==============================================
==================== [46/100] ====================
Summary:
people earn more income base they are attacked a smaller amount of smaller percentage of the rounding. People pay a small person their income tax as their income goes up so only if their income go down they're going to pay a larger percentage of their income. With the 4-channel it's the same so here you see people pay the same percentage whether progressive its detect ops as progressive people pay lark there and so it's not the dollar amount it's gonna be obvious that everyone is must and a larger dollar amount in taxes. Sales taxes are a regressive tax even though rich people buy more stuff I'm going to pay more and sales tax dollar amounts as a percent of their income it's actually usually profit or loss. This marginal tax rate is the percentage change in taxes any tax paid from some changing our average tax rate beer is just going to be tax paid so there's my tax rate's tell us how much additional tax event played based upon our so they so they.taxes redress property tax can be kind of course non-progressive can depend upon how many things that is your taxi in the race and things like that. go coming back to that they have passed out here we've got these marginal tax rates here with you guys. Let's assume that we made for $90,000 you're single and we wanted to know how much you pay so that's how I come here and in essence what you've done is you've got different amounts of here and of these dollars in here. If you're at $8,000 and you go out and earn another hundred dollars you're going to pay $10 and times but if you're making eighty six thousand dollars you need to have you earn another 100 dollars. 17,000 Orlando will go to top Bill and Hillary will both oh eight thousand each so our total BAM attacks if we put this way 19,000 if we tax the household this goes back to this idea we discussed the horizontal language all right we want to treat people that are in similar circumstances the same those people are being treated decide why do we have this front why are we having these different taxes why is the why are these numbers larger than these numbers was because of the progressive nature of the task. a beautiful fiscal policy we have this new classical view of fiscal policy and we have those called the supply side now. What we'll see on Wednesday and what these guys actually do is what we'll hear on Wednesday. We'll see what they actually do and how they do it. It's going to be very interesting to see what happens in the next few days. It will be a very interesting week. It'll be very exciting to see how they go about it. We will find out what happens. Taxes can have all kinds of different applications [Music] that's hot let's look at a tax that looks like this. McDonald's gonna hold want to penalize people for being married does that make sense right. If our expansionary fiscal policy here we're seeing the decrease in taxes or an increase in government spending. If we have a deficit the deficit is going to get larger or if you have a surplus what would happen in the surplus it'll get smaller by contraction fiscal policies exact opposite here.

ROUGE-1: 32.17, ROUGE-2: 29.43, ROUGE-L: 25.47
BERTScore: 68.37

==============================================
==================== [47/100] ====================
Summary:
that we are going to be looking for in an estimator, trying to find them to be unbiased. But we'll see that it's actually maybe not enough. So unbiasedness should not be something you lose your sleep over. Something that's slightly better is the risk, really the quadratics risk, which is expectation of-- so if I have an estimators, theta hat, I'm going to look at the expectation of theta n minus theta squared. And so for different thetas, some estimators are better than others. for sum of independent random variables, now it's time to wake up. So we have the variance of something that looks like 1 over n, the sum from i equal 1 to n of Xi. So it's of the form variance of a constant times a random variable. We would like somehow to say that this is the sum of the variances. And in general, we are not allowed to say this, but we are because my Xi's are actually independent. And that's by independence, so this is basic probability. The bias is 0 and the variance is equal to theta, 1 minus theta divided by n. The second number is better for the other guy, so I will definitely go for this guy compared to this guy. The bias is actually-- just for simplicity, I can think of it as being X1 bar, the average of itself. And I have the variance that's actually n times smaller when I use my n observations than when I don't. So this guy is gone. want this-- so there's theta that changes here, so the distribution of the interval is actually changing with theta hopefully. And theta is changing with this guy. So regardless of the value of theta. that I'm getting, I want that the probability that it contains the. theta was actually larger than 1 minus alpha. And so in particular, if it's equal, then I can put some larger than or equal to, which guarantees my asymptotic confidence level. The total variation distance between probability measures is central to probabilistic analysis. If the total variation between theta and theta prime is small, it means that for all possible A's that you give me, then P theta of A is going to be close to P theTA prime of A. The problem is that we don't know what the total variations is to something that weDon't know. The goal was to spit out a theta hat, which was close such that P thena hat was close to theta star. So here's the strategy. Just build an estimator. PhilipPE RIGOLLET: Let me write the set A star as being the set of X's such that f of X is larger than g of X. So that's the set on which the difference is going to be positive or negative. Rigollet: This, again, is equivalent to f ofX minus g ofX is positive. Everybody agrees? So this is the set I'm interested in. So now I'm going to split my integral into two parts, in A, A star. thing over there. We want to show that if I take any other A in this integral than this guy A star, it's actually got to decrease its value. So we have this function. I'm going to call this function delta. And what we have is-- so let's say this function looks like this. Now it's the difference between two densities. It doesn't have to be non-negative. But it certainly has to integrate to 0. And so now I take this thing. And the set A star is the set over which the function delta is non- negative. So that's just the definition. this constant is 0 for my purposes, or 25 if you prefer. All right. So we'll just keep going on this property next time. And we'll see how from here we can move on to-- the likelihood is actually going to come out of this formula. Thanks. Back to Mail Online home. back to the page you came from. Back from the page where you came From. Click here to go to the show page where we'll be talking about the probability of winning the lottery. PhilipPE RIGOLLET: If I were to repeat this 1,000 times, so every one of those 1,.000 times they collect 124 data points and then I'd do it again and again, then in average, the number I should get should be close to the true parameter that I'm looking for. The fluctuations that are due to the fact that I get different samples every time should somewhat vanish. The risk of this guy is what? Well, it's the expectation of x bar n minus theta squared.

ROUGE-1: 11.89, ROUGE-2: 11.22, ROUGE-L: 10.04
BERTScore: 67.50

==============================================
==================== [48/100] ====================
Summary:
The grading scheme will not be worse than what I've given you here. The great divide-- the great divide or the grade divide-- at 85% between A and B, 70% between B and C, 60% between C and D, and below 50% earns you an F. I don't think anybody can get into this environment as long as they participate. The first one deals with the particle physics content, and the second one with the nuclear physics and experimental method as well. Markus Klute: This class will be taught in an inverted classroom or flipped classroom setting. The course evaluation or your evaluation in this course will be made up 50% out of homework. The great divide-- the great divide or the grade divide-- at 85% between A and B, 70% between B and C, 60% between C and D, and below 50% earns you an F. The grading scheme will not be worse than what I've given you here, Klute says.

ROUGE-1: 35.32, ROUGE-2: 29.17, ROUGE-L: 20.00
BERTScore: 55.60

==============================================
==================== [49/100] ====================
Summary:
the formula for this line is given by y is equal to x plus 1. Conditioned on x, this is the PDF of y. And because it's uniformly distributed and because expectation acts like center of mass, we know that the expectation should be the midpoint, right? And so to compute this point, we simply take the average of the endpoints, x plus1 plus x over 2, which gives us 2x plus 1 over 2. So this is py given x, y given x. And now we can look at this conditional PDF to figure out what this is.  memorizing formulas might seem like cheating, but there's a few important ones you should know. And it will help you sort of become faster at doing computations. And that's important, especially if you guys take the exams. So that's it. See you next time. We'll be back in a few days with a new episode of "The Daily Discussion" to talk about the week's top news stories. Back to the page you came from. Click here for the next episode of The Daily Discussion. Today we're going to do a fun problem that will test your knowledge of the law of total variance. In the process, we'll also get more practice dealing with joint PDFs and computing conditional expectations and conditional variances. So in this problem, we are given a joint PDF for x and y. And then we are asked to compute the variance of x plus y. So you can think of x as a new random variable whose variance we want to compute. And moreover, we're told we should compute this variance by using something called the Law of Total Variance.

ROUGE-1: 28.66, ROUGE-2: 25.67, ROUGE-L: 16.68
BERTScore: 68.67

==============================================
==================== [50/100] ====================
Summary:
There's 16 possible transitions, including four homopolymers, AA, TT, CC, GG, and 12 transitions of the other dinucleotides. We've got CG islands where the CGs have been protected from methylation, and hence, protected from mutations. These islands will be a variable length and just have an increased concentration of CGs. And then outside are the ocean, which are not protected. They're not involved in transcription, and they mutate. And they are very low in CGs, so you want to know where the island begins and ends. an ocean. And so here's one that's illustrated, this dotted, brown line, where it says probability of a C minus in an ocean. So that would be a transition point going 5-prime to 3-prime, from an island into an ocean, going from an A to a C. Aren't you glad that I picked a dinucleotide to illustrate this? OK, here's a real example. Here's an example where I've cut and pasted a very short sequence with only one ocean on the left and one island on the right. Student: Do you know the basis for thinking that the context for a dinucleotide is either an ocean or an island, in other words, only two states? Why couldn't the context be five states? GEORGE CHURCH: OK. Question. Student: Why can't there be more than two states for the context of a dinoinucleotide? Student: I want to know why there can't be more states for dinosucleotides. George Church: I don't know, but I think there must be. George Church: How do we deal with multisequence alignments? Church: This is using all the power that we developed for the pairwise comparison. This does scale exponentially with k. Church: There are very good for inferring structure or function from sequence without experiments. It's like doing a huge mutagenesis and exploring viable mutants, he says. He says the most non-polynomial calculations, that is to say, in this case, in the case of this band, you could take one of the examples and take it to the next band.

ROUGE-1: 8.93, ROUGE-2: 7.65, ROUGE-L: 6.04
BERTScore: 58.70

==============================================
==================== [51/100] ====================
Summary:
Aluminum copper stainless steel cast iron and carbon steel aluminum pots and pans are the ubiquitous pans that you'll find in most every kitchen. copper is one of the best conductors of heat it heats and cools rapidly whenever necessary and it's fairly heavy weight. Additional cooking materials include things such as non-stick coatings like teflon terracotta which is used in cooking things like tangents glass such as corning ware enamel wear which is also used in things like crock pots. interchangeably in many ways but believe it or not though there is a difference between these two does it make a difference in your cooking if you use one instead of the other. A saute pan or satwa is one with the straight sides and has a larger surface area which makes it ideal for tasks like searing meat or reducing a pan sauce. A sawtooth or skillet has a slope side and is used mainly in sauteing the slope sides providing the ample and perfect angle for flipping your food. From full size hotel pans two-thirds pans half pans third pans fourth pans six pans and ninth pans and various other sizes each size is available in six six inch four inch and two inch deep models the name of the pan refers to how many of each would it take to equal a full size pan for example the nine it takes nine of the one-ninth pans or ninth pans to make one full-size hotel pan here you can see various different configurations depending on the usage needs many of the configurations require the use of a spanner bar to prevent the pans from falling in. it takes up too much room in your coolers and takeaway number six you can never have enough hotel pans no matter what size you have. This presentation will attempt to give an overview of the different small wares and pieces of equipment that you'll experience in a restaurant environment. It's not an exhaustive list for more information i suggest ktom.com which can be accessed at the link on the screen. For more information on the different types of hotel pans, visit hotelpans.com. Stainless steel is the preferred cooking utensil for most kitchens it's heavy duty easy to clean surface typically clad which we'll discuss later resists pitting and metal reactions with acidic foods works with induction cooktops and holds its heat well if clad however it's much more expensive than the aluminum varieties cast iron has been preferred for many years it's very heavy duty if seasoned correctly it can also be non-stick it gives a unique flavor to foods and promotes browning better. If you drop it things like the handles and even the lids or even the pan itself can break.

ROUGE-1: 25.26, ROUGE-2: 24.31, ROUGE-L: 19.04
BERTScore: 62.50

==============================================
==================== [52/100] ====================
Summary:
 copyright law doesn't protect US writers from being pirated abroad. It does nothing to prevent US publishers from publishing pirated editions of well-known books already circulating in the continent. So that seems like a bad thing for the aspiring US author. On the other hand remember what I said before, there is no patronage system in place in the early republic; therefore, what is emerging is a kind of marketplace for writing. Without that market, a young American author wouldn't be able to sell his writings and sustain himself as a writer. Edgar Allan Poe's novel, The Grapes of Wrath, is about a young man who finds himself in a state of sleepwalking. Poe's character, Clithero, is accused of killing his friend, Waldegrave, but he refuses to believe it. He believes in reason and the primacy of reason, but in his dreams he descends into madness. Poe says Clit Hero's story is a counterweight to reason and a dramatization of enlightenment principles. in my rambles with some traces of this man, but might he still not live? His words had imparted the belief that he intended to destroy himself. This catastrophe however was far from certain. Was it not in my power to avert it? Could I not restore a mind thus vigorous to tranquil and wholesome existence? Right, we get back to that. So one of the things that Brown does as you might say maps the woods onto Edgar's mind. In exploring the woods, Edgar starts exploring facets of his own mind that have remained hidden from view. and I never sleep but with a candle burning at my pillow. Right, so from the confidence of enlightenment, now it's the pathetic I need to have a nightlight on, right? That's what Edgar has sunk to. What has caused all of this? His experience in the woods. And we'll take it up again on Wednesday, the experience of the woods, the story of Edgar's pit and the panther. I want you to look for the motif of light in the Panther scene, and also track one particular word, and that word is savage. Charles Brockden Brown: The Enlightenment is a critique of a kind of impoverished view of mind or consciousness that over-relies on reason. We started to look at it a little bit with Barlow's [assumed spelling] Raven poem with Poe. The idea that in fact there is something wrong with reason as a faculty, and this can take a couple of forms. One is that all of those nice ideals that come along with the enlightenment may in fact be parasitic precisely on the kinds of negative types of thinking that they are designed to get rid of.

ROUGE-1: 6.93, ROUGE-2: 6.46, ROUGE-L: 5.31
BERTScore: 60.46

==============================================
==================== [53/100] ====================
Summary:
and optics, upon the principle of relative movement." We now know this was wrong, but scientific process happens in scientific environment. And I started this class by explaining that one needs to be open minded to learn and to study and to grow scientifically. And one has to question the assumptions, understand the assumptions when then go into measurements. So this is the first part of this chapter where we talk about tests. We will have a discussion of implications of special relativity as we move on from here. Markus Klute: We're starting a new chapter in which we look at tests and implications of special relativity. One experimental test is stellar aberration, which we discussed can be explained by special relativity and by velocity addition. In all of this experimentation and experimental verification, it's important to understand the importance of uncertainties in the scientific process overall, Klute says. He says one needs to be open minded and scientifically open minded to study and grow to the question of whether or not Einstein's theory is correct.

ROUGE-1: 32.56, ROUGE-2: 28.74, ROUGE-L: 17.25
BERTScore: 59.75

==============================================
==================== [54/100] ====================
Summary:
Many women were also important contributors to the anti-slavery movement, although they tended to have more subordinate roles. Many women’s rights advocates were fighting to overturn not just laws, but also attitudes. It was an international movement. Often American feminists travelled abroad to find allies, prefiguring the later transatlantic movement of other advocates for social justice like Florence Kelley and W.E.B DuBois. It is interesting to note that the U.S. ended slavery more than 50 years before it granted women the right to vote. in comments where you can also ask questions about today’s video that will be answered by our team of historians. Thanks for watching Crash Course and as we say in my hometown, don’t forget to be awesome. Back to the page you came from with this week's Crash Course video. Follow us on Facebook and Twitter @CrashCourse and @CNNOpinion. For more Crash Course videos, visit CNN.com/Crashcourse and follow us on Twitter @cnncrashcourse. In the colonial era, most American women of European descent lived lives much like those of their European counterparts: They were legally and socially subservient to men. Lower and working class women were actually more equal to men of their own classes, but only because they were, like, equally poor. As production shifted from homes to factories, it shifted away from women doing the producing. This led to the so-called “cult of domesticity,” which like most cults, I am opposed to.

ROUGE-1: 15.91, ROUGE-2: 14.07, ROUGE-L: 7.95
BERTScore: 59.54

==============================================
==================== [55/100] ====================
Summary:
here in when i was 1 and 20 the kid kind of learns his learns his uh his issues and still 22. that's still pretty young to learn um to learn a life lesson. That's when i learned a lot about myself. That was when I was 1 to 20. I'm 22 now. I've still got a long way to go, but that's a good thing. I still have a lot to learn. I don't think i've learned all of my lessons yet, but I'm getting there. ae houseman 998-999 uh very intellectual individual um with these two authors today um we're really kind of bridging the gap between the victorian and the modern. Most of his poetry especially towards the end if you look on the right there the grief and poetry era. The death of his mother was pretty traumatic um if you've noticed some of the you know most famous musicians you know a lot of their work comes from some of their pain and torment and struggle that they've had throughout their lives.

ROUGE-1: 18.52, ROUGE-2: 14.71, ROUGE-L: 9.62
BERTScore: 62.53

==============================================
==================== [56/100] ====================
Summary:
the same connection. The pion here is spin 0, and if you discuss this in the rest frame of the pion, the electron and the positron fly off in opposite directions, which means that the spin doesn't in align to 0. So that's why this is highly suppressed. It's not 0, because you can find-- you can put [INAUDIBLE] into a rest frame, where you're just basically looking at both particles from one side that was coming to you, and in that case, it's allowed. In quantum mechanics, the spin of a particle with a vector is quantized. You find that it's square root of f times s plus 1 in units of h-bar. If you want to get an eigenvalue with the physical state of particles, which axis are the right ones to choose-- or, sensible? There's no right and wrong in this discussion. It's not 0, because you can put [INAUDIBLE] into the rest frame, where you're just basically looking at both particles from one side.

ROUGE-1: 38.75, ROUGE-2: 34.34, ROUGE-L: 25.76
BERTScore: 67.81

==============================================
==================== [57/100] ====================
Summary:
In 5th Century BC Athens was a direct democracy that encouraged wide participation through the principle of ho boulomenos, or anyone who wishes. Many modern democracies reconcile this conflict by having citizens elect those they consider qualified to legislate on their behalf. But this poses its own problems, including the influence of wealth, and the emergence of professional politicians. Could reviving election by lottery lead to more effective government through a more diverse and representative group of legislatures? Or does modern political office, like Athenian military command, require specialized knowledge and skills? poll, all examples of how the democratic principle behind sortition still survives today. Polls show that the principle of sortition is still very much alive and well in the United States today. The majority of Americans support sortition, with the majority of people in the U.S. voting in favor of it by a wide margin in the last presidential election in 2008. The most popular type of vote in the 2008 election was for the Democratic Party, followed by the Republican Party and the Libertarian Party. The Democratic Party won the popular vote. In Athens, 6,000 people could attend the ecclesia, a general assembly meeting several times a month. Rather than being elected or appointed, the people in these positions were chosen by lot. The only positions filled by elections were those recognized as requiring expertise, such as generals. Women, slaves and foreigners were denied full citizenship, and when we filter out those too young to serve, the pool of eligible Athenians drops to only 10-20% of the overall population. Some ancient philosophers, including Plato, disparaged this poll, but the democratic principle behind sortition still survives today.

ROUGE-1: 53.80, ROUGE-2: 41.33, ROUGE-L: 26.02
BERTScore: 63.76

==============================================
==================== [58/100] ====================
Summary:
as a function of time. Here is the Fourier transform of a sine wave at 20 hertz. This is phase shifted so the cosine is a symmetric function or an even function. The sine is an odd function. In this case, the real part is 0. And the two peaks are in the imaginary part. If you look at the power spectrum of the square wave, you can see again it's got multiple peaks at regular intervals. It's a series of peaks, because it's a periodic signal. we plot power in log base 10. A difference of an order of magnitude in two peaks corresponds to a unit called a bel, b-e-l. More commonly used unit is called decibels, which are 10 decibel per bel. So decibles are given by 10 times the logbase 10 of the power of the square magnitude of the Fourier transform. Does that make sense? Good question. All right, any questions about this and what the meaning of decibela is? The Fourier transform of a square wave, of this square wave of with 100 milliseconds, is a sinc function. If we take that pulse and we make it narrower, 25 milliseconds, then you can see that the sincfunction, it's the same sinc. function, but it's just stretched out in the frequency domain. As you make the pulse in time longer, the bandwidth gets smaller. And it turns out that the product of the width in time and thewidth in frequency is just a constant. actually reverse the order of integration. We're going to integrate over t first rather than tau. Then we can move the g outside the integral over t, because it's just a function of t Tau. So now, we have an integral dt x of t minus tau e to the minus i omega t. And what do you think that is? What would it be if there were no tau there? If you just cross that out and that, what would that be? Anybody know? What that's? correlation of this function with itself at different time lags. If we do that, you get a 1 at 0 lag and 0 at any other lag. So that's the autocorrelation function of Gaussian noise. All right, now what is the power spectrum? So we can take this thing-- and, remember, when we plot the power [AUDIO OUT] just plot the square magnitude of just the positive frequencies. Why do we only have to plot thesquare magnitude about that? OK. problem with that? Why might that be a bad idea? Yeah. So instead of multiplying this signal by square pulses, we sample the signal by applying it by little things that look like little smooth functions, like maybe a Gaussian, or other functions that we'll talk about do an even better job. OK, so that process is called tapering, multiplying your data by a little [AUDIO OUT] paper that's smooth, unlike a square window. And we're going to come back to that, how to really do that right, on Thursday. of noise. In order to estimate what the spectrum of noise looks like, you have to take many examples of that and average them together. And when you do that, what you find is that the power spectrum of Gaussian noise is a constant. It's flat. The power spectrum, really, you should think about it properly as a power spectral density. So there is a certain amount of power at different frequencies in this signal. And forGaussian noise, that power spectraldensity is flat. It’s constant as a function of frequency. over the sampling rate and another copy sitting up here. The sampling rate needs to be greater than twice the bandwidth of the signal. These copies of the spectrum are too close to [AUDIO OUT] and they overlap. That overlap is called aliasing-- a-l-i-a-s- i-n-g. Now that's an amazing claim. Right? You have a time. All right, it's wiggling around. What this is saying is that I can sample that signal at regular intervals and completely ignore what's happening between those samples, have no knowledge. sample the signal in the time domain and then add a bunch of zeros to it before you Fourier transform. And that gives you finer samples in the frequency domain. And I'll show you in more detail how to do this after we talk about tapering. And it's very simple code actually. Matlab has built into it the ability to do zero-padding right in the FFT function. OK, let's actually just stop there. I feel like we covered a lot of stuff today. Micheal FEE: Today, we're going to continue with our plan for developing a powerful set of tools for analyzing the temporal structure of signals. We'll talk about the convolution theorem, noise and filtering Shannon-Nyquist sampling theorem and spectral estimation. Next time, we'll move on to spectrograms and an important idea of windowing and tapering, time bandwidth product, and some more advanced filtering methods. And there may be, if there's time, a little trick for removing the line noise from signals.

ROUGE-1: 17.14, ROUGE-2: 16.51, ROUGE-L: 15.23
BERTScore: 61.74

==============================================
==================== [59/100] ====================
Summary:
level problem sets. Developing a command of mechanics is a powerful tool for understanding the world around us. Welcome to 8.01, the latest version of the Java programming language. We hope to see you in the next edition of Java 8, which is scheduled to be released later this year. For more information, visit the official Java 8 website or follow us on Twitter at @joshjenson and @jenniferjenson. For the latest Java 8 news, visit our news page. The science of classical mechanics establishes an important principle of cause and effect. Newton's Laws of Motion established the scientific principle of analyzing observed phenomenon through the use of clearly articulated mathematical models rather than through intuition. Developing a command of mechanics is a powerful tool for understanding the world around us. 8.01 assumes a strong background in high school level physics and mathematics, so a previous course in calculus is not a prerequisite. It is a rigorous and technically challenging course aimed at MIT undergraduates. In each of these lessons, you will find a series of short lightboard videos that will help you understand concepts.

ROUGE-1: 54.93, ROUGE-2: 42.33, ROUGE-L: 41.01
BERTScore: 71.31

==============================================
==================== [60/100] ====================
Summary:
G, 1 over the degree of v plus 1. So let us prove this theorem first, and then we'll see an application and some ways to interpret this result. The proof of this theorem applies the probabilistic method. So we are given this graph G. And the first thing we'll do is order the vertices of G uniformly at random. So the edges are 1 to 2, 2 to 4, 3 to 4 and 1 to 3. What because one of them would appear before the other in the order, and that would violate the condition. Turan's theorem is a foundational result in graph theory. It says that every n-vertex. graph G contains a clique on at least this many vertices. So here's the example. Let us take the n vertices and split them into equal parts. And there are r parts, so here in this illustration r equals to 3. And let's put in all the edges between parts, but no edge within a part. So this is called the complete r partite graph. minus 1 minus 1 over r times n. And this quantity here equals to r. So there's a strict equality sign here. In particular, G has a clique of size strictly greater than r, and that finishes the proof of Turan's theorem. Turan’s theorem is a important and foundational result in graph theory. And it's a start of a subject that we now call extremal graph theory, concerning what can you say about a graph that has certain properties, like not having a large clique? An independent set in a graph is a subset of vertices with no two adjacent. For example, if the graph is this cycle on four vertices, an example of an independent set would be two vertices like this. So an important question in graph theory is given a graph, what can you say about the size of its independent sets? The following theorem, due to Caro-Wei, says that every graph G contains a large independent set of size at least the following quantity.

ROUGE-1: 41.36, ROUGE-2: 40.47, ROUGE-L: 32.13
BERTScore: 73.73

==============================================
==================== [61/100] ====================
Summary:
could be something really awesome in the game, and you make a decision. How about if you decide to roll a die? Game state has changed, usually. Is that a meaningful thing? It could be if it's like a choice you have. You roll a dice in one direction of the game or do you not, and choose different that's meaningful. It's like, do I roll the die now, or do I wait a minute before I take my turn? That's not really a meaningful decision. comes with a bunch of cards. Ooh, whoa. What happened to these cards? Good Lord. OK, now the paint could rubbed off or something that. So don't worry too much about the text and the graphics. But just look at the card. What do cards allow you to do? What are the affordances of cards? Hm? Audience: You can hold a couple of them in your hand. Because there's two sides. There's a side that you can put no useful information on, right? Besides the brand of the game, sure. on their side. It's possible but really hard to make something, to make a card stand up. Other orientations other than that face up or face down aren't really considered. A square card could afford full rotation in any direction, rotation. We'll get that, actually, in the next one where you can just rotate things around. The various terrain features such as the-- AUDIENCE: --rivers and roads. You can match up. They line up nicely when you put the tiles in a grid. couple of things in this game that is this board. There's a back of the board, which is not colored. And it has a design on it. We could just pass this one around. It's got little playing pieces that are referred to as meeples by the hardcover board game fact base, I guess. They look like little people. Actually, there's probably enough in that for everyone to grab one or two. And then you can just take a look. to get all the Carcassonne bits back. So and then we'll pick this up in about five minutes. We'll be back with the rest of the story in a few minutes. Back to Mail Online home. back to the page you came from. Click here to read the full transcript of this article. Back To the pageyou came from, click here to Read the Full Transcript of this Article. Backto the pageYou came from the page You were from, Click Here to Read The Full Transcript. Professor: "I want you to keep in mind that you're not constrained to building games that look exactly like those" "I really, really hesitate not-- try not to put any live digital components in your game" "If somebody wants to take a hardcore strategy game into a lighthearted party game, or vice versa, that's their prerogative" "You as the designer are are going to run through a number of different challenges trying to be able to give them an experience"

ROUGE-1: 9.20, ROUGE-2: 8.35, ROUGE-L: 7.73
BERTScore: 57.44

==============================================
==================== [62/100] ====================
Summary:
we do is now we write the full equation and we sort it into sub equations corresponding to powers of lambda. So the lambda to the 0 equation is really easy. It's just H0 psi 0 is equal to E0 psi0. We could put n's on this. And this is the exactly solved problem. It says, yeah, you build your foundation from the Lambda to 0 equation, and it's just what you know already. And what you're going to do is use the psi n 0 and en 0 to do everything else. names that any educated physical chemist will know to say, oh, that's the Bixon-Jortner. And they're still alive. They're still doing beautiful stuff. But anyway, that is all I want to say today. I will do details on one mode and Morse oscillator in other sorts of things next time. Back to Mail Online home. back to the page you came from. Back To the pageyou came from, Back to thepage you came From. Back into the page. Lecturer: We can take a two by two Hamiltonian and exactly diagonalize it. In the next lecture, we'll look at non-degenerate perturbation theory. The next lecture will be on the interactions between normal modes of a polyatomic molecule and an ordinary, ordinary,harmonic oscillator. The lecture will also look at the effect of the structural parameters in this Hamiltonian on the energy levels and properties of the system. It will be presented by Robert Field, a spectroscopist and professor at MIT.

ROUGE-1: 8.24, ROUGE-2: 6.86, ROUGE-L: 5.82
BERTScore: 56.96

==============================================
==================== [63/100] ====================
Summary:
Free disposal is when you can dispose of inputs without spending any resources fine. No free lunch is when at least 1 input is required to produce some output, or more than you know more than 1 kind of output. You cannot produce something out of thin air, you cannot consume something like in the harry potter world. If you have read Chandrakantha book in hind there, also you know people would create something in this world even the current level of technology fine so that is free disposal. The second is no free lunch. 1 kg of rice can be produced from 1 comma 2 plus 1 minus t 2 comma 1, and this is what additivity is if this 1 unit of input 2. So, 100 units we can produce by replicating this process 100 times. And again 50 times we will use the second process. And if we define the t dash by 100 is equal to t, then we can say 1 kg of Rice can beproduced by t 1 comma2 plus 1minus t 2 commas 1. And this will give us 1 kg using this t dash. is possible, then we say that technology exhibits additivity. Another related, but it may sound different let us say, if it is technologically feasible to produce y amount of output, then it is also technologically possible to produce  y plus y dash. This is example of convexity; let us talk about additivity first. So, let us look at it. . What it means? We have taken example where 1 unit of output can be produced using 2 units of input 1 and 2 unit of input 2, we have used different symbols there. feasible here, y is taking care of not only inputs but also output. The combination is all given here and this exhibits convexity. This is a simple example of how to make a complex shape. The shape can be any shape at any time. It can be either a shape or a shape-shift shape. It is possible to combine two shapes to create a shape that looks like a shape shape. For example, the shape could look like the shape of a circle or a circle. The key word is feasibility technology. Feasibility technology represents the feasibilities that out of nothing that is not possible in the real world. For example let us say that we need only milk to produce curd. So, if it is feasible to produce half kg of curd from 1 kg of milk, then it is possible to produce 250 grams of curD from 1kg of milk. Third is non reversibility, what it means is that a production process cannot be reversed. And fourth is convexity, we are going to talk about additivity that we talked about earlier and divisibility fine.

ROUGE-1: 26.68, ROUGE-2: 22.93, ROUGE-L: 17.23
BERTScore: 69.88

==============================================
==================== [64/100] ====================
Summary:
The Great Wall began as multiple walls of rammed earth built by individual feudal states during the Chunqiu period to protect against nomadic raiders north of China and each other. Under the Han Dynasty, the wall grew longer still, reaching 3700 miles, and spanning from Dunhuang to the Bohai Sea. The wall was formidable but not invincible. Both Genghis and his son Khublai Khan managed to surmount the wall during the Mongol invasion of the 13th Century. main body and expanding this remarkable monument to human achievement. Main body is made up of three parts: the head, the torso, and the legs. The main body of the main body is the most important part of the body. The second part is the lower body, which includes the legs, the arms, the legs and the feet. The third part is made of the lower torso, which is the largest body of its kind. The last part is called the lower legs, which are made of marble and marble. The Great Wall of China was granted UNESCO World Heritage Status in 1987. Originally built to keep people out of China, the Great Wall now welcomes millions of visitors each year. In fact, the influx of tourists has caused the wall to deteriorate, leading the Chinese government to launch preservation initiatives. New sections are still discovered every few years, branching off from the main body and expanding this remarkable monument to human achievement. In low Earth orbit, all sorts of structures, like bridges, highways and airports are visible, and the GreatWall is only barely discernible.

ROUGE-1: 48.30, ROUGE-2: 38.41, ROUGE-L: 37.64
BERTScore: 63.02

==============================================
==================== [65/100] ====================
Summary:
scoring function is independent of the protected attribute. So that allows a little more wiggle room because it says that the protected. attribute can still predict something about the outcome, it's just that you. can't use it in the scoring function given the category of which outcome category that individual. belongs to. It says that given the scoring. function, the outcome isIndependent of theprotected attribute. And usually, there are knobs in these learning algorithms, and depending on how you turn the knob, you can affect whether you're going to get a better classifier that's more discriminatory. work here and embarrassing myself. So this is modeling mistrust in end-of-life care, and it's based on Willie's master's thesis and on some papers that came as a result of that. If you look at African-American patients, and these are patients in the MIMIC data set, what you find is that for mechanical ventilation, blacks are on mechanical ventilation a lot longer than whites on average. Now, of course, we don't know exactly why, but that's the case. fairness popping up at different universities. University of Pennsylvania has the science of Data ethics, and I've mentioned already this fairness in machine learning class at Berkeley. This is, in fact, one of the topics we've talked about. I'm on a committee that is planning the activities of the new Schwarzman College of Computing. The college obviously hasn't started yet, so we don't have anything other than this lecture and a few other things like that in the works, but the plan is there to expand more in this area. Peter Solovits: I got a call from a committee of the National Academy of Science, Engineering, and Medicine. He says they convened a meeting to talk about the set of topics that I've listed here. Solovitsch: They talked about AI and decision making, privacy and informed consent in an era of big data, science curricula for law schools, emerging issues, and science, technology, and law. The issue of using litigation to target scientists who have opinions that you don't like was also discussed.

ROUGE-1: 6.97, ROUGE-2: 6.57, ROUGE-L: 5.37
BERTScore: 60.86

==============================================
==================== [66/100] ====================
Summary:
methods. So all those methods basically look the same. You just get equations that have more unknowns in them. And so fundamentally, there's no problem, but in practice, there is a big problem if the number of unknowns gets to be so large. So think about it. How many points do you think you need to discretize? Now, these are all different ways to write down the equations. All of them are correct in the limit that delta z goes to zero. But they lead to really different numerical properties when delta z is large. trying to flow by, sort of, every path. And there's some insulation that's resisting its flow. And it has been in the connectivity of flow a certain way. Those kinds of equations are called elliptic. And the methods that we use for the relaxation mesh that we showed are really good for those kinds of problems. And then another kind of problem that we get into a lot is like this one. This is called parabolic. And typically, in the cases we see that are parabolic, we have time as part of the problem. a terrible approximation to do this. You can see that what we're doing is, when we have this problem where the local Peclet number is getting too large, is we're actually choosing delta z bigger than the, sort of, the thickness of the solution. And approximation to the differential. This is a asymmetrical finite difference formula. It's not a very good value estimate of the derivative, if delta z is big. But you can write it out carefully and write this out and say, oh, this actually is sort of like this plus an effective diffusivity chosen very carefully. before. There's a similar thing and it might be relevant to the COMSOL problem that Kristyn showed you on Monday, is you can-- In that case, there was a region of the boundary here that had some concentration c naught, and then there was, over here, the concentration was zero. Here, it's some number, 17, whatever number it was. And if you think of how to model what's going on, one way to look at it is, I have a diffusive flux coming in from the drug patch, diffusing the drug into the flow. sure we all our time steps are exactly right. We're just going to throw away all those time points anyway. We'll just keep the final one as our initial guess for a Newton-Raphson solve to find the steady state. So this is time accurate. There's another method. I don't know if I should call it time inaccurate. If you don't care, if the solution is really, what the solution yft is, all you care about is where you get to, then you can do other methods. set up is right, so you can use it. But if you can, it can be pretty good. All right. See you on Friday. Back to Mail Online home. back to the page you came from. Click here for the latest from CNN.com. Back To the pageYou came from the page You came from: Back to the Page You Came From: Back To The Page You Were Originally From: The page you were originally from: The Page you were initially from: the Page you started from. Professor: Today we're going to talk about partial differential equations. Professor Swan is going to do a review on Friday. Next time I'll be lecturing to you will be a week from Friday. The homework following the quiz will be posted and so you guys can get started on that. For example, if you wanted to solve the Schrodinger equation for h2 plus, it turns out there's a special coordinate system called the elliptic coordinate system. And in that coordinate system, the partial differential equation is separable.

ROUGE-1: 14.03, ROUGE-2: 13.03, ROUGE-L: 11.20
BERTScore: 57.30

==============================================
==================== [67/100] ====================
Summary:
the da vinci code is not the biggest circulated book in the world. i'm like i i can't speak to don quixote so um that's something i might just have to look up because that's interesting to me. oh no you know don Quixote or something i'm just like i don't know what that is. that's an interesting thing to think about. i may have to do some research on that. i might have to find out more about it. elizabeth the first is considered one of the greatest rulers in england's history if not the greatest for women. She never married can you blame her i mean look at what she grew up with around her dad and all of those moms and stepmoms she never had any kids which that causes a problem come her end time okay where we have i don't have an heir so she eventually does set on a cousin up in scotland which is the country on the same island of england but right above it.

ROUGE-1: 41.04, ROUGE-2: 34.75, ROUGE-L: 22.41
BERTScore: 60.92

==============================================
==================== [68/100] ====================
Summary:
The average velocity depends on the time interval t to t plus delta t while the person has displaced a certain amount of vector delta r. So, as a vector, we have delta x over delta t i hat. This component here is what we call the component of the average velocity. And, again as before, this component can be positive, zero, or negative depending on the sine of delta x. And now what we want to do is consider what happens in the limit as delta t becomes smaller and smaller. And that will enable us to introduce our concept of instantaneous velocity.

ROUGE-1: 55.17, ROUGE-2: 53.33, ROUGE-L: 55.17
BERTScore: 82.08

==============================================
==================== [69/100] ====================
Summary:
this what is the English statement here it is the angular of velocity frame B with respect to frame a right okay so we saw that for the first time now a little bit on the low of angular velocity that you've seen in previous classes but we we Plunge in anymore um the first thing is can of Point have an angular velocity now can a frame have a velocity kind of no because if a frame's rotating some point different points will have different velocities so yeah a frame can have a Velocity but doesn't really mean much and you tell me which point in the frame you're referring to right. If I change the order in which I add angles they don't add up right so if I said 45° up and I'm going to trade 45° my arms up here right why is the angle adding up here a has something changed over the weekend if I turn 45° anyway. But infinite decimal angles do add up you remember this you did this in physics. If I rotate about one axis a certain amount 30° and then rotate about another axis 30° right if I reverse the sequence they don’t add up. But it turns out that here if I take a very tiny rotation not 90° but like. 1° then the sequences do actually add up okay. of thing you need to kind of walk around with a book you know and people will think you're nuts but you know do that and you'll see that the angles kind do add up you get it. Angle of velocity is a measure of the rate of change of angle so it's a d Theta. It's a tiny angle get it in a moment of time right in a very tiny moment oftime so angular of velocity does add up so you can treat it as a vector in the math. here so will you please expand it for me what does that come out to be this is the left hand side of that formula right and we'll do the right hand side separately and show that the two are the same I'm trying to prove it to you right so I'm not you know I'm doing just very boring stuff but we need to do it just establish it what is d by a d by DT of U1 cosine Theta it is U1 do cosine theta right minus U Theta do sin Theta. yeah okay using um frames uh using angle of velocity so the problem was we have the ground, the spider and the Frisbee. We characterize this situation with three parameters okay and the parameters are the positions of the center of the frisbe right and the distance of the spider. And the angle of theSpider from theCenter of the Fr Isbee right and assuming the spider is only moving in a straight line with respect to the FrIsbee away then we just need a distance. the the acceleration the velocity and acceleration of the of the insect anybody how do I begin write down the yeah always begin by writing down the position Vector so r o s is equal to U A1 Plus V A2 plus L B1 L is the distance of the spider from the center of the fris oh oh I call it Q sorry sorry I'm sorry q h say it again ah let me ask you when I write a position Vector does it need a reference frame doesn't the only thing where I can get away without writing a a uh reference frame is when I writing a vector at a vector is just you know the frame when the frame is implicit in the basis vectors. with respect to a what do we call that say again it is yes it is if I take the derivative of this it is right plus the derivative, this so in fact if you want I'll expand it I'll write it in smaller steps so you you you can follow it right right I've just written it out right. So this is the velocity version of the magic formula and I'm sure you'll admit that I did nothing particularly profound in deriving this okay and then that handout the typed handout that you you hopefully downloaded and read from the web you will see this EXP expand it out for you. yeah sorry and plus this thing okay we'll end now because Professor Socrates needs to take over this is it this is correct acceleration of P acceleration of Q with respect to B Oiler coris centripedal and you know why it doesn't go to zero because I'm not taking a Omega B cross a omeg B. I'm taking a omega B cross this whole term which is at 90° to a OmegaB got it got it? Yeah sorry and Plus this thingOkay we'llend now because professor Socrates need to takeover. Last week we looked at the we first saw our first magic formula which you've probably forgotten because it was a wonderful weekend so I'll remind you and um then from there we will uh resolve the spider problem and then uh we're going to solve uh the super magic formula. The Machinery I provided you is powerful enough to solve pretty much any kinematics problem because it's based purely on Geometry angular velocity is a kind of a madeup concept that just simplifies the math and it's kind of intuitive stuff.

ROUGE-1: 17.15, ROUGE-2: 16.62, ROUGE-L: 15.16
BERTScore: 65.44

==============================================
==================== [70/100] ====================
Summary:
Olympic Games will be a dedicated event to celebrate Gamers and eorts F and why was the decision made to go down that separate route so instead of having it scheduled alongside Paris next year uh to put it in its own year. I would say that it's pretty clear that the sem Olympics bringing value to the community to the to the players to the fans and they are clearly positioned. I think there's room for new events in addition I wouldsay we are very focused on let's say Counter Strike or do 2 maybe League of Legend which are games that don't have enough stage to play on. The first edition of the Esports Olympics will be held in LA in 2028. 50% of the athletes will be women 50% will be male. The goal is to reach this target from day one. It will be a game changer not for the Olympics but for Esports. It's got its own separate event but there might be some people who might feel a bit disappointed about that potentially it's not my role to say yes or no because I'm not decision maker but I'm very positive and affirmative. opening ceremony under the the Olympics logos this is amazing the pride in their eyes is the fact that the parents had to find a passport for them to travel to represent I think this is what I want for every single players of G2. I believe this will also help us to connect with the BBC and talk to a mainstream audience about something that they don't know and and be discover this amazing Community this amazing passion the the Quest for excellence and the individuals that will become the heroes to win the trophy for the national team. "Everybody wants to see what a dennish team will do against Corin I I would love to see it too you know so um I've seen a lot of players making the the guess or what the team could look like so his aspiration to be part of is is clearly part of the discussion," he says. "You follow a bit like the conversation about but uh rocket league and OverWatch back in the days at the at the World Cup for for their game and and and League of Legend also often have this conversation about creating the Euro Cup or World Cup" Al shalot is the CEO of GT Sports. He is also a member of the Esports commission the international Olympic Comm. The turning point for him are the Asian Games the people from the Olympic Committee when they attended this event they're like okay now we get [Music] it hi there my name is Al Shalot I'm the CEO. GT Sports uh it's an Esports organization pretty Global they call us the real Madrid of Esports. We have 13 teams in 10 games on three continents.

ROUGE-1: 22.76, ROUGE-2: 21.80, ROUGE-L: 17.63
BERTScore: 63.83

==============================================
==================== [71/100] ====================
Summary:
"untie" means "take something and do things to it such that it is no longer in the state it is standardly in after you have tied it" There's an "un-" that applies to verbs, and has a reversitive meaning. "Un-" number two combines with adjectives and makes adjectives that mean more or less "not (adjective)." So "unkind," or "unfamiliar," "Unfortunate" These all mean not the adjective, whatever it is. "Unlockable" is ambiguous because there are two "un-"s. "Un-" can combine with either a verb or an adjective. " unlockable" consists of three morphemes, a prefix, a stem, and a suffix. It's not a complete description of what's happened either, but it is also those trees, or those trees represent something, namely the order in which you did things. "John walked up the stairs," "Mary looked up the stairwell," "John" and "Mary" are sentences. Theory of syntax would divide sentences into three kinds. There are sentences that you've heard a zillion times before, like "We're going to class" And on the other hand, sentences you have possibly never heard anyone say, but that are fine. So if I say, "My anteater is hula dancing," you may never in your life have heardAnyone say that. Maybe you have. Some of you may have had more exciting lives than I have. But it's an OK sentence. There's a fairly stupid hypothesis, which says, all you're doing is remembering things people have said, and that's what distinguishes grammatical sentences from interpretable sentences. That's false. You can take a sentence you've never heard before and accept it. We're going to have to be explicit about which subparts count and what exactly we mean when we say that. But you're right, there could be a better version of that hypothesis. Good point. Other questions? Did I successfully answer your question? Yeah. "Colorless green ideas sleep furiously" is meaningless if you don't mess with the meanings of the sentences. If the words meant something else, the sentence would be fine. "furiously" is an adverb and it's trying to modify "sleep" When I say it's meaningless, what I mean is you can't sleep furiously, he says. "I wonder if it just has to do with the idea [INAUDIBLE].. NORVIN RICHARDS: Yeah. In many languages, including Latin, you have to say, "About what are you talking?" In English, you always bring it along with the question word to the beginning of the sentence. "Who" is supposed to be the direct object of "you are talking to" this person, so it's like, "to whom are youtalking"? "To whom areyou talking?" sounds fancy and snobbish, but still right, according to the linguist, who says it's not his go-to way to say this. many recordings of English speakers you go through, you will never find an infinitely long sentence. Nobody actually says these things. But the reason nobody says an endlessly long sentence, the idea is going to be, it's a fact about life. And we don't care about life in this class. We're not going to try to find out what's the longest sentence anybody ever uttered and try to get that fact to be a fact that we want our grammar of English, our theory of the possible sentences of English to be. will find the red book" for example, we'll see that syntax treats that string, "The red book," as a unit. It's OK to take a substring like that and put it together with another similar substring conjoined with the word "and" so you can say things like, "I will find thered book and the blue pencils" But "find the red I will book, leave the blue I will pencils." No. Can't do this with just any random three-word string. the fact that it contains a noun. So when we put together "red" and "book," what we get has properties that are determined by the fact that they contain a noun, if there were no noun, it wouldn't have those properties. Similarly, with "the red book," the things that can go in that slot, there are various kinds ofThings that can be larger or smaller. What they all contain is a noun; we're going to name that thing after those kinds of units. We'll give it the label "noun" Kind of like when we added "un-" to "lock" and got "unlock" is that it contains a noun. "Find the red book" we're going to give that the label verb, because having a verb is the important part for that. "In the garage" is a unit, it's a constituent. It's the kind of thing syntax gets to care about. And again, if I say, "I will find the book in the garage," and you're amazed, you can say "in the garage?" It's a prepositional phrase. kind of example that I was exploiting in the first slides I was showing you about syntax. Notice, for example, that if I say I will wake up the cats and you're astonished as you might well be, you can't say "Up the cats?" You cannot say, "I will walk the stairs up," I think. So "up the cats" is not a prepositional phrase. We need different structures for these verb phrases, and we will develop them. I was a way, waking the cats up, it's a little bit like painting the cats red. You can't say, "I will walk up the student to her room," can you? NORVIN RICHARDS: No. That implies you're walking on the student, which is not the case. For "walk up them" we want "up" and "them" to combine to be a propositional phrase. For these other two, we want something else. We're going to want to circle around and try to find out what that other thing is. Do you have a suggestion? Share it with us at CNN iReport. construct syntactic trees for strings of words. It's often the case that we get ambiguities like the "unlockable" ambiguity. There is more than one way to combine things. And what we'll do is develop tests that allow us to see which way we've combined words in different ways. And we'll find cases where, depending on in what order you combine things, you get different meanings, and our tests will combine with that. All right. We will do this again on Tuesday. Linguist: "Unlockable" can mean either it's possible to unlock it, or it is not possible to lock it. "Un-" combines with verbs to make adjectives like "singable" or "understandable" "This door is broken, It is un-unlockable," would mean it cannot be unlocked. "Go harass your roommates whose minds have not been contaminated by linguistics," he says. "If you are going to try to learn from me how to make yourself popular, then you are in the wrong class"

ROUGE-1: 16.11, ROUGE-2: 15.24, ROUGE-L: 14.47
BERTScore: 62.93

==============================================
==================== [72/100] ====================
Summary:
like I said we first started this particular piece talking about it you know that memory if I am dead if I'm gone think back to this time sister if you can't hear my any longer just remember what my feelings are for you. "This is one I probably say the top three or four most difficult pieces not that it's crazy hard but it's just it's a lot more difficult than reading those pulp" "My voice and my spirit will continue because you'll be experiencing all of these things and thinking in the same mind frame that I was thinking" William Wordsworth and Samuel Samuel Taylor Coleridge probably the two of the most influential of this particular era. William Wordsworth just reading about some of this past you know upbringing and how that influences writing. The piece that we'll read today it's heavily influenced by his past. The next piece we read is called The Rime of the Ancient Mariner by Samuel TaylorColeridge. We'll talk about the literary partnership that was that was created between Coleridges and the Mariner.

ROUGE-1: 8.46, ROUGE-2: 7.68, ROUGE-L: 4.43
BERTScore: 58.82

==============================================
==================== [73/100] ====================
Summary:
The goal is to understand solar cell conversion efficiency, which is the ratio of output to input energy. For most solar cells, this breaks down to the following progression, from the solar spectrum to charge collection. After we get through the fundamentals, we'll be in a good position to understand the different technologies and finally the cross-cutting themes. The lecture will focus on charge separation, incorporating elements of either side but mostly focused on Charge separation. The final lecture will be on the diode under illumination. When we reverse bias our device, notice the separation of the quasi-Fermi energies. And the diffusion current increases. And that's why we have current now a positive value. We've defined the electrons traveling to the left as being a positive current. We have now electrons traveling from the n-type to the p-type material. And so instead of electrons flowing from n- type to p- type, where we had defined as positive current, electrons are flowing from p- Type to n-Type in that, which we defined as negative. Solar cell researchers often do is they say, OK, let's normalize the current by the area to get a current density. At the y-intercept, there is maximum current a lot of it, right? That's the maximum power point. This is the point at which the solar cell is producing the maximum amount of power output. It's where this blue curve reaches a maximum. That is where the solarcell is outputting the maximum Amount of Power. The maximum power is truth in advertising. point divided by the solar insulation, fill factor being defined as the ratio of Vmp Imp product divided by Voc Ioc product. These parameters right here are fairly easy to measure using the solar simulator that you just put together. And so from an engineering point of view, when we break the solar cell output down into these three parameters so that we can better understand what's going wrong with our solar cell, we can get a better idea of what's wrong with the device, the professor says. pay more for a high-efficiency cell because I'm using less area, you can use this type of calculation to get to the answer quickly. This is a really back-of-the-envelope envelope engineering approach to estimating costs of a solar system. So I think this is a great place to stop. And if anybody has an idea, a fun idea, for a class project, I'd invite you to give a pitch up here at the front of class, or you're welcome to send it on an email to the class listserv. The total system efficiency is the product of each individual component going on here. So now what we're going to do is just quickly revisit the diode in the dark and construct the energy band diagram for pn-junction in thedark. Now let's try to imagine what will happen under illuminated conditions, and let's start out in a very simple case. We'll assume that the principle of superposition applies here, that the photo-excited carriers-- in other words, when light shines into our device, essentially exciting electrons.

ROUGE-1: 11.44, ROUGE-2: 10.85, ROUGE-L: 8.65
BERTScore: 62.81

==============================================
==================== [74/100] ====================
Summary:
The world woke up this morning to worldwide chaos caused by a global outage. Thousands of flights have been cancelled Banking and health care has been affected including the NHS and some TV channels have been taken off air millions of people have been affected. The firm behind the outage crowd strike has held up its hands but admitted that it'll take time for things to get back to normal. The company is deploying a fix but not before widespread Mayhem tonight we'll be looking at exactly what happened and how it's affected patients passengers and businesses. Disruption on what was set to be the busiest day for UK flights since before the pandemic will take time to sort out. GP practices in England and Northern Ireland that have been most affected with doctors struggling to access their records and online bookings Pharmacy Services have also been hit. GPS can only hope the problems are resolved quickly huim BBC News. Katy Austin BBC News and just a reminder you can get all the latest on the Travel turmoil online and that's at bbc.co.uk. This just goes to show how dependent we are on it and how vulnerable we are I think it really highlights the fragility of our digital lives. There are some calls for people saying actually we shouldn't be so reliant on on a few big companies for everything. Other people are saying well actually if we have lots of smaller companies doing this stuff then are we leaving ourselves more open to vulnerabilities to weaknesses to attack so it is a real dilemma I think but nobody has seen anything of this size. saying well actually if we have lots of smaller companies doing this stuff then are we leaving ourselves more open to vulnerabilities to weaknesses to attack so it is a real dilemma I think. Nobody has seen anything of this size you know I've been covering outages now for a long time and normally they're over before they start so to see something like this have such a huge Global impact I think is really going to um make people sit up and think it certainly made people get cash out of the bank today. Faulty update meant millions of Microsoft users saw this screen pop up if you know it it'll make you shiver the blue screen of death it pops up when there's a critical error affecting the operation of your PC. Microsoft says some people have had to do it 15 times so it could take a while spare a thought for it departments there will be someone In Crowd strike who will be in a lot of trouble right now for not getting this right. from travel chaos to grocery shop payment problems there'll now be tough questions about the Damage Done by one faulty update how did it slip through Microsoft safety nets the cyber security world.

ROUGE-1: 39.07, ROUGE-2: 35.83, ROUGE-L: 23.65
BERTScore: 63.08

==============================================
==================== [75/100] ====================
Summary:
In the year 2000, four-year college grads actually earned more with their entry jobs than they're earning today. In the year 1970, only 1 out of 100 taxi drivers had a college degree. In today's world, the momentum is moving toward people who are trained, says Tyler Cowen. The labor market is more about skills than ever before, Cowen says, and college degrees are no longer enough to get a job in the U.S. Today's labor markets are ruled by supply and demand, and supplies and demands are changing all the time. Kinds of labor. Well, skilled labor -- working with computers -- is much more powerful. The computer enhances the productivity of the skilled laborer. And information technology makes it possible for skilled labor to sell their products around the entire world. At the same time, with information technology, that can be pretty hard to learn. So changing technology has made wages rise more at the top, but has held wages down for a lot of other jobs. And new college graduates are experiencing that when they go into the labor market. in information technology, who work well with computers and who can exploit growing global markets. When supply and demand are ruling labor markets, the people who do well are those who have an economic understanding of where is demand high, and where is supply scarce. Check out our practice questions to test your money skills. Next up, we'll show you where to find data to help you decide which career to choose. We'll also show you how to get the most out of your college degree, including how to apply your knowledge to the real world. Technology has altered supply and demand in the U.S. labor market. The number of start-ups in the American economy has been declining each decade since the 1980s. A third set of factors has to do with slower economic growth, slower productivity growth and slower dynamism. Next up, we'll show you where to find data to help you decide which career to choose. The Daily Discussion is CNN Tech's weekly, offbeat look at what's happening in the world of business.

ROUGE-1: 40.77, ROUGE-2: 34.35, ROUGE-L: 26.18
BERTScore: 67.22

==============================================
==================== [76/100] ====================
Summary:
non-satiation, but let us take example of your monotonicity, monotonicism, and what would it imply? In other words, let us say that is clear that, that is through definition, but it if we translate it into indifference map what we will get that the indifference curve has to be a downward-sloping curve. So, from here we learned that indifference curve have to be downward sloping. What else? Anything else themonotonicity would tell us? indifference curve has to be very thin, fine, it is clear. And now we have convexity plus conveXity. Let us say a person’s preference satisfies all the other axioms, and I draw let us say this is his indifference curve. Can I say it is bowed out? As opposed to this what you here, if convexy is not satisfied you get something like this. When we have satiation or in other words when we have bliss points. How would the indifference curve look like? Concentric circle around like this why I am talking about it good 2 and good 1. All the bundles here are preferred over the original two bundles, why because here at this point utility is increasing in this direction. So, it is convex. Convexity is satisfied, continuity is satisfied. rationality axioms are satisfied. What is not satisfied here is monotonicity or local non-satiation is satisfied everywhere except at this bliss point, is it clear? So, now, what we will do we will start talking about mathematical problems, optimization, and all. So, the first we learned rationality, rationality axioms - completeness, reflexivity and transitivity. And when our when someone’s preference exhibit these three properties, what does it mean that he is able to completely rank all his choices all his potential choices, with also possibility, with possibility that there are more than one bundle at some ranks this is a possibility. One thing also I should add that he will be able to rank only if he has finite consumption set and also what we have learned that this will translate into a utility function. So, if these 3Axioms are satisfied you will get one utility function, in case, of finite consumption good, fine. Next we add I am not saying just continuity implies this, but continuity in addition to earlier three Axioms that we have learning, continuity. And what do we get? What we get is continuous utility function and now we do not have to impose the restriction that our consumption set is the consumption set of this individual is finite.

ROUGE-1: 53.48, ROUGE-2: 52.01, ROUGE-L: 31.53
BERTScore: 77.15

==============================================
==================== [77/100] ====================
Summary:
If you have a complex polyhedron, we found general unfoldings. They work. We proved one of them. If you want an edge unfolding, that's the centuries-old open problem. For non-convex polyhedra, we know this is too much to hope for. Even if it's topologically convex, there's not always an edge unfolds. But for general unfolding, we don't know. So today's lecture is actually mostly about these two open problems and different variations of it. This is actually the base case, if you will. So in general, I just pluck off two or three triangles, repeat until I get one of the base cases. So imagine those guys as being done. I'm left with these four triangles, actually, a little boring because I don't get the Mickey Mouse case. But then, this will be an ear. This will be a second-level ear. And so I'll end up doing this. And this is an ear, and this will Be an Ear. So ideally, k is one, and you're not subdividing at all. But maybe, you take every rectangle, divide it in half. Maybe that's enough to then be edge unfoldable. That would be sort of a refined level two grid-like unfolding. There are a ton of results about this. They're all partial. But one thing you could do, with merely 5 by 4 refinement, is something called Manhattan Towers. Let me show you a picture of Manhattan Tower. This is more crazy examples of what it's like to visit. is what I have written here. I haven't actually read that paper. What else do I have? Orthotubes. Orthotube is just sort of thickness one orthogonal tube. It could even be closed, I think, in a loop, but here I've shown it open. And here, grid unfolding is enough. You just do all the grid refinement. You could even just do it locally. Technically, there's a slice here that might slice over here, but you don't have to worry about that. is to say, suppose you have two convex polyhedra, and suppose they came from the same sort of intrinsic geometry. So there's the geometry of the faces, and there's how they're connected together. Different faces can be different, but they're identical in pairs. That's what we're claiming. Is this one any better? Yeah, it's better. This is an old theorem. You may have heard of Cauchy, famous French mathematician. He proved a lot of things. This theorem he didn't actually prove. The average degree is 5? Slightly under 6, 4, 3, 2, 1? Let's see. Should be like 3 n minus 6 edges, so that should be 3. So most of the faces are going to have low degree. So 3 and 5 really matter, but out here, it doesn't matter so much. This is kind of a magical proof. It shouldn't be intuitive where it came from, but it's really beautiful. You'll see as it all comes together. compute the shortest paths between all pairs of vertices, something like this picture, except you don't know what it looks like in 3D. You know every edge must be a shortest path. So the edges are some subset of these guys. And so you've got lots of little convex polygons here. We know it must make a convex polyhedron. If it made two, Cauchy's rigidity theorem would tell you that they're the same. So even once you fix the gluing, you know that there's a unique convex realization. Theory of the facet-path: A path that alternates between visiting faces, triangles, and vertices. Professor: It's an open problem for something like a cube where you actually have quadrilateral faces. He says the claim is facet- Paths always exist for any triangulated, connected surface. The theorem works not only for a polyhedron-- it works for any manifold, any sort of locally, two-dimensional thing, he says. "It's useful because then, we'll get to Mickey Mouses, as we'll see"

ROUGE-1: 11.07, ROUGE-2: 10.71, ROUGE-L: 9.77
BERTScore: 68.30

==============================================
==================== [78/100] ====================
Summary:
When a particle's undergoing circular motion, it has a velocity that you can describe, which is the tangential motion around the circle. And it also has an angular velocity, which we define as being in a direction that's perpendicular to that direction of rotation. Let's now look at rotation in an arbitrary plane. So if I have a plane like this and I have some particle traveling in a circle like this, then it will see this rotation with these directions. So we can define d theta dt to be the component of the angular velocity omega z. dt. So when a particle's undergoing circular motion, it has a velocity that you can describe, which is the tangential motion around the circle. And it also has an angular velocity, which we define as being in a direction that's perpendicular to that direction of rotation. And so this is another way that we can write the velocity and connect it back to the angular velocity. And now that we have defined this omega z, the component of the angular Velocity, we can rewrite the velocity as just being equal to r times omega z still in that theta hat direction. as being in the counterclockwise direction. Whereas if I have another observer down here and they're looking up at this plane, they'll see the motion as being clock wise. And so you can see we have a need for a more formal definition for the rotation of this. So what we're going to do is use the right hand rule to define a direction that tells you both the direction it defines the plane and it also tells you what the positive direction of rotation is for that plane.

ROUGE-1: 48.41, ROUGE-2: 44.13, ROUGE-L: 27.97
BERTScore: 74.65

==============================================
==================== [79/100] ====================
Summary:
This week's lecture will focus on machine translation. In the second half of the week, we take a break from learning more and more on neural network topics. We'll talk about final projects, but also some practical tips for building neural network systems. This is an important content full lecture. We hope to see you in the next week or so for our final week of lectures. Back to Mail Online home. back to the page you came from.. Click here for the next lecture. When they were in the period of statistical NLP that we've seen in other places in the course. And then the idea began, can we start with just data about translation i.e. sentences and their translations, and learn a probabilistic model that can predict the translations of fresh sentences? So suppose we're translating French into English. We can say, what's the probability of different English translations? And then we'll choose the most likely translation. And we're not really expecting you to understand the details here. But I did then want to say a bit more about how decoding was done in a statistical machine translation system. So there's a fair availability from different sources. And we can use that to build models. So how do we do it though? All we have is these sentences. And it's not quite obvious how to build a probabilistic model out of those. So in this case, what we're going to do is introduce an extra variable, which is an alignment variable. And so if we could induce this alignment between the two sentences, then we can have probabilities of how likely a word or a short phrase is translated in a particular way. In the period from about 1997 to around 2013, statistical machine translation was a huge research field. In 2014, the first modern attempt to build a neural network from machine translations and encoded-decoder model. Within two years' time, Google had switched to using neural machine translation for most languages. There are still lots of difficulties which people continue to work on very actively. And you can see more about it in the Skynet Today article that's linked at the bottom. We'd like to translate languages for which we don't have much data. model end to end on parallel sentences. And it's the entire system rather than being lots of separate components as in an old fashioned machine translation system. So these neural network architectures are called sequence to sequence models or commonly abbreviated seq2seq. And they involve two neural networks. There's one neural network that is going to encode the source center. And we're going to feed it in directly as the initial hidden state for the decoder, or RNN. But we do the same kind of LSTM computations and generate a first word of the sentence. In neural machine translation we are directly calculating this conditional model probability of target language sentence given source language sentence. So we have a source sentence. And that's going to strongly determine what is a good translation. And so to achieve that, what we're going to do is have some way of transferring information about the source sentence from the encoder to trigger what the decoder should do. And the two standard ways of doing that are you either feed in a hidden state as the initial hidden state to the decoding, or sometimes you will feed something in. target languages the sentences, and get them to give judgment on how good a translation it is. But that's expensive to do, and might not even be possible if you don't have the right human beings around. So a lot of work was put into finding automatic methods of scoring translations that were good enough. The most famous method of doing that is what's called BLEU. And the way you do it is you have a human translation or several human translations of the source sentence, and you're comparing a machine generated translation to those pre-given human written translations. For assignment 4 this year, we've decided to do Cherokee English machine translation. Cherokee is an endangered Native American language that has about 2000 fluent speakers. It's an extremely low resource language. So it's just there isn't much written Cherokee data available period. And particularly, there's not a lot of parallel sentences between Cherokee and English. So we can see how far we can get. But we have to be modest in our expectations because it's hard to build a very good MT system with only a fairly limited amount of data. that can sometimes improve performance. And we actually have that trick in the assignment 4 system. And you can try it out. So we generate along and generate our whole sentence in this manner. And that's proven to be a very effective way of getting more information from the source sentence more flexibly to allow us to generate a good translation. I'll stop here for now and at the start of next time. I will finish this off by going through the actual equations for how attention works. In the early 1950s, there started to be work on machine translation. It was hyped as the solution to the Cold War obsession of keeping tabs on what the Russians were doing. Claims were made that the computer would replace most human translators. But despite the hype it ran into deep trouble. And so in retrospect, it's not very surprising that the early work did not work out very well. But it was also the beginning of people starting to understand the science of human languages, the field of linguistics. So that's what I'll talk about in the final part of the class.

ROUGE-1: 16.80, ROUGE-2: 16.05, ROUGE-L: 13.12
BERTScore: 62.98

==============================================
==================== [80/100] ====================
Summary:
into things like voids or loops and super structures that have end up having macroscopic effects on material properties. The amount of energy it would take to actually cause this material to fail is a measure of toughness. The strength of the material is how much stress you can put in until it starts to either plastically deform or it hits its UTS, ultimate tensile strength. And finally, stiffness is more of a response function, so it's how much does it deform in relation to how muchstress you put into it. build up, then what Jared said could happen. You could crack the material because it could get weaker, less ductile, less tough. Weaker is the opposite of strong, and what's the other one? Toughness-- oh, and harder, actually. So the origins avoid swelling I'll start with the humble vacancy. A void is nothing but a bunch of vacancies or a pocket of vacuum or gas in a material, and it all has to start with these single vacancies. As they cluster together, they reached this threshold in terms of free energy where putting a few of them together is not quite energetically favorable, but not so unfavorable that it never happens. Dislocation movement is irreversible. You can't just snap it back when you relieve the stress. By making something stronger and stiffer, you make it more difficult for those dislocations to start moving. And you can do that by throwing any defect in their way. Since radiation creates pretty much any and all defects, it's a great way to stiffen and strengthen the material. If something is stiffer and stronger, then the stress strain curve would be drawn more like that. Problems and no release of radioactive material. Pretty cool. What you want to happen is for dislocations to move on the easiest planes. If you don't push too hard, you can actually see these perfectly symmetrical slip planes at 45 degree angles to the axis of compression. And this is what you Want to happen to nuclear materials because you're really trying to balance this between slip and fracture towards the direction of slip. That means that something will deform a little bit before it just shatters like those channel boxes from the Russian reactor. Every kind of defect takes energy to create. You either have to raise the temperature of a material or in our case, irradiate it. The energy of those incoming neutrons that bounces around different atoms and creates all these different types of defects. So those defects are storing energy in the material. And so if you think about how much energy does it take to destroy something, it would have to be the energy that it's already stored plus the energy you put into it during the transmission electron microscope. the vessel too much, it's no longer a code stamp vessel. Pretty tricky spot that we're in, huh? But we're trying to science our way out of it. I don't want to keep you longer, but I'll open on Thursday with a little story about how mass attenuation coefficients can get you out of apartheid South Africa. I'm serious. And then we'll move into dose and biological effects. It's a couple minutes after. Well, it was just a few minutes. Michael Short: Radiation damage and nuclear materials are the biggest research field in 22.01. Short: The basic mechanism of radiation damage is like you might imagine. A DPA measures the number of times that each atom has moved out of its original site, but it has nothing to do with how many times it stays in its original place. The DPA part only measure is what we call the ballistic stage of radiationDamage, he says. The net effect on the crystal material is nothing, Short says.

ROUGE-1: 11.97, ROUGE-2: 11.33, ROUGE-L: 9.96
BERTScore: 61.96

==============================================
==================== [81/100] ====================
Summary:
reflect their communities. So if you consult the Vietnamese zodiac, you may discover that you're a cat, not a rabbit. If you're in Thailand, a mythical snake called a Naga replaces the dragon. So whether or not you place stock in what the zodiac says about you as an individual, it certainly reveals much about the culture it comes from. The zodiacs of Vietnam, Thailand and the U.S. can be found at www.zodiac.com. In Western astrology, it's a constellation determined by when your birthday falls in the calendar. But according to the Chinese zodiac, your shēngxiào is the animal assigned to your birth year. Of the many myths explaining these animal signs and their arrangement, the most enduring one is that of the Great Race. The first twelve animals to make it across the river would earn a spot on the zodiac calendar in the order they arrived. Each year is associated with one of the animals in this order, with the cycle starting over every 60 years.

ROUGE-1: 39.44, ROUGE-2: 36.05, ROUGE-L: 22.74
BERTScore: 62.59

==============================================
==================== [82/100] ====================
Summary:
the atom-- the same hyperfine state-- but with two different momenta. Then it is a Raman process only in the external degree of freedom, in the motion away function. The only change is you change the momentum. We need our intermediate state, which is often an electronically excited state. We are detuned. And now we have one photon going up and one photonGoing down. Historically, people distinguish between the situation where the final state is lower or higher in energy. But as long as you use laser beams to stimulate it, you don't even care. In perturbation theory with the field one, the state a has now a probability, given by this term, that it has now an admixture. And now, if we have sort of-- we have dressed up our state a with admixing for the near-resonant field some probability of state k into it. And this stressed state now has sort of a stepping stone here. And from this stepping stone, it can now absorb the photon omega 2. So that's how we should think about it. If you have a single photon, you always transfer momentum to the atom. But if you have two photons, the two momenta can cancel. This is actually a powerful method to avoid Doppler broadening in spectroscopy. For two-photon absorption, if the two laser beams are counter-propagating, the total momentum transfer is zero. If we arrange for the two photons to be absorbed from opposite directions, we reach the situation where the Dooppler shift is really zero. of methods of practical importance for eliminating the first order Doppler shift. Since hydrogen is of methological importance, measurements of-- fundamental measurements of the Lamb shift, comparisons with QED calculations, measurement of the Rydberg constant-- these are all done by hydrogen spectroscopy. But you cannot, of course, suppress the process where you absorb two photons from the left or from the right. And therefore, you have sort of a broad pedestal. So the pedestal is where you take one photon-- both photons from same side, whereas the Dooppler free peak is whereyou have photons from counter-propagating directions. Coherence exists if there is a well-defined phase between two or more amplitudes. We can only observe it if else than the time integral over the energy difference between two levels. So therefore, when we are talking about coherence, how can we maintain longer coherence between energy levels? How can we create coherence in three level systems? This is actually intricately related to the fact that we can obtain more precise information about the energy levels. This is a very general introduction to coherence. The first form of coherence I want to discuss is the coherence involved in exciting atoms. of spontaneous emission. The system involves with the following operator, and this is the operator which completely describes the interaction of an atom with the electromagnetic field. The fact that we have a unitary evolution with this operator is 100% or 110% true. But this operator will actually lead to final states of the photon field, which may not have a specific phase. And this is actually what I want to work out with you in-- maybe even today, I think ten minutes may be enough-- what is really the information-- the phase information-- which we have in a photon, which has been spontaneously emitted. one is we know for sure the atom is in the ground state. However, the excited state with zero photon will actually do Rabi oscillation. And it has just swapped excited zero to ground state one photon. So what I suggest is when we, really at the fundamental level now, discuss spontaneous emission, we allow this part-- excited atom, empty cavity-- to undergo half a vacuum Rabiscillation. I just allow half a cycle to evolve. And the result of that is, well, nothing happened to this part. this is what we want to discuss on Wednesday. And this is what I referred to as the fundamental limit of spontaneous emission because we have not lost any coherence here. It's just if the phase is only imprinted in one particle-- one particle quantum physics sets us a limitation. Oh well, we can read out the phase phi. OK. Any question? To be continued on Monday. Back to Mail Online home. back to the page you came from. Click here to read the full interview. Professor: In almost all cases when you address atoms, you do two photon courses because a photon is scattered. In reality, it is a two photon process and not two single photon processes, he says. Professor: If you have any doubts about some subtleties about how is light absorbed and emitted, the correct answer is always obtained from the two-photon picture. He then asks the audience to guess how many terms you would expect when you do the most basic light atom interaction.

ROUGE-1: 15.29, ROUGE-2: 14.45, ROUGE-L: 12.53
BERTScore: 60.48

==============================================
==================== [83/100] ====================
Summary:
fine tune them for your own problem. This is one way that you can attack a lot of problems in deep learning, even if you don't have a huge dataset of your own. So that's kind of the brief introduction to like sort of GPU CPU hardware in practice when it comes to deep learning. And then I wanted to switch gears a little bit and talk about the software side of things. The various deep learning frameworks that people are using in practice. But I guess before I move on, is there any sort of questions about CPU GPU? Yeah, question? debate. So if you guys have AMD cards, you might be in a little bit more trouble if you want to use those for deep learning. And really, NVIDIA's been pushing a lot for deeplearning in the last several years. It's been kind of a large focus of some of their strategy. And they put in a lot effort into engineering sort of good solutions to make their hardware better suited forDeep learning. So in practice, you tend not to end up writing your own CUDA code for deepLearning. most people in deep learning when we talk about GPUs, we're pretty much exclusively talking about NVIDIA GPUs. So to give you an idea of like what is the difference between a CPU and a GPU, I've kind of made a little spread sheet here. And there's a couple general trends to notice here. Both GPUs and CPUs are kind of a general purpose computing machine where they can execute programs and do sort of arbitrary instructions. But they're qualitatively pretty different. For GPUs we see that these sort of common top end consumer GPUs have thousands of cores. TensorFlow is a pretty safe bet for just about any project that you want to start new, right? Because it is sort of one framework to rule them all. However, you probably need to use it with a wrapper and if you want dynamic graphs, you're maybe out of luck. Some code ends up uglier but in my opinion, maybe that's kind of a cosmetic detail. If you're just writing research code, I think PyTorch is a great choice. But it's a bit newer, has less support out there, so it could be a bit of an adventure. Numpy is definitely CPU only. And you're never going to be able to experience or take advantage of these GPU accelerated speedups if you're stuck working in Numpy. So, kind of the goal of most deep learning frameworks these days is to let you write code in the forward pass that looks very similar to Numpy, but lets you run it on the GPU and lets you automatically compute gradients. TensorFlow has this magic line that just computes all the gradients for you. So now you don't have to go in and write your own backward pass yourself. PyTorch provides pretrained models. And this is probably the slickest pretrained model experience I've ever seen. You just say torchvision.models.alexnet pretained=true. That'll go down in the background, download the pretrained weights for you if you don't already have them, and then it's right there, you're good to go. PyTorch also has, there's also a package called Visdom that lets you visualize some of these loss statistics somewhat similar to Tensorboard. different where we're actually building up this new computational graph, this new fresh thing on every forward pass. That's called a dynamic computational graph. For kind of simple cases, with kind of feed forward neural networks, it doesn't really make a huge difference, the code ends up kind of similarly. But I do want to talk a bit about some of the implications of static versus dynamic. And what are the tradeoffs of those two? So one kind of nice idea with static graphs is that because we're kind of building up one computational graph once, and then reusing it many times, the framework might have the opportunity to go in and do optimizations on that graph. Caffe.is this framework from Berkeley. Which Caffe is somewhat different from the other deep learning frameworks where you in many cases you can actually train networks without writing any code yourself. You need to define, now instead of writing code to define the structure of your computational graph, instead you edit some text file called a prototxt. Here the structure is that we read from some input HDF5 file, we perform some super new, it was only released a week ago. [laughter] So I really haven't had the time to form a super educated opinion about Caffe 2 yet. is really great for research. If you're interested in production deployment, you should probably look at Caffe, Caffe 2 or TensorFlow. PyTorch is a great choice. But it's a bit newer, has less community support, less code out there, so it could be a bit of an adventure. So it's kind of unfortunately, there's not just like one global best framework, it kind of depends on what you're actually trying to do, what applications you anticipate. - Hello? Okay, it's after 12, so I want to get started. So today, lecture eight, we're going to talk about deep learning software. This is a super exciting topic because it changes a lot every year. But also means it's a lot of work to give this lecture. But as usual, a couple administrative notes before we dive into the material. So as a reminder the project proposals for your course projects were due on Tuesday. We're also in the process of grading assignment one, so stay tuned.

ROUGE-1: 11.78, ROUGE-2: 11.33, ROUGE-L: 9.34
BERTScore: 58.81

==============================================
==================== [84/100] ====================
Summary:
This is part 3 in our series on distributed word representations. We're going to be talking about vector comparison methods. To try to make this discussion pretty intuitive, I'm going to ground things in this running example. On the left, I have a very small vector space model. We have three words, A, B, and C. And you can imagine that we've measured two dimensions, dx and dy. And then you can see graphically that B and C are pretty close together. And A is kind of lonely down here in the middle. B and C as against the infrequent one A. As a stepping stone toward cosine distance, which will behave quite differently, let's talk about length normalization. Given the vector u of dimension n, the L2 length of u is the sum of the squared values in that matrix. And then we take the square root. That's our normalization quantity there. And A and B are now close together. Whereas B and C are comparatively far apart. And that has come entirely from the normalization step. their generalizations to the real valued vectors that we're talking about. And the other class of methods that you might see come up are probabilistic methods which tend to be grounded in this notion of KL divergence. Now I've alluded to the fact that the cosine distance measure that I gave you before is not quite what's called the proper distance metric. To qualify as a proper distance metrics, a vector different choices that we could make, of all the options for vector comparison, suppose we decided to favor the ones that counted as true distance metrics. the results for "bad" using cosine distance in cell 12 and Jaccarddistance in cell 13. And I would just like to say that these neighbors don't look especially intuitive to me. It does not look like this analysis is revealing really interesting semantic information. But don't worry, we're going to correct this. We're going. to start to massage and stretch and bend our vector space models. And we will see much better results for these neighbor functions and everything else as we go through that material. corner, the infrequent one. Let's start with Euclidean distance, very common notion of distance in these spaces and quite intuitive. We can measure the distance between vectors u and v if they share the same dimension n. There are a few other methods that we could think about or classes of methods. The first class are what I called matching based methods. They're all kind of based on this matching coefficient. And then Jaccard, Dice, and Overlap are terms that you might see in the literature.

ROUGE-1: 36.00, ROUGE-2: 35.01, ROUGE-L: 29.10
BERTScore: 70.95

==============================================
==================== [85/100] ====================
Summary:
the field but somebody that is passionate about their religion and their faith you know the nature and the common man the shepherd person of the flock or even a child in a sense of children so it's a very short one and it's one that I believe is pretty easy to to comprehend and understand okay. "I believe it is one of the easiest to understand and understand," he says. "It's one of those things that is very, very easy to understand. It's very simple to understand" liyan blake a little bit about him he's kind of out there some of his contemporaries thought he was insane you know nowadays maybe he would be heavily medicated. People think that he's out there and there was that who was William Wordsworth who said that there is something in the madness of this man which interests me more than the sanity of Lord Byron and Walter Scott. He was an individual who you know was into art and was into eventually you know religion and such became a big part of his life but his as an artist he was also big-time into painting.

ROUGE-1: 25.74, ROUGE-2: 22.68, ROUGE-L: 14.48
BERTScore: 64.71

==============================================
==================== [86/100] ====================
Summary:
Cú Chulainn, hero of Ulster, stood at the ford at Cooley, ready to face an entire army singlehandedly. The army in question belonged to Queen Meadhbh of Connaught. Enraged at her husband’s possession of a white bull of awesome strength, she had set out to capture the fabled brown bull of Ulster at any cost. But the King of Ulster had chosen this moment to force the goddess Macha to race her chariot while pregnant. In retaliation, she struck down him and his entire army with stomach cramps. broken heart, leaving behind a land that would remain ravaged by Meadhbh’s war for years to come. “I will never forget you,” he wrote to his son. ‘I will always love you.’ “You are my son,’ he replied, “and I will always be your son.” “And I will never leave you, my son. I will forever love you’, he said, ‘even though I’m no longer your son’. Cú Chulainn and Ferdiad met in Scotland while training with the renowned warrior Scáthach. When they returned to their respective homes, they found themselves on opposite sides of a war. The Queen was impatient to get her hands on the prize bull. She goaded him and questioned his honor until he had no choice but to fight. But their teacher had shared a secret with him alone. She told him how to summon the Gáe Bulg, a magical broken heart, leaving behind a land that would remain ravaged for years to come.

ROUGE-1: 46.26, ROUGE-2: 38.64, ROUGE-L: 41.04
BERTScore: 71.42

==============================================
==================== [87/100] ====================
Summary:
down again— all for trying to cheat death. As you can see, Achilles, the Underworld is full of exciting amenities. Here, you don't have to worry about brutal wars or painful cycles of revenge. You can finally just put your feet up and relax. It's a great place to take a break from your daily life. It also has a great view of the city of Athens, which is one of the most beautiful cities in the world. It is also a great spot to take some time off from your regular life and recharge your batteries. The Underworld is actually a lovely place to "live" It boasts historic charm and eccentric neighbors with eternal ties to the area. Tartarus is reserved for a select few who some might call the greatest sinners of all time. Elysium is the Underworld’s exclusive VIP section— and your permanent home. The Underworld also features four other waterways: Acheron, the river of woe; Cocytus, river. of wailing; Lethe, river of oblivion; and Phlegethon, a. great source of natural light.

ROUGE-1: 36.49, ROUGE-2: 29.45, ROUGE-L: 16.82
BERTScore: 64.75

==============================================
==================== [88/100] ====================
Summary:
Fluorescence is the absorption of light energy by a molecule. Luminescence is the emission of light in the absence of heat. There are different types of luminescence. And you'll get to see some of those varieties of luminecence in the next couple of slides. And it's not the last time that you're going to see them, so let's take a look at fluorescent dyes at the end of the electromagnetic spectrum in thenext couple of slide. The next few slides will show you how fluorescent proteins come from. molecules. Now, ethidium bromide is a dye that can get into cells. And we can look at DNA within cells. Here's a picture of how it would look. And you can see over here, the structure of DNA. So you could picture ethidium Bromide sliding between the bases. But there's a big problem here. Because you can't use DNA ethidiumbromide. It's pretty toxic. But you can substitute DAPI and HOECHST, which are way less toxic. The adaptive immune system is an amazing system where you can do combinatorial biology and basically recognize any target entity you're interested in. So we're going to focus exclusively on the B cells and the way that they mature to produce soluble antibodies. When you get a population of B cells that produce antibodies to a particular target, these may be what are known as polyclonal-- sorry, I should have written that up here-- A polyclona antibody, as might be suggested by the name, is an antibody that recognizes a molecular entity. is you have a bunch of different B cells. And there's something you want to recognize. What you might do is challenge this population with the cytokine. And then you will end up with B cells that produce a lot of an antibody to a cytokine such as EGF. Now what's so special about antibodies? They're pretty big molecules. The molecular weight is pretty high. But the key thing about antibodies is that the majority of the structure stays fairly constant. When B cells mature, there's loads of rearranging in that variable section. The way you make antibodies is by injecting. the foreign agent or antigen that you want to make an antibody to. The organisms are adapted not to recognize their own proteins unless there's some disorder like an autoimmune disease. So you would inject the rabbit with a human epitope, so for example human actin, generate antibodies with a specificity for actin. Alternatively, you might want to made a different antibody for tubulin. You've really got two types of macromolecule that can be interacted with a fixed cell. DNA microarrays exploit the complementarity of DNA sequences. They can be used for profiling genetic material or for profiling not just DNA, but RNA. Fluorescence is a magnificent tool. We can use fluorophores as attached to antibodies. And the DNA microarray experiments show you how you can usefluorophores attached to DNA sequences, OK. And I'll see you in the next class. Technology. Technology is known as a DNA micro array has anybody heard of these? Yeah. DNA microarray experiments and how you can use it to profile disease states and cells versus healthy cells. And then at the beginning of the next class, I'll describe how you get information out of DNA microarrays. But at the end of the day, you're always using the fluorophores as the probes for where certain things are, OK. Fluorescence is a magnificent tool. We can use fluorophore on their own, or we can use them as attached to antibodies. Lambda Lambda: Fluorescence is a type of luminescence. He says it's used to illuminate life, to understand details of cellular activity. Lambda says fluorescence can also be used as reagents in diagnostics in all kinds of imaging modalities. He gives three lectures on fluorescence, including one that has even more imaging in it. Llamda: I like fluorescence so much because the images are so captivating. I'm going to redefine all these terms properly in a moment.

ROUGE-1: 17.97, ROUGE-2: 16.22, ROUGE-L: 13.50
BERTScore: 61.34

==============================================
==================== [89/100] ====================
Summary:
 RAFAEL JARAMILLO: Today we're going to discuss the many D's of thermodynamics. The D's indicate exact differentials, which is equal to infinitesimal changes in state variables. In materials thermodynamics, the most common transformations that we talk about are transformations that take place at constant pressure and constant temperature. So of the three D's-- lowercase d, lowercase Greek d, and uppercase Greek D-- this is the first one. In thermodynamics, we have many different transformation quantities that we keep track of. In material science, our most common independent variables are pressure and temperature. But for any transformation quantity, you can at least imagine, if not draw out on a piece of paper, state function surfaces corresponding to the quantity that you're trying to measure, independent variables corresponding to. the variables you're regulating, and a vertical distance, which is the vertical distance between these two surfaces. So this is illustration for an isobaric, isothermal transformation, and we're illustrating this for entropy. is a function of those independent variables that measures the transformation quantity for the transformation between two different phases. For example, in the case of water, the quantity of water in the solution is the ratio of the water volume to the volume of the solution. For the example, the total water volume is the sum of the volumes of the solutions of the two phases. The total water content is the product of the proportions of the different water volumes. For more information, see the Wikipedia article on water. Greek D is often the hardest for students to understand when you first encounter it. So we're going to take some time to draw out what is meant by transformations and transformation quantities. To illustrate the concept of transformation quantities, it helps to draw state function surfaces. Here is-- for some hypothetical phase. is a function of those independent variables that measures the transformation quantity. for the transformation between two different phases. So, for example, we could have the entropy of phase alpha drawn as a. function of temperature and pressure.

ROUGE-1: 49.85, ROUGE-2: 42.09, ROUGE-L: 24.69
BERTScore: 70.15

==============================================
==================== [90/100] ====================
Summary:
In this video I'm going to be going over lung oscilation specifically the sites of where you osculate. We're going to go over normal breath sounds versus abnormal breath sounds. You can access the quiz and the notes over here or in the description below. In the next video I'll be performing an assessment on a patient and show you how to listen with your stethoscope to these sides. I'll also be going through the anatomy of the anterior part of the chest. chest in this illustration you have your right lung and your left lung and how I set up this illustration is that I wanted you to be able to see what is over the lungs. Whenever you're listening with your stethoscope you need to know where your clavicle is and certain intercoastal spaces because they correlate to which lobe of the lung you are listening to. We're going to start from top to bottom and compare sides and work our way down and we'll start right above the scapula right where the Apex is. and discontinuous now first let's go over continuous what does continuous mean this is a extra sound that you're hearing that is lasting more than 2 seconds with a full respiration. The first type is called a high pitch polyphonic whe let the name help you okay so what is it it is mainly heard in expiration so when the patient's breathing out but it can be in Inspiration as well. The third type of continuous adventitious breath sound is called stri spider and this is heard on inspiration because what's happening is that the airway is being obstructed. patient's breathing in and breathing out so that's why you're hearing it on inspiration and expiration now it can sound similar to a parac cardial friction rub how do you tell the difference um if you are wanting to know is this the lungs or is this this the heart just listen have the patient hold their breath. If you can still hear that harsh grading sound it's the heart because they're holding their breath their lungs aren't moving so you've rolled out the lungs. That is lung occultation and normal breast sounds versus abnormal breast sounds. patient's back if you were to look inside look at the lungs you'll have the clavicle on the front then it comes around and it forms into your scapula. From C7 to T3 your cervical and thoracic spine that is where your upper loes are. What you want to do is just go in between where the shoulder blades and the spine are and just work your way down so we're going to listen to our upper Li. We'll go here and then sound and this is what Strider sounds like.

ROUGE-1: 25.72, ROUGE-2: 24.36, ROUGE-L: 20.85
BERTScore: 72.49

==============================================
==================== [91/100] ====================
Summary:
Sparta was the first state to be in command, or in control, or to be the leaders of a coalition of states. The Spartans gained a reputation of being--because they often fight against tyrants--they gain a reputation for being hostile to tyranny. The Spartan alliance most of the time was not clear how it came to exist, but perhaps the place to start is around 570C. The Peloponnesus suffered a defeat in the region of Arcadia to the north of Laconia in the seventh century. The average Spartan did not ever speak in the assembly, it appears. So it's not a democratic assembly, even though every single citizen is there, if he wants to be. Let me turn now to the ephors. These, according to Spartan tradition, were invented somewhat late in the development of the Spartan constitution. Although we don't have a clear picture of the way in which they were chosen, it is clear that there's a strong element of chance involved in selecting who was going to be an ephor. Athens is located in the southeastern portion of the Greek peninsula. The city is Athens; the region in which they live is Attica. The people are Athenians and that's an important point I think I made too. Everybody who is a citizen who lives in Attica is an Athenian, no matter if he lives sixty five or seventy miles away from the city. He's still an Athensian. So the rich-born, because they are pretty much the same in the early days of the polis, run the state in this official way. early seventh century, the date he gives us, of course we shouldn't put too much credence in it, it's too precise, but it's 683 B.C. On that occasion, we are introduced to a new thing, magistrates are chosen from the aristocracy to do various jobs in the city. In Athens, the magistrates were called archons. It means, in the most technical sense, rulers but it means really important magistrates in the state. One of these was called the War archon, polemarch, presumably he led the army. Next came the archon who was actually the most important archon. that there are the kinds of discontents that we have been talking about which find the leader in the form of a man who is an outstanding figure for some reason, who is willing to try to establish a tyranny. That it fails, I think, is an indication that the same forces haven't reached the power in Athens that they had reached in Megara, Corinth, Sicyon, and places like that. It's a warning about troubles ahead and I'll turn to those troubles in the next hour. All adult male Spartans were participants in the assembly. When a question was put to the Spartans, the way they responded was by shouting and banging on their shields. When it involved something fundamental like war and peace or alliances, then they would have to go to the assembly to get their approval. The Spartans got into this war with Tegea and they gained control of it. They claimed to have discovered the bones of the great Homeric hero, Orestes, and taken it away from Tegean.

ROUGE-1: 10.73, ROUGE-2: 10.12, ROUGE-L: 8.00
BERTScore: 56.43

==============================================
==================== [92/100] ====================
Summary:
In 1951, the first nuclear reactor to produce electricity was the experimental breeder reactor, the EDR1. In 1953, President Eisenhower, he created something called atoms for peace. The first nuclear powered submarine, the USS Nautilus, was launched in 1954. The real heyday of nuclear was between 1960 to 1975, when there was a huge commercial energy boom. Today, China, India, and South Korea, they are the main players in this game. The main players are still, you would imagine, coal. About what I've mentioned? Awesome. So now we'll talk a little bit about reactor types. I'll just tell you guys about some of the main ones and how they work. How people like to divide up the reactor types is in generations. So boiling water reactors, or BWRs, comprise about 21% of the reactors that are located and working in the United States. PWRs are actually more important, if you will, than B WRs. But they are functionally essentially the same, and it's just slightly more complicated. Heavy water has a much lower absorption cross-section than light water does. This means that when neutrons are flying around in the reactor there is a chance of it hitting a fission product and undergoing fission. But there's also a chance that the water that surrounds it will absorb that neutron. So if that neutron gets pulled out of the system you're not able to create any more fissions. This is actually kind of a bad thing because the whole point of nuclear reactors is to create heat and fission, so we don't want it. These accidents. like you probably know that they exist, but like what happened during them? So if you do know, sorry, but if you don't know, you're about to know. So Three Mile Island, which is the first one, it happened in 1979 on March 28. So the core melted down, the reactor wasn't able to operate anymore. The next reactor accident that we were alive for, which was cool, was Fukushima Daiichi. So these reactors, I think these are pressurized water reactors. The main way of disposing of the spent fuel is putting it into spent fuel pools. This is an OK solution, except for the fact that we just have way too much spent fuel to be able to do this. Dry cask storage is a way to keep this spent fuel surrounded by an inert gas. repurposing is one other way of dealing with nuclear waste, which I think is the coolest option out of the bunch. is CNN Tech's weekly, offbeat look at what's happening in the world of nuclear power. NRC.gov with less grains of salt than usual. Or if one of these things really piqued your interest, you guys can take 22.04, which is really cool class that's offered here I think this spring, and if not next spring. But basically it's called nuclear power society. It's taught by a guy named Scott Kemp. He talks about all these things and in a lot of detail and slower. So yeah, cool. So thank you guys so much for coming. I know you guys could have slept an extra hour. Ka-Yen: "I walked into MIT not knowing a single thing about nuclear energy" "Nuclear creates 75 times less carbon emission than coal does, and 35 times less than natural gas" "You get 3.5 million times more energy than burning one kilogram of coal" "It can serve as a good baseload source of energy." "It might be better for the environment, but it's not really able to replace all coal and all the other forms of energy"

ROUGE-1: 12.47, ROUGE-2: 11.59, ROUGE-L: 10.51
BERTScore: 55.10

==============================================
==================== [93/100] ====================
Summary:
Professor Steven Smith: I want to talk today about Aristotle's discovery of America. He says Aristotle's mixed constitution differs from ours still in certain important respects. Smith: For Aristotle, it is not the liberty of the individual so much as the functioning or functional well-being of the city that is the highest priority. In these parts of the Politics, Aristotle is very sketchy here about the structure, institutional structure, the make-up of the best regime, acknowledging the best men where the best rule. In Book II, Aristotle criticizes at considerable length Plato's Republic for the excessive unity it demands of its citizens. He clearly understands, in many ways, the virtues of private property and of commerce. Yet, despite his awareness of the importance of commerce and of property, the aim of the city, he tells us, is not the production of wealth. If wealth were the purpose of politics, Aristotle writes, the Phoenicians, you might say, in the ancient world, would have been the commercial leaders. Aristotle's best regime differs from Plato's intransigent demand for the rule of philosopher-kings. The megalopsychos, the gentleman, whatever else he is, is not a philosopher in the strict sense. He is a person of some inherited wealth, chiefly landed property, but whose way of life will be urban. The gentleman may lack the speculative intelligence of a Socrates, but he will possess that quality of practical rationality, of practical judgment necessary for the administration of affairs. the back door. On Friday, let me just remind you, Il Principe. We'll study Machiavelli. On this very partisan note I conclude. On Thursday, we'll study the life of the Italian statesman and play a game of chess with him. We're going to see how well he can play the game of poker. I'm looking forward to it. I hope you'll join us for the game on Friday night at 8 p.m. ET on CNN. Aristotle's proposal for a mixture of oligarchy and democracy seems, in many ways, to anticipate, 2,000 years before the fact, Madison's call for a government where powers must be separated. Aristotle could never endorse the view stated by a famous American president that the business of America is business. He would to war, but in fact to peace. The citizen of the best regime must be able to sustain war if duty requires, but only for the sake of peace and leisure.

ROUGE-1: 13.52, ROUGE-2: 11.53, ROUGE-L: 9.94
BERTScore: 59.28

==============================================
==================== [94/100] ====================
Summary:
SNLI and MultiNLI into Turkish. XNLI is a bunch of assessment data sets that is dev-test splits for more than a dozen languages. Those are human-created translations that could be used to benchmark multilingual NLI systems. So there's a wide world of tasks you can explore, and I think that makes NLI a really exciting space in which to develop original systems, and projects, and so forth. And those could be interesting for seeing how well a model can grapple with variation that comes in very specific and technical domains. SNLI is the Stanford Natural Language Inference Corpus-- MultiNLI, and Adversarial NLI. The premises are all image captions from the image Flickr30K data set. All the hypotheses were written by crowdworkers. The overall Fleiss kappa measured interannotator agreement was 0.7, which is a high rate of agreement. It's clear at this point, for example, that ensembles of deep learning methods are the best for this problem, says Christopher Potts.

ROUGE-1: 11.77, ROUGE-2: 10.99, ROUGE-L: 5.89
BERTScore: 61.87

==============================================
==================== [95/100] ====================
Summary:
In a perfectly competitive market, the firm is a price-taker. No matter how many units they produce, they're just going to be able to get that same market price. A firm in an imperfectly competitive market will have their own firm-specific demand curve. The price that they get in the market is higher than the marginal cost and the marginal revenue at that point. Folks are willing to pay more than that marginal cost, but you still have no motivation to produce more.

ROUGE-1: 21.16, ROUGE-2: 19.73, ROUGE-L: 21.16
BERTScore: 65.43

==============================================
==================== [96/100] ====================
Summary:
can think about this in the absence of a motion. If the motion exists, surely you can take this derivative and evaluate it. But if there's a way to get started moving, that doesn't actually mean you could actually move. I'm just defining an infinitesimal motion to be a velocity vector for every vertices, such that this property holds. This is a dot product between two vectors. If you have two vectors, a and b, you take their their direction or derivative of v. right part has no real intuitive meaning, but it involves this thing-- some velocity vector for w-- and the velocity vectors for v. It's actually a very intuitive relation. Basically, we want to understand how this length changes to the first order. So this is a dot product in d of w-- that vector-- dot product with C of v minus C of w. It turns out dot product corresponds to projection. I'm projecting onto this one. That's how you'd write it algebraically. And same deal over here. can be done in polynomial time. So this is good news. intuitively what it corresponds to is the number of useful edges. And this thing is theNumber of degrees of freedom. So it turns out these will always be equal to d times n in summation. And what we care about, infinitesimal rigidity, means that-- or let's say it's infiniteimally rigid if and only if the nullity of the matrix is the space of rigid motions, which I have to look up. In general, in d dimensions, it's this-- d plus 1 choose 2. and rigidity, and the relation to the generic case. So there as we have before, this definition is not quite the same, but it's effectively the same as the last one. Almost every configuration is generic. So if you want to tell whether a 3D graph is generically rigid, you take a random realization in 3D. You compute the rank of this matrix generalized to the 3D case. You see is it 3 n minus 6, and that will tell you whether that generic realization is infinitesimally rigid. This one is rigid. The only way to move the square-- or in fact, any generic convex configuration-- is one of these pairs has to get shorter. So we lose generic rigidity. But infinitesimal rigidity still works, and generic configurations are still meaningful. It's just that they're not all the same. There's not, in this case, for four vertices, there's two kinds of generic configurations. So this is the same graph, and the same labeling of which edges are bars and which are struts. Theory goes back to Roth and Whiteley, 1981-- good year. If you can find a stress that is nonzero on every particular strut or cable, then all of those things are effectively bars. Every infinitesimal motion holds the length of that edge fixed. This will actually always be true-- the corresponding linkage is rigid-- because I put in every edge is in there. If I turn them all into bars, this thing's not moving at all. Strut can have zero stress-- the weight is zero. A spiderweb is something where every edge is basically a cable. All of the edges can have a positive stress, and it will be in equilibrium. In spiderwebs, in fact, this is the same-- these two-- rigidity and positive stresses are the same thing. This is a brand-new result from this summer at [? OSMI ?] by Robert Lang and Alex Bateman. Here is an example of that-- a spiderweb, so to speak, but drawn visually. And you turn it into a crease pattern, fold it flat and it works. Theorem: All pairwise distances between vertices increase or stay the same. Key to proving it is by making the theorem stronger. Tensegrities will force things to be expansive. So if initially you're non-crossing, you will be non-Crossing forever. That really makes life easier, because crossings are hard to think about. This lets you not worry about crossings. How do I worry about distances increasing? Tensegrity. You compute an equilibrium stress, which is easy to do by linear programming, and draw-- you can directly construct from that the 3D lifting. still buy them at the hardware store. That's it. You can't buy them online. You have to buy them from the store. They are not available online. They can be bought at the store, but you have to pay for them in cash. They're not available on the internet. You must buy them in the store to get them. You cannot buy them on the Internet. They must be bought from the hardware stores. That is it. They have to be bought in the stores. "Between the Folds" is on PBS at 8 p.m. ET Tuesday. Professor: Today we're going to talk about infinitesimal rigidity. He says it's a variation of generic rigidity, but in a different way. "Infinimal motion" is a first derivative of a motion, he says, and it's useful to realize that it's real, honest to goodness, smaller than anything else. The professor says the idea is useful to us, because it's determined by taking a motion and taking its derivative to show it's rigid.

ROUGE-1: 14.57, ROUGE-2: 13.28, ROUGE-L: 12.12
BERTScore: 61.76

==============================================
==================== [97/100] ====================
Summary:
Deep Blue’s triumph over Garry Kasparov in 1997 was the first time a machine had defeated a sitting champion. Today, chess software is capable of consistently defeating the best human players. But just like the game they’ve mastered, these machines are products of human ingenuity. And perhaps that same ingenuity will guide us out of this apparent checkmate, as it did in the case of chess greats such as Benoît Mitterrand and Toulouse-Laffitte. Chess has been known as a tool of military strategy, a metaphor for human affairs, and a benchmark of genius. The game was originally known as chaturanga– a Sanskrit word for "four divisions" With its spread to Sassanid Persia, it acquired its current name and terminology– "chess," derived from "shah," meaning king. Chess-playing computers had been developed for decades, but Deep Blue’s triumph over Garry Kasparov in 1997 was the first time a machine had defeated a sitting champion.

ROUGE-1: 33.97, ROUGE-2: 28.78, ROUGE-L: 21.29
BERTScore: 59.84

==============================================
==================== [98/100] ====================
Summary:
age right over here we have a neural network that whose goal is to sort of predict something about a car. As you go deeper down the network is trying to become more and more abstract. depth refines representations you start with course information like edges and you go all the way down to like find information like this mental model of a car so I know that this was a good exercise for me. I guess the thing I wants you I want you to take away from this is that depthRefines representations. simple computer vision task like a cat versus dog classification or some sort of object detection and again no worries if a convolution is sort of familiar we'll cover convolutions and CNN's in much greater depth very soon. So for example um each of these models should be able to for example capture how low-level features as Arya mentioned such as the general shape the edges the patterns and the colors in the lower layer so the more earlier layers of our neural network. Then once we've moved on and we've gone towards the later layers they should be can to capture some higher level features like the abstractions of the cats versus the dogs people's faces or some of the major objects. So in other words like how do we actually transfer or do transfer learning um does anyone have any ideas perhaps of how we might want to keep certain information from a previous pre-trained model and transfer that knowledge yeah that's basically the right idea what about you you're just copy the weights Maybe yeah so very similar um one of the more common ideas is that well basically our neural networks are just stacks of layers so the idea is can we keep certain layers and basically use that on our next model so there's an idea called freezing. and that will have a homework so if you ever need to review uh the topics from this lecture so to work on that homework this slide deck should be up on the website again if you feel free to do that. That is it for today a second pause. Back to the page you came from. The slide deck for this lecture is now available on our website again. Click through the slide deck to see the rest of the lecture. The lecture will be available again on the site later this week. Aryan: I'm gonna go somewhat into detail into what representation learning is and I think this should sort of cap out the last few weeks of deep learning. Aryan: The quiz for this week will probably go live tomorrow but I'm not quite sure yet but you'll try to get it up as soon as possible so I guess like without further Ado let's Jump Right In. I'm Aryan, one of the facilitators for this decal and I'm going to be presenting today's lecture on pre-training with Verona today.

ROUGE-1: 10.83, ROUGE-2: 10.00, ROUGE-L: 8.76
BERTScore: 59.19

==============================================
==================== [99/100] ====================
Summary:
GPT relies on a lot of tricks and Engineering insights and breakthroughs that we're not going to cover. We apply this self-supervised learning where we learn without label data so we can get as much data as we want because there's no human being in the loop. What we get from this you know by learning from observation and learning from the data directly is a very contextual and relational understanding of meaning. We'll talk about something that's extremely engineering heavy in you know chat GPT. then reduce all other ones so you know the next time it sees uh the same example or a similar example it actually does better and you know this is just one single example but you accumulate all of these directions and information across a batch of examples that you see at the same time. So it takes small small steps to getting a a better and better distribution and a more itic distribution of what word will come next given previous words and you do this in a batch on tons of examples and of course you know we have unlimited amount of data. Transformer part is extremely extremely important so there's a debate a little bit what was the most influential part of making uh CHP and large language model possible uh Transformer is definitely a significant part of it and and I'll let you judge for yourself but uh I think it's less important than the actual modeling perspective that we've we've come up with. In order to understand the Transformer we're going to start to thinking about how we can process sequences so text is just sequence of words. is that for every step here that's label with the same uh digit you know they can all be done in parallel. This is key because in in deep learning we use this uh um computer is called gpus. If we can make multiple steps into single step in parallel this is a single cost. We want to run things in parallel as much as possible so here basically you know this be a cost of four because all these different numbers can be run in parallel uh so this would just be acost of four and then of course processing this whole sequence will be a costs of nine. possible to be as useful as possible okay so uh these are the the the three different things we want to address right what's good and bad dialogue. We want to be more robust and learn to solve correct and this is where we're going to do reinforcement learning from Human feedback. Open AI does on chtp and this was very very hyped for a long time but now people talk less about it uh okay so what do we do well we have a great model that's been fine tune on dialogue and it's able to generate really good answers. the World by looking at videos right you can even sort to understand how human beings work even better because you can see people being upset or sad or happy whatever right in in a video and start picking these cues up. You can connect the vision part to the text part and get a multimodality model that's able to do both in a really really sophisticated way uh also something that I think these these people are working on all right thank you thank you for your time and good luck with your book. The third lecture on Foundation mulative AI will cover chat GPT. Chat GPT was the the tool or the the AI that really made people understand this is different now. Next time we'll talk about stable diffusion image generation. Then we'll cover emerging Foundation models basically Foundation models generative AI in the commercial space. And then we'll end with the lecture on AI ethics and regulation as well as a panel okay so what have we talked about before we started off H with an introduction a short high level intuitive answer to what is foundation MGenerative AI.

ROUGE-1: 10.94, ROUGE-2: 10.43, ROUGE-L: 9.22
BERTScore: 62.88

==============================================
==================== [100/100] ====================
Summary:
A set is convex if for any a and b element of omega, the line between them is in omega, OK? So what does that mean? So let's draw the picture first, and we'll draw the math. Here's the convex set. So it means no matter how I pick a-- here's a-- and no matterhow I pick b, the straight line between. them, the geodesic between them, is in a set. OK? Now, we're going to apply this to functions. If f is twice differentiable and, for all x, f double prime of x is greater than 0, then f is convex, OK? So this says these functions really are bowl-shaped, right? Second derivative being positive means that they have this kind of positive curvature that looks like the U's. Their first dimension-- first derivative goes up and down, but they're kind of always trending. That first derivative is always getting more positive,right? It's negative on the left-hand side, positive on the right-handside. convex function here because we're maximizing likelihood. And this is just notational pain, right? Like, if we were-- maybe we should have minimized unlikelihood. So we need concave functions. And what are concave function? g is concave if and only f minus g is convex. So if I take a chord of this function-- that's a chord-- it's below. Which is what I should hope. If I flipped it upside down, the chord would be above. Cool. Jensen: The problem of optimizing over all those z's seems daunting, directly optimizing the l's. Instead, I'm going to come up with a local curve, OK, and I'll call this curve Lt of theta. It's another function. We're going to try and get that kind of easy-to-optimize function. And then, [MOUTH POP] we then do it again and create another curve. The whole algorithm is going to be Jensen's, and that's the whole algorithm. be theta t plus 1, OK? And we're going to, again, create some new curve, Lt plus 1 of theta, based on that point. And the key aspects of the point that I'll write in a second is this point is a lower bound. This curve is always below the loss, so it's kind of a surrogate that I'm not overestimating my progress, and it's tight. It meets at exactly that point, so I wouldn't think and get fooled that there was a higher loss function somewhere else. Jensen: Q is a probability distribution over the states such that the sum over Q(z) equals 1. Jensen: Q can also be written as an expected value, where z is distributed like Q of this weird-looking quantity. No matter how I pick the probability distribution, this chain of reasoning goes through, Jensen says. The key holds for any Q satisfying star, he says, and that's how we ground it into an example. The result is a curve that's always a lower bound everywhere. T sigma inverse j x(i) mu j. All right, and so just so you're clear what's going on here, the log turns these multiplications into additions. So we want to set this to 0 and use that sigma j inverse. Sigma j is full rank. And that will become clear in a second why that matters so much, because when we pull it out, what do we get? We get here s Sigma j inverse times sum, which is an unfortunate collision. that's OK. You get to screen that off. And I'll just post a one-page write-up for you. Please remind me in the thread, and I will definitely do that. If you don't do that, you'll get the wrong answer. That's also a motivation to learn it. And so what ends up happening here is you get something that says, I get sum i goes from 1 to n w(i)j over phi j plus lambda equals 0. And this implies that phi of j is equal to 1 over Lambda sum i equals 1. do this when you have something that sums to 1. It's not more complicated than what I wrote here, but make sure independently you go through it and ask questions. In the next class, as I said, what we're going to see is this notion of factor analysis. And that is going to tell us how to apply EM to a different kind of setting, which, at first glance, will look kind of impossible to do without a latent variable model. And I think that's all I want to say. The EM algorithm is an unsupervised version of k-means GMM. In GMM, you guess randomly an assignment of every point to the cluster, the probability. You guess where they're probabilistically linked, that is, what's the probability of these points belong to cluster one, this point belongs to cluster two. And then once you have that, you then solve some estimation problem that looks like a traditional supervised learning. The decomposition is quite important. And we're going to try and kind of abstract that away.

ROUGE-1: 10.95, ROUGE-2: 10.45, ROUGE-L: 9.54
BERTScore: 57.83

==============================================
