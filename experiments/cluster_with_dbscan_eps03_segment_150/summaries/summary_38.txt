The bias is a decreasing function as the model complexity. So we say that the bias is large, it's because the model is not expressive enough. So that means that if your model is more expressive, then your bias should decrease. So this is the bias. And now let's think about how do you draw the in some sense. Because for example, suppose you believe that this is a U curve. Then should you try even bigger models, bigger family of models? Because you kind of believe that it will be even worse. So you should just try even more in the middle. fifth-degree polynomial, and then I'm going to try quadratic. So linear model. I guess, you can probably see, guys, what will happen. So you can see that there's a large training error, training loss or training-- let's call it loss just for consistency. So what you really will fit, like if you minimize the error on the training data with this so many training examples, then what you will get is probably something like this. It's not like necessarily matching exactly the ground truth, but you have a small fluctuation. going to discuss this more next time. So the high level thing is just that something else is driving the norm to be small. Thanks. Going to talk more about this in the next few days. Back to Mail Online home. back to the page you came from. Back To the pageYou came from: Back to thepage you camefrom. Back into the page You came from was from: The Daily Mail. Back onto the pageyou came from, the DailyMail.com page you were from. So I think I just spend like five minutes, just briefly review on the backpropagation last time. So I didn't have time to explain this figure, which I think probably would be useful as a high level summary of what's happening. Like this is the forward path. This is how you define network and the loss function. So you start with some example x, and then you have some-- I guess, this is a matrix vector multiplication module, and you take x inner product multiplied with w and b. And then get some activation, the pre-activation. And you get some post activation.