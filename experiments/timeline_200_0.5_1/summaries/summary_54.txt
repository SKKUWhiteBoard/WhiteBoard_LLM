Sadhana sadhana is a machine learning scientist at Themis Ai and the lead TA of the course intro to deep learning at MIT. She'll be teaching us more about specifically the bias and the uncertainty of AI algorithms which are really two key or critical components towards achieving this Mission or this vision of safe and trustworthy deployment of AI all around us. Sadhana will talk about how we can build very modular and flexible methods for AI and building what we call asafe and trustworthy Ai. behalf of Themis so over the past decade we've seen some tremendous growth in artificial intelligence across safety critical domains in the Spheres of autonomy and Robotics. A lot of these Technologies were innovated five ten years ago but you and I don't see them in our daily lives so what is what's the Gap here between Innovation and deployment. We'll talk about how Themis is innovating in these areas in order to bring new algorithms in this space to Industries around the world after we talk about the ramifications for this for real world AI. Commercial facial detection systems are everywhere you actually played around with some of them in lab two when you trained your vae on a facial detection data set. The biases in these models were only uncovered once an independent study actually constructed a data set that is specifically designed to uncover these sorts of biases by balancing across race and gender. There are other ways that data sets can be biased that we haven't yet talked about so so far we've assumed a pretty key assumption in our data set which is that the number of faces in ourData is the exact same as theNumber of non-faces in our Data set. to dbias a model so what we want is a way to learn the features of this data set and then automatically determine that samples with the highest feature bias and the samples with lowest feature bias we've already learned a method of doing this in the generative modeling lecture. Now we'll walk through step by step a de-biasing algorithm that automatically uses the latent features learned by a variational autoencoder to under sample and oversample from regions in our data set um before I start I want to point out that this debiasing model is actually the foundation of themis's work this work comes out of a paper that we published a few years ago. good representation of what a face actually is so now that we have our latent structure we can use it to calculate a distribution of the inputs across every latent variable and we can estimate a probability distribution depending on that's based on the features of every item in this data set. This allows us to train in a fair and unbiased manner to dig in a little bit more into the math behind how this resampling works this approach basically approximates the latent space via a joint histogram over the individual latent variables. data point x will be based on the latent space of X such that it is the inverse of the joint approximated distribution. As Alpha increases this probability will tend to the uniform distribution and if Alpha decreases we tend to de-bias more strongly. This gives us the final weight of the sample in our data set that we can calculate on the Fly and use it to adaptively resample while training. Once we apply these this debiasing we have pretty remarkable results. Keep this algorithm in mind because you're going to need it for the lab 3 competition which I'll talk more about towards the end of this. lecture so so far we've been focusing mainly on facial recognition systems and a couple of other systems as canonical examples of bias however bias is actually far more widespread in machine learning. Consider the example of autonomous driving many data sets are comprised mainly of cars driving down straight and sunny roads in really good weather conditions with very high visibility. In some specific cases you're going to face adverse weather bad um bad visibility near Collision scenarios and these are actually the samples that are the most important for the model to learn. Uncertainty or when a model does not know the answer is the core idea behind uncertainty estimation. In the real world uncertainty estimation is useful for scenarios like this this is an example of a Tesla car driving behind a horse-drawn buggy which are very common in some parts of the United States. The exact same problem that resulted in that video has also resulted in numerous autonomous car crashes. There are multiple different types of uncertainty in neural networks which may cause incidents like the ones that we just saw. epistemic uncertainty so both of the methods we talked about just now involve sampling and sampling is expensive ensembling is very expensive but even if you have a pretty large model um having or introducing Dropout layers and calling 24 word passes might also be something that's pretty infeasible. At Themis we're dedicated to developing Innovative methods of estimating epistemic uncertainty that don't rely on things like sampling so that they're more generalizable and they're usable by more Industries and people. Themis is unlocking the key to deploy deep learning models safely across fields. We can now answer a lot of the questions that the headlines were raising earlier which is when should a human take control of an autonomous vehicle. What types of data are underrepresented in commercial autonomous driving pipelines. We now have educated answers to these questions due to products that Themis is developing and in spheres such as medicine and health care we can now answers questions such as when is a model uncertain about a life-threatening diagnosis. compete in the competition which the details are described in the lab but basically it's about analyzing this data set creating risk-aware models that mitigate bias and uncertainty in the specific training pipeline. At Themis our goal is to design advance and deploy a trustworthy AI across Industries and around the world. We're hiring for the upcoming summer and for full-time roles so if you're interested please send an email to careers themesai.io or apply by submitting your resume to the Deep learning resume drop and we'll see those resumes and get back to you.