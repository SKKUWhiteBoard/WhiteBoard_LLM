Danqi Chen is one of the foremost researchers in question answering. She's particularly well known in recent work for her work on using dense passage retrieval methods for open domain question answering, and is the professor at the Princeton University. Danqi once upon a time was the head TA of CS224N. So she's quite familiar with the context of this class. So I'm very happy to introduce to you some of the fundamentals in this field, as well as on cutting edge and state of the art topics. if you just put your question in a search engine like Google. And those kind of systems are also able to handle more complex questions like how-to questions. So the question is, how can I protect myself from COVID-19? So there isn't really a simple and short answer to this question. So you can see that the system actually returns a very long paragraph, including the best way to prevent illness is to avoid being exposed to this virus. So actually this paragraph is actually a summary from CDC article. So this is also one type of question answering problems. Question answering is probably one of those fields that we have seen the most remarkable progress in the last couple of years driven by deep learning. In this lecture, I will be mostly focusing on the text based, or textual question answering problems. And another class, bigger class of the question answering problem is called visual question answering. So if you have interest in these type of problems, I encourage you to check out those problems, but I'm not going to dig into these problems today. OK. Next, I'm going to start with a part 2, reading comprehension. If you remove the context-to-query attention, the performance will drop to 67.7 F1 score. And then if you remove this part, it will drop a 4-point F 1 score. So basically this theory tells us that these kind of attention scores can actually capture the similarity between the question words and the context words. And now here is our attention visualization to show that how this smorgasbord of attention actually can capture the similarities between the questions and the contexts. BERT is a deep bidirectional transformer encoder pre-trained on large amounts of text. It is trained on the two training objectives, including masked language modeling and the next sentence prediction. The BERTbase has 110 million parameters and the BERT-large model has 330 million parameters. If you just take this BERT model, and by just optimizing all the parameters together, it can give you a very high performance. And even if you use a stronger pre-training models, they can even lead to better performance on SQuAD. yeah, I guess I'm just a little worried about who comes up with the test cases? Who determines what the right answer is? I mean, we will have more discussion of toxicity and bias coming up very soon, including actually Thursday's lecture as well as a later lecture, not specifically about QA though. OK. Next person is-- Thank you for the lecture. Yeah, my question is also related to the open domain question answering. So there is some very specific designs like domain server alignments and efficient level disentanglement techniques that has shown some interesting performance on other tasks.