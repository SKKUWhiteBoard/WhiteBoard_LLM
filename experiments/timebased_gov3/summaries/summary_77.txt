Program evaluations are systematic studies that use research methods to address specific questions about program performance. Evaluation can play a key role in program planning, management, and oversight by providing feedback on programs. An evaluation study can provide a valuable supplement to ongoing performance reporting by measuring results that are too difficult or expensive to assess annually. It can also explain the reasons why performance goals were not met, or assessing whether one approach is more effective than another. In particular, evaluations can be designed to isolate the causal impacts of programs from other external economic or environmental conditions in order to assess a program's effectiveness. Both program design and execution to program managers, legislative and executive branch policy officials, and the public. The PIO role was created in 2007 by executive order. GPRAMA established the role in law and specified that it be given to a “senior executive” at each agency who reports directly to the agency’s COO or to its deputy agency head. It is to advise the head of the agency and the COO on goal setting, measurement, and reviewing progress on the agency priority goals. in promoting agency use of evaluation and other evidence to improve program performance. The act also charged the Performance Improvement Council (PIC), the Office of Personnel Management (OPM), and OMB with responsibilities to improve agency performance management capacity. The PIC is an interagency council that was created in the 1990s to help agencies with performance issues. The OMB is an agency that was established in the 1970s to assist agencies with their performance issues and to help them improve their effectiveness and efficiency. created by executive order, but GPRAMA established it in law. membership would include the PIOs from all 24 CFO Act agencies, as well as any others. The PIC’s duties include facilitating agencies’ exchange of successful practices and the development of tips and tools to strengthen agency performance management. In 2012 through 2014, OMB and the PIC supported several interagency forums on evaluation and evidence that were open to all federal agency staff. The act charged OPM with (1) identifying key skills. OPM identified core competencies for performance management staff, PIOs, and goal leaders and published them in a January 2012 memorandum. OMB has taken several steps to help agencies develop evaluation capacity by issuing guidance, promoting the exchange of evaluation expertise through the PIC. OPM is currently conducting pilot studies through 2015, in collaboration with the Chief Human Capital Officers Council, of how to build staff capacity in several competencies identified as mission critical across government, including data analysis. 7 of the 24 agencies have central leaders responsible for evaluation; in contrast, 7 agencies reported no recent evaluations for any of their performance goals. The GPRA provides a statutory framework for performance management and accountability across the government. Less than a third of agencies have an evaluation plan or agency-wide policies for ensuring study credibility. About half the agencies (11) reported committing resources to obtain evaluations by establishing a central office responsible for evaluating agency programs, operations, or projects. AEA guidance says a central evaluation office can promote an agency’s capacity and provide an organizational framework for planning, conducting, or procuring evaluation studies, but only about half of the agencies in total had one. GPRAMA requires OMB to provide quarterly updates on agency and cross-agency priority goals on a central, government-wide website. In our survey, PIO reviews were mixed about the utility of this website to improve agency capacity to use evaluations in decision making. While timely, public dissemination of performance and evaluation results may not directly influence agency decision making, it is important to support government transparency and accountability for results to the Congress and the public, the authors say. In the absence of explicit authority or congressional request, agencies may be reluctant to spend increasingly scarce funds on evaluation studies that are perceived as resource intensive. ways to encourage agencies to produce credible, relevant studies that inform decision making. consult with agencies on proposed revisions to their strategic plans and priority goals, as GPRAMA requires them to do every 2 years. Request agency evaluations to address specific questions about the implementation and results of major program or policy reforms, in time to consider their results in program reauthorization. Review agencies’ annual evaluation plans or agendas to ensure that they address issues that will inform budgeting, reauthorizing, and ongoing program management. We administered a web-based questionnaire from May 2, 2014, to June 19, 2014. We received responses from all 24 agencies covered by the Chief Financial Officers Act of 1990 (CFO act) Key contributors to this report are listed in appendix III. If you or your staff have any questions about this report, please contact me at (202) 512-2700 or by e-mail at kingsburyn@gao.gov. Contacts for our Office of Congressional Relations and Office of Public Affairs may be found on the last page of this report. Survey gave us information about agencies’ evaluation resources, policies, and activities. We sent respondents an e-mail invitation to complete the survey on a secure GAO web server. Because this was not a sample survey, it has no sampling errors. In practice, any survey may introduce nonsampling errors that stem from differences in how a particular question is interpreted, or how the survey data are analyzed. All can introduce unwanted variability into the survey results. The survey questions and summarized results are in appendix II. science survey specialist designed the questionnaire, in collaboration with our staff who had subject matter expertise. We pretested the questionnaire in person with PIOs at three federal agencies to make sure that the questions were relevant, clearly stated, easy to comprehend, and unbiased. Since this was a web-based survey, respondents entered their answers directly into the electronic questionnaire; thus, we did not key the data. When we analyzed data from the completed survey, an independent analyst reviewed all computer programs used in our analysis. into a database, avoiding data entry errors. In reviewing the agencies’ answers, we confirmed that the PIOs had correctly bypassed inapplicable questions. We concluded from our review that the survey data were sufficiently reliable for the purposes of this report. The 24 agencies subject to the CFO Act include Agency for International Development, Agriculture, Commerce, Defense, Education, Interior, Justice, Homeland Security, Labor, State, Transportation, Social Security. In addition to the contact named below, there are also contact names for the Small Business Administration, National Aeronautics and Space Administration, and Nuclear Regulatory Commission. Administration for Children and Families. Evaluation Policy. Washington, D.C.: Department of Health and Human Services, November 2012. America Achieves. “Investing in What Works Index: Better Results for Young People, Their Families, and Communities.” Results for America, Washington,D.C., May 2014. American Evaluation Association. An Evaluation Roadmap for a More Effective Government. N.p.: Revised October 2013. Canada. 2013 Spring Report of the Auditor General of Canada. Ch. 1. Capacity in a Diverse Federal Agency. Paper presented at Federal Evaluators Conference, Washington, D.C., November 1, 2012. “Framing the Capacity to Do and Use Evaluation,” New Directions for Evaluation, 133 (Spring 2014): 7—24. ‘Developing a National Evaluation System in South Africa,’ eVALUatiOn Matters: A quarterly knowledge publication of the African Development Bank, 2(3) (September 2013): 42—49. 33:307 (2012). National Audit Office. Cross-Government: Evaluation in Government. Partnership for Public Service and Grant Thornton. A Critical Role at a Critical Time: A Survey of Performance Improvement Officers. Washington, D.C.: April 2011. http://ourpublicservice.org/OPS/publications/viewcontentdetails.php?id=1 60. Pew Charitable Trusts and MacArthur Foundation. States’ Use of Cost- Benefit Analysis: Improving Results for Taxpayers. Philadelphia: Pew- MacArthur Results First Initiative. U.N. Evaluation Group: Practical Tips on How to Strengthen National Evaluation Systems. U.S. Department of Health and Human Services, Centers for Disease Control and Prevention: Improving the Use of Program Evaluation for Maximum Health Impact. USAID Evaluation Policy: Learning from Experience. United Nations Evaluation Group Task Force on National Evaluation Capacity Development: A report for the United Nations Evaluation Group Task force on National evaluation capacity development. The World Bank: Building Evaluation Capacity toStrengthen Governance.