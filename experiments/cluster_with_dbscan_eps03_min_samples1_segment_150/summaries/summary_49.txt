Today we're going to do a fun problem that will test your knowledge of the law of total variance. In the process, we'll also get more practice dealing with joint PDFs and computing conditional expectations and conditional variances. So in this problem, we are given a joint PDF for x and y. And then we are asked to compute the variance of x plus y. So you can think of xplus y as a new random variable. And because the parallelogram has an area of 1, the height of the PDF must also be 1 so that the PDF integrates to 1. whose variance we want to compute. And moreover, we're told we should compute this variance by using something called the law of total variance. And for this problem, the logical choice you have for what to condition on is x or y. So again, we have this option. And my claim is that we should condition on x. And the reason has to do with the geometry of this diagram. So notice that if you freeze an x and then you sort of vary x, the width of this parallelogram stays constant. on y and look at the width this way, you see that the width of the slices you get by conditioning vary with y. So to make our lives easier, we're going to condition on x. So this really can seem quite intimidating, because we have nested variances and expectations going on, but we'll just take it slowly step by step. So first, I want to focus on this term-- the conditional expectation of x plus y conditioned on x, and I'm going to erase this bottom one. the formula for this line is given by y is equal to x plus 1. Conditioned on x, this is the PDF of y. And because it's uniformly distributed and because expectation acts like center of mass, we know that the expectation should be the midpoint, right? And so to compute this point, we simply take the average of the endpoints, x plus1 plus x over 2, which gives us 2x plus 1 over 2. So this is py given x, y given x. And now we can look at this conditional PDF to figure out what this is. We have a formula for computing the variance of a random variable when it's uniformly distributed between two endpoints. So we're making good progress, because we have this inner quantity and this outer quantity. So now all we need to do is take the outer variance and the outer expectation. So writing this all down, we get variance of x plus 1, a is x, and b minus a squared over 12 is just 1/12. That's pww. This is pWW. y is equal to variance of this guy, 2x plus 1/2 plus the expectation of 1/12. So this term is quite simple. The expectation of a constant or of a scalar is simply that scalar. We know that you can just take out this scalar scaling factor as long as we square it. And now to compute the variance of x, we're going to use that formula again, and we'll call it 2 squared, or 4 times the variance. we're going to use this picture. So here we have the joint PDF of x and y, but really we want now thePDF of x, so we can figure out what the variance is. So hopefully you remember a trick we taught you called marginalization. To get the PDF ofx given a joint PDF, you simply marginalize over the values of y. So if you freeze x is equal to 0, you get the probability density line over x by integrating over this interval, over y. come over here and draw it. We're claiming that the PDF of x, px of x,. looks like this. It's just uniformly distributed between 0 and 1. And if you buy that, then we're done, we're home free, because we can apply this formula, b minus a squared over 12, gives us the variance. So coming back over here, we get 4 times 1/12 plus 1/ 12, which is 5/12. And that is our answer.  memorizing formulas might seem like cheating, but there's a few important ones you should know. And it will help you sort of become faster at doing computations. And that's important, especially if you guys take the exams. So that's it. See you next time. We'll be back in a few days with a new episode of "The Daily Discussion" to talk about the week's top news stories. Back to the page you came from. Click here for the next episode of The Daily Discussion.