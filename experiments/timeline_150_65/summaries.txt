==================== [1/100] ====================
Summary:
CASEY RODRIGUEZ: We proved these two theorems last time, and we used them for-- and we had a couple of applications of them. So the first theorem, simple theorem, was that a sequence converges to x if and only if the limit as n goes to infinity of the absolute value of xn minus x goes to 0. And then we also had the squeeze theorem, that if you have three sequences-- a sub n,. b sub n, and x sub n-- so that xSubN is in between a subN and bSubN. squeezed in between a sub n and b sub n. Last time we used this to prove a kind of special limit that this equals 0 if the absolute value of c is less than 1. So let's use this to do a few more special limits if you like. I'm not going to prove it, but it's a simple exercise using induction. And the binomial theorem says that [? for all ?] [? N, the ?] natural numbers, x, y in R, x plus y raised to the n is equal to the sum from k equals 0. to n of n choose k, x to the n minus k y to the k. If p is positive, then limit as n goes to infinity of p to the 1 over n equals 1. And the third is-- it's just that a certain limit exists-- limit as N goes to Infinity of n to 1 over N equals 1, OK? Let me make a small comment here. So far in our discussion of the real numbers, so far we've been talking about real numbers. We're going to move on to other topics. we've only defined what it means to take a real number to an integer power, but-- and n-th roots. So using that, we can then define how totake a real numbers to a rational power. OK? All of that is just to say that to define a positive real number, we need to use the elementary facts about the real numbers, the fact that it has the least upper bound property, and that the rationales are somehow dense in the realNumbers. positive real number to a positive real number or to a real number of power doesn't require the introduction of the exponential or logarithm. So all of that is just to say that what we've done up to now-- these things actually do make sense. But we're just going to use the basic properties of exponents throughout all this, so we don't-- we haven't even talked about continuity, or derivatives, or anything like that. So we'll just use elementary means to be able to prove these statements. epsilon positive there, we should be able to find a capital number M, such that if n is bigger than or equal to capital M, 1 over n to the p is less than epsilon. So that proves number one. So number two we'll do-- we really only need to do two cases. One is p. So p equals 1 is fine. This is clear, because then I just get 1 for the whole sequence. Now let me do p bigger than 1. OK. We have an inequality which we proved actually in the second lecture, I think, using induction, but you can actually get from binomial theorem as well. OK? So we use this inequality now with x equals p minus 1. So p-- this is equal to 1 plus p to the 1 over n minus 1 raised to the n-th power. And so I want to show that this quantity here goes to 0.over n plus 1. OK?" "Yes," he says. "I'm sorry. I'm sorry." the binomial theorem. And we'll use the binometric theorem to get a little bit of a different inequality. So for number 3, we want to prove limit as n goes to infinity of n over 1 over n equals 1. So let xn equal n to the 1/n minus 1, which we note is bigger than or equal to 0 for all n. And so my goal I want to show is limit as x as n went to infinity, because then that proves that this converges to 0. way we're going to do that is using an inequality we get from the binomial theorem-- and using this trick here. Now, if we look at plus x to the n raised to theN, this is just-- that's just n-- let me move it over a little bit. Plus x to n raised the n. x sub n is n to the 1/n minus 1. Add 1. I get into n. And these coefficients are just quotients of factorials, so I get n. they're always non-negative as well. This sum is always bigger than or equal to 1 term from the sum. So it's bigger than  equal to k equals 2 [INAUDIBLE] y2-- you'll see-- x sub n squared. Now, n choose 2-- this is equal to n factorial over 2 factorial n minus 2Factorial x to the n squares x of n squared, which equals n times n minus 1 over 2 x ofn squared. to 2 over n minus 1 square root. OK? And now this is just 0, so it converges to 0. This right-hand side is square root of 2 overn minus 1. Now, the limit as n goes to infinity of 2OverN minus 1 is 0. Square root of that also converged to 0, that's a fact we did from the end of last time. So this whole thing convergesto 0. And that completes the proof. All right, so now we are going to study a couple of objects related to a bounded sequence. What's the underlying question? Convergent sequences are bounded, so-- and they have convergent subsequences. Not all sequences have convergence. We're going to prove it by introducing limsup and liminf, because these are also two important objects that arise in analysis. So let xn be bounded sequence. And we define-- if they exist, there are there, there. And this is a very-- really a very powerful statement. And I'll restate it in a little bit when we get to the statement of that theorem-- namely, that every bounded sequence does have a convergence. are going to be certain limits, so it's not clear that they exist at all to begin with. But we'll show that they always do exist. We define limsup x sub n. And sometimes I'll write n goes to infinity underneath. Sometimes I'll just write limsup or I'll have an n underneath it. This is supposed to be a number, and this is equal to the limit as n go to infinity of a new sequence. What are the entries of this new sequence? This is sup of x of k, k bigger than or equal to n. If I have a bounded sequence, then the limsup and the liminf exist. And we show that by proving that these two sequences have these monotonicity properties. And so this uses the sup part of this previous theorem, but if we use the inf part, then we also get the statement for the b sub n. So rather than write out the details, I'll leave it to you just to flip around the inequalities for the inf in your notes. So similarly, for all N, a natural number, b subN is bigger than or equal to b subn plus 1-- or other way. in terms of the a sub n's and b subn's-- means minus B is less than or equal to b sub n. So these sequences are bounded. So in fact, these two implies that-- all right, so we've shown that these two sequences that define-- that we use to define the limsup and the liminf are monotone and bounded, so therefore, the limit of these two. sequences-- the limits, which define theLimsup and liminf, actually exist. The smallest thing in a set cannot be an upper bound for this set, so if you like the Archimedean property, you can always find something from the set less than 0. So we're looking at now the set 1 over k, where n is-- where k is bigger than or equal to n. So the supremum of this set is simply 1/n. So as n goes to infinity, the limit of this supremum here, which equals the limit as n go to infinity of 1/N, equals 0. The Bolzano-Weierstrass theorem says that every bounded sequence has a convergence to the limsup and the liminf. We can prove this by taking the limit as n goes to infinity of 0 equals 0, all right. So the original sequence, which we know-- or shown last time-- doesn't converge. But that's not just a one-way street. In fact, we have something stronger, in that we have at least two two subsequences which converge at least at least once. to these two numbers, which may or may not be the same. OK? So the reason this is so powerful and so strong is that it-- to get your hands on something, it doesn't require you to show something as strong as showing there is a sequence converging to that. So first, take a sequence approaching-- so that the values are approaching that-- the outputs are approaching the maximum. Then you could pass to a subsequence, which actually does converge to something by this theorem, and proceed in that way. small bit of rambling about why this theorem is so useful is that, again, it's very difficult to show convergence to that thing you want to study. But this theorem says you don't need to work that hard or try to do the impossible. It's also useful in the study of PDEs, which is what I study. So I have a soft spot for it. Actually, one of its generalizations-- all right, so let's prove this theorem that there exists some sequences which converge to. the limsup and liminf. So I want to show that there's something converging to the limit as n goes to infinity of the a sub n's. So we know that there exists an n sub 1 bigger than or equal to n. And so what I'm going to do is I's going to try up a subsequence of elements between a subN and a subn minus something which is converging. to 0, and not quite a sub N. So it'll be along asequence as well. than or equal to 1 simply by how this is defined as a supremum, and by the exercise from assignment 3. a sub 1 minus 1 is not an upper bound for the set asub 1, which is x sub k's. Therefore, I should be able to find an element from this set strictly bigger than that. Since a sub 2 plus 1 equals the supremum of the x of k, there exists an n sub 3 bigger than n sub 2, such that a sub n sub 1 plus 1, minus now a third, is less than 1. The limit as k goes to infinity of a sub n sub k minus 1 plus 1 equals the limit of the original sequence, which is, by definition, the limsup. Now, we've shown that there exists a subsequence converging to the lim Sup and the liminf, which gives us the Bolzano-Weierstrass theorem. And now let me come back to the statement I made about these two sequences here-- namely, that the lim sup equals the lim inf if and only if the original. sequence converges. Let x sub n be a bounded sequence. Then xn converges if and only if limsup equals the liminf. And there's one more part. If xn agrees, then all these limits agree. We're assuming that these two things equal each other. They're given by a common value L. And what we're going to end up showing is that this sequence converges to L. So that's another way of thinking about limsups and liminfs is that they also somehow measure just how divergent your sequence is. If that difference is 0, then your original sequence is convergent.

ROUGE-1: 40.27, ROUGE-2: 38.45, ROUGE-L: 37.51
BERTScore: 78.50

==============================================
==================== [2/100] ====================
Summary:
Professor: The configuration of a particle is given by, or described by, a wave function psi of x. In 3D, the wave function would be a function of all three positions x, y and z. Professor: We're currently in our one dimensional tripped out tricycles. If we had two particles, our wave function. would be of the position of each. Each particle would have its own wave function, which would be the same in both 3D and 2D. The meaning of the wave function is that the norm squared psi of x, norm squared, it's complex, dx is the probability of finding the particle- There's an n in their.particle. x1, x2, and so on. So we'll go through lots of details and examples later on. But for the most part, we're going to be sticking with single particle in one dimension for the next few weeks. Now again, I want to emphasize this is our first pass through our definition of quantum mechanics. there are two possible configurations the system can be in, which in quantum mechanics means two different wave functions that could describe the system given psi 1 and psi 2. It's also possible to find the system in a superposition of those two psi is equal to some arbitrary linear combination alpha psi 1 plus beta psi 2 of x. OK? So some things to note-- so questions about those before we move on? No questions? Nothing? Really? You're going to make he threaten you with something. This is not trivial stuff. of x norm squared is equal to 1. This is just saying that the total probability that we find the particle somewhere had better be one. If it's less, then the particle has simply disappeared. And basic rule, things don't just disappear. So probability should be normalized. And this is our prescription. So a second thing to note is that all reasonable, or non stupid, functions of x are equally reasonable as wave functions. OK? So this is a very reasonable function. It's nice and smooth. It converges to 0 infinity. properties you might want. This is also a reasonable function. It's a little annoying, but there it is. And they're both perfectly reasonable as wave functions. This on the other hand, not so much. For two reasons. First off, it's discontinuous. And as you're going to show in your problem set, discontinuities are very bad for wave. functions. The second is over some domain it's multi valued. There are two different values of the function. That's also bad, because what's the probability? It's the norm squared. equally reasonable as wave functions. All states corresponding to reasonable wave functions are equally reasonable as physical states. There's no primacy in wave functions or in states. However, with that said, some wave function are more equal than others. And this is important, and coming up with a good definition of this is going to be an important challenge for us in the next couple of lectures. So in particular, this wave function has a nice simple interpretation. If I tell you this is psi of x, then what can you tell me about the particle whose wave function is the psi of X? What do you know? the Fourier theorem. Take any wave function which is given by some complex valued function, and it can be expressed as a superposition of plane waves. 1 over 2pi in our normalization integral dk psi tilde of k, but this is a set of coefficients. e to the ikx. We're saying pick a value of k. There's a number associated with it, which is going to be an a magnitude and a phase. And that's the magnitude and phase of a plane wave. functions. So this is a plane wave with a definite wavelength, 2pi upon k. We know what its momentum is. Its momentum is h bar k. Any function, we're saying, can be expressed as a superposition by summing over all possible values of k, all possible different wavelengths. That make sense? Fourier didn't think about it that way, but from quantum mechanics, this is the way we want to thinking about it. It's just a true statement. a definite position? AUDIENCE: Delta. PROFESSOR: A delta function, exactly. So I claim that any function psi of x can be expanded a sum over all states with a definite position. So is this true? Is it true that I can take any function and expand it in a superposition of delta functions? Absolutely. We're going to find this is a general statement that any state can be expressed as a superpositions of states for any observable quantity you want. question I want to ask you. Is that a superposition? Yeah. I mean every vector can be written as the sum of other vectors. And it can be done in an infinite number of ways, right? So there's no such thing as a state which is not a superpositions. Every vector is asuperposition of other vector. It's a sum ofother vector. So in particular we often find it useful to pick a basis and say look, I know what I mean by the vector y, y hat is a unit vector in this direction. And now I can ask, given that these are my natural guys, the guys Iwant to attend to, is this a superpose of x and y? Or is it just x or y? There's nothing hallowed about your choice of basis. There's no God given basis for the universe. But any given vector can be expressed as a superposition of some pair of basis vectors. So this somehow is about finding convenient choice of based. Whereas x hat itself is not.a superposition. So there's no natural choice. of basis, but it's sometimes convenient to pick a basis. This is the direction of the surface of the earth, and this is perpendicular to it. This would be slightly strange if you're leaning. this is an expansion of a function as a sum, as a superposition of other functions. We'll talk about that more. Quickly what's the momentum associated to the plane wave e to the ikx? AUDIENCE: [INAUDIBLE]. PROFESSOR: h bar k. So now I want to just quickly run over some concept questions for you. So whip out your clickers. OK, we'll do this verbally. All right, let's try this again. How do you know whether the particle is big or small by looking at the wave function? Professor: Which particle has a larger momentum? Think about it, but don't say it out loud. If it has higher momentum, what do you just intuitively expect to know about its energy? It's probably higher. OK next one. Compared to the wave function psi of x, it's Fourier transform, psi tilde of x contains more information, or less, or the same, or something. So let's vote. A, more information. B, less information. C, same. OK, good you got it. of length l, 0 outside of that region. f has a single well defined wavelengths. Or f is made up of a wide range of wavelengths? Think it to yourself. OK, now before we get talking about it, I want everyone to close their eyes. Or close the eyes of the person next to you. That's fine. And now and I want you to vote. A is f has one well defined wavelength. B isf has a wideRange of wavelengths. It's closer to true. The sine wave is an infinite, and it cancels out past minus l over 2 and positivel over 2. You need to add a bunch of wavelengths to actually cancel it out there. If you only had the thing of a single wavelength, it would continue with a single wavelengths all the way out. If yo you take a superposition, the sine is continuous and differentiable everywhere, because it's a cosine, right? So if yo you Take a Superposition of a Sine Wave, the Sine is Differentiable Everywhere. of sines and cosines, do you ever get a discontinuity? No. Do you get something whose derivative is discontinuous? No, you don't. So it's going to take an infinite number of sine and cosine to reproduce that little kink at the edge. So how would you ever reproduce a thing with a discontinued thing? Well, you'd need some infinite sum of sines & cosines where there's some technicality about the infinite limit being singular. question. That's a very good question. The question here is look, there's two different things you can be talking about. One is arbitrarily large and arbitrarily short wavelengths, so an arbitrary range of wavelengths. And the other is an infinite number. But an Infinite number is silly, because there's a continuous variable here k. You got an infinitenumber of wavelengths between one and 1.2, right? It's continuous. So which one do you mean? So let's go back to this connection that we got a minute ago from short distance and high momentum. That thing looks like it has one particular wavelength. But I claim, in order to reproduce that as a superposition of states with definite momentum, I need arbitrarily high wavelength. To construct or detect an arbitrarily small feature you need arbitrarily large momentum modes. I want the connection between momentum and the length scale to be something that becomes intuitive to you. So when I talk about something with short. distance, I emphasize you to think and encourage you to conflate short distance and large momentum. It's really about the range, not just the number. And I want you to be able to do the same thing with something with long. distance. I hope that this will help you. features, I'm going to talk about it as something with large momentum. And that's because in a quantum mechanical system, something with short wavelength is something that carries big momentum. What should be true of the Fourier transform in order for this to reasonably function? And among other things, being able to have a Fourier. transform where you don't have arbitrarily high momentum modes is going to be an important condition. That's going to turn to be related to the question of whether a wave function can be Fourier transformed. to the derivative being continuous. That's a very good question. So that's the optional problem 8 on problem set 2. Other questions? PROFESSOR: Cool, so that's it for the clicker questions. Sorry for the technology fail. So I'm just going to turn this off in disgust. that's really irritating. So today what I want to start on is pick up on the discussion of the uncertainty principle. The certainty of the momentum seems to imply lack of knowledge about the position and vice versa. So in order to do that, we need to define uncertainty. The probability that any given person in this group of 16 has a particular age? I'll call it a. The sum over all possible ages of the probability that you have age a is equal to 1. So what's the most likely age? If you grabbed one of these people from the room with a giant Erector set, and pull out a person, and ask them what their age is, what's most likely they'll have? AUDIENCE: 22. PROFESSOR: 22, just by eyeball roughly. be 19.2 for this. But if everyone had a little sticker on their lapel that says. I'm 14, 15, 16, 20, 21 or 22, how many people have the age. 19.4. That's what I got. So in particular how did I get the average? I'm going to define some notation. This notation is going to stick with us for the rest of quantum mechanics. The average age, how do I compute it? So we all know this, but let me just be explicit about it. It's the sum over all possible ages. The average value of a squared is equal to the sum over all possible ages of a times the ratio of Na to N. The average of the square of ages is the same thing. The expected value of some function of a is equal-- and this is something you don't usually do-- to the value of f of a, times the probability that you measure that value in the first place. It's a very useful relation. And so, again, does the average have to be measurable? No, it certainly doesn't. average value of a squared is not equal to 0. And that's because the squared has everything positive. So here we have a distribution where its average value is 0, but its width is non-zero. So how do we define the width of a distribution? This is going to be like our uncertainty. How happy are you today? Well, I'm not sure. How unsure are you? Well,. that should give us a precise measure. So let me define three things. First the deviation. So we always get something that's centered at 0. So deviation is not a terribly good thing on average, because on average the deviation is always 0. But we can get a nice measure by getting the deviation squared. So the mean of the derivation squared, mean of a minus the average value of a squared. This is what I'm going to call the standard deviation. Which is a little odd, because really you'd want to call it the standard deviations squared. But whatever. We use funny words. standard deviation is 0, as long as there's no width, which is why the standard deviation is a good measure of width or uncertainty. So standard deviation squared is equal to the average value of a squared minus twice a times the averagevalue of a plus average valueof a quantity squared. But if you do this out, this is going to be equal to a squared plus 2 average value. That's just minus twice the average values of squared and squared. So this is an alternate way of writing thestandard deviation. in this fashion or this fashion. And the notation for this is delta a squared. Different probability distributions are going to give me different delta a's. So one thing that's sort of annoying is that when you write delta a, there's nothing in the notation that says which distribution you were talking about. Sometimes it's useful to just put given the probability distribution p of a. This is not very often used, but sometimes it's very helpful when you're doing calculations just to keep it simple. Professor: The average value of some x, given a probability distribution on x where x is a continuous variable, is going to be equal to the integral. And similarly for x squared, or more generally, for f of x, or the expected value of f of X given this probability distribution. So this is all just mathematics. And we define the uncertainty in x is equal to. the expectation value of x squared minus the expectedvalue of x quantity squared. And this is delta x squared. All of that is just straight up classical probability theory. couple of ways to improve this notation. One of which is to write the expected value of x in the state psi, so you write psi as a subscript. Another notation that will come back-- you'll see why this is a useful notation later in the semester. And we will give meaning to this notation later, but I just want to alert you that it's used throughout books, and it means the same thing as what we're talking about the expectedvalue of x given a particular state psi. The probability of having that momentum times momentum, right? Everyone cool with that? This is what you mean by probability. But we need to know if we have a quantum mechanical system described by state psi of x, how do we get the probability that you measure p? Do I want to do this now? Yeah, OK I do. And we need a guess. We made a guess at the end of last lecture that, in quantum mechanics, this should be dp minus infinity to infinity of the Fourier transform. This is a thing with dimensions of what? Length, right? But over on the right hand side, we have a length and a probability, which is a number, and then another length. So why are we getting something with. dimensions of length, not something with Dimensions of length squared? And the answer is this is not a probability. It is a probability density. So it's got units of probability per unit length. This has dimensions of one over length. The probability to find the particle between x and x plus dx. So that was our second postulate. In quantum mechanics, the expectation value of x.dx squared is the probability of finding it in this domain. So what we're doing is we're summing over all such domains the probability times the value. This is the difference between discrete, where we didn't have these probability densities, we just had numbers, pure numbers and pure probabilities. Now we have probabilities densities per unit whatever. Yeah? The psi is just to denote that this is in the state psi. And it can be pronounced in two. ways. You can either say the expectation value of x, or the expectation of x in the state psi. And this would be pronounced one of two ways. It's the same idea, but they have different flavors, right? So whatever your native language is, you've got some analog of this. This means something in a particular mathematical language for talking about. And so I could see he's a nice guy, I could say he's [? carinoso ?], and they mean different things in different languages. quantum mechanics. Why is there a double notation of psi? Roughly speaking, it's because in computing this expectation value, there's a psi squared. And so this is to remind you of that. Other questions? Terminology is one of the most annoying features of quantum mechanics. Yeah? AUDIENCE: So it seems like this [INAUDIBLE] variance is a really convenient way of doing it. How is it the Heisenberg uncertainty works exactly as it does for this definition of variance? have chosen some other definition of uncertainly. So why this one? And one answer is, indeed, the uncertainty relation works out quite nicely. But then I think important to say here is that there are many ways you could construct quantities. This is a convenient one, and we will discover that it has nice properties that we like. There is no God given reason why this had to be the right thing. I can say more, but I don't want to take the time to do it, so ask in office hours. we're going to derive it twice soon and then later. The later version is better. So let me work out some examples. Or actually, I'm going to skip the examples in the interest of time. They're in the notes, and so they'll be posted on the web page. By the way, the first 18 lectures of notes are posted. I had a busy night last night. So I want to go back to this and ask a silly-- I wantto make some progress towards deriving this relation. in terms of the wave function the following way. Are we ever in a position to say intelligently that a particle-- that an electron is both hard and white? AUDIENCE: No. PROFESSOR: No, because being hard is a superposition of being black and white, right? It's not that we don't get too. It's that it doesn't make sense to do so. In general, being in a definite position means being in an extremely complex superposition. having different values for momentum. They claim that any function can be expressed as a superposition of states with definite momentum, right? Well, among other things a state with definite position, x0, can be written as asuperposition, 1 over 2pi integral dk. But in particular, it's clear that this is not-- this quantity can't be a delta function of k, because, if it were, this would be just e to the ikx. And that's definitely not a deltafunction. this doesn't work. We want some good definition of p given that we're working with a wave function which is a function of x. We have a couple of hints. Hint the first is that a wave-- we know that given a wave with wave number k, which is equal 2pi over lambda, is associated, according to de Broglie and according to Davisson-Germer experiments, to a particle. So having a particle-- a wave, with waveNumber k or wavelength Lambda associated particle with momentum p is equal to h bar k. a wave, a plane wave e to the iks, how do I get h bar k out of it? Note the following, the derivative with respect to x. Multiply by h bar, divide by i, derivative withrespect to x e to ikx. That's suggestive. And I can write this as pe to the ikX. So let's quickly check the units. What are the units of h bar? Momentum times length divided by length number momentum. question slightly differently. We've followed the de Broglie relations, and we've been led to the idea that using wave functions that there's some relationship between the momentum, the observable quantity that you measure with sticks, and meters, and stuff. So if this is supposed to be true in some sense, what is momentum have to do with a derivative? Momentum is about velocities, which is like derivatives with respect to time, right? Times mass. Mass times derivative with respectto time, velocity. And this ties into the most beautiful theorem in classical mechanics. discovered it, Emmy Noether. Noether, incidentally, was a mathematician. Ville went to her and was like, look, I'm trying to understand the notion of energy. And this guy down the hall, Einstein, he has a theory called general relativity about curved space times and how that has something to do with gravity. But it doesn't make a lot of sense to me, because I don't even know how to define the energy. So how do you define momentum and energy in this guy's crazy theory? algebra, looked at the problem and was like I don't even know what it means in classical mechanics. So she went back to classical mechanics and, from first principles, came up with a good definition of momentum, which turns out to underlie the modern idea of conserved quantities and symmetries. Noether tells us the following statement, to every symmetry-- and I should say continuous symmetry-- to every. symmetry is associated a conserved quantity. OK? So in particular, what do I mean by symmetry? Well, for example, translations. x goes to x plus some length l. This could be done for arbitrary length l or translation by this much. Professor: If the system has the same dynamics at one moment and a few moments later and, indeed, any amount of time later, if the laws of physics don't change in time, then there must be a conserved quantity called energy. So this is the first step, but this still doesn't tell us what momentum exactly has to do with a derivative with respect to space. We see that there's a relationship between translations and momentum conservation, but what's the relationship? So let's do this. translate by L. And what translate by L does is it takes f of x and it maps it to f of X minus L. So this is a thing that affects the translation. And why do I say that's a translation by L rather than minus L? Well, if you have some function like this, and it has a peak at 0, then after the translation, the peak is when x is equal to L. OK? So just to get the signs straight. So define this operation, which takes a function of X and translates it by L, but leaves it otherwise identical. This is a series that you should recognize, a particular Taylor series for a particular function. It's a Taylor expansion for the AUDIENCE: Exponential. e to the minus L derivative with respect to x f of x. Which is kind of awesome. So let's just check to make sure that this makes sense from dimensional grounds. So that's a derivative withrespect to x as units of 1 over 6. But I'm going to write this in the following suggestive way. This is equal to 1 times f of X minus L. Professor: We're going to do this all the time in quantum mechanics. We'll talk about it in more detail, but we're always going to define it in this fashion as a formal power series. Can you transform operators from one space to another? Professor: Oh, you totally can. But we'll come back to that when we talk about operators next time. But from this what is a derivative with respect to x mean? What does a derivative of x do? Well a derivative is a function of length, so this is dimensionless, so we can exponentiate it. to x is something that generates translations with respect to x through a Taylor expansion. If we have L be arbitrarily small, right? L is arbitrarily small. What is the translation by an arbitrarily small amount of f of x? Well, if L is arbitrary small, we can drop all the higher order terms, and the change is just Ldx. So the derivative withrespect to x is telling us about infinitesimal translations. But through Noether's theorem translations, in x are associated to conservation of momentum. So you shouldn't be so so. shocked-- it's really not totally shocking-- that in quantum mechanics, the derivative with respect to x is related to the momentum in some particular way. Translations are deeply connected to conservation of momentum. Transitional symmetry is deeply connected with conservation momentum. An infinitesimal translation is nothing but a derivative withrespect to position. Those are deeply linked concepts. But I didn't derive anything. I gave you no derivation whatsoever of the relationship between d dx and the momentum. Instead, I'm simply going to declare it. a priori did the world have to look like. Physics tells you this is a good model. And to the degree that it doesn't fit the data, it's wrong. This isn't something we derive. This is something we declare. We call it our model, and then we use it to calculate stuff, and we see if it fits the real world. Out, please, please leave. [LAUGHTER] I love MIT. I really do. [APPLAUSE] A state with a definite momentum has the property that, when you hit it with the operation associated with momentum, you get back the same function times a constant. This is a state which is equal to all others in the sense that it's a perfectly reasonable wave function, but it's more equal because it has a simple interpretation. If we have a state that's a superposition of different momentum and we act on it with a momentum operator, this gives us h bar k 1. So it changes which superposition we're talking about. We don't get back our same state. the momentum. And these coefficients are going to turn out to contain all the information about the probability of the system. This is the probability when norm squared that will measure the system to have momentum k1. So I think the current wave function is something like a superposition of 1/10 psi pirates plus 1 minus is 1/100 square root. To normalize it properly psi no pirates. And I'll leave you with pondering this probability. See you guys next time. [APPLAUSE] eyes, of foot, of eye, of brow. I see the antique pens do but express the beauty that you master now. So are all their praises but prophecies of this, our time. All you prefiguring. But though they had but diving eyes-- PROFESSOR: I was wrong about the probabilities. [LAUGHTER] CHRISTOPHER SMITH: But they had not skill enough you're worth to sing. [APPLAUSE] It's not over. You wait. your memory. Gainst death and all oblivious enmity shall you pace forth. Your praise shall still find room, even in the eyes of all posterity. So no judgment arise till you yourself judgment arise. You live in this and dwell in lover's eyes. May your day be filled with love and poetry. Whatever state you're in, we will always love you. Signed, Jack Florian, James [INAUDIBLE]. [LAUGHTER] PROFESSOR: Thank you, sir.

ROUGE-1: 59.24, ROUGE-2: 56.55, ROUGE-L: 55.87
BERTScore: 73.47

==============================================
==================== [3/100] ====================
Summary:
the Lord Byron George Gordon Lord Byron very interesting very outgoing very flamboyant personality he stood out I mean if you can't tell by looking at that picture you know he was a lot different than a lot of people his back history and such isn't necessarily testable stuff but look I mean it just really shows you how against the grain he was um you know we even saw Wordsworth even though he seemed very dignified such he was against thegrain with regards to his beliefs in his practices in in the literary world. sit back on his on his limits he was able to still push it and he was accomplished in many activities and sports the literary celebrity down at the bottom had spoken that he was a you know kind of born into not necessarily nobility like a monarch or anything but he was born into his title he didn't do anything to achieve it okay Hinda. He was an individual that you know probably was a bit of a celebrity to some degree he had the money he was wanting it he it said that he got in trouble because he had a lot of love affairs going on he kind of ran out his welcome. able to mention you know celebrity wise and so then he finally gets some fame get some popularity and he does a lot of good with it we see on besides kind of self exiling himself from England what things weren't going to also he leads and he travels and stays with the Shelley's that talks about Mary Shelley and Percy shot Mary Shelley wrote Frankenstein and we'll talk about Percy Shelley later this unit but you know so he travelled around I mean one of the most interesting features in this is one how he died really young just from whoo but when he died he was down in Greece training their soldiers helping them for their rebellion. was helping them fight and prepare them for revolution and preparing them for the battle and so we have this individual armed. He was a celebrity of his era probably more so than a lot of the individuals that we read and you can see when it talks about that he was you know his life as well as his literary accomplishments you know were um you know a mother laughter by you know PO on 8th annual Hawthorne Dostoyevsky, Herman Melville and other famous works of the 1800s. "Heath Ledger was a bold person he was rebellious you know in nature and such and you know he had a you know kind of a tragic end there" "He was a very bold and very dangerous individual okay if you look in the right-hand page and I want you to read this page when you have time" "A lot of times when the tragedy is somebody who is young and had some sort of accomplishments" "You know we're brilliant at whatever they did but you know they they died young" literary or you know in the world to some degree that those individuals are you know Byronic to somedegree so we see those qualities and characteristics portrayed in that individual back to his reading on a 8:45 from childe Harold's Pilgrimage gate. The title of the piece is called apostrophe to the ocean and if you remember apostrophes that's when you are directing a statement toward something that cannot reciprocate it remember. The piece is very short look at the title of it okay the right below the subtitle and this is from a larger work. when we did the poems and such Oh moon Oh sleep you know things of that nature you don't expect to be to have a conversation you're just talking to that individual or thing okay or idea I guess it could be like sleep on it so this one is directed towards the ocean okay our childe Harold's Pilgrimage ' to the ocean from childeHarold's Pil Grimage by George Gordon Lord Byron ' tothe ocean. There is a pleasure in the pathless woods there is a rapture on the lonely shore there is society where none intrudes by the deep sea and music in its roar. I love not man less but nature more from these our interviews in which I steal from all I may be or have been before to mingle with universe and feel what I can narak spread cannot all conceal roll on thou deep deep deep. in dark blue ocean roll ten thousand fleets sweep over the in vain men marks the earth with ruin his control stops with the shore upon the watery plain the wrecks are all thy deed nor doth remain a shadow of man's ravage save his own. For a moment like a drop of rain he sinks into thy depths with bubbling groan without a grave uh knelled on coffin and unknown his steps are not upon my paths my fields are not a spoil for him thou dust arise and shake him from thee the vile strength he wields for Earth's destruction. lay the armaments which Thunder strike the walls of rock build cities bidding nations quake and monarchs tremble in their capitals the okhla by Athens whose huge ribs make their clay creator the vain titled take of Lord of thee and arbiter of war these are thy toys. As the snowy flake they melt into thy yeast of waves which Mar alike the armadas pride or spoils of Trafalgar by shores our empires changed in all save thee Assyria Greece Rome Carthage what are they thy waters wash them power while they were free and many a tyrant since their Shores obey the stranger slave or savage. glasses itself in tempest s' in all time calm or convulsed in breeze or Gale or storm icing the pole or in the torrid clime dark heaving boundless endless and sublime the image of eternity the throne of the invisible even from out the slime the monsters of the deep are made each zone obeys thee thou goest forth dread fathomless alone and I have loved the ocean and my joy of youthful sports was on thy breasts to be born like thy bubbles onward from a boy I want. is addressing the ocean the water about how big and how timeless start you know he mentioned on that page and we'll get there. Leviathan is BC in Atlantis remember the cartoon movie Atlantis the Leviathan was the thing that protects it so big monstrous thing and so these ships that are like okhla vaya thens are really just like toys and if you think about it I mean just the sheer size of that water and those waves what they can do you know there are aircraft carriers that're like cities floating cities with tens of thousands of people. essence and a storm can just mess that thing all up if there's a hurricane coming that ship heads the other way tries to get around it okay because it would turn it into like a toy in a bathtub. The 100-year anniversary is coming up here next month of the sinking maybe not the there rerelease in the movie and I'm accessed off 3ds so that's just for you a little bit of extra stuff for today but the apostrophe on page 845 um. you know he's very pleased with the ocean he loves the ocean you know talking about you know there is a you know pleasure and rapture in this and I love man the less but I love nature more but ILove nature more and think back we've talked about this a lot in this particular unit about all of these nature elements okay nature and the nightmares and kids all those things that influence writing and here we have another individual as to why this particular piece is a good representation of that of that era. the man's ruined it stops at the shore okay because whether it's a million years ago a thousand years ago or two years ago we can go out you know thirty feet into the water and look straight out to the water. okay yes we can look at oil platforms now for looking in the exact rights okay man ceases to be able to control that. okay there are people would say you know we've spent more time at the bottom of the ocean or less time. at the body the bottom. is bigger than Mount Everest underwater underwater were you aware of that I mean that's just the scope and size of what's out there okay and just a little boat out there I could do a lot of damage okay a lotof damage could be thrust upon that and really that's kind of what is talking about the the rest of this about the shoe size of it the the ships and man and how nature Trump's all of that. I like the line forty four time writes no wrinkle on diners your brow so like with humans and a lot, it even animals and such that people age. coming in and the sound will be identical in conclusion at the very end he comes back from talking about all of the size in his love for nature and sums it back that you know and I have loved the ocean so just in case you forgot throughout these short two pages to whom he was speaking or addressing we see once again that it is nature and don't forget what an apostrophe is okay remember I told you when we learned it that's hey you're going to need to remember this and people tend to forget for some strange reason.

ROUGE-1: 81.20, ROUGE-2: 78.94, ROUGE-L: 78.07
BERTScore: 83.33

==============================================
==================== [4/100] ====================
Summary:
Allocation is nothing but assignment, allotment, share, but in economics we are more technical about this particular term allocation. So, allocation here means solving these three fundamental or basic questions of economics, and the first question is what to produce? The second is how to produced? And third is for whom to production? Let us look at to answer these three questions one by one starting with what to produced. We imagine a very simple economy. We have unlimited amount of everything, unlimited. amount of resource to produce unlimited amount. of goods. There are only two activities on this island. The first activity is catching fish, and second activity is gather coconut. So, they have several options there; devote part of the time to catch fish or devote all the time that they have to catchFish depending on their need. The next is how to produce. So of course, how this allocation involves making this decision what you produce. The third activity, that they can take up is that, they can fabricate net that would help them catch fish. In command economy essential authority typically, government some sort of government determines, how to produce. In market economy, as opposed to command economy, decisions are made by individuals. Third is mixed economy, here it is somewhat a mixture of command and market-based economy. Now think of it how would you categorize Indian economic system? Do we have command economy? Or we have market-Based Economy? Or do we have mixed economy? Also, it is good idea to think about what we had before 1991, and what we have after 1991. but after 1991 after economic liberalization we are slowly moving towards market based economy, but we are not yet there. One concept that I would like to emphasize here is laissez faire, this is a French word it means leaving it alone. So, individuals transact without any interference of the government. All the economies of this world we can say we can characterize them near to command economy or marketbased economy. But truly speaking none of the economies are purely command Economy or purely market Economy. the government. So, this is a concept, an extreme concept that we typically do not find, but you would see in newspapers talk about moving towards laissez faire or moving away from laissezes faire. The government. is not a government, it is a body that has the power to decide what happens to people's lives. The. government is not the government. It is a group of people who have the power. to make decisions about peopleâ€™s lives. It has the ability to make changes to the law.

ROUGE-1: 61.65, ROUGE-2: 53.62, ROUGE-L: 48.48
BERTScore: 70.45

==============================================
==================== [5/100] ====================
Summary:
Random variables are an absolutely fundamental concept in probability theory. Let's start off with an example that in fact is a game because that's a fun way to start. We're going to play the bigger number game and here's how it works. There are two teams, and Team 1 has the task of picking two different integers between 0 and 7 inclusive, and they write one integer on one piece of paper. They turn the two pieces of paper face down so the numbers are not visible, and the other team then sees these two Pieces of paper whose other side has different numbers written on them. and turns it over and looks at the number on it. And then, based on what that number is, they make a decision, stick with the number they have or switch to the other unknown number on the face down piece of paper. And the game is that Team 2 wins if they wind up with the larger number. So which team do you think has an advantage here? Course, if you've read the notes, you know. But if you haven't been exposed to them, you don't know. this before, it's not really so obvious. And if you have the opportunity, this might be a good moment to stop this video and try playing the game with some friends if they're around. Otherwise, let's just proceed and see how it all works. So this is the strategy Team 2 is going to adopt. They're going to take this idea about big and small that I mentioned and act on it in a methodical way. So they'regoing to pick a paper to expose, giving each paper equal probability. Team 1 can't try to fake out Team 2 on where they put the number. Team 2 is going to decide whether the number that they can see, the exposed number, is small. And if so, would they switch? And otherwise they stick. So that guarantees that they have a 50/50 chance of picking the big number. And that's true no matter what Z you take. If Team 1 knew what your Z was, they would just make sure to pick their two numbers on the same side of your Z. The most interesting case is the middle case. That is, when your Z, which was chosen at random, happens to fall in the interval between low and high. And then in that case, your Z is really guiding you correctly on what to do. If you turn over the low card, then it's going to look low because it's less than or equal to Z so you'll switch to the high card and win. But if you turn the high cards over, it'll be greater than Z so it'll look high and you'll know to stick with it. So in this case, you're guaranteed to win. And so the probability that you win, given the middle case occurs, is 1. Now, in case H, that's the case where Z happens to be chosen greater than or equal to the high number that Team 1 shows. Well, in that case, Z just isn't telling you anything. So what's going to happen is that both numbers are going to look high to you. And that means that you'll win, if and only if, you happen to turn the low card over first. variable Z was a thing that took a value from 0 to 6 inclusive, each with probability 1/7. So it was producing a number by a random process, that chose a number at random with equal probability. If Team 2 plays properly at random picking which piece of paper to expose, then the number of the exposed card will also be a random variable. And if Team 1 plays optimally, the number on the expose card is going to be aRandom variable. That is, Team 1 in their optimal strategy that puts an upper bound to 4/7 is in fact, going to choose the two numbers randomly. picks its larger and smaller cards randomly, it's going to be another example of a number produced by a random process. And likewise, the number of the smaller card. So that's enough examples. This little game has a whole bunch of random variables appearing in it. And in the next segment, we will look again officially, what is the definition of a random variable? We will also look again at the concept of "randomness" in the game of cards and dice.

ROUGE-1: 50.87, ROUGE-2: 48.74, ROUGE-L: 49.04
BERTScore: 79.32

==============================================
==================== [6/100] ====================
Summary:
foreign and I should turn off the zoom background blur Ry options like this oh it does show up uhYeah there's like speaker notes on your screen but there's be careful because I accidentally just put something else in the first longer okay I don't have too many but yeah there's an interview oh this is where it has speaker notes and stuff I think it's fine. I just think I was just too ready to go I usually uh yeah as our slides were they and put which is the product describing to replace the names of it. yeah party on pictures are good first time we got foreign foreign foreign things okay let me make sure it's it was obviously I think it is for the most part of it that's something the green and the yellow look identical we can go to something different oh my gosh it's mine started oh do you want the mic um I think you should be fine though what hello hello all right so I think we can get about started here I want to start today uh before we get into like talking about uh more advanced CNN architectures I wantto start by sort of recapping what we talked about last Tuesday. review um convolutions and and the architecture of a CNN to make this more clear and put it put it into perspective how it relates to um just standard um dense neural networks I think it's fine um so we talked I think I think most people felt okay about um the actual mechanics of doing a convolution um and I just wanted to sort of clarify that when we do a convolutions operation um we treat it like a layer like with standard dense neural network uh we treated matrix multiplication as sort of like a layers where all the Learned parameters were all the values in our Matrix. and we also have a bias term that gets added to the output of moving each window on each location of our input we refer to it as a volume simply because it sort of looks like a cube um and I wanted to to reiterate this idea that again if you have a whole bunch of different filters you're going to get an output map for every location that we started and put our our filter where every locations that it overlapped. If you have one filter you'regoing to end up stacking up all of the different outputs from taking each one of your different filters. again you can kind of think of this as like a layer of a neural network so after we're done doing this we're still going to add our activation function like array Loop or or something else. We can still take partial derivatives of our loss with respect to our parameters and do gradient descent. When you have images and a CNN you can simply just do convolutions instead of your normal matrix multiplication. which is demonstrated up here. You do convolution followed by your activation functions you have pooling layers. if you want to decrease the size of this volume because it can get quite unwieldy it's much quicker to take this convolution you can do pooling simply just looking at each if you have a two by two pooling you're just going to look at every channel. Every filters has its own bias so basically every everything yeah you canYeah you can just chop your output in half um and were there were there questions on on this on the sort of mechanics of like what does CNN is and what it what it looks like mechanically um yes friend. think of it like that I I don't really think of it as like like after we're done doing all the element wise multiplies um from overlapping our filter with our input uh we then just add the bias corresponding to that filter onto it but yeah that's like in that's probably an equally as intuitive way to do it. Just add the corresponding bias to the corresponding Channel the correspondingChannel and the output yeah. But again the big the big thing I really want to get across is that you treat it just like another layer um you're just gonna stack a bunch of them um and then eventually when you want to getting to the end you take this volume and you just unravel it in a very specific way. regular matrix multiplication um at the end yeah yeah no really um it's just there because like if we if we have like a huge input that's like 256 by 256 I think it's like huge. The output assuming you don't do a strided convolution which is just taking your filter overlapping in this case a three by three area and instead of moving over one to overlap in the next era you move it over two. That just immediately cuts the whole thing in half on your height and width axis so you have a quarter as many values now. but it's still ideally still sort of captures all the main information that was in that uh that feature volume um yeah it's it's more just used so we can get our feature volume down to a reasonable size so it doesn't take forever to run convolutions on it just makes it a lot quicker yeah no well so we're going to talk about um segmentation which is where you have like an image like a person in it and you need to Output another image except each pixel has basically been like labeled with like there's a person inside of like here and then everything else is background so in that case your output is the same size as your input which gets a little bit weird. different activation Maps one from each filter that we obtained so your your Channel's Dimension uh would be 10 Deep um yeah it just corresponds to like if if if this filter is corresponds to horizontal edges and this filter corresponds to edges like this. You can just sort of look along the channel and see like okay like was there an edge that went this way was there a feature that went in this way or this way. They just correspond to what the filter what that filter in the previous layer picked up on does that gonna make sense? This is a survey on the history of neural network architectures for computer vision. We're going to be talking about alexnet BGG, Inception Nets, mobilenets and Landing with with resnets. None of these are state of the art on imagenet now but this is understanding the motivation behind these really sets the stage for the future of advancement in this field. Any more questions then I will hand it over to Rohan who's going to talk about um more advanced CNN architectures. have and lastly come up with a prediction or a model that can be used to predict. Now you have a feature map that corresponds to different classification metrics so there are some observations there's only five convolutional layers. The next slide should have an updated drawing that's hopefully a lot easier to understand than the previous one um but this has a convolutionsal layer followed by a Max pooling layer. Three Hefty dense layers are following this last stack of convolutions and Max pooled and that results in a lot of parameters. up quite a bit this also means that the number of computations that you need to do stacks up. Only having five convolutional layers and three dense layers really limits the amount of information we could synthesize by our feature Maps. We want to be able to have our model learn higher order feature maps and by that I mean low level features um like edges things like that but as we go higher we're starting to see the correlation between features and computations get higher and higher. like color spaces um how edges lead to other forms and things like that yeah this is basically about what like what I was talking about um there's a lot of space that we want to have. We want to uh go through this architecture um so yeah this this this is hopefully a lot easier to understand than the previous drawing and it's saying the same thing so you have um a this is a 5x5 image with three channels with 3 channels similar to what Jake is drawing here actually. convolutions which don't change Dimension you Max pull at the end of that and then you go into the concept that Jake was talking about earlier which is flattening. By unraveling the final kind of layer that you have your and you end up with a one-dimensional Vector instead of whatever you landed up with after your convolutions. These are then passed through three dense layers this is what we were talking aboutEarlier and lastly passing to a soft Max function so up until this point all of the activation functions are religious or rectified linear. soft Max will scale more logarithmically um and it'll give you a final like probability map. If you don't specify a certain type of padding valid padding is going to be applied to make sure that as you're sliding your kernel across an image uh you're left with the same dimension is there anything you want to add Jake or no that's I I should have mentioned adding two yeah I mean you did a good job we basically just had a bunch of zeros on the outside. your image um yeah and as you can see uh we use a relu activation all the way until the end uh vgg is you can think of it as a deeper Alex net um there's not too much to go over here. The motivation behind this is you want a deeper neural network um that's kind of the purpose of this now instead of five convolutional layers you have 23 you have the three dense layers at the end which computes a little bit better because computers evolve CPU power is able to handle these high order Matrix computations. one by one convolutions can actually be used as a form of padding and dimensionality addition and reduction. We do want a higher accuracy we want a deeper Network we want something that is able to effectively both space and time effectively compute these Matrix productsYeah so yeah and you're also adding pixels to uh the the top and bottom as you're sliding if that makes sense there is a yeah there's a picture on the next slide I believe uh uh okay yeah yeah so a one by one conclusion. the important thing the channels change though oh right the number of filters that you have and my channel yeah you won't change the actual size of the image Dimension the depth of your like yeah depth is kind of how I think about it but in reality is channels that are gradiently moving. So based on your kernel size your actual image is shrinking but your number of channels increases as you gain information um as you can see in BGG 16 specifically it looks like the size is approximately getting halved every time. visualization of how you have multiple layers that are stacked they're pulled together. As you apply your kernel of size two by two you're increasing the number of channels and information that you're getting. Lastly you're passing it into three dense layers to do those major Matrix multiplications at the end post flattening all right so um Inception Nets uh this drawing is also quite complicated um but what you need to take away from this is that you want to be able to use one by one convolutions to keep your input size the same. discrimination in lower stages um increase the gradient signal that gets propagated back and provide additional regularization um the motivation behind this is that again we want to learn low level features. There are a couple of common issues that can uh kind of result from just blindly stacking layers um so you might ask uh we saw Alex Ned and we saw bdg which was like basically the same thing but we added a couple more layers. Why can't we just infinitely stack these layers um and there are a lot of answers to that. problems that come with that that Inception and resonance um try to fix and that is adding residuals yeah uh what do you mean by branched uh yeah the classifier is at the end uh by this uh again there's there's a drawing for it but uh essentially you have a yeah yeah you've a multi-headed yeah so you're you're taking whatever your input is in a certain step and applying it to the output of another step. This maintains kind of a about it's a backwards way of maintaining a residual value. about before adding more layers shouldn't hurt because the layer can learn the identity transform which is essentially how you're transforming a certain input in every step. Vanishing gradients is a common problem as you add a bunch of layers stacked together and that the learning signal or the gradient computation becomes extremely weak the model struggles to learn. The other side of this problem is explode ingredients which isn't as applicable to this but another problem a third problem is shatter ingredients and the the the point of shatter. ingredients is that as I go deeper into an extremely deep convolutional neural network my gradients actually start resembling white noise so there's no pattern my model isn't actually learning anything because of the depth of the network. This is where residuals come into play that's why it's called resnet the solution is make it easier to learn at least the identity so keep information from previous stages into future computation that's like the the the key motivation behind residuals so yeah this is what I was talking about earlier. relief activation function um as your X goes through a weight layer the function is applied you go through another weight layer this f of x kind of encompasses that process this is the function that you've applied to X now your output is whatever f of X is the motivation behind residuals is that after your f ofx has been applied you add X back into your network um so by multiplying or by adding the resultant X by whatever your original identity was and using that as the input for the next layer you've maintained a semblance of what you had prior to whatever function you'd applied. residual that's being computed. A 34 layer residual will have jumps between every two. This is a process known as bottlenecking versus if it was after every layer. Adding residuals will increase the time to convergence because you're increasing the number of backwards considering computations that you have so if you're if your bottleneck isn't as big your time to converge will be smaller so as your uh as your residual skips more and more levels your time of convergence will also be smaller but your results may also not be as good. because you're not negating the problem this is highly dependent on what system you're using to compute these as well as where the model is eventually running so yeah um yeah dude that was an example of a very long uh residual net adding skip connections makes the identity easier to learn because you're quite literally adding a previous identity to the resultant of a transformation. As you can see this is a gradient map uh the Lost surface of resnet with and without skip connections with and with skip connections. event like a low dimensional projection s yeah yeah this is like probably like really important thing for today but like this idea of like why it'd be important to sort of be able to learn the identity like it's sort of a weird thing um are there any questions or comments or concerns about that yes yeah for sure right so like if you have a dent snail Network like like let's just ignore convolutions right now if you like a dense neural network trivially you have the identity Matrix which is just ones along the diagonal and it spits out the exact same thing that it took in. so like if I have a neural network and I just trivially add so I have like a whole bunch of like layers right like this this new connection to the next layer right like just a dense neural network. If I just make each layer like the identity Matrix if I make all the weights correspond to the identityMatrix like there's no reason I shouldn't be able to make like a million length neural network which is kind of absurd. But like in practice we've observed that like if you add if you put a million layers on a dense Neural network it's going to just learn like garbage like it's not going to work at all. took in it's just kind of curious that it was observed that deeper networks don't work and this makes it super easy so if your weights are literally all zeros and your biases are literallyall zeros you're going to spit out exactly what you took in so it makes it really really easy for the network to just say like hey okay we've got enough information at this point in the network like we don't need to learn more complicated features I could just send the weights to zero and just ship exactly what I have about halfway through the network. like okay like we've got enough information to like make a good classification but we're only about like halfway through the network with with this it's just super easy for it to learn. "It's just something you can tune and there's like foreign so like if you're doing the chain rule it just results in a lot of multiplications right like the more like um like we talked in the third lecture about applying like the chainRule um to deep neural networks" "If you know exactly like how many years to have in your block here yeah so I mean resnet just used two uh two is a fine Choice" step in your network if you just multiply the partial derivatives of all of those steps you can find the the derivative of your loss with respect to a given parameter just with the chain rule. If all of these different things that you're multiplying are even a little bit smaller than one immediately like at a certain point at acertain number of multiplications your partial derivative uh your chain rule that you've gotten as a result of many many multiplications just gets sent straight to zero. That's just not helpful. is like sort of uh sort of regular a little bit more consistent um so that our weights aren't either just exploding because the gradient steps are huge or they're just literally never going to change. If you're stacking like a bunch of sub 1 multiplications you're going to be left like a super small number as you go back. It doesn't necessarily mean you're close to a minimum either like because your lost surface can be like a little Plateau it just means that for some of our our parameters really early in our Network. well um and it's probably like a bigger contributor to like stopping the vanishing gradient problem then uh and residuals but like residuals help I think residuals are more for like shattered gradients so that's when like you introduce a bunch of like meaningless noise into your gradients. It comes from again like the the depth of the matrix multiplication that you're doing uh so without like by losing form of the identity. That is the reason that stacking a lot of layers doesn't result in like better performance or strictly better performance. shouldn't produce accuracy when in reality like if this is scaled it can yeah awesome group wise uh your Dimensions so yeah this is a really good point um so if your layer is a convolution um the dimension can change which is why often this is result like kind of viewed as f of x plus W of X where W is a transformation that you do on X two to make it the same Dimension exactly. To make sure your Matrix addition stays the same like like basically you have like the X number of layers and things like during the state. you're not necessarily zeroing out uh learned weights uh this like Jake was saying like other ways of uh normalizing your data as you go through like Bachelor affect the vanishing gradient problem more than residuals do the main point of this is that you want to maintain a semblance of identity as you going through your network if that makes sense. This is often viewed as plus W of x there any other questions about resnet all right dope uh so the next thing to talk about is global average pooling which is designed to replace fully connected layers in cnns. the vector that you want to classify your classification Vector you're generating a feature map for each of those averaging those and then that is fed into the softmax layer um this uh the typical dense layer that you previously had that's facilitating these connections does not enforce correspondences between feature maps and categories. As you go through the three dense layers at the end of the network there's no parameter to optimizing global average as well which saves overfitting time. In dense layers this often results in if I have a very deep neural network that is trained on a certain subset of data. at the end it's very easy to overfit to the data that I have provided uh for training um so this kind of prevents that. This comes more into play also in Mobile nuts and uh the efficient that's that will be talked about as well. There any questions on the previous kind of topics all right all right that was kind of the meat of this lecture uh but mobile nuts are very cool in that you're you're using depth wise convolutions and point-wise convolutions to reduce the number of computations. number of uh computations that we need to do the answer is depth wise separable convolutions so this is a a pretty decent visualization of how that works if you have like a three channel uh like some X by X image you're applying a uh like a feature map to it um that results in one product and then you're left with one product by one channel. Instead of that what if we took each Channel individually we applied a smaller or a lower Dimension feature map uh to it created three depthwise layers and then combine those with a convolution. efficiently uh and there's a little example that will hopefully show how the math behind this works. So essentially yeah if you're involved by 12 by 3 image and a like five five three feature you would have to do and this result in an eight by eight by one at the end of your process. This would then be multiplied by 256 times or however many channels that you're doing. If that makes sense, there's some visualizations on the next slide that make a lot more sense. generally work I'm running a thin one by one by three layer here so this is 64 times three it's 192. and this is what is being multiplied by the 256 and added to our previous product which is 74 times 64. so these two are being added together to end up with your your final computation for how many I guess multiplication parameters you have other questions about this yeah. So mobilenet has a lot fewer parameters which results in a lot faster convergence time um and it matches Inception of D3 accuracy just by using depth and point wise convolutions and combining. those so you can think about it instead of doing one step that results in one map and multiplying that by the number of filters you have you're not doing that. You're applying this one step to every channel and then your next step is applying a different sized convolution to do your filter multiplication so instead of one you have two steps that are being combined which reduces complexity quite a bit alrighty I guess we can quickly go over like squeezing anxiety networks basically uh you squeeze you apply this through a couple of dense layers and then you rescale so we talked about global average pooling. connected layer passing it through relu and with a fully connected layer you can also expand this back to whatever Dimension you originally had um rescaling according to the layer output is also not as computationally intensive. I think the slides are pretty good and compressed in a very visual way uh the remainder of the piano more impressive art it's actually the other way. I I hope the main takeaways are that you'll like understand those rules and that you you see that we've like adding all of these different sort of like tools to your tool belt now. CNN.swap out if you're very well CNN building plus. I think understanding like the the base of how optimizations are held and the problems that certain optimizations face and others don't really sets the stage for like future networks like the efficient net in 2020. We can straight up just go by what we've already learned in that we know we can pass through a one by one convolution a depthwise convolution which is where we apply this filter to each Channel individually and recombine them using our squeeze and exide networks. so these are some things that these models wanted to optimize over time accuracy performance and model size um model size is something that has a trade-off if you get too big you lose out on other metrics like accuracy. performance is something directly corresponds to depthwise convolutions and mobile nuts for Edge Computing and things like that. You want to drastically reduce the number of computations that you want to do yep that is basically everything for today thank you guys for coming oh and there will also be a quiz.

ROUGE-1: 71.09, ROUGE-2: 68.58, ROUGE-L: 69.62
BERTScore: 81.64

==============================================
==================== [7/100] ====================
Summary:
Three breads will be made with a brief mint which will be left for 12 hours to ferment then it'll be mixed into the main dough. The main comparison I want to do today is between the two breads which will take the same amount of time to make the one with the bereavement and the one that will be well fermented in the fridge for 24 hours. My opinion is that using a bereavement when cold fermenting makes no sense because we can simply leave the dough in the refrigerator for longer. Both breads will take about the same amount of time to make but why are we doing this a while ago I posted a video comparing prefix and fermentation in that video I concluded the Callback fermentation beats bereavement in every way it develops far more flavor it makes the crust crispier and the crumb most substantial and it simplifies the process because we don't have to make a separate thing. As soon as I publish that video people started asking me about combining the two methods I always told everyone just leave your DOTA for men for longer why make that preferment. Cold fermentation versus brief mint there is no better method. fermenting the whole dough makes the bread more chewy but at the same time it boosts flavor quite a lot. using a Polish improves the flavor slightly but it gives the bread a much lighter and airier crumb or at least it is able to and it can make for a thinner crust too all great characteristics of a baguette. I'm a bit biased just because I like to simplify the process and I prefer the results from cold fermentation. baker or up to the person eating the bread but when it comes to combining Cobalt fermentation and bereavements that's where I say simply fermenting for longer is better than using prevent and then fermenting the dough in fridge. I've said that with confidence even though I had not tried the side by side obviously you can only find this out by trying it yourself my taste buds are different from yours but let's just get back to our three does here so the one on the left has been in the fridge for 24 hours the one in the middle was made with the bereavement which took 12 hours to rise. use slightly less yeast in the dough that was made with the bravement and that was to compensate for the amount of yeast coming from the bereavement itself as it rises it multiplies so I thought technically in the end the double debriefment would have more yeast in it. If you want to find the written formula it is in the link below the video title okay we'll do the final shaping now we'll Place those in love tins we'll let them rise and that will bake them kind of a short video today. when cold fermenting and I'm pretty sure there is is a yes or no question so here we go we got our three loaves they all look pretty much the same on the outside and obviously they have all split open on the side too they were a bit underproofed which doesn't make any difference in this test it is the fermentation time up until the final proof which really counts now cutting them open I can tell you that the crust on all breads is exactly the same next up I smell them all see if they smell any different I did not feel any difference between a 24 hour fermented one and the one with the bereavement. comparison for yourself then tell us of your results you might be surprised. What do you think of my test and my results have you ever tried something like this before do you use preference when cold fermenting let me know down in comments. If you want to see more videos like this one click over here subscribe to the channel click right here that's all I have for you today thank you so much for watching I'll see in the next one and I'll be back in a few days.

ROUGE-1: 70.21, ROUGE-2: 68.11, ROUGE-L: 67.16
BERTScore: 75.17

==============================================
==================== [8/100] ====================
Summary:
Bayard Rustin was the chief organizer of the 1963 March on Washington for Jobs and Freedom. Rustin grew up in a Quaker household, and began peacefully protesting racial segregation in high school. He remained committed to pacifism throughout his life, and was jailed in 1944 as a conscientious objector to World War II. In 1948, he traveled to India to learn the peaceful resistance strategies of the recently assassinated Mahatma Gandhi. He began to work with Martin Luther King Jr in 1955, and shared these ideas with him. As Kingâ€™s prominence increased, Rustin became his main advisor. Rustin was passed over for several influential roles in the 1960s and 70s, but he never stopped his activism. In the 1980s, he publicly came out as gay, and was instrumental in drawing attention to the AIDS crisis until his death in 1987. In 2013, fifty years after the March On Washington, President Barack Obama posthumously awarded him the Presidential Medal of Freedom, praising Rustinâ€™s â€œmarch towards true equality, no matter who we areâ€ are or who we love.â€ â€œIâ€™m so proud of you,â€ she says. â€œYouâ€™re so beautiful.â€™ â€œâ€œI love you, too,â€™ I say. I love you so much.â€œâ€ Iâ€™ll always love you.â€‰â€I will never forget you. â€â€â€œWeâ€™ve been through a lot. Weâ€™d rather be here than there. â€™â€™â€

ROUGE-1: 43.68, ROUGE-2: 39.95, ROUGE-L: 40.33
BERTScore: 63.11

==============================================
==================== [9/100] ====================
Summary:
Deuteronomy describes Israel as a holy people, separated from the common or the ordinary. Intermarriage with the Canaanites is prohibited in Deuteronomy. All alien practices are to be removed from the covenant community. The privilege of having been chosen or singled out entails obligations and responsibility, Professor Hayes says. The idea of a superiority complex, a moral danger involved in the notion of election, she says. It is by no special virtue or merit that Israel has been chosen, she adds. that Israel was the one chosen. Moses admonishes the Israelites not to suppose that their inheritance of the land of Canaan is due to their own powers, or on account of any righteousness or virtue that they possess. Israel was chosen by Yahweh in an act of spontaneous love--;it does not imply her perfection. And the election was entirely God's initiative and is no cause for Israel to boast. So Deuteronomy 7, verses 6-8 read: Of all the peoples on earth the Lord your God chose you to be His treasured people. Moses later warns the Israelites: Don't be tempted to say to yourselves, "My own power and the might of my own hand have won this wealth for me" He emphasizes, it is only because the wickedness of the Canaanites is so great that the Lord has to drive them from his land, and now he is giving you a chance. But it is conditional for you, just as it was for them. Don't fail him or he will, he says. "The Lord has enabled us to possess this land because of our virtues," Moses says. drive you out just as he drove out the Canaanites. That's a theme in Deuteronomy. God's providential love and care for Israel is expressed through various metaphors in the Bible. So in a way, the language we were just referring to was really the language of husband and wife, you know, someone who simply loves someone, not because they are perfect, but that is their. But we will get to that in a few lectures, how important that idea is for the Deuteronomistic historian in general. choice. They love the person, and they make a bond with them. It does not imply anything about other people. It is simply that is the person who has been the focus. So we have a lot of sort of love and marriage imagery, husband and wife imagery, used for God and Israel. But we also have this parent and child imagery that appears. In Deuteronomy 32:10, the image is that of an eagle that bears its young on its wings.â€¦ It almost seems to play on the idea that God and his children are one and the same. At the end of Deuteronomy, the promises still are not fulfilled. The people are still outside the land. Some have suggested that this is quite purposeful. It points to an exilic date for the work's final composition. When it was finally redacted, the redactors were in exile, writing for a people living in exile. And the Deuteronomist was a man of the people, a man who had lived in exile for a very long time, and had to deal with the exile himself. Deuteronomy is not simply the concluding book of the Pentateuch, or the story that began in Genesis. It's also the first part of a much larger, longer literary work, as I mentioned last time. And we are going to consider today the program and the work of this so-called Deuteronomistic school. But before we do that, I wanted to just make a few concluding remarks about source theory and the Pentatesuch. We have talked about the Documentary Hypothesis. of times are some of the debates that occur on the question of dating. There is a great deal of ideological baggage that is involved in the dating of the sources. One of the issues that I think is a real problem is the fact that the Priestly source, P, is so often misjudged and maligned. I hope it gave you a sense of its communal ethic as opposed to an individual morality. But the anti-priest, anti-cult sentiment, of European Protestantism, is apparent in the history of biblical scholarship. Wellhausen: Priestly source represents a late degenerate stage in the evolution of Israelite religion. He argued that in 586, with the destruction of Jerusalem and the people were taken into exile in Babylon, that was when the priests were able to assume control. Wellhausen says the priests built a new identity and religion that stressed the sinfulness of the people, and the need for ritual purity and ritual observance and legalism as the road back to God. And this, according to Wellhauson, was a degeneration. that all scholars who date P to the post-exilic period are motivated by the same problematic assumptions. That is certainly not the case. There are scholars of all stripes and allegiances who view P as late; and there is some very good objective evidence for dating parts of P and D. So when it comes to dating the sources, certainly I would say all scholars agree that the Priestly materials reach their final form in the exile or post-Exilic period. So that is the sixth century, right? the sixth century, the bulk of the middle of the sixth century. P espouses a communal ethic, and post-exilic priests are going to turn increasingly to an individual ethic. Many sections of P do not seem to assume a central sanctuary. Remember that the idea of the central sanctuary really took hold in 622, with Josiah and Josiah's reform. So it becomes a real watershed for us in dating texts. Texts that are happy with the existence of shrines throughout the land of Israel are probably pre-Josiah, pre-622. P contains no universal ban on intermarriage. It does not employ its purity laws or language to mark an inseparable boundary between classes within Israel or between Israelites and gentile others. The use of purity and purity language to inscribe boundaries between Israel and other nations is very characteristic of the post-exilic period. We are going to see that when we get there. So I think that instead of charting an evolution or a degeneration from JE, the pure spirit-filled religion, to D, the humanitarian, ethical religion. cultic obsessiveness and guilt-ridden legalism, as is done or implied in some classical source theory. It may be better to see these three as really representing three distinct and roughly contemporaneous strands of ancient Israelite tradition and experience told from their own perspectives. These materials were transmitted and developed by different circles within Israelite society over centuries, and they crystallized at different times. JE has fragments that are quite old, but it probably reached its final form before the centralization of the sanctuary. traditions, but reached its full and final form in the exilic or post-exilic period. Each of these complex, multi-layered sources possesses its own emphases, its own agenda and its own perspectives. Sometimes they complement one another, sometimes they challenge and contradict one another. Their diversity has not been flattened or homogenized by the final editor of the text. It has been preserved in a manner that stimulates reflection and debate. The Latter Prophets is a collection of books, each of which bears the name of the individual whose prophecies it purports to contain. redaction of these books, would put the materials together by inserting verses and speeches that would frame the older sources and link them together, give them some sort of common uniting thread. The redactors' linking and framing passages exhibit certain common features. They harp on the same themes over and over again. And those features and assumptions have a lot in common with the book of Deuteronomy, and that is what led the German scholar, Martin Noth, to surmise that Deuteronomic and these historical books really form a unit. The interpretive history that runs from Joshua to 2 Kings is based on ideals that are set out in the book of Deuteronomy. The whole unit, as a whole, was redacted after 622: that's clear. It assumes and insists upon the centralization of the cult. The last dated event that is mentioned in 2 Kings was when King Jehoiachin was released from prison in Babylon, in 562. So the work was probably concluded shortly after that date: so in exile or towards the end of the exilic period. or even more, successive editions of this history because there are multiple perspectives that seem to be represented. The last seems to be an exilic perspective, the perspective of someone sitting in exile and we will be returning to that in a future lecture. Some of the books within this very large unit are less influenced by Deuteronomy and its themes and its concerns. But I encourage you to read the excellent introduction to the Prophets, the section of the Bible "The Prophets" which was written by Marc Brettler in your Jewish Study Bible. obedience or disobedience to the covenant with Yahweh. And that conviction is going to color its presentation, its evaluation and its interpretation of Israel's history and her kings from Joshua right through to 2 Kings. Yehezkel Kaufmann uses the term "historiosophy" which I have written up here, historiosophy, to describe this material. It's seeking to ascertain the meaning of events to draw larger philosophical, ideological conclusions from the events of history, and to point to the larger purpose of history. means for us today that it did happen. So the Deuteronomistic history is not simply a history of Israel until the destruction of Jerusalem, it is a historiosophy. It is making an argument and it's attempting to communicate the meaning and the significance of the events of that time. It does so through a pattern, a literary pattern we will see, of reward and punishment. This is an important point, and as we begin to go through the material, we will be coming back to this. There is also a belief in the divine election of David as the king of Israel and his dynasty. In Genesis through Numbers none of the legal materials say: when you have a king this is what he shall do. It is only the book of Deuteronomy that assumes or prepares for a monarchy. Another theme that we see in these books or feature of the Deuteronomistic School is the emphasis on what we call the Yahwist prophets -- prophets like Elijah and Elisha. They are held up as heroes and champions of religious purity. because they maintain cults that rival the central sanctuary of Jerusalem. And this is going to be what does them in. The other theme that we see throughout the Deuteronomistic material is the negative presentation of the Canaanites. But we will talk more about who these Canaanites were and how complicated, in fact, that presentation is. To gain an understanding of some of the issues involved, and the emergence of a tribal structure in the land, it's helpful to know something about the geography of Israel. In the past 4000 years more wars have been fought for the possession of the tiny strip of land known as Canaan. Canaan is about 150 miles long and 70 miles wide, about the size of Rhode Island. Control of these international highways brought a great deal of wealth to the area. In times of peace it would bring prosperity, but, of course, in times of war the land was perpetually invaded as armies would crisscross the land going off to do battle with the great powers.. Egypt boasts great geographical diversity. There are three main geographical subdivisions. You can see them on your map, and they really run in strips from north to south. If you look at your map you will see first on the west side, you've got a low coastal plain. That area was controlled by Egypt at the purported time of the Exodus. Next to that coastal plain is a region of low mountains. These low mountains are cut by some valleys that sort of run east-west. Jezreel, in particular; that was a particularly fertile valley. So the valleys that cut through the mountains are extremely fertile. The Plain of Megiddo also joins with the Valley of Jezreel. That is the most fertile part of the country, but it was also the site of many of the most bloody battles in Israel's history. Then next to that north-south central hill country, you've got also running north to south, what we call the Great Jordan Rift Valley. And the Jordan River runs through this valley. This is because the water is 25% salts and minerals. So it is a very desolate area. Tradition identifies this as the site of Sodom and Gomorrah. The area around the Sea is basically semi-desert. We call this the wilderness, the wilderness of Judea between Jerusalem and the Dead Sea, the Wilderness of Judah or Judea. Being somewhat isolated, the inhabitants of each region developed a distinctive economic and cultural character. You have the small settled farmer in the more fertile areas, you have semi-nomadic shepherds. city dwellers. You have merchants and traders who are handling the commerce on the trade routes and enjoying broader cultural contacts. So that's the geographical setting for what we are about to read in the Book of Joshua. The structure of Joshua is really somewhat simple. We can really divide it into two major parts. The first 12 chapters form a unit that conveys the invasion and conquest. The story of the Battle of Jericho is really a composite of two accounts that have been woven together into a single narrative. According to the Book of Joshua, Israel's tribal structure assumed its classical form at this time. The account of the conquest in Joshua 2 through 12, is concerned to express the basic idea that Israel's victories would not have been possible without Yahweh, without his wondrous help. The first half of the book of Joshua contains a streamlined, idealized account according to which the Israelites managed to take the central hill country, confining the Philistines to a little strip here on the coastal plain. just one small area. In Joshua 13:1: Joshua 13 opens with the statement that Joshua was old, advanced in years, and there was much of the land remaining to be possessed. In Judges 1:8 and 21, we read that the people of Judah did this (conquered the king of Jerusalem) and that despite that victory they failed to actually drive out the inhabitants, the Jebusites, who lived there. And it is not until King David, 200 years later, that we will read about the capture of Jerusalem. of the places from which the Canaanites were not expelled. Also archaeological evidence contradicts the picture in Joshua. Excavations at Jericho and Ai indicate that both of these towns were laid waste at least 200 years before the probable time of Joshua. Some of the sites that are said to be destroyed by Joshua and the Israelites weren't even occupied in this period, the late Bronze Age, beginning of the Iron Age. So the conclusion one can draw from all is that the Bible is wrong. The formation of the nation state, Israel, was much more complicated than the picture that's presented in Joshua 2 through 12. Scholars have proposed three possible models to explain the formation of Israel. The first is an immigration model. This was first posed by German scholars. Well, we do know that at the end of the late Bronze Age, the Israelites, it's thought according to this model, would have entered and they would have occupied the very sparsely populated central highlands. They would slowly have begun to take control of the plains. beginning of the Iron Age, around 1200, this was a time of great upheaval throughout the Mediterranean world. Many are sailing from mainland Greece and from the Greek Islands, and they are flooding this area. They are referred to as "peoples of the sea," coming in from the sea, from islands and coastal areas of the northeastern Mediterranean. One of these groups inhabited an area here: Perasta or Pelasta. The word "Palestine" comes from this, Peresta, Palesta or Philistines. The idea of the immigration model is that Hebrew settlement would have probably occurred at about the same time in the latter part of the thirteenth century. The Hebrews could take advantage of all of these upheavals and the weakened hold of Egypt. Egypt had control of this area but their grasp was weakening with the flood of people coming in from the sea and other migrations. Their hold was weakening and the Hebrews would have been able to take advantage and enter in and occupy areas in the central highlands. model, again, is the archaeological record. Archaeologists have, indeed, found several sites in the central hill country -- which is pretty exciting-- and they were clearly newly established in the thirteenth, twelfth, eleventh centuries. Some have suggested that Israelites escaping from Egypt may have joined with these disaffected Canaanites in revolt, known as Habiru. A final model, then, is a model of gradual emergence, which simply holds that Israelite were basically Canaanites who had developed a separate identity. of Judges, you will read of a temple to Israel's God, the God of the Covenant. The word "berit" means covenant. So in short, we really may hypothesize a union of cultural, religious and ethnic elements. All of these would come together to produce what would be a new political and religious reality called Israel. If so, why does the book of Joshua provide such a different account, one of outside conquest by means of a war led by a man named Joshua? by the hosts of the Lord? Because in this account military skill is much less important than ritual preparation and purity. The conquest is represented as a miraculous victory by God. That's emphasized in Joshua 24:12. It was God, not the sword or the bow, that drove out the enemy. And why the claim of the utter destruction of the Canaanites when evidence points to close Canaanite origins? This practice, which I mentioned before and is known as herem or the ban, is not unique to Israel. century BCE, written by King Mesha of Moab Moab is to the southeast of the Dead Sea. In the inscription he writes, he boasts: "And the god Chemosh said to me, go, take Nebo from Israel" It is likely that such claims are hyperbolic in Moab, and it is likely they were hyperbols in Israel. But that does not lessen the shock value for a modern reader, says Andrew Keen. "War in our time is no less savage and no less brutal," he says. Canaanites were to be completely destroyed. I think assertions of national identity and independence are often predicated on differentiation from others. If the Israelites were, in fact, basically Canaanites, who had withdrawn from the larger collective, then Canaanites who did not join them in this were a special threat to the new Yahwism. This same dynamic of intense sibling rivalry appears again in the first few centuries of the Common Era. Some Jews separated from others and in differentiating themselves and creating their own identity as Christians. In the first half of the book of Joshua, alongside the call for the destruction of all Canaanites, we find interesting tales of alliances and incorporation of various Canaanite groups. One of the heroines of the Battle of Jericho, if not a Canaanite woman, a prostitute no less, named Rahab. She declares her faith in Yahweh and she delivers the city into Joshua's hands. Another Canaanite group, the Gibeonites, trick the Israelites into making a covenant with them. Michael Coogan has described such stories as etiological tales. ideological account in which all Canaanites are obliterated or destroyed. At the very least, these stories raise questions about the biblical portrait or portrayal of invasion and conquest. And at most, they illustrate the biblical writers' taste for literary subversion yet again. The imperative of preserving a distinct identity--based on giving up the worship of other gods or older gods and observing all that is written in the law of Moses--is reiterated in Joshua's farewell address in Joshua 23, and in the covenant renewal ceremony in 24. not serve them or bow down to them, but hold fast to the Lord your God as you have done this day." And verses 11 to 13: For you own sakes, therefore, be most mindful to love the LordYour God. In 24, the Israelites are assembled at Shechem to renew the covenant. Joshua recounts God's mighty deeds on behalf of Israel and exhorts them to keep their promise to God. The Israelites then intermarry with the remnant of these nations. Israel is to show undivided loyalty to God, or God will take the gift of the land from her as he did the Canaanites. Marriage with Canaanites, the people closest to you, specifically, will lead to the worship of that spouse's god. The ban on intermarriage here is quite specific. It is directed against Canaanites only, not all non-Israelites, for a very specific reason: religious purity. The Israelites are sitting. in the sixth century, the time of the final editing of Deuteronomistic history. in exile in Babylon. They are trying to make sense of the tragedy that has befallen them, the loss of their land. Consider how a text like Joshua 23 and Joshua 24 would go a long way towards explaining their fate while retaining faith in Yahweh. We're going to return to this when we reach the conclusion of the Deuteronomistic history in 2 Kings. It would be interesting to see how they would have reacted to the events of the time in which they were living.

ROUGE-1: 58.97, ROUGE-2: 56.20, ROUGE-L: 55.53
BERTScore: 69.60

==============================================
==================== [10/100] ====================
Summary:
Bogdan Fedeles: Today we're going to be talking about Problem 2 of Problem Set 4. We'll discuss in detail the mechanism of HMG-CoA synthase, a key enzyme in central metabolism. The enzyme is responsible for making the five carbon building blocks from which all sterols, such as cholesterol and steroid hormones, are made. To help us understand the mechanism, a crystal structure of this H MG-Coa synthase is provided in this problem. It's shown here. In many reactions that use a cysteine in the active site, which is used to form a covalent bond to the substrate, we first need a base to deprotonate the cy Steine and make it a really good nucleophile. The reaction will start by forming this thioester between the acetoacetyl-CoA carbons and the cy steine. In a lot of these cases, the base is a histidine. But if you look at this histidine, it's quite far from our cysteined here. intermediate you've seen in the serine protease mechanism. Now in that case, such an intermediate was stabilized with hydrogen bonds from the backbone of the protein in a structure that was called an oxyanion hole. Now let's take a look at the crystal structure of HMG-CoA to see how a tetrahedral intermediate might be stabilized. Here is the acetyl of the acetoacetyl- CoA substrate. The acetyl now is bound to the cysteine 111 here in the active site. active site and may also be involved in catalyzing the reaction with the cysteine by stabilizing the tetrahedral intermediate. In that case, this distance will have to become even smaller, that is to form a really good hydrogen bond on the order of 2.6, 2.7 Angstrom. Once acetoacetyl-CoA has reacted with the enzyme, hence, formed the thioester with the Cysteine 111, we're now ready to proceed with the reaction and form a carbon-carbon bond. up the proton from the general base in the active site. So at this point, we're just going to release the thiol of the cysteine 111, and the rest of the molecule is exactly our product, which is the HMG-CoA. The curved arrow mechanism we just wrote answers part 1 of the problem. Second question of this problem is asking about the stabilization of the tetrahedral intermediate, which actually we have just discussed. But let me reiterate as you guys saw in the serine protease mechanisms, they tend to be stabilized in an oxyanion hole. sufficient information to say for sure which are the key interactions to stabilize these tetrahedral intermediates. A lot more work, a lot more experimental data is necessary to figure out which are. the key hydrogen bonds and interactions that stabilize the tetrahedra. The three general mechanisms by which enzymes accelerate reactions are binding energy, general acid/general base catalysis and covalent catalysis. Now let's take a look at our structure and figure out how each one of these mechanisms might be operating. pretty obvious here the acetyl-CoA substrate first reacts and forms a covalent bond with the cysteine of the HMG- coA synthase. So this covalents attachment to the enzyme allows this residue to be positioned just right so that it can react with the other substrate. Now, general acid/general base catalysis, we've seen all these residues that participate. Obviously, in order for this to react, we need a base to deprotonate the cystine. Then we need an acid to stabilize and form this hydroxyl group that will be developing on this oxygen. energy contributes to this reaction. Both of the substrates need to bind to the enzyme. In order to do that, they need to be desolvated, that is to remove all the water molecules that surround them. The binding energy is also derived by when we align the substrate in the active site of the enzyme, we align them so closely the right geometry and within a few tenths of an Angstrom so that the right orbitals overlap and allow the reaction to happen. So also the ability to align this residue so closely that also contributes to the binding energy. or the tetrahedral intermediate is stabilized more than the substrate, then the reaction is accelerated and proceeds towards that pass. Part 4 of the problem is asking us to look up the structure of coenzyme A, or CoA and then contrast the reactivity of say, acetyl-CoA, the thioester with CoA, with a thioesters with a much smaller thiol group. Now, it turns out these thIOesters will be very, very similar because really it's only the thiol moiety that we need to form thio testers. a look. Here is an oxygen ester that shows a proton in alpha position. And as you know, the lone pairs on this oxygen can conjugate with the carbonyl group and form certain resonance structures. So the electrons can move like this, and then we're going to have a negative charge here and a positive charge here. And this is possible because the electrons on both oxygens are found in orbitals of comparable energies. By contrast, in the case of a thioester, we have a sulfur. better electrophile to react as nucleophiles behaves more like a ketone. For the same reason, when we are to deprotonate the alpha position on a thioester, the density on the carbonyl is there to stabilize the enolate much more so than it would be for an oxygen ester. Therefore, the pKa, the acidity constant for this hydrogen on the thioesters is close to 18. This sums up Problem 2 of Problem Set 4. experimental work and evidence. The study of the effects of drugs on the human body was conducted in the 1970s and 1980s. The results of the study were published in a book called "The Effects of Drugs on the Human Body" The book was published by Oxford University Press in 1989. It was the first of its kind to be published in the U.S. and is published by Simon & Schuster, a division of Simon and Schuster Inc. in New York. The book is available in hardback and paperback.

ROUGE-1: 44.01, ROUGE-2: 40.89, ROUGE-L: 41.28
BERTScore: 67.09

==============================================
==================== [11/100] ====================
Summary:
Alberto Riva is an instructor at CHB. He will talk to you about the most important resources for finding and using biomedical information, especially information connected with the study of the human genome. Most of them will be websites, where you can find information, and to talk about how this information is stored and represented, how it's accessible, and what it can be used for. You're going to see a long list of references to sites, websites, with URLs. Don't worry if you can't remember all of them because, of course, I'm going to distribute the slides. so-called central dogma of molecular biology, as you know, almost all our cells contain DNA in their nucleus. DNA is the molecule that encodes information-- for at least from the purposes of this presentation, this is what we're interested in. And this information is transcribed into our name molecules, that then exit the nucleus under the form of mRNA. MRNA is then translated into proteins. And proteins are ultimately what is responsible for essentially all the external manifestations, all the observable properties of our biology. As you move from one end of the spectrum to the other, you're going to encounter very different forms of information, of data. And each one has its own specific nature and function, and needs to be treated with different tools. So essentially these are the questions that I'm going to answer. How is all this information represented? What are the different ways that we can store and describe this information? Where does it come from, where is it stored, how do we find retrieve and use it? The genotype is digital, because each base pair in our DNA can be exactly represented using one of four symbols, A, P, G, C. On the other hand, the phenotype is, say, analog. Most phenotypes are qualitative in nature. They cannot be measured exactly or precise, they cannot even be defined precisely in most cases. You always have to take into account the effect of environmental factors that, again, are very hard to describe in a quantitative way. But essentially, using a small number of symbols, you can provide an exact representation of our genome. of protein is the fact that the proteins are not uniquely determined by their sequence. For DNA, you just look at the sequence and you know essentially all that there is to know about DNA. For proteins, you cannot look at. the subsequence of a protein and understand just by looking at it what the protein. is going to do. Not even how it's going to be-- not even what it's three-dimensional structure is going. to be. That's difficult enough. Then understanding what theprotein does, just byLooking at the sequences, is still very far from being feasible. was discovered, more or less, the same years. But at the time, nobody had any idea that there was any connection between these two things, between the DNA and inherited traits. It took over 80 years for this concept to be proven. So the definite proof that genes are made of DNA dates back to 1952. After that, progress was faster because the elucidation of the structure of DNA, and the DNA replication mechanism, came one year later. Then the geniculate code was deciphered between 1961 and 1966. Something that we now take for granted, like the discovery of introns, only happened in 1977. There are differences between the DNA of two any human beings. These differences are due to polymorphisms, like single nucleotide polymorphisms. Microsatellites, repeats, insertions, deletions, translocations, these are all things that can happen to your DNA sequence that can modify in ways that, of course, are not enough to turn you into another animal. You're going to find approximately one difference every 1,000 bases. And understanding what these differences do and mean is one of the most interesting problems in current genome research. bioinformatics and molecular biology, because now we finally have the tools of looking at our genome with this level of detail. We can look at individual base pairs and we can see, well, there should be an A here, and instead, we have a C. Does that cause a problem? So again, we're going to go back to this soon. And the same thing happens for phenotypes, although in a slightly different ways. Phenotypes are generalizations, too. The typical operations we might be interested in doing are, for example, sequence matching. So to understand if certain stretch of a sequence matches anything else that you've seen before. Homology searches refer to looking for similarities between DNA sequences in different organisms. So if you find a high degree of similarity between the two genes, you can hypothesize that they are also going to have the same function. We will see as we go forward that we're going to encounter very different forms of data, according to what the purpose of our work is. another pretty common cooperation is performing DNA sequences, is SNP detection. They are locations where different individuals don't have the exact same nucleotide. And we'll talk later about why genotyping is important, what kind of information you can get from that, and how this relates to diseases. At a level of RNA, it might be interesting to look at alternative splicing transcription rearrangements-- these are all things that could be used in the future. Back to Mail Online home. back to the page you came from. that happen to the original DNA sequence when it's transcribed into RNA. It undergoes a series of transformations that can, of course, affect, in a very deep way, the final product. And this process, the process of transcribing the DNA sequences into RNA, is, ofcourse, at the basis of expression analysis. So I'm not going to go into too much details on this, but differentiable analysis, clustering, and so on, these are all the usual things that can be done using microarrays. Predicting the three dimensional structure of a protein is another very important and very complex task. Starting homology and conservation of proteins across different organisms can give you a very good idea of the importance of some proteins. And finally, something that is very challenging, and it's receiving a lot of attention lately, is the automatic construction and analysis of metabolic pathways and regulatory pathways. If you are able to understand how proteins interact with each other, and interact with the rest of the cell, how they then regulate other genes, and in turn other proteins, then you can use this information to make better decisions. try to build, in a computational way, the kind of pathway maps that biologists have been drawing by hand for decades. It works in some limited case, and we're going to see later some examples of some of these things. But these are all very challenging problems that, of course, are still very much open. And finally, we get to the phenotype then, we could put a very long list of things here, but could talk about population genetics, about association studies. Association studies are studies that try to correlate the presence of a certain genotype with an observed phenotype. between one or two alleles and the disease, and that might mean that the SNP is indeed responsible for the disease in some way. And clinical trials, of course, to validate all this. OK, so two more slides about philosophy and then we'll start with the more practical stuff. I've already mentioned the word gene a lot of times, and I'm going to mention it again very often. So it might be interesting to ask ourselves, what is a gene? And this is something that it's a question to which the answer is probably obvious, but it turns out that there are actually many possible answers. locus on a chromosome, in a certain region of a chromosome that has a functional characterization. Locus that was studied, and was found to have a specific function in our biology. And finally, if you ask a bioinformatician, you will get the answer that a gene is just a stretch of DNA where we know there is a gene. So in the following, we are to see examples of all of these different ways to look at the gene. And to start, of course, we're going to start from the beginning. GenBank is the largest repository of DNA sequence data. It accepts direct submissions from researchers. GenBank is at the basis of the NCBI cluster. The National Center for Biotechnology Information, is a branch of the NIH, that has the task of assembling the largest possible number of databases of biomedical information. The most recent data that I could find from one year ago contained more than 22 million sequences and 100,000 distinct organisms. With a total of almost 30 billion nucleotides. And this is the URL for GenBank. for a lot of other resources that we're going to see now, that are all part of this cluster of NCBI resources. They're all interconnected, so you can easily jump from one to the other. So this is a graph that shows you the growth of GenBank in recent years. You can see the very steep growth of the number of base pairs. And you can probably tell that the number-- we're sequencing longer and longer sequences, because the blue graph grows more rapidly than the red one. If you have enough sequences from the same organism, you can try assembling them, putting them together, and trying to reconstruct the entire genome. This is what was done to assemble the human genome, for example, and all the other genomes that are being sequenced. You start with-- you look at the sequences you have, and if you can find overlaps, then you know that these two sequences are related in some way, and you proceed from there. And in the end you're going to build a map that tells you where all these fragments should be positioned. The human genome is considered finished by now. It's hard to go above this level of accuracy. But now we have several other organisms, including a chimp, that was recently released. And it's going to be very interesting because it's essentially identical to the human genome. So there is 1%-- the differences are about 1% between the genomes. So and the details of how this process has been implemented and CVI are here. And in addition to thehuman genome, of course, we have a lot of other genomes that are completed, or near completion. Golden Path is a genome browser for several different organisms. Initially it was only for human-- now it has mouse, rat, chimp, Drosophila, yeast, and a few others. It provides arbitrary DNA sequences-- so you can ask for any region of any human chromosome, you'll get back the exact DNA sequence for that region. It gives you the absolute position of all the known elements of our genome. It's very clear, it's very easy to find all the information you need about a certain region of the chromosome. So genes, markers, mutations, other features, they tell you exactly they are at this location, in terms of the absolute base pair. This is the URL for Golden Path. And this is how it looks like-- this is an example, we're looking at the region that contains the TLR1 gene. And you can see all these different tracks that provide different information on different objects. For example, up here we have the genes, we have different sets of known genes. We have predicted genes, according to different prediction algorithms. functional part. So it undergoes selective pressure. There are tracks that tell you the location of SNPs, and so on. You can select the tracks you want to see, and you get your own view of a certain genetic region. You have the coordinates up here, chromosome 4, the band. And this is just to show that you can query it for any-- this is the same DNA region we were looking at before. But in this case, we asked for the DNA sequence, and we get it. maps, radiation hybrid, human mouse homology maps. So each one of these is a view that gives you a different set of objects in the view. Inside the genetic map, for example, you find information about disease genes, what bands break points. It's extremely detailed, because of course, it can rely on the whole set of NCBI databases. I, personally, find it a bit complex to use, a bit harder to use than Golden Path. But it's is a matter of taste. SNPs are the most common form of variation in our genome. They're much more frequent than microsatellites or insertions, deletions, and other things. SNPs are at a fixed location in the genome. And if you know where the SNP is, you can find it. You can use them as causal candidates for diseases, because a certain percentage of the SNPs introduce changes that then have some consequence on the genotype, on the disease.here. They essentially serve the same purpose with different levels of detail in different areas. phenotype. What I mean is that, for example, if you have a SNP in the coding subsequence of a protein, you're going to get a protein that has an abnormal sequence. There are many diseases that are due to the fact that you have SNPs that truncate proteins. They can be used as evolutionary markers, because SNPs arise randomly during the replication, and then they are transmitted from one generation to the next. And it's very interesting to study how SNPs are transmitted. SNPs get-- how the frequency of the SNP changes in a population. Most SNPs are deleterious. But in some cases, the SNP can also provide an advantage, if it generates something that was not present before, and that works better than the original. If a SNP is neutral, then there is no selective pressure, and it will either go away by chance, or will stay at a certain basic level of frequency. So if you have a SNP that introduces a change is beneficial, then you will-- given enough time-- you will see that thefrequency of the SNPs increases in the population. A SNP is a polymorphism that substitutes the nucleotide you should have at one location with a different one. There are ways of calculating the age of the SNP, so when that mutation arose in the history of our genome. Now the largest database of SNPs that we have again, is at NCBI, it's called the dbSNP. It currently contains over 4 million human SNPs-- actually, I think that by now this number is closer to 5 million SNPs. Almost 50% of the SNPs are validated, which is something very important, means that the SNP has been observed independently multiple times. for example, in 80% of individuals. And the alternative allele appears in 20% of the population. Now, knowing this frequency is very important, because it allows you, then, to do association studies. If a SNP arises in a population, then it tends to be limited to that population. You're not going to find it in a different population, unless there is some genetic interchange between the two. So when you look at the frequency of a SNP, it's very important to specify what population you're looking at. the potential consequences of SNPs. Alfred at Yale is another very small database, but it has a very high quality, and it focuses on frequency data. And finally, SNPper that I'm citing because we developed a chip, this is a resource that tries to integrate information from all the places that I sited so far. So you're going to find a lot of information about known associations between SNPs and diseases. It takes a long time to get all the data together, but the results are very interesting. information mainly from dbSNP, from Golden Path, from TSC, from Alfred, from HGbase. It tries to put everything together in a unified view that allows you to look at the gene. And it provides a way of exporting this data in different formats to make it easier to process later. And I just want to show you one slide from SNPper, but this is a window that describes-- that tells you information about the particular SNP. This is a [? SNP ?] identifier. the gene it belongs to, notch 4. And here, it tells you that this gene is in the coding sequence of the gene, and it actually causes an amino acid change at position 319. It affects protein domains-- this is the list of protein domains that are affected by the SNP. And finally under here, I wanted to show you, this data comes from TSC, andIt's a frequency information data. So they sampled 41 individuals from a population of African-Americans. And then they looked at a different population-- these are Caucasian, I think-- and they found very different alleles frequencies. that what was the minor allele in the first case is now the major allele. So this is a very clear demonstration of why it's important to know what population we're talking about when we study the frequency of a SNP. If you believe these numbers, and then you try to run association studies in the SNP on a different population, you're going to find totally different numbers. And this doesn't have anything to do with disease-- you're just getting results that are misleading, because you are not looking at the same population. Protein sequences are known to have some function, they are important because they do something. If you have a SNP that affects one of them, that SNP, in turn, might cause a protein to work-- it can change the function of a SNP-- of a protein. This is not meant to be an accurate prediction of what the SNP does. And we get so many because all all the information is known about it. It's just telling you that proteins have-- the sequence of aprotein is-- well, it contains portions that are active domains. these domains are overlapping. And this information comes from Swiss [INAUDIBLE] database of protein information. And so you see for example, this first domain covers almost all of the protein. AUDIENCE: So six would be the maximum number? ALBERTO RIVA: No, no, it's just that these domains can be overlapping, just because the Swiss people, they annotate the protein sequence saying OK, from here to here, we know that this happens. But-- well, well, there are some domains that cover the entire protein. LocusLink is a curated directory of genes from 13 organisms. LocusLink provides a nomenclature of genes. UniGene is an automated system, so it's actually an automated procedure that looks at the GenBank sequences that refer to a region of the genome where a gene is known to be. And I think that one year ago, this number was something like 14, and now it's growing very fast. This one is probably the only one that could be affected by the presence of a SNP. So don't get confused by this place. Just a list of Swiss [INAUDIBLE] domains that include that location. least in a set of organisms. And if they find a good match between the two sequences, then this pair is added to the HomoloGene database. So right now it encompasses 25 organisms. In these 25 organisms, they have 470,000 ortholog pairs-- so pairs of genes from different organisms that are highly similar to each other. All these are put into the database. And then if you find there are three organisms that share a similarity relationship, this, in turn, is marked. It means that you're finding a match that has an even higher quality. is conserved across all these organisms. This one is partly curated, partly calculated. So they have an automated procedure that looks at sequence similarity using all the many algorithms to do that. And then they have a subset-- this is not mentioned here. But then, most of these entries in [INAUDIBLE] are also manually curated to make sure that they are really-- that they're really similar genes. It's something that is pretty similar to LocusLink in scope. Again, it's a software system for the automated annotation of genomes. So it's basically means it's a system that discovers genes and tries to find as much information as possible about these genes. It's limited to 10 organisms, but it provides a lot of information about the genes in this-- about this organism. It provides information about genes, about proteins, diseases, SNPs, cross-species analysis, microarray data. It has a very powerful data access interface. So you can do queries on this huge database in a relatively simple way. Not everybody uses the LocusLink way of naming genes. And going from one to the other is sometimes tricky. There are links between the two databases. But of course it's not-- they don't necessarily match very well. OK, and finally, a few words about gene regulation. So gene regulation is almost needless to say, it's an extremely complex mechanism. Our understanding of how gene regulation works is still very limited. It's the most visible consequence of everything that is in this complex mechanisms. is a consequence of the fact that there is a very complex machinery behind it that determines which genes are active or not, and how much, in different conditions. This is actually a system that integrates a lot of different factors that might include the following, in no particular order-- The tissue, we know very well that the set of genes that are expressed in one tissue is very different from theSet of genes expressed in another tissue. The time-- the time can mean either a time of day, for the case like the circadian rhythm. Or time at a larger scale, there are processes that take place. We're slowly working to try to understand how it works. What we have for now is some understanding of what transcription factors-- the transcription factors are proteins that bind to the upstream regions of the genes. They have to interact with the target gene, but they also interact with each other in a combinatorial fashion. So what we need to look at is the pattern of transcription factors that binds to a certain gene. And that, in turn, will determine the spatial, temporal, dependent expression of the target genes. Most of the information in TransFIC is experimentally validated. So you can actually trust the fact that particular sequence they give you is the binding site for the transcription factor in question. And so in the end, without going into too much detail, what you can do is can take these binding sites, you can use them to train your favorite pattern matching method, and then you can try scanning new sequences looking for binding sites. This is one of the things that we're currently working on at CHB-- there are various ways of doing this. a computational meter to detect binding sites that works well, then you can think about doing this on a large scale. This is one of the things we are working on in our lab. And it's going to take a lot of work but the rewards are potentially very interesting because this is something that will then allow you, if it works, to automatically build the networks that describe how genes regulate each other. And that's something that, of course, has a lot, of potential interest. GEO is a database of gene expression and hybridization array data. The Stanford microarray database, again, is a repository of all the-- of a large number of micro experiments performed at Stanford. Other resources for gene expression are found in different PGA projects, PGA are programs for genomic applications, they are are large projects managed by the NIH. The [? tracks ?] PGA, for example, offers 565 microarrays from mouse and rat models of sleep, infection, hypertension, pulmonary disease. disease. The Hopkins PGA, again more than 500 microarrays from several human diseases. Cardio genomics provide microarray data on mouse models of cardiac development and signal transduction. Human gene expression index-- these are just some of the most important most useful public resources of micro array data. And if you'd rather stop me with questions, or if there's anything you would like to discuss about what I said so far, we could stop here, or I could just run through this last portion quickly. DNA and RNA world for the reasons that I've explained at the beginning. Some of the reasons are that proteins interact with each other in very complex ways. They combine in three dimensions, they catalyze chemical reactions. They have a behavioral that is much harder to describe in [INAUDIBLE] terms than everything else we've seen so far. So as a consequence, protein databases, first of all, tend to be older, because they were started earlier than genomic databases. They are less integrated, they are less complete. Nomenclature is much less standardized. SwissProt is a database of protein domains and protein families. It's hard to link this database with LocusLink or UniGene, but is its own identifiers for proteins. PFM at the Sanger Institute looks for domains in the proteins, and then they look for similarities between proteins on the basis of the domains that were identified. They use similarity measures, they use hidden Markov models. And as you can see it's growing but at a much smaller rate than GenBank or other resources like that. notation there is a high quality. And then there's a second portion of PFM that has smaller families of lower quality. This is an example of a display, a PFM display, of a protein with all the different domains that were found in the protein with the tails here. So give it this nice graphical display. I'm going to skip protein interaction databases. And I want to get to the end. We're getting to the phenotype and to the spectrum, finally. And there's just a couple of resources that have to be cited because they're extremely important. you can find a description, mechanical feature, the function mapping, and then you can find all known correlations between that gene and diseases. And finally, PubMed, you probably all know what PubMed is, a database of citations from the biomedical literature. It contains 12 million entries starting from the mid-'60s, and it provides references, abstracts, linked to online resources. It's one of the most used resources in the world, and has been growing at least at this speed or faster since '98. Gene ontology is to build a dynamic controlled vocabulary that can be used to describe biological concepts. It's organized in three taxonomies that try to describe everything that is known about molecular functions, molecular biological process, and several components using a standardized nomenclature. It is a work in progress-- still very far from being complete. It could find exact definition of all the terms that people use, especially in this field is very hard. But this is where they are now, and it's aWork in progress, so it will keep growing in the future. a view of taxonomy, for example, for biological process. If you are talking about site communication, then response to external stimulus is a subclass of communication. And if you want to talk about the immune response, you can cite this biology term. OK, I think we're out of time. Well, just a conclusion slide that I'll just let you read, because I think it's just repeating what we're saying so far that we are drowning in data and converting this data into knowledge is not easy. is a challenging task, because as we saw, biomedical data covers the whole spectrum of knowledge representation and management techniques that we know about. We are trying to make the most of the data we have, and we hope that it will help us understand more about the human condition. We hope that this article will be of interest to people around the world who are interested in biomedical data and data management techniques. For more information, go to: http://www.bbc.co.uk/news/science-and-biomedical-data/bio-data-measurement-mechanical-data.

ROUGE-1: 60.74, ROUGE-2: 58.45, ROUGE-L: 55.74
BERTScore: 78.54

==============================================
==================== [12/100] ====================
Summary:
This week in week three, we're actually going to have some human language, and so this lecture has no partial derivative signs in it. In today's lecture, we want to look at, well, what kind of structures do human language sentences have, and how we can build models that, um, build that kind of structure for sentences that we see. And then talk about how you can make neural,Um, dependency parsers. And so we hope that you can put together a neural dependency parser. what you learned about neural networks last week and the content of today, and jump straight right in to building a neural dependency parsers. Um, the other thing that happens in assignment three is that, we start using a deep learning framework PyTorch. So, for doing assignment three, and this is in the PDF for the assignment, is to install Py Torch as a Python package, and start using that. If you have any issues with, with that, um, well, obviously, you can send Piazza messages, come to office hours. there's sort of a one hour introduction to PyTorch on thePyTorch site. We're going to sort of focus on those more in week five, but if it's not bad to be thinking about things you could do, if you're under a custom final project. We have under the sort of office hours page on the website, a listing of the expertise of some of the different TAs. Since I missed my office hours yesterday, I'm gonna have a shortened office hour tomorrow from 1:00 to 2:20. can kind of come for any reason you want, but it might be especially good to come to me if you want to talk about, um, final projects. So, let's leap in and start talking about the structure of sentences. And so, I just sort of want to explain something about human language sentence structure, and how people think about that structure. Um, all of the examples I'm going to give today are in English, because that's the language that you're all expected to have some competence in. But this really isn't meant to be sort of facts about English. Linguists have thought about the structure of sentences in two ways. One of them is called phrase structure, or phrase structure grammars. The idea of phrase structure is to say that sentences are built out of units that progressively nest. So, we start off with words that, cat, cuddly, et cetera, and then we're gonna put them into bigger units that we call phrases. And then you can keep on combining those up into even bigger phrases, like, "Thecuddly cat by the door" they're also referred to as article sometimes in English. There's another word class here of nouns. And so, what I- to capture this pattern here, it seems like we can make this unit, um, that I see all over the place in language, which is made of a determiner, followed by a noun. So, maybe I can say from my grammar that a noun is a phrase structure grammar role, a context-free grammar role of- I can have a noun phrase that goes to aeterminer, and a noun, and so on. phrase goes to a determiner, and then optionally, you can put in an adjective. And then I poke around a little bit further and I can find examples like the cat in a crate, or a barking dog by the door. And so I want to put those into my grammar. But at that point, I noticed something special, because look, here are some other things, and these things look a lot like the things I started off with. So, it seems like, which sort of having a phrase with the same expansion potential that's nested inside this bigger phrase. that a noun phrase goes to a determiner, optionally an adjective, a noun, and then a something else, which I'll call a prepositional phrase. And then I'm gonna write a second rule saying that a prePOSitional phrase goes. to a preposition, that's gonna be these words here, um, followed by a. noun phrase. So then I could immediately generate other stuff. I can sort of say, "The cat by the, the large door." Or indeed I could say, 'The catby the large crate on the table' what you find is that prepositional phrases following the verb. But if you go to a different language like Chinese, what you find are the prepositions coming before the verbs. And so, we could say okay, there are different rules for Chinese, um, and I could start writing a context-free grammar for them. Um,so that's the idea of context- free grammars. This is the dominant approached linguistic structure that you'll see if you do a linguistics class in the linguistics department. sort of phrasal categories, like, noun phrases and prepositional phrases, and things like that. We are going to directly, um, represent the structure of sentences by saying, how words, how arguments or modifiers of other words in a recursive faction. Which is sort of another way of saying how the dependence on other words. So, we have a sentence, ''Look in the large crate in the kitchen by the door''. And if we want to we can give these word, words word classes, so we can still say this is a verb. In this system of dependencies I'm going to show you, we've got in as kind of, um, a modifier of crate in the large crate. And well, then we have this next bit by the door. And as I'll discuss in a minute, well, what does the by thedoor modifying? It's still modifying the crate, it saying, ''It's the crate by the doors.'' Okay. So, the structure you get may be drawn a little bit more neatly when I did that in advance like this. to your friends is that you just blab of something, and I understand what you're saying, and, um, what goes on beyond that, is sort of not really accessible to consciousness. But well, to be able to have machines that interpret language correctly, we sort of need to understand the structure of these sentences. Unless we know what words are arguments and modifiers of other words, we can't actually work out what sentences mean. And I'll show some examples of that as to how things go wrong immediately, because a lot of the time there are different possible interpretations you can have. "What can go wrong?" is a way of saying, ''What can't go wrong?'' Okay. So here, is a newspaper article. Uh, ''San Jose cop kills man with knife''. Um, now, this has two meanings and the two meanings, um, depend on, well, what you decide depends on what, you know, what modifies what? "The cop stabs the guy. The second meaning the sentence can have is, that's the man has a knife" what is modifying what? Um, here is another one that's just like that one. Um, scientists count whales from space. Okay. So again, this sentence has two possible structures, right? [LAUGHTER] That we have, the scientists are the subject that are counting and the whales are the object.Um, and, well, one possibility is that this is how they're doing the counting, um, so that they're counting the whales fromspace using something like a satellite. A prepositional phrase attachment ambiguity is one of the most common ambiguities in the parsing of English. In programming languages, you have an else is always construed with the closest if.um, that are starting to turn up as in the bottom example. In human languages, we have hard rules as to how you meant to interpret things that dangle afterwards, right? And so this is a crucial way in which human languages are different from programming languages. It's a crucial difference between human languages and Programming languages. if that's not what you want, um, you have to use parentheses or indentation or something like that. Human languages are this prepositional phrase can go with anything proceeding, and the hearer is assumed to be smart enough to work out the right one. And, you know, that's actually a pa- large part of why human communication is so efficient, right? Like, we can do such a good job at communicating with each other because most of the time we don't have to say very much. um, who can interpret the words that we say in the right way. So, that's where if you want to have artificial intelligence and smart computers, we then start to need to build language understanding devices. That they can just decide what would be the right thing for form space to modify. And if we have that working really well, we can then apply it back to programming languages. And you could just not put in any braces in your programming languages, and the compiler would work out what you meant. acquisition by Royal Trustco Limited of Toronto for $0.27, $27 a share at its monthly meeting. Boring sentence, but, um, what is the structure of this sentence? Well, you know, we've got a verb here, and we'veGot exactly the same subject, and for this noun,Um, object coming after it. But then what happens after that? well, here, we's got a prepositional phrase. Here, we're gonna get more complicated as we go in, because look, there's another noun here. Okay. So, um, by Royal Trustco Limited, what's that modifying? [NOISE] Right. You see acquisition, so it's not the board approved by Royaltrustco Limited. It's an acquisition by Royal trustco. Okay. Now, we went to of Toronto, and we have three choices, that could be this, this, or this. This one is a dependent of the acquisition. Okay, so, of Toronto is modifying. acquisition of Toronto? [LAUGHTER] No, I think that's a wrong answer. For $27 a share is modifying acquisition, right? [NOISE] So now, we leap right back. And then finally, we have at its monthly meeting is modifying? [Noise] Approved. Well, the approved, right. It's approved, yeah. Okay. [NOise] I drew that one the wrong way around with the arrow. Sorry, it should have been done this way. I'm getting my arrows wrong. Um, um. So that we've got this pattern of how things are modifying. to potentially consider an exponential number of possible structures because, I've got this situation where for the first prepositional phrase, there were two places that could have modified. And so, if you get into this sort of combinatorics stuff the number of analyses you get when you get multiple prepositions is the sequence called the Catalan numbers. Ah, but that's still an exponential series. And it's sort of one that turns up in a lot of studies of the human brain. of places when they're tree-like contexts. So, if any of you are doing or have done CS228, where you see, um, triangular- triangulation of, ah, probabilistic graphical models and you ask how many triangulations there are, that's sort of like making a tree over your variables. And that's, again, gives you the number of them as the Catalan series. But- so the point is, we ha- end up with a lot of ambiguities. Right? That is either that there's somebody who's a shuttle veteran and a long time NASA executive, and their name is Fred Gregory, and that they've been appointed to the board. Or, um, the other possibility is that there're a shuttle vet and a longtime NASA executive. And so, we can represent by dependencies, um,. these two different structures. Okay. That one is not very funny again. Um, that's,Um, one. That's, um. One. In English, you can use kind of just comma of sort of list intonation to effectively act as if it was an "And" or an "Or", right? So, here, um, we have again two possibilities that either we have issues and the dep- and the dependencies of issues is that there are no issues. Um, and then it's sort of like no heart or cognitive issues. So, "Heart" has a depend- has a coordinated dependency of "Issues". That's one one. modifier of "Experience" and the "Job" is also a modifier of " experience" And then we have the same kind of subject, object, um, reading on that one. Um, but unfortunately, this sentence has a different reading where you change the modification relationships. [NOISE] One more example. "Mutilated body washes up on Rio beach to be used for Olympics beach volleyball." Um, wha- what are- [LAUGHTER] what are the two ambigui- being attached, we've now got this big verb phrase we call it, right, so that when you've sort of got most of a sentence but without any subject to it, that's sort of a verb phrase to be used for Olympic beach volleyball which might be then infinitive form. Sometimes it's in part of CPO form like being used for beach volleyball. And really, those kind of verb phrases they sort of just like, um, prepositional phrases. Whenever they appear towards the right end of sentences, they can modify various things like verbs or nouns. that, um, we can have here is another noun phrase muti- mutilated body, and it's the mutilatedBody that's going to be used. Um, and so then this would be, uh, a noun phrase modifier [NOISE] of that. Okay. So, you know, this is back to the kind of boring stuff that we often work with of reading through biomedical research articles and trying to extract facts about protein-protein interactions from them or something like that. is, um, the results demonstrated that KaiC interacts rhythmically with SasA Ka- KaiA and KaiB. Um, and well, [NOISE] I turned the notification's off. [NOise] I actually mis-edited this. This should also be nmod:with. [Noise] Um, we have this KaiC that's interacting with these other proteins over there. We can kind of think of these two things as essentially,Um, patterns. So, we can sort of see this repeated pattern. can kind of think of these two things as sort of patterns and dependencies that we could look for to find examples of, um, just protein-protein interactions that appear in biomedical text. Okay. So, so that's the general idea of what we wanna do, and so the total we want to do it with is these Dependency Grammars. And so, I've sort of shown you some Dependency grammars, and I just want us to sort of motivate them a bit more formally and fully. sort of put the words in a line and that makes it. He see, let's see the whole sentence. You draw this sort of loopy arrows above them and the other way is you sort of more represent it as a tree. So, the dependence of bills and were submitted words, the dependent of submitted and you're giving this kind of tree structure. Okay. Well, in addition to the arrows commonly what we do is we put a type on each arrow which says what grammatical relations holding them between them. So,. is this the subject of the sentence? Is it the object? of the verb? Is that a, um, a conjunct and things like that? We have a system of dependency labels. Um, so, for the assignment, what we're gonna do is use universal dependencies, which I'll show you more, a little bit more in a minute. And for the arrows, you should be able to interpret things like prepositional phrases as to what they're modifying, just in terms of where the prepositions are connected and whether that's right. But, if you don't think that's fascinating, for what we's doing for this class, we're never gonna make use of these labels. All we're doing is making use of the arrows. The Dependency Grammar has an enormously long history. The famous first linguists that human beings know about his Panini who, um, wrote in the fifth century before the Common Era. And a lot of what Panini did was working out things about all of the morphology of Sanskrit that I'm not gonna touch at. Okay. So, it's a connected acyclic single, um,. rooted graph at the end of the day. Or, it could be a tree. In the later parts of the first millennium, there was a ton of work by Arabic grammarians and essentially what they used is also kind of basically a Dependency Grammar. So compared to that, you know, the idea of context-free grammars and phrase structure Grammars is incredibly incredibly new. I mean, you can basically, um, totally date it. There was this idea of this Dependency grammar. And indeed, if you look at kind of the history of humankind, most of attempts to understand the structure of human languages are essentially Dependencygrammars. guy Wells in 1947 who first proposed this idea of having these constituents and phrase structure grammars, and where it then became really famous is through the work of Chomsky. So, in modern work, uh, there's this guy Lucie Tesniere. Um, and he sort of formalized the kind of version of dependency grammar that I've been showing you. And you know it's- it's long-term being influential and influential and long term being influential. Okay. Who's head of the Chomsky hierarchy? Do people remember that 103? Yeah. computational linguistics. Some of the earliest parsing work in US Computational Linguistics was dependency grammars. There's sort of two ways of thinking about this um, that you can either think okay, I'm gonna start at the head and point to the dependent. Or you can say I'm going to start. at the dependent and say what its head is, and you find both of them. Uh, sorry. I'm drawing that wrong. Whoops, um because discussion. of the outstanding issues. So, really um, the dependent is sort of discussion. We go from heads to dependence. And usually, it's convenient to serve in addition to the sentence to sort of have a fake root node that points to the head of the whole sentence. Um, so to build a dependency pauses or to indeed build any kind of human language structure finders including kind of constituency grammar pauses, the central tool in recent work, where recent work kind of means the last 25 years has been this idea of tree banks. Universal Dependencies is actually project I've been strongly involved with. The goal of universal dependencies was is to have a uniform parallel system of dependency description. So, if you go to the Universal Dependencies website, it's not only about English. You can find Universal Dependency analyses of you know, French, or German, or Finish, or Carsac, or Indonesian, um, lots of languages. Of course, there are even more languages which there aren't universal analyses of. So if you have a- a big calling to say I'm gonna build a Swahili Universal, I'll be happy to help. Dependencies um, treebank, um, you can get in touch. So, this is the idea of treebank. You know, historically, tree banks wasn't something that people thought of immediately. This so- an idea that took quite a long time to develop, right? That um, people started thinking about grammars of languages even in modern times in the fifties, and people started building parses for languages in the 19, early 1960s. There was decades of work in the 60s, 70s, 80s, and no one had tree banks. these sentences. It's often a bit more subtle was to why that is because it sounds like pretty menial work um, building tree banks, and in some sense it is. But it turned out to be much better to have these kind of treebank supporting structures over sentences. So, it's really efficient you're capturing lots of stuff with one rule. Um, but it sort of turned out that in practice that wasn't such a good idea, and it turns out that it's better to be more subtle. Treebanks are very reusable. People who started about building a parser invented their own notation for grammar rules which got more and more complex. Once you have a treebank, it's reusable for all sorts of purposes that lots of people build parsers format. But also other people use it as well like linguists now often used tree banks to find examples of different constructions. This sort of just became necessary once we wanted to do machine learning. So that if if you if you want to do a machine learning algorithm, you can use a tree bank. we want to do machine learning, we want to have data that we can build models on. In particular, a lot of what our machine learning models exploit is how common are different structures. We want to know about the commoners and the frequency of things. Um, but then treebanks gave us another big thing which is, well, lots of sentences are ambiguous, and what we wanted to do is build models that find the right structure for sentences. If all you do is have a grammar you have no way of telling what is the right Structure for ambiguous sentences. All you can do is say hey that sentence with four prepositional phrases after it that I showed you earlier, it has 14 different parsers. Let me show you all of them. for this sentence in context. So, you should be building a machine learning model which will recover that structure, and if you don't that you're wrong. Um, there's a question of how far apart words are. Most dependencies are fairly short distance. They not all of them are. There's a questions of what's the right parse for this sentence, and what's a reasonable thing to look for in a discussion of issues. It's reasonable to have issues as dependent of discussion um, where you know, discussion of outstanding. in between. If there's a semicolon in between, there probably is an a dependency across that. Um, and the other issue is sort of how many arguments do things take? So, here we have was completed. You sort of expect that there'll be a subject before of the something was completed, and it would be wrong if there wasn't. So, there's sort of information of that sort, and we want to have our dependency parsers be able to make use of that structure. For each word we want to choose what is the dependent of. We want to do it in such a way that the dependencies form a tree. So that means it would be a bad idea if we made a cycle. So, if we sort of said, Bootstrapping, was a dependent of, um, talk, but then we had things sort of move around. And so I'm gonna cycle that's bad news, we don't want cycles, we want a Tree. And there's one. Final issue is whether we want to allow dependencies to cross or not. Most of the time, um, dependencies don't cross each other. But sometimes they do, and this example here is actually an instance for that. So, we actually have another dependency here that crosses that dependency. And that's sort of rare, that doesn't happen a ton in English, but it happens sometimes in some structures like that. You could've said, I'll give a talk on bootstrapping tomorrow, and then a [inaudible] have a projective parse, but if you want to, you can kind of delay that extra modifier. And then the parse becomes non-projective. is a transition based parser. This was a notion of parsing that, um, was mainly popularized by this guy, walk him Joakim Nivre, he is a Swedish computational linguists. Um, and what you do it's- it's sort of inspired by shift-reduce parsing. So, probably in- in our CS103 or compilers class or something, you saw a little bit of shift- Reduce Parser. And this is sort of like a shift-Reduce parser, apart from when we reduce. I wanna to do is parse the sentence "I ate fish". And yet formally what I have is I have a why I start, there are three actions I can take. So, I stop the parse, and that's the sort of instruction here. By putting route, my root for my whole sentence onto my stack, and my buffer is the whole sentence, and I haven't found any dependencies yet. Okay, and so then, the actions I could take is to shift things onto the stack or to do the equivalent of a Reduce. I build dependencies. So, starting off, um, I can't build a dependency because I only have root on the stack, so the only thing I can do is shift, so I can shift I onto the stack. And so, at this point, I'm in a position where, hey, what I'm gonna do is reductions that build structure, because look, I have I ate here and I want to be able to say that I is the subject of dependency of ate, and I will do that by doing a reduction. sentence is my buffer is empty and I just have root left on my stack because that's what I sort of said back here. So, I've parsed the sentence. So that worked well but, you know, I actually had different choices of when to pa- when to shift and when to reduce. And I just miraculously made the right choice at each point. And well, one thing you could do at this point is say, well, you could have explored every choice and, um, seen what happened and gone different parsers. But that's not what people did in the 60s, 70s and 80s. Joakim Nivre came along with the idea of a machine learning classifier. The classifier would tell the user whether to shift with left or right arc. The arrows are just three actions that the classifier can take on a given position in the parse. It's a very simple way to think about how to use machine learning in a search engine, he says. He says it could be used in a variety of ways, including in the future in the form of an online search engine. shift, left arc or right arc. Um, if we also wanted to put labels on the dependencies, and we have our different labels, um, there are then sort of 2R plus actions because she is sort of left arc subject or left arc object or something like that. But anyway, there's a set of actions and so you gonna build a classifier with machine learning somehow which will predict the right action. Joakim Nivre showed the sort of slightly surprising fact that actually you could predict the correct action to take with high accuracy. he proved, no, he showed empirically, that even doing that, you could parse sentences with high accuracy. Now if you wanna do some searching around, you can do a bit better, but it's not necessary. Um, and we're not gonna do it for our, um, assignment. But so if you're doing this just sort of run classify, predict action, run classify and predict action. We then get this wonderful result which you're meant to explain a bit honest on your assignment 3. And that's not very good if you want to parse the whole web, whereas if you have something that's linear time, that's really getting you places. Okay. So this is the conventional way in which this was done. Was, you know, we have a stack, we might have already built some structure if we hadn't working out something's dependent of something. We have a buffer of words that we don't deal with and we want to predict the next action. And well, the kind of features you wanted was so the usually some kind of conjunction or multiple things so that if the top word of the stack is good, um, and something else is true, right, that the second top word is verb. then maybe that's an indicator of do some action. So ha- had these very complex binary indicator features and you'd build- you literally have millions of these binary indicators. And you'd feed them into some big logistic regression or support vector machine or something like that and you would build parses. And these parses worked pretty well. But you sort of had these sort of very complex hand engineered binary features. Um, so in the last bit of lecture I want to show you what people have done in the, um, neural dependency parsing world. like this. And so these are the correct arcs and to evaluate our dependency parser, we're simply gonna say, uh, which arcs are correct. So here in my example, my dependency paths, I've got most of the arcs right but it got this one wrong. So I say my unlabeled attachment score is 80 percent or we can also look at the labels and then my parser wasn't very good at getting the labels rights, so I'm only getting 40 percent. And that's in our accuracy. good and the second thing on the stack is the verb has or on the top of the stack are some other words. And that part of speech has already been joined with the dependency of another part ofspeech. People hand-engineer these features. And the problems with that, was these features were very sparse. Each of these features matches very few things. Um, they match some configurations but not others so the features tend to be incomplete. And so it turned out that actually computing these features was just expensive. Compute features format. And it turned out that conventional dependency parsers spent most of their time computing features, then went into the machine learning model rather than doing the sort of shifting. And so that seemed like it left open the possibility that, well, what if we could get rid of all of this stuff and we could run a neural network directly on the stack and buffer configuration. And, you know, effectively what we found, is that that's exactly what you could do. So, here's sort of what we did. of a few stats here. So these are these same UAS and LAS. Uh, so MaltParser was Joakim Nivre's Parser that I sort of, uh, we started showing before. And they've got, um, a UAS on this data of 89.8. But everybody loved that. And the reason they loved it is it could parse at 469 sentences a second. There had been other people that have worked out different more complex ways of doing parsing with so-called graph-based dependency parsers. again but it's gotten even slower. Um, okay. So, what we were able to show is that using the idea of instead using a neural network to make the decisions of Joakim Nivre Style shift-reduce parser, we could produce something that was almost as accurate as the very best parsers available at that time. I mean, strictly we won over here and we are a fraction behind on UAS. Um,. but, you know, it was not only just as fast as Nivrse's parser, but it was actually faster than Nivirse's. even though at the end of the day, it was sort of looking at weights that went into a support vector machine. So that was kind of cool. And so the secret was we're gonna make use of distributed representations like we've already seen for words. So for each word, we're going to represent it as a word embedding. And in particular, um, we are gonna use word vectors and use them as the represent- the starting representations of words in our Parser. But well, if we're interested in distributed representations, it seem to us like maybe you should only have distributed representation of words. the sort of the top positions of the stack, the first positions of. the buffer and for each of those positions, we have a word and a part of speech and if we've already built structure as here, we kind of know about a dependency that's already been built. And so we've got a triple for each position and we're gonna convert all of those into a distributed representation, um, which we are learning. Okay. Now for- so, you know starting from- starting from the next lecture forward, we're going to use a more complex forms of neural models. Our neural network is just a very simple classifier of the kind that we are talking about last week. So based on the configuration, we create an input layer which means we're sort of taking the stuff in these boxers and turn- and looking up a vector representation for each one and concatenating them together. So that gives us in our input layer. Um, so from there, we put things through a hidden layer just like last week, we do Wx plus Wx. b and then put it through a ReLU or a non-linearity to a hidden layer. And then on top of that, we're simply gonna stick a softmax output layer. So multiplying by another matrix, adding another, um, bias term, and then that goes into the softmax which is gonna give a probability over our actions as to whether it's shift left arc or right arc, or the corresponding one with labels. And so each step of the shift-reduce parser, we's making a decision as what to do next and we're doing it by this classifier. Google developed a new way to train parsers using a tree bank. It was able to get greater accuracy and speed than Nivre's parsers at the same time. The results were published in a paper by Weiss and Andor, and people at Google said, "Well, this is pretty cool. Um, maybe we can get the numbers even better if we make our parsers even better," he says. "This was showing the fact, um, that, you know, we're outperforming these earlier parsers," he adds. our neural network, um, bigger and deeper and we spend a lot more time tuning our hyper-parameters. Um, sad but true. All of these things help when you're building neural networks. Sometimes the answer to making the results better is to make it bigger, deeper and spend more time choosing the hyper- parameters. Do humans always agree on how to build this trees and if they don't, what will be the [inaudible] or agreement of humans relative? to [inaudible] [OVERLAPPING] [NOISE] So that's a good question which I haven't addressed. Um, humans don't always agree. There are sort of two reasons they can't agree fundamentally. One is that, uh, humans, um, sort of mess up, right? Because human work is doing this aren't perfect. And the other one is they generally think that there should be different structures. So, you know, it depend- varies depending on the circumstances and so on. There's still room to do better. I mean, at the unlabeled attachment score, it's actually starting to get pretty good. Um, and so then, what's the residual rate in which, um, people can actually disagree about possible parses? I think that's sort of more around three percent. But there certainly are cases and that includes some of the prepositional phrase attachment ambiguities. Sometimes there are multiple attachments that sort of same clause although it's not really clear which one is right. Google developed these models that they gave silly names to, especially the Parsey McPa- parseFace, um, model of parsing. So that then- that's sort of pushed up the numbers even further so that they were sort of getting close to 95 percent unlabeled accuracy score from these models. And actually, this work has kind of, you know, deep learning people like to optimize. So this actually led to ah sort of a new era of sort of better parsers because so effectively this was the 90's era of parsers. neural transition based dependency parsers. We sort of have gone down that we've halve that error-error rate. And we're now down to sort of about a five percent error rate. Yeah. I'm basically out of time now but there is further work including, you know, at Stanford. It's more accurate than 95 percent, right? So we- we're still going on but I think I'd better stop here today, um, and that's neural dependency parsing. [NOISE].

ROUGE-1: 65.85, ROUGE-2: 62.97, ROUGE-L: 61.35
BERTScore: 73.40

==============================================
==================== [13/100] ====================
Summary:
Santa Claus has come to town and you know Santa does with naughty kids Hees them finals he gives them finals. He gives them very evil finals is what he does okay so look out for Santa Claus he's really a really a bad guy. We have a couple surprises today one of which is standing in front of you with all this on and there's more surprises as well um let's see first of all uh this is not a surprise it's been announced on the web page but I'll remind you that we have a review session tonight at 6:30 in ALS 401 so I will videotape that and I will uh get it posted later this evening. sometime tomorrow okay um and that's there for those of you who had regrades on exams um they are available for pickup in the BB office and you can pick them up there so that's available to you. Last but not least we have a final exam I have heard and the final exam is in this room on Monday at 9:30 a.m. so uh get here in plenty of time remember to position yourselves with seating as I said before so we SE sit in theice odd-numbered seats. I've written the exam it has 150 points it has um the first section which is the short answer has 75 points that's half of the exam. One of those changes I'm kind of got to decide today is will we have an extra credit question or not I don't know so maybe you guys can help convince me today that we should have anextra credit question. I see well nodding yes doesn't do it it's got to be no that's okay I'm not. I think you know what I like to to have when it comes to extra credit right so we'll The format is the same as before the point changes are different. There are 25 questions in section one that tells you anything. I'm probably the last person you want to ask if an exam is hard or easy. I always try to write them in the same way I always do okay and there might be some music today I don't know so that's that's possible okay um let's see soThat's basically it uh the the format as I said is theSame as before. The points are different there are three questions in sections two and three. I think this looks like a like an average exam in that respect if you did not get a note card on uh Wednesday when I passed them out uh I don't have them here you'll have to come to my office to get them from me I will remind you that with the exam you have to turn in a note cards that you got from me. If you don't or use a different card or something you will lose points and again I need to make sure that you're using these cards and you're not passing them on to your roommates because that's that's important. Glycogen phosphor is U an enzyme that's regulated in several ways all right so when we talk about coent modification it exists in two forms. It exists in the form that has the phosphate on that people describe as the more active and it has the form without the phosphate known as the glycogenosphor B that is less active. Usually in the cell when it's present it'sPresent in the r State because only when glucose is present will it get converted to the t-state. ATP and glucose 6 phosphate convert it into the Tate quite readily. things all come together now again I'm not going to ask you to rank them or do complex scenarios with these that's not the point of telling you all that information but it is important that you understand all those different types of Regulation. Def phosphorilation involves a kise or phosphatase right the r&t involve allosteric affectors okay all right okay so that's uh where we start now um there's a couple things about regulation that we haven't talked about and you say my God it's already you know murderous right well there's an organizing scheme to it. has to itself be regulated just like everything else has to be regulated because if we don't regulate it then everything's going to be def phosphorated all the time and cells aren't going to have energy like they need okay so we need to think about that Def phosphorilation and that's the wrong slide okay here's what we're after okay now what you see on the screen is a um a scheme that shows the regulation of phosphoprotein phosphatase. That's the pp1 okay pp1. protein we've used the term G protein before to refer to proteins that bind to guanosine nucleotides this is not a g protein it's just holding on to phosphoprotein phosphatase phosph protein phosphat enzyme. Epinephrine is bound by the cell surface receptor all right so we've got an active pp1 and we're going to ultimately convert it over here on the other side to an inactive form this is the most active form all right well and again we're looking in muscle what happens is when we have epinephrine being synthesized we see that this protein GM gets phosphorilated. I said we do phosphorilation we want to favor the breakdown of glycogen right if we're putting phosphates onto things we sure as heck don't want phosphoprotein phosphatase one on taking phosphates off of things right because if this is active we put a phosphate onto glycogen phosphor a this guy is going to turn around and take it right off. So this one system protein kisee a by going out in phosph forting all these proteins is favoring completely the breakdown. put them in the same tube I've got purified pure glycogen phosphor and Pure glycogen synthes I put them together in a tube and I want to see what happens I add glucose and something very odd happens. The first person that answers that gets a free metabolic Melodies calendar for 2012 are they different active sites in the the same nope what' you say def phosphorilation come by and get your a calendar okay this Santa Claus is here okay all right so defosphorilation is happening but I only had two enzymes here how do I get DEF phosphOrilation I have a free metabolism Melody CD for the person who answers that. cool all right now why is that important why is it that this thing carries this thing around with it any thoughts about that should I put a c out for that there's a very important reason why this guy carries this around your book actually talks about it nobody's read the book this is quiets a Class B all term all right so why why are cells breaking down glycogen why are they doing thisy they need energy and why do they what's their typical needs for energy quick quick running from running from the grizzly bear right or the teacher that has is wearing a hat that's right either way okay I want this quick. what else did we learn what did I say about driving your Maserati to Fred Meyer you got to control them right if you turn something on and it's really powerful it's going to break things down really quickly don't you want to be able to turn it off really quick carrying this carrying around its own inhibitor is the most efficient way that it can turn itself off really quickly now notice this happens in the liver this is happening in the Liver the liver is producing what what's one of the things that the liver produces that only one other tissue produces glucose glucose. two things are happening one is glucose one phosphat is being produced by the breakdown of glycogen the other thing that's happening is gluconeogenesis is being stimulated both of those converge in the synthesis of glucose. When I stop exercising my tissues don't need it what happens blood glucose levels start going up. When my liver stops pushing out glucose and what happens to the concentration of glucose in the liver cell up and that's what we see right here this stops the liver from making too much glucose and it stops it very very quickly glucose is a poison we're avoiding the poison with this very very Rapid Control. ultimately right and what's that going to happen to the concentration of glucose in the cell it's going to fall we've just reduced the amount of poison okay make sense clear as mud yes sir. I will autograph these for you you can sell them on eBay I you know you don't know how much you might make from your knowledge here okay so knowledge is power knowledge may be money so you might meet some exciting people from having these things too. You never hey come over to. my house we can listen right or come Watch Me Turn the page of the calendar over that's what you're going to say right. glycogen storage diseases arise as a result of efficiency of certain enzymes either in that pathway or related to that pathway okay so um there are several of these voner disease uh this one lacks a glucose 6 phosphatase and affects liver and kidney and what happens to the glycogen well it's got an increased amount of glycogen but it has a normal structure well that sort of makes sense because this doesn't build glycogen is involved in doing other things. only the muscle cells are lacking the glycogen phosphor all right lacking glycogenosphor what happens when we look at the glyc there it's got moderately increased amount not surprising because this is what breaks glycogen down. It has fairly limited effects limited ability to perform strenuous exercise because of painful muscle cramps otherwise patient is normal and welldeveloped a person lacking glycogens phosphor in their muscle loses ability to do strenuous Exercise. The main thing if we look to what happens with the thing here's here's a a plot of the concentration of ADP that's what we get from the breakdown of ATP okay um for a person who has uh mardal disease all right and uh this person is doing this this is. a person with McArdle disease sees ADP levels go high and then it falls meaning that the cells are catching up and making ATP now for that last chance at a CD my question to you is what's making this possible. It's something we learn during the term something we learned a very important process that allows these people who have this disease to lead a fairly normal life. It could be slightly but no that's not the right answer the it's a process we learned during this term. the Cory cycle right what does the Corey cycle do glutose the liver has a normal enzyme right and so when the muscles start running out of energy what happens oh wow we need some glucose they can't get glucose from breaking down of glycogen but the liver sure as he can do that and the Cory cycle kicks in okay so in essence it's a a backwards thing to the lactate that you talked about but it's the fact that the phosphor in the liver is perfectly normal that makes sense. pretty readily in the fact that you're really just you know as as a kid you're going to have problem with exercise and you're just worn out with this so yeah I think it would be fairly easy to to detect that other questions I need to look in the back of the room and see if my surprises are ready yet or not are the surprises ready are the surprise ready oh okay are you ready for a surprise okay at this point you can put your pens down and your pencils down because we're not going to do anything more. heard before okay so um you guys know I like the Beatles I write a lot of stuff to Beatles music and you know the Beatles were like this but I really think they should have been like this you know I mean if this were an ideal world that's what it would have looked like. So as I was putting this together I sat in I thought about the Beatles and so forth and then I thought you know that's really odd you know there's all these things out there that relate to music that involve the letter B. hear the bgs oh you heard the BS okay Night Fever Night Fever right okay so anyway and what succeeded the bGS was a really important group known as right the back street boy what a group huh and of course what succeeded them we know of course was um yeah low moment in music I think but if you thought you've seen low moments in music You Ain't Seen Nothing Yet let me introduce the next bees that are going to turn the music world upside down through the bio comical choir please come down. Valeria and Linda so uh thank them all for uh thank you all for coming to help me with this I thought about you know introducing them you know we think about flash mobs I thought maybe we could just call these guys the world's first flush mob you know but that might be a little mean so I didn't do that so okay so we're going to do some of Britney's favorite hits we're oops we'll do it again and you guys know the rule about singing loud right okay. the first song that we think about is the fact that how many people in here are really sick and tired of that Sunshine there we go. When it finally turns out dry will be put away our reer it will probably be but I'll surely miss the Reindeer cuz the sound of the Falling Rain P down the makes. We don't want that Sunshine anymore please join us in singing our first big hit known as Let It Rain oh the Oregon weather's Dy the is mostly cloudy you can't stop it if you complain. music inside my brain so let it rain it rain let itRain okay I couldn't quite hear you guys Heather is going to pick the key for Heather will pick theKey okay I've been told I'm not picking the key on the next one so okay we have someone here who's much more musically talented than I in fact I should put the microphone with her perhaps we do that. who I'm destroying all my equipment here all right somebody put oh I don't want you don't wants that okay all right maybe I'll just hold it close to you all right wrong one here anyway all right the next song um we learned a lot during the term about hemoglobin. okay this is an old song that many of you may not know and some people here may not generation I grew up with this ad it's an old Coca-Cola ad it goes Heather S put some oy [Applause] [Music] ring Yank on his the globe and shapes will change a bit what a sight to see the way they toy cooperatively and as I exit from the lungs to swim in the blood stream metabolizing they allpress their needs to to them. hear a lot of voices on it's about sering proteases all right okay okay hea Heather started go for SES work almost identically Amino a TR tight changing their structure when they S1 then there are elect shs at the AC as theaction next [Applause] theide elak without ACH so one piece is bound to it the get set free has to act next toag where it started waiting for a pepti chain that it can itself to go and start all again. louder than you've sung before okay you do know you will know the last one. MP3's got added to my iPod some sometimes were and exams when the Cur turned out I don't think it's so my scores are too low sliding by finally there's examination on December. Heather take us no we're all starting all right ready one Anna two mil Hall dirty and they gety he walks to and not louder [Music] started MP3â€™s got added Â to my iPod. 5m I'll have my car pack with information so I don't have to memorize it and I'll feel like aart with my party just one to go and then ho I'll be all right I think you got it thank you. [Applause] oh yes thank you thank you [Music] sh if if if you're too crowded for the final and I donâ€™t get a chance to say it I hope you have a great holiday and I will see you next time thank you indeed you too study hard.

ROUGE-1: 65.27, ROUGE-2: 63.44, ROUGE-L: 62.64
BERTScore: 81.84

==============================================
==================== [14/100] ====================
Summary:
JUDY HOYT: What I'm showing up here is the schedule to orient us. This is lecture 22. We'll talk about silicides, device contacts, and I've added in a new material this year on novel gate materials. Part of this is covered-- the first two topics are covered in chapter 11. And then we have one more lecture, which is on strained silicon and silicon germanium growth and processing. There'll be four speakers in each. And those will be the oral reports and the student reports given on Tuesday and Thursday. On December 7th, we have these four speakers. We're going to hear short presentations, about 16 minutes each, from these four students on everything from high k going to diffusion and gallium arsenide. And then on the Thursday of the ninth we have four students scheduled. And I just want to remind people, if you're doing an oral report, you're expected to provide handouts, the same type of handout that I use during lecture. If you need help in making Xerox copies, contact my assistant. The notes for today's lecture are given in handout 36. If you have any questions about the final project, just please email me or contact me after class. We want to talk about the formation of silicides. How we make contact, how we make the structures and make good, electrical contacts and the device. And as I mentioned, I've added a new module this year on novel gate materials. So far, we've talked about how to get these insulating and doped regions inside. the device. We've talked about oxidation, implantation, diffusion, thin film deposition, and how we etch structures. But at this point in the device fabrication of the seam laws flow, we need some way to make a good electrical contact. The contact itself is still generally considered part of the frontend because you're contacting the silicon. And then beyond, that everything is in the 6.773, which is the backend technology. This is just a schematic I've shown a couple of different times to point out what I mean by the contact. doped drain. Here's the gate material. And I need some way of making a contact between this electrical connection here, this metal line, and the silicon itself. And you can see that can consist of several different materials. In this particular picture, these sort of dark regions contacting the silicon are going to be made of silicide. And we'll talk today about how you fabricate those silicides. Let me also-- I want to talk about local interconnect. Sometimes the contacts themselves are also used for something called local Interconnect. In the early days, if this was the drain, it was called a drain. But this is a local interconnect. It only extends over a very small distance. A very short metal wire locally on the chip to do interconnect from, say, one neighboring device-- in this case a transistor-- to another neighboring device, a resistor. Talk a little bit about historically about how contacts were made. And in fact, if you recognize that this is an NPN device, and this little n region right here is the emitter-- this is the P-type base as shown here in red. or the source of a transistor, a MOSFET, people simply used aluminum, which was the metal of choice, directly on silicon to make both the contacts and the interconnect material. So it was convenient. You could contact the silicon with aluminum, and then you could run wires along the chip. And that could interconnect the various devices. The advantages of aluminum has a low resistivity. It's the second lowest of all the metal candidates. And it has very good adhesion to silicon and to silicon dioxide. If you let it sit for a few minutes, an hour or so, you grow a thin, natural native oxide, SiO2, on silicon. The nice thing about aluminum is that it tends to reduce or eat up that oxide on the silicon, and it forms a very thin layer of Al2O3. But this layer is quite thin, and the aluminum itself can diffuse right through it. So this enables you to form a very good electrical contact without having an intervening layer of oxide. Slide 4 just shows you some of the basic properties of interconnect materials. Here is aluminum on the top. Again, one of the most popular for many years. The resistivity is listed in the second column, somewhere around 2.7 to 3 micro ohm centimeter for the resistivity. And the last column shows the melting point. So it is a low melting point material. The only other metal of consequence that has a lowerresistivity is copper, which is shown here, the third one. Copper is the material of choice for today's interconnect. Copper oxidizes very readily, even at room temperature. Copper is more difficult to deposit than aluminum. Copper was introduced in research in the mid 80s and in production about 10 years past that.it can cause lifetime problems. Contact their contact their at: http://www.electrical.org/electronic-science-and-technology/electrical-science/electronics-scienceÂ andtechnology-andÂ technology. contacts can, to a semiconductor, can be sort of divided into roughly two classes. There's an ohmic contact and a Schottky contact. A Schottki contact is a rectifier. It is when you apply a large voltage in one direction, the reverse direction, not much current flows. So that's not a very useful way to make a contact to a device. It's basically a diode. And the current transport is by this sort of thermionic or thermal emission over this barrier. is not considered desirable for making a good contact. An ohmic contact on the other side, or a tunneling contact, occurs when you can actually tunnel right through this barrier. And so if you do make high doping right near the metal, you can reduce this depletion layer width. And it enables this tunneling. So this is considered desirable. This is what we want. It tends to happen, particularly with aluminum and most metals, if you make the surface doping very high. A concept that is very new. we want to talk about that is shown here on slide 6 is called the specific contact resistivity. And we usually use the Greek letter rho sub C. The definition of it is given here. It's defined as being equivalent to the derivative of the voltage current density characteristic at a metal semiconductor contacts. So it's partial v, the voltage, by partial j, basically. And so we usually assume a structure where the current density is uniform across some contact area. Then you can calculate the contact resistance R in ohms. it's got a units of resistance times an area-- and divided by the area of the contact. So if I make a smaller contact area for a given specific contact resistivity, you're going to have a higher resistance. And this is a problem if I'm scaling devices. As I make the area the current goes through smaller, the resistance of that contact goes up. Unless we do something to make better contacts as we scale devices, just because of this geometric factor. And we'll see some specific numbers on this. A Schottky contact is governed by thermionic emission. So it's a thermionic process emitting carriers over this barrier. It's this barrier between the Fermi level in the semiconductor and the Fermanilevel in the metal. So that's going to tend to be a property of the doping in a semiconductor, and what kind of metal you put on it. So if we take this equation, which we know, the current voltage characteristic is e to the minus q phi B over kT. exponential in the applied voltage. And we just use the definition of roh sub C, you can calculate, as shown on the bottom here of slide 7, what the specific contact resistivity should look like for a Schottky barrier. And you see it goes exponentially, like the barrier height. So if we change that barrier height, we can change rho sub C. So what we do in practice is we try to get into a different regime. Instead of being in the regime where we're dominated by tunneling over this barrier by thermionic emission, rather, excuse me, over the barrier. in the limit of very, very high doping. So we form these-- you see we still have this barrier, phi B. But the distance, the depletion layer thickness in the semiconductor, is very small. And that happens when you make the doping high. So what people do in practice is you dope very heavily above, say, above mid 10 of the 19th, you get quantum mechanical tunneling. That's really what's dominating. And then you will get an IV characteristic that is essentially ohmic. this number, is about 10 to the minus 7 ohm-- that's ohm centimeter squared for an aluminum and silicon contact. So the question is if I change the doping from 1e19 to 1e20 by a factor of 10, how much does rho C go down? And again, this is an exponential relationship. So you expect a big change. It's a pretty big number, as it turns out, if you plug in a standard size of a contact on a silicon. chip. That's a 10 to the 19. At 10 of a 20, you do the same sort of thing, and now you get about 6 times 10 to. the -6 ohm centimeter squared. So that's about a factor of 9,000 lower. So it changed by almost four orders of magnitude, the contact resistivity, just by upping the doping by a. factor of 10. She got four order of magnitude. So this tells you, you need to have-- if you're going to get reasonable contacts in silicon technology. considered a little bit on the too-high of a side for a contact resistance. But it's just interesting to look at these numbers. And in fact, I've taken on the next slide figure 11-7 from your text. And you can see that these numbers are in pretty good agreement with what people have measured. And the theoretical curve is shown here with the solid line. There you cansee there's reasonable agreement. But you can also see the doping up on this scale here for two different metal systems. Notice here this is a log-log scale. So we're getting an exponential dependence in the heavily doped regime. The problem is we know that there are electrical solubility limits. We cannot just arbitrarily keep increasing doping. We're trying to find ways to do it. But you know if you do an implant and you do a certain anneal, you get doping up to a certain value, maybe depending on the doping, maybe in the 20s or the 30s. the low 20s. Maybe 2 to 4 times 10 to the negative. Beyond that, it's very hard to go much further. So the problem is that rho C is not really scaling because of the doping electrical solubility limit. The contact passivity doesn't scale as we shrink technology. And this is a major problem. People are looking for new methods, new materials, whatever, some way of getting the doping up, or a new method of making contact. That's kind of a fundamental issue. are going to be silicides, either cobalt silicides or nickel silicide. They're a contact between a metal and a heavily doped semiconductor, which is silicon. In 2003, they wanted to have about 2 times 10 to the -7th ohm centimeter square. But if you go to 2004, you want to lower it according to ITRS about 1.6 times10 to -7. That's all in yellow, and that's what we call rho C. which means their manufacturable solutions are known. They haven't yet been integrated. And when we get to 2008 in the red, to get down to about 0.8 times 10 to -7 ohm centimeter squared, there aren't any known solutions that are manufacturable. So we're coming up against the red brick wall here because the device scaling and the need to make the contact size smaller means that we need to drop rho C at this rate. And it's just nobody knows yet how to make a contact that has 0.9 times 10. silicide sheet resistance in ohms per square. That's not a problem. None of that-- that's all in white, which means people know how to do that. The real problem is making these really good low resistivity contacts to the silicon. I just want to show an example of how-- so you get a feel for how the numbers work of how one does a contact resistance calculation. This is for a MOSFET. It's shown on slide 12 of your handouts. I'm showing the dimension of the contact, so the region over which the metal is in contact with the silicon, in this dimension is 0.2 microns wide. OK, now into the page, or into the board, we're assuming that it's 1 micron. And in fact, this is a cross-section view of the device. If you were to look down on the device, a top view, this would be your source contact region. Here's your gate in the orange. And here's the drain. So that's the area. Assuming we go back to ITRS, assuming we are here roughly in 2002 and the contact resistivity is about times 10 to -7 ohm centimeter squared. Then can calculate the resistance of just the drain contact itself. The resistance is just that rho C divided by the area of that contact. And you get 100 ohms. So we're talking about 200 ohms of the total resistance of the device just being due to the contacts because of the size. large resistance. So we'll see that the contact resistance actually does dominate. And that's exactly why this number is dropping with time. People want it to drop because they want to be able to continue to scale the area of the device. But there's a fundamental trade-off here, unless we can get this rho C number down. And this is a classic structure to actually measure contact resistance. It's called a Kelvin structure. I took this particular picture out of your textbook. figure 11-35. There's a reference to it in your textbook, a paper that an article that talks about it in much more detail on how it's actually made. And what you do is you have these dark regions here that are funny shaped are considered to be the N plus region that you want to contact. The dashed lines represent the metal. So that would be the metal level. So this is going to take at least three masks to powder. And these little square regions with the X's going through them are the contacts. L-shaped brackets are made of metal. And basically you perform a four-point kind of measurement. What you're doing is this little region here that is square in the center that has a dimension of L in one dimension by L in the other. The current then comes through on this leg. So the current flows through the diffusion. Then it flows up through the square, the square contact. And then it flows out through probe number two on the metal. So you put an ammeter here. You put a volt meter between probes. 1 and 4 and you measure the voltage drop across that face. And then you just divide V divided by I, whatever you measure. And that's going to be equivalent to rho C divided by the area of the contact, L squared. So this is a very common way to do it. You might say, well, why do you go to the effort of having separate probes? Why don't you just measure the current and the voltage on the same probe points? And the reason you do this is because you don't want to have extra contact resistance, say, of your probes going down. the voltage. So that, therefore, you're only measuring, really, the voltage drop across this the contact face, the square face. So it's a very common structure, the Kelvin structure, you'll find on a lot of test masks and test circuits that people use to measure the contact resistivity. Here's an example shown on slide 11 using a cross-bridge Kelvin structure. You find that you get a current of 10 microamps through the contact, so that's I23, when you measure a voltage drop of about 320 microvolts. multiplying 32 ohms by the area of the contact. And you get 3.2 times 10 to -7 ohm centimeter squared. Still a little bit high. It's still about a factor of 2 too high. But it just gives you an idea. Typically you use several different dimensions. So you either use a 1 by 1, a 5 by 5, and a 10 by 10 square. You make sure you get the same specific contact resistivity number over all of those. Plus diffusion and things like that. So you want to use different areas. And for different size areas, you should get the same number. If you don't, then you probably have current crowding effects, and you need a more sophisticated two-dimensional model. So that sort of introduces the whole idea of scaling and why we want to do this. I want to bring up some other requirements. We said it's good, it's important to make a low-resistance contact. But there are other requirements besides that. that will kind of eat away, if there is any little native oxide, that will eat it away. You don't want a lot of excess carbon or other things at the interface because that's going to cause an increase in your contact resistance. That's one thing to get low-contact resistance. The second thing you want is good thermal stability. After all, there will be subsequent thermal processing. And those multi-level metal schemes involve annealing steps or deposition steps that could be in the range of 400 to 500 degrees. Aluminum has a finite solubility for silicon. The silicon actually gets sucked into the aluminum and causes this spiking effect. Today if you do this with any kind of reasonably shallow junction, when you go to heat the thing up to do the final forming gas anneal, you're going to spike the junction and you'll destroy the device. If you have a very deep junction that's many microns deep, it would never spike because it never gets that deep. But now the junctions are very shallow, they're 0.1 micron or less. This is sort of a classic case of junction spiking. You can see it's created all these voids because there's a solubility of silicon in aluminum. When you etch the aluminum off, you see all these holes. This is why you never put aluminum directly in contact with silicon unless you're making a really deep junction, like a micron-deep junction, you have some kind of device. In MOSFETs today, the typical source drain junctions are 0.1 microns. The silicon is soluble in the aluminum, if you put silicon in the metal itself, so when you sputter, you don't sputter pure aluminum. But it's still a bit of an issue is that the silicon itself can actually precipitate out of the aluminum. And you get these little silica precipitates, which can increase the specific contact resistance, especially in N-type silicon. So it's making an aluminum 1% silicon contact to silicon, which was, again, after pure aluminum, people did. in the 1980s or so, but again, it's still not something that people typically do because you're going to get a higher contact resistance. The way people go today is to form what they call a barrier layer. It forms a barrier between this aluminum and the silicon. The barrier has a very low specific contact resistivity. So it still makes a good contact, but it doesn't allow the aluminum or the silicon to talk to each other. So you cannot get this void formation. You can't get the spiking. silicide. So in between the heavily doped silicon, you now have an inter layer of this material that forms a barrier. So this prevents the chemical interdiffusion between the silicon and the aluminum. You pick a material that has good adhesion so it doesn't peel off. And of course, good electrical conductivity and low contact resistance silicon aluminum. So that's to satisfy all of these things. And these materials, titanium and tungsten, have reasonable contact resistivity. They are still not low enough to meet a lot of the ITRS requirements in the future, but today they're good enough. his book how he's saying titanium may work as a sacrificial barrier. May or may not exactly work this way, but it's one potential methodology. When you heat the structure, you may get formation of TiAl3 for some time and portion. And then here at this point in D, you can start to get the aluminum incursion. So the idea is you put down enough titanium that you're not going to end up with a spiking problem. And typically, if you want to anneal a typical forming gas, 450 or so, 1,000 angstroms of titanium seems to be adequate barrier layer. A lot of these materials for barrier layers. Ti-tungsten or Ti-nitride are very often-- they're polycrystalline, basically. And what can happen if you're not careful is the aluminum can actually diffuse through the long grain boundaries and can still make its way to the silicon and end up causing problems. So people often, when they deposit these material, they sometimes sputter them in an ambient that has some impurity. Could be nitrogen, is one of the most common. grain boundaries, it helps prevent the aluminum from diffusing down in and getting to the silicon. What ambient you use will determine whether it's a good barrier layer or a poor barrier layer and how long it's going to stand up. On this page 21, I'm showing a classic process that was developed a number of years ago called the salicide process. Salicide stands for-- the sal comes from self-aligned silicide process and you'll see when we go through it what we mean by self- aligned. So we start here with our naked device ready to be contacted. We just have N plus source and drain. And you have a heavily doped polysilicon layer. We then form our oxide spacers. So you know how to form sidewall spacers now. You deposit a conformal layer of SiO2, say low temperature oxide, and then you etch it back anisotropically. And here's your titanium layer that goes everywhere. And then you do a magic anneal at the right temperature. the metal, the titanium, is contacting the silicon, you form a metal silicide, say TiSi2. So it only forms where it's in contact with silicon, which is right here, this dark region, and on top of the gate. Everywhere else you have still remaining some unreacted metal. So we've created a material, a titanium di silicide or a metal disilicide, that because of the virtue of its chemical structure, it now stands up to the etch. I did not have to do any photolithography to pattern this metal. The metal was deposited over the entire chip. It was reacted with the silicon, and then it was just etched off in a blanket etch. So this kind of a salicide process was a big breakthrough in CMOS technology, say around the 80s or so. It's self-aligned because wherever there's exposed silicon, you will end up with a metal contact, a line to that exposed silicon. So it's very good alignment. easier to understand. It's the exact same process. You have an N plus source and drain. You form your spacers. You react the metal. It does not react. Hopefully it does not creep up the sidewall, which is a problem. You then selectively remove the unreacted metal form, put your dielectric down everywhere else, and put in your metal contacts. So that's a basic metal contact scheme that people use today. What do people use? Which materials are commonly used? Well, some of them are shown here on slide 23.  Ti-silicide also has a tendency to agglomerate when it's very thin at higher annealing temperature. Industry moved a number of years ago primarily from Ti-Silicide to cobalt bisilicide. Cobalt has a little less lateral encroachment over the oxide spacer. It's a little more sensitive to surface contaminants. The beauty of Ti is, again, the titanium eats its way through things, through oxides, sort of reduce oxides. So cobalt, you have to have a really clean interface. Nickel silicide has the lowest silicon consumption. It can be formed at very low temperatures. Big problem with nickel is you have to be careful of your thermal budget. Nickel contamination of equipment and of the wafers is a big problem. It doesn't have very bad narrow line effect for silicide in the gate. And watch out for nickel. Nickel is a very fast diffuser, remember, in silicon. And Nickel is also a deep level. So nickel contamination is a huge problem. Nickel silicide is becoming more and more prevalent in research and development. In the case of cobalt disilicide, the metal diffuses through the silicide into this interface here and then reacts. So you're going to form a reaction between the metal and the silicon. The question is, how does the reaction occur? Does the metal diffuse in and meet the silicon down at this interface or vice versa? Well, it depends on the particular type of silicide. And people need to deal with this. less likely to have creep up. In the case of titanium disilicide, in fact, what happens is the silicon is what's the fast diffuser through the Ti-silicide. It diffuses up and meets the metal. So if you do it long enough and if you have a short enough spacer, you can see the disilicides can creep and grow up from the source and drain down from the gate. And eventually you may actually bridge. And then your device is dead. you have titanium on silicon that's reacting. Here we have a certain thickness of Ti-silicide that's already formed. People do model this. There are silicide models in SUPREM-IV. Not necessarily perfectly accurate, but what people model is the diffusion of the silicon from the bulk through the titanium disilicide up here to this top interface. So this is what might happen in an inert ambient. Now, if you do the anneal in a nitriding ambient, so in an ambient that has nitrogen, at the same time, you're forming Ti- silicide at this interface, you can be reacting. The titanium is fairly reactive. Slide 26 shows you some of the different uses of silicide in silicon technology. So silicide are used, as you can see, to strap the poly. And finally, it can be used as a gate material. And I've actually updated it. I added a fourth one. So you form a little silicide during the salicide process. Well, what does that mean? Again, you're going to reduce the sheet resistance of this junction by forming a thin layer. It also forms a barrier layer, as we mentioned. There are two phases of Ti-silicide. There is a phase called the C49 phase. That forms at low temperatures. The modern silicide that I mentioned here is this nickel silicide, NiSi. It's formed at very low temperatures, 450 or 500. And it has a low consumption, only 1.8 nanometers of silicon consumed per nanometer of metal. But depending on how thick of a silicide you're trying to form, you may eat into your junction. work first. But what this is is a cross section of a MOSFET. And we've seen this cross-section a number of times now in our class. We now have enough ammunition that we can actually go sit down and calculate all these resistances or estimate them given a geometry of a particular device. So the resistance that we really, when we scale the channel length, what we're really trying to scale is the channel resistance, R chan. OK, that's fine. We make the channel shorter, we can reduce that resistance. But the problem is, what happens to all these other parasitic resistances, the net resistance of the device is really not going to go down by very much. with the source drain extension. It has a certain sheet resistance. It's doped to a certain level, it's usually very shallow. The second one is the resistance of this region here, R, that-- and generally, this region has been silicided. So it's going to have a lower resistivity. The third is the contact resistance from the current flowing through the silicon up into the metal. So all three of these are going to add up and give us different contributions depending on the geometry. There is another resistance called the spreading resistance. This first was discussed by Ming and Lynch back in the late 80s. It's a very, very high density of carriers. The current then spreads out as it goes into the source drain extension. This is such an important resistance that it can't be calculated by hand, but it's actually pictured on page 28 here, just to give you an idea. One of the reasons it's so important is that it allows you to control the flow of electrons. old paper. It's before they had source drain extensions. But you can imagine it then spreads out here into this region over certain distance. And how far it spreads out and exactly how it spread out depends on the doping and the geometry of the structure. You can't calculate it by hand. So this that's called the RSP here in this little diagram where he wrote down the different resistances. So our spreading is one that generally has to be computed either by a two-dimensional simulator or you have to get it out of test devices. those three resistances we can calculate by hand, that gives you the minimum series resistance of the device. There will always be a little extra, which is spreading resistance, which you have to simulate in a two-dimensional simulator. That's how we make contacts. I just wanted to go on and spend most of the remaining time of the lecture and talk about something else that's come up in the last three or four years. We can also use silicides not only for the contacts, but we can also fully silicide the gate and use it for the gate. classical older technology, the traditional technology. This is a photo from an Intel device. It's a somewhat older photo now. This was published back in about five years ago in 2000. And what it shows is what we've just exactly been talking about. Here's the polysilicon gate. These are the sidewall spacers. You know how to form them. And this is the silicide in the source. You can see it looks very dark because it's been silicide. depletion of the polysilicon at very high gate biases. So people are concerned. They want to get rid of poly as the gate material. But poly is an extremely easy material to integrate. People know how to etch it. It's not reactive with SiO2. That's not the case for metals. But people are thinking of replacing poly, but it's got a lot of complex process integration. An easier process integration that people are considering is rather than digging the poly out. only reacts to form maybe several hundred angstroms of silicide. People are saying, all right, we'll put enough metal on top of that, make it really thick metal, so that it reacts. And it reacted at a high enough temperature for long enough time that the metal reaction takes place throughout the entire poly. And you get a silicide all the way down to the gate interface. And here's an example of nickel silicide, fully silicided gate that was published about six months ago by annealing at 450 degrees. and drain. It's different from that. But it's not quite as complicated as completely replacing the gate in the etch-out process. In fact, I've got here-- showing here you on slide 30 some fairly recent results from the last couple of years of how people have made nickel silicide. FUSI is the acronym for fully silicided gate. How they've made this-- and this particular article came out two years ago from AMD. And what they're showing here is a method to form this. here, what they had to do is put a metal and maybe some other harder material-- no, sorry. They had to put, yeah, contact material, and then maybe a dielectric over the entire thing. And then CNP it down so it's planarized because you know they're going to get deposition everywhere. And they expose, then-- in the plane rising process, they expose the polysilicon gate. So here they have this very thick region where the entire gate has been silicided. This is an example of an electron micrograph of one of those devices. This gate has been fully silicided. So this is all nickel silicide. This very thin white layer is the gate oxide, very thin. And this layer here is the silicon channel. This looks like it's fairly stoichiometric, almost 1 to 1 silicon to nickel. Maybe a little bit nickel-rich. Again, we talked about Auger spectroscopy as being a means of measuring the composition of a device. using the types of techniques we talked about in our characterization lectures. This is a paper-- that last paper was from IEDM 2002 applied by AMD. IBM the same year also published at the same conference nickel silicide FUSI gates. This time they did them not only on fully depleted SOI. They also did it on a device, which is called a FinFET. We haven't had any time, really, to go into these new types of devices, but there are silicon MOSFETs these days that are not being made in a planar structure. The device has some advantages, although it's a little tricky to make. It's a double gate device. You end up getting two channels in this thin silicon film. So they may have FinFET and they demonstrated they could make a nickel silicide gate going all the way around that fin. An amorphous-looking region with Nickel silicide on the outside. And the reaction stopped right when it hit the gate dielectric. The source and drain are into the board. interesting thing that was also done in this paper, if you end up wanting to do research in this area, is shown here on slide 34. This is something called gate work function engineering. We hadn't really talked about it, but the work function between the metal-- I think we may have talked about threshold voltage control. The work function, which is a property of the metal material, to a certain extent. And the silicon, that determines the threshold voltage of the transistor, the voltage at which the transistor turns on. is, what work function do they have? Well, they have the work function, typically, of the metal. And there are only so many metals in the world. But what IBM has shown in this particular paper is that they can adjust slightly the effective work function of that gate stack. They said they could adjust it to a certain extent by how much they dope the polysilicon prior to the silicide reaction. And this is important because you need this flexibility in being able to adjust your threshold voltage. control the PT or adjust the PT a little bit. It's still a very tricky process. The reaction temperature or the thermal stability temperature is reasonably low. So you cannot take these and then take them to a backend process that is too hot. So they're very much a research. It was only published by IBM a couple of years ago. They're certainly not ready necessarily for manufacturing right now. Perhaps in the near future, but just to give you an idea of the types of things that people are concerned about. couple of days. It's not a homework assignment, but I think it's something you should do-- how to calculate these three resistances. And then we can talk about it and go through it next time. But what I want you to calculate is you're given everything you need to calculate the contact resistance. You're given the specific contact resistivity rho C. And you are given the area of the contact. You just do a simple division, and you can calculate this resistor. through. So you should be able to calculate this resistance of the silicided regions. And then the little resistor here of the source drain extensions, we are given their resistivity, and again, its thickness. So from that figure out-- so you get the ohms square and the number of squares. And you get a resistor. So one, two, and three resistors corresponding to this contact resistance, the resistance of. the current flowing through the sheet, and the resistance flowing through. theSource drain extension. In general, you want to get a high doping concentration of a silicon right at the interface. That will tend to lower the contact resistance by inducing quantum mechanical tunneling. However, there is a fundamental limit on how much doping we can activate in silicon. The so-called self-aligned silicide process, or also abbreviated salicide, has a limit on the contact resistances. It's really a big problem. If you look in the ITRS, there's a lot of concern about how to lower that. been the mainstay of technology for many, many years now. It has a lot of advantages. It's self-aligned. It reduces the sheet resistance of the deep source drain region. And it also provides a local interconnect layer. Silicides can also function as a barrier layer to prevent spiking. And the last thing, which isn't in the summary we just talked about, is that silicides are even being considered to be fully silicide purpose for the gate. And that's something that's in research right now, you may see in production over the next three or four years or so. about your oral report or whatever, please get back to me. OK, thanks. About your oralReport.com. About. Your oral report. About Your Oral Report. Please get. back tome. about your oralreport or whatever. about. your oral Report or whatever,. please getback to me about.your oral Report. about Your OralReport.org. OK. Thanks, thanks, thanks for your report. You can send it to me via e-mail at jennifer@dailymail.co.uk.

ROUGE-1: 64.14, ROUGE-2: 61.88, ROUGE-L: 60.26
BERTScore: 74.27

==============================================
==================== [15/100] ====================
Summary:
The dagger algorithm aims to provide a more principled solution to the imitational and distributional Shi problem so uh as a reminder the problem with distributional shift intuitively is that your policy makes at least small mistakes even close to the training data. When it makes small mistakes it finds itself in states that are more unfamiliar and there it makes bigger mistakes and the mistakes compound. So far a lot of what we've seen so far is that the dagger algorithm is actually something that you're going to be implementing in your homework. "Dagger" is a book about how the U.S. Department of Health and Human Services trains its policy in the real world. The goal is to make the policy more effective in the states it visits. The book is the result of a series of experiments to see how the policy works in real-world states. It is published by Simon & Schuster, a division of Penguin Random House, which also publishes the book "Let's Be Clever" " dagger" is out now and is available on iTunes. see which states it visits and ask humans to label those States so the goal is to collect data in such a way that P Pi Theta uh that the train data comes from PiPiTheta instead of P data. We're going to train our policy first on our training dat just on our demonstrations to get it started. Then we'll run our policy and we'll record the observations that the policy seats and then we'll ask a person to go through all of those observations and label them with the action that they would have taken. step eventually you'll get to a distribution where that the policy can actually learn and then you'll stay there forever so then as you collect from it more and more eventually your data set becomes dominated by samples from the correct P Pi Theta distribution so that's the algorithm. It's a very simple algorithm to implement if you can get those labels here's a a video of this algorithm in action this is in the original diag paper this was a about 12 years ago where they actually used it to fly a drone through a forest. actually get up to fly pretty reliably through a forest dodging trees now there is of course a problem with this method and that has to do with step three uh it's sometimes not very natural to ask a human to examine images after the fact and output the correct action. When you're driving a car you're not just instantaneously making a decision every time step about which action to choose you are situated on temporal process you have reaction times all that stuff so sometimes the human labels that you can get offline in this sort of a counterfactual way can be not as natural as what a human might do when they were actually operating the system. Dagger alleviates the distributional shift problem it actually provably address it so you can derive a Bound for dagger and that bound is linear in t rather than quadratic but of course that comes at the cost of introducing this much stronger assumption that you can collect the additional data okay so that's basically the list of methods I wanted to cover for how to address the challenges of behavior cloning. We can be smart about how we collect an augment our data we can use powerful models that make very few mistakes or we can change the data collection procedure and use dagram.  humans need to provide data for imitation learning which is sometimes fine but deep learning works best when the data is very plentiful so asking humans to provide huge amounts of data can be huge limitation. If the if the algorithm can collect data autonomously then we can be in that regime where deep Nets really Thrive without exorbitant amounts of human effort. humans are not good at providing some kinds of actions so humans might be pretty good at specifying whether you should go left or right on a hiking trail uh or controlling a quadcopter. copter rotors to make it do some really complex aerobatic trick if you want humans to control all the joints in a complex humanoid robot that might be even harder maybe you need to rig up some really complicated harness for them to wear. If you want to control a giant robotic spider well good luck finding a human who can operate that um and humans can learn things autonomously and just intellectually it seems very appealing uh to try to develop methods that can allow our machines to do the same. experience and they can continuously self-improve and get better and better in principle exceeding the performance of humans now in order to start thinking about that we have to introduce some terminology and notation. We have to actually Define what it is that we want if our goal is no longer just to imitate but we want to do something else. Maybe instead of matching the actions in the expert data set we want want to bring about some desired outcome. We want to minimize the probability that we will land in a state S Prime which is an eaten by Tiger State. The cost function and the reward function are really the same thing they're just negatives of one another and the reason that we see both sometimes is the same kind of a cultural distinction that I alluded to before remember I mentioned that we have S a which comes from the study of dynamic programming that's where the reward comes from in optimal control. In optimal control it's it's a bit more common to deal with costs I don't know if there's a cultural commentary here well you know optimal control originated in Russia maybe it's more common in America. thing you actually want like reaching your destination or avoiding a car accident and then use those with more the more powerful reinforcement learning algorithms. In future weeks, we'll cover more of the powerful algorithms that we'll be covering in the next few weeks. We'll also cover how to use these algorithms to help you get what you want in the real world. Back to the page you came from. Follow us on Twitter @CNNOpinion and @cnnOpinION. We'd like to hear from you.

ROUGE-1: 70.54, ROUGE-2: 63.26, ROUGE-L: 63.95
BERTScore: 71.49

==============================================
==================== [16/100] ====================
Summary:
CNN's John Sutter and Jonathan Gruber continue their discussion of consumer choice. They'll talk about what budget constraints are, how consumers make constrained choices. Gruber: What stops people from just bingeing on everything? It's their budget constraint. And then we'll end with an example of food stamps, Gruber says, because food stamps are a form of government aid to the poor. The full interview is on CNN iReport, tonight at 8 and 11 p.m. ET. earn, OK? That is there won't be any savings or borrowing,. OK? Now that is a simplifying assumption. And, indeed, we'll spend a couple lectures at the end of the semester talking about what happens when people can save or borrow. That said, this is not a terrible description of most Americans. The median American household has $400 in the bank. So that's what we'll do. It also might not be sort of a terrible describing of your life. you as well. We write the budget constraint as saying that your resources, your income Y, can be spent on either pizza or cookies. You can essentially devote your income to some combination of pizza and cookies, but you have to consider how much they actually cost in doing that. Every extra cookie that you buy, holding your income constant, lowers the amount of pizza you can have by p sub p, OK? So let's consider an example. Suppose that Y is $96, that the price of pizza-- it's an expensive pizza place-- is $12. back to the key concept we talked about in the very first lecture, opportunity cost. The opportunity cost of a slice of pizza is two cookies. And that's the sense in which you're transforming pizza into cookies or cookies into pizza, OK? Now this seems kind of abstract, but let's actually think of an organization which has taken this principle to heart to develop the best method of weight loss in America, which is Weight Watchers. Now it turns out that dieting is super hard and basically doesn't work. Dieting is incredibly hard and basically doesn't work, OK? But a much more successful approach has been established by Weight Watchers. They set up a budget constraint and ask you to follow it. So, for example, they essentially assign point values to every good you might consume. They then ask, well, what weight are you today? What's your age and gender? That stuff matters for weight loss. And what weight do you want achieve? And they say, if you want to achieve a weight loss of x over y days, then you've got to limit yourself to z points. your goal is to lose weight. So we're going to give you the budget constraint. We're not going to tell you what to eat. That's why it's better than dieting because, once again, Adam Smith was right. People like to have choices. They like to let choice drive things. So, for example, vegetables are like zero points. Snickers bars are like six points, et cetera. They have various point systems, OK? For example, suppose your budget is 30 points, which would be pretty typical. the trade-off by imposing a budget constraint, by setting relative prices across goods. The points are like utils, they're not meaningful. They're only meaningful relatively. So budget constraints can help with a lot of kind of decisions in life. OK, now what happens if we shock the budget constraint? We're going to do a lot in this class of what we call comparative statics, which is, essentially, making changes in one thing or another and seeing what it does to the system. goes from $12 up to $18. Well, what happens to the budget constraint? Let's look at figure 3-2. You have your original budget constraint BC1. The equation of that line is 12P plus 6C equals 72, OK? Now the price of pizza has gone up. What that's done is that has pivoted inward your budget constraint to BC2. It has flattened thebudget constraint because the slope, remember, is the ratio of the price. of cookies to thePrice of pizza. The slope has fallen from negative 1/2 to negative 1.1/3. So what's happened is you can still have as many cookies as you had before. The y-intercept has not changed, but you can have fewer slices of pizza. So that's what happens to the opportunity set when a price changes. And, likewise, you should show to yourself the same thing will happen when the price of cookies change. But your opportunity set will still shrink, OK? Now what about-- yeah? We haven't-- we assume they're spending all their money, but it's just a way of representing. We care about-- we just care about the area because it represents the set. But that's a good question. Now let's ask about a second thing. What if your income goes up? What if prices are back to 12 and 6, but your parents decide to send you more money? Suppose your parents-- or send you less money. It turns out you haven't been paying enough attention in 14.01. parents are mad. They're monitoring you. That's why we have the camera here. This goes directly to all your parents, OK? I'm sort of joking. And so let's say parents cut your allowance to $60. Well, what does that do? That's in figure 3-3. OK, the slope is dictated solely-- you don't do anything to control the slope. The market controls the slope, but you and your family control the level, and the level has shrunk. Audience: How do you determine your marginal rate of transformation? How do determine your-- like say it wasn't just pizza and cookies? How would you determine that value? JONATHAN GRUBER: That's a great question, and we're going to actually answer that question next lecture very explicitly. Hold on to that question. We'll talk about we'regoing to compare explicitly why income changes differ from price changes and what are the underlying mechanisms. Yeah? Audience: Great, great question. it'd just make your head spin. But the basic-- so all the basic ideas can come across with two goods, but it'd be the same mechanics with more goods, OK? You essentially, when we get to the constrained optimization, you'll essentially have more first-order conditions in your constrained optimization. That's the way to think about it. OK, so let's-- actually, that's a great segue. Let's turn to the second part, which is how we use budget constraints and the utility function we learned about last time to describe how consumers make choices. our indifference curves. Utility is square root of P times C, OK? And let's consider the same budget we wrote down up here-- $72 income, $12 price of pizza, $6 price of cookies. And what we see is that point D is the furthest out indifference curve you can achieve while still meeting your budget. And, therefore, we say that the optimum, graphically, is the tangency between your indifference curve and your budget constraint is the optimal constrained bundle. point A better? Why isn't it better to have two? Maybe you just-- maybe you like cookies a lot and don't like-- or like pizza a lot. How can we say that point D is better than point A? Yeah? AUDIENCE: Why not choose point E? It's above the budget. JONATHAN GRUBER: Yeah, you can't afford it. OK, likewise, point C you wouldn't choose. Point C has the same slope as point D. In other words, the slope is minus 1/2 at point C. The math of constraint optimization is all about the marginal decision. Remember, it's hard to say how many cookies you want. It's easier to say should I have the next cookie, OK? It's about constraint optimization. And what we want to ask is we essentially want to compare how do you feel about trading off pizzas versus cookies versus what will the market let you do in sort of trading off pizza versus cookies. That's the graphic. So let's come to the math. is the optimum is going to occur when we set your marginal rate of substitution, which, remember, we defined as minus MUc over MUp. And this is the fundamental equation of consumer choice. If you understand this equation, you can solve virtually every consumer choice problem I'll give you, OK? That basically, at the optimum, the ratio of marginal utilities equals the ratio prices. That is the rate at which you want to trade off pizza for cookies is the rates at which the market will allow you to trade. a position where the MRS was greater than the MRT. The marginal benefit to you of another cookie relative to another pizza is higher than what the market will charge you to turn pizza into cookies. The next slice of pizza makes you 1 over square root of 10 happy. Your marginal rate of substitution is 2.5. That is a meaningful concept. Utils are not, but that that number is meaningless. So we only care about it in ratios. So let's do the marginal utility of cookies. Jonathon Gruber asks audience to trade two pizzas for one cookie. "That's what that number means. And that is a meaningful number," he says. "You are willing to give up 2.5 slices of pizza to get one cookie" "So what should you do? Eat less pizza. Eat more cookies," he asks. "We can use that. That's not an ordinal. that's cardinal" "You're willing to trade. Yeah, say it loudly so we can hear," he adds. You basically want to trade pizza for cookies until these things are equal. If you do the same math starting at point B, you'll find the MRS is much below 1/2. That is, at that point, you are happy to give up tons of cookies to get pizza because, jeez, you've got 10 cookies and one slice of pizza. So you'll happily do it, and you move back towards point D. And that's sort of in a bundle sort of the intuition and math and graphics of the show. how we do constrained optimization. OK, that is hard and very important. If you understand this, you're sort of done with consumer theory, OK? This is sort of the core of what consumer theory is all about. It's all about this balancing act. The whole course is fundamentally all about one equation, which is marginal benefits equals marginal costs. OK? Everything we do is going to be about weighing the marginal benefit of an activity against its marginal cost. We want to set them equal. And this sort of example I hope explained why. The poverty line is essentially a measure of what's a minimum level of resources you need to live in America. The poverty line for an individual is about $14,000. For a family of four, it's about $28,000, depending on where you're from. If you're below the poverty line in America, roughly speaking, you get help with buying food. And that comes through a program we now call SNAP, which used to be called food stamps. It's basically a program the government has that provides money for individuals to buy food. be used to purchase food. So here's the question. Why go through this rigmarole? Why not just give people cash? This fancy thing, if we want to give poor people money, why don't you just give them money? And we're going to-- I don't want the answer yet, OK? What I want to do is show you graphically how we think about the trade-off, and then we'll come to the answer. So let's actually graph how we thought about food stamps. Let's go to figure 3-5A. you're poor. We're going to give you $500 in cash. Well, now all we've done is shift out your budget constraint from 5,000 to 5,500. What does that do to your choices? Well, consider two different types of people. Person y, OK, they used to be on indifference curve I0. They used to spend almost all their income on food and not a lot on shelter. Now what do they do? They spend a little more on food. about what I did here on this graph alone? Yeah? AUDIENCE: Like, even if like you gave them money specifically for food, couldn't they then just reallocate their other money? JONATHAN GRUBER: OK, that's a good point. We'll come back to that. OK, but do people understand what the cash transfer is, how it works? OK, now let's go to SNAP. Instead of handing them a $500 check, we give them a debit card with $500 on it that can only be used on food. How does this affect their budget constraint? this course in drawing budget constraints. The new budget constraint is this kinked line that runs from 5,000 on the y-axis to the point x2 at 5,00. Can someone explain to me why that's the new budget constraints? Yeah? AUDIENCE: You can't spend a negative amount. So you can't spending like negative amounts of your non-food-stamp money on food. JONATHAN GRUBER: Exactly, you have-- we are forcing you to spend at least $500. $500 of your money on food. It doesn't have to be a specifically labeled 500. It can be any 500. But we're forcing you to spend at least $500. Well, what does that do to your choices? Well, for person y, it makes no difference whether they get cash or whether they gets food stamps. Why does it make no difference? Yeah? why does it-- whatever, greenish, I don't know, yeah, you. You're already spending a lot of his money on. food. Jonathon Gruber: People always get to the point that makes them happiest. He says if you force them to spend $500 on food, they must be less happy. He asks audience: Do people understand the graphics here and the conclusions I drew? GRUBER: I just want to know if people understand. Why would we force people to have food? Why would you-- they're better off with cash? Yeah? Audience: Say because what makes people on the highest indifference is just what makes them happier. you die, that would be really bad. The reason to do this is because we think they don't know best. In that case, maybe we don't feel so bad about forcing the guy to buy food instead of cocaine, OK? In other words, this a program which might make sense if we are paternalistic. Now we're getting into normative economics. If we think that people won't necessarily make the right decisions, we're not going to get the best out of them. for themselves, then it may be worth actually making them worse off because they're not worse off. Their perceived benefits are worse, but they don't know what they're doing, OK? Now you can see why-- I hope you can sort of immediately see why this concept makes economists a little nervous because why do we know what we want better than they do? So it makes people a little bit nervous, economists alittle bit nervous. And a lot of people are nervous to say, gee, maybe they're just happier doing cocaine. And how do weknow that that's the wrong way for them to spend their resources? curve and all their information? JONATHAN GRUBER: That's a very good point. If you're really just sad he's poor, then you should give him money. If what you're sad about is, gee, I don't like how he's living, I'm sad he can't have better food to eat, sad at the place he lives. Then you're starting to impose your preferences, but let's be important. That's imposing your preferences. but, really, the point of SNAP isn't really with contentedness or happiness, but rather like what would be to a more sustainable life. If the taxpayer cares about, look, we want a healthy populace that's going to live a long time and be productive and pay taxes, then that would be a reason to do this. But, once again, I want to emphasize, OK, this is paternalism. If you really just care what makes people happiest, you should give them cash, OK? amount of shelter is kind of fixed, but like the amount of food that eaten [INAUDIBLE].. So, if we let people spend more money on food-- JONATHAN GRUBER: Yeah, yeah, so, basically, that's a great question. Do food stamps actually increase food purchases? First of all, there's two reasons why they might not. Reason one is everybody could be like y. X is sort of a silly case, right? You're going to die if you eat that little. in practice. Are they making a difference? Well, actually, we've run an experiment on this, OK? We're going to talk in this class a lot about empirical results in economics. Here we have an uncertain prediction from theory about whether food stamps will affect food purchases or not. So let's test it. And the way we test it is we actually have run food stamps cash out experiments where we literally take guys on in the street. You always want to start with the theory, but the theory sometimes has predictions that are uncertain. food stamps and give them cash instead and watch what happens to their consumption before and after. Food stamps is forcing people to spend about 15% more on food than they would like to unconstrained by the cash. The experiment is a real randomized trial. We literally flip a coin. Heads, you keep your food stamps. Tails, we replace those food stamps with an equal amount of cash. Then we watches what happens. What happens is that people spend about 10% less on food. "The price of our paternalism is 15%, OK? We are making people, effectively, 15% worse off," he says. "We're making them spend 15% more food than they want to," he adds. "So, actually, the evidence is starting to pour in that it might not be worth it" "In developing countries, the answer seems to be just giving people cash makes them better off, that actually, especially in developing country, people use the cash in productive ways" example, they have a series of evaluation programs where they've given people cash. And they find that people spend relatively little of that on drugs and alcohol, but they actually tend to spend it productively. And, in fact, they found, in developing countries, this often provides valuable resources for individuals to start businesses. So they ran experiment Uganda where a nonprofit company randomly offered a group of women $150, which is huge relative to their income. That actually effectively doubled their earnings. From that one injection of cash, it led them to actually double their annual earnings, OK? Vox.com followed these women up nine years later, and the effect had totally gone away. They're not worse off, but it looks like, at least what in the short run made them better off, well, that effect fades over time. But the bottom line is, at this point, I think the evidence is sort of probably in favor of being less paternalistic and just giving people cash, but that runs into a lot of difficulties in terms of our concerns about how people will spend it. stop there. We will come back on Monday, and we'll talk about how we actually go from this stuff to the demand curves we started the class with. Back to the page you came from. back to CNN.com home. Follow us on Twitter @cnnireport and @CNNOpinion. Follow CNN Living on Facebook and Twitter. For more, go to www.cnn.com/lifestyle and www.dailymail.co.uk/lpin.

ROUGE-1: 53.71, ROUGE-2: 50.89, ROUGE-L: 50.17
BERTScore: 70.64

==============================================
==================== [17/100] ====================
Summary:
Professor Shelly Kagan: Would you want to live a life on the experience machine? Would you be happy or would you be unhappy, to discover that you actually have been living a life in a scientist's lab? Hedonist views like hedonism say that all that matters for the best possible life is getting the right kinds of experiences, he says. He says if something's missing from that life, there's more to the best kind of life than just having the right mental states. "If you're just spending your life floating in the scientist's lab, you're not actually accomplishing anything," he says. "You wanted to be climbing the mountain, but you's not actually climbing a mountain" "You're not writing the great American novel. You're just floating there," he adds. "Nobody other than the scientist even knows that you exist" "There's no point in trying to pursue those alternative theories in a systematic fashion," he writes. "They're just not going to work" a variety of things you wanted. You wanted to know your place in the universe, but you don't even have that kind of knowledge either, because you think you're writing novels, finding the cure for cancer, climbing Mount Everest. You're completely deceived about all those things. You don't have the kind of self-knowledge that many of us value. Well, as I say, different theories would try to systematize these examples in different ways. Different theories might have different explanations as to whether these things are valuable because we want them, or because we recognize they're valuable. all think accomplishment's important, but it's not as though any old accomplishment is important. We can say that there are certain things that are good above and beyond experiences. After all, not every bit of knowledge is equally valuable. It's one thing to know your place in the universe, or to know the fundamental laws of physics. But again, just put those details aside. The right kinds of accomplishments, the right kind of knowledge, can be very valuable. We might have to distinguish between any old accomplishments and genuinely valuable accomplishments. thing to know what was the average rainfall in Bangkok in 1984. I'm not clear that that kind of knowledge gives a whole lot of value to your life. The crucial point is that it takes more to have the best kind of life than just getting the insides right. It also requires getting the outsides right--whatever that comes to--having in your life not just experiences but the right kinds of goods or accomplishments or whatever term we use for it. But imagine you've worked that out. We could still evaluate in principle--whatever the practical difficulties might be. about adding up all the positive experiences along with all the--ask yourself how many goods, how many accomplishments of the right sort were in that life? And that's on the positive side of the ledger. And against that we would then have to subtract the sum total of the negative experiences, all the failures and deceptions or what have you. Those would count against the overall value of your life. We could still say it's--how good your life is, is a matter of adding up the goods and subtracting the bads. of chosen to become a doctor. Or my life would've gone better for this period of ten years, but then it would've become worse. Or when we ask ourselves, how will things go for me over the next couple of weeks if I go on vacation versus staying back here? We add up the goods, subtract the bads--whatever our favorite list is--and we come to our best educated guess about the rival evaluations of not just lives as a whole, but chunks of lives. "Life's always worth living; it's always better than non-existence," says optimist. "No, no. Although life perhaps has some good things, the overall grand balance is negative for everybody in every circumstance," says pessimist. moderates say, "It varies. And for some people the balance is positive, for some others perhaps it is negative," he says. "Perhaps more accurately still, all be better off never having been born in the first place," moderates say. of their lives." We then have to get down to facts about cases, try to describe the instance. We've expanded our list of goods so that--Nobody's going to deny that among the goods of life are pleasure and other positive experiences. And among the bads of life is pain. That's what the moderates would say. It varies from case to case. But there's still one other assumption that all these positions still have in common. It's that the future holds out for them is negative. life are pain and other negative experiences. How good it is to be alive is a matter of adding up all of the--call it the contents of life. Add up your experiences and your accomplishments and the particular details of your life as what the story is about. It's as though we've been assuming, and I have been assuming up to this moment, that being alive per se has no value. How valuable--how well off you are, how valuable your life is, is a function of the contents, the pleasure and the pain. accomplishing things, am I having nice experiences or not? Above and beyond the question of the contents of my life, we have to remember that the mere fact that I'm alive gives my life some value. Life may have value in and of itself, but it's not mere life. After all, a blade of grass is alive, and I presume that even fans of the, what we might call valuable container theories, don't think that, "Oh, wouldn't it be wonderful if--as long as I was alive" What we want is the life of a human. We want a life in which we're accomplishing things, there's agency. Because you have to be a knower in order to have knowledge. The life of somebody who can have an emotional side. So, it's something like theLife of a person that, when we say, that being alive per so is valuable, presumably what they mean is being alive as a person per se is valuable. All right. Now, notice that if we accept this view to decide how well off I am, or somebody else is, you can't just add up the contents of the life. subtract the ignorance and deception. Even if your content subtotal was negative ten, that doesn't mean you're not better off alive. Modest versions of the valuable container theory say, although being alive per se is good, if the contents of your life get bad enough, that can outweigh the value of being alive so that the grand total is negative. If you're a fan of the neutral container theory, you won't have anything extra to add, because life is just a zero. theory myself--I don't find it particularly attractive. I'm inclined to think, eventually immortality would always be bad overall. But let me remind you that saying that does not rule out the possibility of consistently going on to say that even though it's a good thing that we die. It could still be the case that we died before life has turned bad. It's compatible with thinking that immortality would be bad to think that in fact death comes too soon. But of course, we now have a return of the division between moderates, optimists and pessimists. The central bad thing about the fact that I'm going to die is that because I'll be dead I will be deprived of the good things in life. But although I've been at pains to say this is the fundamental bad thing, I think it's arguable that this isn't the only bad thing. There are other features of death, as we experience it, that at least add to the way that death occurs for us. Or conceivably for some of these things, perhaps it mitigates it; it minimizes it. It's inevitable that you're going to die. There's no avoiding the fact that you'll die. So we might ask, what about this inevitability of death? Does that make things worse? And here I want to distinguish between the individual question about the inevitable of death, and the universal question. It's not just merely the case that in fact we are allGoing to die; it's a necessary truth that we're all going to death. So just start by thinking about the fact. that it's unavoidable that youâ€™ll die. of death make it better or worse? And the interesting thing is, I think you can see--you can get a feel for both possible answers here. On the one hand, you can imagine somebody who says, "Look, it's bad enough that I'm going to die, but the fact that there's nothing I could do about it just makes it worse" On the other hand, there are those people who'd want to say, "No. Actually, the inevitability of my death reduces the badness" the fact that you can't change it, it loses some of its grip to upset you. If we then realize that there's nothing I can do about the fact that I'm going to die, then perhaps some of the sting is eliminated. When we see that something is just necessary, we--it reduces the sting of it. The philosopher Spinoza thought that if we could only recognize the fact, what he at least took to be the fact,. that everything that happens is necessary. in life is necessary, then we'd get a kind of emotional distance from it; it would no longer upset us. We could no longer be disappointed, because to be disappointed in something presupposes that it could've been some other way. Spinoza thought if you see that it couldn't go any other way, then you can't be sad about it. Well, maybe that's right, but going back to the firsthand, I don't know how many of you have read Dostoyevsky's short novel The Underground Man. can't change the fact that two plus two equals four. And so Dostoyevsky takes that thought and runs with it and says, "Yeah. It doesn't help to say that it's inevitable. It makes it worse." Well, there's both sides. And as I say, I myself, in different moods, get pulled in both ways. What about the fact of our powerlessness that we're stuck with the necessities. God isn't stuck with them. Does the universality of death make things better? or worse? And again, you can sort of feel the pull both ways. On the one hand you say, it's bad that I'm going to die, but I'm not a monster. And there's at least some comfort to be had, isn't there, in the realization that this thing isn't just true for me? It's not like the universe has singled me out for the deprivation of dying too soon. It's something that it does to everybody. So perhaps there's some comfort in the inevitability of death. different aspect of death worth thinking about. What about the variability of death? After all, it's not just the case that we all die. Some of us make it to the ripe old age of 80,90 a 100 or more. Others of us die at 20, or 15, or 10, or younger. We could imagine a world in which everybody dies--everybody dies at the age of a hundred. Does it make things worse or better that there's this kind of variability? of view of somebody who gets less, this is obviously a bad thing. It's bad enough that I'm going to die too soon. But what's even worse is I'll get even less than the average amount of life. That's clearly an extra-bad. But we might then wonder, for every person who gets more than the median, 50 percent of the people get less. So perhaps in terms of the individual badness of death that's a wash. Maybe. But it's a further fact about human psychology that we care more about being short-changed than we do about being, as we might put it, overcompensated. fact that there's variability and so some people get less than average--that extra bad, I suspect, outweighs the extra benefit of some people having more than average. We've had inevitability; we had variability. What about unpredictability? Not only is it inevitable that you're going to die; not only do some people live longer than others, you don't know how much more time you've got. We could imagine a world like this where it's inevitable; everybody's got some date on it. 20s--you know 20--roughly another 60 years are going. And as you're busy calculating all this, you're walking across Chapel Street and you get hit by a truck and you die. Right? Because of unpredictability, you can't really know. And in particular, it's hard to know how to pace yourself. It's a long-term plan, which can go wrong if you get sick and die in your early 20s. Well, that's a rather dramatic example, but the same sort of thing in principle can happen to you. all of us. You make a life plan, what you want to accomplish in your life, and well, obviously enough, some of us will die too soon. If only you'd known you were only going to have 20 more years instead of 50 more years, you would've picked a different kind of life for yourself. We might think of it as, the overall shape of your life matters. What we could also call "the narrative arc of yourLife" matters. Let me illustrate the point with some very, very simple graphs. least the local contents, it's a bit hard to see why that would be the case, right? We've got equal periods of suffering and doing slightly better and slightly better. For every bad period here there's a corresponding good period here. In terms of the contents of your life, being crude but you see the point, both are equally good. So the extra points get added either way. You might say, look, if we're not indifferent between these two lives, that's because we think the overall shape ofyour life matters as well. The story "bad to good" is the kind of story we want for ourselves, while the story "good to bad" is not. Why is that? And this of course should remind us of the puzzle about Lucretius. Why do we care more about future non-existence than pastNon-existence? When the bad is behind us, that seems less bothersome than when the good is in front of us. We're not indifferent. We want the bad behind us. So, whatever the explanation, we care about the overall shape of our life. A lot of us might feel that a life like this, where we peak but then we stick around--you know, isn't--can at least fail to be as desirable in which we end with a bang. If you start thinking about narrative arcs--imagine a novel, right? It's one thing to have--it's not to say that the best--if you want your life to be like the plot of a great story, it's not as though you think, "All right, the dÃ©nouement must occur at the very last page" Without predictability you don't know where to put the peak. If you try to aim for peaking later, you might not make it to that. All of this suggests then that the unpredictability of our death adds an extra negative element. It makes it harder to plan what the best way to live my life would be. And from that perspective it would be better to know how much time you've got left. But then we have to. Care about the overall shape of our lives, we might worry about wanting it to have the right shape overall. ask--so I'll throw the question out and we'll call it a day, start with this next time--then we have to ask, would it really be better to know? would you want the birthmark? Would you want to know exactly how much time you've got left? All Right. See you next time. Back to the page you came from. Click here for more from CNN iReport. Back To the pageyou came from, back to thepage you were from.

ROUGE-1: 53.27, ROUGE-2: 50.54, ROUGE-L: 48.78
BERTScore: 66.18

==============================================
==================== [18/100] ====================
Summary:
MIT OpenCourseWare offers high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourse Ware at ocw.mit.edu. The following content is provided under a Creative Commons license. Your support will help MIT Open courseWare continue to offer high quality education resources forFree. For confidential support call the Samaritans on 08457 90 90 90 or visit a local Samaritans branch, see www.samaritans.org for details. a Geiger counter right here. That's our GM tube. And we have a point source that's emitting things in all directions. Let's say it's a cobalt 60 source. It's now 0.52 microcurie. The question is, how many counts do you expect in this detector when a certain distance away? So I've actually laser-cut out a little Geiger counters jig from a previous class. And you guys can all do this too. Who here has been to the IDC before? A couple. dose and distance or measured activity and distance? Yeah, Luke. AUDIENCE: [INAUDIBLE] r cubed. MICHAEL SHORT: Close. It's, let's say, the measured activity would be proportional to 1 over r squared. Does anyone know why this formula would break down? What happens to our solid angle or our approximation for ourSolid angle? It goes to infinity, right? Can a detector actually take up infinity area on, well, anything? Never mind that unit sphere. Solid angle is kind of the analog to regular old angle, except in 3D. Instead of looking at things in radians, this has the unit of what's called steradians. A full sphere takes up 4pi steradian, which is also the surface area of a unit sphere with radius of 1. So that's where this comes from.should go to infinity, and it does not compute. Does anyone know how many-- first of all, who here has heard of solid angle before? the sphere or how much tin foil you had to use. There is a more complex and rigorous formula for the solid angle of something. Once you get to a few centimeters away, it's pretty close. Anyone want to guess what the maximum value of the red curve is? If I take this source and slam it right up next to the detector, how much of sphere is the detector subtending? MICHAEL SHORT: 2pi-- half half half -- half half a pi -- half a Pi. At 0, the correct formula does give you 2pi steradians. Which is to say that half the gamma rays leaving the source would enter the detector. That's where the detector efficiency comes in. And that's something we're going to be measuring today, which is why I have my big bag of burnt bananas. These are the ashes of roughly 50 pounds of bananas charred to a crisp at about 250 Fahrenheit for 12 hours in most of the dorms and a couple of the frat houses. a lot. So there's a reason I've been using potassium 40 as a lot of examples in this class, because you're full of it. If you eat bananas-- which, I think most of you guys do-- you're intaking a fair bit of radioactive potassium. So today, what we're going to be doing is calculating the activity of one banana. But that's kind of a very difficult thing to do. So anyone know how radioactive one banana actually is in any units at all? Whatever it is. One banana contains a minuscule but measurable amount of radioactivity. One of the ways to boost confidence on any sort of radiation measurement is to boost your signal strength. So we've concentrated the ashes of 50 pounds of bananas in here. This will boost your count rate, which is the intro I want to give to statistics certainty and counting. That should motivate the rest of the day. So I'll pull up that problem set, number 4-- which, by the way, is due Thursday. Tuesday, because we have no class on Tuesday. That was a surprise to me, but whatever. I'll still be here. We don't get holidays-- just you guys. So bonus question-- go do this. So we all know that smoking is a major source of radioactivity. And so I was thinking it'd be neat for us to find out, how radioactive is it to work in a smoke shop? Because there's all these radon decay-- oh, yeah? You actually work there. know. Most of the Boston area is 21. But once you leave Boston-- MICHAEL SHORT: It varies. I don't think it is where I'm-- from Swampscott. But that's kind of up on the commuter rails. You don't want to go to Swampsc Scott. At any rate, I would think that, OK, it's 21. You can buy them. It's still late-stage. it's like town-to-town. But you have to be 18 to smoke. How long would you actually have to bring a detector in and count in order to be sure that there's any sort of measurable difference? That's about as simple as it gets. From Poisson statistics, you can say that the standard deviation of that count rate is actually just the square root of the count rate divided by time. And that's kind of the simple thing right here. But usually, usually, the answer is "not very long" or "not at all long" and that's in the reading for today. If you want to know how much more radioactive is one place than another, you have to take a background count. As you can imagine, the slower the count rate, the less certain you can be that the number that you're measuring is actually accurate. So by counting for longer you can decrease your standard deviation. This is going to take forever. It actually takes about 67 minutes, because we've already done this calculation, to get a 95% confidence on 5% uncertainty for this sort of background. count. The radiation emission from anything is a truly random process. There is no correlation between when one particle leaves and the next particles. It's just the gross count rate minus the background-- let's keep the symbols the same-- count rate. Does anyone know how to quantify the uncertainty of this net count rate? Do you just add the two? Well, in this case, we have to account for the fact that radiation emissions from anything are a trulyrandom process. So it's actually random. And that's what we're going for. CNN's John Sutter asks how long do you have to count in the smoke shop to be 95% percent sure? Sutter: If you just add together the two standard deviations, you actually always get an overestimate of the true error. He says you want to add up the sum of the square roots of those errors. Sutter says with enough statistics, if you count for long enough or you count enough counts, then these things, on average, are going to add in quadrature. How do you know that we're 95% confident of our count rate plus or minus 5% error? That's the main question for today. Does anyone know how we'd start? Anyone get to the reading today? I see some smiles. OK. We'll start from scratch, then. All right, So who here has heard of a normal distribution before? A lot of you guys. Great. The idea here is that with enough counting statistics, this very rare event binomial distribution approaches anormal distribution, where you can say if you measure a certain count rate-- let's say this would be your mean count rate. If you go plus or minus 1 sigma away from your true average right here, you've filled in 68% of the area under this normal distribution. Similarly, if you went plus 2 sigma or minus 2 s Sigma, it's around 95% confident. 3 sigma is getting towards 99 point-- what was the number, again-- I think it's 6.5%. And then so on, and so on. There's actually societies called 6 sigma societies. And the way that they get their name is we're so confident of things we can predict them to 6 s Sigma. you have to give an answer that will relate two times this standard deviation. And now we know the formula for standard deviation of this net counting experiment. So then we can substitute in our expression for sigma-- our uncertainty in quadrature-- and find out things like, well, it depends on what the information we're given is. So this is actually how you decide how long you have to sit in the smoke shop to count in order to satisfy what we asked for-- 95% confidence that your count rate is 5% error. let's start substituting this out. That's not mine, so we can get rid of that. So 0.05 C n equals 2 sigma. And there's our sigma expression, which I'll rewrite right here. So we have see C b over t b squared plus C g over t g squared. What's next? How do we relate t g and C g? Well, let's start with the easy stuff, right? What can we cancel, or square, or whatever? Just somebody yell it out. radiation detector. How long do you have to be here, looking all weird? You want to have an answer. So why don't we just start, divide by 2, right? Divide by 2. We can square both sides. And there's a C n there. Square both sides, and we end up with 0.000625. C n squared equals C b over t b squared plus C g over t g squared. There's lots of ways to go about it. I want to make sure I do the efficient one. The standard deviation is the square root of the count rate over the time. So the standard deviation squared is just count rate overtime time. We've got too many variables, but it's easy to get rid of one of them, either C n or C g. Do you a question? MICHAEL SHORT: No, I was just going to say [INAUDIBLE].. MICHAELSHORT: Great. Now that everything is corrected here, what's next? We've Got Too Many variables. So we'll take out our C n, and we'll stick in a C g minus C b. And we're trying to isolate t g as a function of C g or vice versa. So we'll have 0.000625 C gminus C b squared. Then I'm going to subtract C b over t b from both sides. Minus C bover t b equals C g over t g. And do I have to go through the rest of the math with you guys? out the expression, which I want to show you guys here. Back to smoke shop counting time. That number right there is just a more exact part-- a bit of 2 Sigma. Instead of 0.05, we had something much, much closer. So what I want us to look at is this graph right here. We've got a nice relation now between the count rate and counts per minute-- and it was the gross count rates and the required counting time to get to that 5% uncertainty. some level. So if we have that expression right there-- so let me just actually get it all the way out so we can see. Because I want to show you some of the math-related implications for this. So like Sean said, for the condition where 0.025 C g minus C b-- let's just call it C net squared minus equals C b over t b, this equation is actually undefined. Which means that if your C b and t b -- let's say if the uncertainty from your background counting rate experiment is such that you can never get to that point. the total uncertainty down to let's say 5% error with 95% confidence, you can't actually run that experiment. Because these uncertainties are added in quadrature, if you're trying to reduce sigma down to a value below that already, how can you do that? You can't have a negative standard deviation, right? So what this actually means is that when you're designing this experiment, even if you count for 67 minutes at 25 counts per minute, that might not be enough to discern the activity of the smoke shop, or the source. Sometimes, do you necessarily have to be 95% confident of your result? Depends on what you're doing. If you can't get within 5% error-- and I believe the homework doesn't actually say that for a reason-- yeah, we don't tell what error to choose. But we do say try to get a 95% confidence. The more error you allow, the shorter time you have to count for. And I want to show you graphically how some of that stuff interplay with each other. your counting time, even though you haven't changed the counting rate, it then takes less time to distinguish whatever your source is. So if you doubled your background count time from 67 minutes to 134, then you can measure count rates as low as 42 counts per minute gross. So when you start going into the smoke shop, you can, let's say, count for a few minutes and get some very crude estimate of the counting rates and then decide how long you have to let your background accumulate so you can distinguish the source. activity in the smoke shop to within some confidence and some error. It depends on your elevation to say how much of the atmosphere is protecting you from cosmic rays. In New Hampshire, the background count's quite a bit higher, because there's a lot of granite deposits, and granite can be upwards of 52 parts per million radium. We will get into background counts and sources of background radiation in about a month, but to give you a quick flash-forward, it depends on location. You can use background counts as a radiation altimeter. One of my graduate students actually built a Geiger counter interface to an Arduino, where you could actually tell what the height you were flying at is by the amount of background radiation increase. So certainly it's going to depend where you are, right? But you want to make sure that you're in an area, to answer Sean's question, representative of where the smoke shop is. So yeah, you'd want to be, I don't know, same block. That would be a pretty good. Use this formula right here to estimate how much time you'd have to wait. So for example, let's say you go in there and you get a count rate of 100 counts per minute. That would do that would surprise me. You'd only have to count for an extra 28 minutes to nail that net count rate with 95% confidence to 5% error. If you're willing to accept 10% error, that would be acceptable. We just take that number and double it. Then, all of a sudden, you don't have tocount for nearly as long. it goes down to seven minutes and 18 seconds. So do you guys see the general interplay between confidence, percent error, counting time, and counting rate? Who here is built an NSE Geiger counter before? Awesome. So this is definitely a try-it-at-home kids kind of thing. If you want to find out is something radioactive, this is what you can actually use to answer the question, is it discernibly radioactive to within some limit of error or limit of confidence? radiation quanta or whatever that enter the detector, how many interact, and how many leave out the other side? That's we're going to be spending most of the next month on when we do ion, photon, electron, and neutron interactions with matter. We'll find out-- what's the probability per unit length that each one undergoes an interaction, what kind of interactions do they undergo, and then we'll complete this actual picture. So you can take a source of, let's say, unknown activity, put it a known distance away from a known detector with a known efficiency, and back out what the activity of that source is with accuracy. That's what you'regoing to start doing on this homework as well for the banana lab. efficiency of the detector and the geometry of the detectors. You're going to be able to measure the number of potassium 40 counts that the detector picks up. So by taking-- let's see where we have some space left. We had a little bit here. We've been using cobalt 60 as an example. So remember, we had two gamma rays emitted per cobalt 50 disintegration. Or was that cobalt 70? Or was it cobalt 80? I don't know. on average. Then you can get to the actual activity of the source. Once you know the activity of this bag of bananas, you can then divide by either the mass of one banana, or the number of bananas,. or whatever to get the final answer. That's what we're going to spend the rest of today doing. So since it's getting on five out of five of, do you guys have any questions about what we covered today or what we are about to go do? infinite medium of radiation material. Then you could subtend 4 pi. So if your solid angle is 4 pi, then that would equal-ish the area over r squared of your thing. But this is actually not that good of an approximation when you put a source very, very up close to a detector. So you'll have to integrate to say how many of these little d phi d theta of this unit sphere you have. So the real formula for a solid angle, you actually end up having to do a surface integral of the sine. thetas are actually subtended by your detector. And the value of that actual surface integral gives you the real solid angle. That's the super simple one if you just know the area of something and you know that you're kind of far away. But again, whenever possible, use the exact formula. So any other questions? Yeah, Sean. Sean, if you have any, please send them to us at jennifer.smith@mailonline.co.uk. becquerel of cobalt 60 would give off two gamma rays per second. activity is measured in disintegrations, not in number of gamma rays emitted. Dose-- you'd actually care about how many gamma rays you absorb. But activity is how many atoms are disintegrating per second, and that's the difference here. It's just twoGamma rays per atom. So in this case, it's like twoGammas per atom, or better yet, twoGamas per disintegration. per disintegration. So you've got to know what material you're looking at in order to know how many gamma or how many betas or more that you're going to get. Who here has heard of this uncertainty in quadrature before? There's a couple folks. OK. The idea here is that, again, if you just add the errors up, you're probably overestimating the error and selling yourself short. In that case, if there's no questions, let's go do this. a couple thousand volts across it. When a gamma ray goes into it, it makes some electron hole pairs. So you collect the current from that, and you get a little pulse of current. The height of the pulse tells you how many hole pairs you had, and then back it up to what the energy or your gamma was. That works fine if you collect all of the gamma energy. You don't always quite do that. Anyway, so that's how-- You all can scooch up. There's not a whole lot to see in there. there. The black part is just a carbon fiber window, because you don't want to cut off the low energy gamma. The reason there's copper is if you get a high energy gamma ray into some lead, it will emit a high-energy gamma ray. It shields the detectors from the activity out here, from you guys, from the activities coming out of here-- because sometimes I'm counting very low activity samples. And it also, if I'm count something that has a lot of activity, it shields us from that activity. it makes x-rays. And it makes a very nice 75 keV-- do you guys know keV? Good. So anyway, so this is I've got two germanium detectors. That ones also germania, but it's a well detector. So it's got a little one-centimeter hole in. They're hooked up through a little electronic box and go into the computer over there that does all the peak height analysis. Oh, yeah, liquid nitrogen [INAUDIBLE].. Thanks for pointing. out the thermal noise. Because you're looking for really tiny little signals here, so you cool everything down. And that way, it's not too noisy. These guys are OK warming up. It doesn't destroy the detector. The old detectors you had to keep cold all the time. And if they warmed up, then they were just paperweights. So this is just the counting lab. I've got an actual sample counting in here right now. We'll take a look at the spectrum in a minute. bag. AUDIENCE: Oh, did I break it? MICHAEL AMES: It's just banana ash. We'll find another bag. It's OK. You know, I'm all about making mistakes. There's potassium 40 everywhere. So after we get the count of the bananas, we'll take a background count. You'll want to subtract the two signals. MICHAEL SHORT: We just did 15 minutes ago. MIC Michael AMes: You're right. You're wrong. so ahead of me. OK, I think that's all-- Is this going to fit now? AUDIENCE: [INAUDIBLE] MICHAEL AMES: OK. I've got a whole bunch of little spacers if I'm counting something that's hot. And by hot, I mean radioactive hot. I'll space it out a little further. MICHAEL SHORT: We did just go for a solid angle too, today. MIC Michael AMes: Is there anything else I want to say in here? how long has that been going? Half a day-- less than that. Anyway, so this is a sample of quartz that was irradiated next to the reactor. You guys are going to do shorts in like a month-- did you bring your samples? MICHAEL SHORT: We're getting them. I think this ran six hours. And it's just a little tiny piece. And the reason we're running it is the people who are looking at this quartz want to run it for 80 hours, and we'd like to know if there are any impurities in it. Tungsten 186 activates into tungsten 187. So if you've looked at the chart of the nuclides, you can tell that there's all the sort of parameters you would need to calculate how much activation you'd get based on neutron flux. So you can see, there's a whole mess of peaks in here. This one-- you see that? You see that lovely, little peak right there? Can you all see that?" "Yeah, OK. So that's the full spectrum. That's the peak." The 28.43, that's the abundance of that isotope. The sigma gamma 38 is the cross section for thermal neutrons. So you could, knowing how big that peak is, what the efficiency of the detector is for collecting that peak in that geometry, the half-life, the cross set-- that whole mess of parameters-- back-calculate how much tungsten is in the sample. So that's kind of how NAA works, which I assume you've explained. is these guys are going to calculate what's in their samples. But that's not how I do NAA. The other way that everybody who does NAA is you run a standard material. So I run a bunch of different material, which means a material that how much tungsten is in it or how much a whole mess of other things are. That's the way I do it. It's a simplified version of what they do. But it's not the same thing. standards. So along with this piece of quartz, I ran a standard, irradiated it at the same time. And by comparing the peak heights and doing all the decay corrections and the weight corrections, then I calculate how much tungsten is in my sample. So I don't actually use the cross sections, or the flux, or any of that other stuff-- all of those parameters disappear. Notably, the detector efficiency disappears out of the equation, because that's the parameter that you usually have the funniest idea about. samples. But we'll figure out how many samples we'll run. MICHAEL SHORT: It's one per person. [INAUDIBLE] MICHAEL AMES: That's a lot of shorts. In pairs, right? MICHAEL ShORT: Yeah. So I'll show you how the shorts get run. So when we run your shorts, we'll running your samples and we'llrun standards, and then you can do the comparative method. Or, if you feel like it, you can doing the other method. comparative one on an envelope. Anyway-- well, we'll run standards or not, depending on how you guys are feeling. Oh, right. Let's count your bananas. So this is detector 2. We did an energy calibration earlier today. So actually, I've got a couple of little button sources. Have you seen the button sources? Yeah. So that's just aouple of cobalt 60 lines and a cesium 137 line down in here. And I know where those energies are, so that just gets used to calibrate the detectors. AMES: We're going to let this count until Tuesday. Because, why not? And I don't feel like coming in over the weekend and turning it off. So this is just picking up all the gammas coming out of the bananas, and everything else that happens to get through the [INAUDIBLE],, and all the contamination on the inside of that. And we just let it count. And then you guys can calculate how much potassium 40 is in your ashes. You'll need to do the background subtraction. month or so. So I'll give you a background spectra. I will provide the efficiency for this geometry, which is pretty poorly defined. And I can't give you the program, and it's a pain in the neck to run anyway. If we've got a really well-defined geometry that's not a big bag, usually I try to count sort of point sources-- so I've got an efficiency standard that I can use that I know what the disintegrations in that are at a lot of energies. When you're running NAA, you really want to avoid having all these fast reactions. There's usually an energy threshold for the fast reactions, like 1 meV or so. If you're near the reactor, you're also getting some fast neutrons, which can give you an n p reaction. And that's a pain in the neck, because if you've got iron, you've always got a little cobalt floating around-- you maybe need to do a correction.any questions for Mike on what you've just heard? Well-timed, because we were just talking about this stuff all week. that's how I measure nickel, using n p reaction. And I need to put the rabbits into where I've got a fast flux in the reactor. I try not to have to measure nickel,. because it's pain in the neck. But sometimes people want to know nickel. And we talked a little about what we've run in here for types of samples. MICHAEL SHORT: Well, why don't you tell us? MICHAEL AMES: OK, OK. So back 15, 20, 25 years ago, we did a ton of environmental samples in this lab. We had a whole three grad students, myself included, who did atmospheric particulate matter. lake sediments. Other analytical methods have gotten a lot better, and so they've kind of caught up to NAA, and you don't need a reactor to run those. So the environmental side of this has kind of quieted down a lot. But it's still useful for a bunch of things. And so I do some work here now. I also work in the NCORE group. So that's a lot of my time, rather than just this lab. Practical things-- let's go take a look at a couple other labs. Fish samples that we actually did the fresh fish samples. And you want to kind of homogenize those. And we had this kind of titanium blender-- you remember the Bass-O-Matic? We had this titanium blender that we dropped the fish in, and you completely homogenized the fish. Then you took a little sample of it, and freeze dried it and then analyzed it for mercury. MICHAEL SHORT: [INAUDIBLE] MICHAEL AMES: Yeah, right. Because, I mean guys saw, the rabbits are only this big. that looks at zinc deficiencies, and fingernails and toenails will give you a good record of how much zinc you've had over the last week, or month, or whatever-- depend where you cut the nails. And so I was going to get a couple of hundred African children's toenail. That didn't happen. But I did analyze my own toen nails. Well, if you went to somebody who was a little suspicious of you, asking for toenailed is a lot easier than asking for a blood sample. Because people would give up toenailing-- it's not a big deal. the things we did in this lab was we collected baby hair samples from people's scrapbooks. We analyzed the hair samples for arsenic and chromium, and then we plotted out where they were, when the sample was taken, and how close they were to some contaminated wells. And we found that it didn't correlate with the well water or the time when the contamination was the worst. That was in the mid-90s or so. Anyway, that was one of my samples. And the hair is a pain in the neck to analyze. work with. So I hope none of you give me hair samples. I won't run them. So let's go down the hall, this way. You all got to follow. And so this is just a fine powder. And it's fly ash from a coal-fired power plant. Fly ash means the ash that goes up the smokestack, as opposed to bottom ash which is what falls down. They collect a whole hundreds of kilograms of fly ash, just homogenize it, sieve it, send it out to a lot of labs to analyze. This is some soil from Montana next to a mine, so it's nicely contaminated with some metals. This is my IAEA mercury and hair standard. And this is kind of what everybody uses for standards. And you just kind of have a whole collection of them. And depending on what elements you're looking for, you try to mix and match them so you cover what you want without having to run five or six of them, which is what I do. And so I got this. And they all look the same. For longer radiations there's a spot in the basement in the reactor where they can get these, and they send them into the irradiation location. For short irradiations, like what you guys are going to be doing in a month, I send them in from here. So this is one end of the pneumatic system. And so I can put a couple of samples in here. I stick it in that little tube there, call the control room and say, OK, turn a bunch of knobs, and switches, and whatnot. And it goes schwoonk, and in about 15 seconds it's next to you. the reactor to the core of the reactor in the graphite. I usually run shorts. I'll usually irradiate for about 10 minutes. We usually let the sample sit in the reactor for a little while. So the very short half-life stuff decays away, and then it comes back out here. And the thing just kind of shoots out there and bounces into here. Then pop open the rabbit, and in that hood, pull the samples out. Iusually try to repackage the samples. count it, I'll also have whatever elements are in the vial on the thing. For when I'm running standards-- and this is when if we're not running standards you don't have to worry about this-- that powdered standard stuff, I never get that out of a bag. Because you'd never get all of it out, and I'd have contamination everywhere if I started cutting open those bags. So when I do when an irradiation, I always irradiate a few empty bags, and then you do a correction for those. it on a detector, and we count it. When we're doing shorts, I'll irradiate two samples at a time, because I have two detectors. I usually do a 10-minute irradiation for shorts. I'll do a fairly quick count-- five minutes-- right after I get the sample down there. The shortest half-life I look for is for aluminum. It's 2 and 1/4 minutes. But things usually have a lot of aluminum in them, so I see aluminum pretty well. 15 hour half-life. Longer stuff, I'll do a longer irradiation to count. There's a little overlap on my shorts and longs. That helps me do QA on things. There is a lot of archeology that NAA got used for that a lot. I don't think we ever did it here. Fred Frey, who's a professor, retired now, from EAPs-- Earth, Atmospheric, and Planetary-- he did a lot for NAA. of geological samples. NAA is really good for rare earth elements, which are hard to measure by other methods. By picking out various rare earths and the ratios, it can help identify where things are from in the world. MICHAEL AMES: The thing I really like-- excuse me, where's my vials? I used to have some smaller ones up here. But that should definitely fit in one of those. It's the rabbit. So it's definitely got to fit in there. Like, see that guy. My usual description of what size sample I like is if it's a piece that you would pick up with a pair of tweezers. So not too small to pick up-- to be able to find. And you could maybe get it with your fingers. But 20 milligrams, 50 milligraphic, 100 milligram is just in the right ballpark. MICHAEL AMES: We'll look at what comes in, and-- yeah, I might veto some things or not. working on and myself. The full size bricks-- like, that size, 2 inches by 4 inches, by 8 inches, weighs about 25 pounds. This lab has been doing NAA since the '70s, I think. Anybody else? AUDIENCE: Is there a single brick that I could just hold to see how heavy it is? MICHAEL AMES: Yeah, these are just painted lead bricks. And you know, these have been here longer than I have. And sometimes things just are somewhere, and you never move them. There's usually a bunch of them floating around. So I've got steel toast. If I miss the toe, I'd probably break my-- I don't want to think about it. And they move much bigger things in the reactor. And that's the other dangerous thing in there, dropping really big things. We've never dropped anything that big. I think somebody dropped a steel plate on their. They're heavy. Anybody else want to toss it? No, OK. [LAUGHTER] foot once. That was about the worst of it. You know, like, four-foot, half-inch steel-- boom. That's what happened to my foot. And people trip and fall off ladders. And it's the usual industrial accidents. It's in two parts. The first is raising reactor power using a low worth absorber called a regulating rod. And then the second part will be lowering reactor power. And I'll see you guys in a month or something and have fun running the reactor. power using a high worth absorber. To actually do this experiment, we need two licensed people in here, one at least has a senior reactor operator. Both Tim and I are both senior licenses, so we have that covered. The only way you can actually do these manipulations are if you're in my training program-- I'm the training supervisor for the facility. And the program you guys are in fits that definition. So I just want to show you the controls. And we don't want to run into a chance if you accidentally going too high. The experiment we're doing is basically change reactor power by half a megawatt. And we're currently at 500 kilowatts. We're going to bring the reactor up to 1 megawatts and then bring it back down. So before we can do this, you have to log into our log book as a trainee on console. We'll show you the proper way to make the entries. As you make those entries, you'll go ahead and then do the actual movement itself. using a regular rod to move the reactor power up. Channel 7 is what we control our automatic control at. If you watch the regulating rod, you'll see it move up and down on its own. That's because it's changing power based on what it sees channel 7 is doing. So if channel 7 sees that the power level's going too low, it'll cause the regulating Rod to drive outwards to increase the amount of neutrons making reactor power go up. The two channels are what we used to basically tell us what the wrecked power is. power level is based on a chart that we create. So it's not showing you megawatts, or kilowatts, or anything like that, it's showing you a current coming from a chamber. And that current is then converted into megawatts and so forth. You're going to be bringing a record up to 1. Megawatt and since it's linear, it'll be double that-- so 17.1. Now, you want to be careful when you raise reactor power. So when you start to add power to the reactor by raising a regulating rod, you don't want to keep raising it until you reach your value. period-- the reactor period. The reactor period is amount of time it takes reactor power to increase. At the power level we're at, we're not allowed to go shorter than a 100-second period. Once it reaches that value and you see it going down, you now know that you could control the reactor and keep it from going away-- rack power increasing continuously. And you'll keep holding it in until you see the number not only stop increasing, but actually go down a little. As soon as you see it going down a little bit and go of the regulating rod, You haven't stopped the power at this time, you've just decreased how fast it's going up. Same thing-- as you get closer to the power level you start at, the 500 kilowatts, you don't want to undershoot and go too low. And once you get back to the place where you started it, we'll use a regulating rod to fine tune it to keep the reactor power where would want it to be. and they've actually done a lot of these manipulations already. If, at any time, you don't feel comfortable doing something, let us know. We'll ask you just to take your hands off the console, and we'll take care of doing whatever is necessary to keep the reactor safe. But be aware, we're a factor of 10 lower than where we would automatically scram at so it would be very difficult for you to get to someplace where it would cause a problem without us being able to stop it. The reactor is on autocontrol. When we do these manipulations, the reactor operator is going to take manual control. That'll cause an alarm to come in. And this will only happen for the first time. And that should be the only time you hear this alarm, because we'll leave it on. The last person will make an announcement that we're done with power manipulations. We'll do that at the end-- is she'll take Manual control of the reactor, and she'll answer it. manual control until the final participant has done their manipulations. When you raise reactor power, you basically open reactor power. So she's proving that she could stop the reactor power if she continued driving in this regulating rod. She's closing in on the 1 megawatt. One of the things the note is that when she started, the [INAUDIBLE] was around 0300, 0310, and she's almost right back to there. It's going closer to infinity again. up a valve and let more neutrons in. And when you get to the place where you want to be, you basically close that valve again. So you basically add reactivity and then stop that reactivity addition by bringing the absorbers back to about where they started from. AUDIENCE: We're at 17.1 FRANK WARMSLEY: we're at 1 megawatt? AUDIENCE? Yeah. FRANK: Go ahead and make your log book entry. When the rest of you sit down, we'll guide you through those-- the log book entries that she's making. neutrons not leading to fission. One is direct from fission and the other is decay. That's the way it's produced. The way it goes away is basically absorbing a neutron and decaying to another isotope. The fact that we don't have the reactor at a very high power means that the amount of xenon in the core isn't being removed. So we actually start-- the power would actually want to go down on it's own. So you would have to do a lot. of re-shims. And for a while, that's a very large amount of reactivity that has to be compensated for. For this experiment, though, we actually shut down the reactor yesterday and we started up early this morning. So it's not a big factor as it normally would be after doing one of these lowering reactor power. She's driving the absorber out again to slow down how quickly the power level is going down. And when she's done, the shim blade will end up about at the same point. where it started, the 13.42 inches out of the bottom of the core. It might not make it all the way back up to [INAUDIBLE]. FRANK WARMSLEY: It'll be close. Compensate with the reg rod if you need to. 30.8. OK. And that's the end of the exercise. We'll be back in a few minutes with the results of the test. We hope to see you on "Larry King Live" next week.

ROUGE-1: 65.75, ROUGE-2: 63.01, ROUGE-L: 60.77
BERTScore: 71.66

==============================================
==================== [19/100] ====================
Summary:
Professor: We're just start with a short review problem on rugged landscapes. And then we'll get into the core topic of the class, which is evolutionary game theory. And we'll discuss why it is that you don't need to invoke any notion of rationality. Then we'll try to understand this difference to human decision making, professor says. The course is part of MIT OpenCourseWare. To make a donation or view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu. know what a Nash equilibrium is in the context of game theory versus an evolutionary stable strategy in this context. And we'll say something about the evolution of cooperation and experiments that one can do with microbial populations in the laboratory. Are there any questions before I get started? All right, so just on this question of evolutionary paths, on Tuesday we discussed the Weinreich paper where he talked about sort of different models that you might use to try to make estimates of the path that evolution might take. Each time that an individual divides, it has a 1 in a million probability of mutating. And that's a per base pair mutation rate. Originally when we discussed this, we were talking about just mutations, maybe A's and B's. But now, what we're going to have is just a genotype. And I'll show you what I mean by that. I'm going to give you some fitness values just so that we can be clear about why it is that there might be different paths. short genome that's string length 2. So we're assuming that this is relative fitness as compared to the 0, 0 state. And the question is, what's going to happen eventually? And in particular, what path will be taken on this landscape here? You can start thinking about it while I write out some possibilities that we can vote for, and I'll give you a minute to think about it. So don't-- Are there any questions about what I'm trying to ask here? If we wait long enough, the population will get there, and the 1, 1 genotype will fix in the population. We can talk a bit later about how long it's going to take to get there. We'll also discuss whether it somehow is very likely is going to kind of have to go through one or two mutations. But for now, if you'd like, we can say that this is even just mu sub b, the beneficial mutation rate per base pair, assuming that the 0's can only turn into 1s. the other of them. The probability of getting both mutations in one generation is going to be 10 to the minus 12. And then there's another question, which is, will 0, 1 actually fix in the population before you later fix this population? And actually, I think the answers to all these questions are in principal already on the board. And really, this is in some ways a very simple problem. But in another way, you have to keep track of lots of different things, and which regime we're in. a minute. But if you don't understand what's going on, it'll take you an hour. Yes? No? Maybe? Well, I'll give you another 20 seconds. Hopefully, you've been thinking about it while we've been talking. All right, do you need more time? Why don't we go ahead and vote? I think it's very likely that we will not be at the kind of 100% mark, in which case you'll have a chance to talk about it and think about it some more. a group of D's and a group of B's here, which means that everybody-- AUDIENCE: Let's fight. PROFESSOR: All right, so everybody thinks that everybody agrees with them, but you just need to look a little bit more long distance. So turn to a pseudo-neighbor. You should be able to find somebody there. It's roughly even here, so you should be can't find someone. So I don't see much in the way of vibrant discussion and argument. a group, so don't be too disappointed if you don't get finished there. But I do want to see kind of where we are. Ready? Three, two, one. OK, so it still is, maybe, split roughly equally between D and maybe a B-ish and some C's. All right, does somebody want to volunteer their explanation? Yes. And you're saying, all right, maybe because of the extra, that 1, 0 is somehow more fit than 0, 1. some relative rates or ratios for which reason? Audience: Well, I took 0.02 and then 0.1, which is 1/5. And then I decided that that should be around what it is, but slightly less, because there's also a chance that [INAUDIBLE]. PROFESSOR: OK, yes. I think the arguments there-- there's a lot of truth to the arguments that you're saying. Yeah, it's a little-- right. from 0, 0 to 0, 1. I first checked S, N and it's non-neutral. So probably [INAUDIBLE] S. So the probability for that first path would be the S for 0,1, so it's 0.02, which is 1/50, multiplied by the probability that the other 1, 0 would die out. And I think that's the calculation that you're describing, where you say, OK, well, in order for this individual to fix, he has to survive stochastic extinction. if we ask, we're going to start with an entire population at 0, 0, and now these mutations will be occurring randomly at some rate. And we're trying to figure out the relative probability that it's going to take kind of one path or another. Do you see the difference between these two questions? So indeed, this is the correct answer to a different question. And so it'sgoing to end up being D. And now we want to try to figureout how to get there. Because I think it is a bit tricky. all, we have to remember that we start out with everybody, all 1,000 individuals in the 0, 0 state. So there are initially no mutants in the population. But they're just replicating at some rate. And every now and then, mutation's going to occur. Now one thing we need to answer is whether these are nearly neutral mutations. Verbally yes or no? Ready? Three, two, one. AUDIENCE: No. PROFESSOR: No, right. But in both cases, S times N is much larger than 1. point is that the number needed to become established is equal to the population. If they both appear in the population, and they both survive stochastic extinction, then this mutant loses to this mutant. That's the clonal interference. So remember, this was comparing the two time scales. The time between successive establishment events, which went as 1 over mu N S. And the other time scale was 1 over Mu N S, which is 1 over 1,000 years, which was the time between establishment events. One is the time between the time to fix, which went as 1 over S log of NS, right? So we can ignore clonal interference if this is much larger than that. No clonal interfered corresponds to mu N log NS much less than 1. Is that right? Did I do it right? OK. So and once again, there are multiple S's, and it's easy to get kind of upset about this. But you can just use whichever S would be-- which S would you want to use to be kind of-- to the minus 6, 10 to the 3, and then this is the log of maybe 100, which is, like, 4 or 5. This is indeed much less than 1. So indeed, we don't have to worry about clonal interference. What it's saying is that the population is dividing. Every now and then, a mutation occurs in the population. It could be either the 0, 1 or the 1, 0. But in either case, the fate of that mutation is resolved before the next mutation occurs. of those two steps-- going to 0, 1 or 1, 0. And in particular, this is like a chemical reaction, where we have some chemical state here. And what we know is we know the ratio of those rates. And that's everything we need to know to calculate the relative probabilities of taking those states. So this is how we get 1/6 instead of 1/5. Because this thing is1/5 of that. So it's like 1, and then 1, 5. And this is actually, in principle, not quite answering the question that I asked. talking about the relative probability of the first state, the first mutant to fix. In principle, it is possible that from there, there's some rate of coming back. Or they might not necessarily move forward on up that hill. But in this case do we have to worry about going backwards? No. And why not? It's very unlikely. And in particular, you could think now that you're here you can talk about the rate of going to the 1, 1 state. And those are going to be exponentially different. So the probability of fixing it in the back direction is not 0, but it's exponentially suppressed. In practice, it doesn't actually matter, because this acts as a ratchet. Because all these mutations are non-neutral, once you fix this state or this one, you can't go back. So the population will move forward once it gets to one of those two states. Now I mean, it would be a very interesting question to ask if we instead did a different arrangement. What would the rate of evolution be, and so forth? Yeah, but what you're saying is certainly true, that if this took up all of the benefit going here, then it may not actually be somehow an optimal path. or something like that. I'll think about that when designing. Problems. In this system, 0, 0 eventually becomes 1, 1. So we are guaranteed that we will eventually evolve to this peak in the fitness landscape. And of course, there are non-zero probabilities of going backwards. It's just that they are reduced. Over long time scales, there's going to be an equilibrium that distribution over all. And actually, you can prove, for those of you who are interested in such things, that over long time Scale. these states, where the probability of being in a particular state will-- it goes as the fitness. It scales as the relative fitness to the Nth power. So we talk about these fitness landscapes as energy landscapes. And indeed, in this regime where you have small mutation rates, then it's going to be a detailed balance. And it's actually a thermodynamic system. So then in that case, you can make a correspondence between everything that we normally talk about, where fitness is like energy and population size is like temperature. cohered at this peak in the finished landscape. And so what we have is we have r is relative fitness 1 and 1.02. The rate of going forward, well, we sample mutations at a rate mu. And this is mu only, because we don't have to worry about going up the landscape. We just have the 0, 0 and the0, 1 states, just so we donâ€™t have to worrying about going down the landscape, for example. So if you want to calculate a problem going from 0, 1 to0, 0, then [INAUDIBLE] that would just be-- I guess I'm not sure. for this one state, because pretend that we're not going to mutate this other one. So rate mu N, you have mutations appearing. And times this s, 0.02, is the probability that it'll actually fix in the forward direction. And now what we want to know is the rate of coming back. So which of these terms is going to be dominant? This thing gets up to be some really really really interesting stuff. And the probability of fixation is-- there was this thing X1, which was 1 minus-- now this is r. big number is our problem. So we should be able to figure this out, though. Because this new r is 1/1.02. OK, so there's less than a 1% probability of it fixing. Is this believable? AUDIENCE: It's about right. PROFESSOR: Yes, sorry, I was just saying this doesn't-- so this is why I'm saying you always check to make sure that your calculation makes any sense at all. So it's not this. But it's tiny, right? fixation of a neutral mutation. This is a deleterious mutation. It's not even nearly neutral. So it has to be much less than 1 over N, right? So this whole thing is 10 to the minus 10, or something like that? All right, any other questions about how to think about these sorts of evolutionary dynamics with presence of mutation, fixation, everything? Yeah. Can we handle a situation where [INAUDIBLE] interference is important at this point? PROFESSOR: Yeah, so this is what you do in your problem set with simulations. In the limit, as you get more and more mutations, when clonal interference is really significant, then you're pretty much just guaranteed to take the 1, 0 path. Once you have multiple mutations that have established, then it's likely that one of them is going to be this. And if it's established, it's going to win. But, like, with basic-- I guess I was thinking about it and you could probably imagine that [INAUDIBLE] calculate the probability that 1,0 doesn't arise first. rate, you don't even do successive fixations. So it may be that neither state ever actually fixes, because it could be that the 1, 0 state is growing exponentially, but is a minority of the population. And it has a lot of the same behaviors, in the sense of exponential suppression of probabilities as a function of the depth and the width of the valley you're trying to traverse. And there's some very nice papers, if you're interested in looking at this stuff. syllabus that I mentioned. I think the most important thing to stress when thinking about evolutionary game theory is just that this point that we don't need to assume anything about rationality. Instead, you simply have mutations that sample different strategies. And then you have differences in fitness that just lead to evolution towards the same solutions of the game. So it's evolution to the game solutions, so the Nash equilibrium, for example. And the more fit individuals spread in the population. And somehow, you evolve to the same or similar solutions. we have a 0, 0 state that has some fitness. 0, 1 has a higher fitness, and so forth. But in general, these fitness values may depend upon what the population composition is. And in that situation, then you want to use evolutionary game theory. For example, you can have situations where the population evolves to lower fitness. So it's just important. If the fitnesses depend on composition-- this is the population compositions-- then you cannot even define a fitness landscape. Just knowing the fitness of a pure population is not actually enough information to know that it's going to be selected for. It's still possible that in a mixed population, the genome 0 may actually have higher fitness than the genome 1.1. And once you kind of study these things, it's kind of clear that once you study them, you can't really tell what the fitness is of a population. The key is to look at the whole population, not just one or two, and try to find out what it's like to live in that population. it can happen. But then it's easy to then go back to the lab and forget that it's true. I think that the more formal evolutionary game theory thing-- these two-player games that you guys just read about-- I think they're important because they tell you what are the possible outcomes of measurements or of systems, even in the most simple situation where everything's linear. Now, when things are not linear, of course you can get even richer dynamics. But in this case, we'll see how this plays out. practice, you basically get the categories of outcomes that we saw there. So it's what you would get if you just had some two-player game like they study in game theory, but in a population of 1,000 or whatnot. You just made a bunch of random pairwise interactions. And then you had them do that again over time. And it's really importing the kind of approach, or the nomenclature, from conventional game theory and then immediately applying it to populations where you just assume that all the individuals have equal probability of interacting. The payouts that you read about in Chapter Four are kind of what would happen in that sort of situation, where everybody's interacting with everybody else with equal probability. Depending upon the strategy that these guys are following, you get different payouts. And this is telling us about the payout that the A individual gets depending on what he does, and depending upon what his opponent does. Now, we're not explicitly saying what the payout to the B individual is, but we're assuming that this is a symmetric game, so you could figure it out by looking at the opposite entry. a fitness, whereas B also gets little a fitness, because it's a symmetric game. So the case it's different is when we're in the diagonals. And from this framework, you can see that there are going to be already a bunch of kind of non-trivial things that can happen, even in this regime where everything's linear. And the probably best well-known of these is this Prisoner's Dilemma, which is the standard model of cooperation in the field of game theory. be in trouble, et cetera. So the idea of the prisoner's dilemma is that if you set up these jail sentences in the right way, then it could be the case that each individual has the incentive to confess. And you can come up with some reasonable payout structure that has that property. And we'll call this-- so this is for individual one, say and individual two. So there are different strategies you can follow. And do you guys remember from the reading slash my explanation how to read these charts? Professor: Nash equilibrium is to do strategy D that we're saying here. If both players had followed this strategy C for cooperate, D for defect, then both individuals would be getting fitness 3, or payout 3. But the problem is that that's not evolutionarily stable. So if you're in this state, what you have a choice of is to switch to the cooperate strategy, which would be D. The question is whether you as an individual would have the incentive to change strategy? And the answer is no. to go up here. So you have a choice to move up to this 0 payout, but that's not to your advantage. Now, it's true that your opponent would get payout 5. So that's saying that the strategy D is noninvadable. We can also think about what happens if we're a population of cooperators. Now everybody has high fitness-- fitness 3. Question is, What happens if there's a mutation that leads to one individual following the D strategy? Is he selected four or not? General, in terms of game theory, we like it when the mean of these two is smaller than this one. That's why you're asking, right? Exactly, because that's right. So yeah, so that's a slightly more complicated situation, because in that situation, then, if you had two rational agents, say, playing this game, then you could alternate cooperation and defection. And that would actually be the ultimate form of cooperation in such a game, because you could actually get a higher payout by alternating. cooperator and for the defector. For example, I'm going to draw a solid line for the cooperator, dashed line for a defector, do you understand? So what should these things look like? I'd like to encourage you to-- I'll give you 30 seconds to try to draw what this should look like. So this is the payout or the expected payout. So we're assuming that you're going to interact randomly with the other members of the population as a function of the fraction cooperator. Do you understand what I'm trying to ask you to do? are lines. But you can imagine that the only thing that's important are how these lines cross each other. So for example, there are only a few different things that can happen. You can have one strategy that dominates, which is what occurred here. And surprisingly, that does not mean that that strategy is higher fitness, in the sense that you may evolve to a state of low fitness. That's what's weird. So I'll give you another example of this. So now we're just going to have two strategies. The strategies-- we'll just call them A and B. And the question is, what is the Nash equilibrium? terms of these lines if we draw them? So this is payout as a function of the fraction that is playing the A strategy. Should the lines cross? Yes or no? Ready, three, two, one. AUDIENCE: Yes. PROFESSOR: Yes, and indeed, in principle, the math that we do in all these situations is kind of super simple. Yet it's easy to get confused about what's going on in all of these situations, says the professor. and then that leads to coexistence. Now, in some ways coexistence is the most subtle of the situations. And that's for an interesting reason. And maybe I shouldn't have covered this up, so you're not influenced, in case you actually did do the reading. Then I don't want to. But I'm saying that these things can cross in the other orientation. Let me put a matrix out there, and then-- so this is something that, for example, is what's known as a Hawk/Dove game. you to be influenced by this. So think about it for 30 seconds. Do you need more time? Let's go see where we are. Ready, three, two, one. All right, so most of the group is agreeing in this case, neither are the Nash equilibrium. Does that mean that this game has no Nash equilibrium? Yes or no, verbally-- ready, 3, 2, 1. AUDIENCE: No. PROFESSOR: No, it does not mean that. This game has a Nash equilibrium and indeed, all games like this have Nash equilibria. saying, otherwise we'd be in trouble, all of us. So what he proved is that such games, even with more players, more options, and so forth, they always have such a solution in this sense. There exists some strategy such as if everybody were playing in, nobody would have the incentive to change strategy. But you have to include so-called probabilistic or mixed strategies. And we can draw what this thing is. So just like always, so everyone else is following A, then A starts here at 3, and then it goes to 1. Whereas the B individuals start at 5, and they go to 0. In a population, if you have genetic A's and genetic B's that are each giving birth to their own type, then you evolve to some coexistence of genotypes. Whereas in this situation over here, we have coexistence. Does not matter where you start. So long as you have some members of both A and B in the population, you'll always evolve to the same equilibrium. Whereas the mixed Nash equilibrium is a situation where you have, in principle, genetic homogeneity. So this is a single genotype that is implementing phenotypic heterogeneity. In many cases, isogenic populations of microbes can exhibit a diversity of phenotypes as a result of stochastic gene expression and bi-stability. Another question is, what is the evolution explanation for why that behavior might have evolved? Now in general, we cannot prove why something evolved, but we can make educated guesses that make experimentally testable hypotheses. And for example, in the experiment that we've been doing, we're looking at bi-modality in expression of the galactose genes in yeast. you make the mutants that always turn on or always don't turn on these genes, then they're actually playing game where you get this exact thing. So that's saying that maybe the wild type that follows this stochastic, mixed strategy may be implementing the solution of some game. There are other possible explanations to this. In the coming weeks, we'll talk about this idea of bet hedging-- that given uncertain or fluctuating environments, it may be advantageous for clonal populations to have a variety of different strategies to cope with that uncertainty. Nash equilibrium mixed strategy plays A with probability-- so it's p should be equal to f a star. But the funny thing is, what that means is, it doesn't matter what you do at the equilibrium. What's interesting is that any individual in the population following any strategy has the same fitness. It's either coexistence of genotypes following different strategies, or it could be one genotype implementing both. It could be a mixture of those, actually. The heterogeneity there can be implemented either way. If your at the equilibrium, or if the population or the opponent is playing this Nash equilibrium in these games, then it just does not matter what you do. You can do A, actually, in any fraction. So since A and B have the same fitness, you can choose between them at any frequency you want. And indeed, in this there are nice conditions for what makes it this Nash equilibration. And I'm going to just highlight that you should make sense of why it means what it is. equal to this guy. So that's what I just said-- that it doesn't matter what you do. If everyone else is doing p star, you have the same fitness. That's saying it's a Nash equilibrium. Whereas there's another interesting kind of statement here, that you can't unilaterally increase your fitness by switching. That you don't have the incentive to change strategy. It's true that you're not dis-incentivized. So it's not a strict Nash equilibrium, but it's an equality. not the definition of that. But this thing is true, which means that it's a Nash equilibrium. And if you have questions about this, I'm happy to answer it. It's explained in the book as well. We are out of time, so I should let you go. But good luck on the exam next Thursday. If you have Questions and you want to meet with me, I am available on Tuesday. So please let me know. I'll be happy to talk to you.

ROUGE-1: 61.63, ROUGE-2: 59.34, ROUGE-L: 55.75
BERTScore: 76.50

==============================================
==================== [20/100] ====================
Summary:
hey everyone it's sarah with registerednessrn.com and in this video i'm going to be covering sinus tachycardia. As always whenever you're done watching this youtube video you can access the free quiz that will test you on this content. Let's get started what is sinus Tachy Cardia? Well first let's take its name apart sinus tells us that we're dealing with a heart rhythm that originates in the sa node this is also known as a sinoatrial node and it is found in the upper part of the right atrium. The electrical conduction system is to stimulate your heart muscle cells so they will be and pump blood throughout your body so it all starts here with the sa node. The sa node is located in the upper part of the right atrium. If it's working like it should it should cause your heart to beat at about 60 to 100 beats per minute and its goal is to really stimulate these atria to get them to contract so it leads to atrial depolarization which is going to lead to the contraction of your atria. refer to this as sinus bradycardia and i have a whole lecture on that if you want to check that out but on the flip side let's say that this sa node is firing rapidly like for instance the sympathetic nervous system is really causing this to just fire electrical signals fast because maybe you're exercising or you're really stressed out you're in a fearful event well we would refer to that as sinu tachycardia. sinus tachycardsia is a rhythm that meets the criteria for normal sinus rhythm but it's going to have a fast rapid rate greater than 100 beats per minute. With sinus hack the atrial rate is going to be greater than 100 beats per minute and then whenever you're looking at the p wave take your calipers and go from p wave to p wave and make sure there's the same distance between those because that means it's occurring at a regular interval. With sauna's bradycardia the qt interval was a little bit longer and then after each qrs complex you should have a t wave present as well so now let's analyze this rhythm together using this criteria we just went over here. waves we want to make sure that there's a p wave one p wave in front of every qrs complex. We want to look at those p waves is because they tell us about the atrial rate. Then i want to check the regularity of these qrs complexes just like i did with the p wave so i'm going to go from r wave to r wave with my calipers and i'm just going to confirm that they are regular and they're regular just like with thep wave. the end of the t wave so just take your calipers go at those positions and then count the blocks and here we have about seven blocks so our qt interval is about 0.28 seconds. Usually the reason that the heart will start beating this fast is because it knows that the body is in dire need of oxygen. There's something causing the body to use up oxygen that theBody is trying to replenish by increasing the heart's beat. Now let's talk about the causes of sinus tachycardia so we've already established that the reason this rhythm is occurring. the heart rate now this can be disease related or it can be non-disease related. We want to increase our heart rate whenever we exercise because that gives us a good workout so in that case sound attack isn't really that bad. If we're in a fearful stressful situation let's say you're about to be robbed your sympathetic nervous system is going to kick into gear and it's going to increase your heart rate so it can help hopefully protect you from danger and that's a good thing. can all increase the heart rate so whenever we take those things away remove the maldives and whatever the sinus tack will disappear and hopefully their heart rate will go back to normal. Then there are disease-related issues that can cause sinus tac this can be for instance let's say your patient has anemia so with anemia they have a low amount of red blood cells. Red blood cells carry oxygen throughout the body so if we don't have a lot of those red blood cell hanging out we have low amounts of oxygen our body can increase that heart rate to try to compensate for those levels. whenever a patient develops sinus attack and they have a disease it could be that their disease is worsening and it's a warning sign that hey this needs to be investigated more so anytime you have a patient and they're going in to sinus tack you want to investigate it. You don't want to just write it off. You want to see okay what could possibly be going on with my patient why they went into this so for instance let's say that you're caring for a patient who just suffered a myocardial infarction and they go into sinus tachycardia well this could be a warning signs that they may be going into cardiogenic shock. compensate for what's going on but in the end it's going to fail and the patient'sGoing to have cardiogenic shock and you'd want to report that to the doctor. Be looking for those other signs related to that be checking out the respiratory system are they having shortness of breath whenever they breathe in. Are they having chest pain that's getting worse or are they developing a cough so you'd also want toReport that as well now to help you remember those major causes of major causes. sinus tachycardia let's remember the word tacky hearts t is for temperature elevation and this could be if your patient has infection leading to sepsis a is for aerobics this is exercise and we already talked about why that can occur c is for cardiac disease and this can be in patients who have congestive heart failure or who have suffered a myocardial infarction leading to cardiogenic shock h is for hyperthyroidism and sinus attack may be the only symptom for some of these patients. period of time and it's going really fast this puts extra stress on that heart and it increases its demands for oxygen. If a patient has coronary artery disease where there's fatty plaques in those coronary arteries that's going to limit how much fresh oxygenated blood gets to that heart muscle. So patients who have an underlying problem of that we want to make sure that we keep the heart rate slower. If heart muscle doesn't get the oxygen it needs it can die it becomes ischemic so that could lead to a myocardial infarction. also sustained sinus tachycardia can actually decrease cardiac output in your patient. As a nurse you want to make sure you're monitoring their bottle signs closely and you're looking at your patient making sure they're not showing signs of decreased cardiac output. The reason this can occur is because that heart is beating very fast and whenever we're getting up to rates of 150 or greater the heart's not really pumping as efficiently as it should. If you're pumping so fast those ventricles don't have enough time to fill completely especially that left ventricle. it's going to limit the amount of blood that's going into the body so your patient can start presenting with a very low blood pressure that's the salt getting less than 90. With this heart is just literally failing so you'll get the backup of blood blood will start backing up into the lungs so whenever you listen to their lung sounds you'll start to hear crackles where they're developing pulmonary edema. You also want to look at their extremities how do they feel are they cool check that capillary refill is the time increase that could mean you definitely have decreased cardiac output. very important whenever a patient is in sinus tachycardia that we monitor them closely and if their heart is going too fast we need to look at that possible underlying cause report it so it can be treated and we can get their heart rate down now let's look at the treatment and the nurse's role for sinus Tachycarda. The treatment as i pointed out earlier is going to deal with identifying the cause and treating that cause because hopefully this will help decrease the rate so the healthcare provider can order some tests like an ekg. that and see what's possibly going on with the patient assessing blood levels like the thyroid level making sure they don't have hyperthyroidism looking for anemia or maybe infection they have a white blood cell count that is high and looking at that medication history making sure that they're not on any medicines that could be increasing their heart rate. This leads me to medications that can be ordered to help slow down that heart rate one group of medications are beta blockers and one type is called metoprol beta blockers. can be ordered to bring down the fever and then the nurse's role so as a nurse we want to assess for any potential causes for why our patient is running this rhythm. If all of a sudden you start seeing sinus tack you want to analyze hey why are they in this do they have untreated pain are they having a fever are they hemorrhaging what's going on? You want to report the rhythm change to the physician and let them know about it obtain an ekg if you get an order for that so we can further investigate their heart rhythm. cool extremities and then you want to teach the patient if you're able to avoid any activities that could further increase their sinus tag like if they're smoking or drinking caffeine or using any other stimulants because we don't want their heart rate to get up any higher okay so that wraps up this review over sonos tachycardia. If you'd like to watch more videos on this topic you can access the link in the youtube description below. Click the link below to access the video.

ROUGE-1: 61.80, ROUGE-2: 59.64, ROUGE-L: 59.76
BERTScore: 76.32

==============================================
==================== [21/100] ====================
Summary:
In this problem, we're given a collection of 10 variables, x1 through x10, where each i, xi, is a uniform random variable between 0 and 1. And we'd like to develop a bound on the probability that some of the 10 variables being greater than 7 using different methods. In part A we'll be using the Markov's inequality written here. And in part B, let's see if we can improve the bound we got in part A using the Chebyshev inequality. variance of x, we know is 10 times the variance of a uniform random variable between 0 and 1, which is 1/12. Now, let's compare this with the number we got earlier using the Markov Inequality, which was 5/7. We see that 5/48 is much smaller, and this tells us that, at least for this example, using the Chebyshev Inequality combined with the information of the variance, we're able to get a stronger upper bound on the probability of the event. a better bound. To remind you what a central limit theorem is, let's say we have a summation of i equal to 1 to some number n of independent and identically distributed random variables xi. We take the sum right here, and subtract out its means, which is E of the same summation, and further, we'll divide out, what we call normalize, by the standard deviation of the summation. As the number of terms in the sums goes to infinity, we will actually see that this random variable will converge in distribution in some way. know how the distribution of a standard normal looks like, we can go to table and look up certain properties of the resulting distribution. So right now, we have about 10 variables. If we believe 10 is a large enough number, then this will be roughly equal to 1 minus the CDF of astandard normal evaluated at 2.19. And we could look up the number in the table, and this gives us number roughly, 0.014. Now let's do a quick summary of what this problem is about. We're asked to compute the probability of x greater or equal to 7. 10 uniform random variables between 0 and 1, so we'll call it xi. We know that because each random variable has expectation 1/2, adding 10 of them up, gives us expectation of 5. So if this is a real line, and 5 is here, maybe x has some distribution around 5, so the center what the expected value is at 5, we wonder how likely is it for us to see something greater than 7? Now, let's see where do we land on the probably spectrum from 0 to 1. number, which is roughly equal to 0.7. In fact, we got number 5/7, and this is from Markov's Inequality. Can we even do better? And this is the Chebyshev, and it turns out we can indeed do better. Using the central limit theorem, we can squeeze this number all the way down to0.014, almost a 10 times improvement over the previous number. This is from centrallimit theorem. As we can see, by using different bounding techniques, wecan progressively improve the bound on the probability of x exceeding 7. that even with 10 variables, the truth is more like this, which says that the distribution of x concentrates very heavily around 5, and hence, the probability of x being greater or equal to 7 could be much smaller than one might expect. That is, x is more likely to be greater than 7 than it is to be less than 7, and so the probability is much lower than one would expect. It is also more likely that x is greater than or less than 5, rather than equal to 6 or 7.

ROUGE-1: 57.00, ROUGE-2: 53.06, ROUGE-L: 52.93
BERTScore: 73.25

==============================================
==================== [22/100] ====================
Summary:
So now that we've combined pulley A, string 2, platform, and washer as our system, we can now address our question. If we measure the acceleration of the person, what is the force that the person pulls the rope down with? Well, of course, that will just be the tension in the string. And with this simple system,we can now apply Newton's second law, F equals ma. But recall, we need some directions. So we'll choose a unit vector j hat in the positive direction. Now the problem becomes tension one, three different tensions, 3T1, and gravitational force minus mp plus mw times g. the string, too, were massless. So we have simply mp plus mw a. And so we can now solve for the tension in the string, which is equal to mp plusmw times g plus a divided by 3. And recall that this tension, that the string is pulling, this is what we called the force that the person [? of ?] the string on the person. And by Newton's third law, that's also, on the washer, thatâ€™s also the force.

ROUGE-1: 78.99, ROUGE-2: 77.64, ROUGE-L: 78.99
BERTScore: 89.09

==============================================
==================== [23/100] ====================
Summary:
hey everyone xerath register nurse Orion Orion common in this video I want to go over the veins that I love to use whenever I'm drawing blood or starting IVs. Some veins can only handle about a 20 or a 22 gauge IV cannula versus some of them can handle 18 gages 16 gages so you really want to know which veins can do that now what means do ILove to use. okay number one which I think the consensus is probably the same for this is the median cubital vein this is. The media cubital vein is located right here and as you can see it's nice and large perfect for those blood draws and it arises out of your cephalic vein. Another vein I like to use is located on the forearm so we don't have a bend of an arm causing the patient and issues and it is the median vein of the forum also called the anti brachial vein. Lastly the veins of the hand the dorsal venous network and these veins are great for drawing blood starting IVs but some things you want to remember okay first of all these veins. choosing veins when starting IVs or drawing blood thank you so much for watching and don't forget to subscribe to our channel for more videos. Back to the page you came from. Follow us on Twitter @CNNLive and @CNNOpinion on our Facebook page and on our YouTube channel. For confidential support call the Samaritans in the UK on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255.

ROUGE-1: 29.19, ROUGE-2: 25.60, ROUGE-L: 26.04
BERTScore: 67.87

==============================================
==================== [24/100] ====================
Summary:
When we talk about complement and substitute, we have to be clear whether we are talking about the demand side or the supply side. So, do not think from a consumerâ€™s perspective, but from a seller's perspective. One example let me give you from very low tech to high tech, the simple let us take plastic chair to iron chair. Can you give an example, first substitute think about it? Student: Plastic chair toIron chair like. The simple answer is yes. let us say that here supplier of milk, the milk man he supplies milk. Let us say there is market for cow dung also, earlier when our economy was not developed. So, let us say if there is an increase of price in cow Dung, what would happen? Your willingness to supply milk at the same price would increase. More cows mean more. More milk means more. So of course, herecow dung and milk are complement in production. So that is that. a very low-tech example. Let us talk about a very high-techexample Boeing Company. Boeing is a manufacturer of airplanes; it makes civilian airplanes as well as military airplanes. So, if there is an increase in price of military aircraft, what would happen? Boeing devote more a space to. manufacturing, to manufacture military aircrafts. What would happen to the supply of civilian aircraft? It would go down. Boeing willingness to supply civilian aircraft at the same price would decrease. That is why here civilian aircraft and military aircraft are substitutes in supply or substitutes in production. So, now we have enough knowledge. So that, to talk about the factors affecting the supply schedule or supply function. So, now that we have that knowledge, we can talk about how to get the most out of the resources that are available to us. That's what we're trying to do here. We're going to try and get the best of both worlds. We'll see how it goes from here. It'll be interesting to see how we get on with it. We've got a long way to go, but we're getting there.

ROUGE-1: 64.37, ROUGE-2: 52.49, ROUGE-L: 51.17
BERTScore: 71.63

==============================================
==================== [25/100] ====================
Summary:
Rebecca Sae: I was supposed to go before Ken, and thank goodness Ken insisted he went before me. "It articulated deeply why social intelligence should pervade our thinking about the mind and brain," Sae says. "I think that when people talk about social intelligence, they mean the range of phenomena that people mean in social intelligence," says Sae. "From extremely complex phenomena that govern the interactions of large groups of people, like war, to incredibly minute phenomena, like whether you can get your hand to a target in 100 milliseconds or less" social cognition they do actually mean all of those things. And that is both thrilling-- when you work in social cognition-- and also terrifying, especially when people are hoping for a coherent theory of all of that. I think that trying to get a coherent account of everything from your hand motions and your perception of other people's hand motions all the way to politics and sociology is daunting and, frankly, deeply unlikely. And so, by contrast to Ken-- who starts with, let's look at social interactions and see what's there, which I think is a very awesome approach-- I'm going to take almost the opposite approach, which is say, there's one thing that's probably there a lot. is not the only thing I work on-- is this ability that we have. OK, so a little demo of the problem that I work with-- and because it's early in the morning and everybody needs to wake up, I'm going to get you guys to do this as a task, so as an experiment. So in this experiment, we're going to ask you to make a moral judgment of a character. Her name is Grace. And the more wrong it was, the higher your hand goes. Psychologist David Frum: What matters most for the moral blame that we assign is not what happened, but what Grace thought she was doing. He says that in scenarios like the one he gave you, what matters most is not how bad the outcome was, but how much blame Grace deserves. Frum says the scenario isolates one important feature of our moral judgment and also an important feature. of a lot of the rest of our social cognition. He asks: How much blame does Grace deserve for putting the powder in the coffee? And how much do you think she deserves? been studied from kind of relatively simple perceptual phenomena like assigning intentions and goals to simple moving characters in an animation. This ability has been studied all the way to understanding some of the most complex, abstract ideas that we ever encounter. So to the degree that our minds let us make any sense of that at all, we're using our ability to make sense of other people's minds. And I'm almost exclusively going to talk about the first one, so how we think about what other people see, think, and know-- but not want or feel. This problem was set up as kind of a litmus test for our ability to think about other people's minds, starting in the late '70s. So the origin of this problem for psychology is, everybody knows humans could do this. What about animals? And actually, the debate about whether this capacity for thinking about other person's thoughts is or is not shared with which other animals has gone on continuously since the late 1970s and has not been resolved. And so here's what a false belief task is. false belief task looks like. This is being given to a five-year-old human child. Do you know what pirates really like? CHILD: What? REBECCA SAXE: Pirates really like cheese sandwiches. So Ivan puts his sandwich over here on top of the pirate chest. And while Ivan is away, the wind comes, and it blows the sandwich down onto the grass. And now, here comes the other pirate. This pirate is called Joshua. And Joshua also really loves cheese sandwich. So which one do you think Ivan's gonna take? The task became so famous is that not all participants perform the same way. One class of participants who've become the focus of intense scrutiny is slightly younger kids. This is a three-year-old. He's paid equally rapt attention throughout the entire story. And we come to the crucial moment, and he's asked again the same question. And Ivan says, I want my cheese sandwich. Which sandwich is he? Which sandwich does he want to have? He wants his cheese sandwich, of course. The traditional read of what just happened there is that's a kid who gets wanting, right. But he doesn't get believing. He doesn't understand that because Ivan left his cheese sandwich on top of the pirate chest and he didn't know that it's been moved that he'll believe that that sandwich is his. His actions depend on his own beliefs, rather than the true state of the world. And that's the source of both this wrong prediction-- why does he say he'll take this one? Do you think he's going to take that one? take his cheese sandwich-- and the wrong explanation. So when he goes to take the other cheese sandwich, the one that's actually Joshua's, then we say, why did he do that? And again, this is typical performance that the little kids confabulate. So in this case, it's that his fell on the ground. He doesn't want his anymore. That's why he's taking Joshua's sandwich. And that pattern of performance was interpreted as evidence of conceptual change and development. The capacity to bring to bear a conception of the other person having beliefs, perceptual history, knowledge, an internal representation of the world that guides actions. And so that is what I'm going to call thinking about thought. The idea that this is a domain that you could study on its own-- well, there's two questions here. One is can you study this at all. And the second one isCan you study it separate from the whole rest of cognition? Both of those are related to Liz, and indeed Nancy, and many people's worries. How do we think about other people as containing internal mental lives, mental representations? I'm going to talk about just fMRI, although I do use other methods to study this problem. I think fMRI has been both an incredible gift to our ability to understand the human mind and also imposes a huge number of limitations on what we can discover. And so what I want to tell you about is just a tiny bit of my phase one investigations using the early strategies that fMRI allowed us. And then a more in-depth look at how I'm using more modern techniques in fMRI to try to get further. belief. This is a very simple encapsulation of our ability to represent what somebody else thinks and separate it from the state of the world. While you were doing that, you were clearly using your theory of mind. But you were also using many other capacities of your mind and brain. So we're using everything from your eyes to your fingers and most of the brain in between. And then the question is, the part that required is, what part of the mind did you use? In a control condition, you similarly read stories that involve something that was true and becomes false. You need to think about those two and respond using a button press. The idea is that in this comparison you need the ability to see the stimuli, read English, put together your logical and cognitive capacity of your brain. In this case, what it is is a state of the world. So this is an island and a photograph taken of it. Then the photograph, of course, stays the same. But the world changes. So there's a volcano that erupts. And now we can ask you either about the photograph. thoughts, and choose a button press in both cases. But only in the first case do you also need to think about other people's thoughts. And so that comparison would let us look for brain regions where blood oxygenation or metabolism is higher if you're thinking about others' thoughts. The signal is ridiculously strong and reliable, according to the researchers, who found a whole group of brain regions with higher metabolism if you think about people's ideas in the stories. The difference between thinking about somebody else's thoughts and other logical problems-- in terms of logical problems -- can be huge, the researchers say. of how significant, how reliable, how similar across individual subjects-- is comparable to the difference between looking at gradings and not looking at gratings in V1. That's crazy that something this complicated and abstract would have an unbelievably large, robust, reliable signal in individual subjects. But everyone who has ever come through my lab says that they never believe me until they see it in their own data. And you can do this in any individual subject. You need to read only between 10 and 20 total stories in literally five to 10 minutes. not possibly be true on any a priori story, except for maybe the story Ken just told you about how social cognition is the fundamental basis of everything. When you look inside this brain region, this is in one of them. It's one of five cortical regions. I'm going to talk a lot about it, because the data from the right TPJ are particularly clean. So in the rightTPJ, that's average percent singal change in some of our early experiments to stories about beliefs. story, and the signal starts to go up. This is just showing that difference in how much you think about thoughts contributes a lot of variance across many different individual stories. And if you look within the story, it's the time when you're thinking about a thought that you get activity in this brain region. We showed that after TMS to the right TPJ compared to a control brain region, people use the beliefs of the character less in making their moral judgments. But "involved in"-- that's a euphemism. stories in the scanner, and we record activity in the brain region while you're reading those stories. And so what we do with that is we make arguments about selectivity and these kinds of things that we've been talking about this entire time. Those measures, called univariate measures, measure the amount of activity in that region, on average, as you read a different story. So you get something that looks like this. And what you show is that this brain region responds a certain amount. Both stories involve thinking about thoughts. And one of the things we showed early on is that activity generalizes in the sense that many different stories about many different kinds of thoughts all illicit activity in this brain region. And I told you that I think that that is related to this idea of involvement. This brain region is involved when a story describes thoughts. OK, what's wrong with that for making theoretical progress on theory of thought? That's what we're trying to find out. We want to know what's going on in the brain. mind is that, with respect to the representation of other people's thoughts, that doesn't tell us anything about how our brain does it. So the things that would make something a theory of mind-- a representation of who thinks what, why, and with what consequences-- we can't see in the univariate signal. So what I would like to make progress on, what I think we're starting to makeprogress on using MVPA, is getting beyond that this brain region is involved in theory ofMind and trying to ask something about what is represented in this brain area. analysis-- the things that we were doing mostly for the first 15 years of fMRI-- are called now univariate analyses. What was most effectively revealed by these analyzes are differences in the cortex at the scale of regions, what one region as opposed to another region does. And that turns out in many contexts-- especially in the back half of the brain, the representation regions-- to correspond in some sense to the stimulus type. The answer at the end is-- given that I got this pattern, what can I figure out about the stimulus? Conversation that I would have got to at the end. All the mathematical techniques of MVPA could be used to rediscover all of the things Nancy already discovered using the traditional analyses. And in fact, if you use them uncarefully that's what you're most likely to do, because those are huge signals in the brain. If you're not careful, what you will do is just re-go over old territory with new math. I am more interested in these techniques when they let us see things we could never see before. So when, instead of telling us about region level differences or centimeter scale differences, they're tell us about much smaller and more interleaved populations. for a given type of stimuli, what are the key dimensions of representation. The intuition here is that-- think about a region, like the right TPJ, or the face area if you think about faces. Or V1 is often where I start, because we know enough about V1 that I can use it to imagine what we're talking about. So you can think about within-type dimensions of importance-- and MVP I think is letting us do that in its most interesting applications. V1 is called V1 because information goes from your eyes to the LGN of your thalamus. It's the first cortical stop of visual information. One way that we know that it's very involved in vision is that if you're seeing visual stimuli, you get a big response in V1. That's a selectivity type measure. What we want to know about V1 is what transformations over the information coming from LGN is V1 implementing. And that's why theories like Marr's theory-- which say that there are receptive fields-- are important. V1 as a whole will activate to big images regardless of the orientation of the content of the image. So you need to be able to get to something more fine-grained than V1. You need to say there are different subpopulations of neurons inside V1, some of which will be responding when a line is like this, and some ofwhich will be responses when a lines is like that. And that's the decoding perspective that says, if we wanted to. that V1 has an orientation map, that neurons in V1 have an orientation preference. In fMRI, the unit of measurement is the blood oxygenation in 100,000 neurons. It seems potentially really unlikely that you would be able to tell from the fMRI signal whether the neurons that prefer bars like this are more active. And so it's not stupid that we used to focus on things like how much activity. The neural populations, like orientation preferring neurons in V1, were too spatially mixed to tell the difference between them in fMRI. The traditional way of thinking is to look at V1 and know is the line like this or like that. There's so many things that could cause fine spatial patterns that we don't care about. Where the blood vessels happen to be is another thing. There's a key intuition underlying MVPA. So there's the big signal which is the regional signal-- V1 and vision-- and there's lots of noise. But there might also be inside there a tiny bit of spatial pattern that says something like-- well, this voxel happens to have more neurons that prefer one orientation. And this vauxel has more neurons. that prefer a different orientation. And so from the relative activity in those two voxels, we could still tell you the orientation. That was the intuition behind multivoxel pattern analysis when it was first proposed. And it's now sweeping the fMRI world, many different versions of these analyses. But to give you a more concrete sense of what this is and how it works, I'm just going to show you two different ways MVPA is done concretely in my lab. when we do MVPA. The first dimension or potential feature that we wanted to look for we chose because it really matters to human judgments. And it's the one that you guys did in the very beginning of my talk-- telling the difference between somebody who knowingly or unknowingly commits murder. That, as you saw, makes a huge, huge difference in behavior. And also, we know it's represented in the right TPJ because of the TMS experiment. If we mess up the signaling in the TPJ, we change that judgment. ask how much blame you should get. This is in the second person and doesn't matter. We change on average two to four words in this whole long scenario. So we can make these tiny interventions. It's a complicated stimulus, but the change we make is very small and totally changed the meaning of the whole. We make, for example, a change from you had no idea to you knew. And those stories are different in many, many,. many ways. In this experiment, we make one tiny change. story by just changing your mental state. Whether you knew or you didn't know about your cousin's peanut allergy is really important to the moral judgment of what happened. The right TPJ is tracking the important information about what you think. And so it's activated for both of these kinds of stories. So that's a univariate analysis. Now what's a multivariate analysis? So here's the key intuition behind a mult variables analysis. The idea is, think in a very abstract similarity space. And the intuition is, because in both cases it matters what you Think. person who wrote the essay was in the room when you said that publicly shaming thing? A different story is about demonstrating your karate skills and knocking out your classmate-- again, totally new moral scenario. But again, this one feature-- did you know or not know that your classmate was there when you did the kick? Now here's the idea. Even though each of those new scenarios is completely different, if there are different subpopulations within your right TPJ responding when you knew you were going to cause harm, then a little part of that response will be the same. same way, right, because the same cell population will be more active for all the stories that have knowing harm. And the other population would be relatively active in all the story that have the unknowing harm. OK, so this is the central logic. Take any two stories within the set. They're all unique. So those two stories that are different, you're representing a new mental state of a new person. And so the logic is that if we could look in the right TPJ and measure the pattern of activity-- and hope that reflects something like the relative activation of different cell populations. You have a new pattern in your right TPJ. But if they share the feature that you knew you were going to cause harm, that would be something a little bit similar. Does that logic make sense? And so what you get is a spatial pattern of activation. So the amount of activity in the rightTPJ is a big signal. The relative activity between one voxel and another is a tiny signal. And it's superimposed on a lot of noise. If there's anything there at all, then you'll still still be able to see it. be able to pick up a little more similarity for pairs that are matched on the feature of interest. That's the logic behind a Haxby style analysis. And so literally what you do is, you take the vector of responses across all the voxels inside a region. And you ask whether the correlation in space is more similar for. pairs that share the feature you're interested in compared to pairs that don't share. the feature that you'reinterested in. The first question is-- is that real, or is that a coincidence? That is the first thing you want to know when you do an analysis. you see data like this. Afterwards, we can ask what does it mean. But let's start with is that real. And so the way that you ask is it real is, you just make sure that it would replicate, that in independent data you'd get the same answer. We had actually already run this experiment two times before-- because we were studying this process of representing accidental and intentional harms for a long time before we thought of using MVPA. And the other thing is that we had manipulated this distinction in different ways across the stimuli. did it is, we said you knew about the allergy or you didn't know about the allergies. And what you want to know is, are you decoding the abstract thing-- that she knew she was causing harm or not? Or something less abstract, like whether the story has negation in it. That's an alternative possibility. And so in experiments B and C, we had done it this way. It's also in the third person, not the second person. So if we find the same result, then it generalizes across all these incidental features of the way the experiment was conducted. There's something more real about it than if you knew the hypothesis before you ran the experiment. There's just this experience like, if I had the hypothesis in my head, maybe it somehow got from my head to the data. But when the data were already there and then you went back and analyzed them and the effect was hiding in the data that you'd had on your server, there's something way more real and magical about that. So anyway, because it was there in all of our old data, I just believed it. MVPA is not a technique for collecting better data, it's a technique to get more information out of the same data. It's a way of thinking about data, not a way to get data. The other thing to notice about this is, to get an MVPA signal, we didn't change anything about the fMRI. You can know that for sure, because these are our old data that we had before we started doing MVPA. Was it true that two unrelated stories are about a case in which somebody kills somebody? It was true. right TPJ more similar, suggesting that which part of the right TPJ is more or less active contains information about whether or not the person who committed the murder knew what they were doing at the time. This is specific to the rightTPJ. So these are a bunch of the other brain regions involved in theory of mind and social cognition. And none of them contain any information about this dimension at all. So this dimension is represented in theRight TPJ and not represented anywhere else. Some people think that basically what you thought you were doing is all that matters in these stories. than it is for other people. And the pattern difference in your right TPJ accounts for 35% of the variance in your moral judgment. So it's quite amazing that those are that correlated. But that's what's cool about the data. But we'll get to the method. So Haxby style correlations-- these are these are Hax by style correlations. So the more that you represented knowing harm as different from unknowing harm in yourright TPJ, the more you judged them as different when we asked you for moral judgement. MVPA was introduced by Jim Haxby in 2001, so actually a long time ago. The idea is, take a region you care about and ask this basic question. Is the correlation across neural responses more similar when the stimuli share that feature than when they don't? So that gives you a pretty robust measurement, because you're using all the voxels in the region to get one number out-- the correlation. And you're doing it over partitions of the data, often halves of thedata, so many trials are going into both the train and test. case we're using halves of the data, even halves and odd halves. And so each of the things we're correlating is a relatively less noisy neural measure because it has many trials averaged into it. In this case, it can be sensitive to pretty minimal stimulus variations. So it's sensitive to small distinctions in the stimuli. Here we showed that it generalizes. It gave us a measure that was stable within a participant in the sense that the measure in each individual related to that individual's behavior. it differs across regions. So we could show that this was present in the right TPJ but not present in other regions. That's a whole bunch of extra information than we ever were able to get before. And I'll give you one more example of the way that Haxby correlations can be used. So in this case I showed you, we hypothesized one dimension. And we tried to decode that dimension. Obviously, you don't only have to do one. And so another way to do this is to build stimulus sets that, for example, have two orthogonal dimensions and ask about both of them. stories vary. So here's a bunch of stories. Leslie has just been in a big, important interview. And he sees himself in a mirror, and he sees that his shirt has a big coffee stain down the front. Another one is-- Eric gets to a restaurant to meet his fiance's parents. So that's two completely different stories. And then the third story-- Abigail is painting her dorm room, and she hears somebody's footsteps down the hallway. And the footsteps sound like her beloved boyfriend's. So these stories are all different. But, as you may have noticed, the stimulus set had another distinction in it, which is whether the thing is good or bad that's happening to you. And so we could ask in the same dataset, what about stories that share this feature of valence? The pairs of stories that are matched on valence, do they have a more similar neural signature? And in the right TPJ they're not. We've actually found this a whole bunch of times. The rightTPJ doesn't care about valence. Other regions do-- don't worry, we don't. There's a whole bunch of limitations of Haxby style correlations. All the tests are binary. The answer you get for anything you test is that there is or is not information about that distinction. There's no continuous measure here. And so once people started thinking about this method, it became clear that this is actually just a special case of a much more general technique. It's just that two things are different from one another or they are not different from each other. And that's the way to look at it. more general way of thinking about fMRI data. This particular method, using spatial correlations, is very stable and robust. But it's a special case of a much more general set. It's a very stable, robust method, but it's not a very general way to look at fMRI. It doesn't work for all fMRI patients, but for some, it could be a very useful tool. It could be used in the future to help people understand their brain's responses to stress.

ROUGE-1: 63.34, ROUGE-2: 59.77, ROUGE-L: 57.14
BERTScore: 77.49

==============================================
==================== [26/100] ====================
Summary:
Ribonucleotide reductase is the only way in all organisms that you make the building blocks de novo that are required for DNA biosynthesis and repair. From a practical point of view, it's the target of drugs they use therapeutically in the treatment of cancer. And I think in probably not so distant future in the antibacterials because I think there are sufficient differences between humans and bacteria reductases that you could make specific inhibitors. Why am I interested in it? Because the chemistry is sort of unbelievable. Nature has figured out how to harness the reactivity of radicals to do really tough chemistry with exquisite specificity. ribonucleotide reductases have been the paradigm for thinking about that. There are 50,000 reactions in metabolic systems that are going to be radical mediated transformations, yet we never talk about radicals in introductory courses. So I think that's all going to change. In the active site of these enzymes, the half-life of a tyrosyl radical in solution has a half- life of a microsecond. If you reduce it with an electron and a proton, the enzyme is completely dead. So nature has figured out a way. How do you do this oxidation? She has a little metal cluster right adjacent to where this tyrosine is. And the function of this littleMetal cluster is to put this into the oxidized state, which is essential for the way the enzyme works. Of the enzyme can be on the order four days. And this was the first example of-- it would be another example of a post-translational modification that we talked about earlier. oxidation the two atoms are sitting within a few angstroms of each other. So that's unprecedented. It involves hopping radicals which no one has ever seen before. The other reason that people in biology are interested in this is that if you believe in an RNA world where we have a ribosome where a catalysis of peptide bond formation is all with the RNA, not with the protein. How do you get from an RNA to a DNA world? The only enzyme that does that transformation making these building blocks are ribonucleotide reductases. and do the same chemistry, but they have different metal cofactors depending on where they evolved. The function in all cases is to generate a radical in the active site and then the chemistry is the same in all these things. And the function of the metalcofactors in all case is to create a radical, which is the key to the chemistry in all of these cases, says Dr. Michael Bociurkiw, a professor of chemistry at the University of California, San Diego.

ROUGE-1: 76.20, ROUGE-2: 71.17, ROUGE-L: 65.36
BERTScore: 77.47

==============================================
==================== [27/100] ====================
Summary:
Calculus is the big application of calculus, so it's kind of interesting to see what part of calculus actually get used in differential equations. The derivative of x to the n, the derivative of sine and cosine. Above all, the derivatives of e to the x, which is e tothe x. And I'm going to show you what I see, and it's not everything by any means, but it's some basic ideas, but not all the details you learned. is e to the x. Dy dt equals y. And then the inverse function related to the exponential is the logarithm. With that special derivative of 1/x. OK. But you know those. Secondly, out of those few specific facts, you can create the derivatives of an enormous array of functions using the key rules. Derivative is a linear operation. The product rule fg prime plus gf prime. The quotient rule. Who can remember that? And above all, the chain rule. of functions that really blow open the functions or we can deal with. OK. So the fundamental theorem involves the derivative and the integral. And it says that one is the inverse operation to the other. The derivative of the integral of a function is this. Here is y and the Integral goes from 0 to x. I don't care what that dummy variable is. I can-- I'll change that dummy variables to t. Whatever. I'll use it. Maybe that's better. A key example in differential equations. The function I have in mind, I'll call it y, is the interval from 0 to t. It's a function of t then, time, It's the integral of this, e to the t minus s. Some function. That's a remarkable formula for the solution to a basic differential equation. So with this, that solves the equation dy dt equals y plus q of t. So when I see that equation and we'll see it again, we'll derive this formula, but now I want to just use the fundamental theorem of calculus to check the formula. So I have a function t times another function of t. I'm going to use the product rule and show that the derivative of that product is one term will be y. OK to take that derivative, I notice the t is appearing there in the usual place, and it's also inside the integral. But this is a simple function. I can take e to the t out of the-- outside the integral, and I'll show you how to do it. Be nice, I just think if you plug that into the differential equation it's solved. rather I just called the function f. A function at a point a little beyond t, is approximately the function at t plus the correction because it-- plus a delta f, right? A delta f approximately? It's approximately delta t times the derivative at t. That's a fundamental idea of calculus, that the derivative is quite close to delta f divided by delta t. So the way to get closer is we have to take into account the bending. The curve is bending. What derivative tells us about bending? That is delta t squared times the second derivative. function because that's a nice function, e to the t. We can recreate that function from knowing its height, its slope, its bending and all the rest of the terms. So there's a whole lot more-- Infinitely many terms. That's called the Taylor series named after Taylor. It's frightening because it's got infinitely many terms, and the terms are getting a little more comp-- For most functions, you really don't want to compute the nth derivative of the function. this isn't so practical. Tangent parabola, quite practical. Higher order terms, less-- much less practical. But the formula is beautiful because you see the pattern, that's really what mathematics is about. They all fit that pattern and when you add up all the terms, if you have a nice function, then the approximation becomes perfect and you would have equality. And those are the best functions of mathematics and exponential is of course one of them. OK that's calculus. Well, part of calculus.

ROUGE-1: 56.53, ROUGE-2: 54.55, ROUGE-L: 51.70
BERTScore: 78.24

==============================================
==================== [28/100] ====================
Summary:
The last lecture of the winter term course on probablistic estimation techniques. This lecture will focus on front ends and how to determine if a constraint is likely to be a correct one. We are still interested on adding as few false positives as possible and so this this lecture will look at how to avoid to add roam constraints to the data. We will also look at some of the techniques which can deal with outliers in the data Association so if we have from constraints they are technique that are able to deal with that. is related to the front end and what my goal is for today I will introduce three kind of small front end systems on a very abstract level just giving you the idea on how they work with different sensors. In the second part of this talk today I would like to stress on what kind of conditions should such a constraint fulfill or the the metrics of the local environment fulfill in order to let's say I would say ensure to be out layer free but to reduce the probability that this is actually an outlier mesh. when the robot observes the same part of the environment and so far we always assume these constraints are given so these errors here we assume to be given and today we would like to look at the case how do actually generate those arrows. The two main components of the slam system are the back end and the front end. The back end optimize the graph and returns a new node positions back to the frontend. The front end uses this information together with the new centre information to generate new constraints. to begin by matching observations so we have different observations depending on what platform that can be whatever stereo camera or laser rangefinder or different types of sensory modalities. For every sensor of course there's a different way of obtaining those constraints and those constraints may take into account what the sensor actually sees how kind of unique is the data that the sensor generates for specific area. If you only rely on laser range data and the corridors all look exactly the same from the Rays range data point of view then we may take that differently into account. what we assumptions we make about our observations this tarz can be very hard or not that hard and what typical approaches are is if we go for laser range data is then scan matching. Other approaches use features for example we had those the Victoria Park where trees have been extracted in this case from the laser rangeData. The trends of trees and every trunk of tree was seen as being similar to each other. If we can match them well I'm gonna say okay this part of the environment I see at the moment looks very similar to the part of. the environment that I have seen so far in the past and therefore it is quite likely that we are at the same place. one feature or one landmark and the robot map those landmarks by checking for say fitting circles into the laser range data and whenever it found a good circle say that's likely to be a chunk of a tree and use it as a landmark the third class of approaches uses feature descriptors most popular ones are for example sift and surf. These are two features which you can extract from image data and which kind of describe the local surrounding of the place where this descriptor is computed. You can match surprisingly large databases of images using those descriptors. moment and that's my sensor range I can compute where are those other pulses so in this case B 1 and B 2 just two examples could be more obviously and then I can also estimate what is the uncertainty of those poses B 1 & B 2 relative to a do that by eliminating the note a from my linear system and then inverting the resulting Hessian and looking to the main diagonal blocks this gives me the uncertainty here indicated by these dashed lines. Based on this information I know I can never have an estimate of given my current pose where's b1 and b2 together with The Associated uncertainties certainty estimates. area of my scanner and say okay say if the robot was sitting standing over here that's the area it may have observed then I can simply check is the current sensor range is there an overlap between the current sends a range and the possible observation that I obtained from b1 on b2 and if I found places for which this holds then this is the case for b1. In contrast is that if I look to be - I can say okay the uncertainty of b2 extended with the visibility range of my of my sensor by no means overlaps with a so it's extremely unlikely that a can match b2. was here indicated with a which can where I could I can obtain by inverting the hessian the problem is in practice this is a pretty expensive operation. So you actually want to try to avoid inverting this larger matrix you can do an approximation what actually most system in practice do to do that more efficiently. This is a thing by they say okay we simply ignore the loop closures for the moment just for estimating the uncertainty here and you just do what is also called Dijkstra expansion so we expend propagate the uncertainties through the graph. I reach all the posts I'm interested in looking into but this does is ignores the loop closures so the uncertainty estimates are too big. You can still argue that okay uncertainty estimates I get are toobig but I can compute this extremely efficient. I may inspect a few places too much but I should get all the places which I need to inspect in order to make sure I find the course with whatever 95 percent probability. This is what is done just as a side note. What is done in practice to what inverting this matrix age there so far. a side note and what we do then we just check which areas overlap and if there's an overlap in the area between the current scan of the robot and the sense range of the Robot. At that point I say okay this may be a match this may not be amatch okay next question is how do I determine is there a matter or not. This strongly depends on the late data laser data or the on the data and here is one example of a very simplistic front end which will try to identify constraints which uses iterative closest point. match so how could we do that so for the first thing we do we estimate the uncertainty of the other poses relative to the current pose of the robot so that's what we discussed so far given behind that we take those posters which are in the air we just made just a sample poses in in in those areas so just read we draw horses so if I go back to my example I take a okay I select okay B is a good is aGood potential match so just sample random locations here close to B and what I then do from every of those sample points I apply skin matching. just see okay how well I'll do those observations align or how well does my current observation align with the local map I've built so far let's cook looking into the sum of the squared distances between those the corresponding end points those end points which I regarded as corresponding points and if this is above a certain threshold I accept the match. That's a very simplistic technique of course you can do much better but this is kind of the basis the basics of most laser-based front ends today. into account but in the end the cordilla Mallis boils down to that again you can extend to improve all those aspects here but this kind of the basic decision based on a range data are two places or given an initial guess what's the transformation of the locations from which those two scans have been taken okay where do you see problems here that this were perfectly aware would you see the failure points for this approach. If your customer and I've proposed you this solution what would be maybe your argument against that would you buy that this approach which I propose you good. ICP is a combination of the iterative closest point algorithm and the initialization so ICP depends on the initial guess and it just finds one solution and may be the right solution but as you pointed out in your example it might be the wrong solution. P is sensitive to the initial guessing and as a result of that we may end up in a local minima so in something which looks like a match it may not be the best solution. If you kind of it's an absolutely correct observation this can happens where would you identify this problem in this list of approaches. but in reality is not a match other things we may identify is how do i sample possible locations where the platform can be if this is kind of the uncertainty is a very large area I may need to sample a lot of different poses in order to do that efficiently. How do I find actually even a good initial guess and so these are typical problems that those approaches has or ICP is sensitive to the initial guess we have local minima we may have an inefficient sampling strategy. Just accepting something based on a threshold as always something which some one might dislike. showing you three different examples of systems that we have built here in Freiburg. Some of the mapping techniques we developed here have been used to at least tested on that car so this is a pioneer a two robot which has a two d-day the rangefinder sitting here and sits on a pencil unit so it moves always like this song so it's called a nodding laser and this way generates 3d data you get 3d information about the scene and then it tries to build sorry a 3d map of the environment using this technique. assume the robot is standing still when doing it skins maybe it's driving while it's taking its games driving may make it a little bit more complicated if you have not a good odometry estimate. While driving you don't observe the same part of the environment and this makes it hard to make any incremental alignment. Based on our local 3d scans we can actually build a map we can build a local 3D map of the scene this this map can be either a point cloud accumulated over multiple pulses multiple scans it can also may also be represented by a 3d grid structure. then we can do is we can take those two local maps and try to align those twoLocal maps it's typically Nanban so depending on how many scans you integrate either you could take these skins. If it's just kind of one 3d scan you would although in practice it's a number of 2d scans for matching. Sometimes it's easier to match full maps like versus individual scans this depends on the data that you have and how many ambiguities you may find your environment so if you have a local blast slightly bigger view so you really match a map against the map that may be that. have less local minima so we match those Maps and get a six degree of freedom constraint in this case XY that your patron roll so six dimensional constraint. Then we can accumulate all constraints and then do a graph optimization and obtain a local map so this also a parts of this is building 79 building 51 52 the Mensa building and of course some parts here the green area which robot hasn't seen how does it align those two scans of these are two examples of two scanned 3d scans and which have been taken from different positions. say classification or segmentation of the environment like and if I wall think that stick out and first met results against each other and only in the end it does the alignment of all points because you're less likely to end up in a local minimize so if you let's take the tree the pole and the walls and match them first you if you can separate those part of the skin reliably he typically are less Likely to end in aLocal Minima and then you get this kind of alignment so this the iterative procedure nice based on ICP which align those scans. darkest stripes these are simply small alignment errors of these individual maps they can they can see kind of small steps over here here that was also probably an alignment error which simply leads to her step which was let's say bigger than and all five centimeters in the ground and therefore it's classified as not reversible anymore. Everything is red over here but so what do you see here for example other the bikes which are parked over here and the individual trees here something it's like to have gone wrong or maybe there was some copy. It has a 3d scanner in here on top so that's a valid I'm 3D scanner which is rotating and generate 3d point cards at a very high frequency. You can use a very similar technical basically exactly the same technique in order to align different pulses of the wiegel here. If your initial estimate is better if your laser data is a high quality laser data then you get an example like this you have seen this picture already this is an example of how to do it. is a parking lot or a 3d model of a parking lots where yellow again means drivable areas and red means non drivable area and then you can actually use this this map over here in order to localize the vehicle. This was actually work of China that he built or he realized autonomous parking using this map representation which was built here for that vehicle in that parking lot well it's actually the picture of a Parking garage. It's a trajectory of the car doing the mapping process so stop it from here stop from here and build a map and this was this in this example. done with the grid for 20 by 20 centimeter grid cells and this by lining those grid cells you can actually get maps off and say this quality that's something you can expect to get with this technique. System which was flying on the prototype for a helicopter so never made it to the blimp in the end this was just a self assemble stereo camera system with two webcams assembled in a stereo setup and a small IMU there's there's a lot more to come on this project. an initial inertial measurement unit and one of the advantage of this system is it gives you also the gravity vector this quite accurately at a high frequency. If you know the gravity back door you can eliminate already two of the six dimensions from your state space. The roll angle and the pitch angle can be determined but just by knowing the gravity so you have only one angular component and XY that that you need to estimate and therefore adding this IMU to the tourist error system is is highly advantageous. I'm interested to really get so it's kind of a webcam off 2008 I would say it's about 2007 yeah these times this was actually the work of past times DITA his master thesis when he did that. These are the the piles you can see these releases of hires in our building these are the positive front of our building and the grass area so if you take the stereo camera pointed downwards and walk over the green these are images that you get and if you get if you see this image view you may already at it guess that it's maybe hard if you travel over grass for extended periods of time. Surf features provide a local description of the scene of a small noise a scene of the small part of the image. Alice is computing their computer kind of from a local window around them doing some local operations and returning typically a 128 dimensional vector which is a local descriptions of the area over there. In reality typically is in two step process first so-called key point detector is executed which tries to find could have let's say call it stable areas in the image so if you have two similar images of the same scene. Based on the position of my stereo camera I try to build a local model of the surrounding so what we want to estimate is the X Y that and three angles your roll pitch and yaw so if you have this your camera looking forward this is roll this is pitch and this is your and so as I said before by adding this IMU to the to the stereo camera and the in this case the the camera is looking downward to me of the IMU on top we know the gravity vector and so this eliminates the roll directionally. order to estimate the relative pose of the camera so in practice looked like this so this was the camera pointing downwards they say this these are images which and the red dots are positions for which those features have been computed these are my features in the map let's say this is the current image that our observe saleh bin this looks like this the transform it over here and then you can take this image and add it to you map or add a constraint between the position where this camera image has been take the current camera image and the images have been taken at previous points in time. image and you have a database of all the sort of features that you have seen so far in the past what is the first thing you do is you try to make a nearest neighbor query in the descriptor space to try to find the best matching descriptors over your map or in those areas which are in line with the credit unit in the beginning with its A's and B's which overlap. This cue can typically do that very efficiently with was a KD tree it's a data structure which allows you to search in log n time with a number of data points. the best 100 features which match my current the current feature I'm considering I made and can do that for multiple features in my current image this gives me already a pretty good idea where I might be ok. We then sort those matches according to their quality simply start from the top so we start with the best match it matches we say ok let's take the first pair and with the first other matching pair in the other image and it's compute where the camera pulses should be given the under the assumption that this pair is correct and then we take all other features that we have seen project them into the from one image from projecting to the other. is a procedure which is very very similar to Rancic it's actually a variant of good sake I think which was used here but this is just you you sample a few parameters that you need in order to compute the solution and then use all other informations to evaluate this solution. Then you try that multiple times and see how often do we find a consistent match. That's the way this works this technique is used in three different ways in this approach the first one is for for visual odometry so there is no wheel encoder on the camera. an estimate of where the relative poses are so what you can do is you canDo what's called a visual odometry so based you inspect the images and consecutive frames estimate the positions of features and then estimate the movement of the camera based on the feature that you see and the 3d location of the feature is exactly in the same way. This how we can actually generate odometry information although we don't have a physical odometer information from wheel encoders the thing technique how you can use this is actually for matching your current observations against a small part of the environment so it's good it's kind of a localization step so the robot its reach traversing. an existing part of the environment has a good estimate where it is that is what we refer to as localization and the last part which is loop clothing so given I kind of I don't know where I am some a large uncertainty and I you can use this approach to see how well do the features that I see at the moment mattress features have seen in the past and try to find an alignment for this this is a good alignment you may accept that or you may try this for a couple of consecutive frames that not just kind of one bad image screws up everything. is a stereo camera kind of on a fishing rod so that it's kind of simulating a flying platform which we didn't had at that time and these are they this is kind of this is the current camera image that you see the feature that were extracted. What you see here is a map that the system builds on the fly and that's how that looks like so walking over the green and the back of our building so today this is all butters and trees over there so it's quite a while ago right. the tiles because you get better features to match a few seconds he will return to a place where he has been before so you can see actually he approaches it's actually in reality here. There's a there's a substantial mismatch there no features that are matched at the moment. As soon as he goes back to its starting location you will see that it finds some of the features which are consistent. Some constraints will be added to that graph and even found constraints along the grass because in no way he was walking and tries to walk along the same area again. Weather system real localized is a blue one because it's moving back on the director so you can apply the optimization. Get out this trajectory with the corresponding images and feature locations that the system has observed can then overlay that with our building that was actually Google Maps image of 2007 so the quality was bad today the quality is much better. The rough estimate of this trajectory actually is similar to where he was actually walking you can actually evaluate that even better so the same experiment he can do indoor where you put in known markers in the scene or markers had known positions again. of taking the three positions of those features and doing kind of a mapping beat the textured image on those on the 3d points it was kind of one and a half by five row by ten meter where different markers were placed on the guard which were measured and this was measurement tapes or not the presely perfect high accurate measurement but let's say up to a centimeter. Then you can actually revisit the same place in this way close the loop and then estimate where are the marker positions in between the map and reality. of the Reaper this was one of those boxes was just taking the camera images and projecting it to the or mapping it to 3d point structure. We have the 3d post information only for those feature points so we don't have that for the overall image you can actually overlay that so as x61 out by 10 meters and you could actually see that the estimate so this is a ground truth information the green lines and this is the mean and uncertainty that was estimated so this scene seems to be a somewhat consistent estimate you may see a small bias it's not centered around zero. in the end God used here was exactly the same approach but only a single camera and the SONA which was measuring the depth information and so this was a blend. The tas of the blimp was always to hover on top of this location which was here marked by the book i think somewhere over here or here and so it's always trying to hover and whenever it hovered this is the hovering location someone took it and throw it away so robot was going somewhere else building a map of the scene. Tasker builds a map online and use the map in order to make navigation decisions of where it should actually go. It's an online process which requires us to built the map to update the map and always come up with an consistent estimate of the map. Tasker then generates steering commands which always guide the platform back to the desired location in this case again it should hover here at one location okay these are two problems with this we discussed or we said how can we get around them. The platform is actually a little bit tricky for the platform to always hover or people walking by and yeah and then someone again pushing the platform away. solve that so the ICP is sensitive to the initial guess so one thing you can do is try to find arrange things into Maps instead of single scans this helps or we can separate the local perceptions into some parts let's take this wall so there's obstacle that you stick out and try to match them first we are less likely to end up in a local minima but of course there's no guarantee for for doing that. If you have descriptors like feature descriptors it can actually help you to find good estimates where you can be so you don't have to try all camera polls and see if the camera poses match. talk which I Neff was more over more whatever like wait overview about how different approaches work was not going to too many details. The second part of the talk today I would like to talk about ambiguities in the environment and what are good ways for dealing with them. How can we actually even though we have environments with ambiguity build accurate maps consistent maps of the environment so they are are so or the main assumption here is not we simply ignore all n big you T's and say the environment has no ambiguity. the place a which is the current view of the robot let's say local view and a place B say it's actually place here looks pretty similar to this place over here so our a and B the same place in the ICP based matching approach would say okay let's sample some positions here and then try if you can find a match and actually we will find amatch here. This will mesh this structure here quite well for an ICPbased alignment technique but we could always argue is this the same places what's the problem. be the same place but there might be something else which looks exactly than in this place a here so it may not be a good idea to add this constraint unless we have seen all this part over here. In order to make this constraint view maybe it's better to first explore all this scene over here before we can make this data Association. This is something which is called global ambiguity or something so there may be different places where the system can be which are just which are which do not intersect with the place I'm currently considering. that you want to make sure so they're two ways you can do that the first thing is try to close your loops as early as possible so don't let the uncertainty grow so much and the area smaller it's more likely did you find a match. The other thing is you could simply cover the whole area so that the answer the ellipsis one day and once you found one where it matches then the uncertainty of all other through decrease in this helps the system but so we're not doing here the active approach of Explorer and how to explore in order to build a good map. or not so maybe a bit imprecise from what I talked before so there here is a global ambiguity which is something we don't want to have and they are they example if the uncertainty is small and I have this Metro they say okay that looks good that's kind of what's called global sufficiency so the opposite side so this is a globally sufficient match so there's no other place in the uncertainty area of that node where the system can fit in these are the things I am interested in finding exactly those it's all situation. this structure here you have the corridor and it's a kind of the part of the doors or they whatever small pillar which holds the door in torch to its Agha you can see here. There are multiple hypotheses how it can match inside and they overlap therefore it's local the other ones non-overlapping its global. This is this is our overlapping matches is global so I don't know how this a fits in here so does this guy over here fits this one this one or this one so either here here or here simply something I it's. hard for me to you to to identify and this is also called what's called the picket fence problem so good offense you seem you don't know which part of the fence matches to what you see so far it's a very very long repetitive structure. These are things where you also don't want to add a constraint the curses simply do not know is this is this locally ambiguous or not. What you could do is you could use the max mixture approach and say simply it'm a multi-modal constraint that I may add I'm either here here or here. same author I've been all since ethanol in this group who develop this approach and later on max mixtures so this would be one nice application for mac semesters but assuming we don't have max mixture we have to treat those things separately okay and what can you we can actually do two tests the first one is a global sufficiency test so we want to say there is no possible disjoint match in the uncertainty lives it means a cannot be completely somewhere else it's not possibly that a can be somewhere come at a completely different place. to white or I want to make sure that both constraints are both conditions actually hold and the approach that every Doulton and his team proposed we're saying okay we have all slam back and it gives me an estimate into the prior the current estimate of the of the graph that I have and I do a it does a post poll scan measuring very similar to what you've seen so far. Based on the scan matching we can actually do a topological grouping so pulses which are nearby which are in the same part of the environment I just grouped together it's kind of can see this is a small local map. of doing that and then it does two things the first thing is it tries it tries to find within those groups of those topologically grouped nodes. The second thing is to find consistent constrain so how many constrains I can find in there which are consistent among each other if there some say either I'm one meter to the left or I'm two meters to the right there's an indicator for this picket fence problem we can be like in the corridor it can be either here a media for word or two media for vocal three media forward but nothing in between. is to trying to identify this situation and the second thing is kind of a global ambiguity test which is much simpler which basically takes into account what's the area that I know given the uncertainty lips that I have and is there another local area of what I've seen which would fit in there and still will allow for match. With this with getting rid of those two doing these two tests we can actually eliminate a very very large number of false positive constraints so that's actually one of the state-of-the-art systems which were used in slam front-ends. found based on the sense observations and say this is it seems to be okay or this seems to. be a wrong constraint okay so this is a criterion 1a the second criterion for the for the local local ambiguity and global sufficiency so or local and ambiguity andglobal sufficiency it'll be so these two tests I have okay we would like to go through these three steps over here the first one is the topological grouping which is easy to be done so I just takes my post graph and I just take okay which poses are nearby and then I try to match all of them. good fit maybe yeah doesn't sound too bad just add them to kind of a temporary constraint list and this is shown here in red so this one can Michigan this pot this post this post is against this opposes both this post and this guy again. Some of them will be likely to be right some of them are verylikely to be wrong. The first thing we do is we want to test for local unambiguous so we take one of those groups and check okay is here do they is here the risk for picket fence problem how can we do that? are above a certain threshold I keep the other thigh removed it would optimize this map. I would get this situation over here you can see here they're kind of walls which are dublicate it so it's definitely an imprecise map of the environment. If I however find only those which are the right ones which it leads matchings over here if you get a consistent map of. the environment and based because of this structure over here. You can see this structure in this structure and he actually structure may be seen again as similar. The key trick in here is we have a large number of constraints pairwise constraints between nodes. We want to find we want to check in to how many consistent subgroups are there. If I can assign a kind of a group ID to every constraint and the goal is that among one group within one group they all consistent with each other that's would be the perfect thing. If not I'm happy if there's a local ambiguity I may say okay it's better to not let a constraint okay locally consistent matches how do we actually get those locally consistent matching that's one of the key questions here. Within a group they all agree and this is one of those situations where I can see all which is an indicator for this picket fence program okay how does it look like. Once we're the first time with it the place I just saw here in red and the second time in the robot visited the place here shown in blue and I get those matching constraints in this case so H I and it's J isn't just two hypotheses of four constraints how that can look like and the idea is to say okay in order to check which are consistent I need to check if they kind of transform the environment in the same way. these are those add edges which result from odometry or incremental scan matching if I start from this node over here I can take my little madama tree constrain to go here. I take my constraint HJ to jump into the second trajectory for the point in time when I visited the place a second time. If I have this kind of loop of constraints if they are all perfect and agree and consistent I should add up at an identity transformation if I concatenate all of them of course I'm kind of starting at pose one in the first time series. time one at the second visit go to time two of the second with it and then go back to time one in the first with it. Only if those constrains agree with each other to end together with the odometry information that was collected I will end up at an identity transformation. So the trick is now to use all those pairs of constraints and see which one end up with with an identity in which was the biggest group of consistent transformation that I can find in here you look a bit skeptical of course. and how accurate can you actually align your scans so of course Moodle oh that yeah okay so I have whatever a number of those hypotheses what I can do is I can actually build up my matrix a I J where this simply depends how consistent are the hypothesis using the hype of this I and a hypothesis J together with the odometry. So this is this is IJ so I just cannot make this walk around in my graph and say how close am I with respect to the identity. If I'm closer than you say that's pretty good if I'm far away from identity as they are something has gone wrong here. given those two constraints and these are welders which are which are sitting here so as they are high values if they say it's very likely as I'm at the identity that's a bad thing which can happen to me or I'm getting a really low score close to zero which basically means I'm far away from identity we may use just a Gaussian about how far I am away you're away from the from the identity so what you end up you have a matrix with those values in here and some values are have high. and if you don't understand what the matrix means it will be hard so every entry of this matrix IJ tell us how well do hypothesis hypothesis J agree with each other just looking to this this pair of it's just a pairwise consistency mention the small if they're small Wireless in there I mean they don't agree they are high values and Daisy but they agree that may be good again this so far hasn't helped me to identify these groups or if they identify if they are different groups just says which pairs are consistent with each each other. I have a 1 here at the field I it means that the assumption that H I is correct and if there's a zero of it if AJ is incorrect or it's not correct so I get effect every vector consists of zero. Once it is one hypothesis about the consistency of my matches if I have in there one in there it's pretty good. If all of them are zero which means it's completely incorrect it's just one so the goal is just to find this vector and then later on find a way and how can we determined what V this vector be all right. correct if there's a zero in there it's incorrect and now comes a trick we combine this indicator vector with my matrix. If let's say I and J are one the rest is zero it will directly take out the corresponding value of my matrix a for the consistency of I andJ. If they are all of them are one at the sum of the elements of the matrix if only two elements are one and all of their their are one this gives me the sums of all consistent hypothesis according to the indicator vector. I'll just get this is the corresponding element out and then I divide it simply by V transpose times V so the scalar product of this vector V which is simply the number of hypotheses which are correct according to this vector so it is just an average of course it's consists of zero and once they're the same vector so whenever both elements are one I just add plus one so that's kind of the average pairwise consistency so now given an indicator vector of V I can compute this quantity here and this gives me a score. once once in this vector and I will get a high score if I have ever two groups in there I have I get one. I get scores among the groups but not between each other so we get and I divide by again a large number of apostasy so we getting a small value so I have this function just high values for both elements and low values for bad hypotheses so what can I do again treated as an optimization problem I try to find the vector B which maximizes this fraction that's exactly what is done. this constraint that is an np-hard problem this is a corresponding densest subgraph problem. sort of find the best v actually need to try out all possible solutions which is something which for a large number of constraints simply doesn't work out therefore the ID years okay III know how to compute it but it's to computationally demanding to do that. Let's see if you're trying to find the approximation out of that and actually find a pretty good approximation for that by saying okay I simply don't treat my vector V as discreet I said I just allow continuous variables. problem I should come up with a very similar solution there's no guarantee that this is the case so it is definitely an approximation is a different problem that I solve if I go from discrete value from this credo from zero and once for binary variables to continuous variables but the assumption that I'm not too far away. ok how do I maximize this function i compute the first derivative I set the first derivatives to zero they don't want to go into the details how the derivative is obtained but it turns out solving this equation is equivalent to solving the eigenvalue problem. times V so in order to to solve this problem I simply need to solve an eigen vector eigenvalue problem. We then look into the and so the the vectors V that maximizes this equation. The original equation is kind of the maximum consistent subset or the average maximum cost is some subset. We can use the SVD that we discussed for example with the diagonalization in whatever a few months ago when we when we discussed this I don't know in which context we did that. and if I have multiple solutions for that get MA multiple. If I haveMultiple solutions for this eigenvalue problem this is simply they are multiple maxima in my in my problem. The larger the eigen values are the better the score so there's a proof that i get a perfect combination I get a couple of eigen vectors with current putting eigenvalues the larger the Â eigen value the higher the score and the  eigen vector allows me to say okay which which of the constraints are switch on and off. is a low value low valueLow value is a score of 0 or 1. The first solution corresponds to 1 V 1 so the indicator of 1 V1 which gives me the score Lambda 1 which is the highest score I get this is kind of the best solution that I have and all other solutions are much worse in performance. If I have three different solutions which give me mall as the same consistency score they could four and this is exactly the identical for one of this picket-fence problem I'm working on. have different consistent subsets of constraints which might be don't agree with each other so the only thing I need to do is if I want to say is it a picket fence it's a pickets fence here. If you have more than one solution I can just say okay what the ratio between the largest eigenvalue and the second largest eigenevalue. If this is a value which is let's say 1 or between 1 and 2's again yeah this is very likely to be aPicket fence prom. that might seem a topological grouping is done in a good in a fair manner and the includes all the relevant constraints but under this assumption that's exactly what I get out here so what I do is I take compute the first eigen value in the second eigenvalue and I compare them. If the solution 1 is locally unambiguous that means there is no picket-fence problem where is the high probability of course still may be the case I made a decision but that's my assumption here. I need to discretize V 1 to 0 and once in order to find my activation it's 1 point in here typically the eigen vector is normalized between 0 and 1. I would just round the vector be born I would end up with probably having 0s everywhere but that is easily solved because I just multiply this by a scalar. I just need to find the constants constant which make which maximizes this function over here so just a kind of 1d search problem in order to do the disguise ation of course if I compute the eigen vector or eigen value problem the eigevectors are normalized and I don't need it normalized I really want toDo the discretization so what I do is I just know I'm somewhere along one vector as lies my solution. what V is it's just kind of V times a constant C and just to determine this constant so that this expression is maximized but V is already given so that's that can be easily done okay so now I solved the local ambiguity problem or at least I'm able in a situation we can say there is a picket fence problem here or not. The second question is so this is one potential match is there some area around this area a within this ellipse so they would fit a second time in there so something I haven't seen for example well I see enough white areas that able to fit in there. second time this is the case I mean say I can't be sure that this is a concern it could be a constraint but I'm not sure that it really is a constraint because there's simply an area in the uncertainty on the relevant uncertainty area which I haven't seen so far. What we would in theory need to do we need to really check this area I can see if we can fit it in here an approximation for that is just compute the. size of the ellipse on this circle and theEllipse over here. in here is larger than the largest eigenvector eigenvalue of this guy. There may be possibility to squeeze it in there just by just comparing the eigenvalues along the dominant excess of those ellipses. I can actually do that again if a very very narrow matches this may veryVery narrow corridors this approximation may lead to a failure. If I find then if I find the picket fence promising we say I just abort and say don't add a constraint if it passes the tests. do the global ambiguity test or global sufficiency test so it's a globally sufficient order they say a global ambiguity if there's number you D don't add anything and otherwise I have a loop over which I can say with a high likelihood it's globally consistent and there's no local and acuity. That's a way actually most a lot of different slam system works also the SEM system that we use in here you've seen this video already where the system we have the robot mapping our campus over here. is a picket fence problem see that there is a local and B an ambiguous situation on a global scale and if not it adds the constraints and in this way builds a map of the environment of this kind of basically the front end hears and reimplementation or an implementation of the method of ethanol snow to make this test over here. We found that as very successful techniques in order to solve the same problem and not add false positives constraints or add only a very very small number of false positive constraints okay so to conclude this talk today I know that was kind of compared the front ends to the back ends. strongly depends on the sensors that I'm using and I need to the better I can exploit the individual properties of my sensor the better it is. The approach of this global ambiguity tests and the local ambiguity tests are important things that a good front that should consider in order to avoid adding false positives constraints. This is done with a single graph partitioning approach this was kind of the techniques there the technical - Olson which uses this and yeah again so regarding the the position uncertainty of the platform the higher the uncertainty is in an area. Ambiguity or not it's kind of if the uncertainty lips of speakers need to seen all that area to make this is no that's the only place where I actually can match and about the special clustering technique for the original paper where you find all the information here's the work back in also recognizing places using spectral clustered local matches. This is exactly the approach that I presented here and actually a couple of the slides that I use in here or of the images material at least comes from a tin Olsen.

ROUGE-1: 77.28, ROUGE-2: 75.04, ROUGE-L: 74.86
BERTScore: 71.68

==============================================
==================== [29/100] ====================
Summary:
[Music] because your success is my number one priority tell your neighbor our success is his number onepriority look at your neighbor and say our success are his numberOne priority that's good good job. So i'm hoping everybody gets an a in this class you can do it yes you can you don't believe me watch me. So marketing let's talk about marketing some more marketing so i told you what we're going to talk about now i'm going to tell you and then i'll tell you what I told you. marketing marketing that's capital n a you guys do it okay come on stay with me here no sleeping no facebooking who's facebooking now anybody. No text messaging all right no periscoping marketing is about creating. Marketing is about four things creating communicating delivering and exchanging value that's in chapter one so who can tell me what marketing is somebody good what's your name genius chingus go ahead tell us what is marketing i don't know but i know it's about creating right excellent good job. for something to be of a good value it doesn't need to be a low price it could be a high price but it's a very high quality and it has a lot of benefits do you agree who could explain that further good tell us your name albert alvin alvin Â alvinÂ albert i'm getting bad coaching here alvin go aheadTell us your items yes luxury items so if you purchase a 55-inch samsung 4k high-definition led monitor that has smart capability and 3d for 2500 you might very well consider that to bea good value. clothing yes go ahead like so like i find people saying like buying a pair of jeans and zara is expensive because there's like 65 but they last longer than buying these at all maybe unless so teresa is saying you could buy a pair. of jeans at old navy for 20 or you could buying actually i've done this you could. buy for 300 apair of torn jeans at diesel. You could buy three hundred dollar jeans that are already torn for 300 at the diesel store. So why is 300 for a. pair of diesel jeans considered to be a good value? marketing is about creating communicating delivering and exchanging value the way that we communicate the value is through the brand now the brand is what's wrapped around the product so all products in a given category have the same generic functionality. What makes one car unique from the other is the brand and we're going to talk more about perceptual maps where our brand is positioned in the marketplace relative to our competitors. i want to understand whether or not customers or potential customers or i'll use the word target market which is discussed in. The target market is who we want to buy our product or service. The target audience is usually a subset of the target market. The audience might be grouped by age so we're going to have a different commercial for men that are between 18 and 29 and those that are from 30 to 39. It could be for example all men that's our target market but our target audience could be all men. It's not the same as the target audience but it's who we're trying to reach with our advertising campaign. and those that are 40 to 49 does that make sense so you want to have a commercial for example that's going to resonate with your target audience usually you're not going to be able to have one that resonates with everybody. So when you're showing a commercial do you think that those men that are seeing the commercial between the ages of 18 and 29 want to see somebody in the commercial who's 60 or 65? "That's probably not something that's Going to resonate with them right unless maybe if it's coach no if it't uh bruce willis" their attention their interest create desire and ultimately action so you guys know who hulk hogan is you do what about john cena yeah. You don't know randy orton that's his thing no rko yes out of nowhere. If you were there i would have seen you it's like better than a broadway show they have fireworks on the stage and everything is amazing. So the brand is what distinguishes one product from another and that's what makes the difference between the two. another we could look at that through market research to understand the perceptions that consumers have for our brand importantly relative to other brands so not just where we are on the perceptual map the value of perceptual mapping of doing that type of market research is that we could see where we're positioned in the market based on certain dimensions quality price innovation relative to our competitors so remember it's the perception it's not a question of whether or not our product is expensive or whether it's a high quality the issue is what is the perception of the target market. Chanel: If our target market doesn't think it's high quality then we have a huge problem. Instead of going home crying what we do is what chanel said is develop a compelling advertising campaign to communicate that our product is of a high quality. We need to have pillars of support that means that we need to having proof points we get not enough just to say ourProduct is a highquality we have to support that. We have to provide proof in our commercials in our print ads on our website so think of marketing another way to think about marketing. marketing is about communicating you know creating then communicating so does that make sense so the order is important so when we say marketing marketing is about creating communicating delivering and exchanging value so from 30,000 feet if you will that's a broad overview of what marketing is another thing that we could say about marketing is that marketing includes five activities. What's the first activity the first marketing activity? It's to identify identify an unmet need so marketing we can describe marketing as being comprised of several activities the first thing is to identify anUnmet need that consumers have. being met so what would be a good example how about shampoo i know you're thinking what could this guy possibly know about shampoo. An unmet need is a shampoo that is safe for hair that's what that's dry or that that's curly oily that's perm so the way we identify the need is how guess guess guess oh you're not they're not good at guessing that's not good for exam day you got to be good guessers supply and demand right the wayWe're going to determine the need through marketing research. Focus groups are valuable because we're going to get a tremendous amount of insight from those for example who bake those who cook those who um who use tablets or smart tvs whatever it is that we're researching it's very helpful to do that. What that's going to do is inform our quantitative research a form of quantitative research is what we're doing this semester which is a questionnaire so a questionnaire our goal in industry is toget a representative random sample of how many a million people so in the united states how many people do we need to have complete the questionnaire what do you think million now. we have to have males and females people of different age groups peoples in their 20s 30s 40s 50s 60s. People of different ethnicities people ofdifferent religions so how many people do we need to participate so there's no definite answer. i'll tell you from my experience about a thousand people so if you have a representative random sample a thousand can be statistically significant a thousand to fifteen hundred but in most categories in the united states it doesn't need to be more than that. is that going to cost a hundred and fifty thousand dollars to do more intercept in multiple cities and get approximately 1500 respondents now when we do focus groups we also do multiple rounds of focus groups because each round is iterative so we learn from the first round of focus group and then we incorporate that in the next round before we do the quantitative research. i recommend that do the focus groups then we're going to do quantitative research before that now both of those focus groups and questionnaires qualitative and quantitative research as i describe that.

ROUGE-1: 64.90, ROUGE-2: 62.01, ROUGE-L: 62.37
BERTScore: 77.36

==============================================
==================== [30/100] ====================
Summary:
This morning we're going to carry on talking about Jeremy Bentham and classical utilitarianism. And I'm going to begin by making a few points about the measurement of utility, which we bumped into in a glancing kind of way last time. And then we are going to move from that into talking about utility and distribution in Bentham's theory. I think you'll start to see why classicalilitarianism became such an ideologically powerful doctrine in the eighteenth and nineteenth centuries. The idea being that if you think of, in this case, a very simple two-person society, and you Think of that as the status quo, A has that much utility, B has that many utility. rare case that you get it right about yourself. And it's the objective scientific calculus that's going to tell us what maximizes people's utility. So anytime you think this doctrine is crude or extreme, remember my point that this is a guy who takes every thought to the logical extreme. But if so you get one, it's a very rare case, but if so, it could be a very good one. It could be the beginning of the end of the world, as we know it. let's just for simplicity say, say one Standard International Util costs a dollar. Then I could make you indifferent between coming to class and not coming toclass by paying you two dollars. It could get you to come to class if I paid three dollars, and I would not get you  if I Paid a dollar, right? And so that's the second point. In the first instance we say that utility is quantifiable and expressible through money, but then related to that, and as indicated in the example I just gave you, we can work with a doctrine of revealed preference. utils of pain from coming to class, one experiences three utils of pain, and one experiences two util of pleasure. There's one perverse student in the audience who actually likes coming to the class. So then we would find that if we paid a dollar, one of you would come. If we increase it to two-fifty, two ofYou would come, and so we could vary the price to get information about your utility. And we could even influence your behavior without actually changing your preferences. Bentham allows interpersonal comparisons of utility. We can say that if you take one unit of utility from one person and give it to another person their utility will go up and the first person's utility is going to go down. If it turns out Leonid has a vastly superior capacity to experience pleasure than anybody else, then we could get a huge increase in total utility by redistributing things. But if the price is high enough you'll come anyway. But Bentham's system, classical utilitarianism, operates with numbers that attach to specific actions or policies. taking a lot from B and C and giving it to Leonid, so that we would say "allow," right? Or we could think of this change from the status quo-- we go to a more inegalitarian society and, again, the greatest happiness of the greatest number has increased. We have a world here where there are eighteen utils and a world in which there are nineteen utils. If the utility that the Aryans gain from practicing genocide and ethnic cleansing against the Jews exceeds the utilities that the Jews lose, there would be no reason under Bentham's doctrine not to do it. Econ 101: If you have no food and I give you a loaf of bread, your utility goes up a lot. Anyone know what the principle behind that idea is? Anyone want to take it? How many of you have done ECON 101, the first econ course? Yeah, so what is the principle that would tell you if you haveNo food? If you've got no food, if you're on the verge of starvation, you're going to be happier if you get some bread. If you're about to die, you'll be happier than if you don't get any food. If your utility is going to go up, it's going to make you feel better. Professor: Diminishing marginal utility is the principle of diminishing marginal utility of all good things. If you don't have a car and somebody gives you a Porsche Turbo, your utility's going to go up a huge amount. But if you already have a Porsche, you're going to get less new utility from the second Porsche than you had from the first. The new utility you get diminishes at the margin. Each new Porsche is less valuable to you than the previous Porsche. If we just kept giving you lots of right shoes, there'd be a problem. Professor: Does it mean that rich people will care less about money? just need more money to get the same amount of happiness. Prof: Exactly. So you got it exactly right to see that money creates some problematic examples for the principle of diminishing marginal utility. But the thing that follows from it is that, for Donald Trump to get more utility, you have to give him a huge amount of new money. So the more money you have, actually the moremoney you will want in order to get what you want. The way to think about the desire for money it's a bit like sort of a heroin addict needs more, and more. get the next marginal increment of utility. So we should expect rich people to be greedy by this theory, not to become more and more indifferent to money. Very important assumption and a lot of people get that wrong when they think about the principle of diminishing marginal utility. Are there any other examples of this doctrine that might make it seem problematic? Yeah, over there. If I had a second Porsche Turbo I would be just really reckless with it and I could do whatever I want. I wouldn't have to protect the first Porsche Turbo as much. up, but you really want to protect that little bit, but when you get more maybe it encourages you to save money, to not spend more. Prof: If you had one and I said, "I'll give you my one, it's right out there," you wouldn't want it? Student: It's not that I wouldn't. want it, but maybe the utility for the second one in some cases would be more than the utility of the first one so the curve would be thrown off. so you don't lose what little you have. Prof: Okay, so it's a possibility. Any other examples of where this becomes problematic? I mean, think about beer. One beer increases your utility a lot. If you have a lot of integrity, a little bit more is still worth an equal amount. Once you start putting values like that out there it, I think, threatens the idea that it's all reducible to a single index, right? Because you can't. Spitzer's integrity is blown it's not like there's some--it's a binary good. People either think he's either a hypocrite or he's not, it' a binary thing. So there might be some goods like integrity that are not easily capture-able in this logic. We should put that out there, but yeah, over here? Student: What about health? It's not quite binary because you can be in medium health, but I think it would be pretty useful to be healthy and then super healthy. some people are sighted and some people are blind and you could do eye transplants. Arguably the blind person would gain more utility from getting one eye than the sighted person would lose from losing one eye, so shouldn't we do that? So that can also give you some ways of proceeding that would make you queasy, right, if you allow the principle of diminishing marginal utility. What about the examples I threw out there, beer and aspirins? They're a bit like the sort of left shoe examples, right? Every serious economist since the eighteenth century has assumed that the principle of diminishing marginal utility is true, including Jeremy Bentham. So it's the best assumption you can make given that you've got to assume something. But now, and now I want to come back to the sophisticated point that was made in the middle at the back there a few minutes ago, when you talked about the fungibility of utility and its expressibility in terms of money. Other good that would give you increasing utility at a diminishing marginal rate. start to think about the utility that people at the bottom of the social order derive from a particular good, versus the utility of those at the top. Let's suppose a two-person society, again, and let's suppose it consists of Donald Trump and a homeless woman living out of a left luggage locker in Grand Central Station. And the question is, should we take a dollar from Trump and give it to the bag lady? What? Should we? Yes? No? How many think yes? Okay, yeah, almost everybody. of diminishing marginal utility we take the dollar from Trump up there, his loss of utility is negligible, but we give it to the woman who's starving down here, and her gain in utility is enormous from that dollar, right? So we should take thedollar from Trump. Let's assume there's no dead weight loss to the government and all of that for right now. We will just keep it simple. We should take that dollar from Donald Trump and we should give it. to the bag lady, and the greatest happiness of the greatest number will have increased. Professor Ian Shapiro: We're going to keep redistributing until they have the same amount. Bentham was a fairly radical guy. He was a supporter of democracy, which was a radical thing at that time. But he wasn't as egalitarian as he thought he was, Professor Shapiro says. Professor Shapiro: Bentham completely saw that this was an implication of his doctrine. The underlying logic says take it from Trump and give it to the bag lady, right? At the margin that's what you should do. as all that, and he wanted to temper the downward redistribution that flows from his principle, and so he makes a distinction between what he refers to as "absolute" and "practical" equality. He says, Suppose but a commencement made, by the power of a government of any kind, in the design of establishing it (absolute equality, that's redistributing to equality), the effect would be--that, instead of every one's having an equal share in the sum of the objects of general desire, no one would have any share of it at all. sticker, he's saying the rich will burn their crops before giving them to the poor. It's the sort of reverse of trickle-down, right? Trickle-down is the notion that you allow inequality because the rich create more wealth for everybody. This is the inverse claim. Bentham's saying, "Well yes, in principle absolute equality would maximize the greatest happiness of the greatest number, but in fact if a government set out to do that, the rich would rebel" you assume diminishing marginal utility, utilitarianism becomes a very radical doctrine. Bentham has this monomaniacal view of science. He's got his objective egoism. He can figure it all out, what will maximize social utility, and run around the world writing constitutions for people. But he can devise a whole public policy that's going to scientifically maximize the utility of society, but I'm not seeing a whole lot of room for rights in this doctrine. It seems to allow ethnic cleansing, even genocide. because it's where you start to see our old friend the workmanship ideal creeping by the backdoor into utilitarianism. Bentham says, "Law does not say to man, Work and I will reward you but it says: Labour, and by stopping the hand that would take them from you, I will ensure you the fruits of your labour" So another way of thinking about this is, that Bentham's idea of the state is essentially regulatory. It stays the hand of somebody else who would steal your goods, but the government cannot itself create utility. Bentham's utilitarianism comes into utilitarianism by the backdoor. He says, "Unless you respect individual rights you're not going to be able to maximize utility for the society as a whole" So that's the way in which we see that even a classical utilitarian like Bentham is going to resist dispensing with the doctrine of individual rights. But there's a problem, though, with his mode of doing this, and the problem arises because the claim is that the state is hands-off with respect to the utility creation in the society. that the rich will burn their crops before giving them to the poor might not be true. And even if we get to less extreme circumstances like South Africa before and after the transition, when we look at actual debates in contemporary politics in the United States, this is what we see. Ronald Reagan comes in and says, "If we cut taxes, the pie will get bigger for all and they'll be actually more revenue," and so utilitarianism says do it. And the Democrats say, "No, they won't," and it's an empirical argument. responsible for what happened, versus how much many other things that happened were responsible, nobody really knows. And so a lot of the problem in debating incentives, once you get into the real world of macroeconomic policy-making, is that (a) you never have the counterfactual; you can't go and rerun history without the stimulus, right, or without the Reagan tax cuts. And (b) the sheer complexity; so many other thing happened--the price of the stimulus. oil goes up, or commodities collapse, or the dollar, or this, or that. Do or don't change the value of their currency. So that when it gets down to it, you're never going to get a definitive answer to the question what is the point of practical equality. Are we close to it? Have we gone by it? Are we nowhere near it? There have been periods in our history when we've had top marginal tax rates of 90 percent, right? Reagan thought a topmarginal tax rate of 40 percent was beyond the point. Hobbes said, "For the things we don't make, we can only guess about the causes" We don't really know and there will be--the people who want either policy will be able to find a plausible set of experts to defend their view. So you're getting to this very messy world of macroeconomic prediction, if you want to put some limits on the radical edge of classical utilitarianism. As a matter of history, how it went was to rethink the analytical structure of utilitarianism in a way that completely defanged its radical redistributive edge. classical to what we're going to all neoclassical utilitarianism is a subject with which I will begin on Wednesday. See you then for the next installment of this week's Daily Discussion, which will focus on the role of utilitarianism in the development of the modern world. Back to Mail Online home. back to the page you came from. Click here to read the first installment of the Daily Discussion. Follow us on Twitter @CNNOpinion and @jennifer_newton.

ROUGE-1: 60.82, ROUGE-2: 57.00, ROUGE-L: 54.51
BERTScore: 71.22

==============================================
==================== [31/100] ====================
Summary:
Professor: I'm going to briefly wrap up the lecture we were doing on Friday because there were a couple of things that I wanted to make a note of. Now, in the last class, I introduced you to the lipidic molecules, and you can pick them out of a lineup because they are rich in carbon-carbon and carbon-hydrogen bonds. They are molecules that are mostly hydrophobic, which can also be referred to as lipophilic. You either-- you can hate water and love fatty acid or you can love it and hate it. fatty types of materials, so those both terms are synonymous. And some of the lipids are what are known as amphipathic, and they include hydrophobic and hydrophilic components. There are a couple of tiny terms that I didn't mention explicitly, so I just want to go ahead and do that now. For example, in this phospholipid structure-- and we'll talk about these-- they have long chain fatty acids attached via esters to this glycerol unit, so there's one here and the second one here. bonds take on a particular shape because there's not freedom of rotation around double bonds the same way there is around single bonds. And so double bonds, we refer to them as either trans, where the two groups are on opposite sides, leaving the double bond, or cis. We tend to use that cis and trans sort of naming system in a lot of other contexts as well, but you almost always want to remember that trans is as far away as possible, cis is closer than trans. All right, so I'm just going to take you forward to the phospholipid structure. supramolecular association of phospholipid monomer units. Here's a monomer unit up here. You see it has an amphipathic structure, with a lot of hydrophobicity but also hydrophilicity. These molecules assemble into supramolecules that form the boundaries of your cells. Saying they are semi-permeable tells us a little bit about what can go through them. If they were fully permeable, anything could come and go and they wouldn't be much use frankly. polar head group is interacting with water on both sides. A lot of cells, especially eukaryotic cells, have a lot of endomembranes, membranes within the cells. For example, forming the boundary to the nucleus or to the mitochondria. So what do you think this one might be, folks? Unsaturated. And what's the double-bond geometry? AUDIENCE: Cis. PROFESSOR: Yeah, it is. It's like a-- it looks like a ballerina or something. other small hydrophobic molecules can pass readily in and out through the semi-permeable barrier, but other things, things that are charged, things That are big, need a different mechanism to get in andout. And we will see later on how proteins provide the opportunities to cargo things into cells or out of cells, even very large entities. There are certain mechanisms whereby that happens through a semi- permeable membrane, OK? I want to show you the other feature of membranes. They are self-healing. What this means is if you poke them, you poke a hole in a cellular membrane. is a really cool video of someone doing micro-injection into eukaryotic cells. You can drop something into the cell, and then the cell closes and maintains its integrity of the barrier. So this is a very cool observation. People do this. They have to not drink too much coffee because it's quite complicated to do a lot of micro- injection, because you can really cause carnage in your cell population if you're not very dexterous. So I just want to ask a couple of questions before, give you a couple more things to think about before we close up. components, and just one of the phospholipids is highlighted, and that would be this molecular structure here. So first of all, what do you think the non-covalent forces at that membrane interface may be? What are the types of interactions that you might have there? Give you a minute to think about it, and I want to show you that I'm actually giving you a clue here, because you can see the structure, negative charge, positive charge. Anyone want to tell me what the answer is, and why? Water is a good hydrogen bond donor and acceptor, so there will be hydrogen bonding. Salts are going to need ways to get in and out. Small proteins are too big to dissolve in that membrane through passive mechanisms. We're going to have to figure out how to get proteins in and in of cells. It's electrostatic amongst the head groups, hydrogen bonding between all that sort of dense bunch of charge, and the water. And then the other question, what type of molecules can get across? I've already answered that question. It just can't get through without a transporter of some kind, and it's actually proteins that end up doing the heavy lifting of the transport processes that we'll see. OK, so moving along. This section will be about the building blocks of your protein macromolecules, which I want to remind you comprise 50% of all of the macromoles. Now, the amino acid building locks-- blocks look pretty simple. They're called amino acids because they have an amine, the carboxylic acid. lonely amino acid in aqueous solution, it's in a different charged form, just consistent with what we talked about in the last class. So this is glycine. It's one of the 20 encoded amino acids. That means the amino acids that are made through ribosomal biosynthesis through a code that's provided by the messenger RNA. Later on, you'll see all of the beautiful mechanics of those processes. You'll have a table that shows them, but you do not have to remember them. on that table, I won't necessarily give you the information on what their properties are, because those are things that you should be able to spot by looking at their chemical structures, all right? So that's important. So these are all line-angled drawings, so you see the carbon. The hydrogens aren't shown in there. The charges are shown for what's called the side chain, because most of the amino acids have a side chain. The amino acids are also chiral, but you'll learn more than you ever wanted to know about chirality in 512. on the previous slide, is not an alpha amino acid, actually it's, a gamma amino acid. Alanine has a methyl group, for example, where I've shown the R, that would be alanine. And they get increasingly big. They're quite large. Some of them have quite extended size chains. Other ones have side chains with rings with double bonds in them. Those are what we would designate in organic chemistry as aromatic. They show different properties to this other set of amino acids. that ring system, but also hydrogen bonding with the OH on the tyrosine, so some of the amino acids can do a few different things. The next set of amino acids are those that are polar and charged, and I've shown you the most common state of all of those amino acids. And then finally, there are amino acids with polar uncharged side chains, such as those shown here. Now, this doesn't look like a very exciting set of building blocks. How can life be different? run on things made of 20 relatively simple building blocks with functional groups? And it's that the building blocks are not functional themselves. It is the polymers that are made up of amino acids, and I'll always call them AAs because it's easier for me. And all the functions of proteins are dictated by the order of the amino acids. So once again, remember a couple of things that we will always give you this table to think about. Ooh, come back. There are Glycine is the simplest amino acid with no elaborate side chain. Proline is a little odd because its side chain is kind of in a cyclic structure. collagen's structure is totally dependent on the involvement of proline in the sequence of the amino acids that make up collagen. And then the last sorts of unusual amino acid is cysteine. It has a thiol, and the one clever thing about Cysteine-- I'm just going to put a bit of a peptide here. at a different oxidation state where the two sulfurs are joined to each other. Amino acids are assembled in a unique linear polymer of defined order, and we designate that defined sequence the primary sequence. And proteins can be 1,000 amino acids, 1,500, 100 amino acids. They can be various lengths where they, you know, we would like them to be, but that just sort of sets cysteine apart a little bit for its properties, all right? OK, so coming down the side here. generally consider the smallest protein to be about 400 amino acids, and you might go up to thousands of amino acids. When the proteins are smaller, they are not capable of adopting too much ordered structure, and we mostly call them peptides. So the primary sequence will define the structure of a protein. And that primary sequence is kind of a cool thing because it's very specific. It defines-- it's got encoded into its structure, the three-dimensional fold of the protein, OK? All the information for the folded, compact, globular structure that's functional is encoded in that primary sequence. It's a cryptic code. We may not be able to tell by looking at it what it really looks like, but all the information is there in order to program the folding. So the primary sequence determines the fold, and it's the fold of the protein that mandates its function. And I think it's absolutely amazing that with a relatively limited set of building blocks, we can define so many different functions of all the proteins in our body. limited set of building blocks, OK? Now, let's now talk about peptides because one gets a little frustrated looking at single amino acids. They don't tell us so much about the peptidic structure. When nature bonds all these amino acids together, it carries out a condensation reaction to form a peptide bond between these two components of the amino acid, the amine and the carboxylic acid. And now I'm going to draw two amino acids, and then I'mgoing to tell you one important thing. R1, R2. OK, so this is a dipeptide, two amino acids, and there are some characteristics I want you to remember. When we write out peptides, we always write them N to C. So in that peptide, this would be the carboxyl terminus, and thisWould be the amino terminus. If you don't always remember to write things in this order, and you tell your friend, oh, go and get this peptide made, andyou put it down in the wrong order, they'll make the wrong peptide. The amide, or peptide bond, is unique in that there's restricted rotation about that bond. So it's as if you've got a linear polymer, but every third bond has kind of stuck in a particular orientation, which starts to define a lot of details about protein tertiary structure. It's like spaghetti with little bits that haven't been cooked. They're stiffer than the rest of the sequence. And the other really important thing about the peptide structure is that embedded within that structure, there is the amide. functional group where, remember, this can be a hydrogen bond acceptor, and this can being a hydrogen Bond donor. Once you know that, the next few slides will make a lot of sense as we talk about higher-order structure of proteins. When I condense three amino acids, I spit out two molecules of water, and I put in place two amide or peptide bonds. If I go down this backbone, every third bond is going to be fixed, fairly fixed. There's not freedom of rotation around it. Chemists have for years tried to understand how we could predict the folded structure from the primary sequence. It's not simple because what you're doing is you're solving a massive energy diagram, where as you fold a structure up, you're trying to maximize all those non-covalent forces for maximum thermodynamic stability. There are a lot of ab initio and molecular dynamics programs that are now starting to be able to fold proteins into fairly reliable structures, but they don't always get them right because they haven't gotten all the clues yet. mistakes, and I felt this one was particularly pertinent. So a bunch of guys lugging around in a lab and says, well, we finished the genome map, now we just have to figure out how to fold it. What is wrong with that cartoon? What fold? Yeah? AUDIENCE: You want to [INAUDIBLE].. PROFESSOR: Yeah. It's double helical, duplex DNA or something. You're actually folding proteins, so the cartoon is not quite right, but it's sort of kind of cute. figure out what the one-letter code spells there. Just take out your table with all the amino acids and you'll be able to see what that very large peptide spells. All right, I don't want you working it out while you're here. You've got to listen to me for the time being. OK, so the first order, we get it, there's a primary sequence. The next thing to think about is what's known as secondary structure. It's a higher order than just the primary sequence, and it's established by non-covalent bonds. continuous linear sequence. That's what we would call the peptide backbone, and the secondary structure is put in place by hydrogen bonding between components of the backbone. And there are a couple of major forms of secondary structure. What I'm showing you here is what's known as the alpha helix. It's a continuous strand of peptide, but there are hydrogen bonds between COs and NHs all the way through the backbone, such that this strand can fold up into a cylindrical, helical structure. showing it in detail, they might show it as a cylinder, so you might need to pick that out of a structure. All right, so we've seen primary. Secondary is just with backbone. And things start to get much more interesting when we get to tertiary structure. Tertiary structure is enabled by all these other interactions, electrostatic, hydrogen bonding, hydrophobic forces, that can be put to use. OK, so this is like taking your very extended stored of polymer, knowing there are different kinks in it, because of the backbone bonds, but folding it up in a structure that maximizes the opportunity. in place due to the side chains of amino acids interacting with each other or with the backbone structures. So look here, that's a very small motif. And what I'm going to call your attention to is when you fold up these motifs, when the secondary structure is in place, a lot of side chains are near each other, and they can engage in long-distance contacts. But what I want to do is take a look at this and see, can you put any of those potential interactions on the drawing that's on your handout? It's pretty pretty. obvious where there's an electrostatic interaction, right? Boop. OK, between plus-- get those out of the way, those are the easy ones. interactions between hydrophobic groups, where they want to amass that lipophilic structure, so it's not exposed as much to water, so they cluster, so those are easy. And then you can start thinking about what are all of hydrogen bonds you could draw. Here I've shown one between side chains, between side Chains and backbone, betweenside chains and water. Those may all contribute to the ultimate thermodynamic stability. A video of a protein that holds reversibly under appropriate conditions. This is a simulation. It's not looking at anything by spectroscopy or in solution or anything like that. And what I'm going to do is just show you for a few seconds, you know, this thing's like trying to find its thermodynamic minimum, and it's actually failing pretty badly. And it does that for about 30-- 60 seconds of the simulations, so I made a point to myself to take this video. you to about minute one, where things start to get fairly interesting. You see that nascent helix, in the background, the red and the blue, is starting to form strands that are a little bit aligned. At a certain point in the simulation, five of the hydrophobic groups are in a little pea. That's a breakpoint in the folding process, because that gets everything glued together better, so that the rest of it can start to really find its final place in the folded structure. downhill to get all the remaining interactions in place to fold the protein, OK? So protein folding is a puzzle that can be solved computationally by maximizing thermodynamic interactions. That's going to get difficult the larger the protein gets, but for small proteins, those simulations really start to make sense. All right, so let's just move on here. What did you think of the simulation? It's kind of cool, right? So you can find the link in the sidebar. So just pop these back on now, and that's the folded structure. is the green fluorescent protein, which is a cylindrical structure made up of anti-parallel beta sheets. When you sort of rotate it, you can see all those sheets, but then it does this little sort of curtsy to the audience, and you can look down into the barrel. And then in some cases, proteins may be a mixture of a secondary structure elements. Here it's a little hard to tell. This is triose phosphate isomerase, but if you look down it,you can see the helices, and there's also a group of beta strands that are held together. I'll show you. But wherever I show you a structure, I'm trying to show you the Protein Data Bank code, and in the web site, you can see there is a free download of PyMOL, which is the program I used to create all these structures and movies. And believe me, it took me about three years to learn how to use it properly. It'll probably take you about a week or maybe a couple of days. So if I can learn it,You can certainly learn it. Proteins are condensation polymers of amino acids. Each protein sequence is defined by covalent bonding. Most of them that are not have quite quaternary structure are folded through secondary and tertiary interactions, these things that we already talked about. And subunits may also come together through quaternARY structure. We'll see a little bit more about this when I talk about hemoglobin in the next class, because the features of the quaternaries structure are very, very important for the proper transport of oxygen. Collagen is the most abundant protein in the human body. It plays enormous roles. Collagens provide a mechanical stability to lots of essential components of complex organisms. There are many different types of collagens that are found in different parts of the body. In the next class, we'll talk about transporters and enzymes, and as we move on to signaling, things like receptors and membrane proteins and so on. The next class will focus on proteins that provide mechanical support for tissues. A single amino acid change in the primary sequence of collagen can destabilize the structure, so it is no longer viable. The disease type I'm going to talk to you about is a set of diseases known as collagenopathies, and the particular one is called osteogenesis imperfecta. A lot of babies with this defect can't even be born through the birth canal because it would crush the bones, and many of them don't survive very long at all. Some survive with different kinds of cases, but their lives are greatly impacted. extended, and I show you three strands in this polymeric structure, a yellow, a red, and a green. And these rolled together into a three helix bundle that has a fibrillous structure, and then all these structures come together to make the macromolecular structure that is collagen. And there are many genetic defects of collagen, and what's so important to think about is if you have a defect in one strand that defect will propagate through every single strand. independent strands, and there's a set of magenta residues in the middle, which come from a defect in the sequence where a glycine has been changed to an alanine. That defect is caused by the change of a hydrogen to a methyl group on three residues that come together, and that bulges out that fibrillous structure. So if you look at it, you can even see that helix gets bulged out and it's not as compact and beautiful as it should be. well-aligned as the rest of the structure. And then that defect gets propagated into all the fibrils and results in the weakening of the bones. Either the collagen fails to form properly, or the collagen, when it forms, it has much less mechanical stability. So I think that's a good place to stop and I'll pick up next time with hemoglobin. There's a great link on the website to the Protein Data Bank to see how enzymes work. These slides are posted with these reading assignments, and they're posted in color if you want to look at them again.

ROUGE-1: 65.12, ROUGE-2: 62.95, ROUGE-L: 61.63
BERTScore: 75.30

==============================================
==================== [32/100] ====================
Summary:
The lecture is provided under a Creative Commons License. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT Open CourseWare at ocw.mit.edu. The lecture was presented by Professor John L. Houghton, PhD, of MIT's Department of Computer Science and Engineering. For more information about MIT's OpenCourse Ware, visit opencourseware.org or call 1-800-847-8255. . Without using the representation in terms of. derivatives, with respect to a coordinate, without using the representations, in. terms of translations and rotations along the sphere, right? When we just used the commutation relations, and nothing else, what we found was that the states corresponding to these guys, came in a tower. And we quickly deduced that it is impossible to represent the half integer states with a wave function which represents a probability distribution on a sphere. We observed that that was impossible. to the very first lecture, and so, we'll do this in more detail, but I'm going to quickly tell you-- imagine take a magnet, a little, tiny bar magnet. In fact, well, imagine you take a little bar magnet with some little magnetization, and you send it through a region that has a gradient for magnetic field. If there's a gradient-- so you know that a magnet wants to anti-align with the nearby magnet, north-south wants to go to south-north. So, you can't put a force on the magnet, but if you have a gradient of a magnetic field, then one end a dipole-- one end of your magnet-- can feel a stronger effective torque then the other guy. And you can get a net force. that you've got some large B, here, and some smaller B,Here, then you can get a force. And that force is going to be proportional to how big your magnet is. But it's also going toBe proportional to the magnetic field. And if the force is proportional to. the strength of your magnet, then how far-- if you send this magnet through a region, it'll get deflected in. one direction or the other. How far it gets deflected is determined by how big of a magnet you sent through. sphere-- this is a better model-- imagine you have a sphere of uniform charge distribution. And you make it rotate, and that's charged, that's moving, forming a current. And that current generates a magnetic field along the axis of rotation, right? Right hand rule. And how big is the magnetic moment, it's proportional to the rotation, to the angular momentum, OK? So, you determine that, for a charged sphere here which is rotating with angular momentum,. let's say, l, has a magnetic moment which is proportional to l. can measure that angular momentum by measuring the deflection. The bigger the angular momentum, the bigger the magnetic moment. If the electron weren't rotating, it would just go straight through, right? It would have no angular momentum. And thus it would not reflect. If it's rotating, It's gonna deflect. Here's the experiment we do. And here's the experimental results. The experimental results are every electron that gets sent through bends. And it either bends up a fixed amount, or it bends down. Stern Gerlach Experiment: angular momentum can only take one of two values. The angular momentum is just some geometric constant times the angular momentum. L equals 1/2, plus some constant and, you know, plus h bar upon 2, or minus h bar on 2. But what this tells us is, which state? Which tower? Which set of states describe an electron in this apparatus? And you just do this measurement. But wait, we started off by talking about the rotation of a charged sphere. deducing that the magnetic moment must be proportional to the angular momentum. And what we've just discovered is that this angular momentum-- the only sensible angular momentum, here-- is the two state tower, which can't be represented in terms of rotations on a sphere. If it did, we'd get this nonsensical thing of the wave function identically vanishes. So, there's some other form of angular momentum -- a totally different form ofangular momentum-- at least for electrons. Which, again, has the magnetic moments proportional to this angular moment with some coefficient. call mu0. But I don't want to call it L, because L we usually use for rotational angular momentum. This is a different form of angular momentum, which is purely half integer, and we call that spin. And the spin satisfies exactly the same commutation relations-- it's a vector. Sx with Sy is equal to ih bar Sz. So, it's like an angular momentum in every possible way, except it cannot be represented. It is not related to a rotation. An electron just has it. The legacy of these little L equals 1/2 states is that they represent an internal form of angular momentum that only exists quantum mechanically, that you would have never noticed classically. And so there are plenty of particles in the real world that have L equals 3/2. They're not fundamental particles, as far as we know. There are all sorts of nuclei that carry spin 3/1, but we don't know that. And this is how we describe that experimental fact. know of a fundamental particle. If super symmetry is true, then there must be a particle called a gravitino, which would be fundamental, and would have spin 3/2, and four states, but that hasn't been observed, yet. We'll talk about that a little more when we talk about hydrogen, but it was observed and deduced from experiment before it was understood that there was such a physical quantity. However, the observation that this commutation relation led to towers of states with this pre-existed as a quantity. mathematical statement. So, that was a mathematical observation from long previously, and it has a beautiful algebraic story, and all sort of nice things, but it hadn't been connected to the physics. And so, the observation that the electron must carry some intrinsic form of angular momentum with one of two values, neither of which is 0, was actually an experimental observation-- quasi-experimental observation-- long before it was understood exactly how to connect this stuff. The intent of the experiment wasn't to solve-- that fixed the fact that I was probing Lz is that I made the magnetic field have a gradient in the Z direction. So, what I was sensitive to, since the force is actually proportionally to mu dot B-- or, really, mu dot the gradient of B, so, we'll do this in more detail later-- the direction of the gradient selects out which component of the angular momentum we're looking at. But, the universe is rotationally invariant, so it can't possibly matter whether I had done the experiment in this direction or that direction. momentum of the electron along that direction, I will discover that it takes one of two values. This is also true of the L equals 1 states. Is is every system in a state corresponding to one of those particular values? No, it could be in a superposition. But the eigenvalues, are these three eigen Values, regardless of whether it's Lx, or Ly, or Lz. OK, it's a good thing to meditate upon. Anything else? One more. we're gonna talk about real, physical systems in three dimensions. And as we'll discover, it's basically the same as in one dimension, we just have to write down more symbols. But the content is all the same. So, this will make obvious the reason we worked with 1D up until now, which is that there's not a heck of a lot more to be gained for the basic principles, but it's a lot of more knowing to write the expressions. And that is a beautiful abuse of notation-- in spherical coordinates. 1 over r squared, times the angular momentum squared with a minus 1 over h bar squared. So, in just to check, remember that Lz is equal to h bar upon i d phi. And you can see that that's one contribution to this beast. But, actually, let me-- I'm gonna commit a capital sin and erase what I just wrote, because I don't want it to distract you. OK? So, with that useful observation, I want to think about central potentials. The energy for this is p squared upon 2m, plus a potential, which is a function only of the radial distance. So, the energy is equal to, from the first term, minus h bar squared times r dr squared r. And then from this term, plus minus hbar squared times minus 1 over h bar squares [? to L squared ?] [? over ?] r squared, plus L squared over r squared. And along the way, we'll solve a toy model for hydrogen. can be written in a nice form. This is minus h bar squared, 1 upon r dr squared r-- whoops, sorry-- upon 2m. OK, and this is the energy operator when the system is rotational invariant in spherical coordinates. Questions? Yeah? AUDIENCE: [INAUDIBLE] is that an equals sign or minus? PROFESSOR: This is just quick algebra. So, it's useful to know it. Why would you ever care about such a thing? Well, let's square it. guys cancel, right? 1 over r times dr. So, this is equal to 1 over R dr squared r. But, why is this equal to dr squared plus 2 over R times dr? And the answer is, they're operators. And so, you should ask how they act on functions. Let's see that in just a minute. And then there's a term were two d's hit the r, but if two ds hit the R, that's 0. over r? PROFESSOR: Oh shoot! Yes, that's supposed to be one of our-- Thank you. Yes, thank you for that typo correction. Thanks OK. So, anytime we have a system which is rotationally. invariant, we can write the energy operator in this fashion. And now, you see something really lovely, which is that this only depends on r, this only. depends on the angular coordinates, but only insofar as it depends on L squared. phi E is equal to E phi E, it's going to simplify our lives if we also let phi be an eigenfunction of the L squared. Quick, is little l an integer or a half integer? AUDIENCE: [MURMURS] Integer. PROFESSOR: Yeah, because we're working with rotational angular momentum, right? And it only makes sense to talk about integer values of little l when we have gradients on a sphere. L squared acting on yLm gives us h bar squared lL plus 1. E, acting on phi E, takes a particularly simple form. If phi is proportional to a spherical harmonic, then this is gonna take the form minus hbar squared upon 2m 1 over r dr squared r plus 1 over 2mr squared l squared. Question? AUDIENCE: Yeah. Can we consider superpositions of yLM1 and yLlm2? PROFESSOR: Absolutely. these guys? Absolutely, we can. However, we're using separation. We're gonna look at a single term, and then after constructing solutions with a single eigenfunction of L squared. We can then write down arbitrary superposition of them, and generate a complete basis of states. General statement about separation of variables. OK. So, here's the resulting energy eigenvalue equation. This is purely a function of r. We've removed all of the angular dependence by making this proportional to yLm. The potential, V effective of r, does the following two things-- whoops, don't want to draw it that way-- suppose we have a potential which is the Coulomb potential. So, let's say, u is equal to minus E squared upon r. V has another term, which is h bar squared lL plus 1 over r V on u. And this is exactly the energy eigenvalue equation for a 1D problem with the following potential. The potential gets really large as you get to the origin. The professor asks the audience to guess what a potential looks like. He says it's a constant over r squared, with a plus sign. Can r be negative? No. It's defined from 0 to infinity. So, that's like having an infinite potential for negative r. The professor then asks the crowd to guess the effective potential of a value of l. The audience's guess is 1 over L squared-- or sorry, 1 over 2mr squared. The Professor: "This is my Ll plus 1 [INAUDIBLE] squared over 2MR squared" lL 1 over 2mr squared. In text, when I write this by hand, the potential is a big U, and the wave function is a little u. So, this is my little u and so, now I'm gonna have to-- oh jeez, this was horrible, sorry-- this is the potential, capital U with a bar underneath it. And here's V, which is gonna make my life easier. OK, is everyone happy with that? Yeah?. AUDIENCE: [INAUDIBLE]. PROFESSOR: Which one? AUDIENCE: Middle. Middle.PROFESSor: Up, up. Right there! Up! There. AUDience: [CHATTER] There! PROFessor: Excellent, so the thing that isn't here, would have a bar under it. Ah! You wouldn't think it would be so hard. OK, god, oh! That's horrible! Sorry guys, that notation is not obvious. My apologies. potential capital U, let's just call this V. AUDIENCE: [LAUGHTER] No! PROFESSOR: And then we have V effective. No, no. This is good. We can be careful about this. So, this is V effective, which has V plus the angular momentum term. Oh, good Lord! This is Veffective. V phi [INAUDIBLE] U. Good, this are V. There's no U underline, it's now just V. God! OK. Let's check our sanity, and walk through the logic. So, the logic here is, we have some potential, it's a function only of r, yeah? As a consequence, since it doesn't care about the angles, we can write things in terms of the spherical harmonics. Here's the energy eigenvalue equation. We discover that because we're working in spherical. harmonics, the angular momentum term becomes just a function of. r, with no other coefficients. And now we have to ask, what exactly is the effective potential? if it's 1 over r. So, we get an effective potential-- that I'll check-- there's the effective potential. And finally, the third fact is that r must be strictly positive, so as a 1D problem, that means it can't be negative, it's gotta have an infinite potential on the left. As an example, let's go ahead and think more carefully about specifically this problem, about this Coulomb potential, and this 1D effective potential, for example. by multiplying the whole equation by r. If you see this, declare in your mind a brief moment of triumph, because you know what technique to use. You can do this sort of rescaling by a power of r. And more generally, if you have a differential equation that looks like. a derivative with respect to r plus a constant over r times phi, you know how to solve this. OK? Very useful things to have in your back pocket for moments of need. So, let's pick up with this guy. name for this. This term that comes from the angular momentum [? bit, ?] this originally came from the kinetic energy, right? It came. from the L squared over r, which was from the gradient squared energy. Why is there a kinetic energy term? Well, what this is telling you is that if you have some angular momentum-- if little l is not equal to 0--- then as you get closer and closer to the origin, the potential energy is getting very, very large. Professor: angular momentum barrier is just an expression of that. It's just saying that as you come to smaller and smaller radius, holding the angular momentum fixed, your velocity-- your angular velocity-- must increase. The reason is that the electron can radiate away energy and angular momentum, and so l will decrease and decrease, and can still fall down. So, we still need a reason for why the hydrogen system, quantum mechanically, is stable. [? Why do ?] [? things exist? ?] The wave function, phi sub E, which goes near r equals 0, like u of r over r. So, what should be true of u? Can u diverge? Is that physical? Does u have to vanish? Can it take a constant value? So, I've given you a hint by telling you that I want to think about there being an infinite potential, but why? Why is that the right thing to do? Well, imagine U of r went to a constantvalue near the origin. That's maybe not so bad. let's look back at the kinetic energy. The energy is going to go like, p squared over 2md squared. But here's an important fact, d squared-- the Laplacian-- of 1 over r, well, it's easy to see what this is at a general point. As you approach the origin from any direction, the function is going like 1 overr, OK, so it's 1 over 1. But can that possibly be true at r equals 0? No, because what's the second derivative at 0? growing, but it's growing in every direction. So, what's its first derivative at the origin? It's actually ill-defined, because it depends on the direction you come in. The second derivative has to go as you go across this point, it's telling you how the first derivative changes. But it changes from plus infinity in this direction, to plus infinityin this direction. That's badly singular. And, in fact, d squared on 1 over r-- and this is a very good exercise for recitation-- is equal to delta of r. exactly the way you need to get the delta function. OK, which is pretty awesome. So, what that tells us is that if we have a wave function that goes like 1 over r, then the energy contribution-- energy acting on this wave function-- gives us a delta function at the origin. If we calculate the energy, we'll discover that the energy is badly divergent. It does become divergent if we don't have u going to 0. That's about the derivative of u, as you approach the origin from Lucatau's Rule. would've got the same equation. And that means that the energy eigenvalue can depend on l, but it can't depend on m, right? So, that means for each m in the allowed possible values, l, l minus 1, [? i ?] minus l-- and this is 2l plus 1 possible values-- for each of these m's, the energy is the same. And so, here we have a degeneracy. And this degeneracy isn't fixed by rotational invariance. of E and Lz. Can I also find a common eigenbasis of ELz and Ly? Are there common eigenevectors of ELZ and Ly?" Professors: No. Audience: No, because they don't commute, right? E commutes with each of these. So, this tells you that if you have an eigenfunctions of E, and you act with a raising operator, you act on E with Lx plus iLy and Lx minus iLy. get another eigenfunction of E. And thus, we get our 2L plus 1 degeneracy, because we can walk up and down the tower using L plus and L minus. And so, this is like the statement that L squared with L plus/minus equals 0. OK, and so this 0 because this is just Lx plus iOi. So, E with Lx is 0, and E with Ly is 0,. So, so E commutes with these guys. some examples. So, the first example is gonna be-- actually, I'm going to skip this spherical well example-- because it's just not that interesting, but it's in the notes, and you really need to look at it. OK, so, the spherical well. Here's r equals 0. And if it's a spherical infinite well, then I'm gonna say, the potential is infinite outside of some distance, l. And it's 0 inside. OK? So, what does this give us? Well, in order to solve the system, we know that the first thing we do is we separate out with yLms, and then we re-scale by 1 over r to get the function of u, and we get this equation. E on u is equal to minus h bar squared upon 2m dr squared and plus v effective-- well, plus [? lL ?] plus 1-- over r squared. And the potential is 0, inside. So, this is not a terrible differential equation. And one can do some good work to solve it, but it's a harder differential equation than I want to spend the time to study. case-- when there's zero angular momentum, little l equals 0. Eu sub 0 is equal to h bar squared upon 2m. This is saying that the energy, a constant, times u is two derivatives times this constant. So, u0 can be written as a cosine of kx-- or sorry-- kr plus b sine ofkr. And I should really call this E sub 0, because I should call this u sub l-- EuSubL. it could depend on little l, here. So, there's our momentary solution, however, we have to satisfy our boundary conditions, which is that it's gotta vanish at the origin. And so, this tells you what the energy is. It's just exactly like when the 1D system. So now, to finally close this off. What does this tell you? Well, it tells you that sine of kr, evaluated at l, must be equal to 0, and kl must be the 0 of sine, must been n pi over-- must beequal to n pi, a multiple of pi. that the eigenfunctions are? And let me do that here. So, therefore, the wave function phi sub E0 of r theta and phi-- oh god, oh jesus, this is so much easier in [INAUDIBLE] so, phi is equal to y0m. But what must m be? 0, because m goes from plus L to minus L, 0. OK, so, we get that our wave function is 1 over r times sine of n pi over Lr. So, this is a very nice more general story for larger L, which I hope you see in the recitation. OK. Questions on the spherical well? The whole point here-- Oh, yeah, go. AUDIENCE: What do [INAUDIBLE] generally [INAudIBLE]? PROFESSOR: That's true. So, let me rephrase the question, and tell me if this is the same question. So,. this is strange. There's nothing special about the origin. do I have a 0 at the origin? Is that the question? AUDIENCE: Yeah. PROFESSOR: It's true. There's nothing special about the origin, except for two things. One is that we're working in a system which has a rotational symmetry. Second, saying that little u has a 0 is not the same as saying that the wave function has a0. So, the physical thing is the probability distribution, which is the [? norm ?] squared. have a 0 at the origin. Does that satisfy? AUDIENCE: Yes. PROFESSOR: So, the origin is special when you have a central potential. That's where the proton is, right? Right, OK. So, there is something special about the origin, and the wave function doesn't vanish there. It may vanish there, but it doesn't necessarily have to. And we'll see that in a minute. Other questions? Yeah? Audience: What again, what's the reasoning for saying that the u of r has to vanish at [? 0 instead of L? ?] Professor: Physics is a process of building models that do a good job of predicting. But they're all wrong. Every single model you ever get from physics is wrong. There are just some that are less stupidly wrong. These are gonna be good models, but they're not exact. So, we're not solving hydrogen. We're gonna solve this idealized Coulomb potential problem. OK? So, so let's solve it. If all those things were true, in that imaginary universe, this would be the salient problem to solve. squared minus e squared over r u is equal to e sub l u. So, there's the equation we want to solve. We've already used separation of variables, and we know that the wave function is this little u times 1 over r times yLm. Also known as p squared l, momentum squared over 2m, 2 times the mass times the length. It's useful to put things in terms of mass, momentum, and lengths, because you can cancel them out. From this, we can build two nice quantities. We can build something with units of a radius. We have the mass, which has units of mass. And from this, it's easy to see that we canBuild a characteristic energy by taking e squared and dividing it by length squared. So, length squared over length, this has Units of length, so this is good. And what's the only other parameter we have? We have to build r0. And I'm going to choose the factors of 2 judiciously. The energy, which I'll call e0, is equal to 2me to the 4th over h bar squared. It doesn't have infinite negative energy. It's got some finite energy. What do you expect to be roughly the ground state energy of this system? AUDIENCE: [MURMURING] PROFESSOR: Yeah. Roughly minus e0.it by this length scale. That's the energy of the system. And so then, the energy, Â is equal to e squared over r0, and we know something about 1D quantum mechanical problems. seems like a pretty good guess. It's the only dimensional sensible thing. Maybe we're off by factors of 2. But, maybe it's minus e0. So, that's a good guess, a first thing, before we do any calculation. And if you actually take mu e to the 4th over h bar squared, this is off by, unfortunately, a factor of 4. This is equal to 4 times the binding energy, which is also called the Rydberg constant. gonna be to deal with this factor of 4, right? Which, I mean, is important, but I just want to emphasize how much you get just from doing dimensional analysis. Immediately upon knowing the rules of quantum mechanics, knowing that this is the equation you should solve, without ever touching that equation, just dimensional analysis gives you this answer. OK? Which is fabulous. So, with that motivation, let's solve this problem. Oh, by the way, what do you think r0 is a good approximation to? Well, it's a length scale. because solving it is a sort of involved undertaking. Most differential equations of some, maybe if you're lucky, it's a special function that people have studied in detail. We first did, we did asymptotic analysis, at infinity and at the origin, to get a nice regular differential equation that didn't have any funny singularities. Then we did a series approximation. OK? Now, do most differential equations have a simple closed form expression? A solution? No, most. most don't have a simple solution like a Gaussian or a power large, or something. Most of them just have some complicated solution. This is one of those miraculous differential equations where we can actually exactly write down the solution by doing the series approximation. So, the first thing when doing dimensional analysis too, let's make everything dimensionless. OK, and it's easy to see what the right thing to do is. Take r and make it dimensionless by pulling out a factor of rho, or of r0. The form of this differential equation is, OK, it's not different in any deep way, but it's a little bit easier. As rho goes to infinity, which terms dominate? Well, this is not terribly important. That term is gonna dominate. If l is equal to 0, then this is the only term that survives, so we'd better make sure that that behaves gracefully. So, this tells us, having done this in analysis, we should write that rho to the l plus 1 times e to the minus root epsilon rho times some remaining remaining terms. function, which I'll call v, little v. Little v of rho, and this, asymptotically, should go to a constant near the origin and something that vanishes slower than an exponential at infinity. So then, we take this and we do our series expansion. V is equal to sum over, sum from j equals 0 to infinity, of a sub j rho to the j. So, this is the resulting differential equation for the little v guy. of the harmonic oscillator equation, and get a series expansion. And the series expansion has a solution, which is a sub j plus 1. So, what that tells us is that for some maximum value of little j, root 2 epsilon times j maximum plus l plus 1 is equal to minus 1. But that gives us a relationship between overall j max, little l, and the energy. And if you go through, what you discover is that the energy isequal to 1 over 4 n squared. Rydberg relation explains why the spectrum of light of hydrogen went like 30 over 4 n squared. So, we've solved for that expansion. But there's a real puzzle here. Purely on very general grounds, we derived earlier that when you have a rotationally invariant potential-- a central potential-- every energy should be degenerate, with degeneracy 2l plus 1. It can depend on l, but it must be independent of m. But here, we have discovered-- first off, we'd fit a. nice bit of experimental data, but we've discovered the energy is, in fact, not just independent of m, but it's independent of l, too. Why? What symmetry is explaining this extra degeneracy? We'll pick that up next time. Back to Mail Online home. back to the page you came from. Click here to read the rest of the article. Back To the pageyou came from, click here to reads the rest. Back into the pageYou can now read the full article on this site.

ROUGE-1: 58.22, ROUGE-2: 55.21, ROUGE-L: 54.02
BERTScore: 68.23

==============================================
==================== [33/100] ====================
Summary:
The 60002 course is the second half of the 600 program. The goal of the course is to improve your skills as a programmer. There is a lot more conceptual, algorithmic material in 60002 than in 600. The course is offered free of charge to students at MIT. For more information about MIT OpenCourseWare, visit ocw.mit.edu. Your support will help MIT Open courseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT Open CourseWare at ocW. The course is really less about programming and more about dipping your toe into the exotic world of data science. The lectures will be-- and maybe I'm speaking euphemistically-- a bit faster paced. The assignments are going to be a bit easier, at least that's what students have reported in the past, because they'll be more focused on the problem to be solved than on the actual programming. Today, for example, we'll talk about Lambda abstraction. Inevitably, some comments about software engineering, how to structure software engineering. The main topic of the course is what I think of as computational models. How do we use computation to understand the world in which we live? What is a model? To me, it's an experimental device that can help us to either understand something that has happened or build a model that explains phenomena we see every day. Hopefully it will go a little bit smoother than in the last problem set in 60001. More emphasis in using packages.your code, more emphasis in use packages. Science is moving out of the wet lab and into the computer. Increasingly, there is an increasing reliance on computation rather than traditional experimentation. We'll talk about three kinds of models-- optimization models, statistical models, and simulation models. An optimization model is a very simple thing. We start with an optimization model and then go on to other types of models, such as statistical models or simulation models, which can be used to predict the future of a given area of science. For example, a climate change model. We can build models that sort of explain how the climate has changed over the millennia. with an objective function that's either to be maximized or minimized. We then often have to layer on top of that objective function a set of constraints, sometimes empty, that we have to obey. So maybe the fastest way to get from New York to Boston is to take a plane, but I only have $100 to spend. So I have the constraints there on the amount of money I can spend. And as we'll see, there's an asymmetry here. We handle these two things differently. The burglar has to solve the optimization problem of stealing the stuff with the most value while obeying the constraint that it all has to fit in the knapsack. So we have an objective function. I'll get the most for this when I fence it. And a constraint, it has tofit in my backpack. And you can guess which of the two of those is the burglar's solution. The burglar is the one who gets the most money from the fence. The thief is the person who gets to fence the most of the stuff. The 0/1 knapsack problem means you either take the object or you don't. You can solve it with what's called a greedy algorithm, and we'll talk much more about this as we go forward. These might be the most valuable items here. So here is in words, written words what I just said orally. There's more stuff than you can carry, and you have to choose which stuff to take and which to leave behind. I should point out that there are two variants of it. is much more complicated because once you make a decision, it will affect the future decisions. Let's look at an example, and I should probably warn you, if you're hungry, this is not going to be a fun lecture. So here is my least favorite because I always want to eat more than I'm supposed to eat. So the point is typically knapsack problems are not physical knapsacks but some conceptual idea. So once I take one thing, it constrains possible solutions. A greedy algorithm, as we'll see, is not guaranteed to give me the best answer. A binary number is going to represent the set of items I choose to take. For item three say, if bit three is zero I'm not taking the item. If bit 3 is one, then I am taking theitem. So it just shows I can now very nicely represent what I've done by a single vector of zeros and ones. Does anyone have any questions about this setup? It's important to get this setup because what we're going to see now depends upon that setting in your head. mathematical representation. We're going to try and find a vector v that maximizes the sum of V sub i times I sub i. I want to get the most valuable V I can get subject to the constraint that if I look at the item's dot weight and multiply it by V, theSum of the weights is no greater than w. So I'm playing the same trick with the values of multiplying each one. So that tells me the value of V. And I'm trying to get a value that maximises the sum. The most obvious solution is brute force. I enumerate all possible combinations of items; that is to say, I generate all subsets of the items that are available. So now I've generated all possible sets of items. I can now go through and sum up the weights and remove all those sets that weigh more than I'm allowed. And then from the remaining combinations, choose any one whose.by zero or one, and that's my constraint. Make sense? All right, so now we have the problem formalized. The power set is if you have 100 Vec.value is the largest. Even for a fast computer generating that many possibilities is going to take a rather long time. We often end up solving optimization problems where n is something closer to 1,000, sometimes even a million. Clearly, brute force isn't going to go as far as we'd like, so it's kind of disappointing. We look at it and say, well, we got a brute force algorithm. It will solve the problem, but it'll take too long. We can't actually do it. There is no algorithm that provides an exact solution to this problem whose worst case running time is not exponential in the number of items. But that should not make you sad because while there's no perfect solution, we're going to look at a couple of really very good solutions that will make this poor woman a happier person. So let's start with the greedy algorithm. It is an exponentially hard problem. There is no really good solution. I shouldn't say we. Am I just being stupid? Is there a better algorithm that would have given us the answer? you about greedy algorithms. We say while the knapsack is not full, put the best available item into the knapack. When it's full, we're done. You do need to ask a question. What does best mean? Is the best item the most valuable? Is it the least expensive in terms of, say, the fewest calories, in my case? Or is it the highest ratio of value to units? Maybe I think a calorie in a glass of beer is worth more than a calories in a bar of chocolate. red there's a parameter called keyfunction. That's going to be-- map the elements of items to numbers. So it will be used to sort the items. So I want to sort them from best to worst, and this function will beused to tell me what I mean by best. So maybe keyfunction will just return the value or maybe it will return the weight. But the idea here is I want. to use one greedy algorithm independently of my definition of best. And then for i in range len of items sub copy-- I'm being good. effect in the parameter. In general, it's not good hygiene to do that. So for-- I'll go through it in order from best to worst. And if the value is less than the maximum cost, if putting it in would keep me under the cost or not over the cost, I put it in. And I just do that until I can't put anything else in. So I might skip a few because I might get to the point where there's only a few calories left. actually works? I hope not because I think it does work. Let's ask the next question. How efficient do we think it is? What is the efficiency of this algorithm? Let's see where the time goes. So I deleted the comment, so we'd have a little more room in the slide. Who wants to make a guess? By the way, this is the question. So please go answer it. We'll see how people do. But we can think about it as well together. See who remembers. so we know that is n log n where n in this case would be the len of items. So we know we have that. Then we have a loop. How many times do we go through this loop? Well, we gothrough the loop n times, once for each item because we do end up looking at every item. So it's pretty efficient. And we can do this for big numbers like a million. Log of a million times a million is not a very big number. we're going to test greedy. I actually think I used 750 in the code, but we can use 800. It doesn't matter. And here's something we haven't seen before. So used greedy by value to allocate and calls testGreedy with food, maxUnits and Food.getValue. Notice it's passing the function. That's why it's not-- no closed parentheses after it. Used greedy to allocate. And then we have something pretty interesting. What's going on with this lambda? Lambda is used to create an anonymous function, anonymous in the sense that it has no name. What Lambda does is it builds a function that evaluates that expression on those parameters and returns the result of evaluating the expression. So instead of writing def, I have inline defined a function. So if we go back to it here, you can see that what I've done is Lambda x one divided by Food.getCost of x. Notice food is food is the total number of calories. the class name here. So I'm taking the function getCost from the class food, and I'm passing it the parameter x, which is going to be what? What's the type of the argument to getCost? We'll go back and we'll look at it. So it has to be of type food because it's self in the class. Oh, Napoli would have caught that. So we do have a tradition in this class that people who answer questions correctly get rewarded with food. Lambda can be really handy as it is here, and it's possible to write amazing, beautiful, complicated lambda expressions. Back in the good old days of 6001 people learned to do that. And then they learned that they shouldn't. My view on lambda expressions is if I can't fit it in a single line, I just go right def and write a function definition because it's easier to debug. But for one-liners, Lambda is great. Let's look at using greedy. TestGreedys.that, and then here is the call of it. It chooses a burger, the pizza, and the wine for a total of-- a value of 284 happiness points, if you will. Well, what we see here is that we use greedy by value to allocate 750 calories. On the other hand, if we say, "Let's try a burger and a pizza," we get 750 calories, and we get 284 points. So let's go look at the code that does this. we use greedy by cost, I get 318 happiness points and a different menu, the apple, the wine, the cola, the beer, and the donut. I've lost the pizza and the burger. And here's another solution with 318, apple, wine-- yeah, all right. So I actually got the same solution, but it just found them in a different order. The problem is that a greedy algorithm makes a sequence of local optimizations, chooses the locally optimal answer at every point. add up to a globally optimal answer. This is often illustrated by showing an example of, say, hill climbing. So you might choose as a greedy algorithm if you can go up, go up. If you can't going up, you stop. So whenever you get a choice, you going up. And so if I start here, I could right in the middle maybe say, all right, it's not up but it'snot down either. So I'll go either left or right. Then I'll just make my way up to the top of the hill, making a locally optimal decision. The problem with greedy algorithms is that you can get stuck at a local optimal point and not get to the best one. Let's say I'm feeling expansive. I don't want to go down. So I'm here and I'm happy. On the other hand, if I had gone here for my first step, then my next step up would take me up, up,. I'd get to here, and I'd stop and say, OK, no way to go but down. I'm done. and I'm going to allow myself 1,000 calories. Well, here what we see is the winner will be greedy by value, happens to find a better answer, 424 instead of 413. So there is no way to know in advance. Sometimes this definition of best might work. Sometimes no definition ofbest will work. You can't get to an optimal solution with a greedy algorithm. On Wednesday, we'll talk about how do you actually guarantee finding an optimal Solution in a better way than brute force.

ROUGE-1: 64.03, ROUGE-2: 59.67, ROUGE-L: 53.16
BERTScore: 64.76

==============================================
==================== [34/100] ====================
Summary:
Expectations play a huge role in economics, says Ricardo Caballero. CaballERO: I want to give you a shortcut to think about the role of expectations in the kind of models we have already discussed. And so I'm going to do all that in the most basic model we have discussed, which is the IS-LM model. And I hope you'll get the gist of what expectations can do in economics. And the main idea is that expectations play a big role in asset pricing. here is that the IS-LM model as we have described it up to now really overweights the present. And in practice, expectations about future conditions play a big role in the decision of all economic actors. We'll look at investors, asset pricing and so on. But it's also true of consumers and firms. And even governments and foreigners, when they invest, do foreign direct investment, they go and invest in a country, it's a lot about expectations of what the country will do in the future. impact on asset prices and so on precisely because they change what people think, for good or for bad, about future conditions. So we want to do things in two steps. The first, I'm going to revisit the consumption function and the investment function, now taking into account expectations. And then I want to embed not the fully fleshed out consumption and investment decisions, but the flavor of the role of the future into the IS-LM model. And by then, you would have seen-- you will have seen all that I wanted to communicate, at least, in this set of lectures. impact on your consumption. People know early in life that they have a lower income than they will have later on. So they will tend to spend and borrow more when they're young. Then, in the middle of their life cycle, before retirement, they panic, and you tend to save more. So you don't consume all you have because you know there are many years ahead of you where income will be lower than your consumption needs. How wealthy you are will pin down more or less the consumption you have more than your current income. expect to inherit or whatever, minus the debts you have. So very much as we discussed in the previous lecture in the context of asset pricing, the expected present discounted value of the cash flows of all the assets you have, that's your financial wealth. And the very rich often have no income, [CHUCKLES] at least labor income. All the income comes from returns on assets. And again, they mostly borrow against that. But in any event, the point there is that what really brings out your consumption is your wealth, not the current flow of income. live out of the income that they get, they couldn't afford what they normally afford. But they spent a lot more than that income because they expect to get a big bonus and things like that. So in principle, your consumption should be something that is not proportional to your disposable income. But in reality, both things really matter, so a more realistic consumption function is something that depends on both things.. Many people have no savings. But it's about 0.03, that kind of thing, OK? People who live hand-to-mouth don't think about smoothing consumption over time. They're consuming whatever income they receive. Most banks are not likely to lend you a lot against your expected present discounted value of labor income. Your income-- you think about how wealthy you'll be, but you also think about your flows, the cash flow you're receiving. That's also part of your considerations. The richer you are, the more this term matters, the less this one matters. like that. So we weren't wrong when we did IS-LM, having the consumption function as increasing in disposable income. But I always told you there is a lot of interesting stuff hidden in that little C0, in the-- in that autonomous component of consumption. Well, that-- lots of interesting things has a lot to do with wealth, OK? And again, this term here is something that captures a many things that are permanent. But it's also the case, in a boom, wages are high. A lot of people tend to spend more. Even so, this captures a lot the temporary component. you're going to consume more for any given level of wealth, OK? It's temporary, but that's what it is. What about investment? That's a decision by the firm. How much physical capital? I'm talking about physical investment, real investment, not financial investment. The decision also depend on current, but particularly on expected profits. And when you think about expected profits, you need to think about interest rate as well. We put the interest rate, as I said, OK, it's more expensive to borrow if the interest rates is high. Investments that give you a return, a quick return, are worth more than things that have a pay-off in the very long run. So the decision, for example, of buying a machine needs to look at the price of the machine right now and then at the expected present discounted value of the cash flows, OK? So let's think a bit more carefully about that decision. So suppose you buy a machine for a price. Let's normalize that price to 1. The first thing you need to know is, well, how long will this machine last. And a reasonable assumption is, for most, the machine will be worth a lot simply because interest rates are very high. machines, is some sort of geometric depreciation-- so meaning, it's not deterministic. It's more or less-- machines break down occasionally, but there is certain probability that they break down. We typically call that notation in economics-- we refer to that as delta. That's the depreciation probability. So if you think in terms of expected value, if you buy a machine today, and you ask, how much of a machine I'll have next year, well, it'll be a weighted average of 0 and 1 probably. you know. I have this machine, and it's likely to give me cash flows over this many years and so on. And then I have to know how much expected profits I expect to get in each of those years. So at the end of the day, when I calculate, I do my little project, and I need to decide whether 1, which was the price of the machine or not, is too expensive or too cheap. So here is an example. This is a machine that gives-- the first expected cash flow comes next year. There is something in the market that I could look at and that I really know. What is that? AUDIENCE: Is it the [INAUDIBLE] RICARDO CABALLERO: Exactly. I could use 1 plus r2. These are one-year rates. R2t squared. So when you have the term structure, when you see all the interest rates, a firm deciding whether to invest or not has the interest rate it needs. It doesn't need to have expectations. The market is doing it for them. In principle, a better investment function-- remember, we wrote an investment function as investment, a function of output, current output, and then the interest rate. It depends on many things, but not only today's, also the ones that you expect for the future, OK? And it depends on the interest rates of the future. If I look at this expression, even if the interest Rate today doesn't change, but I expect the interest Rates to change in the Future, to go up, that will lower the value of my project. when we posted the initial investment function. But here we have that. And sorry, and this is an increasing function of that. The higher is V, the higher is the expected present discounted value of buying a machine given the price, the larger is the investment. Now, this is in principle. In practice, current cash flows also matter a lot, OK? So in the same sense as in the case of the consumption function, we said, in principle, it's only wealth that matters. But in practice, there's lots of consumers that are financially constrained, they're hand-to-mouth and so on. much or is not as optimistic as the firm is and so on. So it may not borrow-- the firm may not be able to borrow as much as it would want given how optimistic that particular firm is on its own project. The bank may say, you know, I'm going to be more conservative here since I'm lending you the money. And one way that firms use, actually, to get around financial constraints is simply by returning their earnings, meaning they generate a cash flow, and they save. firms, especially smaller firms, have deposits and cash flow and so on mostly because, if they get a good opportunity, they may face financial constraints. So if current activity is high, sales are high, firms are going to be less likely to be financially constrained. And that's the reason current profits also end. Now, current profit is an increasing function of output over capital that-- for any given level of capital, if output goes up, that's going to generate more profit. And so we can write our investment function a little bit like we had in the earlier lectures. more realistic model. If you expect profits to remain high for a very long period of time, that machine is going to be worth a lot more than if you only expect the machine to be very profitable for only one year. And the same is true for interest rates. If I expect-- since interest rates are high today, but we expect them to go down in the near future, then that's not going to happen. Anything that is likely to be persistent is also likely to have a much larger impact. affect a lot the discounting of future profits. If interest rates go up today, and I expect them to remain high for a long time, that's going to affect a lot more the present value of profits. And therefore, it'sgoing to depress investment more. In fact, central banks, much more than playing with the current interest rate, they play with your minds. That's what they do. They are always telling you stories for why interest rates will remain high, for why-- [CHUCKLES] time, because otherwise it would be irrelevant. One of the problems they're having now, actually, when the Fed is trying to cool the economy, is that they keep hiking rates, but the loan rates have begun to decline already. And that's a problem for them. They would like you not to believe, bankers not to Believe that will happen. And they're trying to convince firms and households and so on that the interest rate will remain high for a while. Otherwise, you're going to get very little effect out of that. of aggregate demand, aside from the government, which is something that moves, more or less-- OK, with different behavioral functions. But the big drivers are consumption and investment. Those are at least the private sector drivers of aggregate demand. And what we have said now is that human wealth is affected not only by current income, but future after labor income, future real interest rate. That affects human wealth. That's very important in financial wealth. Future nominal interest rate affect the price of bonds. For firms, future after tax profits affect expected present value. in this column here that enters into the consumption and investment decisions that we care about. So remember the basic IS-LM model. We wrote it this way. Output was determined by aggregate demand. And closed economy-- forget all that, fully sticky prices. And we wrote consumption as these functions. So aggregate demand was increasing in output and government expenditure, decreasing in taxes, and decreasing on the interest rate. So a shortcut-- so what I want to do now is give you a shortcut to integrate these views of expectations or the concept of expectations. current taxes, current interest rate, current expenditure, but also function-- and with the same signs-- of future output. The LM is going to be the same as before. So what I want you to think about now is a model that is like the one you had before with thesame LM but now the IS is a little bit richer. It has more parameters-- these are parameters-- because I'm going to determine today's output. And all these parameters are essentially the same variables that we worry about today. but are the variables we expect of those-- are the values of respect for those variables in the future and, again, with the same sign. So if output-- so if taxes go up today, aggregate demand will decline, and output will decline. But if I expect future taxes to go up as well, then that's going to depress aggregate demand even more. That's the type of logic I want you to develop. So that's the way our model will look. So this is the IS in the same space I had before. it did in lecture 3 or 4? So suppose we increase taxes by 10%. Will that reduce output more or less than when we had the static IS-LM model? Yeah? AUDIENCE: Depends on the expectation. RICARDO CABALLERO: OK, but I haven't moved. These are parameters from my curve. So I don't get the right to move them. It's a combination of the present and the future. So if-- that means that anything that is just the present will matter less than in the past. said, well, it depends on whether I expect the future taxes to change or not. That tells you there is a difference between changing temporarily the taxes and increasing taxes permanently. So what happens with this curve-- so we decided that increasing taxes reduces this IS to the left by a smaller amount than in the past. What happens if you expect taxes to increase in the future? Which wealth goes down? Human wealth, in particular. Your human wealth will go down because you expect your disposable income to be taxed more. the static model. Changing government expenditure, same idea-- it will also move aggregate demand to the right. But will it do it by more or less? Well, think how government expenditure worked in the basic model. It increased aggregate demand, and that then led to a multiplier. And we got a lot more income and so on. Now, if we expect this government expenditure it to be temporary, that multiplier also will be a lot smaller because, yes, it will increase income, but people are not going to spend all their income today. on whether they expect future income to also go up as well or not. Now, that's a tricky experiment because if you-- and it's very relevant for today. If this government expenditure goes up permanently, it's unlikely that the central bank will remain unmoved. And so you also have to start thinking, well, what will the centralBank do? And that takes me to this variable here. Well, actually, let me point out that it's not accidental that I made this curve a lot steeper than it used to look. I mean, this looks like a pretty steep IS curve, which is a way of saying that a given change in interest rate now has a very small effect on current output, OK? Much smaller than we had in the static model. And the reason is, again, this is permanent versus transitory. If you spec the interest rate to decline only for today, and that's it, that's not going to have a very large effect on consumption or investment. For that, you want those changes to be more or less permanent, persistent. If the Fed cuts the interest rate but doesn't persuade anyone that this rate will remain low in the future, then it is going to get very small effect on output. However, if we convince people that there will be future changes, that the rates will remain lower for a long time, that means that this IS now will shift to the right. That's what we have here. So you have distinguish which is a movement-- when the Fed cut the interest rates, you get a small movement along the curve. But if the Fed persuades you that this is a long-lasting cut in interest rate, then the IS shifts to the left. And you recover the power of monetary policy. Alan Greenspan is known as one of the biggest central bankers that the US has, at least in recent memory. He went through a period which was called-- was known as the Greenspan conundrum. The economy was overheating. He kept hiking interest rates. But the loan rates kept coming down. So he couldn't cool off the economy. There was no way around that because they couldn't persuade the markets that this would be a long-lasting effect. The reason was a different one. It happens that, at the same time, you had China sending massive capital flows to the US. ineffective in terms of its monetary policy. So again, expectations mattered quite a bit. If you convince the markets that-- and the markets and consumers, households, and so on-- that you're cutting interest rates and that, with that, you'll be successful in cutting rates. If the Fed convinced that the interest rate will be lower in the future as well, then you get the IS to shift to the right. But if interest rates will be low in thefuture, that means output will be high as well. creating a-- getting out of a recession, for example, in the future, that also increases human wealth, expected present constant value of cash flows, of profits, and so on and so forth. So again, for central banks, it's a lot like-- it's mostly about expectations management. That's the business of a central bank, really. And he described good monetary policy very much like Maradona's goal scored against the UK, England, in some World Cup. essentially drew in a straight line to the goal and scored. But he persuaded everyone around to move away from his path, and that was a successful strategy. And central banks do a lot of that-- lots of talking. And, you know, at the end of the day, the true actions of moving the interest rate are the least important part of, really, a monetary policy strategy. That's what the Fed is trying to do, and it's doing a good job so far. Most of the time when you have episodes of fiscal consolidation in environments that are not of very high distress, financial crisis, and so on, it typically sort of-- how successful that is depends a lot on whether people expect to be a sort of implicit deal between the central bank and the Treasury. So, for example, if you have a fiscal contraction that leads to an anticipation of a big cut in interest rates in the future, that may be expansionary. It can offset quite a bit of the fiscal contraction side. So towards the late '80s, they began a delivery plan of fiscal consolidation. Fiscal consolidation means, essentially, reducing the deficit. And they were very successful, as you can see. But contrary to expectations, at least, output growth did not decline, actually. They finally sort of-- they had a very good period like that. So that's all-- it was all about expectations. Notice that unemployment, though, did go up. So despite the fact that you got more unemployment and so on, output began to grow. example is abused by almost anyone that wants to cut taxes and things like that. But there are experiences. There is a whole spectrum of experiences. But in situations that are as extreme as this one, it clearly proved to be very effective. So that's that. So the role of this lecture was to say something that I sort of should have said earlier on, but I would have been a bit confusing. But it's very important. Expectations plays play a central role in economics. In particular, expectations influence aggregate demand. did talk about expectations mostly in the context of aggregate supply. But I think a much bigger role is played-- of expectation is really on aggregate demand, and certainly on asset prices. And finally, I want to say that, many times when you find episodes of fiscal, even sometimes monetary policy that are counterintuitive, it's entirely due to the expectations part. So this is case of fiscal consideration is not that the cutting in fiscal expenditure is not the reason for the reduction in aggregate demand. was expansionary. That was contractionary. But it was overwhelmed or offset, more than offset by the improvement in the outlook that you had. And that also happens with monetary policy. Countries that have high inflation problems and so on sometimes get-- and they have to go through dramatic tightenings. Yes, most of them get very short-lived recession. But sometimes they are veryshort-lived recessions because eventually the reduction of the instability caused by high and unstable inflation sort of ends up dominating any direct contractionary effect.

ROUGE-1: 67.03, ROUGE-2: 64.95, ROUGE-L: 64.13
BERTScore: 75.51

==============================================
==================== [35/100] ====================
Summary:
CNN's John Defterios takes a look at the U.S. government's fiscal policy. He looks at three different views of fiscal policy and how well it works. Defterio: We have expansionary and we had contractionary and in our expansion area fiscal policy we saw that taxes were going down or government spending was increasing. With our contractionary fiscal policy it was the exact opposite here we had taxes increasing or spending decreasing such that if you had a deficit it was getting smaller or ifyou had a surplus it was growing larger. it doesn't work so let's kind of look at them in the atas model right we have this Keynesian view. We have our kind of a classical view and we have our what would be called supply-side view. There's more views than that obviously but we're just gonna look at these these three stir them the three main ones. We know that eventually SRA s increases to S aureus - output equals output - so we know that whatever it is eventually our short-run aggregate supply curve is going to increase. YF price level equals po2 car cane says though hey this could take a long time and he's famous for saying in the long run we're all dead meaning yeah eventually everything is gonna work out but why wait for that why not go ahead and fix it now. He says let's just change aggregate demand to go to point a because there's no difference between point a and Point C anyway other than the fact that the price levels higher takes more green. cane says well if you're in this type of situation what we can use is we'll go out and we'll borrow money. We'll make aggregate demand increase right. If we're in a situation like this so here we would use expansionary fiscal policy we could also be in a situations like this. We've got to say real GDP we've got the price level we have our long-run aggregate supply curve. We also have our aggregate demand and a short- run aggregate supply. What happens here eventually exactly the short run decreases right because we see here at y2 employment is greater than the natural rate of employment the unemployment rate is lower than anatural rate of unemployment. aggregate demand decrease and so what we get is we get aggregate demand doing something like this. Keynes says we can change aggregate demand in such a way that we can make. We can make that guy be exactly where we want him to be. We don't have to guess we can know we can. know we don't need to touch my tie anymore and remember Keynes says don't let me touchMy tie anymore. Keynes: We can't wait for nominal prices to increase why not just engage in some contractionary fiscal policy. exactly right with that Marg propensity to consume and thatMarg propensity to import and knowing all of that lets us know the multiplier and we know how large autonomous expenditures are and all that stuff. We can essentially just it's just an Excel spreadsheet you just plug in the number that you want for these changes and taxes or these changes in government spending now you've got a political problem here which is that once you actually start spending money it becomes difficult to take money away once you start giving people something taking out money away now becomes very very difficult. change the demand for loanable funds so you have this market right if you're gonna have the government go out and borrow money they're going to borrow the money. There's a market out there for people borrowing and lending the money and that can be for us savings bonds. When the interest rate goes - I - what happens to private borrowing what is it at now do it q2 is the total that's private and public how much is private borrowing. It's more than that right because when you guys put money into your savings account your parents put money aside for college. yeah it's less than q1 it's a way over here I'll call this guy q0 here's your public here're your private so you see that private investment private borrowing goes down. interest rates went from i1 to i2 so let's think about what this guy's says because here's the total borrowing that was occur used to have total private borrowing of this now we have let's see we'veGot public borrowing here we've got private borrowing here in essence what this increase in the interest rate does is it makes consumption go down and it makes investment go down. get over here we wanted to get the YF right and we said oh look we can just easily program the number into the our Excel spreadsheet and so exactly how much to increase government spending. But if that increase in G changes interest rates and causes these guys to go down the guy doesn't become this guy what does he do he doesn't shift to this guy he's down alright. Shortland implication is is that you can't just plug in the number from here and get to where you want to be. if this guy's going down what does that mean for the long-run do what well of investments decreasing what else is decreasing investment goes down. We don't build the factory your interest rates are too high I'm not building a factory in 2017. The factory doesn't exist right. The quantity and quality of resources and the level of technology are what determines this guy right so here's our guy in 2017 and it had we built the factory out here in 2025 the guy's gonna be out here. red not the guy in blue because this decrease in investment made you say I'm not going to the increase in the interest rate made investment go down. If investments going down the quantity and quality of our resources are smaller. The capital stock is smaller the future output will be smaller. You will have less stuff in the future and here's what's really interesting how are people going to know that here they are on the red line and they could have been at the blue line you see what I'm saying because we'll be like they won't even know that it's there. this here we are in 2025 are on the red line but we could have been on the blue line but people won't even know it. People argue okay a you got this crowding out effect you're not even going to get all the a change and output that you want to anyway. Even if you could all that you're doing is sacrificing future output for today. You're just making people invest less today you're making the economy worse in the future. The new classical view or the classical view kind of says that people are rational so here's our long-run aggregate supply curve. F and basically this guy says look we know eventually the short-run aggregate supply curve will increase and we go to the full employment level of output if you guys engage in this type of policy over here. The deficit today means that at some point in time in the future you're going to have to increase taxes so you can kind of think of it as the budget deficit over two different time periods. In fact thanks to interest it won't be 20 that you have to borrow or in raise taxes for it'll actually be like say 30 all right. opposite they're going to have to raise taxes and cut expenditures so even though the aggregate demand curve could in theory do this if people know that this is going to occur they're gonna save back for the higher taxes. The alternative way to think of it is this and this is especially true if it's a closed economy if you're not borrowing the money from outsiders from foreigners if were the government if we're the economy and I'm the government and I say you guys aren't spending enough money lend me money to spend. you're spending a thousand or you can spend anything I'm spending a hundred all right that's the way it currently is right now and then I say to myself you guys aren't spending enough money we need to spend more right. So I'm gonna borrow from you you guys lend me two hundred so now I can spend three hundred but you guys now have two hundred less so now you're spending eight 1,100 1, 100 right G is going up hey I'm going to borrow money and I'mÂ  gonna spend it this guy's going up but where am I gonna get the money from to borrow fromYou? The new classical view says essentially fiscal policy doesn't make any sense it's worthless it's not gonna work in a long run. The third view is the supply side view. The supply side of you looks at this and says look here's tax revenue. If we have a tax rate that's equal to zero how much tax revenue will we collect zero? And if we have an tax rate equal to 100 percent howmuch tax will we get? And so on and so on. That's the classical view. And that's the third view. revenue will we collect how many guys are going to work later today okay what's what's your name again Paige okay what do you do again okay. So here the supply-side view this is called the Laffer curve. It's not what you spend it's what you tax and it's not even necessarily the amount that you tax it's the marginal tax rates that are important. If tax rates are 20% if the government takes 20% of my pay they are in essence taking all of my. labor every Monday right Monday Tuesday Wednesday Thursday Friday 20 40 60 80 100 % I don't teach on Saturdays all right and so if they're taking 20% it's like every single Monday that I come to work I'm essentially not doing anything I do all the day's work. If you raise this guy too much the marginal tax rates too much people are like forget it it's not worth it so if you keep them low enough people have the incentive to save and invest right because in essence the taxes are a form of taking their taking your labor. term low in parentheses because it doesn't necessarily mean that it's like 12% it just means that it'm lower than this guy right here whatever this number is as opposed to here would be our PPC curve and say 2025 with the high marginal tax rates right in essence people wouldn't work and save and invest as much because it wouldn't be worth it. They're taking more of a long-term view of things rather than a short- term view the fiscal policy in the short term. run doesn't really matter it's the long run stuff that matters is their view. There's some evidence that people respond to these incentives right because if you think about it like this think about like this somebody makes somebody who's on welfare they're getting a check % thousand dollars and you say that's bad we don't want you doing that go get a job and so they go out and they earn ten thousand and one dollars. But what happened to their real income they went down right because they had nine thousand nine hundred ninety nine dollars in wages. doesn't make any sense I'm not gonna do that I'm gonna goof off. I don't want it because they're facing a marginal tax rate that's really really high so which view is Keynesian new classical supply? I'll write the paper and win the Nobel Prize and I can go to Sweden and get the nice little bitty gold medallion that I couldn't wear around my neck for the rest of life at such a such recession. alright this is the end of test three material I will.

ROUGE-1: 57.88, ROUGE-2: 55.61, ROUGE-L: 54.11
BERTScore: 72.76

==============================================
==================== [36/100] ====================
Summary:
Professor: The plan for today is as follows. We're going to look at this unitary time evolution and calculate this operator u, given the Hamiltonian. Then we will look at the Heisenberg picture of quantum mechanics. And it's a pretty useful way of seeing things and calculating things as well, and makes the relation between classical mechanics and quantum mechanics more obvious. So we'll discuss that. We'll find the heisenberg equations of motion and solve them for a particular case today. t t0 is equal to H of t U of t t0. You should be able to look at that equation and say I see the Schrodinger equation there. So what do we have? ih bar. Let's write dU dt is equal H times U. And we tried to write a solution of the form U use equal to e to the minus iHt over h bar times U0. Does that work? Well, we can think du dt and ih. the right. It cannot be to the right of U0 though, because this is a matrix, a constant matrix that we've put in here as a possible thing for boundary condition. So so far we've taken this derivative, and then i's cancel, the h bar cancels, and you get H. But this whole thing is, again, U. So the equation has been solved. So try this. And it works. So having this solution we can write, for example, that U of t t0 is going to be e to the minus iHt over h bar. back here what U0 is and finally obtain U of t t0 is e to the minus iH over h bar t minus t0. And this is for h time independent. There's very little to add to this. We discussed that in recitation on Thursday. This unitary operator you've been seeing that from the beginning of the course in some sense, that you evolve energy eigenstate. If this acts on any energy eigensstate, h is an energy. is just the function evaluated at the eigenvalue. A little time dependence is an idea, the sign to make it possible for you to solve the equation. So you could have Hamiltonians that are time dependent, but still have a simplifying virtue. So H of t is time dependent. But assume that H at t1 and h at t2 commute for all t 1 and t2. So what could that be? For example, you know that the particle in a magnetic field is minus gamma B dot the spin. You could have a time dependent magnetic field. The magnetic field is time dependent, but its direction is not time dependent. And the Hamiltonian at different times commute because Sz commutes with itself. So if you have a magnetic field that is fixed in one direction but change in time, you can have a situation where your Hamiltonian is timedependent. And you will discuss such case because it's interesting. But later on as we do nuclear magnetic resonance, we will have the more interesting case in which the magnetic field isn't time independent. a magnetic field rotates and therefore it's not that simple. So what happens if you have a time dependent Hamiltonian that actually commutes? Well, the claim is that U of t t0 is given by a natural extension of what we had before. You would want to put exponential of minus iHt, but the reason this worked was because the derivative with respect to time brought down an iH over h bar. So one way to fix this is to put t t 0 H of t prime dt prime. So this is an answer to try this. the derivative of this quantity with respect to time. Well, when you differentiate an integral the upper argument, you get just the integrand evaluated at the time. So this is H of t. And now here comes a crucial point. This U is really e to the R. And you're trying to differentiate to see if the equation holds dU dt. Would be d dt of 1 plus R plus RR plus 1 3 factor RRR. You, would have one half R dot R plus R R dot. And then 1 over 3 factorial, but three factors. R dot depends on H, and R is an integral of H as well, but the H at different times commute anyway, so this must be true. Since the Hamiltonians are assumed to commute, R dot commutes with R. And this becomes like a normal derivative of an exponential in which you can move the R dot to the left everywhere. So actually that means that we've got pretty much our answer, because R dot is minus i over h bar H of t. And e to the R is U, so we got dU. dt equals this, which is the same as this equation. The only reason a derivative with respect to time will not give the usual thing is if R and R dot fail to commute, and they don't. So you could put the R dot here. You can put R dot on the other side, because it commutes with R, but it's better here. And therefore you've got this very nice solution. So the solution is not that bad. So that's case-- there was a 1, a 2, a 3 H of t general. something that makes sense. So here it is. U of t and t0. I'll write the answer and explain how it looks, and then you will see that it's OK. It's interesting. But it probably is not the most practical way you can solve this problem. There's an acronym for this thing. T it's called the time ordered exponential. This operator does something to the exponential function. So I have to say what this time ordering exponential is, and it's the following. You take the exponential and just begin to expand. and call this t2. So t1 will always be greater than t2, because t2 is integrated from t0 to t1. And as you integrate here over the various t1's, you just integrate up to that value. So you're doing less of the full integral then you should be doing, and that's why the factor of one half has disappeared. This can be continued. I can write the next one would be minus i over h bar cubed integral. of this, you will get H times that thing. So since it's a power series, you'll differentiate the first term, and you'll get the right thing. Then the second term and you will start getting everything that you need. It's reassuring that something like this success, but in general, you would want to be able to do all these integrals and to sum them up. So it's of limited usefulness. But when you have a practical problem, generally that's not the way you solve it. We will try to figure out the solution some other way. But in terms of completeness, it's kind of pretty in that you go from the exponential to the time ordered exponential. And I think you'll see more of this in 806. So that's basically our solution for H and for the unitary operator U. And what we're going to do now is turn to the Heisenberg picture of quantum mechanics. Yes, questions? AUDIENCE: Why does R dot [INAUDIBLE]? PROFESSOR: Because that's really a property of integrals. T is not an operator in the usual sense of quantum mechanics or anything like that. It's an instruction. Whenever you have an exponential of this form, the time ordered exponential is this series that we've written down. So at this stage, this is a definition of what t on an exponential means. If we have operators in differential equations, do we still get unique [INAUDIBLE]? Yes, I think we do. I think that's a good question. Yes, it is. solutions? PROFESSOR: Yes, pretty much. Because at the end of the day, this is a first order matrix differential equation. So it's a collection of first order differential equations for every element of a matrix. It's pretty much the same as you have before. If you know the operator at any time, initial time, with the differential equation you know it at a little bit time later. So I think it's completely analogous. It'm just that it's harder to solve. Nothing else. function out of this. What really is happening is that you have learned how to calculate this operator given H. And therefore now you're able to evolve any wave function. So you have solved the dynamical system. If somebody tells you a time equals 0, your system is here, you can now calculate where it's going to be at the later time. So that's really all you have achieved. You now know the solution. If you know it at any time, you've solved problem. OK, so Heisenberg picture of quantum mechanics. picture. So basically the Heisenberg picture exists thanks to the existence of the Schrodinger picture. The motivation comes from expectation values. Suppose you have time dependent states, in fact, matrix elements. So you could ask what is the matrix element of A between these two states. So it all begins by considering a Schrodinging operator As hat, which is s is for Schrodingers. And the motivation comes out of expectation values, which are the same as the time dependent state alpha of t. two time dependent states, a matrix element. But the time dependence has already been found, say, in principle, if you know U dagger. And then you can speak about the time dependent matrix elements of the operator As or the matrix element of this time dependent operator between the time equals 0 states. This operator is sufficiently important that this operator is called the Heisenberg version of the operators s. Has time dependence, and it's defined by this equation. So whenever you have Schrodinger operator, whether it be time dependent or time independent, whatever the Schrodingers operator is, it has time dependence. I have now a definition of what I will call the Heisenberg operator. And it is obtained by acting with a unitary operator, U.S. And operators always act on operators from the left and from the right. If you have an operator that's on another from theRight only or from theLeft only, I think you have grounds to be suspicious that maybe you're not doing things right. And as you can imagine, there's a lot of things to be said about this operator. the Schrodinger operator? PROFESSOR: You have to speak louder. AUDIENCE: Is the Schrodingers operator related to the Hamiltonian [INAUDIBLE]?PROFESSor: Any Schrodings operator. All the operators you know are Schrodinging operators. At t equals 0 A Heisenberg becomes identical to A Schrodinged. When t is equal to 0, U of t-- of 0 0 is the operator propagates no state, so it's equal to the identity. C Heisenberg is just A Heisenburg times B Heisen Berg. So if you have C Schrodinger equals A Schrodingers, B Schrodingen, C Heisenber is a commutator equal to C He Eisenberg. If the Hamiltonian is time independent, does that work for any operator that commutes with the Hamiltonians? If this is happening, the two Hamiltonians are identical, and we'll have the chance to check this today in a nice example. So we will have an interesting question, in fact, whether the Heisen Rosenberg is equal to theSchrodinger Hamiltonian. whole thing is the same. So this is something very useful and we'll need it. One more comment, expectation values. Comment number four on expectation values, which is something you've already-- it's sort of the way we began the discussion and wanted to make sure it's clear. So we say that the Schrodinger expectation value is equal to the Heisenberg expectation value. We right it in the bottom, but we mean the top equation. And we use it that way. difficult. So what we try to do in order to simplify that is find an equation that is satisfied by the Heisenberg operator, a time derivative equation. So finding a differential equation for the operator is useful. We want to calculate ih bar d dt. And so what do we get? Well, we have several things. Remember, the Schrodinger operator can have a bit of time dependence. And even if you know U, you have to do this simplification, which is hard. So we have three terms. ih bar dU dagger dt As U plus U dagger As dU dt plus-- with an Ih bar-- U dagger ihbar dAs minus dt. dAs dt and U. Well, you have these equations. Those were the Schrodinger equations we started with today. The derivatives of U, or the derivatives ofU dagger. so what did we have? Well, we have that ihBar dU. dt was HU-- H Schrodingers times U. And therefore ih Bar dU Dagger dt is equal to U dagger Hs with a minus here. Time dependence of expectation value. How does the expectation value of a Schrodinger operator depend on time? You're faced with that expectation. value of As, and it changes in time, and you want to know how you can compute that. Well, you first say, OK, ih bar d dt. But this thing is nothing but psi 0 A Heisenberg of t psi 0. Now I can let the derivative go in. And using this, assuming that A is still no time. dependence, A has no explicit time dependence, then you can use just this equation, which give you psi 0 Ah Hh psi0. The Heisenberg operator is actually time independent. It just doesn't depend on time. A Schrodinger operator, it's a funny operator. It doesn't have time in there. It has X's, P's, spins, and you don't know in general, if it's time independent in the sense of conserve of expectation values. But whenever As commutes with Hs, well, the expectation values don't change in time. But as you know, this d dt can be brought in, because the states are not time dependent. minutes to do an example and illustrate much of this. In the notes, there will be three examples. I will do just one in lecture. You can do the other ones in recitation next week. There's no need really that you study these things at this moment. Just try to get whatever you can now from the lecture, and next week you'll go back to this. So the example is the harmonic oscillator. And it will illustrate the ideas very nicely, I think. Professor: X and P are time independent Schrodinger operators, so that equation that I boxed holds. Heisenberg equations of motion look like ordinary equations for dynamical variables. Professor: It's going to simplify your life quite dramatically when you try to use these operators. This time the operators change, and you will know what they change like, so you have to write this then you have this solution of sine cosine t plus sine sine omega t and B are some time independent operators. variables in, it just becomes identical to the Schrodinger Hamiltonian. All right, so that's all for today. I hope to see in office hours in the coming days. Be here Wednesday 12:30, maybe 12:25 would be better, and we'll see you then. [APPLAUSE] We'll be back at 12:50 on Wednesday, and be here at 1:30 on Thursday. Back to Mail Online home. back to the page you came from.

ROUGE-1: 48.40, ROUGE-2: 46.22, ROUGE-L: 46.03
BERTScore: 66.53

==============================================
==================== [37/100] ====================
Summary:
Professor Steven Smith: I want to talk today about my favorite part of the Second Discourse, a book that never grows old, that never fails to produce. Last time, I focused on a famous passage in which Rousseau claims it was the establishment of private property that was the true formation of civil society. But in fact, that's not really true. If Rousseau were only interested in issues of class and economic inequality, he wouldn't have written about inequality in the first place. Rousseau understands that even for institutions like property and civil society to be possible there must be huge and important developments that go on or take place even prior to this. And it is for Rousseau far more what we might call "the moral and psychological injuries of inequality" than the material aspects of the phenomenon that is of concern to him. There would be very little difference between him and materialist theorists of society like Karl Marx although Marx was in fact a very appreciative reader of Rousseau. Rousseau like Plato finds his voice when discussing the various complexities of the human soul. So what is the chief villain in Rousseau's Second Discourse and his account of the beginnings in development of inequality? Real inequality begins in a faculty or a disposition that is in most editions of the book rendered simply by the French term because it is really untranslatable into English. It is amour-propre, the first term I put on the board, which is the first and most durable cause of inequality for Rousseau. Rousseau distinguishes amour-propre from another disposition that he calls amour de soi-meme, a sort of self-love. Love of oneself is a natural sentiment, he writes, "which moves every animal to be vigilant in its own preservation" "Amour- Propre is merely a sentiment that is relative," he says, "artificial and born in society which moves each individual to value himself more than anyone else" "It inspired in men all the evils they cause one another and which is the true source of honor," he adds. For Hobbes, and this idea of pride, vanity, what Hobbes called vainglory, was a very important part of Hobbes' political and moral psychology in Leviathan. For Rousseau by contrast amour-propre is something that could only come about after the state of nature, a state that Hobbes had called solitary, poor, nasty, brutish, and short. But how could pride have arisen in such a state? Rousseau speculates about this and, again, this is part of his hypothetical or conjectural history. "From that gaze, from the look or gaze of another, that the passion of vanity was born," he says. The one who sang or danced the best, the handsomest, the strongest, the most adroit or the most eloquent became the most highly regarded. From these first preferences were born vanity and contempt on the one hand and shame and envy on the other. "The fermentation caused by this new leavens eventually produced compounds fatal to happiness and innocence," he writes. produced in many--for many people again, as he puts it, pride and vanity from some shame and envy on the part of others. That too is a part of amour-propre, the desire to be seen and recognized and respected. The desire for recognition, he says, is at the root of our sense of justice and underlying this is the intuition powerful and in many ways I think deeply true, that our feelings, beliefs, opinions and attitudes be acknowledged and respected by others around us. Rousseau: "From this came the first duties of civility even among savages" "Every voluntary wrong became an outrage because along with the harm ... the offended party saw in it contempt for his person," he says. "Each man punished the contempt shown him in a matter," he writes. "It is not the physical aspect of the harm that bothers him. It is the sort of contempt that is implied or entailed in the act of injury," Rousseau says. 'The contempt is more insufferable than the harm itself,' he adds. Rousseau: Amour-propre and society gave rise to the state of war. Do you remember that, about the cartoons of the prophet Muhammad and the outrage and the protests, often violent, that occurred about that? To some degree, I think, Rousseau would believe the protesters over those cartoons had a point. Their views were not being respected and to which you might say a Lockean or a liberal formulation of the problem or response would be, "Well, so what?" The task of government, according to Locke or the liberal view, is to ensure the respect.proportionate to the esteem in which he held himself. Government's job is not to impose a gag order on what can and cannot be said, he says. This is a respectable, sort of liberal line of thought going from Locke to John Stuart Mill, he adds. But there is something powerful and true about what the government is supposed to do, he writes. It is to protect you from harm and provide you with the freedom to practice what religion you like, consistent with others' freedom to do so too, he argues. The Danish prime minister has refused to apologize for the cartoon. Rousseau has to say about it, about this kind of issue. To tolerate simply means not to persecute, to leave alone, while respect for something requires that we esteem it. This is a vast topic. I think that amour-propre, the desire to be esteemed, recognized, and to have your values and points of view esteemed by those around you is very different from what Locke talked about. It doesn't require us to censor, self-censor, our own views on the ground that they may be disrespectful or hurtful to others. is in fact a violent and uncontrollable passion. It is the passion very much like Plato's thumos, spiritedness, back in the Republic. Like Plato, in many ways, Rousseau wants to know whether amour-propre is purely a negative passion or disposition or whether it can be redirected, in some way, to achieve social goods and social benefits. So much of Rousseau's subsequent account of civilization and its discontents grows out of this peculiar psychological disposition and passion. about the assertion that men who were once free and equal are so easily, as it were, led to consent to the inequalities of property and to rule by the stronger, which government brings into being. The social contract, as he presents it in the Second Discourse, is really a kind of swindle. Government is a con game that the rich play upon the poor. Political power simply helps to legitimize economic inequalities. How else can one explain why the rich live lives that are so much freer, so much easier and so much more open to attack? enjoyment, than the poor? That is Rousseau's real critique and real question. And it is the establishment of government that is the last link in the chain of his conjectural history. But what, again, is most painful to Rousseau is the emergence of a new kind of human being that this stage of civilization has been brought into--that this state of civilization have brought into being. The bourgeoisie is RousseAU's invention. Most striking about this human type for him is the necessity to appear to be one thing where actually being something else. Rousseau describes the dilemma of the bourgeoisie in the penultimate paragraph of the Second Discourse. He says, "The savage lives within himself. The man accustomed to the ways of society, the bourgeoisie, is always outside of himself and knows only how to live in the opinions of others" "From this distinction there arose grand ostentation, deceptive cunning, and all the vices that follow in their wake," he says. "Being something and appearing to be something" are two different things, Rousseau says. that he draws the sentiment of his own existence." Think of that sentence. It comes from the next to the last paragraph of the book, that in society we only live through the opinions of others, through the gaze of others. Such a person is duplicitous, hypocritical, and false. This is why this is the true, you might say, discontent of civilization. It is what our perpetual restlessness and reflectiveness have made of us. We are constantly our own sentiment of existence, he says. Rousseau's Second Discourse ends on a note of utmost despair. It offers no positive answer to cure the problem of civilization but only hints at best at two possible solutions. Democracy for him, this kind of simple rural democracy like that of Geneva, is the social condition that most closely approximates the equality of the state of nature. Only a very few people, Rousseau writes, are capable of finding their way back to nature, and he believed himself to be one of them. of civilization is responsible for all of our miseries. He denies that we can, as a practical solution, return to simpler, more natural forms of political association. But how then do we resolve the problem that he leaves us with? And his answer to it, his political answer, is contained in his book, yes, called the Social Contract, Du Contrat Social, published in 1762, seven years after the Second Discourse. It is not his only or final answer, but one such answer to the problems of inequality and amour-propre. In the state of nature, we are born free, equal and independent. Only in society do we become weak, dependent, and enslaved. How did this take--how did this change take place, Rousseau asks. I do not know. What can render it legitimate? I believe I can answer this question. In the Second Discourse. I take it he means the chains as in--that states man is born free and is everywhere in chains. It is what follows after that sentence in a way that is the shocker. Discourse, he had attempted to completely delegitimize the bonds of society. Now in the Social Contract, he asks the question, "What can give these chains or bonds moral legitimacy?" He says I believe I can answer that. Has Rousseau simply undergone a massive change of heart in the seven years between these two books? I don't think so but I think these are--this is part of his--one of his answers to this fundamental question. But before going into the details, let's consider some of the differences between these very powerful books. Rousseau's political philosophy begins, at least he believes, with the realistic or even empirical assumption that each individual has a deep rooted interest in securing the conditions of their own liberty. He does not presuppose altruism on the part of any human being or any other kind of self-other regarding characteristics. We are selfishly concerned with our own freedom and the best means to achieve it. The Principles of Political Right suggests that are appropriate to human beings conceived as free agents responsible to themselves alone. Each of us has a desire to preserve his or her own freedom and that social order will be rational or just, that allows us to preserve that freedom. The state of nature quickly becomes a state of war based on conflicting desires and conflicting again means of liberty preservation. This is the question that the Social Contract sets out to answer and to which his famous formulation of what he calls the general will is the solution. I'm going to end on that note today and Wednesday I want to talk about the.of preserving it and protecting it. general will and how Rousseau sees it as a sort of collective answer to the problem of the securing of individual liberty. So meditate on that if you like for the next day. If you like, you can read the rest of the book tomorrow. It's a great read and a great way to start a new day. I hope you'll join me for a cup of tea and a glass of wine in the next few hours. I'm looking forward to seeing you in the morning.

ROUGE-1: 54.67, ROUGE-2: 50.63, ROUGE-L: 47.22
BERTScore: 73.42

==============================================
==================== [38/100] ====================
Summary:
So I think I just spend like five minutes, just briefly review on the backpropagation last time. So I guess I'm drawing in this way. Like this is the forward path. This is how you define network and the loss function. So you start with some example x, and then you have some-- I guess, this is a matrix vector multiplication module, and you take x inner product multiplied with w and b. And then get some activation, the pre-activation. And you get some post activation. one of those three lemmas. If you know how to compute the derivative with respect to the output of some module, suppose this is a module, tau is the output. And now you can see what this does kind of like lemma are for. Those lemma, basically, are saying that if you know dg over the d tau, how do you computedg over da? And there's another lemma which says that ifYou know how. to compute dgover da, howDo you compute dG over dz? All of those lemma is about this kind of relationship. If you know this quantity, then how to compute the derivative with back to the last layer weight. And from this quantity,. you know how to complete a derivative with respect to w1. And also the same thing for b's. And this kind of-- the last row, this quantity. So they don't depend on, for example, after you get this, you can convert this, right? And after you've got this quantity you can come up with a derivative. We don't have enough time to review again. these two quantities. But this row, the derivative with respect to activations, you can only do it sequentially. You can not say, you compute this before you do this. So this arrow is kind of the orders of the dependencies between these quantities. And each of these arrow is basically done by one of the lemma that we discussed last time. Any questions? This is just an extension of the last five minutes of the previous lecture. I didn't have enough time to elaborate on this. Some of the practical viewpoint of ML, like how do you relate to your model, what you have to do in this whole process, right? So like you start with the data process, and then you has to tune the model. So basically, in these two lectures, I think we're going to discuss this concept. I think that generalization is probably the main thing that we are talking about here. It's really just about how well your model is performing, and syntax examples. And we fit some model on them. So now, what we care about whether this model will work for future unseen examples. And we are going to discuss a bunch of concepts, the balance variance trade-off, which is a kind of a principle when you think about how test error changes as you change model complexity. OK. So I guess, that's just a very high level overview. I use a lot of buzzwords. I'm not expecting everyone to follow everything. So let me maybe be concrete. it means. Training loss or sometimes, it's called training error. Sometimes, we use the word cost. So they all mean the similar type of concepts. This is the loss function you care about when you have square loss. And other loss could be cross-entropy loss. It could be like MLE, the maximum likelihood estimator. I think we have to write down-- we have written down this equation a lot of times. It's actually one principle to derive the training loss. You derive the maximum likelihood estimator for data sets. And that you use that as your training loss. So this is basically, so far, what we have focused on in the last few weeks. How do you get a training loss, and how do you really implement this, and optimize this, right? So there are many ways to optimize it. So like for example, like in deep learning, we are using stochastic gradient descent. And then we have talked about Newton's method, so and so forth. is this loss function when we try to find the minimizer of this lossfunction. So ideally, you want the model to not only perform well on the training data because for the trainingdata, you already know the prediction. So that's why the test loss is defined on unseen examples. And I'm going to use this notion. So suppose, say, you draw-- the process is that you draw some data and then try to predict it. Why you care about letting themodel to predict something you already knows? New example, x comma y, from some distribution D. And often, this is called test distribution. And then you evaluate what's the expected loss on this new test example. So what's important is that this x and y is not seen in a training. It's a new fresh example. And just to be clear, these test examples, you haven't seen them in aTraining set. They are something you draw. You can draw them in advance, but you cannot let them to be seen in the training process. is a notion called generalization gap. When you test, you find that your model is not as good as you thought before on the training set. Sometimes, it's probably a little worse, sometimes a lot worse. But generally, you shouldn't expect that your test performance is dramatically better than the training performance. In extreme cases, you can design the set, such that this happens. But I think in realistic practical situations, I don't think you should expect that at all. The gap is either very close to 0, or maybe a slightly negative, slightly positive, or is much bigger than 0. So you want this gap to be as small as possible. This one is something you can control in some sense. But this one is harder to control because you don't-- because you cannot say, I'm going to find a theta, such as l theta is small. So that's why the generalization gap is something that is very hard to control. At least, you cannot directly control it. And the point of this lecture is to discuss in what cases you can somewhat know this is not too big. overfitting is that the training loss, j, is small, but the test loss is big. So you have a discrepancy between training and test. So for example, I guess, I'll probably draw this very often-- I'll draw this figure very often in this lecture. So suppose you have some x and some y. You have some data set. The data are approximately quadratic. So x and y. So it has a one-dimensional problem. So given x, you want to predict y. like this, maybe this, and something like this. You see these four blue points, and you want to fit a line to it or fit some curve to it. And the question is what curve you are going to fit? So suppose, you fit something crazy like this, let me try to see what color I'm using for this. One moment. Let me think about how do I use the color in a consistent way. So I guess if you fit-- I'm going to use black for the model you fit. you can imagine this model shouldn't generalize to anything examples. Then you can see that the fitting to the right point becomes very worse. So the test loss is very big. So this is a typical situation of overfitting. In some sense, you are saying that you fit the data very well, but you are overfitting in the sense that you only focus on the training data. I will discuss why this will happen. I guess, you can probably guess, but this is so far, I'm just defining roughly what overfitting means. that you are not-- you fit the training data, but you don't generalize. Another notion is called underfitting. An underfitting, basically, just means that you face something like this. And whether you are in the overfitting regime or the underfitting regime, depends a lot on different things. And one kind of decision we are trying to discuss today is that what is the right model complexity. So like what are we going to use? Linear model, maybe use quadratic, or fifth degree polynomial, or neural network, so on. and so forth. So we're going to discuss what will happen if you change your model complexity, and whether in what cases, you may underfit. In what cases you may overfit, and what is the best response. Any questions so far? And kind of like as a spoiler, in some sense, like we'regoing to discuss two-- we are going to decompose the test error, l theta. The test error is the test loss, and l theTA. The bias is going to be a decreasing function as the model complexity. So the mechanism is that if you change the model. complexity to make it more complex, then your variance will be bigger and so on. So these are-- basically, you are kind of like trying to figure out the underlying kind oflike mechanisms. The bias is something like this. And the variance is somethinglike this. So we are going to see something like that in the next section of the book. The book will be published by Simon & Schuster, Inc. in September. bias will be smaller. And your sum of these two functions, which is a test error, will be. something like this. And then the best one will be something in the middle. So this is kind of the quick overview of what we're going to discuss. OK. So now, I'm going to define bias and variance in a little bit more formal ways. And I'll show some examples. So any questions so far? Why is the bias [INAUDIBLE]. Why is bias this crazy? Oh, squared, I mean. I drew above. These training examples are something like yi is equals close to a quadratic function. Sometimes, they are called this h star xi. Just for the sake of terminology, I think, sometimes, they call this the ground truth. And sometimes, the true function you are trying to find out. But of course, you don't know it. You want to try to recover it. And I'm going to do a thought experiment first. I's going to start with linear model, and then I'm Going to try a few experiments. fifth-degree polynomial, and then I'm going to try quadratic. So linear model. I guess, you can probably see, guys, what will happen. So you can see that there's a large training error, training loss or training-- let's call it loss just for consistency. There's a big training loss because I guess-- what's your prediction on this particular data set? So maybe-- let me see-- how do I-- maybe let me erase this for a moment. I'mgoing to redraw this again. the training data set. This is your prediction for this x. And you look at the distance between the prediction and the true label. You see that the distance is pretty big. So this is underfitting, by our definition of underfitting because the tuning is already big. And now let's think about so what you should blame. Why the training is big? What's the culprit? The culprit, I would argue, is that it's just because no any linear model can fit your data. well. So when in this kind of settings things happens, like you have the bias. So the bias is basically like it's saying that the reason why-- I don't know exactly why people call it bias in the very first time. But I think you can-- see kind of the relationship. So you are imposing a linear structure, but the true data is not linear. So it doesn't matter how many data you see, as long you impose this, you just insist that I just believe that this thing is linear, you're going to fail. cannot be mitigated by more data, as I said. And actually, it can also not beMitigated by less noise, even though there is-- and by less Noise data. So suppose, you see a little more data. Suppose you see some more data as training data. And maybe let's say, you just-- suppose in extreme case,you just see everything exactly on this quadratic line without any noise, still, if you think about what's the best fit. The best fit probably would change a little bit. Mathematically, one way to define a bias is that you can say this is the-- So bias is-- I guess, actually, there's some approximation here, depending on what exactly your model is. But roughly speaking, it's the best error or loss, you can get with even infinite data. And you can kind of see that it's probably important for bias to be small because if bias is large, even with infinite data, you cannot do anything. And that's the problem with linear models. you mean, like I don't know. Within the same model. You're not changing the model, right? You're only using linear. Like you cannot-- OK. So bias would be the best [INAUDIBLE] linear model. Exactly. So this is the bias. And here, there is-- I'll come back to the variance for this model. But here, the variance is, in some sense, you can say, it's not very important. Only the bias is the important. The model is something like h theta x is some theta 5x to the 5 plus up to theta 0. But recall that we can do this with linear regression because you just-- this is still linear in the theta. So we are able to fit this. And now, I'm going to show cases where the variance is the culprit to blame for. So I guess, I's going to redraw this. So you have-- [INAUDIBLE] four points. So if you fit the fifth-degree polynomial, so probably, you're going to get-- a fifth-degree polynomial can go up and down so many times, several times. And actually, if you really look, you can probably do something like this. So the exact details here don't matter. So just the point is that if you have high degree polynomials,. you can be more flexible. And then if you fit the data-- if youFit the polynomic to the data, then possible, you's going to getting something kind of pretty flexible. up some-- like this is not required for this course, but if you look up the book for the calculus of like polynomials, you know that if you have four points, there's always a fifth-degree polynomial with a path for all of them. So in some sense, the intuition is that this kind of model fits. So it's fit to the spurious patterns in the small and noise data. So this is because you don't have enough data, and your model tries to explain all of this small perturbations, small noise. spurious patterns, that means that if you redraw, you are going to-- you're going to learn the new spurious patterns. And you aregoing to have a different model. And if you are not specific or sensitive to spurious patterns, even you have a new data set, you probably shouldn't change much, but you should still be somewhat the same. You should still opt for the same model. If you have the 5-degree polynomial , you redrawn the data sets, then you will find a new model. this, maybe they're like point like this. Maybe we want to keep this. And I'm going to try to make the pattern rather different. Then, maybe you're going to get something different. Maybe, I don't know. You try to find out what the degree of the polynomial. Maybe you want to getSomething like this, maybe. OK. Actually, these two are still similar, but I can't draw anything. Empirically, you will see that they will be different, just because any small perturbations of this would change a lot. that you draw the same number of samples with similar ground truth-- the same ground truth and the solution. But just their randomness are different. And that's a good question. That's exactly what I'm going to talk about next. OK. One moment before that. So basically, OK, just to summarize here, if you redraw all the examples and you find that a large variation between-- so suppose, you have a-- so you so you have -- so you call this-- that means you have large variance. And if you don't see a lot of differences, then you donâ€™t have a large variance, that's the somewhat formal definition of this. We will have a little more formal version of this, but this is the idea. So maybe, for example, if you get a new data set, you get something like maybe. maybe here, here, Here, Here and here, and maybe you're going to learn something very different, maybe something like this. variance is caused by lack of data. And it can be mitigated if you have more data. Sometimes there are two reasons. One thing is like you have lack ofData, and the other is you have too expressive models. So if you've got a very expressive model, but your data is really, really big, then probably, it's OK. It's probably, you cannot say this is only caused by loss of data because you have a different model of a variance. On the other hand, if you have not too many data, but you have very, very simple model, then it's probably still OK. The mitigation is that either you get more data or you have simpler model. So technically, you don't have more data. If you have moreData, you should already use them already. But for the understanding, let's see, for example, what happens if you've got a million data, roughly. There's a little bit fluctuation, of course. So now you want to fit a fifth-degree polynomial. What happens will be that this is probably not entirely obvious-- OK. One obvious thing is that you probably wouldn't do anything like crazy as this right. So what you really will fit, like if you minimize the error on the training data with this so many training examples, then what you will get is probably something like this. Maybe there are still some small fluctuations. It's not like necessarily matching exactly the ground truth, but you have a small fluctuation. This is kind of more like a quadratic. minima [INAUDIBLE] So the question is that another possibility is that a failure mode is that you just couldn't find this degree 5 polynomial because some optimization issue. So this is something that we don't discuss, at least, in the scope of this lecture. So in this lecture, we are assuming that you can just-- optimization always works. You always find the best model. So if it exists, then you can find it. So that's why I'm like in this case, even have a lot of data, and even you have a very complex model as a degree 5 polynomial or even degree there's always exist one model that works, which is like something like this, like the ground truth. And we'll find it. For this case, definitely, we will find it because it's a linear regression problem. You will find the best model. OK. Cool. So any other questions? What happens to the [INAUDIBLE] You got more data. You're getting moreData. Yeah. So here, when I say more data, I really mean that you have-- you just collect-- you have more data from the same distribution. same distribution. Yeah. So like if you collect more data from-- yeah. So in some sense, you kind of like the mindset-- I'm not saying this is universally applicable to every situation, but the mindset we are in is that, for example, you have-- how do I say that? You have a lot of like medical images. So probably one thing is that I can just sample more data. But these four images are samples from this big population. And now, I'm asking I found out my variance is very big. So howDo I mitigate that? from the same-- I have like 1 million and label examples. I had four labeled ones, and now I say, I'm going to collect more labels. So I sample like another like 100 examples from the same distribution, and then I label them. And then I run the algorithm, and the variance will be smaller. Actually, [INAUDIBLE] to ground truths of the data. When you don't know ground truth, so all of these are so far are for analysis purpose. the ground truth, I think you cannot exactly compute the bias. Because the definition of the bias, actually, requires you to sample a lot of data. So there is no way you can evaluate the bias exactly. So typically, what you do is you say, you fit the data on the training set. And you see you're underfitting. And that's when you say-- underfitting means you have a large training error. And when you start to believe that you've got a large bias. I didn't even tell you what this is. I'll go back to come back to this. Are we [INAUDIBLE] for highly imbalanced data set? So maybe let's discuss this offline. I'm not sure whether this-- I think, it probably requires more-- the imbalancedData set is pretty often. Like we have research on that. But maybe it's not exactly related to the context here. Maybe we can discuss offline. Any other questions? OK. I think I do have something to say about the variance. is not expressive enough. Doesn't depend too much on the data. For linear models, you can just say, doesn't depend on the [INAUDIBLE] of data for non-linear models. There is some technicality, which you don't have to make-- like the only reason why I had much is just because there's some technicalities that prevented me to say this is exactly irrelevant to number of data. But you should basically just believe that it's intuitive. It's really about how expressive your model is. There is way if I were to prove that test is equal to a bias plus variance. But maybe, let's just draw this from scratch. So this side is the model complexity. This is the test. And now let's think about how do you draw the bias on this curve as smaller complexity change. So we say that the bias is large, it's because the model is not expressive enough. So that means that if your model is more expressive, then your bias should decrease. variance on this thing. So we said the variance is caused because you have too complex of model. That means if your model is more and more complex, then you should have bigger and bigger variance. So the test error is the sum of these two. And so the question you want to answer is that if you change the model complexity, what is the best test error, right? So it means that it's somewhere in the middle. But suppose you believe in this, then what the conclusion, the implication of this is that you should somehow kind of find a sweet spot. the model complexity. So for example, maybe at the beginning you find that your training error is very low, which means our bias is very high. And the bias is high, it means you are underfitting. So basically, you increase the model complexity to some extent until your bias and variance has a right trade-off. And at some point, you. find that you are in other regime, where the variance is too. high, then you should stop. One of the reasons for this is that when you see the training. error is big, you kind of see your biases. You kind of believe that your bias is too high, so that's why you should increase themodel complexity. of bias and variance first change, did you use different type of model [INAUDIBLE] So I think this figure, so this is the-- OK. You ask a good question. So probably, the best thing is to use quadratic. Quadratic is, in principle, expressive enough to express our data. So that's why quadRatic has small bias. And also, quadratics is probably, among all models, the most expressive of all models. But where the trade-off comes from, where the sweet spot is would depend on the ground truth. the models with small bias, among all the models that can express your function, quadratic is the least complex. They don't necessarily have to match each other because it also depends on the data, how many data. For example, suppose you are-- maybe let's give you an example. But it's somewhat look like a linear function. So suppose your ground truth is almost linear, but with a little of a kind of like small fluctuation. But you don't have a lot of data. You just have like five. data points. So the bias, the trade-off, depends on, for example, how many data you have as well. And all of this, all of what we discussed today is more about some internal understanding. So this bias and various is not a problem. We just [INAUDIBLE] for the loss function. So how can [INAudIBLE]. That's a good question. And the answer to that is that no, you cannot compute the bias and variance. But if you use a linear, your bias is not zero, but still small enough, right? something you can-- at least, in some case you, can estimate them a little bit. But typically, you probably shouldn't really actively estimate the bias and variance in your-- these are mostly just for-- its internal understanding for our research, for ourselves, but not necessarily something you, empirically, evaluate. So the variance and bias are just for understanding. Empirically, what you really do is that you try a lot of different models. And you select based on a validation set. in some sense. So there is some more formal definition of the bias and variance. And that's in the lecture notes in section 8.1. I think I don't have time to discuss the formal definition. Even I give the definition, I probably wouldn't be able to give you the proof. The proof is actually relatively simple. So if you are interested, you can read that section yourself. I can't give the proof, but the understanding will help you. So that's what this understanding willhelp you. OK. Don't think it's required for the exam or anything, but it's a relatively simple word if you're interested. And also, just this kind of bias and variance trade-off, it's not that always easy to achieve, mathematically. So that's why in the lecture notes, we only talk about square loss. But the intuition is still kind of fun. So if you don't care about what exactly definition of bias is. But like how do you do the mathematical decomposition is actually pretty challenging. So I will spend the next 20 minutes to talk about a new-- something that is actually challenging this picture. So this kind of like a U curve test error and bias-variance trade-off. This has been like discovered or like analyzed for I don't know how many years, maybe like 40 years or something like that. But this is like a very classic. However, people realize that there are some issues with this understanding, especially we realize that in deep learning, like you-- actually, people start to realize this in deep, learning. what I'm going to talk about. And this is an area of research productive in the last, probably, three or four years. So let me try to find out where should I erase. So this phenomenon that people observe, empirically, and then analyzed theoretically, this phenomenon is called double descent. If you are a historian, then I think actually this phenomenon actually dates back to something like 1990. But I think it just becomes popularized and more relevant these days. And what does this mean is that, so basically, I've told you that this is test error. This is model complexity. In some cases, like in many cases, you will see a second descent. Is this because we are [INAUDIBLE] the one with much more data? Not directly, I say. Because this is-- at least, on the surface, if you look at this, so this regime is the regime, where the parameters is bigger than the number of data points. So if you want to want to know what's going on, you have to look at the data yourself, and you can see what's happening. to find the right course, I'm not saying-- like you probably will say, at least, to be in this regime, probably, you need to compute. You need a lot of compute because probably, like 10 years ago or 20 years ago, you cannot even afford to run experiments. But of course, nowadays, we also have more data points. And this is the so-called double descent phenomenon. It's about less mysterious these days like after people have studied this in the last five years very carefully. the explanations, intuitions. But before that, let me also give another related phenomenon, which is also called double descent, but it's called data wise double descent. So on the x-axis, I'm going to change the number of data points. So here, the y-axis is still a test error. And the x -axis is the amount of data. OK. What this curve should look like? As you have more data points, how does the test error change? Right. if you believe in that, then you should say that OK, the test should look at this. And it should continue to decrease as you have more and more data. But it turns out that, actually, in many cases, what happens is that the test error will look like this, or increase, at some point, and it will decrease again. And this peak here is kind of similar to the peak here. So this peak is often happening when-- it's roughly equal to d. I guess, by the way, here, like there-- this is active research area, so I'm not being very precise in every places. d or not is in 2d or the relationship is less clear. But let's suppose, when you think about relatively simple models, then when n, the number of data points, is closer to the number. of parameters, then in this case, you're going to see a peak. And then after that, you have more data. It actually helps. I saw some questions. So the original double descent, does that like continue to decrease or does it eventually increase again? So in the first figure. This is a good question. this function. This was like this has been for a while. This phenomenon. This one, I think, is also-- actually, the paper that first systematically discussed this is like 2020. About that peak, when was that discovered? The peak? Yeah. This is discovered in the same paper, the peak. It's not monotone. The fact that there exists a peak was also discovered right, essentially. Yeah. But at least I would say, at least, it's only until 2020 that most people start to realize this. And because of that paper. are changing the number of data points. OK. This sounds like a mysterious enough. So like a very, very interesting. And what's the explanation? In the last few years, people try to explain what happens, and try to reconcile with our old understanding about this. And also, this is an important question because this regime, this blue regime, is actually-- actually, it's not clear whether when you run like a classical linear, models I don't think necessarily, you are in this regime. people really care about it. And what I mean by that is that even within linear models, you can try to change the model complexity. So what that means is that you try to decide how many features you use. So you can start with only using one feature or two features like for example, in the house price, where you can use the square foot as the single feature, or you can collect a bunch of other features. So keep adding more and more features. That means you have more. and more parameters. So even within linear models, you can still change the complexity, just to clarify that. Most of this theoretical study, I think, are for linear models. And they are pretty precise these days. And I'm going to try to kind of roughly summarize the intuition from the study of this double descent. So I think the first thing to realize is that this peak, so you can argue what is the most exciting or surprising thing about this graph. But let's first talk about a peak, this peak in the middle. stochastic gradient descent for linear models. So the existing algorithms underperform dramatically when it's close to d. So both these two peaks are basically like this. So here, you are changing n, the number of data points. And you found that when n is close tod, you had to pick. And here,You are changing the number. of parameters, you're changing d, the. number of features you use. And we realized when d is kind of above n, above the number Of data points, you have a peak. Algorithm that you use to produce this graph, it really underperforms very dramatically. If you change your algorithm, you probably wouldn't see this peak. What goes wrong is that a norm of the theta, the linear models you learned, is very big. It's very big, so that's why the peak shows up. OK. So for linear models, maybe this is-- I say, this is forlinear models. So what goes wrong with the so-called existing algorithm? So this basically gradient descent algorithms. when n is roughly equals d. And we kind of believe that this is, at least, a partial reason for why this leads to a peak. So even though-- so OK. So I guess, let me draw something here. We have some real experimental, real data, in the lecture notes. But if you draw that norm-- so suppose you change the number of parameters, which means you add more and more features in your data set. And if you visualize the norm in the y-axis, you're going to see something like this. And this peak here is roughly corresponds to n is close to d. have more parameters, maybe sometimes, you have lower smaller norm. So the norm when n is close to d, for some reason, it is very, very big. So in some sense, this is saying that your model is actually very complex. So very complex on [INAUDIBLE] to the norm. This model, it seem it doesn't have a lot of parameters compared to, for example, this model. So if you compare this model to the classifier theta, you can argue that if the norm is too big, then your models is too complex. and this model. So this model seems to have less parameter than this. That's by definition. The norm is actually very big. So in some sense, if you use the norm as the complexity, actually, these peaks have large complexity. So what is the right measure for complexity? So this is a very difficult question. Like for different situations, you have different answers. But there is no universal answer. But norm could be one complex measure. And it's also a way to describe how many choices to fit your data. options, in some sense, to fit your data. So that's restrict the complexity. And which norm, that's actually, for different situations, you can argue which norm is the right complexity. Actually, there's probably no universal answer. But I guess what I'm trying to say here is that the number of parameters is also not necessarily theright complexity measure. Even you have more parameters, suppose all the parameters are very, very close to 0. That's probably also very simple model because those parameters are not working. happens that for mathematical reasons, I think l2 norm behaves really nice. It seems to relate to a lot of fundamental properties. And actually, if you-- and you can test this hypothesis in some sense. So you can say that OK, I'm saying here the existing algorithm underperforms. But if you have a new algorithm, that's regularized, suppose you recognize the norm. OK. So here, it's just saying that at least for this case, it sounds like norm seems to be a slightly better complex measurement. mean is that you try to find a model such that the norm is small. So you don't only train on the training loss, but also youtry to make the norm smaller. Then you're going to see something like this. So regularization would mitigate this to some extent. I would discuss more about regularization in the next lecture. But here, it really just means that you donâ€™t only care about training loss. You try to finding a model with small norms. And you have some kind of balance between them. Your algorithm didn't use the right complexity measure. And you can fix that peak by adding norm. But there's one more question, which is there is no peak, but why there's no ascent? So suppose you just see this. Actually here, you will also see this, something like this. So this figure is actually pretty reasonable. Because if your data point is increasing, you probably should just have one decrease, like you just keep decreasing. So why, when you use, for example, a million parameters, and you just have five examples, why you can still generalize? Why you don't have ascent, eventually? In many cases, the best one is just you have more and more parameters. And actually, for example, another question is when number of parameter is bigger than the number of data points. Sometimes, you are thinking this is the-- you have too many degree of freedom to fit all the specifics of the data set. But actually, empirically, you do work pretty well. points. So the thing is that even though it sounds like you are supposed to overfit, but actually, the norm is small. The reason is that your optimization algorithm has some implicit encouragement to make the norm small, which is not used. And that's something I'm going to discuss, I think, more next time. So for this lecture, I Think I'm just-- so we're just going to focus on the loss function, and then we'll move on to other topics. going to discuss this more next time. So the high level thing is just that something else is driving the norm to be small. Thanks. Going to talk more about this in the next few days. Back to Mail Online home. back to the page you came from. Back To the pageYou came from: Back to thepage you camefrom. Back into the page You came from was from: The Daily Mail. Back onto the pageyou came from, the DailyMail.com page you were from.

ROUGE-1: 67.20, ROUGE-2: 64.78, ROUGE-L: 62.25
BERTScore: 70.40

==============================================
==================== [39/100] ====================
Summary:
Vladimir Ilyich Ulyanov, AKA Lenin, was one of the most influential figures of the 20th century. He helped overthrow the Russian tsar Nicholas II in 1917 and founded the Soviet Union. But was he a hero who toppled an oppressive tyranny or a villain who replaced it with another? It's time to put Lenin on the stand in History vs. Lenin, on CNN at 10 p.m. ET/PT on Sunday, July 8. For more, visit CNN.com/History. "He reluctantly did the bare minimum to avert revolution, and even there, he failed" "Perhaps there would've been more reforms in due time if radicals, like Lenin, weren't always stirring up trouble" "Your Honor, Lenin had seen his older brother Aleksandr executed by the previous tsar for revolutionary activity" "Such slander! The July Days were a spontaneous and justified reaction against the government's failures" "He even launched another failed offensive in the war, where Russia had already lost so much, instead of ending it like the people wanted" and outlawed his Bolshevik party, forcing him to flee into exile again. "It's a good thing the government collapsed under their own incompetence and greed when they tried to stage a military coup then had to ask the Bolsheviks for help when it backfired" After that, all Lenin had to do was return in October and take charge. The government was peacefully overthrown overnight." "How many people did they execute without trial? And was it really necessary to murder the tsar's entire family, even the children?" in his cause, living modestly and working tirelessly from his student days until his too early death. "He saw how power-hungry Stalin was and tried to warn the party, but it was too late." "But these advances could still have happened, even without Lenin and the repressive regime he established." "Yes, and I could've been a famous rock and roll singer. But I'm not that kind of singer." "You could call it that. But it was Lenin's efforts that changed Russia in a few decades" how would I have sounded?" We can never be sure how things could've unfolded if different people were in power or different decisions were made, but to avoid the mistakes of the past, we must always be willing to put historical figures on trial. We must never forget that history is not an exact copy of the present, but it can be a guide to the future. It can be used to learn from the mistakes made in the past and to make better decisions in the present. It is never too late to put a historical figure on trial for their actions.

ROUGE-1: 57.49, ROUGE-2: 50.35, ROUGE-L: 45.48
BERTScore: 68.07

==============================================
==================== [40/100] ====================
Summary:
The subject of this lecture is really the core of what I got from William Klemperer. He showed me how to evaluate matrix elements of many-electron operators. Our goal is to be able to reduce the complexity of electronic structure, which is really complicated. The electrons interact with each other really strongly, and there are a lot of them. And it's very hard to separate the complexity into many-body interactions into separate parts. It's the key to being able to interpret-- not just tabulate-- electronic properties of atoms and molecules. things that we can put in our head and interpret. The whole goal of this course is to give you the tools to interpret complicated phenomena. When we go to molecular orbital theory, we take what we know about atoms, and build a minimally-complex interpretive picture. We have the vibrational problem as a way of understanding internuclear interactions-- nuclear motions. And we have electronic structure and the hydrogen atom as a ways of understanding what electronic structure is, and to reduce it to the things we learn about hydrogen. every pair of electrons, not just two. In helium we just dealt with two, and that wasn't so bad. But when we deal with n electrons, what we are going to discover is that in order to anti-symmetrize the wave function, we have to write a determinantal wave function. When you expand an n by n determinant, you get n factorial times. And when you calculate matrix elements, you haven factorial squared integrals. So you're not going to be handling these one at a time, and looking at them lovingly. happen. But this was something that nobody in the world was interested in because it was the breaking of the usual patterns. I was convinced that I had collected some stuff that told an interesting story. And I told Klemperer about this, and he said, well, have you thought about how to evaluate these integrals? And then he showed me, on a scrap of paper, how to do it. That has been the foundation of my career for the last 50 years. But he just gave it to me on a silver platter. least the rudiments of what it is you're up against, and how you reduce them to things that you care about, that you can think about. You can understand the hydrogen atom in rather complete detail. Or at least you can understand how one observable relates to another. And so the relationship between the effective quantum number and the ionization energy of a state then provides a hydrogen-atom-based structural model for everything you can observe. Now spectroscopists have the unfortunate habit of saying we're interested in structure. Structure is static. Dynamics is magical, and special, and hard. dynamics, which you can understand, as opposed to just saying, I'm going to tabulate the dynamics too. You don't know anything unless you have a reductionist picture of what's going on. And since the hardest part of dealing with molecules is the fact that they have a lot of electrons, this is really the core of being able to do important stuff. Now it's a horrendously complicated problem, and notationally awkward, too. And let me just try to explain it. We talked about helium. And helium has two electrons. And there's this 1 over r12 interaction between electrons, which looks innocent enough. You know, it's just a few symbols. But that's really a lie, because it's as big as it sounds. as almost everything else. We rely on n and l to get almost everything. But here we find that, in addition to this being that small, it destroys the foundation of our picture. And so how do we think that we can make any sense of many-electron atoms and molecules? Well it turns out we can hide most of the complexity by working out the rules for calculating these matrix elements. The matrix elements of operators that we care about, like transition moments, spin orbit, Zeeman effect. able to evaluate these matrix elements is the permutation requirement. And it turns out that there is a really simple way of dealing with the requirements for electron permutation, and that is to write the wave function as a determinant of one-electron orbitals. And that is the Pauli exclusion principle-- not what you learned in high school. What you learned is a small consequence of that. So if we can build anti-symmetric wave functions, we have aufbau, we can only put one electron in an orbital. can't-- just the question of indistinguishable electrons is such a subtle thing that you can't say, well, they have to be anti-symmetric. OK, so we know that the Hamiltonian has to commute with-- these capital letters mean, many electrons' angular momenta. And this is the spin, this is a projection of the spin. We know this is true because the Hamiltonians doesn't operate on spin. It's a trivial result, but it's a very important result. MIT professor in physics. He invented these things in 1929. So basically what Slater did is showed, yeah, you can do the necessary algebra to deal with any atom, and to be able to reduce an atom to a small number of integrals. And there are two ways of doing this. One is the truth, and one is the fit model. Now the truth is really boring, because you lose all the insights. And a fit model also tells you what are the import the actors. And maybe they're in costume, maybe not, but we can deal with them. when you go from hydrogen to helium, you can't solve the Schrodinger equation exactly. But you can do it really well, and it just costs computer time. And if the computer is doing the work, you don't really care. Once you've told the computer the rules, then it's off to the races. You can go have lives or you can goHave a life, and come back, and the computer will tell you whether you made a mistake and you're getting a nonsense result, or that you have the correct result. So what we know is this permutation operator, operating on any two-electron function, has to make P 2, 1, which has to be equal to minus. So there's only two possible eigenvalues. You can have minus 1 or plus 1. And the minus 1 corresponds to fermions, things that have half-integer spin, like electrons. The plus 1 corresponds, like photons, and vibrons, and other things. And actually, it's harder to construct a symmetric function than an anti-symmetric function. boson symmetry is less important in most applications. OK, so suppose we want to talk about something like this, the 1s, 2s configuration. A configuration is a list of the occupied orbitals-- not the occupied spin orbitals, which is a spin associated with an orbital. And so this two-electron thing can be expressed as a space part. And alpha 1, beta 2, and then we have minus or plus beta 1, alpha 2. And it doesn't matter, because you can permute rows or columns. write what is in my notes. OK, so this thing, this two-electron function, has two anti-symmetrized possibilities. One is a singlet, and one is a triplet. So s equals zero, s equals 1. We recognize this alpha beta minus beta alpha as the singlet spin state, and alpha beta plus betaalpha as the triplet spin state. And this wave function has the necessary spin symmetry and the necessary permutation symmetry. If, instead of two electrons, we have 1, 2 dot dot dot N, then Mr. Slater says we do this-- whoops. by N determinant. And the rows correspond to the electrons, and the columns corresponding to the orbitals. Now this, because of the properties of the determinant, is anti-symmetric with respect to permutation of any two electrons or any two orbitals, because it's really the same thing is permuting the electrons. And so this N factorial is a consequence of normalization, because when you expand an N by Neterminant, you get N factional, additive products of N functions. can reduce it simply by, instead of writing psi every time, just writing the state. But the best way to do this is simply to say-- this is just the main diagonal of the determinant. It conveys everything you need. Again, if you permute any two of these guys, any adjacent pair, the sign changes. And so you'll be dealing with the orbitals one or two at a time. And soon, you start to take this for granted. And it's a very simple thing, but it isn't. you're doing a huge number of tricks. Demonstrating that for a two by two, that what I asserted is correct, you can do that very easily. The goal is to be able to do the algebra in a way that maybe you can't describe to your friends because it's too complicated. But it is something that you can learn, and you can ask a computer to do it, and there are all sorts of intuitive shortcuts where you can look. And so we immediately know what our job is going to be. at a problem, and you could say, I understand. OK, so you're used to orbitals. And that's perfectly reasonable, because for hydrogen, we have orbitals, and there's only one orbital, and it could have either spin. We don't mess with that. But now we're going to talk about spin orbitals and that's just the combination of the name of the orbital with whether the spin is up or down. And the reason for this is it's easier to do the algebra. For every kind of orbital, an orbital that is a scalar, that doesn't depend on quantum numbers, that has a selection rule delta SO of 0. And the algebra for each is something you work out, and then you know how to do it. And I'm going to try to give you just a little bit of a taste of this. So we already looked at something like this. But we use a different kind of spin. We use a one-electron operator. And then we have our friend 1 over rij. That has aselection rule delta spin orbital of 2, 1, and 0. Stick diagrams are great, because it's easier to see on a picture, who are the actors, and have I included all of them, or have I left something out? And so now we're interested in the stick diagram for the 1s 2s configuration. And there are several kinds of 1s/2s configurations, depending on what the alpha and beta are. So there's four guys, and we can put our arrows on these things. And we know everything we need to know about these guys. It tells us what to do. Well, when we do this, the diagonal matrix elements of the 1 over rij Hamiltonian can be expressed. And we use this notation, J tilde minus K tilde. So for every two-electron thing, we're going to get this kind of-- now these are simple integrals, and some of them are 0. Because this doesn't operate on spins. So this tilde notation is a convenient thing, because you can use any Slater determinant, and you can express it in terms of J's and K's. In order to make an eigenstate of s squared or sz, you sometimes need two or more Slaters. When you have mismatched alpha and beta, the K's are 0. But when you have K, the 1 over rij matrix element between two Slaters, you can fix that. Now if you looked at 100 textbooks, I think 95% of them will have Hund's rules wrong. You're never going to get it right. But some things in life are worth suffering for. to make that mistake. And interpretive-- well, we want to be able to do something like what you did in freshman chemistry on shielding. Now you probably memorized some rules about what shields what. But I'm going to give you a little bit more insight into that. So we're going to talk about this for the rest of the lecture. OK, so you specify a configuration. And this configuration might be two electrons, two spin orbitals, two orbitals times e, or three, or 10. outside. And so you need some sort of a set of rules for how does that work. And that's shielding. So first, we specify a configuration. And you also learned-- in high school, probably-- how to determine the L, S, J terms that result from this configuration by some magical crossing-out of boxes. And if you didn't, I'm glad. Because it would have just clouded your mind, and caused earlier insanity than MIT causes. So anyway, so we have orbital angular momentum. And we can add the orbital angular momenta of the electrons following certain rules. the possible J's. Hund's rules is all about, of all of the states that belong to a particular configuration, which one is the lowest? One-- which one, not the second lowest. And why do we care? Because in statistical mechanics everything is dominated by the lowest energy state. And so if you can figure out what is the low energy state, you've basically got as much as most people are going to want. And mostly, you don't want to know the details. want details. OK, so Hund's rules-- you look at all of the L, S, J states that are possible for a particular configuration. And you can use the crossing out of ML/MS boxes if you want. And for example, if you had 2p squared, you're going to get singlet D, triplet P, and singlet S. If your friends tell you they want details, well, you tell them, this is what you have to do. But I'm an expert at that. well, here's the triplet. That has the largest S. The triplet P is the lowest energy state. Now if there were multiple triplets, as there would be, say, for 2p3d, then you'd have to decide which of those triplets was the lowest. And it's the one with the maximum L. And then the last step is, what's the lowest J for that LS state? And that's kind of cute. Because you have the P shell, there's-- for a P shells, you can have six P orbitals to fill the shells. L minus S, absolute value. If N is greater than 3, you have the lowest being. The highest possible value of J is equal to L plus S-- so for L, N greater than3. When you have a half-filled shell, the lowest state is usually an S state with maximum spin. But it doesn't matter. Hund's rules tell you how to identify, without knowing beans, what is the lowest. It doesn't have a spin orbit splitting, and it just has one value, which is whatever the spin is. energy state, and it's never wrong. Well, maybe sometimes wrong, but that's because of one of my things where you have a perturbation between states belonging to two configurations. But people get really excited when they discover a violation of Hund's rules. And it's just trivial. So there is this. What time is it? I have a few minutes to talk about shielding, and I will. OK, so we have a nucleus. and it has a charge of z. And so if we penetrate inside of it, what we see is only the plus z, minus the number of electrons inside this sphere. Z effective is a charge that is dependent on distance from the nucleus. It goes from the integer value that you know, from the atomic number, down to 1, because you've taken one electron away from a neutral atom, and taken it outside. And so beyond r0, the charge that you see is plus 1. Add 0, you see a charge of z, and so what ends up happening is you get z effective. And now we have this wonderful thing called the centrifugal barrier. we have a state that has a non-zero of l-- well, if we have a zero value of l, it can penetrate all the way into the core, to the nucleus. And the larger the l is, the less it can see this extra charge. So high l's are very well shielded, low l's not so well shielded. The shielding goes s least shielded, p, less, so on. Now there's some other interesting things. Which, you know, I hate to say this, but comparing 5.111 or 5.112 to 3.091, there is this business of what happens. shielding arguments are capable of explaining that. OK, so this is the end of atoms. And I've asked you to observe some complicated algebra which you're never going to do. Everything you need to know about atoms, you can tell a computer, and it can do it. Now molecules are much more complicated. And that's we're going to start on next time. We'll start with molecular orbital theory. I'm not going to be presenting the normal textbook approach. I'll present an interpretive approach, where you understand why things happen.

ROUGE-1: 69.13, ROUGE-2: 66.62, ROUGE-L: 65.16
BERTScore: 75.88

==============================================
==================== [41/100] ====================
Summary:
This is cereth registered nurse re and calm and in this video i'm going to be going over blood transfusions which will include the nurses role and as always I've been to this YouTube video you can access the free quiz that will test you on this procedure so let's get started what is a blood transfusion it is where as a nurse we will transfuse a patient who is low on red blood cells with new blood cells via a venous access of some type. This is most commonly done through donated red blood cell so a patient needs them. they're low on red blood cells and what can cause a person to be low on Red Blood Cells. Red blood cells are very vital for our survival and how our body works so in other words our body can't function very well without them so what a red blood cell do with the help of the body. What can happen in conditions like renal failure cancers just to name a few because the body is not producing enough substances to produce or maintain those red Blood cells now what's the importance of red Blood Cells? hemoglobin it carries oxygen it receives from the lungs throughout our body in addition it removes carbon dioxide co2 and it will take that take it to the lungs so the lungs can't exhale it. Whenever your patient is low on red blood cells they're going to have some side symptoms that can present especially if they're really low they'll be very pail. I've seen patients they literally look white as a sheet before the transfusion and then after they've had a transfusion their skin color is back to where it should be. be tachycardic because that heart is trying to pump that blood because consents of the oxygen is low so it's like I got to get more blood everywhere else so it can overwork itself so when is a patient transfuse well this really depends depends on what's going on with the patient their vital signs how are they tolerating that low blood level and recent guidelines by the American Association of blood banks recommends transfusing blood when hemoglobin levels fall to 7 to 8 grams per deciliter. Nursing lecture exams but you need to know it for the job okay the first thing before a patient is even transfused is a lot of prep work that is super important and essential because our prep work helps prevent transfusion reactions. Most hospitals require that you're a registered nurse in order to transfuse the blood so again follow your Hospital protocol with that so let's say you got an order for patient to be transfused with two units of packed red blood cells what's the very first thing that's going to be done. whole video where I went over that in depth with you and you can access that and take a quiz that can test you on that. You'll want to get informed consent tell the patient what they're going to be receiving assess their understanding of it also this is a good time to ask about their allergies and if they have received any blood transfusions in the past. If you have received a lot of blood transfusion in the the past they're at risk for febrile nan hemolytic transfusion reaction where their body has just built up these antibodies. and things like that so a lot of times physicians like to pre medicate them and you'll want to let the physician know if they do have a history of that. Sometimes they're pre-medicated with benadryl or Tylenol acetaminophen before hand orally or when about 30 minutes before you start the transfusion. Look at the health status of your patient are you giving a patient who is in fluid overload or congestive heart failure has renal failure and but they really need blood you need to be looking at that because they may be at risk for circulatory overload. You typically want an 18-gauge or larger IV site. It takes anywhere between two to four hours for a unit of blood to transfuse. You use special tubing which is called Y tubing with an inline filter which helps filter some of those substances out of the blood before it actually goes to the patient and keep in mind again it depends on hospital protocol a lot of protocols say only one set of Y tubing per unit that you transfuse so you'll have to use multiple sets. next you'll want to grab a bag of normal saline 0.9 percent ofnormal saline this is the only only solution you ever use whenever transfusing blood you never use any met other medications or any other fluids only saline. Because dextrose and red blood cells don't get along it can cause them to clump up together. We will be using that saline to prime that why tubing whip and then to flush that tubing with afterwards once the blood is done transfusing and in addition just whenever everything's wrapped up you're ready to take that tubing down you'll need to get a red biohazard bag to dispose of it properly. Trash now let's talk about transfusing okay done all your prep work the blood bank calls you and says hey your blood is ready let us know whenever you're ready for us to send it to you because they're keeping it refrigerated for you. Some key things you want to remember you will be giving one unit at a time patient needs two units you're gonna give one unit now and then whenever that's done call blood bank and say send me the other unit and then they'll send it. notify the blood bank whenever you're ready to start that transfusion now blood wormers blood warmers can be used if the patient needs large amounts of blood quickly and they're at risk for experiencing hypothermic response so you're not gonna warm the blood up by using a microwave or anything like that you want to use a special device if need be next before you even start the transfusion you're gonna be doing this verification process so as the nurse you're going to be getting another nurse it's usually to our ends cuz ourian's are usually the ones who can transfuse. matches up perfectly you're gonna look look at the patient's blood type versus the donors tie and the Rh factor. If there's a discrepancy you'll need to notify the blood bank immediately and just from personal experience this has happened with one of my patients I was doing the whole verification process with another nurse and we were looking at the blood bag. There was one letter that they had did a clerical error on so I had to send the blood and we had to go to the hospital. through the whole process again so this does happen so always make sure you verify everything also before transfusing you're going to be getting baseline vital signs which is going to include the temperature the blood pressure respirations and heart rate. If you have a temperature greater than a hundred degrees Fahrenheit you'll want to notify the physician and make sure they just want to still proceed with the blood transfusion then again before you actually transfuse you want to explain to your patient if they're alert and oriented they can talk to you what you're about to do and for them to notify and report to you if they feel any of the signs and symptoms I'm fixing to describe. breath headache backache or nausea and vomiting and if this happens you'll immediately want to stop the transfusion okay now it's actually time to start the transfusions so you're gonna have your blood ready hung and it's going to be controlled by an infusion pump which will deliver it to the patient. You want to start  slowly about two milliliters per minute for those first 15 minutes in addition you want to stay with that patient at their bedside looking at them monitoring them. of different reactions the patient can have and here in a moment we're gonna go in-depth over those but it's where the recipient that patients immune system is interacting with the donors blood. You can have a hemolytic transfusion reaction where what's happening is that the patient's blood and the donorsBlood are not compatible. This is dangerous it can lead to death also allergic they can have an Astra cry this because this tends to happen days two weeks after a blood transfusion it's rare and it's deadly. any patient that's at risk for whenever you put extra fluid volume in their blood they'll have trouble with it. Patients who have heart problems like congestive heart failure their heart muscles weak and you just throw that extra fluid in it it can't do well with it so the fluid starts backing up into the lungs and into the tissues. Also patients who have renal failure you know these patients need blood but their risk for being able to tolerate all that fluid going in there so you want to keep that in mind. A 418 is your patient saying I have a backache all of a sudden or I'm having chest pain or my head is hurting that's a red flag c-4 chills t4 tachycardia especially if it's really increased from baseline I for increased respirations same thing with that increase from baseline oh for all glory so you really want to be looking at your patients urinary output during this blood transfusion and you want to remember those major signs and symptoms of a transfusion reaction. after are they putting out low or are they just putting out no urine at all are they an Urich and then look at the color what does it look like are they experiencing a condition called hemoglobinuria where there's free hemoglobin in the urine it will have like this purplish color so watch the earring closely and then in for nausea GI issues like diarrhea then when the transfusions done your patients tolerated it well you'll want to flush that remaining blood out of that line with that saline that's hanging on that Y tubing. hemolytic this is where the immune system is killing the donors red blood cells. antibodies in the recipients blood match that antigens on the donors blood cells so hence they've been missed tight. This can lead to di C and renal failure and even death and a lot of times what's going to happen is you're gonna see a fever chills anxiety back pain chest pain hemoglobinuria where you have that purplish look to the urine. Another type is called allergic and this isWhere the recipients immune system. is reacting to the proteins found in the donorsBlood leading to like rashes hives and itching. someone's having an anaphylactic reaction to something another type is febrile and this is non hemolytic so you don't have the breaking up of those red blood cells. This is where the recipients white blood cells or reacting with the donors white blood cell. This causes the body to build antibodies so you can see that increased temperature like one degree Celsius or one point eight degree in Fahrenheit from the baseline. Another transfusion reaction you can have is the GVHD. graft-versus-host disease and again like I said this is rare but it's deadly and it tends to occur days to weeks after the transfusion so this is where the donors T lymphocytes cause an immune response in the recipient but actually in grasping in the marrow of the recipient and attacking the recipients tissue. Other complications that can arise that really aren't immune related it's like septicemia where the blood is contaminated. There can be a risk for hepatitis B C or HIV etc also that circuit or e overload we are talking about or developing high iron levels and this happens with people who've had frequent blood transfusions. it in the back of your mind so the first thing what you want to do is stop the transfusion. Note mentally what time this occurred what time you stopped it because you'll be documenting this later on. disconnect the blood tubing at the access side and replace it with new tubing and have some point nine percent normal saline running to keep the vein open then you're going to notify the doctor and the blood bank of what's going on. During all this you'reGoing to be staying with the patient at their bedside you need be watching them you need your eyes on them so this is a great time to call in other people on the floor. signs every five minutes looking at them watching them looking at that respiratory status it's not compromised or they have an allergic response what's going on now whenever you contact the physician depending on what type of reaction they suspect the patient's having or how severe it is they may order some medication so it varies some things they can orders like corticosteroids which is going to suppress that immune response along with fluids helping flush out that free hemoglobin that's in the body getting it out we want out of the body. diuretics also some labs are going to be ordered they want to look at those claudine levels because remember if this is hemolytic type because a lot of times they don't know what type of reaction this patient is having. Look at the renal function how's our kidneys and other blood levels in addition you'll be collecting urine urine urine on them looking for the free hemoglobin that's came from those red blood cells I have lysis and whenever you are disconnecting your tubing over here do not throw it away don't throw any of it away. bank who's going to test it look out and see what went wrong. Of course you're going to document you want to document the time it happened. What actions you took what the patient was given if you gave them anything. What labs you drew all that and how the patient is currently doing okay so that wraps up this review over blood transfusion. thank you so much for watching don't forget to take the free quiz and to subscribe to our channel for more videos. Back to the page you came from.

ROUGE-1: 70.10, ROUGE-2: 68.05, ROUGE-L: 68.36
BERTScore: 80.06

==============================================
==================== [42/100] ====================
Summary:
Markus Klute: Why this is an important discussion is because it is very convenient and it simplifies life quite a bit if one does not use SI units. And it's also important to avoid carrying around large exponents. And one example is the introduction of a new unit for the cross-sections of-- units for cross-section which describes an area, and that unit is barn. We talk about cross- Sections of barns, or femtobarns. One bar is defined as 10 to the minus 28 square meters. The unit came out of the Manhattan Project. The idea of the scientist was to confuse potential spies towards what cross-sections for nuclear processes are. One barn is a cross-section where it's really, really hard to miss. In this context, also, the shed was introduced. This is not very popular today anymore. And it turns out that this idea of confusing readers of papers or of discussions turned into a new standard. So we have a new unit of a barn, and they're trying to characterize nuclear collisions. In particle physics and in nuclear physics, we use a system called natural units. This system is based on fundamental concepts of quantum mechanics and special relativity. The idea here is that we replace kilogram, meters, and seconds by h-bar, which is a unit of action in quantum mechanics, c, the speed of light, and GeV, where GeV is a typical approximate mass of a proton. That means when you talk about relativistic equations, E, you find that energies are expressed in GeV. equals m c squared and all those things, m, E, and also the momentum have the same unit. That simplifies quite a bit. You might think that you lose information by setting fundamental constants to 1, but you actually do not, because you carry with you, in your equations, the dimension of the problem. If you want to do a quick exercise here, I invite you to calculate the charge radius of the proton, which is 4.1 over GeV, or per GeV. equal to 0.197 GeV femtometers. On top of this, it's useful to use Heaviside-Lorentz units and combine them with some measurable units we discussed. In some examples, we'll use SI, in others, use natural units. So this is also very convenient, to have this kind of convention. We'll use those natural units as we go through class. So you should already know the answer from previous discussions in the lecture, but the calculation is rather straightforward. always be clear from the problem we're looking at. Always be clear about what you're trying to do. Always show us how you're going to solve a problem. Always. Show us how to get to the solution you're looking for. always. show us the way to get there.always. be clear of the problem you're aiming to solve. always be clear. of the goal you're seeking to achieve.always be. clear of your goal. of getting to the answer you're after.

ROUGE-1: 71.96, ROUGE-2: 64.51, ROUGE-L: 59.94
BERTScore: 74.65

==============================================
==================== [43/100] ====================
Summary:
The planet is kind of a storage device. It's an energy storage device for that thing over there, right, and so like if you think about all the energy flows that go on on planet Earth, well, then you've got-- there's a picture I like. It kind of shows you the different energy flows, right. You've got the sun, so you'veGot like solar radiation. There's the tides, there's the sun. You're in the solar system. moon, you've got wind. You've got all these kinds of energy happening on the planet, all the way down to life happening, rock formation, right. And then sometimes those things, you know, rocks can form alloys over millions and millions of years. The problem is that it's like 10, 20, 30 million year old sunlight, right, and it'll happen again, but the question is how do we store energy on timescales that matter to us? And so you can draw this line and then think about what that means. Electricity is more and more important in our lives, and if you look at just sort of like the major sectors, so you have the power generation, transportation, industry, you have buildings, and this is a plot of these sectors and the CO2 emissions. OK, so now why electricity? Why electricity, right? And so we get to sort of how do you think about storage technologies, and again, I just want to kind of gently introduce us to energy storage and we'll go into batteries. would be like, I've got energy storage technology and it's got this much density, this much power-- well, then it's going to last if I use it at that power for 41 days and so forth. Why don't I just want high and high? That sounds like a good thing, right, so shouldn't we be pumping water up hills all over the place? Well, obviously, if you think about it, you don't do that in your phone. You don't evenDo that in a town. Why? Because pumped hydro is extraordinarily limited. very constrained, so we can't use this in most applications, pumped hydro. Compressed Air, CAES. That's got a whole lot of limitations as well. We've got, just to give you the abbreviations, Superconducting Magnetic Coils. Superconducters, right, just keep it going. And then you draw the [MUMBLES] and it just keeps going forever. All of these things exist. They're interesting, important, electrical energy storage devices, right. rotating something heavy really, really fast. I don't want to be in that building, but they do build flywheel energy storage device where you slow it down and then you generate electricity from that. So these kinds of plots are really,really, really helpful for comparing one energy technology with another. Now, the thing is as I said, there's a whole list of these and it goes on and on. They've all got a lot of limitations, all right, and so capacitors have a low density. You can convert energy into some fuel and store it and then combust it. That's got low round-trip efficiency. There are challenges there too. There is an advantage about using electrochemistry. It's the relationship between electricity and chemical reactions. We're getting to the point where we're electrifying everything. We need electricity almost everywhere, even in your combustion car. You need electricity a lot more than you used to, than 20 years ago. And so as we electrify our society, we need to make sure we have the right technology to meet the needs of our society. And this isn't just one type of thing, it's this broader definition. The second law of thermodynamics makes you pay a penalty of energy if you convert it into heat and then back into electricity. A power plant gets up to a higher temperature so the penalty is less, but still most power plants, you lose about 50%. Most power plants at best are around 50% efficient in terms of converting the thermal energy into electrical energy. electrochemistry is another way to do it. That's how we power most of our world today. And it's one of the reasons why electrochemical. energy storage is so appealing, because you don't really pay a penalty. I can go back and forth without the second law hurting me. Averill has a beautiful chapter on batteries, chapter 19. I'm sure you know. It's really well written. This is what he says about entropy, though, and for now we can state that entropy is a thermodynamic property of all substances that is proportional to their degree of disorder. So people people people, let me ask you guys a question. Entropy is not about smoothness and it's not about disorder. Entropy is about accessibility to states. A messier room does not have higher entropy, and in this case, it's just simply the rules of the algorithm. It's about how many states you have to be in. Now, that can appear to be like disorder, right, but a messier Room does not has higher entropy. I love that you guys are blown away. I have rules here about entropy. the dots being able to touch each other. That means that those dots had fewer possibilities. They had fewer states that they could be in. This system has much higher entropy. It's about the number of states. There's a lot of reasons why this is so appealing. No penalty on the second law of thermodynamics is no penalty on second law is. There are a number of reasons electrochemical storage is a good idea. It can be used to store energy in a variety of ways. one of them. You can have transport easily, right. We drive electric cars. We see that. No pollution at the point of use. Also, the batteries can be charged by renewable technologies like solar wind, and they're very highly efficient. Electric cars, for example, have a very high efficiency depending on the car, but upwards of 90% in terms of converting that electrical energy back and forth. These are the things that matter in batteries, but so many other things matter, and this is why this is a complicated problem. change not going from your computer to your phone but from your car to a grid. And so the needs are all going to be different, and then which ones of these things you care about is going to depend on what chemistry you think about. It all comes down to the chemistry as we're going to see. And just to put a few numbers down, the cell phone has a few watts of power. Light bulb is 10 to 100. Needed to drive a car 200 miles, 100 kilowatt hours. Powering your house, 40 kilowatts max. is this many watts as of a few years ago. So if you had, I think it's something like 20,000 billion AAA batteries, you could run the world for an hour-ish, something like that. These numbers are just fun to play with, so I wanted to put a few examples down. So where'd it all begin? It all began with an argument. And it was Galvani who was a physiologist, and he really loved the topic of why animals move. Theory of electricity was similar to theories for motion of the human body. Galvani wanted to make a connection between things that move and electricity. He hooked up his lightning rod to a frog. The frog was not alive. The motion of a frog, and all motion of all living creatures, generates electricity. That's what he said. He deduced that the motion itself is something that generates electricity, and that's how he came up with the theory. It was like, ah-ha, motion, electricity. little article about this debate, because in Galvani's case, if you have two metal wires hooked up to a frog, like we say, ifyou close the loop, then what he said is that the charge that was already in there moves around the loop and back and makes the leg move. Volta got really interested in this and he said, you know, let me study this. So I think this is about the metals, not the frog, and they had a big huge argument, right. win that argument, and we have the volt named after him, and he also created the first stable battery, the voltaic pile. Galvani on the other hand really opened the doors to the idea that we have electricity in our bodies, which is pretty cool. He also is the reason why the story of Frankenstein was written. It's actually true because they went around and took all sorts of things and electrocuted them and showed that they moved, and often they weren't alive. Mary Shelley, I think, saw that. There's over a billion people who can't read at night because there's no access to electricity. $25 billion liters of kerosene are used to meet the needs of the world's population. This is already making a big difference in millions of people's lives. You just press this and you can reading at night, right. That doesn't happen unless you've got electrochemical energy storage, right, and there's some stats up here. It's a really cool program. basic lighting needs in a lot of these places. That releases tremendous amounts of toxic fumes, and you can make a huge difference. So the challenge is, but you don't cook. If you have a solar cooker, that's great except that most people don't cooking during the day. They cook at night or in the morning, right. And so you've got to store energy to make these things actually useful, right, and I really like this program so I wanted to make that one of my, why this matters. lots of metals. That's what he did. And he showed that the frog moved with most of them, so it's the metals. So let's take these two classic metals and show what happens. You've got copper and you've got zinc. Now, in this case, I'm just going to have a zinc piece of metal, and this is a piece of zinc, and I put it in a solution of copper ions. So what happens is there is a transfer of electrons, right. in solution plus copper solid. That's the trading. Now it turns out that when something loses electrons like that we call it oxidation, and when something gains electrons we call this reduction. And so when two different materials-- in this case, these two metals-- trade electrons and one of them is oxidized, that's also got a name. It's called a redox couple. Those are a redot couple, redox, Redox, right. So these are aredox couple, is what they're called when you trade electrons. like this. OK, so what's happening? What's happening is at the surface of the zinc, I see these copper ions in solution. And it's like, well, if I gave you two electrons, then you'd be able to become a copper solid, right. If I lose two electrons as a zinc atom, I'm a zinc 2 plus. That's this. Why does that happen? Well, we'll get to that, right, but that's what is happening. and the zinc is coming off of the strip. All right, why is that happening? Because if you put that strip in there and the thing just heats up, this is exothermic. That means that this reaction will go. This is spontaneous. Where can I write that? Nowhere. But all that's happening is you're going down in energy. You're giving energy away and you're heating up the environment. Now the question is, how can I not let that happen? How can I stop the heating from happen and instead take advantage of this electron trading to do work? Fundamentals of a battery is this kind of thing, but now instead of allowing this plating to happen, I'm going to construct it in such a way that those electrons get traded through some wire that I can do work with. So what you saw wasn't a battery because I wasn't stopping the electron flow and doing anything, but if you construct it like this, is called a galvanic cell. That's the difference. So let's go through this. So on the left, Zinc has zinc ions in solution, right. Now, copper, copper is in a solution of copper ions. On the left I've got zinc nitrate. In this case it's a nitrate, not a sulfate. It doesn't matter. The whole point of the solution is that I get these ions in a beaker. So you've got the copper ions on the left. Got to get these ion in aBeaker, so you'veGot the copper ion on the right. right with the copper solid and you've got the zinc ions. So let's look at what's happening and blow up those different sides, right. So the zinc is becoming 2 plus. What about those two electrons? Where do they go? A zinc atom leaves its metal strip and goes into that beaker of zinc ions, right? But now you'vegot two charges, two electrons on the strip because it left a zinc 2plus. Nothing more will happen unless those 2 electrons go. away. What's so cool about batteries is that it's all about neutrality. If I just build this charge up here, I can't have another zinc atom go in so the charge has to go somewhere, but that's what that wire is for. This wire allows the charge to go over to the other place, the cathode, where the copper is sitting there saying, you know what, if I had two electrons on the copper strip then I could use those as a way to lure in a copper 2 plus ion, right. right here. It's the same thing that we just did with the plating except now those electrons are going through this wire up here. The zinc is trading electrons with the copper. That's keeping this neutral, so now the electrons go away and now another zinc can go into solution. Then the copper grabs them, plates a piece of copper, and then more electrons can come, right. This is what it looks like. If you take those electrodes out of the solutions after running this for five, 10 minutes, look at what happened. Just one other piece of it that you've got to understand to understand how a battery works, and it's this thing here. This is called a salt bridge and that completes the circuit. See, this lets the electrons flow. This gives ions. It doesn't matter what it is, right. That's the electrolyte. It's just a source of ions. Here is an ACL, so now for every copper 2 plus that plates onto the copper electrode, two NA plus atoms go into this beaker from the bridge, because here I've got dissolved salt. Dissolved salt, sodium chloride is in water, so I got all these sodium ions. have lots of items on the table tomorrow maybe at a dinner, and I'm just suggesting that you play around with this idea, because look. This is literally what the name of that device, the guy that that's named after, this is what he did. He hooked up two different metals. I just put some paper clips in there, it works. It can be almost-- not almost, but lots of different metals will work. We'll get to that in a sec. The power isn't coming from you as Galvani thought. No, the power is coming from the difference in potentials of those metals wanting or not wanting electrons. Just that now we're talking about the metals and whether they're more interested than the other metal in having those two electrons. That's what a potential is. And you know, when you look at this, you might say-- this is from Averill so he actually is missing the f's because this is just taken right from the textbook, but anyway, so that's the potential. Look at this. This is like an energy diagram but these aren't electronics. These are just potentials, but the potential is related to which one wants the 2 electrons more. is yes, but I'm taking 2. I'm not taking 1, I'm talking about the oxidation state of 2 plus. That's going to be harder here. It's harder to take a 4s1 in a 3d from that beautifully filled 3d shell than it is to take these 2s electrons. So what you can see is that the potential difference is all about chemistry, right. The delta v is allabout the chemistry. It is more than that because of these solutions, so it's more complicated than that. here would be 1/2. And you can sort of look at the table and think about why that is. Cobalt has a 4s2 but it's got less d electrons, and so is it going to be easier or harder to pull them out? Well, it's going to been easier than copper but harder than zinc so it goes in the middle, right. And so the potential difference is less for cobalt and zinc but you still get a potential. And that's what Volta did, and he did all sorts of different metals. The standardization in the world of batteries is hydrogen. You can only get the changes in potentials. You could write reduction, you could write oxidation. They're just a flip of the sign, right. It's just a flipped sign of the potential, but what you write these down with respect to a common electrode, and it's the standard. it's called the hydrogen standard. It doesn't matter. I'm not going to go the other way, right, so nothing happens when you do that. standard hydrogen electrode. So sometimes you'll see it as the SHE in the battery world. And what it is it's just a very nice platinum electrode that doesn't change. So it doesn't plate or lose atoms. And it's a reaction that on that electrode happens with hydrogen, hydrogen gas. And so what you do is you hook this up on one side, and then you put all the metals against that. And you measure their potential. So hydrogen electrodes gives you that ability to standardize it and create huge tables. The Nobel Prize was given to the development of lithium ions as a storage technology. A lithium battery works much the same way in the sense that you have the separator here. That's the electrolyte. But now it's rechargeable. All the chemistry is the same. You're shuttling ions back and forth. You've got that external circuit. And there's a whole bunch of chemistry. So what has exploded in the last-- well, that's a bad word for batteries because that is a danger with lithium batteries. This is the grid now. So we went from small to very big. The growth in solar and wind has been incredible over the last 10, 20 years. The problem, as I think I've shown you, is the variability. And so here's the question. I said, well, OK, how do you fix this? You got to store it. There's no way to use it. And that was my last Why This Matters in the last 2 and 1/2 minutes. renewables at large scales unless you store it. In fact, we're really at essentially the tipping point. If you look at-- this is Germany, now. Huge penetration-- these are these six years, seven years of adding PV. They're now at 7%. 2016 is 7%. This is how much the price of electricity was in Germany when they added. They can sell it for a lot of money. But as they add more of this renewable to the grid, its price goes down when it's available. need. So that's a real challenge for chemistry. I hope you guys have a great Thanksgiving and maybe hook up some different metals. And I'll see you all next week. Back to the page you came from. Follow us on Twitter @CNNOpinion and @cnnireport. Back To the pageyou came from, back to the CNNOpinions page.Back to thepage you came From. Back from the CNN Opinion page. Back in the page, click here for the latest from CNN.

ROUGE-1: 60.02, ROUGE-2: 57.05, ROUGE-L: 55.74
BERTScore: 74.67

==============================================
==================== [44/100] ====================
Summary:
We are going to start talking about the optimization perspective in deep learning for two lectures. And here, I guess I'm going to explain what optimization landscape means. It really means the surface of the loss function, but I guess you will see. So we're going to introduce some very basic things about optimization, but the main focus is to analyze what the functions you are optimizing look like so that you can use some trivial or some standard optimization algorithm for it. So you don't need any background about optimization. need to know what gradient descent is. The bigger question we are trying to address here is that why many optimization algorithm. are designed for convex functions. But why they can still work for nonconvex functions? So why they could still work and actually, pretty well in practice for non-conveX functions in deep learning? Note that it's not like these algorithms, like gradient descent or stochastic gradient descent, can work for all functions. It's just a way to get around the problem. In machine learning, there are atypical case or outliers, whatever you call it, especially if your parameterization of your model is very complex or kind of somewhat weird. For example, if you have a very deep network, like a feedforward standard deep networks, then it's actually pretty hard to optimize. However, some of these are solved by changing the architecture, which changes the optimization landscape. Anyway, Anyway, Some of These Are Solved by Changing the Architecture, which Changes the Optimization landscape. In most of the cases, people observe that nonconvex functions in machine learning can be optimized pretty well by gradient descent. And we are trying to understand why we can optimize reasonably well. So that's the question. And maybe just before talking about more details, let's first quickly review kind of like what gradient descent is just in case. This is very quick. So suppose g theta is the loss function. And the algorithm is just something like sets 0 is some initialization. And you have something like theta t plus t. 1 is equals to theta t minus eta times the gradient of g of theta. This is gradient decent. And you can have stochastic versions of it. Many of you probably know them. And I'm going to list a few facts just to kind of motivate the discussions here. So maybe let's call it observation. The first observation is that so GD cannot always find local mean or global minimum, right? This is for continuous functions,. This is kind of obvious. Because depending on where you initialize, depending on how the function look like. And gradient descent will go rightward. finding global minimum of general functions, general nonconvex functions, is NP-hard. This is just really saying that it's computationally intractable to find global minimum. So clearly, you cannot hope that gradient descent work, you know, in the worst case for all possible nonconcex functions. So observation two, actually, this is a theorem. But just to clarify what does that mean, that means that there there is no such thing as a "global minimum" Exists a function that you cannot solve. But it doesn't really mean that there is no subset of functions that you can easily solve, right? So for example, a convex subset of function can be solved in polynomial time. So gradient descent can solve convex functions, as I said. And I guess the observation four is that objectives in deep learning is nonconvex. This is probably not entirely trivial. It's almost trivial, but not altogether trivial. But I'm just saying, for most of the cases inDeep Learning, for example. stochastic descent or gradient descent seems to work pretty well. And why they are finding the global minimum? So you know that because you know the loss function is nonactive, right? So suppose you run ImageNet or you do some kind of vision experiments. And you can see how small the loss SGD or GD can get you. And often, the lossfunction is pretty small, something like y minus 2 or something like that. Or depending on whether you use regularization sometimes it could be y minus 4, y minus 5 depending on the situation. or the intractability of optimizing nonconvex functions. So the way that can reconcile this is really just that the lower bound, the impossibility results, is about worst case functions. But actually, we didn't identify all the functions that we can solve. There are actually more functions than convex functions that gradient descent or some other algorithms can solve, and that's a slightly larger family in between. And today, we are going to talk about these kind of functions. And two, we're going to prove that, as for some special-- some of the loss function, in machine learning problems belongs to this set we just identified. The results, they're actually, in some sense, kind of intuitive. But they do require a lot of backgrounds to talk about details, right? So that's why we don't focus on that. We mostly focus on the second part, which is more about the statistical properties of those functions used in machine learning. The first bullet is to show why I SGD can solve this set of functions. But I guess I would tell you what people can show in the first bullet, along the line of first bullet. simple.simple.com: So basically, you say that-- so you know that gradient descent can find local minimum. This is somewhat easy to believe, but actually, there are some caveats about it. We need to characterize when you show that the functions we are actually using in machine learning are solvable by GD and SGD. We are going to identify the set of functions that we aregoing to identify to besolvable byGD andSGD is just a set of Functions with the property that all local minimum are also global minimum. have this property, right? Of course, not all problems have this property. We're going to show some very, actually, simple cases where we can prove this. But I guess, as I mentioned, there is some caveat about whether you can even converge to a local minimum. So this is actually somewhat nuanced. So I'm going to formalize this converging to aLocal Minimum. But, of course, I'm not going to prove any of the theorems here. So the next part is the convergence to local Minimum. this in calculus class, right? So x is a local min of the function f if there exists an open neighborhood-- let's call it n-- around x such that, in this neighborhood n, the function value is at least fx. So that's the definition of local min. If x is the local min, it means that the gradient of fx is 0. The gradient square of the Hessian of f is PSD. So these are necessary conditions for being a local minimum, but not vice versa. that makes it tricky because then the higher order gradients start to matter. And when you look at this-- and once it becomes about the third order derivative or fourth order derivative, things becomes much more complicated. So that's why local minimum is not only always a property of the first and second order derivative. And there's a theorem, which is the following. So the theorem is that verifying if x is a local minimum without any assumption of the local minimum of f is actually NP-hard. NP-hard. So I've told you that finding a global minimum is NP-hard, but actually, finding a local minimum is also NP- hard. So we have to consider these kind of pathological cases, which makes things harder, right? So how do we proceed? So the way to go beyond it is that there is a way to also remove some of the pathological cases as well so that you can find a local Minimum in polynomial time. And then we can. execute our prime. So this is what will happen. So here is a condition called strict set of conditions. And if you certify the condition, then you remove those pathological cases which requires high order derivatives. So-- sorry. Strict-saddle condition-- so in some sense, I guess I'm not sure whether this makes sense before I define it. But generally, you are basically saying that you want to rule out this kind of somewhat subtle possible candidate of local minimum. So there's no set of cases in your function. I think I wrote a book chapter about this kind of optimization thing for our book. So I can send that to the person who take the Scribe notes. And that probably help you to have some references. But the materials are not exactly the same as the book, so you still have to do the Scribes kind of from scratch in some sense. OK, cool. So the definition of strict-saddle, I'm citing this paper. The very, very original paper that introduced this term and this notion is by Rong Ge, et al. is the definition. So we say f is alpha, beta, gamma strict-saddle if, for every x in RD satisfies one of the following. So the first one is that, for some of the x, it just satisfies that fx, the true norm of x is larger than alpha. And the second thing is that the Lambda min of the Hessian at x is less than minus beta. So if you satisfy this, you cannot be a local minimum because your Hessian is not positive semidefinite. Theory: If you are just given an arbitrary function, differentiable functions, you should then be able to check whether it satisfies strict-saddle, right? It should be as hard as finding a local minimum in some sense. Theorem is somewhat kind of like informal just because I'm not-- it's pretty formal in the sense that all the bounds are correct. Then many optimizers, for example, GD, SGD, if you use the theorem, can be used to solve the problem. written word correctly, and many other articles, like cubic regularization, I guess many algorithms can do this. So far as can converge to a local min with epsilon error in Euclidean distance in time poly d-- d is dimension-- 1 over alpha, 1 over beta, 1over gamma, and 1 over epsilon. So this theorem is very coarse-grained. Of course, different optimizers have different convergence rate. But at least for the purpose of this course and this lecture, we are not interested in which one is faster. We are mostly just interested in whether it's polynomial time versus exponential time. Strict-saddle is just because the pathological case is a saddle point, right? So when you have these kind of cases where the gradient is 0 and the Hessian is PSD, but not strictly positive semidefinite-- so you have some direction where you can potentially have a negative curvature. This is called cubic regularization. Cubic regularization is a type of strict-s saddle. It's a special kind of strict saddle point. So in some sense, this explains the name for this. one of the early work in 2006 by Nesterov. But there are many other optimizers. Many other people published papers on this. I think I can add more references in the Scribe notes, in the final Scribes notes, to cite some of the recent works. So basically, the next theorem is trying to say that-- are global and you have the strict-saddle set of condition, then this means that optimizers can converge to global min. I guess I'm writing it a slightly different way. Just in some sense, I unpack it a little bit. thought that this either provides a slightly different way of thinking about this, or it's just more explicit. So basically, you say that you assume the strict-saddle condition, but let's rephrase all local minimum global strict-Saddle condition like this. So you say there exist epsilon 0, and tau 0, such that, if x in RD satisfies, the gradient is small at the epsilon and the Hessian is larger than minus tau0. somewhat big, almost kind of larger than 0. So then, actually, it's close to a global minimum of the function f, right? So this condition is just a slight different way to say that you have all local minimum global and strict-saddle together, all right? And then I know this condition. Then optimizers-- again, the same set of optimizers which can converge to local minimum. All right, so it's not a big deal. Many optimizers can convergence to aglobal min of f up to, say, delta-error and Euclidean distance in time poly 1 over delta, 1 over tau 0, and d. exactly the thing that we did for the strict-saddle. But if you think about it, it's basically the same statement. OK. Anyway-- so cool. So we are basically done with the first part, so about identifying the subset of functions that are easy to optimize. But these are all local minimum, global minimum functions. And next, we are going to show some examples where these kind of properties can be proved rigorously for machine learning situations, but these examples are pretty simple. They are not deep learning. do linearized network, there is a little bit more things to do beyond that. And the second example I'm going to give is matrix completion. This is an important machine learning question by itself as well, right? So before deep learning, this was one of the most important topic maybe in machine learning. And now, still I think it's used in the recommendation system. So we're going to talk about that. OK, cool. So any questions so far? I guess let's talk about PCA first. The best rank one approximation is basically the Eigendecomposition or the singular value decomposition of the matrix here. Just for simplicity, let's also assume this matrix M is symmetric. And this becomes a nonconvex objective function because you have a quadratic term here. And our goal is to show that, even though it's non Convex, all local minimum of this g are global minimum under the assumptions that we have mentioned, so like rank one, PSD. so one dimension. So d is 1. Then you just have a scalar, m minus x squared squared. This is our function, g of x. And you plot this function. This function looks like this. And there are two local minimum. And they are both global minimum because there is some symmetry here. And if you have a higher dimension, it becomes a little bit more complicated. But generally, you have some kind of rotational kind of symmetry here to make this happen. You first find out all stationary point, the first order stationary points. And then you find all local minimum, and you prove that they are all global minimum. So basically, it's just more or less like we solve all of these equations and see what are the possible local minimum you can have, right? So gradient of x is 0. And what is the gradient of g of x? I'm not going to give a detailed calculation here. But believe me, this is equal to minus this times x. So this means m times x is equal to 2 norm fx squared times x, right? Because the three things together, the last two things, becomes the 2 norm of x squared. And that's a scalar. And this is a matrix vector application. So basically, this is saying that x is an eigenvector. So x is eigen vector, and x squared corresponds to eigenvalue. So the eigen Vector doesn't have a scale. So you first find out the unit eigenVector. me just specify all this. So this part just follows some intuition. So suppose eigenvalues are distinct even though we don't have to assume this. Then, basically, all the stationary points are of the form that x is equal to plus minus square root Lambda i times the eigenvectors. And now, let's look at which of these is a local minimum. And then we say OK, all of these are global, right? So ideally, we just want to say that only vi, the v1 thing, is the local. minimum because that one is also a global minimum. So how do we do this? And also, we don't necessarily want to assume all the eigenvalues are distinct. So there's the small thing to be done regarding that as well. So let's compute Hessian, right? So we need to use the Hessian. So here, it's actually not that hard. The Hessian is in dimension d by d because you have d parameters. Sometimes your parameters is a matrix, and the Hessians becomes a fourth. order tensor. And it's kind of very complex to be even just written down to just write down the Hessian. So here is a kind of a very useful trick and which actually also has some fundamental reasons that this is useful. So the useful thing is that, if you look at the quadratic form regarding the. Hessian and youLook at v transpose Hessian v or v in the part that was Hessian times. v, this is the quadRatic form related to Hessian, and this is much easier to compute. methodology also applies here when you talk about the Hessian. You just iteratively expand it, Taylor expand it into something like g of x plus some epsilon times some vector. And then if you have this, then this basically corresponds to v dot g square gxv. So if you apply these kind of techniques, you can get the. Hessian like this. So the quadratic form of the Hessia is equals to something like this, right? So we have to have this. And we know that the Hessians that are larger than 0 is equivalent to that. In many cases, you only care about a few special v's because some of v's are much more informative than the others. So you want to choose some informative v's to evaluate this formula so that you get some important information about what x can be. So it turns out that the v's that are informative here is the top eigen vector. By the standard results in PCA, you know that the best one-to-one approximation is the best approximation to the global minimum. top one eigenvalue-- eigenvector with the right scaling. So the second case is that x has eigen value, let's say, lambda, which is strictly less than lambda 1. And then because x is an eigen vector, also the eigen Value of x is orthogonal to the eigenevalue. So you know that x is Orthogonal because different eigenvectors with same eigenvalues will be orthogonally. There is no guarantee that two eigenivectors are always orthogona because they could have the same Eigenvalue. So 2 means that the first term goes away. So you get just x2 norm square is bigger than v1 transpose in Mvi. And we have a contradiction because this is contradictory with the assumption that lambda is less than lambda 1. So write that. OK, any questions about this? So, guys, maybe just a very quick summary-- so basically, this is saying that, if x is stationary-- by stationary point, it always means first order stationary point. So I'm not going to clarify that in the future. point and is x is not global min then moving in v1 direction. Because you have stationary point, that means your point is flat. So changing in v 1 direction wouldn't change it by a lot. It would lead to a second order improvement. And that's why it's not a local minimum. Because if you are local minimum, moving inv1 direction shouldn't give you any second order improvements either. So that's basically the gist of the analysis. All right-- so cool. so now, let's talk about matrix completion, which is kind of like an upgraded version of PCA. The setup is the following. We are given random entries of M. So we pick some random indices of M, and you review the corresponding entries. That's the only thing you know about M. And then the goal is to recover the rest of the entries, right? More formally, so you say that there is omega, which is a subset of the. entries, subset of indices of d times. And so in other words, you can assume M equals something like zz transpose. And z is in dimension d. P omega of A is the matrix obtained by zeroing out every entry outside omega. And everything that is not in omega, you'll make those entries 0. So we observe P omega of M. And our goal is to recover M.d. And why people care about this question a lot in the past, one reason is that it has this relationship. D.C. scientist: We need to find a way to solve the problem of how do we find the answer to the question "How do we solve the mystery of M?" with a recommendation system. So suppose you think of we have a matrix. And in one side, the columns are indexed by the users. And every user probably have an opinion about every item, right? Either they like it or not, so and so forth. But it's not like every user buys every item. So every user only buys a very small subset of the item. And that's why you have to recover all the rest of the entries to serve the users better in the future. matrix M, there is no way you can recover the other entries because they can be arbitrary. So that's why you have to assume that the matrix M has some low rank structure or some other structures. So maybe just to give you a quick kind of sense about how does this structure matters here-- so if you count the number of parameters, we have d parameters, right, to describe a rank one matrix of dimension d by d because you can just write it as xx transpose. it's unlikely it can work. So basically, that is saying that p is bigger than roughly 1 over d. And speaking of the objective functions, this is actually a pretty commonly used method in practice. So you just say I'm going to minimize this function that's called fx, which is defined to be that basically you have a parameterization called xx transpose. This is your target. And you want to say this matrix actually faced all my observations, right? So you are taking a sum over all possible observations. the only cases you know what the entries are. You know this Mij, and you minus this with xi times xj. So this is our prediction. This is our observation. And you take the square and take the sum over all the observed entries. And just to follow future notational easiness, actually you can write this as P omega of M minus xx transpose, right? Because this is the matrix. You're looking at error matrix, right, and then you zero out all of those that you don't know. convex transition methods and so and so forth. However, those methods actually often have stronger guarantees. For example, they have tighter sample complexity bounds. In practice, just because the convex transition takes too long time, people actually are using objective functions or methods like this. And that's why it's also practically relevant to analyze these kind of objective functions because they are, indeed, used in practice. All right, so our main goal is to prove that this objective function has no local minimum, all local minimum are global. this assumption. It may not sound very intuitive. I wouldn't spend too much time on it, but just let me mention it. So this is called incoherence assumption. And this assumption is necessary. People know it. I guess we assume, for example, we assume the ground truth has norm 1. This is with all this generality, just which is for convenience fix of scale. And then after you fix the scale, you assume that the groundtruth vector z-- so we call that [INAUDIBLE] zz transpose. the reason why you don't want that is because, for example, a counterexample is that, if z is just e1, then your M is just  e1e1 transpose. So basically, all bets are off. You have to see enough entries. So this incoherence condition is, in some sense, trying to rule out these kind of pathological cases. But I'm not going to talk too much about it. It's just for the formality. the theorem is that suppose p is something like poly mu and log d over d epsilon. Recall that we are in a regime that p is roughly 1 over d. And this is a poly factor in mu and also poly log in d, OK? And then we assume the incoherence. And then our local of f are when we are-- so actually, you can prove that they are all exactly global minimum. But for the moment, we only prove that the error will be exactly 0. also have strict-saddle conditions. You can also prove that. It's just that I didn't include it just for the sake of simplicity. And you do have to prove that to have the rigorous result. And if you don't prove it, you just prove that all local minimum are global. Sometimes you may get somewhat misleading results. So I think there is a paper that shows that actually, in somewhat weird cases, you can show very strong looking results. The reasons why they are so strong is because somehow, in that setting, you ignore the strict-Saddle, which is problematic. The answer is no especially if you look for a global property, like globally, all local minimum are global. I don't think we have any proofs for any real neural network models. I guess there is a proof for linearized network models, like all the activations are linear. If you have more than two layers, you don't have strict-saddle conditions. You have a lot of [INAUDIBLE] points. Otherwise, I think we are good today.take some questions if anybody has any questions. assume that the input are linearly separable, then there is a proof for this. And there are a bunch of other cases where you can have some partial results. Next week, in the next lecture, maybe the second half of next lecture,. I'm also going to give another result, which is somewhat more general. It applies to many different architectures, but it has other kind of constraints. First of all, it doesn't really show exactly these kind of landscape properties. It shows that these kinds of properties holds for a region, for a special region in the parameter space.

ROUGE-1: 62.31, ROUGE-2: 59.70, ROUGE-L: 59.14
BERTScore: 77.02

==============================================
==================== [45/100] ====================
Summary:
Iceland is one of the world's most active volcanic hotspots crafer has erupted 30 times in a thousand years and last blue in the 1980s. Scientists are now preparing to drill into it the is to learn more about how volcanoes behave so that we can better predict eruptions and also tap into a super hot source of energy. The plan is to drill just short of the magma itself possibly poke it a little bit the geothermal resource which is at Loc at the bottom of the volcano. just above the magma body we believe that is around 5 to 600Â° C just two ball holes of this kind could match the output of this entire plant. There is an obvious uh Game Changer and there's the exciting possibility a potentially Limitless cheap clean energy. This is a big part of how we are going to take geothermal to the next level and also of course a huge part in the green energy transition. At the University of Iceland lab work is underway testing materials to withstand extreme heat and pressure this is carpon steel. New materials and more corrosion resistant Alloys they're working with temperatures of up to 500Â° and corrosive gases. We have been focusing on highgrade Alloys nickel Alloys and also titanium Alloys but there's still one question I need to ask from the outside all this sounds you know just a little bit risky. Is it going to be safe to do this we believe that sticking a needle into a huge magma chamber is not going to create an explosive effect this happened in 2009 and they found out that they had probably done this a few times before without even knowing it. many other locations around the world where we have active volcanoes so this crazy sanding plan may actually have huge potential e. Many other locations in the world. where we has active volcano so thiscrazy sanding plans may actually be a huge potential. e. Back to Mail Online home. Return to the page you came from. Back To the pageyou came from, back to the site you came From. Click here to read the original article on The Daily Mail Online. Back into the Daily Mail home.

ROUGE-1: 59.28, ROUGE-2: 52.50, ROUGE-L: 53.09
BERTScore: 62.51

==============================================
==================== [46/100] ====================
Summary:
[Music] okay one of the things that we're trying to figure out is which one of these is one to do right so we know that we wanted to raise our axis efficiently as possible once the minimize of deadweight loss we also [Music] [Applause] their payroll taxes these attaches our wages and these are used to fund social programs so this would be things like social security insurance so we've got our taxes so so these are taxes on corporate incomes and all the money that they're making and where wealth taxes access people. people earn more income base they are attacked a smaller amount of smaller percentage of the rounding. People pay a small person their income tax as their income goes up so only if their income go down they're going to pay a larger percentage of their income. With the 4-channel it's the same so here you see people pay the same percentage whether progressive its detect ops as progressive people pay lark there and so it's not the dollar amount it's gonna be obvious that everyone is must and a larger dollar amount in taxes. Sales taxes are a regressive tax even though rich people buy more stuff I'm going to pay more and sales tax dollar amounts as a percent of their income it's actually usually profit or loss. This marginal tax rate is the percentage change in taxes any tax paid from some changing our average tax rate beer is just going to be tax paid so there's my tax rate's tell us how much additional tax event played based upon our so they so they.taxes redress property tax can be kind of course non-progressive can depend upon how many things that is your taxi in the race and things like that. go coming back to that they have passed out here we've got these marginal tax rates here with you guys. Let's assume that we made for $90,000 you're single and we wanted to know how much you pay so that's how I come here and in essence what you've done is you've got different amounts of here and of these dollars in here. If you're at $8,000 and you go out and earn another hundred dollars you're going to pay $10 and times but if you're making eighty six thousand dollars you need to have you earn another 100 dollars. for obvious reasons why what did you do then people stopped working Sunday so we're looking at these taxes it's interesting it's also interesting that we want to know do we tax people or to be tax household so let me show you an example because the units that were taxed and can have all kinds of different applications [Music] that's hot let's look at a tax that looks like this let's soon on the first 20,000 20% from 20,00 so let'sLook at their income right Donald makes $8,000 Elena makes $20,000 bill makes $50,000 Hilary makes $ 50,000 if we tax them individually okay Donald your first 20,.000 taxes ten percent your money from 20 to 50 stops the 20 percent. Your money about 50 stops at 30% we do the warmer that we just did if we look at this on an individual tax basis McDonald's gonna hold. 17,000 Orlando will go to top Bill and Hillary will both oh eight thousand each so our total BAM attacks if we put this way 19,000 if we tax the household this goes back to this idea we discussed the horizontal language all right we want to treat people that are in similar circumstances the same those people are being treated decide why do we have this front why are we having these different taxes why is the why are these numbers larger than these numbers was because of the progressive nature of the task. want to penalize people for being married does that make sense right I mean society should not encourage people to do just shack up right exactly make sense of maybe that for at least generally we've got what we're done matter so we know we don't want this that's not the answer is is that there is no answer you cannot devise but these are just kind of illustrates some of the problems that you have in developing the taxes do you want to make you wantto penalize marriage generally all right. when we're looking at fiscal policy Keynes's and we'relooking at things wide changes and taxes or changes in government spending. When we look at government we can have for the government of course the revenue for them the taxes so we can say a budget deficit this is when they're spent is greater than government brothers. When they can also have a bunch of surplus this would be even government spending last thing or so here's government spending evil. If you look at the national debt that's just some eight of all these government debt assistants are possible just a doll and we saw for our country. was in this year spec's 383 three point eight trillion dollars when we spent almost three point nine those caught 329 Troy and we had parameters seeds we have revenue three point three trouble nice we have seven under six hundred billion dollars and we can engage in types of policies here too we're under the change and your demand as we can have spam canary fiscal policies. We can have contractionary order restrictions physical follows so if our expansionary fiscal policy here we're seeing the decrease in taxes or an increase in government spending and if you have a deficit the deficit is going to get larger. deficit or if you have a surplus and interestingly enough these surpluses and with these deficits we can go out and we can engage the fiscal policy that makes these guys change on purpose we can have it's called discretionary fiscal policy. So here it's a tariff pair is keeping everything else constant you're going to get an expansion the economies grow employments increasing other one is going down well if employments going up the taxes are going if unemployment going down and we're standing government spending going down. automatic stabilizers are things that change government spending automatic. These things automatically increase taxes or was change tax that automatically change taxes and/or so examples would be things like food stamps Wow because by the time you know you're in a recession and then you go out and say what should we do about this let's help people, it could be like we don't need a I just took too long that's why I call automatic stabilizers they automatically begin to kick in they automatically start increasing government spending. on the progressive income tax does the exact same thing because if people's income is $50,000 right and then for some reason it falls to say $20,000 if you have progressive taxes they're going to pay their tax burden. The average tax rate is going to automatic certainly when you've got the expansion apart you're going from time here t2 to t3 people theoretically don't need food stamps and Welfare right so spending on these guys is automatically reduced. You're automatically seeing reductions in government spending automatically. a beautiful fiscal policy we have this new classical view of fiscal policy and we have those called the supply side now. What we'll see on Wednesday and what these guys actually do is what we'll hear on Wednesday. We'll see what they actually do and how they do it. It's going to be very interesting to see what happens in the next few days. It will be a very interesting week. It'll be very exciting to see how they go about it. We will find out what happens.

ROUGE-1: 60.88, ROUGE-2: 58.18, ROUGE-L: 57.08
BERTScore: 78.28

==============================================
==================== [47/100] ====================
Summary:
PHILIPPE RIGOLLET: --124. The fluctuations that are due to the fact that I get different samples every time should somewhat vanish. And so what I want is to have a small bias, hopefully a 0 bias. If this thing is 0, then we see that the estimator is unbiased. So this is definitely a property of the model that I'm looking for. It's a very, very powerful tool. It can be used to improve the quality of education. that we are going to be looking for in an estimator, trying to find them to be unbiased. But we'll see that it's actually maybe not enough. So unbiasedness should not be something you lose your sleep over. Something that's slightly better is the risk, really the quadratics risk, which is expectation of-- so if the quadratic risk goes to 0, then that means that theta hat converges to theta in the L2 sense. If you reduce one too much, then the variance of the other one is going to increase, or the opposite. examples. So am I planning-- yeah. So if I do, for example, X1, Xn, there are iid Bernoulli. And I'm going to write it theta so that we keep the same notation. Then theta hat is the average of Xi's. So what is the bias of this guy? Well, to know the bias, I just have to remove theta from the expectation. So this thing is actually theta, which means that this isn't biased, right? for sum of independent random variables, now it's time to wake up. So we have the variance of something that looks like 1 over n, the sum from i equal 1 to n of Xi. So it's of the form variance of a constant times a random variable. We would like somehow to say that this is the sum of the variances. And in general, we are not allowed to say this, but we are because my Xi's are actually independent. And that's by independence, so this is basic probability. equal to theta, 1 minus theta divided by n. So this is just summarizing the performance of an estimator, which is the random variable. The decomposition, as the sum of the bias square and the variance, is really telling you that-- it is really accounting for the bias. Then you can see that those things, bias and variance, are actually very different. So I don't have any colors here, so you're going to have to really follow the speed-- the order in which I draw those curves. All right. So let's find-- I'm going to give you three candidate estimators, so-- estimators for theta. So the first one is definitely Xn bar. That will be a good candidate estimator. The second one is going to be 0.5, because after all, why should I bother if it's actually going to being-- right? So for example, if I ask you to predict the score of some candidate in some election, then since you know it's going to been very close to 0. 5, you might as well just throw 0.4. And it'sactually going to cost you 0 time and $0 to come up with that. very helpful if your prediction is telling you this. But if it was something different, that would be a good way to generate some close to 1/2. For a coin, for example, if I give you a coins, you never know. Maybe it's slightly biased. But the good guess, just looking at it, inspecting it, maybe there's something crazy happening with the structure of it, you're going to guess that it's 0.5 without trying to collect information. And let's find another one, which is, well, you know, I have a lot of observations. But I'm recording couples kissing, but I'm on a budget. The bias is 0 and the variance is equal to theta, 1 minus theta divided by n. The second number is better for the other guy, so I will definitely go for this guy compared to this guy. The bias is actually-- just for simplicity, I can think of it as being X1 bar, the average of itself. And I have the variance that's actually n times smaller when I use my n observations than when I don't. So this guy is gone. the bias, it's actually really not that bad. It's 0.5 minus theta. And so you can actually now look at what the quadratic risk looks like. So here, what I'm going to do is I'mgoing to take my true theta-- so it's going to range between 0 and 1. And we know that those two things are functions of theta, so I can only understand them if I plot them as functions of Theta. So at 0, the risk is 0 plus the square of 0. 5 minus Theta, and at 1, it is 1. The risk of this guy is that it will depend on n. So I will just pick some n that I'm happy with just so that I can actually draw a curve. And we'll write it like this. So when theta is very close to 0.5, I'm very happy. When theta gets farther, it's a little bit annoying. And so now I need to plot the function. So this here is the risk of0.5. And at 1, it is going to be 0.25 as well. theta, 1 minus theta divided by 10. So really, if n is equal to 1, this is what the variance looks like. The bias doesn't count in the risk. So if you're sure-- let's say you're talking about presidential election, you know that those things are going to be really close. Maybe you're actually better by predicting 0.5 if you know it's not going to go too far. But if I look at the risk of Xn, all I'm doing is just crushing this curve down to 0. As n increases, it's going to look more and more like this. The risk is really telling you how much fluctuations I have around my expectation if unbiased. If I'm unbiased, it coincides with the variance. But if I'm biased, then I have to account for the fact that I'm really not computing the risk. And so for different thetas, some estimators are going to be better than others. But there's also the entire range of estimators, those that are really biased, but the bias can completely vanish. Are there any questions? can be large. Or you have 0 bias-- you have a bias, but the variance is 0. So you can actually have this trade-off and you can find things that are in the entire range in general. Those things are actually-- those trade-offs between bias and variance are usually much better illustrated if we're talking about multivariate parameters. In this class, it's mostly one-dimensional parameter estimation, so it's going to be a little harder to illustrate that. But if you do, for example, non-parametric estimation, that's all you do. what a confidence interval is. And so we fixed a statistical model for n observations, X1 to Xn. Theta is a subset of the real line, and that's why I talk about intervals. An interval is just a one-dimensional conference region. And it has to be an interval as well. A confidence interval of level 1 minus alpha-- so we refer to the quality of a confidence intervals is actually called it's level. It takes value 1 minusalpha for some positive alpha. is between 0 and 1. The closer to 1 it is, the better the confidence interval. And so for any random interval-- so a confidence interval is a random interval. The bounds of this interval depends on random data. Just like we had X bar plus/minus 1 over square root of n, for example, or 2 over squareroot of n. This X bar was the random thing that would make fluctuate those guys. And now I have its boundaries, but now the boundaries are not allowed to depend on my unknown parameter. The probability that I contains theta is at least 1 minus alpha. So it better be close to 1, because it's really telling you that whatever random variable I'm giving you, my error bars are actually covering the right theta. But I want this to hold true for all possible values of the parameters that nature may have come up with from. So I don't know what my confidence -- my parameter of theta -- is, but I want it to be true. And I really want to emphasize that the randomness is in I. want this-- so there's theta that changes here, so the distribution of the interval is actually changing with theta hopefully. And theta is changing with this guy. So regardless of the value of theta. that I'm getting, I want that the probability that it contains the theta, is actually larger than 1 minus alpha. So maybe for each fixed n it's going to be not true. But for as no goes to infinity, it's actually going to become true. you actually need to use things such as Hoeffding's inequality that hold for every n. So as a rule of thumb, if you use the central limit theorem, you're dealing with a confidence interval with asymptotic level 1 minus alpha. And the reason is because you actually want to get the quintiles of the normal-- the Gaussian distribution that comes from the centrallimit theorem. So this is the formal definition. It's a bit of a mouthful. But we actually-- the best way to understand them is to build them. belongs to the confidence interval is actually 1 minus alpha. Now, if I start plugging in numbers instead of the random variables X1 to Xn, I start putting 1, 0, 0. 1, 1,0, 1. And this guy, the probability that theta belongs to it is not 1 plus alpha. It's either 0 if it's not in there or it's 1 if it is in there. So the sample average, Xn bar, is a strongly consistent estimator of p. one of the properties that we wanted. Strongly consistent means that as n goes to infinity, it converges almost surely to the true parameter. That's the strong law of large number. It is consistent also, because it's strongly consistent, so it also converges in probability, which makes it consistent. We've actually computed its quadratic risk. And now what I have is that if I look at-- thanks to the central limit theorem, we actually did this. We built a confidence interval at level 1 minus alpha. as n goes to infinity to some standard normal distribution. This is by definition of the quintile of a standard Gaussian and of a limit in distribution. So the probabilities computed on this guy in the limit converges to the probability computed on that guy. And we know that this is just the probability that the absolute value of sum is greater than the sum of the squares of n and p1 minus p. That's exactly what I did last time. I'm actually going to use the same notation, limit as n go to infinity, this is the same thing. n 0, 1 is less than Q alpha over 2. And so in particular, if it's equal, then I can put some larger than or equal to, which guarantees my asymptotic confidence level. And I just solve for p. So this is equivalent to the limit as n goes to infinity of the probability that theta is between Xn bar minus Qalpha over 2 divided by times square root of p1 minus p divided by squareroot of n. And there you go. I have my confidence interval. Except that's not, right? We just said that the bounds of a confidence interval may not depend on the unknown. And here, they do. two ways of getting rid of this. Since we only need this thing-- so this thing, as we said, is really equal. Every time I'm going to make this guy smaller and this guy larger, I'm only going to increase the probability. So what we do is we actually just take the largest possible value for p1 minus p, which makes the interval as large as possible. And so now I have this. I just do one of the two tricks. I replace p1 plus p by their upper bound, which is 1/4. also to some standard Gaussian. We've seen that when we saw Slutsky as an example. And so those two things-- actually, just because I'm taking the limit and I'm only caring about the asymptotic confidence level, I can actually just plug in consistent quantities in there, such as Xn bar where I don't have a p. And that gives me another confidence interval. All right. So this by now, hopefully after doing it three times, you should really, really be comfortable with just creating this confidence intervals. not Slutsky, right? AUDIENCE: That's [INAUDIBLE]. PHILIPPE RIGOLLET: So Slutski's about combining two types of convergence. So if you actually have one Xn that converges to X in distribution and Yn that converge to Y in probability, then you can actually multiply Xn and YN and get that the limit in distribution is the product of X and Y, where X is now a constant. And here we have the constant, which is 1. is no. The only thing you're losing is the rate of convergence of the central limit theorem. Of course, the price you pay is that your confidence interval is wider than it would be if you were to use Slutsky for this particular problem. So it depends on how comfortable and how critical it is for you to put valid error bars. If they're valid in the asymptotics, then maybe you're actually going to go with Slutky so it actually gives you slightly narrower confidence intervals. how critical it is for you to output valid error bounds or if they're really just here to be indicative of the precision of the estimator you gave from a more qualitative perspective. So here, there's basically a bunch of errors. There's a theorem called Berry-Esseen that quantifies how far this probability is from 1 minus alpha, but the constants are terrible. And then for Slutsky, again you're multiplying something that converges by something that fluctuates around 1, so you need to understand how this thing fluctuates. if this function is super-sharp, then small fluctuations of Xn bar around this expectation are going to lead to really high fluctuations of the function itself. So that's what the function here-- the function you're interested in is 1 over square root of X1 minus X. So what does this function look like around the point where you think P is the true parameter? Its derivative really is what matters. OK? Any other question. OK. So it's important, because now we're going to switch to the real let's do some hardcore computation type of things. When we do maximum likelihood estimation, likelihood is the function, so we need to maximize a function. And if I give you a function, you need to know how to maximize this function. Sometimes, you have closed-form solutions. You can take the derivative and set it equal to 0 and solve it. But sometimes, you actually need to resort to algorithms to do that. And we'll briefly touch upon it, but this is definitely not the focus of this class. OK. So we'll do a little bit of reminders on those things. estimator, what I'm going to try to do is to give you an insight for what we're actually doing when we do maximum likelihood estimation. So remember, we have a model on a sample space E and some candidate distributions P theta. And really, your goal is to estimate a true theta star, the one that generated some data, X1 to Xn, in an iid fashion. But this thea star is really a proxy for us to know that we actually understand the distribution itself. In a way, what does it mean to have two distributions that are close? It means that when you compute probabilities on one distribution, you should have the same probability on the other distribution pretty much. So what we can do is say, well, now I have two candidate distributions. So if theta hat leads to a candidate distribution, and this is the true theta star, it leads to the true distribution P thetaStar. That's my candidate. As a statistician, I'm supposed to come up with a good candidate. And what I want is that if you actually give me the distribution, then I want when I'm computing probabilities, I know what the probabilities for the other guys are. a probability under theta hat of some interval a, b, it should be pretty close to the probability under. theta star of a, a. And more generally, if I want to take the union of two intervals, I want this to be true. Does that sound like a reasonable goal for a statistician? That's a pretty strong notion. So if the total variation between theta and theta prime is small, it means that for all possible A's that you give me, then P theta of A is going to be close to P theTA prime of A. are you to compute this maximum over all possible events? I mean, it's just crazy, right? There's an infinite number of them. It's much larger than the number of intervals, for example, so it's a bit annoying. There's actually a way to compress it by just looking at the basically function distance or vector distance between probability mass functions or probability density functions. So I'm going to start with the discrete version of the total variation. Throughout this chapter, I will make the difference between discrete random variables and continuous random variables. integrals. But they're all the same thing, really. So let's start with the probability mass function. This is the function that tells me for each possible value that it can take, the probability that it takes this value. So what I want is, of course, that the sum of the probabilities is 1. And I want them to be non-negative. Otherwise, we can just remove this x from the sample space. And so then I have the total variation distance, I mean, it's supposed to be. the maximum overall sets of-- of subsets of E, such that the probability of A minus probability of theta prime of A-- it's complicated, but really there's this beautiful formula that tells me that if I look at the total variation between P theta and P theTA prime, it's actually equal to just 1/2 of the sum for all X in E. So that's something you can compute. But if I give you just the densities and the original distribution, the original definition where you have to max over all possible events, it is not clear you're going to be able to do that very quickly. what it is doing for you. It's controlling the difference of probabilities you can compute on any event. But here, it's just telling you, well, if you do it for each simple event,. It's actually simple. Now we have also the continuous ones, such as Gaussian, exponential. And what characterizes those guys is that they have a probability density. So the density, remember the way I use my density is when I want to compute the probability of belonging to a group. The probability of X falling to some subset of the real line A is simply the integral of the density on this set. That's the famous area under the curve thing. Since for each possible value, the probability at X-- so I hope you remember that stuff. But essentially, we know that the probability that X is equal to little x is 0 for a continuous random variable, for all possible X's. There's just none of them that actually gets weight. So what we have to do is to describe the fact that it's in some little region. probability that I belong to the interval a, b is just the area under the curve between A and B. If you don't remember that, please take immediate remedy. So this function f, just like P, is non-negative. And rather than summing to 1, it integrates to 1 when I integrate it over the entire sample space E. And now the total variation, well, it takes basically the same form. I said that you essentially replace sums by integrals when you're dealing with densities. Two Gaussian densities, exponential minus x squared. You could actually write it as an integral. Now, whether you can actually reduce this integral to some particular number is another story. So now, you have actually a handle on this thing and you could technically ask Mathematica, whereas asking MathematicA to take the max over all possible events is going to be difficult. All right. So the total variation has some properties. So let's keep on the board the definition that involves, say, the densities. And you have two Gaussians, one with mean theta and one withmean theta prime. This guy is computing the absolute value of the difference between f and f theta prime. You can check for yourself that graphically, this I can represent as an area not under the curve, but between the curves. So this thing here, this area, this is 2 times the total variation. The scaling is the same as the scaling of the Gaussians. It's just saying, well, if I have-- so think of two Gaussian. For example, I have one that's here and one that is here. 1/2 really doesn't matter. It's just if I want to have an actual correspondence between the maximum and the other guy, I have to do this. So we have this definition. And so we have a couple of properties that come into this. The first one is that it's symmetric. TV of P theta and P thea prime is the same as the TV between P thetas prime and P tas. And it's actually also true if I take the maximum. Those things are completely symmetric in thea and theta prime. really the way you want to do this, because you have to understand what pretty much everywhere means-- which I should really say almost everywhere. But let's go to this definition-- which is gone. That's the one here. The max of those two guys, if this maximum is equal to 0-- I have a maximum of non-negative numbers, their absolute values. Their maximum isequal to 0, well, they better be all equal to0, because if one is not equal to 1, then the maximum is not 1. The total variation equal to 0 implies that P theta is equal to P theTA prime. If this thing being small implied that P. theta could be all over the place, that would not help very much. The fact that you need two definitions of the [INAUDIBLE],, is it something obvious or is it complete? PHILIPPE RIGOLLET: I'll do it for you now. So let's just prove that those two things are actually giving me the same definition. going to do is I'm actually going to start with the second one. And I'm going to write-- I'mgoing to begin with the density version. But as an exercise, you can do it for the PMF version if you prefer. I just don't want to have to write indices all the time. So think of this as being f sub theta, and Think of this guy as beingf sub thea prime. So I'm Going to Start with this thing, the integral of f of X minus g of X. PhilipPE RIGOLLET: Let me write the set A star as being the set of X's such that f of X is larger than g of X. So that's the set on which the difference is going to be positive or negative. Rigollet: This, again, is equivalent to f ofX minus g ofX is positive. Everybody agrees? So this is the set I'm interested in. So now I'm going to split my integral into two parts, in A, A star. RIGOLLET: It is. Just look at this board. So this is definitely at most the maximum over A of Pf of A minus Pg of A. Right? We agree with this? Because this is just for one specific A, and I'm bounding it by themaximum over all possible A. So that's clearly true. So now I have to show you that the max is actually this guy, A star. So why would that be true? Well, let's just inspect this. thing over there. So we want to show that if I take any other A in this integral than this guy A star, it's actually got to decrease its value. The set A star is the set over which the function delta is non-negative. So if I start adding something to A, the value goes lower. If I start removing something from A, like say this guy, I'm actually removing this value from the integral. So there's no way. This A staris the one that actually maximizes the integral of this function. when I take A to be the set where it's positive. Just need to make sure that there is someplace where it is, but that's about it. So it's a distance. It's symmetric, non-negative, equal to 0, if and only if the two arguments are equal, then it satisfies the triangle. If it's not satisfying this thing, it's called pseudo-distance or quasi-distance. Or just metric or nothing at all, honestly. So we have this notion of distance between probability measures. inequality. And so that means that we have this actual total variation distance between probability distributions. And here is now a statistical strategy to implement our goal. Remember, our goal was to spit out a theta hat, which was close such that P theta hats was close to P theTA star. So hopefully, we were trying to minimize the total variationdistance between P thena hat and P thea star. But here, one of the arguments is not known to us, so we need to estimate it. The surrogate for total variation distance is actually called the Kullback-Leibler divergence. It has some roots coming from information theory, which I will not delve into. But if any of you is actually a Core 6 student, I'm sure you've seen that in some-- I don't know-- course that has any content on information theory. All right. So the KL divergence between two probability measures, P theta and P theTA prime-- and here, as I said, it's not going to be the symmetric, so it's very important for. you to specify which order you say it is, between P theta and P thea prime. And so we denote it by KL. And the KL, if I use the same notation, f and g, is integral of f of X over g of X, dx. It's a weird function. OK. So this was what we had. That's the TV. And then we replace this absolute value of the distance divided by 2 by this weirdfunction. This function is P. theta, log P thena, divided by P theda prime. Thatâ€™s the function. bit different. And I go from discrete to continuous using an integral. Everybody can read this. Everybody's fine with this. Is there any uncertainty about the actual definition here? So here I go straight to the definition, which is just plugging the functions into some integral and compute. So I don't bother with maxima or anything. I mean, there is something like that, but it's certainly not as natural as the total variation. Yes? AUDIENCE: The total variation, [INAUDIBLE].. of differences between probability density function, at least for the probability density functions we're used to manipulate is actually a nightmare. So people prefer KL, because for the Gaussian, this is going to be theta minus theta prime squared. And so those things are much easier to manipulate. But it's really-- the total variation is telling you how far in the worst case the two probabilities can be. This is really the intrinsic notion of closeness between probabilities. So that's really the one-- if we could, that's the one we would go after. here, it has a very specific meaning. If I tell you the KL divergence is 0.01, it's not clear what it means. OK. So what are the properties? The KL divergence between P theta and P theTA prime is different from the KL divergences between theta prime and theta theta in general. Of course, in general, because if theta is equal to thetaprime, then this certainly is true. So there's cases when it is not true. The divergence is non-negative. compared to the convex function of the expectation of a random variable. If you know Jensen, have fun and prove it. What's really nice is that if the KL is equal to 0, then the two distributions are the same. And that's something we're looking for. Everything else we're happy to throw out. So they're not symmetric. It does satisfy the triangle inequality in general. But it's non-negative and it's 0 if and only if the two Distributions are the Same. The total variation distance is actually an expectation of something. The divergence is doing a pretty good thing for us. And this is what will allow us to estimate it and basically overcome what we could not do with the total variation. It's the integral of some function against a density. That's exactly the definition of an expectation, right? That's what we're trying to get at here. We're looking for a way to get a distance from P theta to P prime. We can get it by taking the average of the two possible values it can take. So this is the expectation of this particular function with respect to this density f. And I could actually replace the expectation by an average and try to minimize here. The problem is that-- actually the star here should be in front of the theta, not of the P, right? That's P theta star, not P star theta. But here, I still cannot compute it, because I have this P theTA star that shows up. I don't know what to do. Philip Rigollet: If I change theta, this thing is never going to change. It depends only on theta star. The log itself is a very, very specific property, which allows us to say that the log of the ratio is the ratio of the log. If you actually pay attention, I said you can use Jensen to prove all this stuff. You could actually replace the log by any concave function. That would be f divergent. That's called an f divergence. theta star is and what P theta is. And so what I'm doing is I'm replacing any-- I can actually-- this is a very standard estimation method. You write something as an expectation with respect to the data-generating process of some function. And then you replace this by the average of this function. The law of large numbers tells me that those two quantities should actually be close. Now, it doesn't mean that's going to be the end of the day, right. "We had an expectation. We replaced it by an average. And then we were gone. But here, we still have to do something, because this is not telling me what theta is," he says. "So this is now my candidate estimator for KL, KL hat. And that's the one where I said, well, it's going to be of the form of constant. And this constant, I don't know. You're right. I have no idea what this constant is" this constant is 0 for my purposes, or 25 if you prefer. All right. So we'll just keep going on this property next time. And we'll see how from here we can move on to-- the likelihood is actually going to come out of this formula. Thanks. Back to Mail Online home. back to the page you came from. Back from the page where you came From. Click here to go to the show page where we'll be talking about the probability of winning the lottery.

ROUGE-1: 60.72, ROUGE-2: 58.34, ROUGE-L: 56.29
BERTScore: 71.90

==============================================
==================== [48/100] ====================
Summary:
This class will be taught in an inverted classroom or flipped classroom setting. It's going to be online-only so we will not have in-person opportunities to discuss. What you are typically used for as lectures is organized solely in short videos where I discuss concepts or methods. The videos also include a few short questions for your own self-evaluation, and we'll pick up those questions and later in recitation session. So when you meet Tuesdays and Thursdays we'll have time for recitation. to answer your questions. We'll have time to go through those [INAUDIBLE] and hopefully have a good discussion. The recitations are also used for another concept, which I'll explain on a later slide, which is your presentation of a specific paper. This is part of your homework set is to find a paper to discuss with me whether or not it fits into this class schedule, and together with a partner, have a short discussion of it. So we'll use these Tuesday and Thursday sessions for this purpose. And in addition, there's going to be an office hour on Friday. and then we'll find the best possible time for everybody involved. The course evaluation or your evaluation in this course will be made up 50% out of homework. The paper presentation I was talking about will have 20 points. This is 20 minutes, so the actual exam is only going to be 20 minutes. Again, this is being done in two groups so you have to split up the aspect of presenting-- preparing and presenting, and then also when it comes to the response and the questions. The grading scheme will not be worse than what I've given you here. The great divide-- the great divide or the grade divide-- at 85% between A and B, 70% between B and C, 60% between C and D, and below 50% earns you an F. I don't think anybody can get into this environment as long as they participate. The first one deals with the particle physics content, and the second one with the nuclear physics and experimental method as well.

ROUGE-1: 74.92, ROUGE-2: 72.60, ROUGE-L: 67.70
BERTScore: 75.05

==============================================
==================== [49/100] ====================
Summary:
Today we're going to do a fun problem that will test your knowledge of the law of total variance. And in the process, we'll also get more practice dealing with joint PDFs and computing conditional expectations and conditional variances. So in this problem, we are given a joint PDF for x and y. And then we are asked to compute the variance of x plus y. So you can think of xplus y as a new random variable whose variance we want to compute. And moreover, we're told we should compute this variance by using something called the law Of Total Variance. In the unconditional universe, x and y were uniformly distributed. So it follows that in the conditional universe, y should also be uniformly distributed, because conditioning doesn't change the relative frequency of outcomes. Conditioned on x, this is the PDF of y. And because it's uniformly distributed and because expectation acts like center of mass, we know that the expectation should be the midpoint, right? So to compute this point, we simply take the average of the endpoints, x plus 1 plus x over 2, which gives us 2x plus 1 over 2. We have a formula for computing the variance of a random variable when it's uniformly distributed between two endpoints. So we're making good progress, because we have this inner quantity and this outer quantity. So now all we need to do is take the outer variance and the outer expectation. So writing this all down, we get variance of x plus 1, a is x, and b minus a squared over 12 is just 1/12. That's pww. This is pWW. y is equal to variance of this guy, 2x plus 1/2 plus the expectation of 1/12. So this term is quite simple. The expectation of a constant or of a scalar is simply that scalar. We know that you can just take out this scalar scaling factor as long as we square it. And now to compute the variance of x, we're going to use that formula again, and we'll call it 2 squared, or 4 times the variance. we're going to use this picture. So here we have the joint PDF of x and y, but really we want now thePDF of x, so we can figure out what the variance is. So hopefully you remember a trick we taught you called marginalization. To get the PDF ofx given a joint PDF, you simply marginalize over the values of y. So if you freeze x is equal to 0, you get the probability density line over x by integrating over this interval, over y. come over here and draw it. We're claiming that the PDF of x, px of x,. looks like this. It's just uniformly distributed between 0 and 1. And if you buy that, then we're done, we're home free, because we can apply this formula, b minus a squared over 12, gives us the variance. So coming back over here, we get 4 times 1/12 plus 1/ 12, which is 5/12. And that is our answer.  memorizing formulas might seem like cheating, but there's a few important ones you should know. And it will help you sort of become faster at doing computations. And that's important, especially if you guys take the exams. So that's it. See you next time. We'll be back in a few days with a new episode of "The Daily Discussion" to talk about the week's top news stories. Back to the page you came from. Click here for the next episode of The Daily Discussion.

ROUGE-1: 53.49, ROUGE-2: 49.62, ROUGE-L: 48.33
BERTScore: 72.06

==============================================
==================== [50/100] ====================
Summary:
The second half of the MIT OpenCourseWare lecture series will focus on multisequence alignment. In the second half, George Church will talk about how to get an empirical substitution matrix from distantly related protein sequences. The second half will be available on Thursday, February 14, at 10:30 a.m. and 11:30 p.m., respectively. For more information about MIT Open CourseWare, visit ocw.mit.edu and follow us on Twitter @MITOpenCourseWare. let's think about it in three dimensions for just a moment here. And when you have a multiple alignment, you can think of it as dynamic programming on this hyperlattice and that the indels for any pairwise combination may not be optimal for the triple. And let's go beyond triple, but to a very simple dinucleotide alignment. And we will say that this is the optimal multiple alignment. You can see here that the multiple examples of AT anchor the A and T as being separate positions, even though normally, if you just did a pairwise alignment with a high gap penalty. You would not have these canceling indels. will be a recursive algorithm where the score of a two-character string is defined in terms of the maximum of various shorter strings. At the very top is the case where we have no insertions-- the simplest case. Now, the number of different cases we have here-- before, it was 3 for a global alignment, which was 2. Now k is three for a three-way comparison. And all possible subsets is 2 to the k minus 1, in this case, so it's 7. and you can just walk through them. Now, as k grows, then both the space complexity-- the amount of lattice points that you have to store somewhere, either in RAM, or disk, or somewhere-- grows by n to the k-th power. Now to compute each of those nodes-- well, I mean, what will be on the order of 2 to thek power, because remember I said that the number of subsets in a lattice is k. So this is the seven cases for a three-way comparison. general is going to be 2 to the k minus 1. And so the time complexity is have to do 2 to k comparisons per node. And the larger k is, the more you can explore. It's like doing a huge mutagenesis experiment and exploring viable mutants. And it's not like we only want to do k equals 2. There are very good reasons for inferring structure or function without experiments, just from sequence. So we use all the power that we developed for the pairwise comparison and we're just generalizing it. want to do multisequence alignments, so how do we deal with this? This is the way we dealing with most non-polynomial calculations, that is to say, in this case, exponential, which is we approximate. Now, you can get something that's very close to the true optimum if how to prune this hyperlattice. Remember, one of the examples I showed was you could take this band. If you know where the band should start and how wide it should be,. you can essentially prune off many of the nodes without really losing any optimality. in the next couple of slides is a tree alignment, as illustrated by ClustalW. By the way, pruning is illustrated by a program called MSA, which is short for multisequence alignment. And we'll show a star alignment. When we get, later on into the transcriptome part of the course, we will talk about the Gibbs algorithm. And I think most of you, if I had given you the luxury of just thinking this through during the break, how you would do the multialignment, this might be the algorithm you would come up with. The best score is S1 with S3, which has a score of 9. And so you can construct a tree. The distance of each from the common ancestor is indicated by the length of these lines. And you get this 4 by 4 matrix. It's going to be symmetric, so you only have to do the diagonal and the off diagonals on one-half of it and.pairwise alignments. And this is-- basically, we're starting to describe the method by which we construct a Tree. The final branching closest to the trunk of the tree or the roots of tree is called the dendrogram. The longer branches indicate greater divergence. And they're in their own cluster. The common ancestor for all the sequences, which would be the common ancestor of the common ancestors of the first two clusters, is represented by this final branching. And here, distance is this horizontal axis. And then, once you have this dendprogram, the next step, or the full steps, are aligning each of the sequences. S2, S4. And you could imagine keeping doing this hierarchical process. If there were additional sequences which are even more distant related, let's say S5. So you can see how you can align not only sequences, but also pseudosequences. So that's one method. This is a different method. And here, the premise is that you've got one sequence which is sufficiently close to all the other sequences that you can use it as an anchor sequence. Whatever indels you put in individually pairwise, for that sequence, can be propagated throughout the entire multisequence alignment. give a score. These scores are the scores that would have come out at the end of that traceback in the pairwise alignments. So this is not a pairwise matrix. This is the results of 5 times 4 over 2 pairwisealignments. Each of these boxes itself is the outcome of a full matrix on S1 versus S2, for example. And you can see from these set of scores that the best score, or the best set of Scores for any sequence, is S1. best score for S1 with each of the others, and have S1 in red in each case, and use that as the anchor. And so then in the multialignment, you take all the indels relative to the red one, and introduce them so that it's the anchor, and so on. So those are two radically different ways. And we'll get to the Gibbs sampling later. The Gibbs sampling, just in a nutshell, is in general when you have a hard problem, where you can't comprehensively go through the entire space, what you do is sample it. by having this storing, this pairwise or multi sequence in a matrix-- so that's actually you've done a trade-off where you've taken up computer memory in order to save time. And then if you're willing to sacrifice a little accuracy or a little comprehensiveness, then you can save even more time or memory. Now we want to use motifs, which is the sort of thing that you get out of local alignments, to find genes. And we're going to use the motifs and the finding genes as a way of introducing a particular motif. or RNA-coding region, you'll have regulatory elements such as promoters and so-called CG islands. The CG islands are basically an abundance of the CG dinucleotide. Of the 16 different dinucleotides, CG happens to be underrepresented in general invertebrate genomes, and over-represented in promoter regions upstream from genes. And the reason is probably that they bind to transcription factors, and the transcription factors protect them from methylation, and thereby protection them from a mutagenic process that would otherwise cause them to become a TG. in the cell, as well as other constraints on the sequence. Promoters and CG islands are sort of degenerate. They're weak sequence signatures. There's a high variety, and they're used in combinations. Conservation requires that you have the right species, that at least some of the species in your multisequence alignment are just the right distance. If you have very rare [? trends, ?] you need to have the cDNAs, if you have them, to look for conserved positions and interspecies conservation. cell type and the rare [INAUDIBLE],, rare messenger RNA within a cell type. So let's talk about the sizes of proteins. If you go to humans, this would go out to 10s of thousands of amino acids long for the largest proteins. But let's focus attention on the smallest proteins. How is it that it precipitously drops off at 100 amino acids? Why are there so few proteins that are short? And there are slightly more short proteins in Mycoplasma? Any guesses why they're so few? Stop codons tend to be made up of As and Ts. The stop codons are TAG, TGA, and TAA. So if you have an AT-rich genome, you're going to tend to have a lot. You tend to run into a stop codon at random quite frequently. And you can see that there's this general trend. You need to have more codons in a row to convince yourself that a genome is CG-rich. So it's usually somewhere in between. convince yourself as the GC content on the horizontal axis goes higher. And basically, the place where you start getting too many false positives is around 100 amino acids. And so that's why the community just decided to cut off there. When we get to proteomics, we'll talk about ways that you can empirically, by mass spectrometry and so forth, find those small proteins. And genetically, of course, you can find them. Let's talk about the most extremely small ones, and ask whether these extremely small open reading frames are interesting. presumably a separate molecule, maybe possibly a degraded version of it. But in some way or another, the 23 sRNA encodes this pentapeptide, which is not just some junk. But this one actually confers erythromycin resistance at low levels in wild type. It is not a mutant kind of peptide. It's the normal pentapepticide. Now, here's three examples that are related to one another. They have this very strange amino acid composition when you do the translation conceptually in the computer. row happen to be-- the next gene down is a histidine biosynthetic gene. And not only that, but about eight histidine genes in a row come after that. And the same thing with phenylalanines. This weird excess of tryptophan is upstream of tryPTophan biosynthesis genes. So what does this all mean? What it means, probably-- and there's actually quite a bit of experiments on this-- is that this is an excellent feedback loop, where you want to do feedback in the most relevant way. you're not, then you'll pause here. That ribosome will hesitate, waiting for the right transfer RNA. And as it hesitates, this RNA changes. It's folding. And a series of events results in-- if it's hesitating, then it wants to make the biosynthetic genes downstream. So the tRNA has to be charged up. So you get this nice, little feedback loop that the hesitation causes a change in RNA, which causes change of transcription. ask, how do we deal with them more rigorously? And the way we deal With these profiles, we're going to take a multisequence alignment. You acknowledge that you don't have a generic substitution matrix for all positions in all proteins or all nucleic acids. Because one position might be, say, an alpha helix. We have one substitution matrix. And another one might be in a coil. So here, this is all about what motifs are all about. Each position has a different set of rules. be A, C, G, or T. These are four different sequences, real start sites, that we've aligned, either manually or by computer. This is dead easy to do the alignment, but the interpretation here is the position upstream of the start codon doesn't matter. So your matrix down below is-- A,. C,. G and T each get a 1, which is a count. We're doing it in terms of counts here because that's just a restatement of the data. perfectly good start codon in, say, 1 sequence in 10 or 1 in 4 in this case. And so you get 3 and a 1. So this is the weight matrix or position-sensitive substitution matrix. This is more precise than a consensus sequence or a single sequence from the sample. But it's not the most precise way of representing this. It's position sensitive, but we've lost the higher order correlations between positions. But let's see how this plays out, this position sensitive. the same motif, ATG. The T and G were invariant in this larger sample, or nearly invariant. And it turns out that-- again, experimentally, you find this little blip of Gs and As, mostly, at minus 9 relative to the A of ATG at 0. And then the base just upstream from the ATG is almost completely random. And so its information content is close to nil, and so it's 0 bits. Now, this is easy enough that you can just do a big search aligning on theATG. verified-- this motif-- so the ATG motif binds to transfer RNA, and the GA-rich motif actually binds to a ribosomal RNA sequence. And so then basically, the messenger RNA is coaxed into the right position, to be in the right location of the ribosomes where the tRNA can bind the initiator. So here's an example where you can do a multisequence alignment. Here are 1,000 of sequences. k equals 1055. And you can find these motifs that have great biological significance. do that is now take this weight matrix, and ask for each-- we're scanning the genome, and we run into the sequence [? AAT ?] AATG. Now you want to know, how good a match is that to this weight Matrix, which was taken from either 4 sequences or 1,000 sequences? And the way you do it is for each position, you ask what was the score in the whole learning set? And now this should be a now independent test set you're trying this out on. for this particular tetranucleotide instance of this motif represented by this weight matrix. And then you can see that the top three sequences, which all have ATG, have the best scores. And the bottom one, GTG, even though it's a valid member of the learning set, it was something which was underrepresented statistically. GTG tended to be less frequently encountered than ATG and so it gets a lower score when you search the genome for it. So if you prioritize these, they would be prioritized in this order by 12, 12,12, 10. So now the final topic, which talks about a very simple and short motif, which is the CG motif. of them is recognition-- for example, is a particular sequence of protein start? In other words, does it have a score which is statistically significant? That's basically what we were doing, very anecdotally, in the previous slides. Or another task is discrimination. We ask questions like, is this protein more like a hemoglobin or like a myoglobin? The first question is about one sequence relative to, say, a weight matrix. The Other one is about two sequences, asking how-- or three sequences-- whether a particular protein is more like one than another. P of s/m, s bar m-- is the probability that you would get that sequence given a model. And as with any good probability, as we mentioned in the first class, they should sum to 1. We can also have the probability of a sequence in your population of sequences irrespective of model. These are probabilities which are not conditional. They do not depend on something else. And here's a very useful theorem, called Bayes' theorem, which is completely general. It doesn't depend on models and sequences. the middle, it means that you have the probability of the model given the sequence. It's called a posterior probability. Now let's see what all this Bayesian stuff is useful for. We're going to be doing-- of the various applications, we had recognition discrimination and database search. We'll have two models, a model that we actually have a hydrolase and the model that We have randomness. We want to report all the sequences where the probability that that sequence, given the model, is better than that sequence given a null model or random amino acids, that that is significant, and it's significant by the delta. between just the null versus the probability of the model in general. So if we look, if we, let's say, do a database search where we have scoring metrics just as the ones we developed earlier in the talk, we'll get one distribution in orange. And if we score for fide hydrolases, we might get this distribution in blue. And we're asking whether the probability. of getting a particular sequence given the model this is a hydrolase is better than. probability of getting that sequence at random, the orange. the dinucleotide level, and so on, and rather than just dump this on you as a mathematical fact, I want to give you some biological rationale for why you can have nonrandomness at every order of a Markov chain. And you might have a bias where C would be rare because the Cs mutate into Us. In organisms that lack a uracil glycosylase, which would then return it back to a C, Cs will change into Us because it's a very common chemical reaction. biases. And I just elaborated on one of them here, which is the triplet bias, documented here that this 10 times lower frequency of ATG than of some of the other arginine codons. So now let's talk about a Markov model. This is not a hidden Markovmodel yet. In just a moment, it will be. It's a MarkOV model because we're asking what is-- the columns that we had kept independent when we were making profiles or weight matrices. We've said that CGs are underrepresented in the genome as a whole, and they're over-represented in promoters. This particular transition of what's the probability of getting a G given a C in the 5-prime position-- this is one of those conditional probabilities. And so this particular arrow going from a C to a G is represented by this probability. And you can see going the other way is a different probability. That would be p of C given G. And these little arrows will refer to itself, is example of a p of an A given an A. There's 16 possible transitions, including four homopolymers, AA, TT, CC, GG, and 12 transitions of the other dinucleotides. We've got CG islands where the CGs have been protected from methylation, and hence, protected from mutations. And then outside are the ocean, which are not protected. And you want to know where the island begins and ends because that helps you know where regulatory factors are. And so when you look at a new sequence, you won't know whether you're in an island or not. are 0s. 0s are a problem, both for the CG dinucleotide in the ocean and for the transitions between oceans and islands. The way you handle it is called pseudocounts. You basically say, what if we just missed finding that thing? We're going to add 1 to it because however big the counts are, you can always add 1. And so you can see. You can actually calculate these conditional probabilities by hand in the privacy of your home, not while the hordes are waiting to get into the room. known islands, again annotated by some person. And you can see those that this A matrix, focusing on those things that were 43 and 0 before, now more realistic numbers are 27% and 8% for an island and an ocean. Now we're going to plug these numbers-- basically, I've cut off the transition tables, which are off to the right. Now let's use them to actually do an HMM. And the sequence we're testing is, is CGCG in an ocean or an island? What's your guess? extreme case. But this is actually using the numbers from the previous slide, which were taken from real oceans and islands. And so there are two possible places it can be, and they're equally probable. It's in an ocean or island, just given the C, 1/8. Now you make a transition where you multiply this times the A matrix, A sub k l, so you're going from state 1 to state 1, from an island to an island. And if you carry this all the way out to all four tetranucleotides, you get a much higher probability of being in the island.

ROUGE-1: 63.90, ROUGE-2: 61.33, ROUGE-L: 60.47
BERTScore: 71.04

==============================================
==================== [51/100] ====================
Summary:
There are five basic metals that are used in cookware aluminum copper stainless steel cast iron and carbon steel aluminum pots and pans. copper is one of the best conductors of heat it heats and cools rapidly whenever necessary and it's fairly heavy weight. If it is cheap or if it's thin it can have hot spots and you can't use it with acidic foods just like the aluminum soft metal. stainless steel is the preferred cooking utensil for most kitchens it's heavy duty easy to clean surface typically clad which we'll discuss later. Carbon steel is heavy duty if seasoned correctly can be non-stick it'll provide a unique flavor to foods and promote browning better. It holds onto its heat very efficiently and is less fragile than cast iron and is relatively inexpensive. The cons may require seasoning or re-seasoning before use and just like cast iron you should never soak in water and follow the same cleaning instructions. Allcloud is an amalgam of several different metals cladware sometimes referred to as allcloud because of its brand name is using different layers. in of metal including stainless steel copper and aluminum to be able to provide the benefits of each one of those metals with the durability and cleanliness of the stainless steel on the inside of the pan. Additional cooking materials include things such as non-stick coatings like teflon terracotta which is used in cooking things like tangents glass such as corning ware enamel wear which is also used in things like crock pots and things that are cast iron that have been coated with enamel and baked on in silicon. A saute pan or satwa is one with the straight sides and has a larger surface area which makes it ideal for tasks like searing meat or reducing a pan sauce. A sawtooth or skillet has a slope side and is used mainly in sauteing the slope sides providing the ample and perfect angle for flipping your food. A rondeau is a favorite staple in a chef's arsenal and should be in any home cooks as well sometimes called a brazer or brazier this wide somewhat shallow pan is. similar to a stockpot or dutch oven but not nearly as deep the pan has slight sides that are straight usually has two loop handles for easy carrying and nearly always comes with the lid generally it is made of stainless steel copper or combination of clad metals. Part of the rondo's allure is its versatility its shape lends itself well to searing brazing oven roasting frying poaching pan roasting and simmering or boiling this shape is deep enough to hold liquid for poaching or braising but shallow enough that it can evaporate. oven also make sure the pan is not too wide it should not be more than a couple of inches in diameter larger than your burner or it won't heat properly like stock pots or dutch ovens rondos come in a variety of sizes choose one that will accommodate the number of servings you usually prepare a six quart or seven quart version should be sufficient for preparing four to six servings a saucepot is a cooking utensil that is round and shaped with high straight sides and a longer handle equipped for a tighter fitting lid. Saucerpans are deep pots used for simmering stock and soups. saucier pans are shorter in height and are made with a sloping sides instead of a straight side. Both pans work equally well for the preparation of sauces and various foods stockpots. choosing a saucepan or saucer pan is typical typically a personal preference as both pans are typically taller than they are wider. They come in various different sizes to accommodate various different stocks or soup sizes and can even have a spigot at the bottom for easy draining. There are various different kinds of specialty pans including crepe pans which are shallow and thin and flat and used to make a crepe using the method of smoothing out the batter across the bottom roasting pans are used for roasting meats and vegetables they're heavy duty and can accommodate multiple pieces in large quantities whole turkeys and whole cuts of meat can easily fit into these pans. paella pans are specialty pans from spain used to making a spanish dish called a paella this is a cooked rice dish usually with seafood and woks are used to cooking and chinese cooking and asian cooking and are typically designed for a much higher much faster heat process. Large stock pots are taller than they are wide and have a capacity of at least eight quarts with two strong grab handles. This pot is great when you need to feed a crowd or make large quantities of food like potatoes or corn on the cob. A small saucepan is really versatile you can use it for cooking smaller portions steaming or reheating when shopping for pots there are a few common features to look for in a set of pots and pans. You don't have to purchase the most expensive brands to have a good quality set that will last. to look for these are stainless steel pots with thick bottoms they allow for even heating without scorching or burning. In any good quality set of pots you want tight fitting lids the lid helps bring things to a boil much faster which saves both time and energy when buying pots and pans pay attention to the handle i prefer a metal handle that way the pan can go from the stove top right into the oven just be sure to use a pot holder when you take it out now for saute pans commonly called frying pans. pancakes in this smaller pan maybe two eggs again the metal handle is great for moving from the stovetop to the oven to cook omelets or frittatas you should also have a good sized roasting pan this will hold about two maple leaf primed chickens a pan this size is also good for a roast or a turkey so these are the basic pots and pans you need to get started in the kitchen there are a lot more you could add but the best rule of thumb is quality over quantity. Polycarbonate and stainless steel containers called hotel pans are designed to be used to store small amounts of ingredients on a refrigerated make table such as a sandwich station. They come in sizes ranging from 4 6 8 12 18 and 22 quarts and they often come with matching or size lids to accommodate them. They wash well by either hand or dishwashing and can stand up to years of usage other food storage options include what is often referred to by polycarbonate's trade name lexan or by the company trade name cambro. from full size hotel pans two-thirds pans half pans third pans fourth pans six pans and ninth pans and various other sizes each size is available in six six inch four inch and two inch deep models. The name of the pan refers to how many of each would it take to equal a full size pan for example the nine it takes nine of the one-ninth pans or ninth pans to make one full-size hotel pan. Many of the configurations require the use of a spanner bar to prevent the pans from falling in [Music] notice that this two inch hotel pin will fit directly into this and it'll fit snugly. This is because you'll have water underneath in your four inch hotel pan that will be simmering. You do this by using sternos and these sternos will go in those little indents on the bottom and you'll fit this whole thing into a stand. You also have perforated hotel pans which are basically hotel pans with holes in them. These can be used as steamers you can use them to drain things in a steam steamer setup. no hole on the side that traps in steam and then you have a lid with a lid that will allow a spoon to stick out. You'll commonly see this on either buffet lines or like half brows any restaurant that is executing off of a steam table now we also have service pans also called mise en place pans. They come in the two inch four inch and six inch depth and so here we have a sixth pan because you can fit six into a hotel pan the same with the nine pans or ninth pan. called a third pan because you can fit three to a hotel pan now there are also half hotel pans which are simply just half the size of a hotel pans still coming in a two inch four inch and six inch depth. Large sheet trays which can be used for any number of things roasting reheating baking whatever you want to use them for and then you also have half sheet tray which are literally half a sheet tray now before we go one last thing you'll normally see these roasting racks were just a rack insert for largesheet trays and this is good for resting meats. Sip top bags are an indispensable storage device for kitchens. They allow the storage of dry goods and other small quantity items. They can be used in the freezer or refrigerator as easily as they can be in dry storage and they can even be used for sous-vide cooking. They come in a variety of different sizes but most common sizes are the full size and half size. The speed rack is essential for storage and movement within the restaurant. The ziploc can be left open wrapped with plastic for transportation and air protection or draped with a plastic bag. Not all cookie medals are identical cheap cookware often translates into cheaply made and burnt product. Specialty cooking surfaces allow for more versatility in the cooking process and different results. The right size storage bin is essential why store two quarts of stock in a 22 quart container it simply doesn't do the right job.specially designed shrouds are essential for the right size stock pot or pan to be used for the job. You should never use a rondo to simmer stock for a long time because evaporation will be more significant use a stockpot. it takes up too much room in your coolers and takeaway number six you can never have enough hotel pans no matter what size you have. This presentation will attempt to give an overview of the different small wares and pieces of equipment that you'll experience in a restaurant environment. It's not an exhaustive list for more information i suggest ktom.com which can be accessed at the link on the screen. For more information on the different types of hotel pans, visit hotelpans.com.

ROUGE-1: 71.66, ROUGE-2: 68.80, ROUGE-L: 66.82
BERTScore: 68.12

==============================================
==================== [52/100] ====================
Summary:
We're gonna continue the train of thought that we began last time, which has to do with the critique of The Enlightenment. Part of what I suggested to you is that you as poets move from Neoclassicism to The Enlightenment, part of what they're engaged in is a critique of a kind of impoverished view of mind or consciousness that over-relies on reason. And they therefore try to develop a higher faculty than human reasoning which they refer to alternately as fancy and imagination. All right so that's one problem with Enlightenment thought, that it is impoverished. that in fact there is something wrong with reason as a faculty, and this can take a couple of forms. One is that all of those nice ideals that come along with the enlightenment may in fact be parasitic precisely on the kinds of negative types of thinking that they are designed to get rid of. The other thing is that reason itself may not be as powerful as we think, that there might be other things going in, on within human consciousness that are either hostile to reason or are its opposite. takes over, things that go on when reason loses its purchase on the mind and the mind becomes maddened for example or goes insane. All of these things are things that Charles Brockden Brown starts to explore, right? So again I want to review some of the places that we've been. I mean we're moving towards the mid-term at the moment so we want to get our story straight here, we try to understand the larger story that we're talking about. Again the idea that enlightenment, from Kant, is an emergence from a self-incurred immaturity. The cause is not lack of understanding, but lack of resolution and courage. Edgar Huntly's story is a different kind of story altogether. Edwards and Franklin right, are two men who are, roughly speaking contemporaries. They are poised you might say in the cultural exchange between Calvinism and The Enlightenment. Edwards tries to appropriate enlightenment modes of thinking in order to bolster up US Calvinism. Franklin understands the continuing power of Calvinism as a mode of religious thinking but tries to minimize its cultural power, to use it where he must, but to promote a set of ideals that really do rely or promote the idea of reason. we called him also a kind of pre-romantic because he makes use of images that are drawn from nature. This is a very good passage for thinking about that. The soul of a true Christian appears like such a little white flower that we see. It's a literal process of enlightenment right? It opens itself up to the light of the sun, and we've talked I think over the past couple of days about the ways in which the poems and writing that have to do with The Enlightenment often use light itself as a trope. because a Calvinist would never say something like, the appearance of virtue was almost more important than the reality of it. But remember Franklin's idea of the erota and these are just a couple, some examples right? He believes that you can identify error. And you might say that part of your goal as someone living life is to try to see error for what it is and correct it. And one of the things we suggested was that in the process of writing his life, which and I suggested to you that that shares something in common with the kind of confessional mode started in the west perhaps by St. Augustine. self as author which requires him to create a self as character. And in so doing he's able as author to pick out the defective font [phonetic] of type those errors, and either talk about the ways in which he was actually able to correct them in real life in his real life, or, saying I wish now that I would correct that, I can point that out as an error. It's a sort of textural do-over as he rewrites his life. first to take many of these things for granted. The question is, how well does it go for him? Is this something that happens to him that in the end should lead him to question all of those ideas? All right so what I want to suggest to you is that Edgar Huntly is in fact exploring the dark side of The Enlightenment, the underside of it. It's turning over the rock to see what's there. And if you look at the back of your, I think it's. Passion comes from a Latin verb that means to suffer. That's why it's called The Passion of the Christ; it's what he suffers on the cross, all right? So, the passions are something you suffer. You're not entirely in control of them. But even more I wanted to point out to you the fact that the back of the book, the back. of the edition that you have, it describes this as a story of a young man who sleepwalks each night a threat to himself and each other. book tells you it's set in Philadelphia in 1787, all right? The same time as the Constitution is being framed a hop, skip, and a jump away. There's a way in which we might say this is also if not a critique, then a cautionary tale you might say about the principles of enlightenment that are enshrined in The Constitution. A kind of meditation on what the dangers to the new nation might be at the moment that the new country is being formed. Brown is an interesting character because he is one of the first US writers to try to take advantage of theFirst American copyright law which was passed in 1790.  copyright law doesn't protect US writers from being pirated abroad. It does nothing to prevent US publishers from publishing pirated editions of well-known books already circulating in the continent. So that seems like a bad thing for the aspiring US author. On the other hand remember what I said before, there is no patronage system in place in the early republic; therefore, what is emerging is a kind of marketplace for writing. Without that market, a young American author wouldn't be able to sell his writings and sustain himself as a writer. even a possibility you might say. In writing he is trying to do what in another age you might have done as a philosopher, or a professor or even a lawyer. He gives up the law because he feels that the United States doesn't need another lawyer. But he doesn't give up the idea of doing something that's morally good, all right? He thinks of himself as a teacher, and he says that the novelist should be thought of as a storytelling moralist. So I want you to see that there's a bridge to be made between the kinds of didactic neoclassical poetry that we were looking at. We didn't look at a ton of the kind of hagiographic poems that are in the vein of say the praised poem towards the Reverend Whitfield, the poem by George Washington and others. Brown wants to fulfill that didactic purpose, but he wants to reclaim a genre that already you might say is in bad repute, and that genre is the novel. So Wieland: or, The Transformation, and he says that his aim isn't merely to please the idle and the thoughtless, but actually he says to engage those who study and reflect. appears in 1798 and it's the first novel that he actually publishes, and he talked he echoes what he had said before there, and says that the novelist should be regarded as a moral painter. And he proposes, he says, to illustrate some important branches of the moral constitution of man. It's a very strange story actually, it plays on religious enthusiasm, it uses ventriloquism, it has an episode of spontaneous combustion. Brown, as a sort of man of The Enlightenment was very interested in science. And therefore he was interested in scientific oddities and brought them into some of his novels. page. An American Tale, right? He's stressing that he's doing something American. If you could read the little epigraph here it says from virtues blissful paths away, the double-tongued are sure to stray. Good is a forthright journey to still, and many paths but lead to ill. And yes, if you can actually see it, that is not an F,. that is an old fashioned way of setting an S. That's the way the S was originally printed at the beginning of a word. it mean to substitute F there. And that's one of those things where if you, he says he was aghast but he didn't correct it right away and then there was nothing to do but sit there the entire time. So don't make that mistake yourself. Okay, other thing. See he's taking advantage of the copyright law which has been passed just 8 years before in his first novel Wieland: or, The Transformation: An American Tale. So 1, 2, 3, culminating in Edgar Huntly, all of them in 1799. about it a little bit but there is a certain kind of haste that is evident in the plotting of Edgar Huntly. There are red herrings, there are loose ends that are not exactly tied up, and that might be the result of the fact that it was the third book that he wrote in that particular year. So that's one of the things to bear in mind. Brown is writing in order to transform the novel into a higher form than it's thought to be, and he's writing something that is not within the main line of novelistic writing. happy, many, many pages. Has anybody read Clarissa or an abridged Clarissa? Clarissa's a seduction narrative right, in which a middle class heroine is menaced and finally seduced and raped by an aristocrat. And you might say right away in the early English epistolary novel there's the worry about what it is we're writing and reading. And one of Laurence Sterne Tristram Shandy actually makes fun of this little thing [inaudible]. The novel starts to question its own devices early on. Susanna Rowsan's Charlotte Temple is probably the earliest example of this. Brown is not writing in this tradition. He is writing, trying to write over against this tradition and you could see that again, this is a front matter from an early novel. The Power of Sympathy which is thought to be the first American novel published. It's an endless kind of thing. And you can see that you can't get to the end. look at it. To the young ladies of United Columbia, these volumes intended to represent the specious causes and to expose the fatal consequences of seduction to inspire the female mind with a principle of self complacency. So that's what The Power of Sympathy is, but it addressed to young women. So there's something feminized about the form of the novel in this period which is part of why it is, you know regarded as a kind of lower form of writing, not really literary. fiction. And what is fiction, if not the opposite of truth? Fiction means lies, right? Why would you read this? If you do it's got to be only a guilty pleasure. So fiction, as opposed to fact, fiction somehow has falsehood. Therefore early novels try to insist on their basis in fact. Don't worry about this, it's based on a true story. As if there were something that would then could be morally improving for that. There's a certain way in which part of the problem for writers like Brown, and you might say for Romanticism, is how to take some of the prestige. that is you know linked to the to some of the prestige factuality and history and transfer it over to fiction and literature. How to create the literary as a category that is separate from the bible and sermons and biographies and history. A category that's going to be linked to this other faculty of the mind called imagination. This is part of the larger project of romanticism of gothic fiction. It's part of Brown's project as well. All right so that's the kind of regime of facts, the tyranny of fact. a young lady who has attended her dearest friend to the altar, a few months after marriage which perhaps, but for her had been a happy one, to fix her affections on a friends husband and by artful blandishments allure him to herself. Be not staggered such moral reader at the recital. Such serpents really are in existence. I have seen two poor disconsolate parents drop into premature graves miserable victims to their daughter's dishonor and the peace of several relative families wounded never to be healed again in this world. Why? Because they read novels. come on. Do we really think books are dangerous? Most of us probably don't. I mean can you imagine that a book's gonna cause like what, social unrest? Maybe it's better to live in a culture where they actually do persecute the novelists 'cause it would mean that literature matters. Well literature mattered to these people. Here it's negative, but they thought that novels were actually dangerous. You could read a novel and become depraved. That's part of what he is trying to promote Virtue comes from the Latin roots of man. guy. He's more like he's talking about these things, manliness and courage and the ability to act decisively, right? So Brown is trying to find a form of the novel that can be used to instill virtue and all of these other qualities. In part because he wants to say that you know to accept that kind of separations of fear does neither men nor women credit. So if we could get away from this idea that somehow there's something feminized about the novel, it's good for both sexes. be pronounced that no one was ever an extensive and especially a habitual reader of novels even supposing them to be well selected without suffering both intellectual and moral injury and of course incurring a diminution of happiness. Okay, this is the context in which Brown writes this book. Now, let's think about virtue again. The form that Brown decides to use is the Gothic novel. The Gothic novel isn't, is a forum that in the English context is probably pioneered by this guy, Sir Horace Walpole. it's a Gothic cathedral. They're gorgeous. But it becomes a pejorative term by this time that is, that takes on the medieval association and makes you think of you know it's so Gothic, it's medieval. Romantic writers are gonna mobilize the medieval and Gothic and dark over against The Enlightenment to show you what's wrong with The Enlightenment. Story of the Castle of Otranto, a villain named Manfred who lives in the castle and rules his realm unlawfully. His grandfather has poisoned the rightful ruler whose name was Alonso. goes on. The villain who is now ruling named Manfred wants to marry the son, marry his son off to a woman named Isabella who's the daughter of a Marquis. In one of the novel's many supernatural events, a giant helmet falls out of the sky and crushes Conrad. So Manfred then decides to marry Isabella himself, whom he, you know he's hoping that it'll kind of firm up his succession when and he's, a young peasant named Theodore that Isabella is really interested in. the rightful heir of Otranto and we have a happy ending in the end, okay? The ghosts are real. And one of the things that Walpole said about The Castle of O Tranto which he published anonymously, was that later on he said, it's not everyone that may play the fool with impunity. Right so again it goes back to that model of artistic production. He's a nobleman, he has spare time, he can write a book,. he can publish it. It's no big deal. Later on however, with the success of the novel, he takes it more seriously and he says in fact that the novel had he said,. freed up great resources of fancy. of a trifle nevertheless has a role to play because it frees up these resources of fancy. Walpole had a decided predilection for what may be called the Gothic style, a term which he contributed not a little to rescue from the bad fame into which it had fallen. But it's interesting that the novel, the Gothic novel itself as a form doesn't take off in 1764. It has to wait about 25 years in and around the French Revolution and then it really takes off when a woman named Ann Radcliffe writes her Gothic novels. like that. There appear to be manifestations of the supernatural. She often finds herself in the various kinds of settings crumbling castles, dungeons, graveyards, darkened churches. Usually she almost escapes her persecutors, then they catch her. They are trying to get her out of greed or lust or both. In the end, all of the ghosts and supernatural manifestations that have tyrannized her are shown to be fakes. They're people in costumes or [inaudible] effigy's or there's some machinery. It's a very popular formula and it continues to this present day. it, if you go back to classic Scooby-Doo which would be the early the first season, [inaudible] on DVD 1969, the ghosts are never real. It's always Mr. [inaUDible] in the blah blah blah. So, later on there was one cartoon called Scooby.Doo and Zombie Island or something where it's much later on and Daphne's like. oh my god [inaudsible] she's now a reporter she says but you know what, the. ghosts are always fake. So they go looking around New Orleans for a real ghost and eventually they actually find one. just too much of the actual supernatural. Classic Scooby-Doo is Ann Radcliffe. The ghosts are fake. Okay, but there's another tradition of Gothic that happens at the same time. Matthew Gregory &quot;Monk; Lewis got this nickname because he wrote a very famous book called, The Monk. And The Monk you might say is really horrific Gothic. In it the ghosts are real. It is blasphemous. The story goes something like this, again it's Italian right. Ambrosio is a man who's so repressed and severe that Shakespeare calls, what does he say? He scarce confesses that his blood flows. He's soon readily corrupted by a satanic woman named Matilda who gains access to his cell by disguising herself as a young nun. They become lovers, naughty, naughty. But he soon gets tired of her and of course she's promoting this, and he dreams of possessing a 15 year old girl named Antonia, who is the daughter of a preacher. Elvira who is a noble lady who is one of his, you know in his parish. He's her confessor. With the aid of the satanic Matilda who conjures up the devil also for added backup, Ambrosia gets into Antonia's room and is about to rape her. So he kills Elvira by smothering her with a pillow, gives Antonia a sleeping potion, and throws her in the dungeon. Later on, he does manage to raped her among the rotting dead. She cries out so he kills her. a little bit of Mary Rowlandson. Anyway, let's just listen to this, I won't bother to put it up. My, this is Agnes speaking toward the end of the novel, my grief unavailing, my infant was no more nor could my sighs impart to its tender little frame the breath of movement. I vowed not to part with it while I had life. Its presence was my only comfort. It soon became a mass of putridity, and to every eye was a loathsome and disgusting object. To every eye but a mothers. In vain did human feelings bid me recoil from this emblem of mortality. I persisted in holding my infant to my bosom and lamenting it, loving it, adoring it. Hour after hour have I passed upon my sorrey couch contemplating what had once been my child. Sometimes the quick, cold lizard roused me leaving his slimy track upon my face and entangling itself to the trusses of my wild and matted hair. waking around my fingers ringed with long worms which spread in the corrupted flesh of my infant. So this conflation of this kind of carnal house, you know disgusting flesh, morbidity, is part of this stream of the Gothic in which as I suggested the supernatural as real. We should go back to the story of Ambrosio. He manages to escape their clutches by selling his soul to the devil. Except he doesn't quite specify the terms of the bargain well enough so he's immediately transported by a demon to the top of a mountain peak. There's a kind of weird conflation of supernatural demonic activity, sexuality, violent and disgusting death. This is come all the way down to current slasher movies and other, and you know the kind of torture porn that people have been watching the last couple of years. It's all part of this larger idea of this strain of Gothic. And one last thing to say about this is the, what I just read to you from The Monk really might be considered a form that we could call the anti-sublime, right? The sublime is kind of like the romantic emotion par excellence. It's what they are try, they are striving to recreate. In a sense, Matthew Lewis's disgusto Gothic is actually making fun of that. Ann Radcliffe makes a distinction between what she calls, let me see if I have it here, the distinction between terror and horror. So Monk Lewis' Gothic is horror. Her Gothic she would've offered was a form of terror, okay? Finally, this is a rather famous if somewhat overstated account of what's going on in the Gothic novel. is still a very interesting book although if you read the subtext of the book, it suggests it's an account of American literature says that a lot ofAmerican literature is about cross-racial friendships and more between men. [Inaudible] he has a wonderful chapter on the Gothic novel and [inaudible] writes this, the guilt which underlies the Gothic and motivates its plots is the guilt of the revolutionary haunted by the paternal past which he has been striving to destroy. And the fear that possesses the Gothic is that in destroying the old ego ideas of church and state, the west has opened a way for the eruption of darkness. think there's a cultural reason why Gothic takes off, not when Walpole writes, but when Radcliffe and Lewis do. All those democratic ideals, liberty, equality, fraternity, turn into the horror of the terror, and that's a terror that is a horror. And you could see that in the United States there's this idea that in overthrowing what [inaudible] calls the old ego ideals of church and state we're opening up a new, a new moment. Right what, remember Jefferson's quote, that not everyone is born to be booted and ridden by other people. There's grounds of hope for everybody, he says. But it also means destroying old systems of obligation. What if the total depravity of human beings is true, not because of something called the fall of human kind, but just because that's human nature? Then, we've got a big problem. All of this you might say is the context for Charles Brockden Brown's Edgar Huntly. Okay? Now, let's take a look at the first pages of this. This is the preface. to Edgar Huntly on page 1 of the text. It's in the part that's called, to the public, right? And this lays out what we might think of as the project of American Gothic. Look at the third paragraph, well no let's just look at the whole thing. So, he says America has opened new views to the naturalist and politician but it has seldom furnished scenes to the moral painter. That new springs of action and new motives to curiosity should operate that the field of investigation opened to us by our own country should differ essentially from those which exist in Europe. is the purpose of this work to profit by some of these sources to exhibit a series of adventures growing out of the condition of our country. One merit the writer may at least claim that of calling forth the passions and engaging the sympathy of the reader by means hitherto unemployed by preceding authors. Puerile superstition and exploded manners, Gothic castles and chimaeras are the materials usually employed for this end right? If you're not writing seduction obviously you're writing Gothic. And if you're doing English Gothic you'reWriting about these stupid things. But here in the United States we have an opportunity. wilderness are far more suitable and for native of America to overlook these would admit of no apology. These therefore are in part the ingredients of this tale, and these he has been ambitious of depicting in vivid and faithful colors. The success of his efforts must be estimated by the liberal and candid reader. So that's the project of American Gothic, and that whole question of what are we supposed to do. I mean you know again think of Barlow; I'm gonna use Neoclassical poetic machinery, I's gonna give it a new world subject the hasty pudding and we're gonna come out with this great poem. giant knights and you know demons and all that stuff, but there are monsters in those woods here in the United States, all right? I'm gonna write about those. Take a look at the beginning of the novel, allright? It is adopting this epistolary form. So it's a series of letters that Edgar Huntly is writing down. Page 5, I sit down my friend to comply with thy request. At length does the impetuosity of my fear as the transports of my wonder permit me to recollect my promise to perform it. language of enlightenment right? My faculties. Terminated in repose. This will, proleptically remind us of what Wordsworth would later write about the way poetry springs, from emotion recollected in tranquility. That's theoretically what we're getting here. Turn the page. The second full paragraph he says this, how short is the period that has elapsed since thou and I parted, yet how full of tumult and dismay has been my soul during that period. How [inaudible] and enormous the transition from uncertainty to knowledge, exclamation point. Light burst on my ignorance.  Edgar Huntly becomes interested in Clithero Edney right? Remember what I said about doppelgangers last time. Take a look on page 15. This is in the second chapter. He worries about the possibility of behaving rashly here he says. Find it? He found it. Found it. Is it? Is this a story about enlightenment? Let's skip a little bit further on. Let's take a look at page 15 of the book. You know the situation right? He has a good friend Waldegrave who's been killed. at the second, second to last paragraph on the page. But it suddenly occurred to me for what purpose shall I prosecute this search? What benefit am I to reap from this discovery? How shall I demean myself when the criminal, all right the one who murdered Waldegrave, is detected? I was not insensible at that moment of the impulses of vengeance. But they were transient. I detested the sanguinary resolutions that I had once formed. Right and that's a form of [inaudible] right, for talking about being bloody minded or being revengeful. Yet I was fearful of the effect of my hasty rage. be impossible to arm myself with firmness? If forbearance be the dictative wisdom can it be so deeply engraven on the mind as to defy all temptation? My late experience has been of use to me. It has shown me my weakness and my strength. Having found my ancient fortifications insufficient to withstand the enemy, what should I learn from thence but that it becomes me to strengthen and enlarge them? No caution indeed, he says, can hinder the experiment from being hazardous. Is it wise to undertake experiments by which nothing can be gained and much may be lost? Curiosity is vicious if undisciplined by reason and inconducive to benefit. insane. And he says oh curiosity if vicious if undisciplined by reason. Okay, so we can keep curiosity in check and disciplined if we use our reason. But how does that square with what he says in the next paragraph? I was not however to be diverted from my purpose. Curiosity, like virtue, is its own reward. Knowledge is a value for its own sake and pleasure is a next to the acquisition without regard to anything beyond. It is precious even when disconnected with moral inducements and heartfelt sympathies. Ask yourself is there something wrong with that pattern of reasoning. as you might say free from danger. Is knowledge a value for its own sake? And is it true that it's valuable, but it's even more valuable when you have a personal stake in it? There's something odd about Edgar's reasoning here, and the text is again one of these texts where the way which Brown has put it down seemingly through the words of Edgar should be allowing us to open up space between what Edgar is ostensibly realizing about himself and what we are realizing about Edgar. to your knowing cares, to the deep and incurable despair that haunts you to which your waking thoughts are [inaudible] from which sleep cannot secure you. I know the enormity of your crime, but I know not your inducements. Whatever you were I see the consequences with regard to yourself. That is enough. Why should the efforts of our misdeeds be inexhaustible? Why should we be debarred from comforter? An opportunity of repairing our errors may at least be demanded from the rulers of our destiny. he who killed Waldegrave inflicted the greatest possible injury on me. That was an error which reflection has cured. Be comforted, he says. And he says Clithero was still incapable of speaking here. All right, this is the confidence of enlightenment thinking. This is the kind of thing that somebody like Franklin would believe, right? He can diagnose what's wrong with this person. He can help him. Right? Take a look a little bit further down on page 32. My condition was not destitute of enjoyment. My stormy passions had subsided into a calm, portentous and awful. eve of being ushered into a world whose scenes were tremendous and, now he uses the term, sublime. He is indeed said I, the murderer of [inaudible] yet it shall be my promise to emulate a father's clemency and restore this unhappy man to purity and peace. That you might say is the ultimate statement of enlightenment principles and also of enlightenment hubris. The enlightenment will take the place of Calvinism, Christianity and everything else. Edgar will fulfill the role of a father. confessor. He will dispense the healing balm of rationality and reason, right? How does that work out? Chapter 4, page 34. The bottom of the page, Clithero abrades him. You were unacquainted with the man before you. The inference with to have drawn with regard to my designs and my conduct are a tissue of destructive errors. You like others are blind to the most momentous consequences of your own actions. They have brought my life to a miserable close. Clithero portrays Edgar here not as a redeeming confessor, but as an agent of perdition, of damnation. And if we look at what happens in these 4 chapters right, Chapters 4 through 8, which his Clithero's story, we see that he actually has had nothing to do with the death of Waldegrave. And the story reinforces the novel's picture of identity as confusing and inconstant right? Think about the motif's in there. There's that strange co-partnership of being that Mrs. Loramer has with her brother Arthur Wyatt. reconcile to common maxims might prove consistent with them. It's like it doesn't look like it makes sense but he believes there's got to be some design, something he can discover that will make it all make sense. I desire to restore him to peace but a thorough knowledge of his actions is necessary both to show that he is worthy of compassion and to suggest the best means of knowledge. So what is Edgar gonna do? A little breaking and entering. Take a look on the next page, Chapter 12, The Box. the hand and by which force could be exerted. Some spring therefore secretly existed which might forever elude the senses, but on which the hand by being moved over in all the directions might accidentally light. The process was effectual. A touch, casually applied at an angle drove back a bolt and a spring at the same time was sent in action by which the lid was raised above half an inch. No event could have been supposed more fortuitous, by chance than this. And a hundred hands might have sought in vain for the spring, the spot at which a certain degree of pressure was sufficient to produce this effect. last likely to attract notice or awaken suspicion. I opened the trunk with eagerness. The space within was divided into numerous compartments, none of which contained anything of moment. Tools of different and curious constructions and remnants of minute machinery were all that offered themselves to my notice. My expectations being thus frustrated, I proceeded to restore things to their former state. I attempted to close the lid, but the spring which had raised it refused to bend. No measure that I could adopt enabled me to place the lid in the same situation in which I had found it. enabled me to discover, to discover enabled me to push forward the bolt and thus to restore the fastening. I now perceive that Clithero had provided not only against the opening of his cabinet, but likewise against a possibility of concealing that it has been opened. The box cannot be restored to its former state. If you look inside it does look like it's a little bit of a kind of parody of the enlightenment mind. It has lots of compartments, it has kind of machinery. But Edgar can't understand it. You know the language is keeping you at a distance but you can see him starting to get a little pissed off, right? And reason is having a more tenuous hold here. And this this account of breaking into the box seems a little [inaudible] but, in a kind of neutral sentence like, in my efforts to press down the lid which were augmented in proportion to the resistance that I met with it, the spring was broken. It give us an account of Edgar's relationship with Waldegrave. It gives us our first glimpse into Edgar's personal life. The opening of Chapter 13 suggests that Edgar may be feeling guilty too because you might say he's torn by conflicting allegiances to his dead friend Waldegrave and to Mary. Take a look on page 124 where Edgar tells us that he isn't sleeping very well. But it isn't Clithero that appears in his dream. Third sentence, the top of the page. Me thought the sentiment that impelled him to visit me was not affection or complacency, but inquietude and anger. Some service or duty remained to be performed. by me which I had culpably neglected, to inspire my zeal, inspirit my zeal to awaken my remembrance and insight to me to the performance of this duty, did this glimmering messenger, this half indignant apparition come. And now some dodgy things come to light. Bottom of the page, and again this is maybe a critique of The Enlightenment. Waldegrave like other men early devoted to mediation and books had adopted a different [inaudible] different systems of opinions on topics collected with religion and morals. Edgar looks for these letters, on page 128, he finds that they're missing. This is the second full paragraph. I think it's this chapter if by now we haven't already that we start to realize that there is something wrong with Edgar's thinking process. Even more so perhaps on page 129, when he can't find the letter he finds himself lost in horror and amazement. I was not conscious of having taken it away, yet no hands but mine could have done it. On the last evening I had doubtless removed it to some other corner but forgotten it. page 130 when his uncle starts quizzing him about what he was doing last night. But why did you go upstairs the uncle says. You might easily imagine that the sound of your steps would alarm those below who will be puzzled to guess who it was that had thought proper to amuse himself in this manner. Upstairs? I have not left my room this night. It is not 10 minutes since I awoke and my door has not since been opened. Edgar has no idea that he's sleepwalking, right? that probably don't get fully worked out in the course of the novel. They are, they involve the appearance of a stranger named Weymouth who claims that Mary's inheritance from Waldegrave belongs to be their own. I mean, it's actually his own. And WaldEGrave hasn't left a record of it, but Edgar believes Weymour's claim, and something else comes out. This is on page 149. [ Pause ] Middle of the long paragraph. Think upon the merits and misfortunes of your brother's friend, think upon his aged father whom we shall enable him to rescue from poverty. I am not insensible to the evils which have returned upon us with augmented force after having for a moment taken their flight. I know the precariousness of my condition and that of my sisters, that our subsistence hangs upon the life of an old man. And the first act of whose authority will unquestionably be to turn us forth from these doors. Marriage with thee was anticipated with joyous emotions not merely on my encounter on thine, but likewise for the sake of these beloved girls to whom that event would enable me to furnish. an asylum. But wedlock is now more distant than ever. We start to see that there's a whole property motif that is sort of hidden and starting to come up to the surface here. He's been banking his whole future on the fact that Mary is supposed to inherit from Waldegrave. What doesn't, what happens if that doesn't happen? All right? So there'sa whole way in which you might say Edgar is self interested, that he only reveals to us in the margins of the narrative. He doesn't actually address it. "I love to immerse myself in shades and dells and hold congress with the solemnities and delicacies, secrecies of nature in the rude retreats of Norwalk" "The disappearance of Clithero had furnished new incitements to ascend its cliffs and pervade its thickets" "I cherish the hope of meeting you" "As I cherish my devotion to the spirit that breathes its inspiration in the gloom of forest and on the verge of streams" "You might say, it's this whole you know business of the sublime right?" in my rambles with some traces of this man, but might he still not live? His words had imparted the belief that he intended to destroy himself. This catastrophe however was far from certain. Was it not in my power to avert it? Could I not restore a mind thus vigorous to tranquil and wholesome existence? Right, we get back to that. So one of the things that Brown does as you might say maps the woods onto Edgar's mind. In exploring the woods, Edgar starts exploring facets of his own mind that have remained hidden from view. and I never sleep but with a candle burning at my pillow. Right, so from the confidence of enlightenment, now it's the pathetic I need to have a nightlight on, right? That's what Edgar has sunk to. What has caused all of this? His experience in the woods. And we'll take it up again on Wednesday, the experience of the woods, the story of Edgar's pit and the panther. I want you to look for the motif of light in the Panther scene, and also track one particular word, and that word is savage.

ROUGE-1: 71.10, ROUGE-2: 69.41, ROUGE-L: 69.14
BERTScore: 80.62

==============================================
==================== [53/100] ====================
Summary:
Markus Klute: We're starting a new chapter in which we look at tests and implications of special relativity. We started the entire discussion and evaluation of Lorentz transformations and the description of the paradoxes based on Einstein's postulates. One experimental test is stellar aberration, which we discussed can be explained by special relativity and by velocity addition. So this gives us some idea about what light is. Light isotropy is being tested in a new experiment that will reveal more about the nature of light. variety of different experiments, starting from Michelson-Morley, which basically tests that the speed of light is independent of the orientation of the apparatus. We can look in particle physics at the decay of a pion into two photons. And those pions, they can have a lot of energy, for example, with a beta of 0.999 times thespeed of light. And still the photons are of course of the same type. And that has been tested with the motion of binary stars, as we did in our pset. One of the hypotheses you could have is that the photon actually is a massive particle. This would directly modify Coulomb's laws, which are tested experimentally. Another class of experiment is where we look directly at time dilation, for example, in the decay of the muon. There is weird electromagnetic effect if you introduce a mass to the photons like torque on a magnetic ring. Again, here precision measurements have been performed. And they're all in agreement with the hypothesis that the photons are massless. muons in the laboratory as well and study them. Or we can put very precise clocks on planes, fly them around the globe, and compare them with stationary and just simply measure the effect of special relativity on those clocks. In all of this experimentation and experimental verification, it's important to understand the importance of uncertainties in the scientific process overall, he says. "Experiments can have biases as well. And one example of a biased experiment is here one by Walter Kaufmann who tried to measure e/m" bias. And he conducted the experiment at the time Einstein was proposing his theory. And, as experiments, they were inconsistent with Einstein. So he said Einstein is wrong. Einstein and Lorentz are wrong. Planck looked at this and said maybe, but Einstein's conclusion immediately by looking at this was, no, this cannot be. And it took a little bit of time to tee up those experiments until 1940. You can read more about this in this Wikipedia article about Walter Kaufmann's experiments. and optics, upon the principle of relative movement." We now know this was wrong, but scientific process happens in scientific environment. And I started this class by explaining that one needs to be open minded to learn and to study and to grow scientifically. And one has to question the assumptions, understand the assumptions when then go into measurements. So this is the first part of this chapter where we talk about tests. We will have a discussion of implications of special relativity as we move on from here.

ROUGE-1: 74.89, ROUGE-2: 71.51, ROUGE-L: 68.65
BERTScore: 74.22

==============================================
==================== [54/100] ====================
Summary:
This episode of Crash Course U.S. History looks at the history of the United States as seen through the lens of Marvel comic superheroes. We talk about how women transformed pre-Civil War America as they fought to improve prisons, schools, decrease public drunkenness, and end slavery. And while fighting for change and justice for others, American women discovered that the prisoners, children, and slaves they were fighting for were also victims of war and violence. The episode is presented by John Green. fighting for werenâ€™t the only people being oppressed and marginalized in the American democracy. So in the colonial era, most American women of European descent lived lives much like those of their European counterparts. Lower and working class women were actually more equal to men of their own classes, but only because they were, like, equally poor. In general, throughout world history, the higher the social class, the greater the restrictions on womenâ€” although high class women have traditionally had the lowest mortality rates. So at least you get to enjoy that oppression for many years. expected to marry and have kids rather than, like, pursue a career. Under the legal principle of â€œcovertureâ€™ actually husbands held authority over the person, property and choices of their wives. Also since women werenâ€™t permitted to own property and property ownership was a precondition for voting, they were totally shut out of the political process. Citizens of the new Republic were therefore definitionally male, but women did still improve their status via the ideology of â€˜Republican Motherhoodâ€™ it was a result of not having potties. So even living without rights in a pottyless nation, the Republican Mother idea allowed women access to education. Also women were counted in determining the population of a state for representation purposes. And then the market revolution had profound effects on American women, too. As production shifted from homes to factories, it shifted away from women doing the producing. This led to the so-called â€œcult of domesticity,â€ which like most cults, I am opposed to. domesticity decreed that a womanâ€™s place was in the home, so rather than making stuff, the job of women was to enable their husbands to make stuff. The rules here are simple. I either get the author of the Mystery Document right...oh, hey there, eagle...or I get shocked. Let's see what weâ€™ve got. â€œWoman is to win everything by peace and love; by making herself so much respected, esteemed.â€ and loved, that to yield to her opinions and to gratify her wishes, will be the free-will offering of the heart. â€¦ But the moment woman begins to feel the promptings of ambition, or the thirst for power, her aegis of defense is gone.â€ Well it was definitely a dude and I have no idea which dude, so Iâ€™m just going to guess John C. Calhoun because heâ€™s a bad person. No? Well, what can you do? It wasnâ€™t a dude? It was apparently Harriet Beecher Stowe's sister Catharine who was an education reformer. The idea of true equality between men and women was so radical that almost no one embraced it. Despite the economic growth associated with the market economy, womenâ€™s opportunities for work were very limited. Only very low paying work was available to them and in most states they couldnâ€™t control their own wages if they were married. Still poor women did find work in factories or as domestic servants or seamstresses. Some middle class women found work in that most disreputable of fields, teaching, but the cult of domesticity held that a respectable middle class woman should stay at home. in reform movements. Reform movements were open to women partly because. if women were supposed to be the moral center of the home, they could also claim to be. the moral conscience of the nation. Many of the most famous advocates for legally prohibiting the sale of alcohol in the US were women, like Carry Nation attacked bars with a hatchet and not because sheâ€™d had a few too many. The somewhat less radical Frances Willard founded the Womenâ€™s Christian Temperance Union in 1874, which would be a powerful lobbying group by the end of the century. 19th century. Women gave many temperance lectures featuring horror stories of men who, rather than seeking refuge from the harsh competition of the market economy, found solace at the bottom of a glass or at the end of a beer hose. Now don't get me wrong: Prohibition was a disaster, because 1. Freedom, and 2. Itâ€™s the only time we had to amend the constitution to be like, â€œJust kidding about that other amendment,â€ but itâ€™S worth remembering that back then people drank WAY more than we do now. Many women were also important contributors to the anti-slavery movement, although they tended to have more subordinate roles. Harriet Beecher Stowe wrote the terrible but very important Uncle Tomâ€™s Cabin. Sarah and Angelina Grimke, daughters of a South Carolina slaveholder, converted to Quakerism and became outspoken critics of slavery. Sarah Grimke even published the Letters on the Equality of the Sexes in 1838, which is pretty much what the title suggests. And they may have had had husbands. Like abolitionism, the 19th century movement for womenâ€™s rights was an international movement. Often American feminists travelled abroad to find allies, prefiguring the later transatlantic movement of other advocates for social justice like Florence Kelley and W.E.B DuBois. Most of the delegates at Seneca Falls, for instance, were from the middle class. There were no representatives of, like, cotton mills, but this didnâ€™t mean that working women didn't acknowledge the needs of working women. And other women recognized that women needed to be able to participate in the market economy to gain some economic freedom. Amelia Bloomer popularized a new kind of clothing featuring a loose fitting tunic, trousers, and eponymous undergarments. Bloomer and her pants were ridiculed in the press and in the streets, and this brings up the third important thing about the 19th century womenâ€™s movement. It faced strong resistance. Patriarchy, like the force, is strong, which is why Luke and Yoda and Darth Vader and Obi-Wan and whoever Samuel Jackson played...all dudes. Many womenâ€™s rights advocates were fighting to overturn not just laws, but also attitudes. Some of those goals, such as claiming greater control over the right to regulate their own sexual activity and whether or not to have children, were twisted by critics to claim that women advocated â€œfree loveâ€ The Equal Rights Amendment, despite being passed by Congress, was never ratified. But by taking leading roles in the reform movements in the 19th century, not just when it came to temperance and slavery, women were able to enter the public. American women changed the world for better and for worse, just as great men do. And along the way, they made â€œthe woman questionâ€™ part of the movement for social reform in the United States. In doing so, American women chipped away at the idea that a womanâ€™s place must be in the home. That might not have been a presidential election or a war, but it is still bringing real change to our real lives on a daily basis. Iâ€™ll see you next week. in comments where you can also ask questions about todayâ€™s video that will be answered by our team of historians. Thanks for watching Crash Course and as we say in my hometown, donâ€™t forget to be awesome. Back to the page you came from with this week's Crash Course video. Follow us on Facebook and Twitter @CrashCourse and @CNNOpinion. For more Crash Course videos, visit CNN.com/Crashcourse and follow us on Twitter @cnncrashcourse.

ROUGE-1: 64.84, ROUGE-2: 61.11, ROUGE-L: 62.84
BERTScore: 72.42

==============================================
==================== [55/100] ====================
Summary:
These are the last authors that we'll focus on in this time period some of their philosophy some of the writing styles and things that motivated them. We're really kind of bridging the gap between the victorian and the modern we're really transitioning. The more we know about it the more we can understand and hopefully appreciate their work a little bit uh in finer detail. We'll be focusing on the works of William Blake, Emily Dickinson and Emily Dickinson in the next few episodes of the series. self-taught um even after he you know it said his nervous breakdown and he went back the next year and finished his schooling but not with honors. He continued on his own time to go and study these classics and in studying these classics he got better and better and more refined and more educated and eventually that's where his job took him. Most of his poetry especially towards the end if you look on the right there the grief and poetry era you know especially the last of his poems. if you've noticed you know some of the you know most famous musicians you know a lot of their work comes from some of their pain and torment and struggle that they've had throughout their lives. You almost wonder would they be able to have obtained that enlightenment without suffering that pain so can truly anybody be rock star do you really have to be a troubled you know childhood or something i mean it's just something that people debate uh here and there but with houseman he can tap into that pain and that darkness. It's a short one to an athlete dying young by a e houseman the time you won your town the race we cheered you through the marketplace man and boy stood cheering by and home we brought you shoulder high today the road all runners come shoulder high we bring you home and set you at your threshold down townsmen of a stiller town smart lad to slip be times away from fields. It might even be active already some of you may have read it already. It's a bit of a departure from the usual stories we hear about young students dying young and things of that nature. where glory does not stay and early though the laurel grows it withers quicker than the rose eyes the shady knight has shut cannot see the record cut and silence sounds no worse than cheers after earth has stopped the ears now you will not swell the route of lads that wore their honors out runners whom renown outran and the name died before the man so set before its echoes fade the fleet foot on the sill of shade and hold to the low lintel up the still defended challenge cup and round that early laureled head will flock to gaze the strengthless dead and find unwithered on its curls. um you know a nice little song to some degree um there was a good flow a good meter and all of that um you know from the first stanza the time you won they're reminiscing of remember that time that we you know carried you chaired you lifted you up in celebration of whatever uh a compliment accomplishment you had oh that was wonderful and then the second stance is well we're doing this now today the road all runners come we're not talking about a race okay we're carrying you now shoulder high. medals and such um and so they would come and remember you we would come to think about this we will come and look at those as if they were curly as so much stuff on it as if it were a girls. So it's a piece that's uh you know to an athlete young you already know what it's kind of about um but really in essence the main thing is the reflection of the past and and kind of sad but written in a lyrical kind of way it's still kind of melodious and semi-enjoyable. okay the next one is much shorter if that's possible when i was 1 and 20. so when i'm 21 when I was 1 in 20 by a.e housman when I'm 21 i heard a wise man say give crowns and pounds and guineas but not your heart away give pearls away and rubies but keep your fancy free but i was one in twenty no use to talk to me. When i was 1 and 20 i heard him say again the heart out of the bosom was never given in vain just paid with size aplenty and sold for endless rue and i am two and twenty and oh tis truth is true okay the first few lines when i was 2 and 20 and i heard a wise man say give crowns and pounds and guineas but don't give your way. Don't fall in love you can spend money on them you can give them all this stuff but what ultimately don't you want to give them at this age? to talk to me i'm not hearing it i'm 21 i know what's best right you guys have all experienced that your folks you know at this age until you do something you're like no way I'm not going to do that. So within that year from 21 to 22 what did he give away his heart he didn't listen to the wise man that he was two and twenty and oh tis truth is true. He didn't listening to thewise man or wise woman in that case okay um and that's he even noticed this. he had heard mention that okay so now he is crushed okay he's been defeated to some degree because when i was 1 and 20 i heard him say again all the heart out of the bosom was never given in vain to paid with size of plenty and sold for endless rue sorrow remorse in the footnote there. So giving it out okay it's you're going to be getting some pain and you're opening yourself up uh for a lot of sorrow and remorse and he gets struggled so you can see this kind of as the lover's lament. here in when i was 1 and 20 the kid kind of learns his learns his uh his issues and still 22. that's still pretty young to learn um to learn a life lesson. That's when i learned a lot about myself. That was when I was 1 to 20. I'm 22 now. I've still got a long way to go, but that's a good thing. I still have a lot to learn. I don't think i've learned all of my lessons yet, but I'm getting there.

ROUGE-1: 78.43, ROUGE-2: 72.69, ROUGE-L: 69.51
BERTScore: 71.61

==============================================
==================== [56/100] ====================
Summary:
In this class, we'll talk about spin. Last week, we discussed the decay of a pion into an electron and a positron. The pion has spin zero, and the electron and the positron have spin 1/2. It is not easily possible to align the electrons and positron such that the spins of the particles are aligned such that their velocity can be calculated. We'll talk more about spin in the next week's 8.701 class. Back to the page you came from. In quantum mechanics, the spin of a particle with a vector is quantized, and in terms of its length and its components. The components, and along any axis, have eigenvalues, and they are listed here. And we find that there is 2s plus 1 possible values. So I'll pick here, just arbitrarily, the z axis. But the question-- it's an obvious question-- which axis is a sensible choice for this problem? So I want you to actually stop here and think about this. What are sensible options? physical state of particles, which axis are the right ones to choose-- or, sensible? There's no right and wrong in this discussion. Let me motivate this. If you look at the orbital momentum of a particle, that's given by r cross p, where p is the momentum vector of the particle. So now, if you're looking at the total momentum, we have to look add the angular momentum and the spin of the particles together. So this is a nice choice of coordinate system or of axis. of the particle perpendicular, and the transverse component is its angular momentum. This, then, immediately gets us to a new definition, then of helicity. You can define the helicity of a particle as the spin of the particle dotted with the momentum. So basically, for a fermion, which has a spin 1/2, you get plus 1.2 if the spin points in the momentum direction and minus 1.1 if it points in opposite direction. So now, if you go back to our particle here, off by here, decaying into an electron and a positron, spin is at 1-1. the same connection. The pion here is spin 0, and if you discuss this in the rest frame of the pion, the electron and the positron fly off in opposite directions, which means that the spin doesn't in align to 0. So that's why this is highly suppressed. It's not 0, because you can find-- you can put [INAUDIBLE] into a rest frame, where you're just basically looking at both particles from one side that was coming to you, and in that case, it's allowed.

ROUGE-1: 75.32, ROUGE-2: 70.32, ROUGE-L: 71.90
BERTScore: 76.77

==============================================
==================== [57/100] ====================
Summary:
In the 5th Century BC Athens was a direct democracy that encouraged wide participation through the principle of ho boulomenos, or anyone who wishes. This meant that any of its approximately 30,000 eligible citizens could win a position in the legislature. Most offices were filled by random lottery from a pool of citizen volunteers. This might strike you as a strange way to run a government, let alone a democracy, but it was the way the ancient Athenians ran their government. In fact, elections only played a small role in Athenian democracy, with most offices filled by lottery. could attend the ecclesia, a general assembly meeting several times a month. In principle, any of the 6,000 or so who showed up at each session had the right to address their fellow citizens, propose a law, or bring a public lawsuit. The Athenian system also relied on a 500 member governing council called the Boule, to set the agenda and evaluate proposals. Rather than being elected or appointed, the people in these positions were chosen by lot. This process of randomized selection is know as sortition.  democracy arose in Athens after long periods of social and political tension marked by conflict among nobles. Powers once restricted to elites, such as speaking in the assembly and having their votes counted, were expanded to ordinary citizens. By 21st century standards, Athenian rule by the many excluded an awful lot of people. Women, slaves and foreigners were denied full citizenship, and when we filter out those too young to serve, the pool of eligible Athenians drops to only 10-20% of the overall population. Some ancient philosophers, including Plato, disparaged this. Many modern democracies reconcile this conflict by having citizens elect those they consider qualified to legislate on their behalf. But this poses its own problems, including the influence of wealth, and the emergence of professional politicians. Could reviving election by lottery lead to more effective government through a more diverse and representative group of legislatures? Or does modern political office, like Athenian military command, require specialized knowledge and skills? You probably shouldn't hold your breath to win a spot in your country's government. But depending on where you live, you may still be selected to participate in a jury, a citizens' assembly, or a deliberative. poll, all examples of how the democratic principle behind sortition still survives today. Polls show that the principle of sortition is still very much alive and well in the United States today. The majority of Americans support sortition, with the majority of people in the U.S. voting in favor of it by a wide margin in the last presidential election in 2008. The most popular type of vote in the 2008 election was for the Democratic Party, followed by the Republican Party and the Libertarian Party. The Democratic Party won the popular vote.

ROUGE-1: 78.01, ROUGE-2: 68.00, ROUGE-L: 62.44
BERTScore: 73.16

==============================================
==================== [58/100] ====================
Summary:
Micheal FEE: Today, we're going to continue with our plan for developing a powerful set of tools for analyzing the temporal structure of signals. Last time, we covered Fourier series and the Fourier transform. Today we'll talk about the convolution theorem, noise and filtering Shannon-Nyquist sampling theorem, among other things. The series of three lectures will continue on Friday and Saturday. The lectures will be webcast at 10:30 a.m. and 11:00 a. m. ET. and spectral estimation. And next time, we're going to move on to spectrograms and an important idea of windowing and tapering, time bandwidth product, and some more advanced filtering methods. So last time, I gave you this little piece of code that allows you to compute the discrete Fourier transform using this Matlab function FFT. And we talked about how in order to do this properly, you should first circularly shift. And then circular shift again to get the negative frequencies in the first half of the vector. This shows an example where we took a cosine. as a function of time. At some frequency, here, 20 hertz. We compute the Fourier transform of that and plot that. So that's what this looks like. Here is a cosine at 20Hertz. And you can see that what you see is the real part as a. function of frequency. It has two peaks, one at plus 20Herz. And the imaginary part is 0. So any questions about that? Feel like I didn't say that quite as clearly as I could have? OK. we plot power in log base 10. A difference of an order of magnitude in two peaks corresponds to a unit called a bel, b-e-l. More commonly used unit is called decibels, which are 10 decibel per bel. So decibles are given by 10 times the logbase 10 of the power of the square magnitude of the Fourier transform. Does that make sense? Good question. All right, any questions about this and what the meaning of decibela is? which is 2 bels, which is 20 decibels. All right, now I just want to show you one important thing about Fourier transforms. There's an interesting property about scaling in time and frequency. So if you have a signal like this that's periodic at about-- I don't know, it looks like-- OK, there it is-- about 5 hertz. If you look at the Fourier transform of that, you can see a series of peaks, because it's a periodic signal. Fourier transform pairs are functions where you have a function. You take the Fourier transform of it. You get a different function. If you take the transform of that, you go back to the original function. OK? All right, so that was just a brief review of what we covered last time. And here's what we're going to cover today in a little more detail. We'll talk some more about the idea of Fourier transforms pairs. And we'll also talk about Fourier transformations in general. Convolution in the time domain looks like multiplication in the frequency domain. It's a very powerful theorem. We're going to talk about the Fourier transform a Gaussian noise and this power spectrum ofGaussian noise. We'll talk about how to use the convolution theorem to understand Fourier transforms of different types of functions. And then we'll look at how to apply it to different kinds of data sets, such as data from a computer or a computer network, for example. do spectral estimation. And we'll end up on the Shannon-Nyquist theorem and zero padding. And there may be, if there's time at the end, I'll talk about a little trick for removing the line noise from signals. OK, so let's start with Fourier transform pairs. So one of the most important functions to know the Fourier transforms of is a square pulse like this. The Fouriertransform of asquare pulse is a function called the sinc function. It's basically a sine wave that is weighted so that it's big. The Fourier transform of a square wave, of this square wave of with 100 milliseconds, is a sinc function. If we take that pulse and we make it narrower, 25 milliseconds, then you can see that the sincfunction, it's the same sinc. function, but it's just stretched out in the frequency domain. As you make the pulse in time longer, the bandwidth gets smaller. And it turns out that the product of the width in time and thewidth in frequency is just a constant. make the pulse in time wider, then the Gaussian in frequency space gets narrower. This is where the Heisenberg uncertainty principle comes from, because wave functions are just-- you can think of wave functions as just functions in time. So if the particle is more lo-- [AUDIO OUT] in space, then if you compute the Fourier transform of that wave function, it's more dispersed in momentum. OK, so the uncertainty in momentum is larger. It's very cool. spacing in the time domain is just equal to 1 over the spacing in the frequency domain. So that's another Fourier transform pair that you should remember. OK, convolution theorem. Imagine that we have three functions of time, y of t, like this one. We could calculate the Fourier transforms of that. And that's capital Y of omega. And then we have some other function, x of t,. And its Fouriertransform, X of omega, and another function g of tau and its Fouriers transform, capital G of Omega. So in this case, we're defining y as the convolution of g with x. a convolution. The convolution theorem tells us that the Fourier transform of y is just the product of the Fouriers transform of g and x. So that, you should remember. All right? I'm going to walk you through how you derive that. I don't expect you to be able to derive it. But the derivation is kind of cute, and I enjoyed it. So I thought I'd show you how it goes. So here's the definition of the convolved. What we're going to do is we'regoing to just take the. Fouriertransform of y. Capital Y of omega is just. the integral over all time dt y of t e to the minus i omega t. actually reverse the order of integration. We're going to integrate over t first rather than tau. Then we can move the g outside the integral over t, because it's just a function of t Tau. So now, we have an integral dt x of t minus tau e to the minus i omega t. And what do you think that is? What would it be if there were no tau there? If you just cross that out and that, what would that be? Anybody know? What that's? The convolution theorem relates convolution in the time domain to multiplication in the frequency domain. So if you take a Gaussian, some window centered around 0 in time-- this is a function of time. So what we're going to do is we'regoing to calculate transform of aGaussian times a sine wave. So I just showed you the Fourier transform of the Gaussian. Now I'm going to show you how to do the same thing with the sine waves. now right? So there's a little Gaussian pulse in time. We're going to multiply that by this sine wave. And when you multiply those together, you get this little pulse of sine. OK? [WHISTLES] Sorry, constant frequency. Boy, that's harder to do than I thought. [WHistles] OK, just a little pulse Of Sine. So what's the forehead transform of that? Well, we don't know, right? We didn't calculate it. But you can actually just figure it out. of that and can involve it with the Fourier transform of that. So let's do that. If this is 200 milliseconds wide, then how wide is this? AUDIENCE: [INAUDIBLE] MICHALE FEE: It's 1 over 200 milliseconds, which is what? 5 hertz, right? 1 over 0.2 is 5. The Fouriertransform of this sine wave-- and I think I made it a cosine instead of a sine. You can just know in your head that that's the product of a Gaussian and a sine wave, or cosine. And therefore, the Fourier transform of that is the convolution of aGaussian with these two peaks. There are many, many examples of interesting and useful functions in the time domain that you can intuitively understand what their Fouriertransform is just by having this idea. It's very powerful. Here's another example. We're going to calculate the Fouriers transform of this square windowed cosine function. So it's a product of the square pulse with this cosine to give this. Gaussian noise is a signal in which the value at each time is randomly sampled from a Gaussian distribution. It's that kind of wiggly, peaky thing. The Fourier transform of that is just two peaks. And we're going to eventually bring all these things back together. OK? All right, so what is Gaussian noise? So you can do that in Matlab. That's a very simple function. This returns a vector of length N, sampled froma normal distribution, with variance 1. wanted to show you what the autocorrelation function of this looks like, which I think we saw before. So if you look at the distribution of all the samples, it just gives you a distribution that it has the shape of a Gaussian. And the standard deviation of that Gaussian is 1. Now, what if you plot the correlation between the value of value of this function at time t and time t plus 1? Is there any relation? So they're completely uncorrelated with each other. correlation of this function with itself at different time lags. If we do that, you get a 1 at 0 lag and 0 at any other lag. So that's the autocorrelation function of Gaussian noise. All right, now what is the power spectrum? So we can take this thing-- and, remember, when we plot the power [AUDIO OUT] just plot the square magnitude of just the positive frequencies. Why is that again? Why do we only have to plot thesquare magnitude? of the positive frequencies? AUDIENCE: [INAUDIBLE] Gaussian, so they're all [INAudIBLE] MICHALE FEE: Yep. We're going to come back, and I'm going to show you that on average, if you take many different signals, many copies of this, and calculate the power spectrum and average them all altogether, it's going to be flat. But for any given piece of noisy signal, the powerSpectrum is very noisy. so now let's turn to spectral estimation. How do we estimate the spectrum of a signal? So let's say you have a signal, S of t. And you've got a bunch of short measurements of that signal. What you can do is calculate the power spectrum, just like [AUDIO OUT] for each of those signals. So literally, we just do what we did here. We have a little bit of signal. We Fourier transform it, take the square magnitude. And now, you average together all of your different samples. into short pieces. extracting that little piece of signal from this longer signal is essentially the same as multiplying that long signal by a square pulse. So that process of taking a long signal and extracting out one piece of it has a name. It's called windowing. Sort of like you're looking at a scene through this window, and that's all you can see. OK, so one way to estimate the spectrum of this signal is to take the signal in this window. And then apply this window to the next piece. problem with that? Why might that be a bad idea? Yeah. So instead of multiplying this signal by square pulses, we sample the signal by applying it by little things that look like little smooth functions, like maybe a Gaussian, or other functions that we'll talk about do an even better job. OK? All right. So that process is called tapering, multiplying your data by a little [AUDIO OUT] paper that's smooth, unlike a square window. Computing spectral estimates from each one of those windowed and tapered pieces of data gives you a very good estimate of the spectra. a noisy signal that has a little bit of underlying sine wave in it, if you take the autocorrelation of that function, you get a delta function and then some little wiggles. So there are ways of pulling periodic signals, periodic structure out of noisy signals. But it turns out that this method of spectral estimation [AUDIO OUT] did the most powerful way to do it. I'm just going to show you one example. This blue function here is noise plus the red function. And it's buried in the noise, so that you can't see it. we're learning about, you can see that that signal buried in that noise is now very easily visible. So using these methods,you can pull tiny signals out of noise at a very bad signal to noise ratio, where the signal is really buried in the noise. So it's a very powerful method. And we're going to spend more time talking about how to do that properly. All right, so let me spend a little bit more time talk about the power spectrum of noise, so that we have a better sense of what that looks like. So remember, I told you if you take a sample of noise like this and you estimate the spectrum of it, you compute the powerSpectrum of one sample. of noise. In order to estimate what the spectrum of noise looks like, you have to take many examples of that and average them together. And when you do that, what you find is that the power spectrum of Gaussian noise is a constant. It's flat. The power spectrum, really, you should think about it properly as a power spectral density. So there is a certain amount of power at different frequencies in this signal. And forGaussian noise, that power spectraldensity is flat. Itâ€™s constant as a function of frequency. low pass, by convolving a signal with a kernel. So when you convolve, that's the kernel for a low pass. And for a high pass, anybody remember what that looks like? AUDIENCE: [INAUDIBLE] MICHALE FEE: Yep. OK, so this was how you filter a signal. We're going to talk now about how you do filtering in the frequency domain. And then you subtract off a low-pass filtered version of the signal. if filtering in the time domain is convolving your [AUDIO OUT] with a function, what is filtered in the frequency domain going to be? MICHALE FEE: It's going to. be multiplying the Fourier transform of your signal times what? The Fourier transforms of things like that. All right, so here's an example. So in blue is the original Gaussian noise. In green is the kernel that I'm smoothing it by, filtering it by. Convolving the blue with the green gives you the red signal. Noise.noise.com: How does a Gaussian filter work? The power spectrum of that signal is going to just be aGaussian. Filtering in the frequency domain means multiplying the spectrum of your signal by a function that's low at high frequencies and big at low frequencies. Does that makes sense? So convolving our original blue signal with this green Gaussian kernel smooths the signal. It gets rid of high frequencies. It's that simple. Any questions about that? Well, yes-- multiply in the frequency, could you theoretically multiply by anything and that would correspond to some other type of filter? So why don't we just like throw away high frequencies? Or something like multiply by a square in thefrequency domain and correspond tosome different filter we don't know. MICHALE FEE: Yeah. You can do that. It would be convulsing your function with a sinc function. It turns out that's-- the reason you wouldn't normally do that is that it mixes the signal across all time. Gaussian, you're not adding some of the signal here that were over here. Convolving with a sinc function kind of mixes things in time. So normally you would smooth by functions that are kind of local in time, local in frequency, but not having sharp edges. So we're going to talk about how to smooth things in frequency with signals with kernels that are optimal for that job. That's Thursday. What would a high- pass filter look like in the frequency domain? So high-pass filter would pass high frequencies and suppress low frequencies. The Wiener-Khinchin theorem relates the power spectrum of a signal with the autocorrelation. If we plot this on a log plot in decibels, a Gaussian, which is e to [AUDIO OUT] like f squared, that's minus f squared. That's why on alog plot this would look like an inverted parabola. Any questions about that? I want to tell you about a cool little theorem called the Wiener/Kinchen theorem. The power spectrum of a signal is just the Fourier transform of the autocorrelation. What's the width of this in time? How would I get that from here? How are the width in time and frequency related to each other for-- AUDIENCE: [INAUDIBLE] MICHALE FEE: Right. The power spectrum is the magnitude squared of the Fouriers transform of a delta function. It's a constant. And how about our smoothed? Our smooth signal has a power spectrum that's a Gaussian in this case. width of this in time is just 1 over the width of [AUDIO OUT] So you have to take the full width. Does that makes sense? OK. Wiener-Khinchin theorem, very cool. All right, let's talk about the Shannon-Nyquist theorem. Any signal that has discrete components and frequencies is periodic in time. Anyone who's acquiring signals in the lab needs to know this. It's very important. And we talked about how if you have a signal that's periodic in. time, that you can write it down as a set of sets. frequencies that are integer multiples of each other. In these signals, time is sampled discretely at regular time intervals. Discretely sampled in time means that the Fourier transform is periodic. In fact, really be thinking that those discreetly sampled signals have a Fourier transforms that's actually periodic. There's another copy of that spectrum sitting up here at 1. It's also periodic. And I've been showing you the Fouriers transforms of those signals. But I've only been showingYou this little part of it. over the sampling rate and another copy sitting up here. So there are copies of this spectrum spaced every 1 over delta t. The sampling rate needs to be greater than twice the bandwidth of the signal. That means delta t is too big. These copies of the spectrum are too close to [AUDIO OUT] and they overlap. That overlap is called aliasing-- a-l- i-a-s-i-n-g. It's a little strange, but we'll push on because it's going to be more clear. signal has some bandwidth B that in order to sample that signal properly, your sampling rate needs to be greater than twice that bandwidth, 1, 2. Actually, there was actually recently a paper where somebody claimed-- I think I told you about this last time-- there was a paperWhere somebody claimed to be able to get around this limit. And they were mercilessly treated in the responses to that paper. So don't make that mistake. Now that's an amazing claim. Right? You have a [AUDIO OUT] time. All right, it's wiggling around. of what's happening between those samples. And I can perfectly reconstruct the signal I'm sampling at every time point, even though I didn't look there. So how do you do that? Basically, your sampled signal, you're regularly sampled signal,. has this spectrum-- has this Fourier transform with repeated copies of the signal, repeated copies. of the spectrum. The spectrum of the original signal is just this piece right here. So all I do is in the frequency domain I take that part. I keep this, and I throw away all those. square wave in the frequency domain equivalent to in the time domain. Multiplying this spectrum by this square wave, throwing away all those other copies of the spectrum and keeping that one is multiplying by a square wave. MICHALE FEE: Convolving the timeDomain sinc-- that regular train of samples, convolving that with a sinc function. If we take that function, which is a bunch of delta functions here, here, and here, it's like doing what? The Nyquist-Shannon theorem says that we can perfectly reconstruct the signal we've sampled as long as we sample it at a sampling rate that's greater than twice the bandwidth of the signal. So there's this cute trick called zero-padding, where you don't perfectly reconstruction the original signal, but basically you can interpolate. So you can extract the values of theOriginal signal times between where you actually sampled it. OK? And basically the trick is as follows. We take our sampled signal. We Fourier transform it. And what we do is we just add zeros. When you inverse transform, inverse Fourier transform, what you're going to have is your original samples back, plus a bunch of samples in between that interpolate. So you can essentially increase the sampling rate of your signal after the fact. Pretty cool, right? Again, it requires that you've sampled at twice the bandwidth of the original signal. Yes. From nearly all applications, you have a pretty good idea of what's going on. And then when we inverse Fouriers this, you can see that you have an array of zeros between and make it a longer vector. good sense of what the frequencies are that you're interested in a signal. And then what you do is you have to put a filter between your experiment and your computer that's doing the sampling that guarantees that it's suppressed all the frequencies above some point. And that kind of filter is called an anti-aliasing filter. So in that case, even if your signal had higher frequency components, the anti-Aliasing filter cuts it off so that there's nothing at higher frequencies. Does that makes sense? see something at the wrong frequency. That's an example of aliasing. OK? OK, so here's anexample. We have a 20 hertz cosine wave. I've sampled it at 100 hertz. So I'm, you know, 5-- so what frequency would I have to sample this in order to reconstruct the cosine? I'd have to samples at least 40 hertz, so those are the blue points. And now, if I do this zero-padding trick, I Fourier transform. I do zero- padding by a factor of 4. That means if I take the Fourier. transform signal and I'm now making that vector 4 times as long by filling in zeros, then I inverse. sample the signal in the time domain and then add a bunch of zeros to it before you Fourier transform. And that gives you finer samples in the frequency domain. And I'll show you in more detail how to do this after we talk about tapering. And it's very simple code actually. Matlab has built into it the ability to do zero-padding right in the FFT function. OK, let's actually just stop there. I feel like we covered a lot of stuff today.

ROUGE-1: 60.13, ROUGE-2: 57.18, ROUGE-L: 55.52
BERTScore: 73.74

==============================================
==================== [59/100] ====================
Summary:
The science of classical mechanics establishes an important principle of cause and effect. Newton's Laws of Motion established the scientific principle of analyzing observed phenomenon through the use of clearly articulated mathematical models. These concepts are so important to the modern branches of science and engineering that we require all of our undergraduates at MIT to take classical mechanics regardless of whatever course they intend to specialize in. In many high school level physics courses, mechanics is taught as a set of formulas to memorize for a series of standard situations. 8.01 assumes a strong background in high school level physics and mathematics. It is a rigorous and technically challenging course aimed at MIT undergraduates. The OpenCourseWare site contains a coherent set of lessons that will take you through all the basic concepts of classical mechanics. In each of these lessons, you will find a series of short lightboard videos that will help you understand concepts, mathematical derivations, and problems solving techniques. You will find many other useful resources including an online textbook, many worked example problems, and MIT. level problem sets. Developing a command of mechanics is a powerful tool for understanding the world around us. Welcome to 8.01, the latest version of the Java programming language. We hope to see you in the next edition of Java 8, which is scheduled to be released later this year. For more information, visit the official Java 8 website or follow us on Twitter at @joshjenson and @jenniferjenson. For the latest Java 8 news, visit our news page.

ROUGE-1: 74.58, ROUGE-2: 65.99, ROUGE-L: 68.47
BERTScore: 76.57

==============================================
==================== [60/100] ====================
Summary:
An independent set in a graph is a subset of vertices with no two adjacent. An important question in graph theory is given a graph, what can you say about the size of its independent sets? The following theorem, due to Caro-Wei, says that every graph G contains a large independent set. It contains an independent set of size at least the following quantity, summing over all v among vertices. For example, if the graph is this cycle on four vertices, an example of anindependent set would be two vertices like this. G, 1 over the degree of v plus 1. So let us prove this theorem first, and then we'll see an application and some ways to interpret this result. The proof of this theorem applies the probabilistic method. So we are given this graph G. And the first thing we'll do is order the vertices of G uniformly at random. So the edges are 1 to 2, 2 to 3, and 4. And let's consider the set I of vertices defined as follows. I claim that I is always an independent set. It will be impossible to have two vertices in I that are adjacent to each other. But in more complicated graphs, it can pick up additional vertices. I would pick out is a set of vertices such that-- so let's see if each vertices would belong to I. The first vertex appears before all of its neighbors. So we put the first vertex in I. But the second vertices do not appear before one of their neighbors, 1, so we do not put it in I as well. And the third vertices here also does not appears before its neighbor. And we don't put them in I, either. because one of them would appear before the other in the order, and that would violate the condition on how we chose I. Next, let's think about how large I is. Well v has D sub V with degree of V neighbors. And all the ordering are chosen uniformly at random, so this probability is 1 divided by V plus 1. And thus by the linearity of expectations, the expected size of this set I is equal to the sum over vertices V in G of the probability that this V lies in I. that induces an I so there is some I with the size of I at least the quantity that we just produced. So that finishes the proof of the Caro-Wei theorem. Again, it says-- the way to think about this theorem is that if you are given a graph g such that typically one does not have large degrees, then it must contain a large independent set. By considering the complement of this graph G-- by considering the graph complement, we switch, flip the edge and non-edges. Turan's theorem says that every n-vertex. graph G contains a clique on at least this many vertices. The biggest clique you have comes from taking one vertex. Turan's. theorem gives us some bound on the maximum number of edges that a. graph can have if it doesn't have a large clique. And furthermore, this bound here is best possible in the following sense. When n is not divisible by r, you need to do a similar construction, turns out to be best possible. G has a clique of size, at least sum over the vertices in G, 1 over n minus the degree of v. And here, let us use the convexity. of the function, sending x to 1 overn minus x. So this is a convex function, which allows us to lower bound the sum by n over n plus the average degree of G. And putting this into the expression, we can have a final expression strictly bigger than n overN minus 1 minus 1 over r times n.

ROUGE-1: 64.42, ROUGE-2: 61.20, ROUGE-L: 56.87
BERTScore: 79.37

==============================================
==================== [61/100] ====================
Summary:
Professor: Today I've got quite a lot of stuff to go through. So hopefully we'll get to the actual game playing, but if not, don't worry, you'll actually get to play the games. The games that we'll end up playing today are games from last year. A lot of them are actually the final semester-- the final project, which means they are not answering the same question that you're trying to answer with your very first project. But it should give you a sense of what the scope of this class actually is. a two week project, and that was just without staff. These were more like four week projects. And we'll design my students with larger teams and probably closer to the kind of game that you're going to end up making. I want you to keep in mind you're not constrained to building games that look exactly like those. All these games are like this sort of board game. You find out what this is. And you'll be able to do-- you can think a little bit about what would it be like to design a game that's not that. you just wanted to make your car game, for instance? You can. That's no reason why you couldn't. What if you want to do a live action game where you actually move around with your body, that sort of thing? That's totally doable. I really, really hesitate not-- try not to put any live digital components in your game. I know some people-- unless it's something simple like a timer that you can run off your iPhone. OK, maybe that's fine. By actually writing code, then the scope of this project just went through what I expected you to do. I want to-- I try to cover quite a bit of it from the first reading during class itself. Was anyone here not here on Wednesday? OK, all right. So we need to make sure that your name's on the attendance sheet. And you should come and talk to me after class. And we'll make sure you get a copy of the syllabus and everything like that. Make sure that you get expectations for this class. So I hope you got-- I got it allright. a game? AUDIENCE: (COLLECTIVELY) The players. PROFESSOR: The players, right, not the designers, not you. But you when you actually play someone else's game. Then you're the most important person. If that person's experience is problematic or exciting or engaged or outright hostile to other players, or something like that, that's making it the way that they want to take it. You as the designer are are going to run through a number of different challenges trying to be able to give them an experience that you're trying to create for them. hate the people around me, the table. And I don't like it, that is fine. It's OK for them to not like your game based on my criteria like that. However, one of the things that comes up in the Brathwaite reading is this concept of meaningful decisions, right? Well, what's-- Sid Meire how many of you heard of Sid Meier? Yeah, what games can people remember from-- AUDIENCE: (COLLECTIVELY) Civilization. might come up in the reading or occur to you right now? That a decision in a game can be meaningful-- what does it mean? What does it means to be meaningful? Couple hands? When you make that decision, the game's status changes or code that meanders the change? PROFESSOR: OK, so when you make a decision, and then the outcome actually has changed. So the corollary is that if you made a decision and the outcome hasn't changed, it wouldn't terribly be meaningful. OK? could be something really awesome in the game, and you make a decision. How about if you decide to roll a die? Game state has changed, usually. Is that a meaningful thing? It could be if it's like a choice you have. You roll a dice in one direction of the game or do you not, and choose different that's meaningful. It's like, do I roll the die now, or do I wait a minute before I take my turn? That's not really a meaningful decision. version of Candy Land which lets you choose which pile of red cards to draw from. But is that meaningful? A stack of randomly shuffled cards? Audience: Yeah, it has to do with [INAUDIBLE].. PROFESSOR: The thing is that they might be games but that particular decision may not be the meaningful one. And it's possible that in the entire game, maybe you don't get that many meaningful decisions. That doesn't necessarily make it not a game. It just means that these things aren't games. good game, which is a different thing. To a two or three year-old it maybe an awesome game. You get to play in a land of candy. A few more hands I thought I saw? AUDIENCE: Yeah, on that topic. I think there's a reason why people who over a certain age never really wanted to play Candy Land anymore because they realized that they don't really do anything, so they get really bored with it. For kids or some other targeted thing going on more than the meaningful decision, making it fun to actually just doing something and moving-- or winning cards that makes it fun. I believe Candy Land was invented to keep kids from getting polio from each other. That might be urban legend. With polio, you can't do much of anything. There's a huge inversion from the get out and get some exercise. It's a serious game. It has health benefits. Let's play it. I can actually play this with an adult? Learning how to take turns is one thing that people have actually get good at the games like Candy Land. I believe it was invented. play in the land of Candy. You make a decision in a game, and you've changed a game state. If you don't let the player know what changed the game state, is it that meaningful a decision anymore? You did something. Some numbers changed inside the system. It's good to affect how things go out later. But anyway, so what do you need to be able to communicate to the player that their decision actually changed anything? OK, actually let me flip that around. It wasn't a decision-- it wasn't-- I get to try to roll from three identical dice. you don't actually know what happened. And also if you expect players to get very into your game, this is the stuff that you can leave with because they will understand it and figure it out on their own. And that has to be part of the game. Whereas if you expects players to pick it up and play it three times in their life and then move on, then it probably won't help them that much and you should you should probably should probably. Does that sound familiar? AUDIENCE: I feel it's very much potential to player and the system. give them more feedback socially. There's a long term consequences, so a lot of immediate consequences. In Dominion, oftentimes you can draw cards that don't help you just pointlessly causing a reshuffle. But normally if I were to do this without thinking and thinking doesn't matter. Would it actually be slightly beneficial or slightly [INAUDIBLE] that actually do this? But unless you really think about it, you won't even notice that it caused any sort of change. If you have an adventure game where there's a story or something. And you tell some guys to just not help the guy. And then he becomes an evil warlord later. There's a specific point where you must-- if there's a dog, you need to give it a sandwich. Otherwise you're doing it yourself 200 turns later, like hours later in this game. Sometimes, your opponent sees something that you didn't see. And they changed their strategy based on that. I've played a number of adventure games that actually have this in them. There's a game called The Hitchhiker's Guide to the Galaxy text adventure. There is a game where you can't really see what your opponent is doing. more as a puzzle solving thing. So it's not like 200 turns later something changes. It's like something changes right away, and you need to figure out what changed. There's not immediate feedback. But I want to say I probably didn't enjoyed those games. Maybe someone does. Something-- Do you want to ask it? AUDIENCE: Well, you have to be careful that it doesn't have too much complexity or some sort of unanticipated change that there's too steep of a learning curve to actually enjoy it. game state changes, and you're not really sure how your decision came up with that outcome. So not random exactly, but overly complex maybe. You have to react on the fly. You can't just plan out all of your moves. Right, in chess you see the board and you-- a lot of the really good players will see X number of moves in advance. But when things happen, they just randomly appear. And so even though you make meaningful decisions, you don't know what the meaning is. "I just feel as a player, that would frustrate you to no end," he says. "It kinda turns it into a Candy Land game even if it's not" "We sort of did stuff, but we had-- and then afterwards, we didn't really understand. We didn't understand how we were changing it, but it took awhile before you really-- you don't understand," he adds. "I've played some word [INAUDIBLE] games that are hard to understand. And the mechanics aren't intuitive like Village" what's happening. And there are many games where you can do very poorly or very well. In a digital game, usually people have to take their turns and have to play out more slowly, whereas in a good board game, you change something and-- if you do something and something changes, maybe you can just start over and do it again like it's a different thing. Some games let you save state and then reload state. So you can can do trial and error. And it takes a while to understand exactly why you're doing very poorly. say, well, what if I tried this decision? And then there's an interesting phenomenon that goes with that in a lot of strategy games called save scrubbing. And that is where you know that the outcome of something is based on a probability. And so if you save and reload often enough, you will always be successful. But for a game whose random number seed has been saved and you fail and then you reload from the start, it means you'll always fail because that's a different concept of how the random number generator works. The book used to be called The Psychology of Everyday Things, which had a nice little acronym him of POET. But then people had trouble finding the book because he was looking for design books. And it was shelved in the psychology section. So he changed the name to The Design of Everyday things, which I think is a really interesting application of the kinds of things that he's talking about. So you get to re-roll exactly the same time, exact the same way, which means you've got to come. make a change and you iterate on it. And if you look at the copyright, it actually still Psychology of Everyday Things. He talks about visibility. And what does visibility do in a syst-- in a design? Audience: It helps people understand the qualities of what they're doing or what they want to accomplish. It gives them a clue on what they could do to accomplish that. So already, that's a direct application to games, right? You have a goal in mind. It's like I want to accumulate more cash. in a visual game, that's telling me visibly, right now, that this might be the way I get to do that. In a lot of strategy games, some of these things are very literal, right? So and so technology gives you this bonus. It's depending on the design of the game. But visibility has something to do with the intent of the player of the user in Norman's case. But he's not talking about games. He's talking about the user's intent. design of everything. And what the system can actually do, the actual operations of the system. The other thing is this concept of mapping, that there is this-- again, it has to do with the player's intent of what they want to do. But mapping, instead of the actual Operations of the System, actually has toDo it for the player. So I need to be able to convey to the player that this is not something you can actuallyDo in the game. You can tell which hex to move your tank, but that's it. what you can see of the system. So there are affordances and there are constraints. These are both words that are introduced in that reading. I think affordances is introduced in this reading. What's an example of an affordance? Audience: If you can sit on a chair? PROFESSOR: What about this thing tells you that you could sit on it? AUDIENCE: It seems sturdy, and it's got a place for your butt. PROFessor: Yeah, it'sGot a nice little butt-shaped thing, here right? It's not made of spikes. It's got at least three legs, which may help, and evenly distributed, which means that it's not going to tip over. handle on a door? PROFESSOR: What does a handle on adoor allow you to do? It's like-- it's a place for your hand. It's hand-shaped. If you hold your hand out in a natural way, you grab-- looking at the text. Oh, I wasn't thinking of that handle. I was thinking of the vertical type of handle. AUDIENCE: The one that looks like a U-shaped tube-- like that. PROFessor: Because they're not finger-shaped, although it has a kind of weird happy happy happy. face on it, which I always thought was a little bit strange about-- that might have been designed, too, actually. That might have something because if you-- this won't kill you, really. So you should put it in your home. I want to find out more about the history of the Edison plug. It's actually-- the design with the ground on the bottom is a bad idea because if something starts falling out that are too exposed to it, it will not be the ground one. But when it's the other way around, it's actually a little more stable. You could stick your finger in a British pin, which means they have to design all kinds of protection mechanisms, plastic springs, and things like that. It does have-- yeah, this one's actually nice because the biggest hole in there is the lethal hole. It's actually like a mo-- British plugs, actually, have the pin usually on top and-- AUDIENCE: The British just have the eyes [INAUDIBLE] pin. in there, is the one that doesn't have any current running through it. So they talk about materials like wood and glass, right? Glass is for looking through. Wood is for holding things together. And in games-- let me just bring in an example. Let's try to identify the components of-- how many of you have played put before? Really, really-- this is the box. I guess it affords reading, but I'm not going to talk about the rule sheet. about. It has this thing. Actually, what you do with this thing? AUDIENCE: Ring it. PROFESSOR: Slap? [BELL RING] Yeah, that's what it does. OK, all right, so now that you've seen what this thing does. What is one of the things that this-- not in the rule book completely. If you have this in your game, what is this thing good for? Audience: Getting attention, yeah. It's loud. You could use it to annoy people. comes with a bunch of cards. Ooh, whoa. What happened to these cards? Good Lord. OK, now the paint could rubbed off or something that. So don't worry too much about the text and the graphics. But just look at the card. What do cards allow you to do? What are the affordances of cards? Hm? Audience: You can hold a couple of them in your hand. Because there's two sides. There's a side that you can put no useful information on, right? Besides the brand of the game, sure. on their side. It's possible but really hard to make something, to make a card stand up. Other orientations other than that face up or face down aren't really considered. A square card could afford full rotation in any direction, rotation. We'll get that, actually, in the next one where you can just rotate things around. It'd be hard to do with a square or circle card, but a regular shape, an elongated shape. Stiffness and shininess of them distinguishes them. them from stacks. Cards do a lot. And when you're designing a game, you need to think about whether cards are the right thing for your choice, for your game. Something that might be a little subtle-- the rounded corners actually make it much easier for you to do things like this. If it wasn't around the corner, it's actually pretty uncomfortable to do a fan. It's not like you couldn't. You totally could. There are a bunch of things that cards do are already that you've identified which are all very accurate. stationary stores actually do sell punches, corner punches around of your cards. It is not something that I would actually recommend that you do during prototyping because it takes too damn much time. But if you were to design a game for home, for your family, or something like that, and you want to make it a pleasant experience. You might just want to spend $2 on a punch and just punch the corners out. It's really, really hard to do it consistently when using your hands, by the way. information from other people. And then there's the affordances of the system. Now if I wanted to hide my cards from you, then I will hold my cards in a way that only you can only see the side that doesn't reveal any useful information. So that's a very, very direct, clear what he calls natural mapping, although I am not quite sure that phrase is very easy to use in practice. It gets a little bit more complicated when you actually look at the system that the game is trying to reproduce, right? couple of things in this game that is this board. There's a back of the board, which is not colored. And it has a design on it. We could just pass this one around. It's got little playing pieces that are referred to as meeples by the hardcover board game fact base, I guess. They look like little people. Actually, there's probably enough in that for everyone to grab one or two. And then you can just take a look. Whoops, and a bunch of tiles that I will also hand out. the tiles suggest, just by looking at them? Terrain? PROFESSOR: Terrain, all right, something to do with land. What else? The various terrain features seem to match up. The fact that you've got a hidden back gives you quite a lot of different possibilities. This rule-- this game in particular uses mostly because of this shuffling and this randomization. You don't know what tile you're going to draw. The idea is that maybe you could freely, just freely rotate these things. that is probably a little bit less insightful for this particular lecture. It's a combination of all three. It is a scorecard. If you loop around, I think it means that you've got 100 points or 50 points. So you do something to move you along the path somehow. And then the first person to reach it probably wins. It makes me think that maybe instead of winning by just getting around, maybe every loop, you get a new tile or something like that. So it's probably just a scoreboard. just add 50 to your score every time that you go around. And what fits on those things? What would you place on that board? AUDIENCE: The little people? PROFESSOR: The meeple. You place the meeples on the tiles. You wouldn't place a tile on thatBoard because there's no hexes there. So there's a mapping of probably what intent that you've got. Let's make some big things and put our people on them. And the affordances of what you can do with these tiles that suggested that to you. a whole bunch of ways that you can help people with these sorts of mappings. I guess Donald Norman would describe a lot of these as spatial, metaphors to use. Spatial mostly to describe things like driving in a car and you turn the wheel to the left specifically toward the top of the wheel. And you car it's directed to turn left, that sort of thing. There are sort of bodily metaphors as well. Things that are high are either supposed to be good and happy, things that are low when you're feeling depressed. that you can play off. I'll give you a couple of more examples in about two weeks when we revisit the idea of user design. He talks about things like single control, single function where if you've got something that does something, you might not want to make it do yet another thing on top of it because that starts to get really, really confusing. I personally think this game will be a little bit easier to learn if they just gave you a different piece for the scoreboard that was the meeple. about is what do these tiles not let you do? Well, they did let you doing that, but was it easy? AUDIENCE: No. PROFESSOR: No, OK, all right. They're also not very good building materials, just like cards aren't. Holding a whole bunch of them is hard. And you saw the difficulty I had just trying to pull half of them out of the box. They were unwieldy. You can-- all right, maybe I'll do this once a game. just put the whole back hiding thing and just put them all into a bag and then just pull one out of random. So these are constraints. You're not really supposed to have more than one tile at a time in Carcassonne. You are supposed to draw one, figure out where it goes, put it down. So it's OK that the tiles are designed in such a way that it makes it hard for you to hold on to do. They are not very useful to you when you've got them face down because you can't really see the information. of cards, like in Pit, you really want then held face up, facing you. When they're face down, they're not interesting to you. So these are constraints. These are things-- this is another way that the visibility of the system can help you with those mappings. You're looking at the system and the pieces that it's giving you, and you're thinking, what can't I do with these things? And that's probably not what the game wants you to do. be designed poorly. That's a caveat. Everything that I say is a qualitative, subjective statement. As you play around with these pieces-- of course when you read the rules and you see the illustrations, maybe when they read it at the back of the box. Usually you start trying to figure out what a game is when you pick it up off the shell and you start looking at it. And it says, hey, this is a game that I want to play. It says Deluxe Pit, over 100 years of--100 years of card game fun, geez 100 years. The title of the game suggests things. It isn't like a commodity trading game. On the side, it says, "Corner the Market." And it's got a bell. This is like, this game back in the time when stock market are run with bells. I guess they still are but mostly just run with computers nowadays. I'd love to see Pit done on some sort of updated 21st century thing. Shout your Shout Your Shout! for the next episode of iReport.com. Deal and trade your cards to corner the market, et cetera. Family age seven plus, 30 minutes, three to eight players, just to tell-- to give you a better idea. When it comes to Carcassonne, there is actually a deep, deep problem with this game despite how popular it is. And that scoring is actually pretty difficult to do. It's a math intensive problem. It does largely map on to how many of the meeples that you have. you have of your own color on large patches of things. How much those things are worth requires a lot of counting. So that is a big problem with that game on how the mapping works. It doesn't really give you a good idea or a good conceptual model of how much something is worth. But you've got a large patch of thing. You've got your dude somewhere in there. You can at least make the mapping. That's worth something. And then that's-- the feedback that you get back from games when it's Pit. a couple of board games where you have to put pieces together, and that gives you an idea of maybe those two pieces don't go together. What others things look for in the realm of feedback when it comes to board games? AUDIENCE: Maybe a track? PROFESSOR: Hm? You mean a board track? Audience: Yeah, you want to stay on the track. If you fall out of it, you are no longer-- that's not a legal place for you to place your token. It doesn't necessarily mean anything but it's a good indicator. Just something like that would usually be nice to see you just quickly look at it and say, oh, this person's winning for this reason. In Monopoly, if you look at the board, whoever has the most houses. Similarly, in Catan, you can see if somebody has massive roads or a lot of settlements or cities. And, of course, in that game, you earn points by having the longest road. In poker and other games, other players are your primary feedback mechanism on whether you've done a move that's OK or not. In Mafia, all the information you're getting in the game is through other people in Mafia. In Battleship, there's information that's hidden from you, but it's completely available to your opponent and vice versa. Charades and Pictionary-- usually your teammates are the ones who are guessing, so I wouldn't necessarily call that feedback because it might be confusing. be good feedback on whether your clues are getting across to your teammate. But your opponents are also usually some sort of feedback mechanism that's keeping time. If they hear you say something, they go ah, ah,Ah. And are there a few more hands or something like that? So just always remember that you can employ other players into your feedback mechanism. It doesn't always have to be your game alone. The game is called Scotland Yard. The player positions is almost never known. You get some feedback about what he's doing. your objectives from the player that knows the information. The person who's running knows where they're going at any given time. The detectives are working on partial information to try to corner and close this dragnet. So I think that's on the list. Do you remember it? That was on the syllabus. It used to be-- Scotland Yard. But we may have changed the game. But that also falls in mastermind category of games where it's like, here's this person with all the information, only that person is changing the information as the game goes on. That's a big difference in Scotland. Donald Norman ends his very first chapter on why is it so hard to actually make something right? Anyone remember? Or anyone thinking of-- AUDIENCE: Doesn't the designer never really communicates one-to-one with the user? They're communicating through the object that either was designed or being used? PROFESSOR: That is definitely true. It is a second book. We do have a copy. We'll bring it in. It's a good game. We've gone through this huge list of things. order problem. You're designing something that then becomes this manifestation that somebody else uses. And that's actually when all the problems occur. Market forces push you to add things, to do additive design in order to distinguish yourself from the competition. That naturally leads to complexity in interface. And a lot of products, you said, don't get through that process because it'll take five or six times to get it right. But if it's not good by the second time, people just won't buy it. get back to iteration. 5 or 6 times means five or six times at the same problem, right? So iteration is the reason why design starts off as being very clunky. But it can eventually become something that works well, communicates well, or something that people can learn and maybe even enjoy in the case of the games. One thing that's funny about the book is that it talks a little bit about the clock radio that could do-- make phone calls, and be used as a desk lamp. And it's exactly the same thing they he's describing. what he's talking about only, I doubt that actually imagined that this was something to be possible at the time when he wrote it. That was 1980. And cell phones obviously have gone through a lot of criticism. But it is it has been successful through a number of different reasons. Don't discount marketing as being a big part of it. It's expensive for what it does. But then, arguably, by locking out a many things that you might want to do but maybe don't have to do, they are trying to make it easier for you not to do the wrong thing. something that the does sell. But what I want you to think about now is actually the process of prototyping. Prototyping might be something we'll leave up to Wednesday. So that there'll be a little more time for you to work in your teams. So I'd like you to start forming your teams, thinking about what kind of game that you want. And then the last hour of class, what I'm going to do is I'mgoing to go into brainstorming. to get all the Carcassonne bits back. So and then we'll pick this up in about five minutes. We'll be back with the rest of the story in a few minutes. Back to Mail Online home. back to the page you came from. Click here to read the full transcript of this article. Back To the pageyou came from, click here to Read the Full Transcript of this Article. Backto the pageYou came from the page You were from, Click Here to Read The Full Transcript.

ROUGE-1: 68.75, ROUGE-2: 65.94, ROUGE-L: 61.98
BERTScore: 80.31

==============================================
==================== [62/100] ====================
Summary:
The two-level problem is one that's exactly solved. It's one of our favorite exactly solved problems, although it doesn't seem to have any physical relevance. So we can take a two by two Hamiltonian and exactly diagonalize it. And that's done using a unitary-- or actually, in the case that we looked at, orthogonal-- transformation. And so we have talked about the two- level problem. Now if you looked at today's notes, you'll notice that they're very long and very complicated. it's a rotation in state space. And the rotation angle is an explicit function of the parameters in the Hamiltonian. Now all good things come to an end. We cannot do this for anything more than a two-level problem. But we can describe a transformation that diagonalizes the end level problem. And it has the same property of being unitary. But the good thing about it is it's solved by a computer. You tell a computer what the operator is, and it will diagonalize it. by two and does transformations. And it keeps doing that until the off diagonal matrix element is small. So that means that it doesn't matter how big the problem is. You just have to have a computer that's patient or fast and it will crank out the results. Now you need to know how to use the t matrices, or the t dagger matrix. These things enable you to solve basically any problem in time independent quantum mechanics and a lot of problems in time dependent quantum mechanics. is another way, and that's going to solve an n-level problem. It's called non-degenerate perturbation theory. We could also be working in the time domain, and we could we could be looking at some kind of quantum beating system or some decaying system. We make these measurements. But this is not why we do it. All spectra have buried information about the physical parameters of the system. That's what's kept me going for my entire career. We're not allowed to determine the wave function by any experiment. But we are able to observe the energy levels and properties of the Hamiltonian. The Hamiltonian is a fit model, a model where there are adjustable parameters which are the structural parameters. And today's lecture is mostly going to be on the interactions between normal modes of a polyatomic molecule. And it's in your problem sets. You're going to do that in the next lecture. I might start using buried.word encoded rather than buried. word encoded. that. So we go from what we can observe to a representation of it, which we call the effective Hamiltonian. And from that, we can calculate everything, everything that we could possibly observe, including things we didn't observe. So it's really powerful. It's a way of taking the totality of observations that you're going to make and saying, yes, I have looked inside this molecule and I've determined everything that I'm allowed to determine. And I can calculate the wave function. This is amazingly powerful. you the tools to be able to take any arbitrary spectrum and extract from it the crucial information. In the last lecture, we talked a little bit about matrix mechanics, and that involved linear algebra. And there is notation. And the notation is unfamiliar, and you have to learn how to use it. And so we have for example-- the analogy to the Schrodinger equation in matrix language. So it's an eigenvalue or eigen vector equation. And we can use the standard approaches, but it's useful. to work in matrix notation. We use these t daggers and ts to diagonalize the Hamiltonian. And when we have this in diagonal form, we can say, well, this equation is just E1, 100 et cetera. So for any eigenvalue, we have an eigen vector. Now what we'd really like to know is, how do we get these eigenvectors from the unitary transformation that diagonalizes H? We don't calculate this unitary-- yes? T dagger c equals c. This is telling you that the columns of t dagger are the eigenvectors. They are linear combination of the basis vectors that correspond to each eigenvector. And so it's possible to show-- and I don't want to do it. I did it last time. And then it's completely transparent. It's really quite simple. But it's just this extra notation. And it's easy for you to wonder, what the hell am I doing, until you've done it. the most common, doable problem, and it's also something that one does in experiments. You can set up a problem so that, with a short pulse, you prepare the system at t equals 0 in something that's not an eigenstate. And I like asking exam problems like this because it's easy to get hopelessly involved in ordinary algebra rather than just using linear algebra. So if this is the transformation to the eigenbasis, then the columns of t are the transformation back to the 0 order bases. of t are the rows of t dagger. Now why should you care? Because you don't know how to calculate the elements of the t matrices yet. With perturbation theory, it doesn't matter that the computer could solve for the t and t dagger matrices. But there's no insight. You just get the numbers. And so depending on whether you're doing a time domain experiment or frequency domain experiment, you're going to want to use either the columns of T dagger or T dagger. bunch of problems-- I'll go over here-- that are related to the particle in a box. And so one of the things that you might do is round off the corners because physical systems don't have discontinuities. Well, that's going to be a very modest change to the energy levels and wave functions. Another thing you may do is have a barrier, and you could put the barrier anywhere. Or you could do something like this. So the particle-in-a-box is a whole family of problems that you could solve using perturbation theory. and eigenfunctions. Now, for the harmonic oscillator-- again, you could put a barrier in the middle or you could make it an asymmetric like almost all molecular potentials are, where this is dissociation and this is two closed cells colliding with each other. And so that is harmonic near the bottom, but it's not harmonic elsewhere. And the Morse oscillator is a cheap way of generating something with this shape and then doing the perturbation theory to understand how the nonharmonic aspect of the Morse can affect the energy levels. n atoms, there's 3n degrees of freedom. There's 3 translations and 3 rotations. And so that leaves 3n minus 6. And all of that is vibrations. So we have many normal modes, and it's not too surprising that, if you stretch one normal mode, it'll affect the frequency of another. And we'd like to know that. So perturbation theory is really valuable for polyatomic molecules. And that's the bulk of the examples that I worked in the non-lecture notes for this lecture. to know J, CJ eigenstates. Once you have this, then you know how to write the time dependent wave function. And then there's the origin of life. You need two particles to come together and start to condense into a liquid. That's the beginning. Perturbation theory explains the long range interactions by which all gas phase particles attract each other weakly. So that's important too. And so you'll be able to do all of this stuff. So here we have non-degenerate perturbation Theory. And it is important too, because it is just mechanical and boring. a mind numbing, formal derivation. So we start out with this rotary equation. We say, well, let us expand the Hamiltonian. And let's put a little thing here. This is an exactly solved problem. And we do the same thing to the energy levels. So these are the. energy levels for the exactly solved Problem. And these are. the first order corrected energy levels, and these. are the second order correctedenergy levels. Now we write the Schrodinger equation with these three term expressions. we do is now we write the full equation and we sort it into sub equations corresponding to powers of lambda. So the lambda to the 0 equation is really easy. It's just H0 psi 0 is equal to E0 psi0. We could put n's on this. And this is the exactly solved problem. It says, yeah, you build your foundation from the Lambda to 0 equation, and it's just what you know already. And what you're going to do is use the psi n 0 and en 0 to do everything else. psi n 0. So we're going to get a bunch of terms. We have integral, integral. And on the left hand side, we have E n 0 integral psi n 0 psi n 1. Well, this is kind of an ugly term. It's a psi 0 and a psi 1. But we know that H, when operating on psi 0, gives E 0. And so we get a simple equation that is just H1 n n is equal to E1 n. first-order correction to the energy. And we can continue. The algebra isn't beautiful, but we end up getting the following equations. We have E n 1 is H 1 nm. And then we get the second-order corrections to theenergy, which is m not equal to n h n m 1 H m n 1 over En 0. And when we do that, we endup with this formula. This is the mixing coefficient, and these are the state-- now why do I exclude n? Because we already have it. all we need. Now it does say non-degenerate perturbation theory. And so it's subject to the requirement that H1 n m over E n minus E m. So if the energy denominator is near 0, we know we're in trouble. But for the vast majority of energy levels, this term is much less than 1. So that means we can deal with all of the interactions among the non- Degenerate levels in one fell swoop. And then we're just interested in this little subspace of the Hamiltonian. energy levels that we're sampling in our experiment. So the molecule more or less tells you how to focus on the part that you care about. And it just contaminates the wave functions a little bit. And if you wanted to know what that contamination is, you could deal with it. So this is your handy dandy key. And you don't need a computer, although when you see the horrible complexity that will result when you start dealing with these sums, you will say, well, I do want to use a computer. But now it's up to me to organize the program so that you can ask the computer to do what you need in a sensible way and you still get good answers. So in the notes, I'm dealing with a two-mode molecule. There are no two- mode molecules. There's one-mode molecules, and there might be three or four or six or whatever. But the complexity is the interaction between two modes. And so we're going to talk about that. Well, we know these are just ordinary harmonic oscillator. And we've got to do some work on this. And that's where perturbation theory comes in. levels are that some of the energy levels for the two independent oscillators and the wave functions are the products. So these then turn out to be the zero order states that you use to evaluate all the integrals here. And we have these and A and A dagger operators, which are enabling us to-- we have the operator for coordinate x is proportional to A plus A dagger. And this has a selection rule, delta V of plus and minus 1. So we like these things because we don't have to do any integrals. sorts of things to deal with the most important terms beyond harmonic. And so there's a cubic and there is a quartic. And although you haven't really explored this, what happens when you make dimensionless coordinates? You factor out something. And if you have cubic terms, they're 100 times smaller than quadratic terms. And the quartic terms are 100 times bigger than the cubic terms. So you don't need to go much further. And you could have Q1 cubed, but we already deal with that in the single-mode problem. Q2 cubed, and those terms usually are not important because they mostly are dealt with under here. These are the parameters, and these are the things that you need in order to understand what this molecule is going to do when it's excited. Now when I was a graduate student, there was a great deal of excitement about doing what's called mode-specific chemistry. Ordinary compounds cost on the order of $1 a kilogram. But if you could do mode specific chemistry, you could make things that aren't makeable by ordinary, organic chemistry. talk about the primary paths for the energy to flow and the rates. And that was a major area of research for the last 30 years. But it started out being IVR, yeah, anything can happen. It's statistic or whatever. But no, only specific things can happen, and they're controlled by these specific coupling terms. And you could calculate them. Now there's an interesting other thing. I told you that the first-order correction to the energy is equal to a diagonal matrix element of the correction term to the Hamiltonian. Non-degenerate perturbation theory works when the energy denominator is large compared to the coupling matrix element. And accidents occur when you have, say, a situation where omega 1 is approximately equal to 2 omega 2. And so you want to really know how to do these sorts of things. So you want the algebra that combines all this horrible stuff according to selection rule that leads to simplification of the formulas. And then once you've got everything sorted according toselection rule, then you can calculate what happens. isn't just blowing smoke. This happens an amazing number of times because stretches are higher frequency than bends. And it's very common for the bending modes to be roughly half or one third the frequency of a stretching mode. And so you get a resonance. So this is special because now it's violating the fundamental approximation of non-degenerate perturbation theory. But it's a two-level interaction. And these resonances have names. There is a Fermi and there is a Darling-Dennison. level V1 minus 1 V2 plus 2 V3. Because of the energy denominators, these two guys are nearly degenerate. One gets shifted up, one gets shifted down a little bit. And it might also be that this state is what we call bright and this is called dark. This state might be connected by an allowed transition from a lower-- an initial state and this might not. So the levels repel because they're interacting and they're out of position. But because of the interaction between these two levels, the eigenstates have mixed character. This is called a spectroscopic perturbation. This is the core of everything I've done for the last 45 years. And so you can learn about some of these coupling terms because, instead of hiding in the forest of these small corrections, you get a big effect. And it's easy to observe. And the last thing I want to talk about today is a little bit of philosophy. Among spectroscopists or physical chemists, there are two communities-- communities that like small molecules and Communities that like big molecules. dark state. The width of this thing is related to the number of dark states and their average coupling matrix element. That's called Fermi's golden rule. And so in this case, you get the main transition in an extra line. And if you have high enough resolution, you see that there is a whole bunch of eigenstates under it. If it's a large enough molecule, you couldn't resolve them anyway. We'll talk more about this in a few minutes. There is this dichotomy between small molecules where the vibrational density of states is always smaller until you get to really high energy. And bigger molecules-- now they're not very big. Benzene is plenty big for this sort of thing. And there is the question.about that later. So I think there's a pretty good place to stop because what I try to do is to show you, yes, it can be really complicated. But it's something that you can do, and you can project out the coupling constants. says, well, tough luck. You can't do spectroscopy in emission. But you can still see the absorption spectrum because then your signal is the removal of photons from your beam. So there's a huge amount of photochemistry and interesting stuff connected with a large density of states. And again, when I was a graduate student, there was a huge controversy about non-radiative transitions in medium sized molecules. And that got resolved by two gentlemen called Bixon and Jortner. names that any educated physical chemist will know to say, oh, that's the Bixon-Jortner. And they're still alive. They're still doing beautiful stuff. But anyway, that is all I want to say today. I will do details on one mode and Morse oscillator in other sorts of things next time. Back to Mail Online home. back to the page you came from. Back To the pageyou came from, Back to thepage you came From. Back into the page.

ROUGE-1: 69.44, ROUGE-2: 67.15, ROUGE-L: 64.25
BERTScore: 72.24

==============================================
==================== [63/100] ====================
Summary:
We also talked about axioms. Assumption you can say axiom assuptions, or you can says also properties that is this technology that we talking about satisfies. And I am going to talk about only few of them there are modes. So, one we said free disposal, what does it mean that throwing away inputs is cost less, you can dispose of inputs without spending any resources fine. In other word if certain amount of output can be produced by given amount of inputs, then the same combination of input puts can also be used to produce less amount ofOutput. In economics at least 1 input is required to produce some output, or more than you know more than 1 kind of output. So, the key word is feasibility technology. Feasibility technology represents the feasibilities that the combination of inputs and outputs, that can be achieved in this world even the current level of technology fine so that is free disposal. The second is no free lunch. And this is quite famous term that we use in economics again and again at no free Lunch and what does it mean here. out of nothing that is not possible in the real world. Third is non reversibility, what it means is that a production process cannot be reversed. So, if you obtain half kg of curd from 1 kg of milk, you cannot obtain 1kg of milk from halfkg ofCurd. That is what we are talking about no free lunch, that's what we're talking about. We're not talking about a free lunch here. That's not what we mean by 'no free lunch' in the process and labor hours spent in the process back. So, in that sense all the production and processes are irreversible. And if we have reversibility in the production process, then it would violate the laws of thermodynamics. Basically it is related to entropy, if you are not familiar with this term forget about it, but you should just remember that a production process cannot be reversed fine. Next is convexity ok, but before we talk about conveXity we are going to talk about additivity that we talked about earlier and divisibility fine what is additivity. Student: To produce 1 kg of rice ok, you need either let us say 100 grams of fertilizer or 50 liters of water. We need land, but that is fixed those are fixed, we are not talking about it only these 2 are variables. So, on average we are saying this is what it is not always true, but I am saying on average, what we can do is that we can produce 1kg of rice here, using 1 comma 2 and 1 minus t by 100, 2 comma 1. is possible, then we say that technology exhibits additivity. Another related, but it may sound different let us say, if it is technologically feasible to produce let us says y amount of output. And it is also technologically possible to produce y 1 amount ofOutput, then y plus y dash amount of Output is technologically possible. This is example of convexity; let us talk about additivity first. What is additivity? Let us say that a production plan is let us talks in sense of first production set, if there is a productionPlan y what does this production plan y means, that it gives certain combination of input and output that is feasible. If y bar and y bar dash both are feasible, then what additivity says that y bar plus y bar hat is also feasible, is it clear. Let us say let us take an example y bar is nothing, but 1 2 minus 1 minus 2 comma 1 what it means, that we are using 1 unit of input 1 and 2 units of input 2 and we are getting one unit of output. Now y barhat is let say two comma 1, then here now we're using 2 units and 1 unit and it leads. to it gives us 1 unit of output. Then this is also technologically possible, that we use 3 units of both the inputs 1 and 2 and we get then 2 units of output, in other word now let us come to divisibility. So, again we are talking about feasibility, we are againtalking about feasibility fine. If y bar is feasible production plan if ybar is a feasible production, then it is possible to produce y bar. And in the process we will use three units ofboth the inputs. plan, it means let us say this take one example, minus 1 minus 2 and 1 if this is a feasible production plan, then Lambda y bar is also a feasibleproduction plan. So, what we are saying is that a production process can be miniaturized ok, a productionprocess can be synched fine at this level. It sounds very you know it may not be possible sometime, but if we are talking about really large scale, then what we're saying that if we decrease all the inputs in the production process, then we can get half unit of output. same proportion, then output will also decrease in the same proportion and this is possible this is feasible fine. The easier is easier way easier although they these two are not same, but the similar 1 implies the other, but not the other way around. If this is the input combination and it is feasible to combine them, in this way and get some output, then also it is also possible to combine lambda x 1 to lambda x 2 of course, here we are not talking about the amount of output. are concerned about it whether it is feasible to combine the inputs in such a manner or not ok. When it is possible then we say that technology exhibits divisibility, or production set or technology is divisability in each other fine. So, let us look at it. . What it means? We have taken example where 1 unit of output can be produced using 1 unit. of input 1 and 2 unit of input 2. And similarly what we have discussed that this is also feasible. Then convexity says that there let us say this is y bar and this are y bar dash. Then or in other word if it's possible then y bar is an element in the production set. 1 unit of input 2. Now let us say we just do not want to produce 1 unit we want to production 100 units. So, 100 units we can produce by replicating this process 100 times. What we are using basically 150 units of both the input. And if we define this t not by 100 using say that t not. by 100 rather than using 100, we say it is t. So,. basically t 1 comma 2 1 minus t 2 comma 1 will give us again 1 unit of output. If we add these 2 up we will get 100 units of output ok. feasible here, y is taking care of not only inputs but also output. The combination is all given here and this exhibits convexity. This is a simple example of how to make a complex shape. The shape can be any shape at any time. It can be either a shape or a shape-shift shape. It is possible to combine two shapes to create a shape that looks like a shape shape. For example, the shape could look like the shape of a circle or a circle.

ROUGE-1: 58.79, ROUGE-2: 54.07, ROUGE-L: 52.26
BERTScore: 76.15

==============================================
==================== [64/100] ====================
Summary:
The Great Wall began as multiple walls of rammed earth built by individual feudal states during the Chunqiu period to protect against nomadic raiders north of China and each other. Under the Han Dynasty, the wall grew longer still, reaching 3700 miles, and spanning from Dunhuang to the Bohai Sea. The wall was formidable but not invincible. Both Genghis and his son Khublai Khan managed to surmount the wall during the Mongol invasion of the 13th Century. The Great Wall of China was granted UNESCO World Heritage Status in 1987. Originally built to keep people out of China, the Great Wall now welcomes millions of visitors each year. In fact, the influx of tourists has caused the wall to deteriorate, leading the Chinese government to launch preservation initiatives. It's also often acclaimed as the only man-made structure visible from space. In low Earth orbit, all sorts of structures, like bridges, highways and airports are visible, and the GreatWall is only barely discernible. main body and expanding this remarkable monument to human achievement. Main body is made up of three parts: the head, the torso, and the legs. The main body of the main body is the most important part of the body. The second part is the lower body, which includes the legs, the arms, the legs and the feet. The third part is made of the lower torso, which is the largest body of its kind. The last part is called the lower legs, which are made of marble and marble.

ROUGE-1: 47.83, ROUGE-2: 39.45, ROUGE-L: 39.36
BERTScore: 62.40

==============================================
==================== [65/100] ====================
Summary:
NASEM is the National Academy of Science, Engineering, and Medicine. It's chaired by David Baltimore, who used to be an MIT professor until he went and became president of Caltech. Judge David Tatel is a member of the US Court of Appeals for the District of Columbia circuit. He also happens to have a Nobel Prize in his pocket and he's a pretty famous guy. The NASEM body is an august body of old people with lots of gray hair who have done something important enough to get elected. important circuit court. He happens to sit in the seat that Ruth Bader Ginsburg occupied before she was elevated to the Supreme Court. So these are heavy hitters. And they convened a meeting to talk about the set of topics that I've listed here. The issue of using litigation to target scientists who have opinions that you don't like. And the more general issue of how do you communicate advances in life sciences to a skeptical public. So this is dealing with the sort of anti-science. tenor of the times. A group of us that talked about AI and decision making, I was a little bit surprised by the focus because Hank really is a law school professor at Stanford. Cherise Burdee is at something called the Pretrial Justice Institute, and her issue is a legal one which is that there are now a lot of companies that have software that predict, if you get bail while you're awaiting trial, are you likely to skip bail or not? This is influential in the decision that judges make about how much bail to impose and whether to let you out on bail at all. building convolutional neural network models to detect pulmonary emboli and various other things in imaging data. Suresh Venkatasubramanian is a professor. He was originally a theorist at the University of Utah but has also gotten into thinking a lot about privacy and fairness. And so that that was our panel, and we each gave a brief talk and then had a very interesting discussion. One of the things that I was very surprised by is somebody raised the question of shouldn't Tatel as a judge on the Circuit Court of Appeals hire people like you guys to be clerks in his court? interesting to me. He said, no, he wouldn't want people like that, which kind of shocked me. And so we quizzed him a little bit on why, and he said, well, because he views the role of the judge not to be an expert but to be a judge. To be a balancer of arguments on both sides of an issue. And he was afraid that if he had a clerk who had a strong technical background, that person would have strong technical opinions which would bias his decision one way or another. Tatel: Your duty as a lawyer is to argue as hard as you can for your side of the argument. Tatel: In law school, they teach them, like in debate, that you should be able to take either side of any case and make a cogent argument for it. The truth will come out from spirited argument on two sides of a question, Tatel says, but your duty is to try to argue both sides of the same question. The Supreme Court will hear arguments on the issue of gerrymandering on Tuesday. using computers and actually machine learning techniques to try to figure out how to get Republicans or Democrats elected. So in the law, people are in favor of these ideas to the extent that they inject clarity and precision into bail, parole, and sentencing decisions. However, conversely, the use of technology to determine whose liberty is deprived and on what terms may minimize harms that are the products of human judgment. So by formalizing it, you might win, but you might also lose, too. The decision of whether you get bail or not is going to be made by a computer algorithm, not by a human being. There is some discretion on the part of this county official who will make a recommendation, and the judge ultimately decides. Until there are some egregious outcomes from doing this, it will probably be quite commonly used. The critique of these bail algorithms is based on a number of different factors. One is that the algorithms reflect a severe racial bias. So for example, if you get arrested in California, the decision is made by an algorithm. example, if you are two identical people but one of you happens to be white and one of them is black, the chances of you getting bail are much lower if you're black. The algorithm is learning from historical data, and if historically, judges have been less likely to grant bail to an African-American than to a Caucasian-American, then the algorithm will learn that that's the right thing to do. And then the second problem, which I consider to be really horrendous, is that in this particular field, the algorithms are developed privately by private companies which will not tell you what their algorithm is. answer, but they won't tell you how they compute it. And so it's really a black box. You have no idea what's going on in that box other than by looking at its decisions. So the data collection system is flawed in the same way as the judicial system itself, he says. "They won't even tell you what data they used to train the algorithm," he says, "and so you have no know what's happening in that black box" "It's a flawed system," he adds, "but it's not as bad as we think it is" The Wisconsin Supreme Court ruled that an algorithm's output was not enough to violate a man's rights. The decision is likely to be appealed and maybe overturned, says CNN's John Sutter. Sutter: Algorithms could help keep people out of jail and get them psychiatric help. "I'm sure it'll be appealed," Sutter says of the court's decision to rule against the man. "It's kind of an outrageous decision," he says, "and I think many people consider it to be kind of outrageous" There is a long discussion-- you can find this all over the web-- of, for example, can an algorithm hire better than a human being. If you're a big company and you have a lot of people that you're trying to hire for various jobs, it's very tempting to say, hey, I've made lots and lots of hiring decisions and we have some outcome data.so on. So that's the positive side of being able to use these kinds of algorithms. It's not only in criminality. look like they're a better bet. When I was an undergraduate at Caltech, the Caltech faculty decided that they wanted to include student members of all the faculty committees. And so I was lucky enough that I served for three years as a member of the Undergraduate Admissions Committee. And in those days, Caltech only took about 220, 230 students a year. It's a very small school. And we would actually fly around the country and interview about the top half of the applicants. So we would talk not only to the students but also to their teachers and their counselors. admissions decisions have been made, one of the professors, kind of as a thought experiment, said here's what we ought to do. We ought to take the 230 people that we've just offered admission to and we should reject them all and take the next 230 people, and then see whether the faculty notices. Now, of course, I and others argued that this would be unfair and unethical and would be a waste of all the time that we had put into selecting these people. But then this guy went out and he looked at the data we had on people's ranking class, SAT scores, grade point average, the checkmarks on their recommendation letters about whether they were truly exceptional or merely outstanding. And he built a linear regression model that predicted the person's sophomore level grade. point average, which seemed like a reasonable thing to try to predict. And he got a reasonably good fit, but what was disturbing about it is that in the Caltech population of students, it turned out that the beta for your SAT English performance was negative. So if you did particularly well in English on the SAT, you were likely to do worse as a sophomore at Caltech. And so we thought about that a lot, and of course, we decided that that would be really unfair to penalize somebody for being good at something. What is fair? What characteristics would you like to have an algorithm have that judges you for some particular purpose? PETER SZOLOVITS: It's impossible to pin down sort of, at least might in my opinion, one specific definition, but for the pre-trial success rate for example, I think having the error rates be similar across populations is a good start. And you'll see later Irene-- where's Irene? Right there. Irene is a master of that notion of fairness. to capture that in a short phrase. Societal goals. But that's tricky, right? I mean, suppose that I would like it to be the case that the fraction of people of different ethnicity who are criminals should be the same. How do I achieve that? I could pretend that it's the same, but it isn't the same today objectively, and the data wouldn't support that. So that's an issue. Yeah? AUDIENCE: People who are similar should be treated similarly, so engaged sort of independent of the [INAUDIBLE] attributes or independent of your covariate. are to people similar? And what characteristics-- you obviously don't want to use the sensitive characteristics, the forbidden characteristics in order to decide similarity. But defining that function is a challenge. All right, well, let me show you a more technical approach to thinking about this. I'll show you an example that I got involved in. Raj Manrai was a MIT Harvard HST student, and he started looking at the question of the genetics that was used to determine whether somebody is at risk for cardiomyopathy. well, and eventually, you die of this disease at a relatively young age. So what happened is that there was a study that was done mostly with European populations where they discovered that a lot of people who had this disease had a certain genetic variant. And so it became accepted wisdom that if you had that genetic variant, people would counsel you to not plan on living a long life. And this has all kinds of consequences. Imagine if you're thinking about having a kid when you're in your early 40s, and your life expectancy is 55. Would you want to die when you have a teenager that you leave to your spouse? in the US, there were tests of this sort done, but the problem was that a lot of African and African-American populations turned out to have this genetic variant frequently without developing this terrible disease. So you go, well, we must have learned that lesson. So this paper was published in 2016, and this was one of the first in this area. Here's a paper that was published three weeks ago in Nature Scientific Reports that says, genetic risk factors identified in populations of European. descent do not improve the prediction of osteoporotic fracture and bone mineral density in Chinese populations. So it's the same story. Different disease, the consequence is probably less dire because being told that you're going to break your bones when you're old is not as bad as being told your heart's going to stop working. But there we have it. OK, so technically, where does bias come from? Well, I mentioned the standard sources, but here is an interesting analysis. This comes from Constantine Aliferis from a number of years ago. is choose some family of models to try to fit, and then I'm going to use some fitting technique, like stochastic gradient descent or something, that will find maybe a global optimum, but maybe not. And then there is noise. And so his observation is that if you count O as the optimal possible model over all possible model families, then the bias is essentially O minus L. The variance is like L minus A, it's the error that's due to the particular way in which you learned things. the data, randomizing, essentially, the relationships in the data. And then you get a curve of performance of those models, and if yours lies outside the 95% confidence interval, then you have a P equal 0.05 result that this model is not random. So that's the typical way of going about this. Now, you might say, but isn't discrimination the very reason we do machine learning? Not discrimination in the legal sense, but Discrimination in the sense of separating different populations. can't define a universal notion of what it means to discriminate because it's very much tied to these questions of what is practically and morally irrelevant in the decisions that you're making. And so it's going to be different in criminal law than it is in medicine. And it's feature-specific as well, so you have to take the individual features into account. The government has tried to regulate these domains, and so credit is regulated by the Equal Credit Opportunity Act, education by the Civil Rights Act and various amendments. Until 1967, it was illegal for an African-American and a white to marry each other in Virginia. If you went to get a marriage license, you were denied, and if you got married out of state and came back, you could be arrested. Trevor Noah, if you know him from The Daily Show, wrote a book called Born a Crime. His father is white Swiss guy and his mother is a South African black. It was literally illegal for him to exist under the apartheid laws that they had. He had to pretend to be-- his mother was his caretaker rather than his mother in order to be able to go out in public, because otherwise, they would get arrested. So here are some of the legally recognized protected classes, race, color, sex, religion, national origin, citizenship, age, pregnancy, familial status, disability, veteran status, and more recently, sexual orientation in certain jurisdictions, but not everywhere around the country. OK, so given those examples, there are two legal doctrines about discrimination, and one of them talks about disparate treatment, which is sort of related to this one. is something not right, that there is some sort of discrimination. Now, the problem is, how do you defend yourself against, for example, a disparate impact argument? Well, you say, in order to be disparate impact that's illegal, it has to be unjustified or avoidable. If I brought suit against you and said, hey, you're discriminating against me on the basis of this medical disability, a perfectly good defense is, yeah, it's true, but it's relevant to the job. So that's one way of dealing with it. Now, how do you demonstrate disparate impact? Well, the court has decided that you need to be able to show about a 20% difference in order to call something disparate impact. So the question, of course, is can we change our hiring policies or whatever policies we're using to achieve the same goals, but with less of a disparity in the impact? So that's the challenge. But what's interesting is that disparate treatment and disparate impact are really in conflict with each other. And you'll find that this is true in almost everything in this domain. and you can't square that circle easily. Well, there's a lot of discrimination that keeps persisting. There's plenty of evidence in the literature. And one of the problems is that, for example, take an issue like the disparity between different races or different ethnicities. It turns out that we don't have a nicely balanced set. We tend to know a lot more about the majority class than we know about these minority classes, and just that additional data and that additional knowledge might mean that we're able to reduce the error rate. This talk was given at KDD about a year and a half ago, I think. Moritz is a professor at Berkeley who actually teaches an entire semester-long course on fairness in machine learning. And so he formalizes the problem this way. He says, look, a decision problem, a model, in our terms, is that we have some X, which is the set of features we know about an individual, and we haveSome Y, which are the outcome that we're interested in predicting. now you can begin to tease apart some different notions of fairness by looking at the relationships between these elements. So there are three criteria that appear in the literature. One of them is the notion of independence of the scoring function from sensitive attributes. Another notion is separation of score and the sensitive attribute given the outcome. So this is the one that says the different groups are going to be treated similarly. In other words, if I tell you the group, the outcome, the people who did well at the job and the people Who Did poorly at the Job. scoring function is independent of the protected attribute. So that allows a little more wiggle room. It says that the probability of a particular result, R equal 1, is the same whether you're in class A or class B. So what does that tell you? That tells you that can we build a fair scoring function that separates the outcome from the protectedattribute? So here's some detail on those. If you look at independence-- this is also called by various other names-- basically, what it says is that the probabilities of a result are the same. you that the scoring function has to be universal over the entire data set and has to not distinguish between people in class A versus class B. That's a pretty strong requirement. And then you can operationalize the notion of unfairness either by looking for an absolute difference between those probabilities. If it's greater than some epsilon, then you have evidence that this is not a fair scoring function, or a ratio test that says, we look at the ratio, and if it differs from 1 significantly, then it's an unfair scoring function. Hiring is based on a good score in group A, but random in B. So you might wind up with a situation where you wind up hiring the same number of people, the same ratio of people in both groups. Well, the outcomes are likely to be better for a group A than for group B, which means that you're developing more data for the future that says, we really ought to be hiring people inGroup A.or whatever topic you're interested in. And so what if hiring is based in group B? So for example, what if we know a lot more information about group B than we do about group A? because they have better outcomes. Or alternatively-- well, of course, it could be caused by malice also. There's also a technical problem, which is it's possible that the category, the group is a perfect predictor of the outcome. They can't be independent of each other. Now, how do you achieve independence? Well, there are a number of different techniques. One of them is-- there's this article by Zemel about learning fair representations, and what it says is you create a new world representation, Z, which is some combination of X and A, and you do this by maximizing the mutual information between X and Z. So this is an idea that I've seen used in machine learning for robustness rather than for fairness, where people say, the problem is that given a particular data set, you can overfit to that data set. One of the ideas is to do a Gann-like method where you say, I want to train my classifier, let's say, not only to work well on getting the right answer, but also to work as poorly on identifying which data set my example came from. the protected attribute, but is as independent as possible. And usually, there are knobs in these learning algorithms, and depending on how you turn the knob, you can affect whether you're going to get a better classifier that's more discriminatory or a worse classifiers that's less discriminatory. So you can do that in pre-processing. You can do some kind of incorporating in the loss function a dependence notion or an independence notion. And again, there's a knob where you can say, how much do I want to emphasize misclassifications for the protected attribute? does in other populations, and the FDA has actually approved the marketing of that drug to those subpopulations. And if you think about the personalized medicine idea, which we've talked about earlier, the populations that we're interested in becomes smaller and smaller until it may just be you. And so there might be a drug that works for you and not for anybody else in the class. But it's exactly the right drug for you, and we may get to the point where that will happen and where we can build such drugs. and I draw ROC curves for both of these populations, they're not going to be the same, because the drug will work differently for those two populations. But on the other hand, I can draw them on the same axes, and I can say, look any place within this colored region can be a fair region in that I'm going to get the same outcome for both populations. So the advantage of separation over independence is that it allows correlation between R and Y, even a perfect predictor. And it gives you incentives to learn. to reduce the errors in all groups. And then the final criterion is sufficiency, which flips R and Y. So it says that the regressor or the predictive variable can depend on the protected class, but the protectedclass is separated from the outcome. So for example, the probability in a binary case of a true outcome of Y given that R is some particular value, R and A is a particular class, is the probability of the outcome of A and R in the binary case. same as the probability of that same outcome given the same R value, but the different class. So that's related to the sort of similar people, similar treatment notion, qualitative notion, again. So it requires a parody of both the positive and the negative predictive values across different groups. So for example, if the scoring function is a probability, or the set of all instances assigned the score R has an R fraction of positive instances among them, then the scoringfunction is said to be well-calibrated. degree of calibration will give you a good approximation to this notion of sufficiency. These guys in the tutorial also point out that some data sets actually lead to good calibration without even trying very hard. So for example, this is the UCI census data set, and it's a binary prediction of whether somebody makes more than $50,000 a year if you have any income at all and if you're over 16 years old. It's almost exactly along the 45 degree line without having done anything particularly dramatic in order to achieve that. for whites versus blacks, the whites, not surprisingly, are reasonably well-calibrated. So you could imagine building some kind of a transformation function to improve that calibration, and that would get you separation. Now, there's a terrible piece of news, which is that you can prove, as they do in this tutorial, that it's not possible to jointly achieve any pair of these conditions. And so you have three reasonable technical notions of what fairness means, and they're incompatible with each other except in some trivial cases. choosing different notions of fairness. So they say, well, there are two scenarios. One of them is that gender, A, influences whether you're a programmer or not. And this is empirically true. There are fewer women who are programmers. It turns out that visiting Pinterest is slightly more common among women than men. And then visiting GitHub is much more commonamong programmers than among non-programmers. So what they say is, if you want an optimal predictor of whether somebody's going to get hired, it should actually take both Pinterest visits and GitHub visits into account. The probability that you visited the Grace Hopper Conference is dependent on your gender. Computer scientists are much more likely to be programmers than non-computer science majors. The optimal score is going to depend basically on whether you have a computer science degree or not. If you're a historian, you're not likely to have been interested in going to that conference. It's a really cool conference. Grace Murray Hopper invented the notion bug or the term bug and was a really famous computer scientist starting back in the 1940s. the separated score will depend only on your gender, which is kind of funny, because that's the protected attribute. And what these guys point out is that despite the fact that you have these two scenarios, it could well turn out that the numerical data, the statistics from which you estimate these models are absolutely identical. So from a purely observational viewpoint, you can't tell which of these styles of model is correct. So that's a problem because we know that these different notions of fairness are in conflict with each other. work. I got an invitation last year from the American Medical Association's Journal of Ethics, which I didn't know existed, to write a think piece for them about fairness in machine learning. I decided that rather than just bloviate, I wanted to present some real work. And so Marcia, who was one of my students, and I convinced her to get into this, and we started looking at the question of how these machine learning models can identify and perhaps reduce disparities in general medical and mental health. McLean's hospital here in Boston, which both have big psychiatric clinics. The type of insurance you have correlates pretty well with whether you're rich or poor. So we did that, and then we looked at the notes. We wanted to see not the coded data, but whether the things that nurses and doctors said about you as you were in the hospital were predictive of readmission, of 30-day readmission. So these are some of the topics that we wanted to look at. We used LDA, standard topic modeling framework. White patients have more topics that are enriched for anxiety and chronic pain. Black, Hispanic, and Asian patients had higher topic enrichment for psychosis. It's interesting. Male patients had more substance abuse problems. And so we said, what happens when you look at the different topics, how often the different topic arise in different subpopulations? And so what we found is that, for example, white patients haveMore topics enriched for Anxiety and Chronic pain. Female patients had more general depression and treatment-resistant depression. Men still have substance abuse problems in the ICU population. Women have more pulmonary disease. And we were speculating on how this relates to sort of known data about underdiagnosis of COPD in women. By race, Asian patients have a lot of discussion of cancer, black patients have  kidney problems. Hispanics of liver problems, and whites have atrial fibrillation. So again, stereotypes of what's most common in these different groups. Those with public insurance often have multiple chronic conditions. Public insurance patients have atrial fibrillation, pacemakers, dialysis. Private insurance patients, on the other hand, have higher topic enrichment values for fractures. So maybe they're richer, they play more sports and break their arms or something. Just reporting the data. Just the facts. So these results are actually consistent with lots of analysis that have been done of this kind of data. Now, what I really wanted to look at was this question of, can we get similar error rates. And the answer is, not so much. they are for women, statistically significantly lower. So this indicates that there is, in fact, a racial bias in the data that we have and in the models that we're building. These are particularly simple models. In psychiatry, when you look at the comparison for different ethnic populations, you see a fair amount of overlap. One reason we speculate is that We have a lot less data about psychiatric patients than we do about ICU patients. So the models are not going to give us as accurate predictions. for example, a statistically significant difference between blacks and whites and other races, although there's a lot of overlap here. Between males and females, we get fewer errors in making predictions for males, but there is not a 95% confidence separation between them. And for private versus public insurance, we do see that separation where for some reason, in fact, we're able to make better predictions for the people on Medicare than we are-- or Medicaid. So just to wrap that up, this isn't a solution to the problem, but it's an examination of the problem. work here and embarrassing myself. So this is modeling mistrust in end-of-life care, and it's based on Willie's master's thesis and on some papers that came as a result of that. So here's the interesting data. If you look at African-American patients, and these are patients in the MIMIC data set, what you find is that for mechanical ventilation, blacks are on mechanical ventilation a lot longer than whites on average. So there's something going on where black patients are kept on mechanical breathing longer than white patients. or social differences, but to a difference in the degree of trust between the patient and their doctors? It's an interesting idea. And of course, I wouldn't be telling you about this if the answer were no. And so the approach that he took was to look for cases where there's clearly mistrust. So there are red flags if you read the notes. For example, patient refused to sign ICU consent and expressed wishes to be do not resuscitate, do not intubate, seemingly very frustrated. and mistrusting of the health care system, also with a history of poor medication compliance and follow-up. So that's a pretty clear indication. And you can build a relatively simple extraction or interpretation model that identifies those clear cases. So the problem, of course, is that not every patient has such an obvious label. In fact, most of them don't. And so Willie's idea was, can we learn a model from these obvious examples and then apply them to the less obvious examples in order to get a kind of a bronze standard. Those who are agitated are more likely to be mistrustful. If a person is in pain, that correlated with these mistrust measures as well. If the patient was restrained, then trustful patients have no pain, or they have a spokesperson who is their health care proxy, or there is a lot of family communication. If restraints had to be reapplied, or if there are various other factors, then they're more Likely to be Trustful. And so the approach that Willie took was to say, well, let's code these 620 binary indicators of trust and build a logistic regression model. The disparity between black and white patients is less significant than the disparity between a population of high trust and low trust patients. The fundamental feature here that may be leading to that difference is, in fact, not race, but is something that correlates with race because blacks are more likely to be distrustful of the medical system than whites. Findings suggest that for both predicting the use of mechanical ventilation and vasopressors, the disparity is less than between high trust patients and low Trust patients. "I understand some of the strong family feelings that happened as a result of some of these historical events," he says. "So I would expect that people in my status might also have similar issues of mistrust" "But the answer seems to be, not so much. So if you look at these severity scores like OASIS and SAPS and look at their correlation with noncompliance in autopsy, those are pretty low correlation values, so they're not explanatory of this phenomenon," he adds. "There is a significant difference in sentiment expressed in the notes" between black and white patients. The autopsy derived mistrust metrics don't show a strong relationship, a strong difference between them, but the noncompliance derived mistrust metric do. There is a lot more work that needs to be done in this area, and it's a very rich area both for technical work and for trying to understand what the desiderata are and how to match them to the technical capabilities. One of the pairs of people, Mike Kearns and Aaron Roth at Penn are coming out with a book called The Ethical Algorithm, which is coming out this fall. fairness popping up at different universities. University of Pennsylvania has the science of Data ethics, and I've mentioned already this fairness in machine learning class at Berkeley. This is, in fact, one of the topics we've talked about. I'm on a committee that is planning the activities of the new Schwarzman College of Computing. The college obviously hasn't started yet, so we don't have anything other than this lecture and a few other things like that in the works, but the plan is there to expand more in this area.

ROUGE-1: 72.94, ROUGE-2: 69.34, ROUGE-L: 67.73
BERTScore: 76.00

==============================================
==================== [66/100] ====================
Summary:
MIT OpenCourseWare offers high quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourse Ware at ocw.mit.edu. The next time I'll be lecturing to you will be a week from Friday. The homework following the quiz will be posted and so you guys can get started on that. That homework involves a COMSOL. The quiz is for students who want to learn about partial differential equations. problem which, for those of you who had trouble with COMSOL, might take some extra time, since it's the first time you're doing it. So I would suggest you at least give it a try early. I'm sure the TAs would be very happy to help you to force COMsOL to cooperate. Bend COMSol to your will. All right, so we're going to talk about partial differential equations. And, as it sounds, what's different about a partial differential equation is, it has partial derivatives in it. a diffusion term, a convection term, and a reaction term. This is part of the Navier-Stokes equations for the whole reactive flow system. A very important thing about partial derivatives, which you probably have encountered in 1040 already, is, it really depends what you hold fixed. And you get different results if you hold different things fixed. Now the implication, when you write this equation, is that the reaction term is the product of the diffusion and convection terms. an equation like this, is that whatever partials you see-- when I wrote this, if I have this and it has a term that's like d squared, dx squared, is one of the terms in this thing. This says t, this says x. The convention is, oh boy, I better hold x fixed. And here must be, I must hold t fixed. Because there's another one in the same equation. Now, you can change coordinates however you want. Just really watch out that you carefully follow the rules about what you hold fixed, when you change things. Otherwise you can cause all kinds of craziness. stuff? Yeah, so you've seen how completely confusing it can be with negative signs showing up all over the place. And other things like this. I don't know if you've encountered this yet? At least, I thought it was confusing when I took it. So just be aware. It's the same thing. Now, often you do want to change the equations. So you can write down an equation like this, but, for example, if you have a special symmetry of the problem, like it's cylindrical, then you might want to changed the cylind spherical coordinates. it turns out there's a special coordinate system called the elliptic coordinate system. And in that coordinate system, the partial differential equation is separable. And so, if you do it in thatcoordinate system, you can actually solve analytical solution, which is pretty unusual for the Schroedinger equation. But it's a pretty goofball coordinate system and you really have to watch out, when you convert, to make sure you're doing it just right. It's just the rules, chain rule and the rules about how to keep track of what's being held constant. methods. And it's really no different. So all those methods basically look the same. You just get equations that have more unknowns in them. And so fundamentally, there's no problem, but in practice there's a big problem if the number of unknowns gets to be so large. That's the main problem. How many points do you think you need to discretize to get to this point? That's what I'm trying to figure out. I don't know. your solution in the spatial coordinate? There might be somewhere, might be 100, I don't know, points might be enough. And so now I have x and y and z. So I'll need, well, just in COMSOL, you saw this on Monday. Suppose I just have two dimensions. And I start putting points in. Well, I want to have some points along this way, and I want a few points along that way. So, I actually have an unknown here and anunknown here, and one here and one there. things they called the d's before in the basis functions. And I have a lot of them. 10,000 unknowns are a lot harder to solve for than 100 unknowns. And once you get up to a million unknowns, we're starting to talk serious. All right? So you can just see how it just gets to be, like, a big numerical problem. So that's two dimensions. The third dimension, you'll get another 100 times as many points. You might have a millionunknowns. math, now. OK? Even for your good computers that you have. In addition, it's not just you have the number of mesh points, but it's the number. ofMesh points times number of variables at each mesh point. So in the Navier-Stokes equations, what variables do you have? AUDIENCE: [INAUDIBLE] PROFESSOR: Louder. What else we got? Density or temperature. So maybe temperature would be what you might use. And then you'd have a state function maybe with these guys. a pretty big set of variables and you need to know all these numbers at each point. So this might be-- how many have we've got? One, two, three, four, five, plus however many species we have? So this is n species plus 5 times the mesh. And I told you the mesh was what, a million? So maybe I have 10 million unknowns. So the issue, to a large extent, has to do with just, can I solve it? physically, then probably we're not going to get a stable solution. So you have all those kinds of problems that we had before in the ODE case, and now it's just sort of amplified by the fact, now we have boundary conditions in more than one dimension. So we have multiple chances to screw it up. And we're trying to figure out how to set the boundary conditions correctly. So those are the different kinds of things we have to worry about. But it's all the same problems you had before, just amplified. up to three dimensions, you might be able to solve it. And then in reality, we have problems like the Navier-Stokes is four dimensions, right? There's time, as well. So then that gets to be really hard. The Schrodinger equation has three times the number of electrons dimensions in it. So that gets impossibly hard. And so, specialized methods are developed to handle those systems with a lot of dimensionality. And there's been a huge effort, over decades, to figure out really clever basis sets that are really close to the real solutions. The PDE system, itself, can be intrinsically unstable. In the Navier-Stokes world, I'll show you what people do to try to deal with that. There's many other problems. I don't know all the problems in the world. But in general, when you have three or more dimensions in your PDEsystem, you're looking up special tricks. You're looking. up, how do people in this field deal with this particular PDE? Special ways that are good for that kind of PDE. the case where it's stable, that it just sits there, a hydrogen and oxygen. Or it could turn into a regular burning. Or if I change the conditions a little bit differently, it could change into a detonation, where it actually sends a shockwave down the tube faster than the speed of sound. So those kind of systems can be really sensitive to the physical initial conditions. A very small spark can make a really big difference in a system like that. And also, in your numerical solution, if the thing is physically sensitive, it'll typically be sensitive also to numerical noise. of a cell culture or the growth of a tumor, as you know, if somebody has a tumor and one of the cancer cells mutates and does something different, it can have a really different outcome. A small change in one cell, for example, could be a really big difference. So this is not just in combustion problems you have these kinds of instabilities. All kinds of problems have this kind of thing. You can have just regular chemical reactors, like in multiple steady states, little tiny fluctuations can make it jump from one steady state to another one. stable in some sense, but it causes a problem. We call those hyperbolic. And those are like wave equations. The solutions are propagating waves. So what happens, then, is you have some numerical noise that will make a little wavelet that will propagate, more or less, without any damping, too. And it'll keep bouncing back and forth inside your domain numerically. And if you keep introducing numerical noise, eventually the whole thing is just full of noise. It doesn't have much relation to the real physical solution. I'm not going to talk about how you solve them in this class, but there's a special, whole group of solution methods that people use who are solving acoustics equations and solving electromagnetic equations. If you get into those things, you should take the PDE class for hyperbolic equations and they'll tell you just all about the solvers for those kinds of things and special tricks. Here, what we're going to focus primarily on two kinds of problems: elliptic problems and parabolic problems. ones where there's some dissipation that's very significant. In an elliptic problem, you introduce some numerical noise and as you solve it, the numerical noise kind of goes away. In a hyperbolic system, information-- there's regions of the domain that you can make a change here and it doesn't make any effect on some domain part over there. So for example, if I'm modeling a shockwave that's moving faster than the speed of sound, I can introduce any pressure fluctuation I want behind the shockwave, and it has no effect on the shock wave. speed of sound. They won't catch up to the shock. So they will have no effect whatsoever. So if I was judging what was happening by looking at what's happening in the shock, I can introduce any kind of random noise I want back over. And it won't make any difference at all. And so, that's part of the reason why I need a special kind of solver. If I have elliptic equations, every point affects every other point. A famous case for that is, like, this steady state heat equation. trying to flow by, sort of, every path. And there's some insulation that's resisting its flow. And it has been in the connectivity of flow a certain way. Those kinds of equations are called elliptic. And the methods that we use for the relaxation mesh that we showed are really good for those kinds of problems. And then another kind of problem that we get into a lot is like this one. This is called parabolic. And typically, in the cases we see that are parabolic, we have time as part of the problem. a flow in a pipe. And you have a nice, fast velocity flow down the pipe. What's happening downwind is very much affected by what happened upwind, but not vice versa. So it has a directionality, even though I might do it as a steady state problem and not have time in it at all. You've probably already done this, where you can convert, like, a flow reactor. You can write it, sort of, as a Flow Reactor. time thing or as a space thing. Time and space are so related by the velocity of the flow. We'll have similar kinds of phenomenon then. It's almost like a parabolic time system. If the flow is fast enough, the fusion backup, anything moving upstream is negligible. And so then, you'll have the same kind of issues. In fact, you may even try to solve it by just starting it at the upstream end and competing stuff and then propagating what that output from that first one does to the next one downstream. very slow, the Peclet number very low, then you really have to worry about things diffusing back upstream. And that would be more like the elliptic problems we have. Because things downstream would actually affect upstream, if the flow is really small. But typically for our problems, the velocity is always really high, and so not much goes from downstream to upstream. It's almost all upstream to downstream. This leads to a famous situation. If you look in the textbook at figures 6.7, 6.8, it's kind of a very famous problem. here and here and change this into this obvious looking thing. You think that that would be a reasonable thing to do, right? And you can do the same one here. You can write-- I'm terrible with minuses, sorry. So these, the finite difference formulas. And so, you can write these like this. This stays equal to zero. And now it's just an algebraic problem to solve. A system of equations, you have equations like this for every value of n. And there's the mesh points. called local Peclet number, which is-- OK? If you make the local PEClet number too large, actually anywhere bigger than 2, and you try to solve this equation, what you get is oscillations, unphysical oscillations. They'll make the phi go negative. It's crazy. It looks like the simplest equation in the world, right? It's a linear equation, so what's the problem with this? But it doesn't work. And so, then you could think, well, why doesn't it work? And there's, like, multiple ways to explain this. at point n plus one, I guess. Here we have the flow this way. So here's n minus one. Here's my point n, n plus 1. I really should not include, is this right, n Plus 1 in this formula. Because I don't think that what happens downstream should really affect this at all. So really, I would do better to change from this center difference formula to what's called the upwind difference formula. Just use that instead of using this formula, and it makes a gigantic difference. when you do that. But where you do this one, you get crazy, oscillatory, unphysical solutions, unless you choose delta z really tiny. So I think this is the correct way, the best way to think about it is, it has to do with information flow. So upwind does not really depend on downwind. If you force it to, by choosing to include that information here, you end up with crazy stuff. Another way to look at it is that, if you really want to compute these derivatives, you've got to keep delta z small. a terrible approximation to do this. And you can look at it. You can see that what we're doing is, when we have this problem where the local Peclet number is getting too large, is we're actually choosing delta z bigger than the, sort of, the thickness of the solution. So if you look at the solution, the analytical solution of this problem, it's like this. Where this has a very, very thin layer at the end. It's like the flow has pushed all your stuff to one side. And if you choose your delta z to be from here to here, that's how big yourDelta z is, and then you're computing the derivative of this point. in fact, you really should have a bunch of points here and here. And so you did something really crazy to use a big value of delta z to start with. Now, the fix, by doing this upwind differencing, I think the best way to look at this is saying, well, I'm just going to make sure I only depend, I only make the equations depend on what's upwind, with the convective term. Because there's nothing convecting from downwind. So just leave that out. approximation to the differential. This is a asymmetrical finite difference formula. It's not a very good value estimate of the derivative, if delta z is big. But you can write it out carefully and write this out and say, oh, this actually is sort of like this plus an effective diffusivity chosen very carefully, so the terms cancel out just right. And it turns out, if you look at it that way, the effective diffusion you've added, by using this instead of that, is just enough to make the local Peclet number stay less than 2. before. There's a similar thing and it might be relevant to the COMSOL problem that Kristyn showed you on Monday, is you can-- In that case, there was a region of the boundary here that had some concentration c naught, and then there was, over here, the concentration was zero. Here, it's some number, 17, whatever number it was. And if you think of how to model what's going on, one way to look at it is, I have a diffusive flux coming in from the drug patch, diffusing the drug into the flow. with this size right here. Is that right? So you could compute what the steady state concentration would be if it's just coming in and flowing out. This is the finite volume view of this kind of problem. And so you can write the equations that way, instead. And what you really care about are what the velocity flows and the diffusive fluxes are on these boundaries around the point. So you don't try to compute things right at the point, you compute around it. All of them are correct in the limit that delta z goes to zero. If you have an infinite number of mesh points, all these are exactly the same. But they lead to really different numerical properties when delta z is large. And they're all inaccurate when deltaZ is large, so it's all about what happens with the inaccuracies. And what we're basically doing in a problem like this is turning it into some function of y is equal to zero, where y is the value of all the unknowns. And there's a lot of equations. or every state variable at every state point at all times. And I know in the limit, as I make the number of elements of y go to infinity, it will actually be the real solution. And the problem is, my computer can't handle infinite number of unknowns. In fact, it's even going to have trouble with a 100 millionunknowns. And so, I have to figure out what to do. So how would I solve this normally, is I would take the Jacobian of this and I would do. As Newton-Raphson is how you'd find improved from an initial guess. This is actually pretty hard if you have 100 million unknowns. You have to provide the value of the initial guess for every one of the 100 million.million times. And now you want to refine that guess and this is the formula for it. And so, you just use backslash, right? But the problem here is that now f is a 100 million long vector. And a100 million squared is pretty big, 10 to 16th elements in it. 16th numbers in this matrix are zero. So we don't have to represent them. But there still might be quite a few. Probably the diagonal events are non-zero, so that's like 10 to the 8th of them. And we've got, probably, a couple of other bands inside this thing, which is pretty nutty. And certainly, if you tried to do Gaussian elimination to solve this, you're going to have a problem because you get what's called fill in. solve this. So you just try to minimize that, right? You know at the solution this is going to be zero. Right, jy plus [INAUDIBLE] zero when this is solved. And then this method, it turns out that the conjugate gradient, if everything works great, this is guaranteed in n iterations to go directly to the solution of this kind of problem. Now n is large, now, because we have 10 to the 8th unknowns. the method. And what's really nice about this method, if you look into the details of how it works, it never has to store any intermediate matrices. So all it needs is the capability to multiply your matrix times some vector. And from that multiplication, it figures out a step direction. That's the trick of this method. Because it only has to do a forward multiplication, you don't have to actually store j. You can just compute elements of j, as needed, in order to evaluate this top product. This j times v. iterations like this, you tend to pick up numerical problems. And so, they've worked out better methods. And there's one that people use a lot for these problems called bi cg stab. Which is biconjugate gradient stabilized. And this is the one that, I think currently, people think is the best. Though probably, there's a lot of research on this, so maybe there's even better ones now. But inside Matlab,. I think this isthe best on they have. compute delta y. So we have an interim procedure and another iterative procedure inside the first iterative process. So this is going to be a lot more CPU time. And it's also, it's not guaranteed like Gaussian elimination, to beautifully come to machine precision solution. But anyway, this is what people do. So that's one good thing to try. Now, this whole approach is sort of based on Newton-Raphson. We know that doesn't have the greatest radius of convergence. So you need a pretty darn good initial guess. nonlinear terms. You're really good at solving linear systems of PDEs. You start with that and then you gradually turn the non-linear term on. Maybe you could coax it over. Another possibility that I've run into a lot is the problem you're trying to solve, for example, might be a steady state problem like this. Where this is zero and you try to figure out what the steady state situation is in a flow reactor. And so, it's actually, your steady state problems came from a time dependent problem. at the solution you want. So that's called a time marching idea. So there's one idea, sort of the homotopy continuation kind of idea. And the key about it is, you have to really believe that, physically, the system does march to the steady state. If it doesn't, then you're not going to end up where you want, because it's not going where you wants. But in some situations, this is true, that things work. So I do a lot of combustion problems. A lot of these things, you light a spark on a stove burner. No matter how you light it, it ends up basically the same flame. a good one. But I have some other ones where I light a candle and. I'm in a convective field, a turbulent field, and it flickers. And I never get a steady state, so I'm never going to find a. steady state solution with that one. And so I could time march until I retire. My computer's still burning CPU time all that time. So you really have to know what the real situation is. But if you have one where it's going to converge, then this is a reasonable idea. for the derivatives. Or I did colocation or something to convert this into algebraic equations. So the right-hand side is now algebraic equation, no longer differentials. And now, I'm going to time march this and I just-- This is very long. It's a 100 million. So how do we time march that? Well there's kind of two schools of thought for this. One school of thought is, if I can use an explicit method, an explicit ODE solver, those are pretty nice. there's just some explicit formula. I plug in the old vector. I compute a new vector. So that's good. And this is, indeed, the way that the Navier-Stokes equations are solved currently by the best possible solver. So the best solver in the world discretizes in space and then does ODE IVP using explicit method for marching it. They do problems that are pretty big. So they'll have like 100 million mesh points and then 100 species. The biggest thing you have to store are the vectors. So that's one possibility. Now, this is really good if an explicit solver can solve it. But suppose we're trying to really solve the steady state problem over here. Then we really don't care about the time accuracy. In the end, we're only going to report our steady state solution. That's all we cared about. So in that case, there's no reason to try to have a really high accuracy, explicit formula and try to make it too big. sure we all our time steps are exactly right. We're just going to throw away all those time points anyway. We'll just keep the final one as our initial guess for a Newton-Raphson solve to find the steady state. So this is time accurate. There's another method. I don't know if I should call it time inaccurate. If you don't care, if the solution is really, what the solution yft is, all you care about is where you get to, then you can do other methods. if we're doing an iterative procedure in order to get the initial guess. This kind of thing is called method of lines. And in certain systems like this, it's a smart thing to do. But this is currently what people do. So you guys are smart. Maybe you can figure a better way to do it. The world is waiting. I think I'll stop there. By the way, actually just names-- this kind of things are called method Of Lines. And if so, if anybody ever says I solved something by method of Lines, what they meant was, they discretized in some of the coordinates and they kept one of thecoordinates as a differential. set up is right, so you can use it. But if you can, it can be pretty good. All right. See you on Friday. Back to Mail Online home. back to the page you came from. Click here for the latest from CNN.com. Back To the pageYou came from the page You came from: Back to the Page You Came From: Back To The Page You Were Originally From: The page you were originally from: The Page you were initially from: the Page you started from.

ROUGE-1: 70.11, ROUGE-2: 67.48, ROUGE-L: 68.11
BERTScore: 72.42

==============================================
==================== [67/100] ====================
Summary:
elizabeth the first is considered one of the greatest rulers in england's history if not the greatest for women. She never married can you blame her i mean look at what she grew up with around her dad and all of those moms and stepmoms she never had any kids which that causes a problem come her end time okay where we have i don't have an heir so she eventually does set on a cousin up in scotland which is the country on the same island of england but right above it uh james king james of scotlands she names him as the heir. okay so in referencing england in that area in those countries it's the united kingdom and that's because we have um uh the uh where we are here the stewards so we went from the family of tudors to theFamily of stewards. That's where we start with james and his son and and we'll talk more about that when we get to uh the next unit and so on the king james bible page 414 415. um i'm not as i told you i's not going to go through necessarily what it was about but there was some more example of parallel structure here towards the beginning. know how to read latin or french you were stuck by solely getting your material this is what the bible says solely from your clergy solely from the church so you were kind of a mindless robot with regards to comprehending the the word of god or whatever the bible said on your own. Now that something is in english and if you can read english you are able to read it over and over and make your own decisions. So you were less mindless page 414 is a really nice page that if you need to come back to review the significance of this or you can't remember um it's pretty good. widely read english book but the most widely read excuse me hold on for centuries. The bible was not just the most important or the most read but in english around the world. The highest distributed book in the world is the bible or you know some stat like that i i wonder if i could find that again or see if i's updated see if it's still if that stat is still legit but um because people are like oh man no the the da vinci codes the the biggest circulated book like the bible. the da vinci code is not the biggest circulated book in the world. i'm like i i can't speak to don quixote so um that's something i might just have to look up because that's interesting to me. oh no you know don Quixote or something i'm just like i don't know what that is. that's an interesting thing to think about. i may have to do some research on that. i might have to find out more about it.

ROUGE-1: 83.81, ROUGE-2: 78.04, ROUGE-L: 78.92
BERTScore: 82.32

==============================================
==================== [68/100] ====================
Summary:
The average velocity depends on the time interval t to t plus delta t while the person has displaced a certain amount of vector delta r. So, as a vector, we have delta x over delta t i hat. This component here is what we call the component of the average velocity. And, again as before, this component can be positive, zero, or negative depending on the sine of delta x. And now what we want to do is consider what happens in the limit as delta t becomes smaller and smaller. And that will enable us to introduce our concept of instantaneous velocity.

ROUGE-1: 55.17, ROUGE-2: 53.33, ROUGE-L: 55.17
BERTScore: 82.08

==============================================
==================== [69/100] ====================
Summary:
Last week we looked at the we first saw our first magic formula which you've probably forgotten because it was a wonderful weekend so I'll remind you and um then from there we will uh resolve the spider problem and then uh we're going to look at uh uh something called the super magic formula. These are not official names I made them up or it's please please never ever say these in public okay but uh it's a useful formula okay um so last week we looking at as I said first of all we.  angular velocity is a kind of a madeup concept that just simplifies the math and it's kind of intuitive stuff is rotating Theta Dot multiplied by you know the Le lever arm right gives you a velocity. The Machinery I provided you is powerful enough to solve pretty much any kinematics problem because it's based purely on Geometry. The angle of velocity of in fact I'll fill that in later on a b and I wrote it as this so help me write it.  angular velocity is the angular of velocity frame B with respect to frame a right okay so we saw that for the first time now a little bit on the low of angular velocity that you've seen in previous classes but we we Plunge in anymore um the first thing is can of Point have an angular velocity now can a point have a velocity yes can a frame have a Velocity kind of no because if a frame's rotating some point different points will have different velocities so yeah a frame can have aVelocity but doesn't really mean much. "Ales don't add up right if I change the order in which I add angles" "Infinite decimal angles do add up" "If I rotate about one axis a certain amount 30Â° and then rotate about another axis 30Â° right" "You' seen this in Cloud yeah huh and that's right and why is that say again" "There's a plus minus two angles right but you know where I'm going with this" "Why is the angle adding up here a has something changed over the weekend" actually come pretty close all right so it turns out that infini dismal angles do add up. angle of velocity is D Theta by DT right and it's a vector if because it is about some direction and there's a d Theta here. If you you know have another angle of Velocity you add them up they doAdd up so the map does work out you understand am I making sense or not making sense any questions about this anyoneYeah angles don't add up what I mean by angles donâ€™t add up is that if I said um rotate rotate. a rigid body right take this rigid body body and we we have two rotations one is about this direction right I was I was a little quick because I assumed you seen it before but I'm noticing that you haven't seen this before perhaps they don't talk to you about this in physics anymore so maybe let me take a step back and describe it in more detail. Instead I if I said rotated about X first and then rotated about Z instead I would have said X Y and Z so let's say I'm going to rotate it about Z 90Â°. you understand so if I just took Theta as a Theta with this vector and I said apply these two rotations well depending on the sequence in which you added the rotation vectors up you end up with a different position right but vectors don't have the problem when you add two vectors it doesn't matter what sequence you add them in right if I have two vectors whether I do this or whether I write this first and do this the net Vector is the same you get it. So if I'm going to treat angles like vectors they should add up correct regardless of sequence they must give the same result but they don't. of thing you need to kind of walk around with a book you know and people will think you're nuts but you know do that and you'll see that the angles kind do add up you get it. Angle of velocity is a measure of the rate of change of angle so it's a d Theta. It's a tiny angle get it in a moment of time right in a very tiny moment ofTime so angular of velocity does add up so you can treat it as a vector in the math. right then and between two other frames and you can create a sequence of frames you can calculate the angle of velocity of the final frame so if you look like look at a like a a um like a really complex system a gimbal assembly for example right you can always find little joints right mechanical engineering is full of these you know one Dee Freedom joints we call them hinges for example. You can always add up the angles of velocities and the net angle ofÂ velocityÂ is the angleÂ of velocity ofÂ the final frame with respect to the first frame. the final you know in terms of that initial frame get it and W so we introduced the the velocity and then the next thing we did last last in the last class was I revealed to you this magic formula I said if you have a vector let's call it n and you want to take its derivative with respect to the frame a now if it turns out it's more convenient to take the derivative of that Vector in b then you can do this. A lot of math lot of derivatives that's how we did it uh. but you need this correction term which is very beautiful done done okay so this was the magic formula that I introduced in the last class how would we go about proving this anybody yeah do the math how wouldWe do theMath how would We prove this here's what we'll do let's prove it let's consider a frame a by the way you notice I will always show frames with this little circle a saying that it's a frame and with a little wiggly line pointing to it I willAlways do that if I don't stop me and make sure I do it okay. little A2 are the basis vectors okay or the unit vectors you can always assume that little B1 little B2 are. the basis Vector vectors in b I'm going to stop writing it because it just clutters up the diagram. Let's let's assume n is equal to sum U1 which is not a constant time B1 + U2 * B2 now what I'm trying to prove is this formula how would I go about doing it someone wake up everyone's asleep wake up wake up. yeah let's Express exactly we're going to express B so here's what we're looking for we'reLooking for a d by DT of N and look n is expressed in terms of B1 and B2 that's really not nice. The way you would do it is convert it to an A1 and A2 representation can you please look at your notes and tell me what B1 is interms of A1 or A2 quick look atyour notes say it again is it plus or minus so B 1 is cosine Theta A1 is that right? compute the right hand side up there what would the so the rightHand side would be to take U1 B1 plus U2 B2 and take the derivative with respect to to frame B right yes maybe right so tell me what it comes out to be what's the first term on the righthand side mhm B2. Let's see if these terms show up there do they aha yes this shows up this Shows up up so this matches this matches right so now let's take a Omega B what is a OmegaB folks quick Theta dot it's a vector B3 isn't it the A3 why is it the. B3 they're the same. that's aligned get it okay so that right hand side term and we're going to use B3 instead of A3 just because our Math's going to be simplifi simplified. If you do the math there I'm not doing it because I want you guys to stay awake in class I don't want to just blindly copy down the notes here right so it all works out okay I will never ask you to prove something like this in an exam right this is almost like a solved example. you're confused that is fantastic because that's a symptom of something else and I'd like to surface it and help you figure it out any confusion about this anything. The first term here was BD by DT of n the second term is simply that this guy make sense John you convinced no no no are you convinced uh convinced enough okay anybody else you've totally got to get this Andrew yeah you had a rotating and rotating and Des okay okay. I took so look what's the magic formula it is the left hand side is this is equal to b d byDT of n right in the B frame. let's do that so let's imagine I'm spinning a basketball on my finger I could never do that but let's just imagine I's doing it right I'm standing at this and spinning a Basketball on my fingers the room the world the Earth is a frame the basketball is another frame the kind of the U you know you guys need to be like uh Neo in Matrix have you seen that movie right it's very very important if you understand Matrix algebra you need to see Matrix all right so go see Matrix. video game right so similarly so what others see is a is a basketball spinning what you see once you're done with the scores is you will see an embedded V embedded basis frame you know with its AR you know pointy arrows sticking out of the basketball get it and you would see it spinning. But one of the axes which is the one one pointing up ain't sping right it remains vertical got it? You can kind of do this Freeze Frame where you frame and freeze it then a second you freeze it again you measure the angle and that's Delta Theta over Delta time. a frame and be done with it okay any more questions about this very important hey let me ask you another question when I say frame is rotating with this is this is a tough one. When a frame rotates on another frame for an instant with respect to that other frame there might be a point that does not move. That is called the instantaneous Center of rotation but that but the angle of velocity is in about that point. The frame has an angular of velocity it's not an angular velocity about a point get it. yeah okay using um frames uh using angle of velocity so the problem was we have the ground, the spider and the Frisbee we put a frame here. How many degrees of freedom does the insect have in the same plane in the the same Plane in 2D right assume this it's like a hockey puck it's sliding around the ground how many degrees does the U frisbee have two dimensions in two Dimensions I have a Frisbees and it's you know I'm I'm throwing it in a flat on a flat plane right how manydegree does it have three okay. The three parameters are u v and L the way we're doing our geometry we're saying the the spider look this is just in formal okay I'll formalize this ston right. Those are the three parameters that change in our geometry and with those three parameters we're going to capture the blocation of the spider but we're using three parameters but in the end the SP spider is only going to have two degrees of freedom right but that's okay because when you get the velocity of theSpider it'll have only two components when get the acceleration only have two components so it'll work itself out. the the acceleration the velocity and acceleration of the of the insect anybody how do I begin write down the yeah always begin by writing down the position Vector so r o s is equal to U A1 Plus V A2 plus L B1 L is the distance of the spider from the center of the fris oh oh I call it Q sorry sorry I'm sorry q h say it again ah let me ask you when I write a position Vector does it need a reference frame doesn't the only thing where I can get away without writing a a uh reference frame is when I writing a vector at a vector. B it's just a mishmash of little vectors that are all defined in terms of parameters it's it's an important question you need to understand this this actually encapsulates the geometry of this entire problem right because if I CH change U1 the whole thing is going to move move to the right if I change U uh V uh sorry if I changed uh sorry U the frisbe is moving to the left. If I change the parameters things change parametrically that's also called parametric design okay okay so how do we solve the problem now I want both the velocity and acceleration of the spider. With this with the magic formula we can rewrite this as what so um first of all L is a scalar so there are a couple of routes we can go here okay and I just want to give you the routes one thing we could do is we could say l do a by DT B1 plus B1 you know we know we.d by DT of this Vector which is now these two guys no problem I can write them as U1 Dot A1 Plus U uh sorry V Dot A2 not U1 not U2 but U do V Dot right plus now I need I have this kind of mismatched term. can kind of do it that way but the simple way to do it is to simp well you know it doesn't matter we can just write this as B take the whole term d by DT of lb1 plus what quick hm I'm hearing a hesitant murmur not the yeah I was mumbling something a moment ago I'll tell you what I mean what I was trying to say uh cross lb1 what is a Omega B so we can rewrite a Omega b as Theta dot B3. um what I was trying to say here was you can go a couple of ways with this right you can say l is a scaler and pull it out and just apply this whole thing to you know do by CH by by uh uh use the chain rule or you can just treat the whole thing like one vector get it and they're both okay they'll both come out with the same answer that's okay okay because L is a Scaler. L is doesn't care what a reference frame is B1 is a vector it cares which reference frame you take its derivative in L doesn't you understand. by DT of B1 whichever way you do it the answer will come out to be the same just go naturally understand the the basics go naturally it'll work itself out is my point all the rules apply okay all right so now we want to calculate the acceleration now. We want to do the acceleration plus you how do we do this come on say it again yep take the derivative of this guy right I'll just write it all out and we'll do it neatly this time d by DT of u. A1 Plus v. A2 plus L dob1 plus Theta do L B2. on someone back there huh magic formula right and so the magic formula the way it will come out is this is going to break down to two terms. The first term is b d by DT of B1 of l. B1 plus a Omega B I'm going to stop writing a omega B I'll just call it lb3 to save our soul sorry theta. B3 cross l dob1 so these are the two terms from this guy and what do I do with the next term I repeat it. On purpose by mistake you never know with me I think it's correct okay and that is U do a1+ v. A2 plus this is going to be easy now. We need to do this guy by by in the using the chain rule right because the two terms you have to take the derivative of right say it again I'm sorry oh l dot here yeah so here what do we have we get th. lb2 L do B2 so by the way you notice this term showed up twice right that'll become so anyway we'll remember that plus what is this. compacted the math recognizing the magic formula right and it was all initiated by Andrew who asked the question why don't you do it right for which he gave up his watch AJ I'm going to show the videos now okay just to kind of break them on monotonous prob start with the um Med go round and then the other one right so this is it I'll tell you when to start in a second right so these are all the terms they're going to be there should be one two three did we miss anything oh we missed something for sure yeah okay um help me remind me what these terms are. you'll notice with coris these two terms always show up in different places and they add up just and it becomes two right. What is this guy cental what is this guys it's called Oiler whatever okay if you as I said if one of you invents a new term we'll name it after you okay and and so far I've used these words coris and all that I kind of called them out without telling you a lot more about them right so what we're going to do now is take a break in the following way I'm going to show you some videos showing you the coris force. We're going to derive a very general formula for something moving on something that's moving get it no seriously it's going to be a general formula. The super magic formula as a code word in this class so it turns out that several people have done research uh and I mean not like hard C technical research but research involving merar rounds. All the formula that you have so far are for things moving on a frame right but now we're going. to kind of but this frisbee is somethingMoving on Something that's already moving so we're Going to come up with a General formula for that. The Coriolis effect is a phenomenon that occurs when objects in an inertial frame move in a different direction to the path of the ball. In this video, four kids are sitting on a merry go round and then someone comes and starts spinning the Mero around. The kids in the merry go around see something different to the observer above them. G volume is turned up to an observer above the merrygo around the path the ball appears to appear to go in a new direction. The Corioli effect is the result of a change in the shape of the object in the frame. This is to this one I discovered uh I think last night and um there are two dudes who went to a high school and they put a bilard a pool table on top of the mound okay and then they did some experiments and these are very committed people I must say was obviously also a cold day and I just thought I'd put it up just to show you the power of human Innovation go ahead but these these dudes are very. committed people and they're very smart and they've got a lot of ideas. totally into it so they don't stop but the real the funny thing is that the kids actually can't see all this because they're below the level of the pool table so they're like jumping off you know okay so let me explain what's going on here so it turns out and then we're going to do the super magic formula in about a minute right. It turns out that with respect to someone standing in space and not rotating with the planet earth right so if you're standing above the North Pole and you're looking down at the Earth rotating it's like a mer around. kind of Swing Away get it and what happens with things like hurricanes and we'll show you I'll show some videos later if we have time is so now you're you're on the North Pole right you're sitting in the North pole and this is the Earth this isThe North Pole okay you're looking down a particle when it's let's say there's a low pressure region here low pressure so when all the particles start rushing towards it because it's low pressure right but they think they're going in a straight line but meanwhile the particle is moving with the Earth. tornadoes and stuff like that that's why it spins in a certain direction in the north on in the Northern hemosphere and the southern emisphere spins the other way right. There is a Coriolis effect but the slight deviation angle is so slight it's like a fractions of a degree per meter at that scale that it doesn't build up enough to really impact the Earth's climate. It's turns out that in that scale in fact there's a Coriolais effect. It doesn't affect the climate in the northern hemisphere. direction in which the vortex takes place okay the vortex is created far more by asymmetries in the sink or by rotation that was created earlier that can of remained right okay the angle of momentum which we'll cover later on the class it stays for a long time and it influences things to go in one way or the other. So it sinks you in fact you can construct a really large sink and you know apparently you can show it but it's very hard to do it it's hard to kind of isolate environmental factors so sinks not a valid example hurricanes avalid example. rotating other words there's a Theta Dot and an l dot term get it then there is a deflection in the B2 Direction in the way we've written it now I'll give you the general formula and you know B2 what it is ETC it become more clear any questions about coris by the way in the last class I told you this anecdote I said that artilleries artillery guns right in the 1700s 1800s um they would have to compensate for directionality because of the coris effect. that wasn't the reason the corus effect was discovered so I take it back right but there it is also true that in the in World War I when the British when a British Fleet near Faulkland ran into a German Fleet they spend they shot 1,000 shells uh taking the Coriolis effect of the northern hemisphere well they were in the Southern Hemisphere and missed and then 60 shells um they actually use the right correction and they nailed the German Fleet and they won that battle so it's certainly true that by this you know by by the time World War II came along the range of these guns was high enough that the coriolus effect is relevant. What is the force that the astronaut feels you know or what force must the astronaut exert in order to move in a straight line with respect to a spaceship or a space shuttle or something? That's the question we seek to answer. What we're going to do is basically generalize the Frisbee problem and the way we're gonna do it is just watch YouTube videos all day. To see more videos like this just in fact why don't we just watchYouTube videos all Day it'll be fun right all right. Kane K an is a professor at Stanford he I think he's still there retired um and uh kan's method is used uh to analyze the Dynamics of robots complex robots and Space Systems. Once we finish this concept it's beautiful and now by the way this kinematics that I've done is completely 3D right you can do any 3D system with this stuff. Going to do it is like this we will Define as usual and you'll find this all repetitive because really it's all the same stuff over and over again just getting more and more compacted. around Etc they use this method they use the symbology a b and all that right very few undergraduate courses on the planet uh learn teach the mechanisms that you've learned and understood right this is it that's all there is to on the kinematic side now Kan also has a way of doing Dynamics which I won't tell you I'll do the Newtonian approach uh but you certainly have it okay so the problem we seek to solve now is a your frame a a I'm actually trying to derive a general formula that captures what we did for the frisbe you have a frame B and what we're going to say is frame B is hurtling through space. to my notes p and this is point Q so I'm just generalizing it earlier put that you know the spider was going along uh the B1 basis Vector right. We want to express the acceleration the velocity and acceleration of Point Q with respect to frame a is assuming that it's more convenient to naturally denote it in terms of frame B get it like I'm walking in a spaceship I can measure my distance to the back of the spaceship right but I really want to calculate my acceleration withrespect to the Earth okay so that's what we're trying to do now. with respect to a what do we call that say again it is yes it is if I take the derivative of this it is right plus the derivative, this so in fact if you want I'll expand it I'll write it in smaller steps so you you you can follow it right right I've just written it out right. So this is the velocity version of the magic formula and I'm sure you'll admit that I did nothing particularly profound in deriving this okay and then that handout the typed handout that you you hopefully downloaded and read from the web you will see this EXP expand it out for you. acceleration of Point Q with respect to frame a what do I do yeah just take the Der of that one. Point p is a point fixed in frame B you understand very important so space shuttle astronaut cting on Space Shuttle find one point on the shuttle for example the instrument panel that figures out you know where the space shuttle is. If I'm doing anything that's not boring that means I'm making a leap that is not uh grounded yeah did I miss something yep yeah yeah P just so you know thank you AJ. is that's Point P get it so rpq is that vector okay okay so now let's do this how do we expand this what is this term come on yep what do I do here guys magic formula so that you know I line these two guys up right plus what what plus so that's these these thesethese these two terms correspond to this guy what next whatDo I do with this guy same thing okay absolutely the same thing it's correct precisely okay same thingOkay don't worry it's all going to work out this is perfectly cure I didn't do anything wrong here I don't think anyway I did anything wrong. yeah ah very good B where's this guy well it's just that it is what it is you will recognize it as anyone recognize what this guy is it's half of the corus effect the coru effect is actually two terms that come together right and it'll become two eventually so we need to look for another of these guys keep an eye open all right okay what do we do here folks tell me claudo leave it as it is no we want to expand it out take the derivatives away y what's your name yeah what's his name sry Jeremy yeah what did you say a yeah but it's a vector you're on the right track though can you do it using the chain rule why not let's do that okay let's doing this b d by DT of a Omega B right cross rpq okay I have a caveat when I finish this I'll come back to it what I'm doing it is is fine plus a Omega B cross b d by DT of rpQ so that's these two guys make sense plus what about this could I do there I just just leave it as it is don't worry okay yeah okay I can't change the order did I changed the order yeah you can'tchange the order you cannot change the Order say it again I'm sorry aha. a just a PhD student is getting his PhD in U in wiress sensing oh oh sorry sorry sorry Simone I'll be out in a minute one more minute excuse huh just one minute sorry thanks Andrew next time set your watch 3 minutes fast like mine okay so folks I'm going to write out the super magic formula actually this is it okay the supermagic formula is this and I'll name the terms and we'll finish it next time a acceleration of Q is equal to the acceleration of Point P which is the fix point plus b a Q Plus ahuh what is this guy Alpha huh do I skip which term do Iskip we'll come back to this. yeah sorry and plus this thing okay we'll end now because Professor Socrates needs to take over this is it this is correct acceleration of P acceleration of Q with respect to B Oiler coris centripedal and you know why it doesn't go to zero because I'm not taking a Omega B cross a omeg B. I'm taking a omega B cross this whole term which is at 90Â° to a OmegaB got it got it? Yeah sorry and Plus this thingOkay we'llend now because professor Socrates need to takeover.

ROUGE-1: 69.52, ROUGE-2: 67.04, ROUGE-L: 63.42
BERTScore: 74.53

==============================================
==================== [70/100] ====================
Summary:
Al shalot is the CEO of GT Sports. He is a member of the Olympic commission the international Olympic Comm. He has been advising in the background for a while now. He says it makes absolutely sense to pay respect and celebrate gaming by having a dedicated event. It's part of the agenda strategic agenda 2020 plus 5 to connect with the audience the youth audience where they are and to leverage gaming and Esports to do that so it was strategically cited and we're just part of a discussion about how to implement it. have been very successful at using the gaming and the entertainment of virtual games to connect with audence with borts so there's less of like a fear and more kind of an excitement for the the potential. The Asian Games officially added League of Legend and other games on their list and suddenly you had like a lot of people watching a lotof people attending. The people from the Olympic Committee when they attended this event they like okay now we get it now we see that this brings so much potential to connecting with this generation that we need to take it seriously. moving around very much they're going to be in one location can you explain why Saudi Arabia as the host. I'm not sure that from from what I heard um this is a strategic partnership with a with with a host that has a lot of capabilities and we can talk about that in a second. They just said that it's going to come regularly to to be hosted in Saudi so my understanding is that that means that we're Going to go several times but not all the time just to to put this into context. a reason I think 70% of their constituents are passionate Gamers um and and if you're a gaming publisher or gaming team like us this is the fastest growing region of the world right now for gaming and eort so this is why finally I would just like PC always brought the idea to bring a property and events to a country to create some bridges I remember when Beijing was elected to host for some Olympics it created kind of like a a moment of like creating Bridges with like China and I I see the same way gaming entertainment in general could be a breach now for Saudi Arabia. you expecting to have those kind of conversations with some of the national Olympic committees and at the very least is that something that came up when you were advising the ioc on this. We have not been involved in the discussion with the host cities I know several City apply and and wanted to be the host uh this 12 years partnership sounds like a amazing opportunity to have a fing partner to launchable property but what I would say is that you know we we have been attending multiple events all over the world with or teams. to use this platform to to be open to anyone I think that's the way they describe it um so I look forward to it uh what I would say is like as a team as a as as players as athletes we want them to to play in the the best tournaments the best teams and therefore want everybody to participate so you mentioned the Esports World Cup there uh it feels like we've got lots of big new announcements lots of tournaments are we in danger of having too many things going on I don't think so and and we can talk about it. Singapore and we had an exhibition for Rocket league so apparently at this time this kind of game will be official titles and not just exhibition so all those games you've mentioned pretty uncontroversial. Do you think that there could ever be an Olympic branded event that has a shooting game in it though like do you thinkThat's ever so it's going to be possible to have a shooter under Olympic branding if if if you ask me I believe. Is it g to happen next year probably not I think there's kind of like a it's a common theme to talk about which sports are featured in the Olympic Games. Competition and as you can as you probably know poetry is no longer on the official program so I think uh it's totally possible that in the future uh finding the balance as always between popularity relevancy and a certain fit with the values that the Olympic Committee wants to project this kind of game will be futureed. At the short term it would be either depending of each title probably either a dedicated tournament for woman or a full mix tournament where it's possible but I'm very positive and affirmative that this will make a huge step forward. I'm not aware of any plans to to include video games or Esports in the Summer Olympics uh organizing Olympics games like winter or summer is a huge logistical challenge one of the idea from the ioc has always been to say okay can we can we do smaller or can we stop growing because it would be difficult for any City to host it if we keep growing again and again. By creating a a dedicated competition I think it gives more space for more game title to be featured. It give more room for celebration of gaming and ort instead of being one the additional Sports I Come Just As exhibition or just as a visit. of view of someone who runs a team uh one of the most successful teams in the world. What kind of impact will this have on your players because uh you know they might be getting pulled away to compete in these big International tournaments. There might be different connections they can form with players what's the impact going to be what's going to change I I see the long term okay I don't want to talk about oh who'sGoing to pay them should we be should we receive innity because we we give our players to the teams. opening ceremony under the the Olympics logos this is amazing the pride in their eyes is the fact that the parents had to find a passport for them to travel to represent I think this is what I want for every single players of G2. I believe this will also help us to connect with the BBC and talk to a mainstream audience about something that they don't know and and be discover this amazing Community this amazing passion the the Quest for excellence and the individuals that will become the heroes to win the trophy for the national team. similar to the summer and winter games uh there'll be something you know with a flag ceremony uh probably at the beginning. I think you know to see some of the players that we selected when they were underage that we help become the best version of them themselves as athletes being selected to represent. We have been dreaming of this like France against Spain with the best player of the World in League of Legend for years um so that's exciting for me as a as a fan not as a professional just as afan. their country wherever the country we have Chinese players we have malesian players. We have French players German players Turkish players American players at G2 make will make me super proud. I'm very excited about that and that makes by definition this event very special. There has been some small minor events with amateur players representing the country but nothing that ambition to be the best player of the world in the biggest games with national teams. That makes this eventvery special for us. We've got lots of events in Esports already what makes this one different is this idea of national teams like it's in the DNA of Olympic games. special the parity in terms of like uh balance between over multiple games is also something special aside from Bas Force World Cup. The mixity in gender which I think is very important desperately needed by Esports industry. It will give us an opportunity for the best player of the world to Showcase their talent and Inspire the Next Generation to believe it's possible for me to have a ro to play in Esports at a professional level just to follow that one up obviously you talked to lots of Esports players in your team is there a real want to compete under the national flag people want to do it. "Everybody wants to see what a dennish team will do against Corin I I would love to see it too you know so um I've seen a lot of players making the the guess or what the team could look like so his aspiration to be part of is is clearly part of the discussion," he says. "You follow a bit like the conversation about but uh rocket league and OverWatch back in the days at the at the World Cup for for their game and and and League of Legend also often have this conversation about creating the Euro Cup or World Cup"

ROUGE-1: 58.41, ROUGE-2: 56.55, ROUGE-L: 53.83
BERTScore: 64.18

==============================================
==================== [71/100] ====================
Summary:
"Unlockable" is ambiguous. It can mean either it's possible to unlock it, or it is not possible to lock it. So it can be a desirable property of a lock or not. I have this desire to put an extra oomph on "un-" -- an extra little demi-stress beat on "Un-" if I mean the thing on the right. I want to pronounce it a little differently depending on which of those things I say. "It's unlockable," means it cannot be locked. in the following way. To say that something is singable is to say that it's possible to sing it, right? That's what that means. So there's a "-able" suffix that changes verbs into adjectives. And then, we said, there are two "un-"s. There's an "un-" that combines with verbs and makes verbs. That's something like undo the effects of, or change something so that it is no longer in the state that it would have been if the verb had applied to it. "untie" means "take something and do things to it such that it is no longer in the state that you have tied it" "Un-" number two combines with adjectives and makes adjectives that mean more or less "not (adjective)." So "unkind," or "unfamiliar," "Unfortunate" These all mean not the adjective, whatever it is. And so what we said was-- oh, hey. Raquel? So I have a question for you. horrible thought, and it's random. If I untie a shoelace, first of all, it has to start off tied, is that right? So if I have a Shoelace which is not tied, I can't untie it. But if it's tied and then I take scissors and I cut it into many small pieces, have I untied it? No, surely not. When Alexander cut the Gordian knot, he wasn't untying it. the knot. He was being more direct than that. So you have to put it back in the state that it was in before it was tied. Is that the way to say it? AUDIENCE: Going back and tie it, [? essentially ?] NORVIN RICHARDS: Yeah. So yeah, that's a nice point. Undo. That doesn't mean "take the socks and make them dirty again." You can't-- if I take some shoes, I can't unwash shoes, or unwash socks. could imagine that it would, but that's not what it means. Joseph, did you have a-- AUDIENCE: Yeah, I was going to-- based on what Raquel said, does the final-- after you "un-" something, is that going to be able to be redone? So if I untie a shoelace by cutting it up, now-- NORVIN RICHARDS: Yeah. It can't be tied again. Well, let's see. If you undo an operation on a computer, does it have to be possible to do the operation again? There are two "un-"s. One combines with verbs to make verbs, the other combines with adjectives. The ambiguity of "unlockable" can be attributed to the fact that there are two 'un's. There's an "-able" that changes verbs into adjectives, and there are "un"s, one that combines with verb and another that combines. with adjective. It's a little complicated, figuring out what it means, as you can see, but what I've said is true. have attached the "un-" after you attached the "-able" Because the "-ables" is going to change a verb into an adjective. So that was the way we were talking. And the ambiguity, we said, comes from the fact that, well, there are two "Un-"s, which is something we can observe. And that means that there's an "un" that can go before the suffix. And so "unlockable" is ambiguous. It's related to the meaning of "lock" in mysterious and complicated ways that we've now been talking about. can go after the "-able," and so we get this ambiguity. And the ambiguity is what we would expect it to be. Go ask some people whose minds have not been contaminated by linguistics. Go harass your roommates or whoever. You'll make yourself popular that way. And if you are going to try to learn from me how to make himself popular, then boy, are you in the wrong class. OK, is this all clear? So the important part of the story is to say, yeah, "unlockable" is a word. It's got three morphemes in it, a prefix, a root, and a suffix. But it isn't just three morphos in a row. You assembled them pairwise. You first put two of them together, and then you added another one to the result of that first putting together. That order has consequences for interpretation. Now what we're going to do now is start talking about syntax. It is the study of how words are assembled to make sentences, words, sometimes smaller than words. you last time was, effectively what we're going to want to say is, there was an operation that created the substring "up the stairs" in that first sentence. That's what we call a constituent. And there is no similar operation creating a substring 'up the reference' in the second one. And again, this is review, but it's review from the first day. What I convinced you, I think, I hope, I tried, was that there are various syntactic phenomena, various things you get to do with sentences. It's a strange way to ask the question, but you can say it. As opposed to, "Up which reference did Mary look?" which is gibberish. So we're going to draw a distinction. This is maybe the first time that I've shown you a case where syntacticians have to care passionately about the difference between one sentence and another. There's a fair amount of great syntax that's built on those kinds of distinctions. The point is, just as with "unlockable," yeah, it's three morphemes, prefix, stem, suffix. But having said that, we haven't said everything. We have to know which parts of "unlockable" are single parts. And there is a part, "up the stairs," what we call a constituent, that various kinds of syntactic phenomena care about, like the syntactic phenomenon can I repeat this if I'm astonished? Yeah, that's a test-- kind of test for this property of constituenthood. Theory of syntax divides sentences into three kinds. There are sentences that you've heard a zillion times before, like "We're going to class" And on the other hand, sentences you have possibly never heard anyone say, but that are fine. syntacticians are the opposite of normal people. When we see things we don't like, we give them a gold star. Usually, it's not gold. It's black. But it's an OK sentence. As opposed to, "We's class going to," which I've given a star there. You're not just categorizing sentences into sentences you've heard before and sentences you haven't. You've got this intuition about which sentences are acceptable. We're going to try to figure out what that is. But I'm giving you these three sentences to slay a hypothesis that you might be entertaining. Stop entertaining that hypothesis. Make it go home. It's not a good hypothesis. It won't do you any good. Is that clear? Are people clear on the hypothesis that I'm attempting to slay? Yeah? So this is day one of syntax. So no, you're raising a good point. What if all you're doing is remembering chunks of sentences? So maybe there are some parts of this that you could be acquiring that way. We're going to have to pursue that hypothesis long enough to find out exactly what it says, right because what I just said, which wasn't really the hypothesis, it was an attempt to represent it, we're going-to have to figure out how to rule out "We're class" There's a fairly stupid hypothesis, which says, all you're doing is remembering things people have said, and that's what distinguishes grammatical sentences from interpretable sentences. That's false. You can take a sentence you've never heard before and accept it. We're going to have to be explicit about which subparts count and what exactly we mean when we say that. But you're right, there could be a better version of that hypothesis. Good point. Other questions? Did I successfully answer your question? Yeah. a living? How I answer depends on whether I feel like talking to the person or not. If I would like to get them to leave me alone so that I can read a book or whatever, I tell them I'm a theoretical syntactician. That usually ends the conversation fairly quickly. But when it doesn't, when they say, "Oh, what's that mean? What do you work on?" Then I will say, well, I'm trying to figure out why some sentences are grammatical and others aren't. Chomsky: We're capable of distinguishing grammaticality, even in sentences that don't mean anything. "Colorless green ideas sleep furiously" is meaningless if you don't mess with the meanings of the sentences. "Furiously sleep ideas green colorless" obeys the rules for how words can be combined. We can have English sentences that consist of two adjectives modifying a noun. And we can say, "We're class going to." Maybe that's what's wrong with it. then there's a verb, and then there's an adverb. "Big green monsters snore loudly" that would be fine. "Oh, what's wrong with 'We're class going to' is that it's a meaningless sentence" If I'm really, really desperately trying to end the conversation, I bring out these kinds of pairs. So it's not about meaning. We have this intuition that there are sentences that are OK and sentences that're bad. It's separable from our intuition about what means something and what doesn't. that certain types of words are categories that you can add more words to. And like, "This house is very [blope?]" That's grammatical, even if you don't know what it means, or you can't make that. We were talking about open class and closed class morphemes. So Jabberwocky is a poem that you could write, changing all the lexical items to nonsense words, but you couldn't do that with functional items. Yeah, that's right. it's [INAUDIBLE].. NORVIN RICHARDS: Yeah. That's a nice way to put it. I guess this is similar to what I was trying to say about a reaction I sometimes get to this sentence, which is, you say "Colorless green ideas sleep furiously" doesn't mean anything. And people will sometimes say, "Well, but if these words meant something else, then it would be OK," which is true. But it's clear what "furiously" is trying to do. It's an adverb and it's trying to modify "sleep" right places. We will eventually do the semantics part, which is about meaning. But the point is that it's possible to study these things independently of each other. So completely independently. The reverse, there are sentences that are ungrammatical, but-- that are meaningless, but grammatical, like "Colorless green ideas sleep furiously." On the flip side, there is a sentence that is grammatical but is meaningless. But our feelings about whether sentences are grammatical or not, or acceptable or not are separable from our feelings. That's the point, if anything. are sentences that are meaningful, but ungrammatical. It's clear what "I put on it" would mean, but there are facts about how English pronouns work and how English particles work that mean that you don't get to say that. The only point of these few slides has been it's possible to study syntax independently of meaning, where by independently, it's not a meaning thing. It is something about how these parts get to combine. You want to try to understand that. I just mean the facts of syntax don't just reduce to facts about meaning. That's what I've been trying to show you. Here's another thing you might think about what's wrong with "We're class going to." It ends in a preposition. Where any of you taught in school you must not end sentences with prepositions? Some of you were-- AUDIENCE: [INAUDIBLE] NORVIN RICHARDS: Yeah. I was beaten by English teachers for ending a sentence. There are some cases like that but look there are also cases like, "Who are you talking to" where-- sorry, where-- who am I apologizing to? The chalk, I guess. English speakers end sentences with prepositions every day. Do you know why your teacher told you not to do that? Yes? AUDIENCE: Maybe it's because the object isn't clear? NORVIN RICHARDS: Well-- but is it? I mean, it's kind of-- if I ask you, who are youtalking to? There's a question there. sense in which the object isn't clear. "Who" is supposed to be the direct object of "you are talking to" this person, so it's like, "to whom are you talking"? "To whom" is part of this phrase that's at the beginning. But question, why does "to" have to come along, according to the audience? "I don't know about you guys. It's not my go-to way to say this," he says. your English teacher? Yes? AUDIENCE: Is this another example because that's how it's done in Latin? NORVIN RICHARDS: Yes. Yes. Your English teacher told you to do that because Latin, actually, among many other languages, doesn't allow you toDo this. You have to do this. English is quite rare in being able to doing this. Most of the languages of the world can't. Some time in the 15th, 16th century, a number of grammarians decided that English would be way cooler if it were more like Latin, and so they began declaring that it was. like that. There should be a stranded preposition, a preposition at the end of the sentence. So yeah, no reason English has to be like Latin. Or like I say, a zillion other languages. Most of the languages of Europe, French, or German, or Italian, or whatever, you can't leave prepositions at the ends of sentences. None of those kids would ever do that. But in English, we can. We should be proud of that. grammar. So what we are doing in this class is trying to figure out what people actually say, what the rules are for putting sentences together in English. We're not going to talk about that stuff, except to mock it the way I did just now. So prescriptive grammar is the study of rules that your teachers might have taught you in school about how to speak. Some of which, just to stop mocking it for a second, your teachers may have tried to tell you things that would genuinely improve the quality of your writing. that were valuable. But they also taught you some things that became popular around the 15th, 16th century because people thought that English would be better if it were more like Latin. So we're not going to try to improve your writing in this class, except insofar as the writing advisors can do that. So this is going to be a study of descriptive grammar and not prescriptive. Yeah? AUDIENCE: So for that second sentence on the board, "What are you talking about?" NORVIN RICHARDS: Oh, this one? Yeah? In many languages, most languages, including Latin, you have to say, "About what are you talking?" In English, there's this distinction between the examples where leaving a preposition behind is what you prefer, "Who are youtalking to" But you can kind of say, 'To whom are you Talking?' Do you know the answer to that question? If so, please email us at jennifer.smith@mailonline.co.uk and we'll feature it in next week's show. other people have this intuition, that "About what are you talking?" is worse than "To whom are youtalking?" I have that feeling, too, I think. There are examples that are really quite bad. And other examples which get better. So things like "We left despite her warnings." And then consider two kinds of questions you could ask about that. "What did you leave despite?" And "Despite what did you left?" Is either of those acceptable at all? Who prefers "What Did You Leave?" and "Despite What did you Leave?" a fruitful area of research here. English is happy to leave prepositions at the ends of sentences. But in which cases is it happy to do the Latin thing? And in some cases, it's happier than others. Another distinction to make. So we've drawn this distinction now between meaningless on the one hand and ungrammatical on the other. That sentence can be both meaningless and un grammatical, but it can also be meaningless and grammatical. We've drawn a distinction between prescriptive and descriptive statements. here's another useful distinction. It's sometimes called competence versus performance. Imagine that I'm standing up here talking to you and I say, "This is the--" and then I Inhale a fly. And then imagine that this experience is so traumatizing for me and also for the fly, that I just I never complete that sentence. That's the sentence that we could have to me having uttered that sentence, and that's the attitude that we can have to each other. I uttered. "This is the cough, ugh, puh." That's something I said. And I'm a native speaker of English. So there are two kinds of things we could say. One would be to say, we're developing a theory of all of the kinds of sentences that Native English speakers can say. And that was one. And then there are going to be other things. Flies, sudden heart attacks, and then other kinds of thing that are maybe less clear to think what to say about them. was going, and-- where was I going with that? Who knows. So what we're going to have-- so this is a different approach, and it's the one that you might imagine I'm recommending. What we'regoing to have is the idea that we's going to develop a theory of what English speakers say, but we're Going to imagine the kind of English speaker who never inhales flies, and never forgets what they were going to say, and only speaks in completely grammatical sentences. Journalists know that the best way to make someone look like a complete idiot is to quote them accurately. What journalists, in fact, do is to clean up all that stuff so that people sounded like they were talking in complete sentences. So we're going to develop a theory of what English speakers say, but it's going to be a theory that's divorced from reality to a certain extent. We're Going to Imagine what English Speakers Say is going to look like to you and me. people would be like if there were no distractions, and no flies, and. no sudden homicides, no falling asleep in the middle of your sentences, all of that stuff. So the distinction here is competence versus performance. We're imagining a speaker who's kind of like a frictionless plane, that there are various kinds of complications, and there's no air resistance or whatever else. That's the study of what people actually do. And we want to study that, sure, but we're going to develop a theory of competence on the theory that it'll be simpler. There is no bound on the length of English sentences. For any sentence in English, it's always possible to create a longer sentence. You can always say, "She thinks that S," where she maybe refers to different people in every clause. When we say it that way, you can tell that I am talking about competence because no matter how long you say it, it can keep going arbitrarily long. It's a possible sentence of English. "Mary thinks that John thinks that it's raining" is a possible English sentence. many recordings of English speakers you go through, you will never find an infinitely long sentence. Nobody actually says these things. But the reason nobody says an endlessly long sentence, the idea is going to be, it's a fact about life. And we don't care about life in this class. We're not going to try to find out what's the longest sentence anybody ever uttered and try to get that fact to be a fact that we want our grammar of English, our theory of the possible sentences of English to be. begin doing some syntax? Here's the sentence, "I will find the red book." grammatical sentence. It's clear what it means, although we've just said it doesn't matter whether it means anything. I said early on we're going to want to have a way of saying which parts of this sentence were put together as units, like with "unlockable" We wanted to be able to say "unLockable" is ambiguous because it can consist of a unit "unlocked" to which you've added "-able" will find the red book" for example, we'll see that syntax treats that string, "The red book," as a unit. There are various phenomena that care about that. One of them is what's sometimes called topicalization. For me at least, it's easiest to say things like that if I follow it up with "The blue book, I will leave right where it is" It is OK to use "the red books" as a possible answer to a question. This is like the stuff we were talking about earlier. saying before about things you can say if you're astonished. You can say "the red book" as, basically, a sentence under the right circumstances. So I can rearrange the words of the sentence in a way such that there is a word, "is" before that string "thered book" It puts a special kind of emphasis on " the red book." It's called clefting. Contrast that with-- so this is not just a test. Yeah, this is atest. a property of every three-word string in the sentence. So "find the red," for example, is not a constituent. It's not a phrase. So you cannot say things like " find the red I will book." So "the red book, I will find," "the blue book,. I will leave where it is," fine. But "find. the red, leave the blue I will pencils." No. Can't do this with just any random three- word string. Yeah? AUDIENCE: What color do I need to find? NORVIN RICHARDS: "Find the red" Really? Oh, I see. You mean "What color book do Ineed to find?" RICHARD: "The red book" Yes. But yeah, I take your point about-- to the extent that you can use "the red" But if I tell you that I will find the red book and you're amazed, you're not going to say, "FindThe red?" I think. "Find the red" is an acceptable answer to a question that you're finding this-- suppose you have this fictional-- this children's game where there's a bunch of little tiles. So we have some cases where we have things that you certainly-- should be adjectives, that either we're getting to use them as nouns, or we're using them as adjectives. It's kind of the same thing-- "land of the free," "home of the brave," NORVIN RICHARDS: Oh. or we're getting to modify nouns that you can't hear, however we want to talk about that. So all this slide is meant to convince you of is that "the red book" and "find the red" don't have the same status. "The red book," we want it to be a substring that has certain privileges, can be used for these various types of phenomena, as opposed to " find the red," which can't do those things with. So it isn't just these are phenomena that pick out three-words substrings. It's these areÂ phenomenonÂ that pick out certain substrings and not others. as with "unlockable" we were taking pairs of things and putting them together to form larger things, larger units. We'll do the same thing here, only with words. And similarly here, what we're going to do to create a sentence like "I will find the red book," we'll start with just the end of it. And then we'll take that unit that we've created by putting together "red" and "book" and we'll put that together with this word, "the" things and putting them together in pairs to create these larger and larger structures. We're going to do the same thing to create sentences out of words. This way of talking about it has the virtue of giving us a vocabulary for talking about those kinds of observations we were making on the last two slides. When we say "the red book" is a unit that various things get to apply to, things like what I called topicalization where you take a chunk of the sentence and put it at the beginning, and it has some kind of emphasis. a unit that we created in the course of putting things together in pairs that is just "the red book" it's the unit that I've circled there. Do people see that in this tree? So there's a node in the tree, if you want. It's the one that I circled in red that consists just of the words "thered book" But there is no thing that I could circle that would consist just of "find the red" There are other things I couldcircle. the red." And that's what we're going to relate to all those observations we made on those two slides. When we were doing morphology, we were using this operation, we called it merge, that assembled pairs of things and created new things. So when you put together "un-" number one, and "lock," it's part of the specification of un- number one that when you combine it with a verb, what you get is a verb. So the tree on the left there, "lock" is labeled as a noun. verb, and "unlock" is also labeled as a verb. People see that. When you combine that verb "unlocked" with a "-able," it's a property of "-able" that it merges with verbs and the thing that you create as a result is an adjective. This is what we were doing with labels before. We're going to want to do something similar for syntax. What kinds of labels are we going to use? Well, look, I just gave you all these diagnostics to try to convince you. that have all of those properties. So if I said, "I will find red books," well, you'd be able to topicalized "red books" Or "redBooks I will find." "Books?" You're amazed. So "books" by itself is apparently a unit of the same kind. "Those red books about linguistics," that's a unit a similar kind. You can say "ThoseRed books About Linguistics, I will Find" Yes, so that'm a unit we want to be can to make reference to. the fact that it contains a noun. So when we put together "red" and "book," what we get has properties that are determined by the fact that they contain a noun; if there were no noun, it wouldn't have those properties. Similarly, with "the red book," the things that can go in that slot, there are various kinds of things that are larger or smaller. What they all contain is a noun, so we're going to name that thing after those kinds of units. We'll give it the label "noun" "Find the red book" is also a constituent, also a unit that we're going to want syntax to be able to make reference to. The important part for this part is the verb, the part that determines that that's the kind of phrase that can go in that position. "I said I would leave," and then "leave" has all the properties we just ran through. "Leave" is a unit of the same kind as "find the red Book" Or "I will leave" and you're amazed. You can say, "Leave?" is that it contains a noun. "Find the red book" we're going to give that the label verb, because having a verb is the important part for that. "In the garage" is a unit, it's a constituent. It's a phrase. And again, if I say, "I will find the book in the garage," and you're amazed, you can say "in the garage?" If I want to, I can topicalize "inTheGarage" just contain a preposition, like, "I will look up," where, again, you can say, "Up?" (Why will you look up?) "I said I would look up, and up I will look"-- Maybe. Adverb is a funny word because there are a lot of things that can be used. If by adverb, we mean thing that modifies the verb, there are many ways to use it. It can also be used to describe prepositional phrases, like "I'll leave in a chariot" "the day after tomorrow" sure looks like a noun phrase. It's got a noun in it, "day," and then "the" before that, but we know that can go at the beginnings of noun phrases. So there are probably-- so the word "adverb" can be used to cover a bunch of things, including things that we don't have any other word for. And so I think you might be right that this is an adverb in the sense that it modifies the verb. my goal in discussions. There are a bunch of things that look like prepositions that combine in an interesting way with verbs in English and a lot of other Germanic languages. "wake up" is one of those. You can also say, "I will wake up the cats." It's unwise but it's grammatical. But I think "up the cats" is not a prepositional phrase. And "I said I would wake up and up I will wake," I'm not even going to try. don't want to think of "up the cats" as a unit that has the cats as an object. Relatedly, "I will wake up the cat" is OK. "Are you up for lunch?" or " are you down for lunch? They mean the same thing. And so we are learning-- this is why I'm glad I'm not a physicist, yes. If I were a physicist,. then if NASA were to hire me, the spacecraft would have all kinds of problems. up," which is different from "I will walk up the stairs" You cannot say, "I'll walk the stairs up," I think. "Up the cats" is not a prepositional phrase. We need different structures for these verb phrases, and we will develop them. You had a-- AUDIENCE: Yeah. I was I was "up"s are different. You have to say I'll walk up them. "I'm going to walk them up" is no good. If you're taking someone home, you can say, "I will walk you up to your room" You can't say "I'll walk up the student to her room," though. That implies you're walking on the student, which is not the case. "Up" is different from all of these, actually, kind of interestingly. I think maybe "up" is the right word for it. It's like the opposite of "walk" or "walk up" in the same way. modifying "to her room." We want there to be a constituent "up to her room" Notice that if I say, "I will walk her up to her. room" and you're amazed, you can say "Up to. her room?" which suggests that that's a constituent. So it's kind of like, I don't know, an adjective, in some sense, is describing [? state. ?] But at the same time, it's not an adjective. It's describing a verb. a way, waking the cats up, it's a little bit like painting the cats red. And as a result of that, the cats are red. We want "up" to not be a preposition that's combining with the cats. It's like a predicate of some kind, like "red" in. "I will wake up the cats," is a prepositional phrase. "Up" is something else. And possibly also red. It depends on how you did it, I guess. "I will paint the cats red." "I will walk her up to her room" "You can also wake the cats. You shouldn't, but you can" "I can't walk up the student, unless the student is lying down and you're walking on her" "We want "walk the student" up to be different from "wake the cats up," and maybe "maybe" "Wake the cats" is modifying "to her room," but I don't think it doesn't have to, does it? also different from "walk up the stairs." Yeah, it's a third kind of thing, which, as we work further on this, I'm glad that we're running out of time because it means that I have a week to create slides about this. But we're going to want different structures for this. So we've got now three kinds of examples to talk about. There's "wake them up," there's "walk her up," and there's 'walk up them' For "walk up them" we want "up" and "them" to combine to be a propositional phrase. But for these other two, we want something else. We're going to want to circle around and try to find out what that other thing is. Does anybody else-- yeah? AUDIENCE: I was going to suggest something else [INAUDIBLE] Even though you can't say, walk the-- "walk the stairs up to your room." NORVIN RICHARDS: "I walk--" the book in the garage," what we want to do is construct a structure for this that's sensitive to all of the tests for structure that we've been developing. It's going to involve putting things together via pairwise merge and creating labels for the things that we create. The labels we create are typically labels that come from one of the two things we've merged. So when we merged "the book" or "the garage," we're going to create something we're Going to give the label "noun" to. up with a structure like that. Notice that if I say, "I will find the book in the garage," it's OK. That's a unit that topicalization gets to make reference to. So our tests get to tease this out now. Now I'm regretting us being almost out of time because there are many things to say. What we're going to see next is that when we go to the next level, we'll be able to combine things in a different way. construct syntactic trees for strings of words. It's often the case that we get ambiguities like the "unlockable" ambiguity. There is more than one way to combine things. And what we'll do is develop tests that allow us to see which way we've combined words in different ways. And we'll find cases where, depending on in what order you combine things, you get different meanings, and our tests will combine with that. All right. We will do this again on Tuesday.

ROUGE-1: 62.30, ROUGE-2: 59.51, ROUGE-L: 57.09
BERTScore: 75.53

==============================================
==================== [72/100] ====================
Summary:
William Wordsworth along with the next person we talked about Samuel Samuel Taylor Coleridge probably the two of the most influential of this particular era. William Blake from earlier is very important as well. These names that I've been telling you are people that show up on Jeopardy from time to time especially if there's a Romantic era or British literature type thing. It's usually a good stab in the dark if you don't know to kind of throw out one of these names very interesting individual. to Hunts you know I will not go after her any more and she had the necklace around her neck for Caesars I am you know we understood that it was more than just an allusion to Caesar and his pets because we knew a little bit about him here is something else about another person that we have a lot of that in same information about and that's William Wordsworth. Just reading about some of this past you know upbringing and how that influences writing and the piece that we'll read today it's heavily influenced by his past. sister I've never lost a parent um I don't know if anyone has but I would imagine that's a big gap in your life and you may be bond a little bit more with your siblings maybe she being the only female he has a sense of protection for and so being separated you can imagine the struggle that one might have in dealing with it with the loss and so he you know he longed to be with her and such and it wasn't until it said the mid-20 so for you know half of his life up till he's like 12 13 14 when the dad died. You know his passion he developed for poetry for simple country living and for the natural world was to influence him for the rest of his life. So throughout his upbringing even though he was away from his sister at the school he developed this passion for poetry and this observation of nature and such and we will see that played out in the piece today. It's kind of interesting just a little paragraph it has about rebellion in France remember the very first pages of our introduction to this unit was dealing with revolutions it had Industrial Revolution but also the American Revolution and the Napoleonic Wars. degree not like spiritually but worships these ideas he goes and and helps um you know he falls in love with a woman but he becomes broken so he has to take off and go back home and so for years it talks about there that he's feeling a sense of abandonment and loss for leaving the woman that he loved back in France that I can't stay and you keep the cause going any longer because I have to run back home because I'm broke. So he has some of that guilt and some ofThat that pressure and you can see how he teetered that last line there he cheated on you know a nervous breakdown and a collapse. The Rime of the Ancient Mariner for Coleridge was as we'll read here and for the intro for that you know Wordsworth worked with him on that it was going to be a dual credit both of them were going to get credit for it um but Wordsworth had to drop out of that. Some of the most famous elements of the piece still are in there and they're still a focal point so we still see his kind of finger prints on that masterpiece Ã¡willÃ¡ will take care of in the next episode. couple days but just a very famous individual very uh you know emotional a pioneer a visionary at that time and so you know understanding all this stuff about him will help us in our in our you know undertaking via tintern abbey here in a little bit okay you see the literary term enjambment for Wordsworth is key that's a term you probably haven't heard of before this class it's very easy it's more about identifying by looking and you'll see it throughout his piece today. different than the typical every line it's kind of its own little thing and so when it's read in a different way it's it might see a little Jill at times button jamming is something very easy to visually identify a once you understand oh that's in JAMA it's a piece of cake okay but something you haven't done before something you never heard of before it might give you a little bit of reservation here and there but it shouldn't okay what I want to talk about first is a 786 lines composed a few miles above Tintern Abbey on Abbey. the Canterbury Tales where you could go and visit the Canterbury Cathedral like you seriously could go there now tintern abbey still stands okay it is not a practicing monastery any longer it was closed down during the time of Henry the eighth if you recall he had that big religion issue with his you know with Anne Boleyn and so he shut down monasteries. You can see more information about it on the PowerPoint slide but then there are several pictures that you can look at that are really kind of neat um sprinkled throughout now in England. a little bit you know there's one look at you know a grass I think there's no roof on it but imagine what it'd have been like to you know to walk through this when it was a practicing monastery and such what was the like with that big roof on there with the stained glass windows all still in there I mean we don't have much of this here in Fort Wayne you knowthere might be a couple bigger churches sprinkled throughout that are kind of still Gothic influence but you know things like this it's pretty pretty amazing. within the Abbey but it's still some place that you can go in and view and see and I don't know maybe people can still get married there maybe they can have ceremonies I have absolutely no idea but someplace that's so historically relevant and famous Wordsworth's Tintern Abbey very famous and you can going in and to the area that was the motivation for this particular piece it's kind of neat so I like if you canGo to one of the globes and watch a Shakespeare play I mean that's that's time travel guys I really like this picture here. You know this might be some sort of view notice the river winding through he referenced his cottage and the smoke coming out of their chimneys. There's that there's that moment of wow this you could technically time travel to some degree here so just some pictures and stuff that I think it's kind of neat to to to. You know something like that where we are in the vicinity. He's not saying I'm sitting there staring at Tintern Abbey right now but you know this could be probably. look at from time to time so let's go ahead and read it on a 786 follow along with it if the rhythm gets choppy and you start to get lost refocus this is only about eight minutes so it's not a long one but focus on what he is saying about nature. This is probably one of the most difficult readings that we have throughout the semester I don't think it's impossible but you're going to have to you're gonna have to work a little bit ok. can we guess who that might be and why this moment is interesting ok lines composed a few miles above tintern abbey hopefully you found that I know is probably a little bit of a struggle to get through you found some of those those elements of nature and we're going to go through those but who is the individual that surprisingly is he speaking with his sister okay and it's not just oh it's a brother-sister thing fine but we know about his feelings for his sister based on their absence for a decade a decade plus. Five years have passed since he's been there okay five years have been there and it's really interesting because he's still there. You know some places if I die think back to this time. Think back to the love that I have for you but think back of the love I have to nature and all of these these feelings and these memories you know and we will be able to you know be together again kind of what you know in thought and such so the beginning if you look back on the first two pages I'm just going to point out a couple key things. he talks a lot I mean just describing you know leaning against the tree and looking out amongst the field on looking at the orchard with the you know it talks about the all of the which at this season with the unripe fruits are clad in one green hue. "I'm just enjoying this situation this scenery I know if any of you have ever gone on a vacation at some place where it's just visually beautiful you know" he says. "Some people would some Hermits and some cave" just maybe mountains maybe a lake you know just something that's just very calming okay very calming and he almost has kind of a teleportation back to some degree of when he was a child okay he goes into great details about when I found through around the river like a like a row like a deer and I would play and when I was little I was having a great time but when you're a kid playing outside you really appreciate how beautiful it is everything are you just like play play play run run run okay. He says that the memory of the woods and colleges offered tranquil restoration to his mind and even affected him when he was not aware of the memory. While he was away thinking back to this it helped calm him and help restore him. If he mentioned that when I was off in a city whether I was alone or far away or with some people you know I would think back to these place. It brought me a lot of peace it brought meA lot of comfort ok do you remember a certain trip that you took at some point in your life maybe five to ten years ago and. you distinctly remember a visual image have you ever gone back to that same place and like oh yeah this is the place one of my earliest memories was I was like two or three and I went to Disneyland on California I remembered nothing throughout my life except I remember look you know right and the entrance usually there's a big train that goes across and you have to walk underneath it you know well not like under a train but like a tunnel. I just remember that I don't remember sights and sounds and smells but I remember visually what it looked like. in California and watch the train go across and was like this is the same spot I stood when I was three you know and so it's kind of a nice little Wow think about how I've changed in my life think aboutHow I've grown up things that I've experienced you know stresses and things and you can think back to this this for me I didn't look back to Disneyland and think hey that was awesome but you look back at certain things in life and that brings you some calm those are you looking forward to spring break or summer. calm and then when you go there it's enjoyable I like line 61 right around in there it says that the pictures of the mind revives again while here I stand not only with the sense of present pleasure but with pleasing thoughts that in the moment in this moment there is life and food for future years. So you go back to experience that memory and you're there and maybe it's identical to what you thought. Maybe it's a little different but it's almost like you're now you're hitting the record button. steeped in nature and such okay he mentions the river you know meandering through the the trees and through the fourth that's why looking at that picture before we started you know that river is the same river that he was looking upon and quoting and talking about here. To go to that place and visually see that nature that appreciation maybe you could hunt down I don't know if that orchard is still there I want to be kind of cool if through the little you know the little hints here an orchard there's some cottages of smoke the near the river. introduction the child and the common man the innocence of children and such this isn't a story about or poem about children but yet through his childhood memories we are able to make that connection to those passion emotion feelings about nature and and his sister and such. We get to see little elements sprinkle in four motivations you know just lines sprinkled throughout you know therefore am I still a lover of the meadows and the woods and the mounts so he just he keeps going on and I think that if you were to read this through a second time these would pop out a little bit more. a little maybe some of the footnotes you know that's why a second exposure as always is always beneficial yeah we don't know that there's anybody with him okay anybody with them until he says my dear dear sister they're at the bottom of 790 and such let me see here. Even if he did not feel this way about the nature or understand all of the things he would still be in good spirits for this day I wouldStill be happy for what's going on today even if I didn't have those previous four pages. hitting it wasn't now we know it's not just because he wants to record all the beautiful panoramic surround it's recording my time with my sister as well okay and so to see that they can appreciate that you know a few lines in your nature never did betray the heart that loved her nature's power over the mind that seeks her out is such that it renders that mind impaired impervious to evil tongues rash judgments and the sneers of selfish men and instilling instead a cheerful faith that the world is full of blessings. like I said we first started this particular piece talking about it you know that memory if I am dead if I'm gone think back to this time sister if you can't hear my any longer just remember what my feelings are for you. "This is one I probably say the top three or four most difficult pieces not that it's crazy hard but it's just it's a lot more difficult than reading those pulp" "My voice and my spirit will continue because you'll be experiencing all of these things and thinking in the same mind frame that I was thinking"

ROUGE-1: 78.08, ROUGE-2: 76.29, ROUGE-L: 75.28
BERTScore: 73.24

==============================================
==================== [73/100] ====================
Summary:
Professor: We're going to be taking this IV curve that we've so laboriously set up and understood-- sorry about that. And now we will subject it to illumination. So that's the essence of our lecture today, the diode under illumination. And as part of today's lecture, we have some wonderful little kits over there in the corner where we'll actually be testing IV curves of solar cells. So I hope some of you brought the computers today, and if not, we've some extras up here as well we can use. So again, just to situate ourselves. We're here in fundamentals. We're approaching the end of our fundamental section, but we still have a few really important lectures to get through. After we get through the fundamentals, we'll be in a good position to understand the different technologies and finally the cross-cutting themes. And our goal is to, at least for the basics, to understand solar cell conversion efficiency. For most solar cells, this breaks down to the following progression, from the solar spectrum to charge collection. And we're going to be focusing on charge separation, incorporating elements of either side. Photosynthesis is the process of converting sunlight into chemical energy. The total system efficiency in blue is somewhere, depending on the plant, somewhere around 1%, maybe as high as 7% or 8%, depending on very specialized plants. And that, in part, is largely due to optical losses. If you can see the pie chart, the efficiency of each individual part can be broken down to this little pie chart up here. And just like a solar cell, the photosynthesis conversion efficiency of the entire system is dictated by the efficiency. Each of you should have on your desk these sheets. We laboriously filled this out last class. We're just going to refresh ourselves to make sure we're all on the same page and redo it this class right at the beginning because it's that important. For those who are still struggling, let's make sure that you get this sometime between now and, say, the next two weeks because this will feature prominently on the exam. So if you would not mind working directly with your partner, the person who's sitting directly next to you. Let's walk through the diode in the dark. and understand how drift and diffusion currents come into being in the first place and then being able to bias your diode under different conditions is a really important fundamental skill for understanding how a solar cell works. Question. On the forward and reverse bias, does the Fermi energy actually continuous, or does it actually [INAUDIBLE]? PROFESSOR: So the Fermani energy, which we defined here as the chemical potential, notice we're avoiding talking about what's happening here in the middle until a couple of lectures from now. That gets into a gray zone where we talk about quasi-Fermi energies. absolute energy scale. So there is an energy difference when you're driving the electrons from one side to the other. And this is why we have current flow coming from this side into that side. And it's happening because we're using that battery in the dark to change the chemical potential on either side, which, in effect, reduces this barrier height. So you can think about it as forcing carriers up the junction. In a real device, when we you have a two-dimensional device within homogeneities, the current will travel through the weakest point of that pn-junction. let's try to imagine what will happen under illuminated conditions, and let's start out in a very simple case. We'll assume that the principle of superposition applies here, that the photo-excited carriers-- in other words, when light shines into our device-- and light's coming in and generating electron-hole pairs, essentially exciting electrons across the band gap. What will happen to those electrons now that they're in the conduction band? Where will they want to go? To the right. When you start illuminating your solar cell device and you start injecting carriers into it, what will happen is, very naturally, this band alignment that you see right here will begin to shift toward the forward bias condition. To get the solar cell to go into reverse bias, you really do need to bias your device. So that shifts the entire thing down. And we would add illumination current, an arrow pointing to the right right here, which would mean that we would have current flowing through our device, but there's still no difference in the chemical potential on either side. in the p-type and the n-type, which means our voltage is equal to 0. So it's really just a superposition. OK. Now what happens if we forward bias our device either because we're adding a resistor in series to our solar cell? So instead of a battery there, you would replace that with a resistor. Or if we're applying a bias voltage as well, we could also do that under illumination. So we'd still have the illumination current, right? And we, through superposition, shift this entire curve down, we'd be operating somewhere in this quadrant. battery there, we have a resistor, the electrons will travel from the n-type material through that external load. And so this entire curve shifts down. You have your red x somewhere in the quadrant over here. And power is flowing out of the solar cell across that External load. So in the next slide, pretty much everything is right, except that, mea culpa, I forgot to replace the battery up there with a little resistor. So you'll want to correct that in your notes. replace those with resistors or a resistor in series with a battery, if you prefer. Since depending on the illumination condition, the intensity we may have natural for a bias condition, we may need to apply a bias voltage. OK. So we have our IV characteristic like this. We have our red x under forward bias conditions in the IV quadrant, denoting that power would be flowing out of this solar cell device under these conditions. And now the bias is inverted. And notice that the current still has the same sign. device in the dark. But under illumination, now we have all of our carriers traveling from the p-type into the n-type. What's varying is the potential that the carriers have and, of course, the total amount of current. Eventually at some point, if you keep forward biasing here, the current will be 0. There will be no net current flow because there'll be no driving force for the carriers to go from the P-type to the N-Type. The voltage is such that we can power an external load. We have charge separation. The electrons are accumulated over here. And they have higher potential than they do on the other side. So the conditions are just right under illuminated forward bias conditions to drive power through our external Load. Under all other conditions of operations of the solar cell, we're putting power into the device, not getting power out of it. This IV quadrant over here, this forward bias illuminated case is the only case in which power is coming. with a superposition, which we call the illumination current, I sub L. And that's what shifts our entire curve down by this. What do we think will happen if our light intensity goes down by a factor of 2? So now if the amount of sunlight falling on our solar cell drops by 1/2, what will happen? And what do we predict will happen based on this right here? AUDIENCE: [INAUDIBLE]. PROFESSOR: The curve will shift, the red curve willShift up by about 1/1. be cut by whatever this would be here, a log of 2. So OK. So we're beginning to develop an intuitive understanding of where electrons are flowing inside of our solar cells. In the dark is important because we can test our devices in the dark, and we can still learn a lot about our solar cell device characteristics. As well, we can force carriers from one side of the junction to the other the wrong way and probe for weaknesses in the pn-junction regions. That's helpful. So what I'll ask folks to do now is to-- we'll begin passing around these little tools. David Berney Needleman is our lab guru. He's the one who helped build these, really was the driving force behind getting them built. These are IV testers that will allow you to measure the current voltage characteristics of solar cells. And he's going to-- well, we'll pass them out while maybe he comes to the front here and explains how they work. So modify the intensity of the light and see how this works. IV curve changes. Note the y-axis scale, which might change as well. It might rescale depending on the condition. Give that a shot. All right, folks. Why don't we circle back real quick. I am very much in favor of multitasking and browsing. So if you want to keep your experiment running over the course of the remainder of the lecture, I will certainly have nothing opposed to testing a few different illumination conditions. The I sub L, just to really recap here, we have this ideal diode equation, the illumination current coming in from our light source. see there? AUDIENCE: One. PROFESSOR: How many batteries do you see total in our set-up? Look especially at that light source. There's a 9-volt and a 1.5-volt. So one of them is powering the light source, and we have, as well, bias to the solar cell device, right? So we have a bit of a combination of the last two slides,right? In this case, in the dark, we were biasing our solar cell using the battery. And in the illumination conditions, the light itself was causing the solarcell to become forward biased. don't understand still why having a load would bias the device. Professor: It's more energetically favorable for these electrons to be on the other side. It's difficult for them to get back the other way. It could be more easy for people to get to the other end of the line, but it's not impossible, he says. "It's raised the chemical potential of this side," he says of the device's illumination. "I think that's a good thing," he adds, "because it means that the device is not biased." them to flow through an external circuit to get back to the other side. The biasing is because you have a shift in the chemical potential of this side up relative to the p-type side. That's a bias. And is the biasing because there is a voltage drop across the resistor? PROFESSOR: Yes. And as they flow through that external circuit, they're depositing their energy across that External Circuit. What energy? Well, it's the potential difference from this side to that side. your solar cell, you have a bias. Whether that's generated by light or a battery, that's a matter of detail. Photons are forward biasing the device. Can some ever reverse bias? That would be very difficult. What you could do, though, is have a bunch of solar cells connected in series with this one, right, that are producing forward power. You could shade this device, and then power it from the sun, for example. It's just photons. could be flowing backward through it, right? And you could be in a reverse bias condition just because of the way the other solar cells around it are behaving. So imagine a seagull lands and kind of covers up one of the cells. That will be under reverse bias, and that could present problems if the solar cell can't withstand the reverse bias. No, this is a very ideal condition. In the real world, you'll just have biased it so much that electrons will be able to tunnel through from the p-type into the n-type right here. what happens to this IV curve is it goes zoom, begins dropping. If the solar cell reverse bias. current, or the current at reverse bias voltage, is not low enough, you could have a catastrophic failure of your module by just shading one of your cells. Thankfully, this is one of the testings that are done with the solar simulator to prevent that failure mode. All right. I'll try to keep the lecture focused on the broader general topics. But if somebody is interested in learning more, I'm happy to kind of dive into there. far, and really tried to impart the wisdom of pn-junctions. You should be able to explain to your roommates exactly what is going on. Define parameters that determine solar cell efficiency. So now we have a qualitative sense about where current is flowing, where electrons are moving around, what defines the power output. Let's start putting some discrete variables to all of that. And there are a bunch of two-letter or three-letter acronyms with some subscripts here that we'll get to know. Most often, PV researchers will report a current density, in other words, a current per unit area instead of the actual current coming out of a solar cell device. So what you've been measuring here off of the DAC has been current, total current output from that device. We'll use current density J, and we'll call current I, right? So for calculating power, we'll have to use I. And that's essentially the ideal diode equation with a superposition term, this J sub L right there. There's no energy gain of the electron traveling through the external circuit, but there's a maximum current. And no power flowing through that external circuit because there's no potential to be dropped across the external resistor. The opposite happens over here at this point called Voc, which we'll call open-circuit voltage. That's the maximum voltage that could be supported by that solar cell device under illumination conditions. And somewhere in between these two extreme conditions, you have a maximum power point where there is a power being deposited on external load. a lot of it, right? That's the maximum power point. This is the point at which the solar cell is producing the maximum amount of power output. If I were to take current times voltage right here using IV quadrant data, my power would be a negative number. So I'd multiply a positive and negative number together, you get anegative number, and that just sounds weird. It almost sounds like power's going into the device. So this is another convention that you're going to have to get used to is looking at the IV curve in the I quadrant. have the right load. So the two need to be matched to each other. And that's where some of the power electronics come into play. And the rationale for that assumption is as follows. The open-circuit voltage, this point, is generally between 0.35 and 0.4 volts minus the band gap, or lower than theBand gap. So you have the band. So it's a very interesting question. Let me repeat it so that the microphone can hear it. The homework question in the last homework, there was one question that inquired. gap energy minus 0.4 volts. It essentially has to do, in part, with losses inside of the solar cell at thermodynamic limits of conversion. Then what we've done is we'vedone another additional discounting from the Voc to the maximum power point, which we've assumed is around 0.1, maybe 0.2 volts. Notice the shape of the IV curve right here. The maximum powerpoint is interesting because the voltage at the maximumpower point is almost the Voc, in a good device. And the current at themaximumpowerpoint is almost Jsc, but not quite. good device. In a bad device, this maximum power point here could be dragged all way down here. You could have an IV curve that looked something more like this instead, almost like a resistor, at which point the maximum power output would be a lot less. So we have efficiency here as well as the efficiency of the solar cell. Eta, this Greek letter eta, is our power out versus power in. Our power in is the illumination intensity given in units of watts per meter squared. power out versus power in, the power out being the maximum power point power and the power in being the illumination from the sun. OK. This is starting to get interesting because it's beginning to click. Pieces from lecture number 2 come together with what we're seeing now. So this is solar cell output power at themaximum power point and sunlight coming in. And that box looks like this blue one right here. The area of that is the area of the solar cell that is producing power. box is Jmp times Vmp. OK? And notice I have another box around here. I have this clear box that starts at the Voc point and the Jsc point. And now I have two rectilinear shapes, this blue one and the clear one right here, the bigger one. The bigger one has an area of Jsc times Voc. And I'm going to define a parameter called fill factor, which will be the ratio of these two areas. If this is 1, which is virtually impossible to do, but if this were 1, it would mean that these two boxes were the same size. point divided by the solar insulation, fill factor being defined as the ratio of Vmp Imp product divided by Voc Ioc product. These parameters right here are fairly easy to measure using the solar simulator that you just put together. And so from an engineering point of view, when we break the solar cell output down into these three parameters so that we can better understand what's going wrong with our solar cell, we can get a better idea of what's wrong with the device, the professor says. The conversion efficiency determines the area of solar cells needed to produce a certain peak power. Many costs scale with area, including glass, encapsulants, the absorbent materials within the solar cell devices. The aluminum and racking and framing materials that go into holding the panels up in the field either on a roof or out of the field. So efficiency affects pretty much everything but the inverter and possibly some of the soft costs of the project. The material costs might end up whopping you, but it might not. pay more for a high-efficiency cell because I'm using less area, you can use this type of calculation to get to the answer quickly. This is a really back-of-the-envelope envelope engineering approach to estimating costs of a solar system. So I think this is a great place to stop. And if anybody has an idea, a fun idea, for a class project, I'd invite you to give a pitch up here at the front of class, or you're welcome to send it on an email to the class listserv.

ROUGE-1: 53.84, ROUGE-2: 51.39, ROUGE-L: 50.53
BERTScore: 74.19

==============================================
==================== [74/100] ====================
Summary:
The world woke up this morning to Global chaos massive Tech outages are impacting Airlines businesses offices thousands of flights grounded globally long cues frustrated passengers there was nothing on the boards there were nothing there's no G staff in the UK doctor surgery is forced to let down patients we going to have to cancel your appointment businesses unable to serve customers we'll try to receive a credit card payment and just would not accept it credit card and debit card and TV programs abruptly taken off air the cause at crowd strike we monitor trillions of cyber events. A faulty update meant millions of Microsoft users saw this screen pop up. The blue screen of death pops up when there's a critical error affecting the operation of your PC. Every single machine affected needs a manual reboot in safe mode which is not as simple as turning it off and on again. Some people have had to do it 15 times so it could take a while spare a thought for it departments there will be someone In Crowd strike who will be in a lot of trouble right now for not getting this right. The firm behind the outage crowd strike has held up its hands but admitted that it'll take time for things to get back to normal. Thousands of flights cancelled around the world at UK airports there have been huge cues and delays all on.still advises that it's a good idea to keep on top of software updates although perhaps today is not the day to bang that particular drum Zoe kimman BBC News as we heard the firm behindThe outage crowd Strike hasheld up itshands but admits that it will take time to get things back tonormal. Emma vardi is outside their Headquarters in Austin Texas. Passengers should have been on planes were forced to wait out delays so people are tired they've been handing out water the boards don't really say anything so it tells you where to go but there's no departure. Many airlines found themselves unable to use their normal systems we've had to revert back to pen and paper basically and manually check each of our customers in of course that takes longer for our customers so we've seen a good operation but it's a slower operation. from chaos at Amsterdam to planes stuck on the ground at Newar in the US cancellations and delays spread around the world Edinburgh stopped accepting incoming flights. Disruption on what was set to be the busiest day for UK flights since before the pandemic will take time to sort out. GP practices in England and Northern Ireland that have been most affected with doctors struggling to access their records and online bookings. Pharmacy Services have also been hit here's our health editor H Pim so I am at the minute doing life is usually hectic at GP practices but a lot more so today most in England had no access to electronic patient records frustrating for doctors and patients. At some health centers only the sickest patients were being seen with other appointments cancelled. Only written prescriptions are available with pharmacists warning patients the electronic system has failed anybody who's coming in for their prescriptions. "We have to tell them to go away uh go to back to the surgery and then get a the oldfashioned fp10 uh which is the old green prescriptions," says one pharmacist. "I can't get my sick note um updated and unfortunately I was about to be sanctioned by the um Social Security office" GPS is monitoring developments across the health system. There's a genuine glitch that's affected systems right across the world and is having a particular impact on GP practices and Pharmacy. We're working with colleagues across government to get things back up and working as quickly as possible hospitals say urgent and Emergency Care has not been affected and if people have got appointments booked they should come in as normal but no one's denying that there has been an impact on some routine day-to-day activities at NHS trusts. This just goes to show how dependent we are on it and how vulnerable we are I think it really highlights the fragility of our digital lives. There are some calls for people saying actually we shouldn't be so reliant on on a few big companies for everything. Other people are saying well actually if we have lots of smaller companies doing this stuff then are we leaving ourselves more open to vulnerabilities to weaknesses to attack so it is a real dilemma I think but nobody has seen anything of this size.

ROUGE-1: 56.72, ROUGE-2: 53.84, ROUGE-L: 52.16
BERTScore: 66.18

==============================================
==================== [75/100] ====================
Summary:
In the year 2000, four-year college grads actually earned more with their entry jobs than they're earning today. Having a college degree means you have a much lower chance of unemployment than if you don't finish college at all. But overall, what we see is a lot of waste of talent, of human capital -- people who finish college degrees but don't have the right skills to get the jobs they want. In the year 1970, only 1 out of 100 taxi drivers had a college degrees. These days it's about 15 out of100. the best jobs. So there's good and bad news from the labor market. How do we think about what's been driving it? Well, we should go back to the core economic concepts. That is, the supply and demand for labor. To think about how those supplies and demands have changed, let's start with the factor of technology. Technologies have changed. And this will affect both the supply of labor and the demand of different types of jobs. It's not just manufacturing, it's also information technology. Kinds of labor. Well, skilled labor -- working with computers -- is much more powerful. The computer enhances the productivity of the skilled laborer. And information technology makes it possible for skilled labor to sell their products around the entire world. At the same time, with information technology, that can be pretty hard to learn. So changing technology has made wages rise more at the top, but has held wages down for a lot of other jobs. And new college graduates are experiencing that when they go into the labor market. -- you can sell to, and this means the value of your labor, and thus your wages, will be higher. If you don't have a special skill, you might find your job prospects aren't doing so well. A third set of factors has to do with slower economic growth, slower productivity growth and slower dynamism in the American economy. For instance, the number of start-ups in the U.S. has been declining each decade since the 1980s. That means there are fewer new jobs. When productivity growth is low, dynamism is lower, there is less turnover in jobs. Over a quarter of the jobs in the U.S. require this kind of legal permission, often coming from a state or local government. It may make sense for some jobs, but should it really be the case that you need a legal license to be a new labor worker? The answer is probably not, but it's a good idea to be aware of what you're doing and how to do it. The Great Recession hit the U.S. economy hard in 2008. People who start working during bad economic times are slower to climb the ladder of success. The cost of getting a license to be a.barber, or to be an interior decorator? That increases the cost of entering those sectors, it means a lot of time and some money, to get the license. It's good for the incumbents, who face less competition, but it's bad for people starting off in the labor market. Finishing college is a great idea, but these days it's no longer enough. What really matters is how much value you can produce for an employer. Take a look at the relative wages of, say, engineering majors versus psychology or communications majors. In today's world, the momentum is moving toward people who are trained, says David Frum, president of The Frum Group. The labor market is more about skills than ever before, Frum says, and this has led to a persistent effect on American labor. in information technology, who work well with computers and who can exploit growing global markets. When supply and demand are ruling labor markets, the people who do well are those who have an economic understanding of where is demand high, and where is supply scarce. Check out our practice questions to test your money skills. Next up, we'll show you where to find data to help you decide which career to choose. We'll also show you how to get the most out of your college degree, including how to apply your knowledge to the real world.

ROUGE-1: 68.28, ROUGE-2: 60.05, ROUGE-L: 54.96
BERTScore: 75.57

==============================================
==================== [76/100] ====================
Summary:
So, the first we learned rationality, rationality axioms - completeness, reflexivity and transitivity. And when our when someoneâ€™s preference exhibit these three properties, what does it mean that he is able to completely rank all his choices all his potential choices, with also possibility, with possibility that there are more than one bundle at some ranks this is a possibility. One thing also I should add that he will be able to rank only if he has finite consumption set and also what we have learned that this will translate into a utility function. consumption good, fine. Next we add I am not saying just continuity implies this, but continuity in addition to earlier three axioms that we have learned, continuity. And what do we get? What we get is continuous utility function and now we do not have to impose the restriction that our consumption set is the consumption set of this individual is finite. What else, what does it mean continuity? No, break indifference curve, can I say that, no break in the indifference curve would be continuous. non-satiation, but let us take example of your monotonicity, monotonicism, and what would it imply? In other words, let us say that is clear that, that is through definition, but it if we translate it into indifference map what we will get that the indifference curve has to be a downward-sloping curve. So, from here we learned that indifference curve have to be downward sloping. What else? Anything else themonotonicity would tell us? indifference curve has to be very thin, fine, it is clear. And now we have convexity plus conveXity. Let us say a personâ€™s preference satisfies all the other axioms, and I draw let us say this is his indifference curve. Can I say it is bowed out? As opposed to this what you here, if convexy is not satisfied you get something like this. So, what we will do we will start talking about mathematical problems, optimization, and all.

ROUGE-1: 44.90, ROUGE-2: 43.33, ROUGE-L: 44.76
BERTScore: 79.80

==============================================
==================== [77/100] ====================
Summary:
If you have a complex polyhedron, we found general unfoldings. We proved one of them. For non-convex polyhedra, we know this is too much to hope for. Even if it's topologically convex, there's not always an edge unfolding. That was the tetrahedral Witch's Hat. But for general unfolding, we don't know. So today's lecture is actually mostly about these two open problems and different variations of it that we know how to solve. model. At the end, there'll also be some stuff about the reverse direction folding, but mostly, it will be about unfolding. There's a third kind of unfolding which we call vertex unfolding, and it's kind of like a hinged dissection. You're only allowed to cut on edges. And in fact, we will cut on all the edges because that'll be the most flexible. Every edge gets cut, but you're going to leave intact certain vertices to make one. Every connected triangulated manifold -- this is a very general result. It actually holds in any dimension. So this works both for convex and for non-convex. The only catch is that every face has to be a triangle. We've even implemented this algorithm here. A bunch of random points on a sphere. So you get this nice chain of triangles, don't intersect each other, and this will fold up into that 3D polyhedron on the left. Here's some bigger examples, hundreds of vertices. Amazing. It's an open problem for something like a cube where you actually have quadrilateral faces. So the way we prove this is to construct what we call a facet-path. This is a path that alternates between visiting faces, triangles, and vertices. It should visit every facet, every triangle, exactly once. Vertices you can visit multiple times, although I think it's a bad idea to visit the same vertices twice in a row. Other than that, you can visiting a vertex more than once. than once. Once you have this facet-path, you're basically golden because you can lay it out without overlap. So if you have a triangle and you have some corners of it that are hinged to adjacent triangles, you can rotate that triangle 'til it fits in a vertical slab. And the hinges are on the ends of the slab, so each triangle lives in its own slab. Slabs don't intersect. No intersection. The hard part is really getting this path. It's a little bit nontrivial with obtuse triangles. They don't necessarily just lie along the horizontal line. to work for discs just as well. It should work for anything that's connected. So ideally, I cut it all apart into lots of little triangles, but it has to stay connected. Why not? So I can add some cuts until I get down to a spanning tree of the faces. OK. For whatever reason, this is the triangulation I chose, andThis is the unfolding I chose. But just keep cutting edges until cutting an edge would cause it to disconnect. So the maximal set of cuts, there are many ways to do it. going to cut this up into a facet-path. Instead of being given a polyhedron, we're given a disc like this, a triangulated disc, and we have to deal with it. We're going to visit every triangle exactly once, and passing through vertices. Distances don't matter. It's just topology. You could think of it as a circle with some decomposition into triangles, if you like, but that's maybe harder to think about. In a triangulated polygon, we usually call them ears. These are leaves and in that tree which call the dual tree. So cut edges until you can't anymore, so until cutting would disconnect. So this means what you're left with will be sort of a tree of faces. There'll be no cycles because if there was a cycle, you could cut one of the edges, and it wouldn't fall apart. So obviously, there's a tree here. Now, trees have leaves. That's our favorite lemma lately. original thing, we think of this triangle as being an ear, and this triangle is an ear. Now, the next step is to color what are called the second-level ears. I'll call them the remaining ears, if you remove those ears, what would, then, become an ear? All right. Yeah, that's kind of yellowish. So this would become an ears. And I'm going to stop there, just two levels. What could I get in this process? I mean what it looks like I'm getting is I get an ear and a triangle. then, a second-level ear. It could be a little more general than that. Maybe, for example, if I had a triangle like this, both of these would be first-level ears, and then, this would become a second level ear. That's it. Unless there's only four pieces left. Right? PROFESSOR: Sorry, what do you mean? AUDIENCE: You could have three ears. PROFessor: You can have three years. would only happen at the very end. But yeah, this could be first-level ears, and this is the second-level ear. Good point. Most of the time, we will either get something like this, the rest of the polygons over here. This is, most of thetime, what you'll get in the base case of this induction. I'm going to pluck off these ears and keep making the thing smaller. At the end, there are a few cases to think about. picture, or if you just have two maybe. Well, I guess-- Yeah, because then, these are both first-level ears. It doesn't look quite the same. Or maybe just a Mickey Mouse because those are all-- Well, it probably works. But for these cases, I just need to check that I can find a facet-path. So for example, this one,I just visit the triangle. This one-- I don't know-- I do it like that. In fact, I can make it a cycle if I want to go crazy. This is actually the base case, if you will. So in general, I just pluck off two or three triangles, repeat until I get one of the base cases. So imagine those guys as being done. I'm left with these four triangles, actually, a little boring because I don't get the Mickey Mouse case. But then, this will be an ear. This will be a second-level ear. And so I'll end up doing this. And this is an ear, and this will Be an Ear. even attached to these cycles, so it's kind of a problem. That's step five is we're going to fix all the problems. Connect cycles together. So that's a local change, and now, it will be one big cycle. We've probably seen this trick once or twice before, I think in the Mountain Valley assignment stuff. So, that'd be a great title. That would be a good title for a book. It would be called, Connecting Cycles. here I have, for example, these two triangles, which are adjacent, but the paths don't meet. So I'm preserving, at all times, that I'm a facet path, and I'm merging components. So by the end, I'll have one big component. Now, I have a facet-path for a triangulated cube. Actually, it's probably the top one, something like that, might be. I may not have matched exactly what's in the textbook. it can connect to other things. That will cause you make two vertices of odd degree. But that's OK because there's still an Euler path that starts at one of the vertices and visits all the other edges. And I just need a path. You can actually characterize when you get a cycle. It's when the original thing is not too colorable, I think. Anyway, that's vertex unfolding. I think we solved most of it in like an afternoon. We had this idea, and then, we solved it kind of quickly. natural version is to think about what we were originally trying to attack, convex polyhedra. This turned out to not require convexity. But what about convexpolyhedra, not triangulated? Is there always a vertex unfolding? We don't know about edge unfoldings. And the answer is no. Well, no that's not right. Sorry. The answer is we don'tknow. What's annoying about this example is that there's no facet-path. So there are two things that could go wrong. can't-- let's say if your two hinges were here and here, if that's where you attach two adjacent pieces, you can't fit that in a vertical strip. So also this layout problem doesn't work if you have something more than triangles. It's even open for non-convex. At the very least, you need to forbid faces having holes. If you remember this example, the box on a box, this also doesn't have a vertex unfolding because still, this guy has to fit in that little square hole. An orthogonal polyhedron is one where all the faces are perpendicular to one of the three coordinate axes. Google SketchUp makes it really easy, and you can add shadows and texture. There are three kinds of faces. There's the ones perpendicular to x, like these guys. And there's the one perpendicular to y. That's all the yellow faces. And then there are the ones parallel to z. So we call them x- faces, y-faces, z-faces. if you can voxelize it. So this is really a lot of stuff. I would love to generalize this approach arbitrary polyhedra, but that's the big open question. So what do we do? Well, we're going to single out, from this color coding, the y-faces. Just color them yellow. Then, there's all the other faces. Well, they form bands. They're cycles. They go around in a loop. A lot of them here, I've just drawn as rectangular loops, but in general, all those wooden faces, the x and z-faces, will form a bunch of loops. out here, and then, it has two children. There will be some front children and some back children. You pick some root arbitrarily and then you have children going off of there. Now, if you're orthogonal polyhedron has genus 0-- it's topologically a sphere-- this will be a tree. If it's like a doughnut, it will have a cycle. So we're going to exploit that that dual drawing, how the bands are connected together, is like a dual drawing. tree. A band is a cycle of x and z-faces, and they are connected together in a tree. The challenge, I guess you could say, is avoiding overlap. It's how do you piece those bands together and then, have room for the yellow faces to attach on the sides, no overlap? But it can be done with the awesome, crazy idea that we'll get to shortly. But it's going to start out kind of like a depth-first traversal of this tree. of innocent, but the general approach is always proceed rightward in the unfolding. So the unfolding will look something like this. We start here, and we might go up and down, but we never go left. And then, that's going to be all the band faces. All the band stuff will be connected like that, and then, there'sGoing to be yellow faces that can just hang off the sides. So these are the y-faces. As long as I get the band to do this, y- faces can hang up and. down. It's not going to intersect anybody. but I could not turn right again. I have to turn left next. I can actually do two left turns in a row. As long as I adhere to those rules, I'm fine. We're going to subdivide into a lot of little pieces, an exponential number of pieces, so this is kind of hard core. So here is one example. This is a leaf. So trees have leaves, and at the end, we're Going to have to visit a Leaf. So this is one box. There's this funny view. you can see like a mirror on the bottom. And our parent tells us you have to start at s, and it says you better finish at t. And I want the property that if initially, I think, initially, you're going right. No, it looks like initially,you're going up. It matters. You can do stuff, and then, at the end, you should still be facing up. And normally, that would be hard to do. If you just tried to visit one. face at a time, you can't do that, but if you visit faces multiple times and kind of weave around in a clever way, you could do it. In fact, I basically just zigzagged. So I start at s. I go up. I turn right. Now, I better turn left. I going down over here, up there. I turned left. Then, I turned right. So if you follow along here, I just turn right here. So now, I go down here. work if it was rotated 90 degrees. It's really powerful. It also works if t is on the other side of s. You could do sort of the mirror image traversal. Now, obviously, I didn't cover the entire surface. I'm leaving room for later, but if this was all I was going to do, I would actually sort of fill out all those strips, just kind of extend them. It just makes this kind of fatter. So this got a little bigger. I've got the first half and then, the second half. This is really glued up there. also, in this case here, we're imagining-- oh, this is actually two of them. Two of these strips joined together. They just attach up and down. They're not going to intersect anything because this is not actually below this. This is way over here. So that's the leaves, and I still haven't gotten to the exciting part. So imagine you have a band. Just going to represent that by this big rectangle, and it has a bunch of children. Remember, it can have front children. And it could have back children up in the y-coordinate. Don't have to think about whether it turned, don't want to have to depend on that. Initially, you must be facing up. And I could handle two right turns, as long as the next thing I did was a left. So I come into this thing saying, look, you're facing-- this is facing down. Now, you better turn left next, and by the end, I still want to be facing down again. And here, I'm wrapping around to here because this is actually a band that cycles around. You just have to slightly switch your orientation, but again, preserve that you're doing left-left-right-right. You tell each of the children which way you're initially going, and they can deal with it. It's just a little hard to see because I'm drawing it on a flat surface. But if it was on a ring, it would be much clearer. Just going left and right and left andright, alternating direction. At some point, I get to here. I loop around. I make a little wiggle at some point. the lavender edge is at t10. Now what? We want to come back here, and I'm not allowed to sort of intersect myself. That would be the paper going into two parts of this unfolding, so that's not good. But I have all this space, so natural thing is to just wander from there back down to here, using up the space. So it's going to look like this. Everything that you did, you just undo. At every level of the tree, you're going to double what was below you. So this recursive thing from this structure ends up getting doubled. At the parent structure, it will also get doubled. that's why you get exponential, in general. On the other hand, if your tree happens to be nice and balanced, doubling is not so bad because here you'll have constant. This a double everything below, but there's only log n levels. So is that linear? It should be about linear. It's certainly 2 to the theta log n, and it matters what this constant is. I think it's n or maybe n squared, but not too bad. So if you're lucky and the just the structure of your tree. of your bands is balanced, it's good. Exponential number cuts is a lot, but it works. You can unfold every orthogonal polyhedron this way. I would love to see an implementation of this algorithm. You could only do it in a computer because you'd be splicing into all these little things, and it would fall apart. Jason? You've been making these, I guess, gadgets [INAUDIBLE] voxel would attach just by a side. You Could imagine it attaching at a corner attaching to multiple sides. I'm not quite sure what you're imagining. Maybe something like that where they share a partial face here? AUDIENCE: Yeah, but it could also be inset into the [INAUDIBLE]. PROFESSOR: If it's inset, I'm cutting with every-- I maybe didn't mention that-- through every vertices. So that will cut into lots of little strips, and then, there's no sort of overlap with the strips. I'm subdividing into little substrips. an edge unfolding of that. Do those exist? These are what we call grid unfoldings. This only makes sense for orthogonal polyhedra. It might be easy. Well, it's not easy. The next best thing you could hope for is to refine. So you take each of the grid rectangles and divide it into k by k, so subgrid. We had lots of examples where those fail, like the cube with little bites taken out of the edges. But grid unfolding, you get lots of subdivision. So ideally, k is one, and you're not subdividing at all. But maybe, you take every rectangle, divide it in half. Maybe that's enough to then be edge unfoldable. That would be sort of a refined level two grid-like unfolding. There are a ton of results about this. They're all partial. But one thing you could do, with merely 5 by 4 refinement, is something called Manhattan Towers. Let me show you a picture of Manhattan Tower. This is more crazy examples of what it's like to visit. staircase. It's, again, to make everything keep going to the right, but here, they find a clever way to visit all the faces without having to revisit, basically, at all, just visiting each face a constant number of times. So here, the floor is a rectangle. That's the only additional requirement, and again, as you slice upwards, things only get smaller. Here's a. Another case looks like this. Boom! AUDIENCE: Woah. Isn't that cool? I'll play it again. The idea of bands came from an old paper in 1998, from the beginning. It's just I have a band, and then, I stack another band on top. So that's a little different. With towers, I could have multiple towers here. I really only want one tower built slab by slab. These things we don't know how to grid unfold. That's an open problem, but if you refine just in z by a factor of 2, that's enough to unfold. So 1 by 2 refinement is enough for orthostacks. is what I have written here. I haven't actually read that paper. What else do I have? Orthotubes. Orthotube is just sort of thickness one orthogonal tube. It could even be closed, I think, in a loop, but here I've shown it open. And here, grid unfolding is enough. You just do all the grid refinement. You could even just do it locally. Technically, there's a slice here that might slice over here, but you don't have to worry about that. other open problems. This was genus 0. Interesting question is can you do genus higher than 0? Orthogonal polyhedra. I would guess so, but I'm not sure. I think the biggest question is, can you make this non-orthogonal? But then, the bands get messy. Haven't been able to do that. All right. I'm going to take a break from unfolding now and switch the other direction of folding. So with folding, we're imagining we're given some polygon, and we'd like to make a polyhedron out of it. It's exactly the reverse of what we've been thinking about. When is this possible? The opposite of cutting is gluing. We'll be more formal about defining gluing, I think, next lecture. But you end up gluing-- I want to make something, let's say-- in fact, we're always going to talk about folding convex polyhedra. There's very little work on the non-convex case, though, there was actually a recent result. I have to be able to draw a picture like this. Question is when do these gluings make a polyhedron? That is the question we will be answering next class. like yet in 3D. In particular, you can compute shortest paths here. I could compute the shortest path from this point to this point you might think is a straight line. But no, it's not. Or maybe it is. A little tricky. So you have to think about it for a while, but it turns out, in polynomial time,. That's cool. What I want to show now is that suppose you could make a convex polyhedron in this This is Cauchy's rigidity theorem. I claim you can only make one, never more than one from the same gluing. So I've defined locally what this thing is. It's like a piece of paper. I can mangle it around. If I want to make something convex, there's only one thing it could possibly make. Finding out what that one thing is is quite a challenge, but at least, we can prove that it's unique. There's a lot of ways to state this theorem, but one way. is to say, suppose you have two convex polyhedra, and suppose they came from the same sort of intrinsic geometry. So there's the geometry of the faces, and there's how they're connected together. Different faces can be different, but they're identical in pairs. That's what we're claiming. Is this one any better? Yeah, it's better. This is an old theorem. You may have heard of Cauchy, famous French mathematician. He proved a lot of things. This theorem he didn't actually prove. Cauchy-Steinitz rigidity theorem is often attributed to both of them. It's sort of a proof by contradiction. We want to prove uniqueness. So we're supposing, well, maybe, there's two polyhedra, p and p prime, and they're combinatory equivalent and have matching faces congruent. And then, I want to slice them with an epsilon sphere, a radius sphere centered at v and v prime. But this is not true if you allow non-convex realizations. In a convex situation, here's what the slice looks like. I get a polygon on the sphere. Convex spherical polygons, convex because the polyhedra are convex. I actually get two of them. One for p, one for p prime. If p and p prime are supposed to be different, then there must be two angles that differ. That's why this is about rigidity. Maybe the convex polyhedron could flex. Maybe it's flexible. Maybe there are two different states. are the same and all the angles at which you join them are the same. There's no flexibility there, but it could be there are pluses and minuses. But if there's going to be a problem with this theorem, there have to be pluses or minuses, that's the proof by contradiction. So we have-- it's a spherical polygon. I'm going to draw it more like a polygon, maybe some pluses, some zeroes, some minuses,. whatever. a sphere. Think of it is as almost flat. What that would mean is there's some other way to draw this thing. Basically, there's a way to flex this linkage so that all of these angles increase and this one stays the same. How could I get a polygon where all of the angles increases and still be convex? Ain't possible. Why is it not possible? I think we've used this fact a couple lectures ago. It's not possible by something called the Cauchy Arm Lemma. And here's the thing. If you have a convex chain but open chain here. There's a missing bar. if you open all the angles in a convex chain, then this distance increases. So I put plus. Some of them could stay the same, but then, this distance will increase, as long as you stay convex. But in this situation, we know that both the initial position in p and its target position in prime are both convex, so the distance can't increase. The edge lengths are fixed. So if they're all pluses and zeroes, or all minuses and zero, the same is. true just viewing p prime as p and p as p prime. So if there's anything in there other than zeroes, there has to be at least one plus, at leastone minus. In particular, there have to be two alternations. Alternation is either going from plus to minus or from minus to plus. So it could be something like plus, plus,plus, minus, minus,. minus,minus, minus. Plus, plus. Whatever. OK? Maybe that's your polygon. Is that possible? Whatever. These angles down here are decreasing. Therefore, this distance decreases. The angles up here are all increasing. Therefore,. this distance increases. Can't have both. So this is also not possible. So in fact, you have to have at least four alternations. It's always even. And so it has to be at least a bunch of pluses, then a bunch. of minuses. Then a bunch more pluses and then more minuses, and so on. might think, well, what happens if there's only three vertices. Well, yeah, you can't have those four alternation because if you have a triangle, even on the sphere, triangles are rigid. So you would know if I had a degree 3 vertices, locally that thing is rigid. It can't flex at all. We're only interested in cases where it might flex locally at a vertex like the pentagon, like a quadrilateral. All right. So what? This was true at every vertices that was not entirely zero. a capital V. We'll get two different answers, but we know they must end up being the same. And then, we'll get a contradiction. The other natural way to count angles is by looking at the faces. It's sort of the dual perspective. Every phase has a bunch of angles that have some degree or whatever. They're really kind of the same thing. Oh, here was Cauchy's Arm Lemma. Beautiful. If you look at the alternations as you walk around a vertex versus as you walked around a face, The labels are on the edges of the graph. They could be zero, plus, or minus. And if I have an alternation from plus to minus, view from the vertex, it's also an alternations as I walk around the face. So instead of counting by walking around all the vertices-- which are just did, and I got at least four at every vertex-- let's do it from the perspective of the faces. And we're in this weird subgraph of plus and minus edges, so assume there are no zeroes. All right. have a face of 2 k or 2 k plus 1 edges, then it will have, at most, 2 k alternations. I'm going to try and prove an upper bound, sandwich it between, and show that, actually, the upper bound is smaller than the lower bound, and that's a contradiction. So this is kind of obvious. Right? If you have 2 k vertices, no more than 2k alternations, slight, the place where we're making a little improvement is for the odd case. The average degree is 5? Slightly under 6, 4, 3, 2, 1? Let's see. Should be like 3 n minus 6 edges, so that should be 3. So most of the faces are going to have low degree. So 3 and 5 really matter, but out here, it doesn't matter so much. This is kind of a magical proof. It shouldn't be intuitive where it came from, but it's really beautiful. You'll see as it all comes together. conveniently relates vertices to faces, but it involves edges. The number of edges is half the sum of the degrees of the vertices. If I look at every face and I count the number of edge, I will end up counting every edge twice, once from each side. So this is half 2-- No, sorry. Not the number faces. What am I doing? Half theSum of the Degrees of the faces. That's handshaking lemma from way back when. is half-- what is the degree of degree 3 faces? 3. What is thedegree of degree 4 faces? 4. And so on. So now, things are starting to look similar, and I want to get some cancellation going on. Use my cheat sheet here. I'm going to rewrite this formula as V equals 2 plus E minus F. OK? All I did here was decrease by-- well, because there's a half out here, I decrease each coefficient by 2, nothing surprising. 4V is, at most, this number, and yet, it's also equal to this number. It can't be both. This number's at least 8 larger than this number; it could be even more larger. This works as long as there is at least one face, meaning 1 plus or minus because we're only looking at the subgraph plus and minus edges. And that is Cauchy's rigidity theorem. And in our situation, here, we don't actually necessarily know where the creases are. We just know how things are glued together. compute the shortest paths between all pairs of vertices, something like this picture, except you don't know what it looks like in 3D. You know every edge must be a shortest path. So the edges are some subset of these guys. And so you've got lots of little convex polygons here. We know it must make a convex polyhedron. If it made two, Cauchy's rigidity theorem would tell you that they're the same. So even once you fix the gluing, you know that there's a unique convex realization.

ROUGE-1: 61.83, ROUGE-2: 59.73, ROUGE-L: 58.77
BERTScore: 74.82

==============================================
==================== [78/100] ====================
Summary:
We've seen that the velocity can be written as r d theta dt. In the theta hat direction, theta is increasing. And so the particle is traveling around the circle in this direction. Let's now look at rotation in an arbitrary plane. So if I have a plane like this and I have some particle traveling in a circle like this, then it will see this rotation. And I have an observer that's above the plane looking down on this plane, then I will see it. as being in the counterclockwise direction. Whereas if I have another observer down here and they're looking up at this plane, they'll see the motion as being clock wise. And so you can see we have a need for a more formal definition for the rotation of this. So what we're going to do is use the right hand rule to define a direction that tells you both the direction it defines the plane and it also tells you what the positive direction of rotation is for that plane. it's the normal unit vector to that plane. So in the case of d theta dt positive, our circle looks something like this. And you can see that if I use my right hand rule, the plane, the vector that I've defined, is out of the board. In our other case, for d thea dt less than zero, our particle is traveling in this direction. And for that, I'm going to draw this as an x in the circle. So these are symbols that you'll see throughout the rest of the course.

ROUGE-1: 46.81, ROUGE-2: 44.67, ROUGE-L: 45.28
BERTScore: 81.89

==============================================
==================== [79/100] ====================
Summary:
This week's lecture will focus on machine translation related topics. In the second half of the week, we take a break from learning more and more on neural network topics. We'll talk about final projects, but also some practical tips for building neural network systems. This is an important content full lecture. You can download the full lecture for free on the iReport app, which is free to download from the iTunes App Store and the Google Play Store. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or click here for details.  assignment 3 is due today, assignment 4 is out today. Today's lecture is the primary content for what you'll be using for building your assignment 4 systems. For assignment 4, we give you a mighty two extra days. So you get nine days for it. And it's due on Thursday. On the other hand, do please be aware that assignments 4 is bigger and harder than the previous assignments. So do make sure you get started on it early. And then as I mentioned Thursday I'll turn to final projects. In the early 1950s, there started to be work on machine translation. Machine translation is the task of translating a sentence x from one language to another language. So we start off with a source language sentence x. L'homme, and then we translate it and we get out the translation man is born free, but everywhere he is in chains. OK. So there's our machine translation, and now let's get to the neural machine translation part of the story. Get straight into this with machine translation and we'll go through the prehistory of machine translation in a bit. This video clip shows some of the earliest work in machine translation from 1954. One of the first non-numerical applications of computers. $500,000 simple calculator, most versatile electronic brain known, translates Russian into English. Instead of mathematical wizardry, a sentence in Russian, it could be -- instead of Mathematical wizardry,. It could be-- instead of mathematical Wizardry. It was hyped as a way of keeping tabs on what the Russians were doing during the Cold War. The computer will be able to do about with a modern commercial computer about one to two million words an hour. This will be quite an adequate speed to cope with the whole output of the Soviet Union in just a few hours of computer time a week. When do you hope to achieve this speed? I our experiments go well, then perhaps within five years or so. And finally, Mr. McDaniel, does this mean the end of human translators? I say yes for translators of scientific and technical material. But as regards to poetry and novels, no, Despite the hype it ran into deep trouble. So the experiments did not go well. And so in retrospect, it's not very surprising that the early work did not work out very well. I mean, this was in the sort of really beginning of the computer age in the 1950s. That it was also the beginning of people starting to understand the science of human languages, the field of linguistics. So really people had not much understanding of either side of what was happening. So what you had was people were trying to write systems on really incredibly primitive computers, right? using to translate. And so effectively, what you were getting were very simple rule based systems and word lookup. So it was sort like, dictionary look up a word and get its translation. But that just didn't work well. Because human languages are much more complex than that. Often words have many meanings and different senses as we've sort of discussed about a bit. Often there are idioms. You need to understand the grammar to rewrite the sentences. So for all sorts of reasons, it didn't working well. And this idea was largely canned. when they were in the period of statistical NLP that we've seen in other places in the course. And then the idea began, can we start with just data about translation i.e. sentences and their translations, and learn a probabilistic model that can predict the translations of fresh sentences? So suppose we're translating French into English. We can say, what's the probability of different English translations? And then we'll choose the most likely translation. And it's not immediately obvious as to why this should be because this is sort of just a trivial rewrite with Bayes' rule. The Rosetta Stone allowed the decoding of Egyptian hieroglyphs because it had the same piece of text in different languages. In the modern world, there are fortunately for people who build natural language processing systems quite a few places, where parallel data is produced in large quantities. The European Union produces a huge amount of parallel text across European languages. The Canadian Parliament conveniently produces parallel text between French and English, and even a limited amount in Inuktitut, Canadian Eskimo. And then the Hong Kong parliament produces English and Chinese. So there's a fair availability from different sources. And we can use that to build models. So how do we do it though? All we have is these sentences. And it's not quite obvious how to build a probabilistic model out of those. Well, as before, what we want to do is break this problem down. So in this case, what is an alignment variable. So a is the alignment variable, which is going to give a word level or sometimes phrase level correspondence between parts of the source sentence and the target sentence. is working out the correspondence between words that is capturing the grammatical differences between languages. So words will occur in different orders in different languages depending on whether it's a language that puts on the subject before the verb, or the subject after the verb. And the alignments will also capture something about differences about the ways that work languages do things. So you can have words that don't get translated at all in the other language. So in French, you put a definite article "the" before country names like Japon. So when that gets translated to English, you just get Japan. One French word gets translated as several English words. You can get the reverse, where you can have several French words that get translated as one English word. So here we sort of have four English words being translated as two French words. But they don't really break down and translate each other well. These things don't only happen across languages. They also happen within the language when you have different ways of saying the same thing. So another way you might have expressed the poor don't have any money is to say the poor are moneyless. That's much more similar to how the French is being rendered here. English to English, you have the same kind of alignment problem. So probabilistic or statistical machine translation is more commonly known. What we wanted to do is learn these alignments. And there's a bunch of sources of information you could use. If you start with parallel sentences, you can see how often words and phrases co-occur in parallel sentences. You can look at their positions in the sentence. And figure out what are good alignments for you. But alignments are a categorical thing. And so you need to use special learning algorithms like the expectation maximization algorithm. CS228 is a statistical machine translation system. It picks out the most likely why there's the translation of the sentence. The naive thing is to say, well, let's just enumerate every possible y and calculate its probability. But we can't possibly do that because there's a number of translation sentences in the target language. That's exponential in the length of the sentences. So we need to have some way to break it down more. See CS228.off and see CS228 if you want to know more about that. We had a simple way for language models, we just generated words one at a time and laid out the sentence. But here we need to deal with the fact that things occur in different orders in source languages and in translations. And so we do want to break it into pieces with an independence assumption like the language model. But then we want a way of breaking things apart and exploring it in what's called a decoding process. So we start with a source sentence. So this is a German sentence. And as is standard in German. So that's probably not in the right position for where the English translation is going to be. we have is based on the translation model. We have words or phrases that are reasonably likely translations of each German word, or sometimes a German phrase. And so then inside that, making use of this data, we're going to generate the translation piece by piece kind of like we did with our neural language models. So there's a search process. But one of the possible pieces is we could translate "er" with "he", or we could start the sentence with "are" translating the second word. And in the process, I'll go through in more detail later when we do the neural equivalent. In the period from about 1997 to around 2013, statistical machine translation was a huge research field. The best systems were extremely complex. And they had hundreds of details that I certainly haven't mentioned here. So Google Translate launched in the mid 2000s. And people thought wow, this is amazing. You could start to get sort of semi-decent automatic translations for different web pages. But that was chugging along well enough. And then we got Google. Translate, which is now one of the most popular online translation tools. Neural machine translation, well, it means you're using a neural network to do machine translation. But in practice, it's meant slightly more than that. It has meant that we're going to build one very large neural network, which completely does translation end to end. These neural network architectures are called sequence to sequence models. And they involve two neural networks. Here it says two RNNs. The version I'm presenting now has two Rnns. And it's a language model that's going to generate a target sentence conditioned on the final hidden state of the encoder. "he." And so then doing LSTM generation just like last class, we copy that down as the next input. And we've translated the sentence, right? So this is showing the test time behavior when we're generating the next sentence. For the training time behavior, when we have parallel sentences, we're still using the same kind of sequence to sequence model. But we're doing it with the decoder part just like training a language model, where we're wanting to do teacher forcing and predict each word. Everywhere else as well. So you can do summarization. You can think of text summarization as translating a long text into a short text. But you can use them for other things that are in no way a translation whatsoever. So they're commonly used for neural dialogue systems. So the encoder will encode the previous two utterances, say. And then you will use the decoder to generate a next utterance. Some other uses are even freakier but have proven to be quite successful. So if you have any way of representing the parse of a sentence as a string. arc, right arc, shifts like the transition system that you used for assignment 3. Feed the input sentence to the encoder and let it output the transition sequence of our dependency parser. These models have also been applied not just to natural languages, but to other kinds of languages, including music, and also programming language code. So you can train a seq2seq system, where it reads in pseudocode in natural language, and it generates out Python code. And if you have a good enough one, it can do the assignment for you. was just to start at the beginning of the sentence and generate a sentence based on nothing. But here we have something that is going to determine or partially determine. And that's going to strongly determine what is a good translation. So in neural machine translation we are directly calculating this conditional model probability of target language sentence given source language sentence. And so at at the end of the talk, we will reveal the results of our machine translation project, which will be shown in the next few weeks. each step, as we break down the word by word generation, that we're conditioning not only on previous words of the target language, but also each time on our source language sentence x. Because of this, we actually know a ton more about what our sentence that we generate should be. So if you look at the perplexities of these kind of conditional language models, you will find them like the numbers I showed last time. They usually have almost freakily low perplexities, that you will have models with perplexities that are something like 4 or even less. Both of those in a bit more detail. So the first step is we get a large parallel corpus. And we grab a lot of parallel English French data from the European parliament proceedings. So then once we have our parallel sentences, what we're going to do is take batches of source sentences and target sentences. We'll encode the source sentence with our encoder LSTM, and feed its final hidden state into a target L STM. And this one, we are now then going to train word by word by comparing what it predicts is the most likely word to be produced, versus what the actual first word, and then the actual second word is. generating the correct next word "he" and so on along the sentence. And the crucial thing about these sequence to sequence models that has made them extremely successful in practice is that the entire thing is optimized as a single system end to end. So starting with our final loss, we backpropagate it right through the system. So we not only update all the parameters of the decoder model, but we also update all of the parameters in the encoder model which in turn will influence what happens next. conditioning gets passed over from the encoder to the decoder. So this moment is a good moment for me to return to the three slides that I skipped. I'm running out of time at the end of last time, which is to mention multilayer RNNs. And having a multilayers RNN allows us the network to compute more complex representations. So simply put the lower Rnns tend to compute lower level features, and the higher RNN's should compute higher. level features. And just like in other neural networks, whether it's feed forward networks, or the kind of networks you see in vision systems, you get much greater power and success by having a stack on multiple layers of recurrent neural networks. And multilayer or stacked RNNs are more powerful. Can I ask you, there's a good student question here? What would lower level versus higher level features mean in this context? Sure. So I mean, in some sense, these are lower level features. are somewhat flimsy terms. The meaning isn't precise. But typically, what that's meaning is that lower level features and knowing sort of more basic things about words and phrases. So that commonly might be things like what part of speech is this word, or are these words the name of a person, or a company? Whereas higher level features refer to things that are at a higher semantic level. So knowing more about the overall structure of a sentence, knowing something about what it means, whether a phrase has positive or negative connotations. systems just don't work well. But you can build something that is no more complex than the model that I've just explained now. That does work pretty well by making it a multi-layer stacked LSTM neural machine translation system. And so our representation of the source sentence from our encoder is then this stack of three hidden layers, whoops. And then that we use to then feed in as the initial, as theinitial hidden layer into then sort of generating translations, or for training the model. become much less clear. Normally to do deeper LSTM models and get even better results. You have to be adding extra skip connections of the kind that I talked about at the very end of the last class. Next week, John is going to talk about transformer based networks. They're typically much deeper. But we'll leave discussing them until we get on further. So that was how we train the model. So let's just go a bit further and look at the data. So that we have our LSTM, we start, generate a hidden state. It has a probability distribution over words. And you choose the most probable one the argmax, and you say "he", and you copy it down and you repeat over. So doing this is referred to as greedy decoding. Taking the most likely word on each step. And it's sort of the obvious thing to do, and doesn't seem like it could be a bad thing toDo. But it turns out that it actually can be a fairly problematic thing todo. stuck with it. And you have no way to undo decisions. So if these examples have been using this sentence about, he hit me with a pie going from translating from French to English. But once you've generated it, there's no ways to go backwards. And so you just have to keep on going from there and you may not be able to generate the next word. And there are lots of reasons it could think so. Because after hit most commonly, there is a direct object now and then he hit a car, right? So that sounds pretty likely. translation you want. At best you can generate, he hit a pie, or something. And well, what could we do? Well, I sort of mentioned this before looking at the statistical empty models. Overall, what we'd like to do is find translations that maximize the probability of y given x, and at least if we know what the length of that translation is. And that's where that then requires generating an exponential number of translations. And it's far, far,far,far away. Far too expensive. So beyond greedy decoding, the most important method is something called beam search decoding. beam search's idea is that you're going to keep some hypotheses to make it more likely that you'll find a good generation while keeping the search tractable. So what we do is choose a beam size. And for neural MT, the beam size is normally around 1.5 to 2.5 times. It's not the only other decoding method. Once when we got on to the language generation class, we'll see a couple more. fairly small, something like 5 to 10. And at each step of the decoder, we're going to keep track of the k most probable partial translation. So what we want to do is search for high probability hypotheses. So this is a heuristic method. It's not guaranteed to find the highest probability decoding. But at least, it gives you more of a shot than simply doing greedy decoding. So let's go through the typical way using our conditional language model. So as written all of the scores are negative. And so the least negative one, i.e., thehighest probability one is the best one. an example to see how it works. So in this case, so I can fit it on a slide. The size of our beam is just 2. Though normally, it would actually be a bit bigger than that. And the blue numbers are the scores of the prefixes. So these are these log probabilities of a prefix. So we start off with our start symbol. And we're going to say, OK. What are the two most likely words, to generate first according to our language model? I was, I got. OK. So we have four partial hypotheses. We work out the scores of each of them. And then we can say, which of those two partial hypotheses? Because our beam size, k equals 2, have the highest score? And so they are, I was, and he hit. We keep those two and ignore the rest. And so then for those two, we are going to generate k hypotheses for the next word. And we can do that by taking the previous score that we have the partial hypothesis and adding on the log probability. the most likely following word. He struck me and I was, I don't know, he struck me. And he hit a. So we keep just those ones. And then for each of those, we generate the k most likely next words tart, pie, with, on. Then again, we filter back down to size k by saying, OK, the two most likely things here are pie or with. And at this point, we would generate end of string. And say, OK,. We've got a complete hypothesis. then trace back through the tree to obtain the full hypothesis for this sentence. So that's most of the algorithm. There's one more detail, which is the stopping criterion. So in greedy decoding, we usually decode until the model produces an end token. And when it produces the end token, we say we are done. In beam search decoding, different hypotheses may produce end tokens on different time steps. And so we don't want to stop as soon as one path through the search tree has generated end. n complete hypotheses. And then we'll look through the hypotheses that we've completed and say which is the best one of those. And that's the one we'll use. OK. So at that point, we have our list of completed hypotheses and we want to select the top one with the highest score. Well, that's exactly what we've been computing. But it turns out that we might not want to use that just so naively. Because that turns out to be a kind of a systematic problem, which is not as a theorem. In a newspaper, the median length of sentences is over 20. So you wouldn't want to be having a decoding model when translating news articles that says, huh, just generate two word sentences. They're just way high probability according to my language model. So the commonest way of dealing with that is that we normalize by length. So if we're working in log probabilities, that means taking dividing through by the length of the sentence. And then you have a per word log probability score. you can argue that this isn't quite right. In some theoretical sense, but in practice it works pretty well and it's very commonly used. Neural translation has proven to be much, much better. It has many advantages. It gives better performance. The translations are better. In particular, they're more fluent because neural language models produce much more fluent sentences. But also, they much better use context because neural. language models give us a very good way of conditioning on a lot of contexts. all parameters of the model end to end in a single large neural network has just proved to be a really powerful idea. The models are also actually great in other ways. They actually require much less human effort to build. There's no feature engineering. There're in general, no language specific components. You're using the same method for all language pairs. Of course, it's rare for things like this to happen, but it's not unheard of. We'll come back to the costs of that later in the course. Neural machine translation systems also have some disadvantages compared to the older statistical machine translation system. They're less interpretable. So they're hard to debug. They also tend to be sort of difficult to control. So there are various safety concerns. But at the end of the day, BLEU gives a score between 0 and 100 where your score is 100. If you are exactly producing one of the human written translations, and 0 if there's not even a single unigram that overlaps between the two. Machine translation with statistical models had been going on since the mid 2000s decade. But by the time you entered the 2010s, basically progress in statistical machine translation had stalled. And you were getting barely any increase over time. Most of the increase you weregetting over time was simply because you're training your models on more data. In those years, around the early 2010s,. the big hope that most people had was that machine translation was going to get better and better. And it didn't. In 2014, the first modern attempt to build a neural network from machine translations and encoded-decoder model. Within two years' time, Google had switched to using neural machine translation for most languages. Does that mean that machine translation is solved? No. There are still lots of difficulties which people continue to work on very actively. But there are lots of problems with out of vocabulary words. And domain mismatches between the training and test data. And hopefully, you'll even get a sense of this doing assignment 4. Even our best multilayer LSTMs aren't that great of capturing sentence meaning. There are particular problems such as interpreting what pronouns refer to. For languages that have lots of inflectional forms, these systems often get them wrong. So here's just sort of quick funny examples of the kind of things that go wrong, right? So if you asked to translate paper jam. Google Translate is deciding that this is a kind of jam just like this. And so this becomes a jam of paper. Many languages don't distinguish between things masculine or feminine. When that gets translated into English by Google Translate is that the English language model just kicks in and applies stereotypical biases. So if you want to help solve this problem, all of you can help by using singular they in all contexts when you're putting material online. And that could then change the distribution of what's generated. And people also work on modeling improvements to try and avoid this. Here's one more example that's kind of funny. People noticed a couple of years ago. That if you choose one of the rarer languages that Google will translate, that the gender neutral sentences get translated into, she works as a nurse. such as Somali, and you just write in some rubbish like ag ag ag. Freakily, it had produced out of nowhere prophetic and biblical texts, as the name of the Lord was written in the Hebrew language. As far as I can see, this problem is now fixed in 2021. So there are lots of ways to keep on doing research. NMT certainly is a flagship task for NLP and deep learning. And it was a place where many of the innovations of deep learning NLP were pioneered, and people continue to work hard on it. For assignment 4 this year, we've decided to do Cherokee English machine translation. Cherokee is an endangered Native American language that has about 2000 fluent speakers. And particularly, there's not a lot of parallel sentences between Cherokee and English. And here's the answer to Google's freaky prophetic translations.actually for the last bit of the class and the minute I'm going to present one huge improvement, which is so important that it's really come to dominate the whole of the recent field of neural networks for NLP. And that's the idea of attention.  Cherokee is not a language that Google offers on Google Translate. So we can see how far we can get. But we have to be modest in our expectations because it's hard to build a very good MT system with only a fairly limited amount of data. There is a flipside, which is for you students doing the assignment. The advantage of having not too much data is that your models will train relatively quickly. We'll actually have less trouble than we did last year with people's models taking hours to train as the assignment deadline closed in. Most Cherokee now live in Oklahoma. There are some that are in North Carolina. The writing system that I showed on this previous slide, it was invented by a Cherokee man, Sequoyah. So he started off illiterate and worked out how to produce a writing system. And given that it has this consonant-vowel structure, he chose a syllabary which turned out to be a good choice. So here's a neat historical fact. So in the 1830s and 1830s, a lot of the Native Americans from the Southeast of the US got forcibly shoved a long way further West. 1840s, the percentage of Cherokee that were literate in Cherokee written like this was actually higher than thepercent of white people in the southeastern United States at that point in time. And so we had this model of doing sequence to sequence models such as for neural machine translation. And the problem with this architecture is that we have this one hidden state, which has to encode all the information about the source sentence. So it acts as a kind of information bottleneck. And that's all the info that the generation gets. is conditioned on. The order of words is very important to preserve. It seems like we would do better, if somehow, we could get more information from the source sentence while we're generating the translation. If you're a human translator, you read the sentence that you're meant to translate. And you maybe start translating a few words. But then you look back at the source sentences to see what else was in it and translate some more. And in some sense, this just corresponds to what ahuman translator does, right? words. So very quickly after the first neural machine translation systems, people came up with the idea of maybe we could build a better neural empty MT that did that. So the core idea is on each step of the decoder, we're going to use a direct link between the encoder and the decoding that will allow us to focus on a particular word or words in the source sequence and use it to help us generate what words come next. I'll just go through now showing you the pictures of what attention does and then at the start of next time we'll go through the equations in more detail. The hidden representation is used to look back at the source to get information directly from it. So we'll be training the model here to be saying, well, probably you should translate the first word of the sentence first, so that's where the attention should be placed. And then based on this attention distribution, which is a probability distribution coming out of the softmax, we're going to generate a new attention output. And so this attention output is going to be an average of the hidden states of the encoder model. that can sometimes improve performance. And we actually have that trick in the assignment 4 system. And you can try it out. So we generate along and generate our whole sentence in this manner. And that's proven to be a very effective way of getting more information from the source sentence more flexibly to allow us to generate a good translation. I'll stop here for now and at the start of next time. I will finish this off by going through the actual equations for how attention works.

ROUGE-1: 66.74, ROUGE-2: 63.99, ROUGE-L: 62.22
BERTScore: 70.44

==============================================
==================== [80/100] ====================
Summary:
Michael Short picks up where he left off in 22.01. He talks about radiation damage and nuclear materials. The course is available for free on MIT OpenCourseWare. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT Open CourseWare at ocw.mit.edu. Your support will help MIT Open courseWare continue to offer high-quality educational resources for free. Back to Mail Online home. Back To the page you came from."What's all this nuclear materials?" asks Michael Short. into things like voids or loops and super structures that have end up having macroscopic effects on material properties. The amount of energy it would take to actually cause this material to fail is a measure of toughness. The strength of the material is how much stress you can put in until it starts to either plastically deform or it hits its UTS, ultimate tensile strength. And finally, stiffness is more of a response function, so it's how much does it deform in relation to how muchstress you put into it. So the basic mechanism of radiation damage is like you might imagine. Let's say this green particle is a neutron or a heavy ion or a proton or an electron or anything. Anything that's energetic enough to cause atomic displacement. So as that neutron or whatever enters, it will strike some of the atoms in this perfect crystal, creating what's called a primary knock on atom, or PKA, for short. And then that neutron and the released PKA will go on to hit more and more atoms, resulting in what we call a damage cascade. A measure called DPA, or displacements per atom, is a simple measure of how many times has every atom left. It's not actually a unit of damage, and I'll be giving a talk at MRS, the materials research conference tomorrow, railing against this DPA unit. What is a DPA? A DPA measures the number of times that each atom has moved out of its original site, but it has nothing to do with how many time it stays. That's it, though. The DPA is a simple formula that I think you guys may recognize. It's an energy dependent flux times another type of cross-section that we call the damage displacement cross- section, or sigma D. So with what you know 22.01, you can understand the basic unit of radiation damage. But it says nothing about where they end up, and that's the really interesting part about radiation material science. Even though they were displaced, and would be counted as part of the DPA, or the radiation damage dose, the net effect on the crystal material is nothing. energy E and imparting kinetic energy T to another struck atom? That comes right from-- remember our treatment-- I think I've drawn this probably 50 times now. Our hollow cylinder treatment of a charged particle with charge little ze interacting with a particle a big ZE at some impact parameter B. We wanted to know well, for all possible approach paths, the area of this hollow circle, or the probability that this particular approach path is taken, is just the area here 2pi b db. the number of displacements done, for each one of these reactions. And there are simple models, there are mostly linear models for-- if a particle comes in with energy E, leaves with energy T, how many displacements happen? It's a pretty simple linear piece-wise model. But I want to get the idea of DPA versus damage. They're two very different things, and they're often equated. Much like the material properties of strength, ductility, hardness, and toughness are equated in colloquial speech, but that's absolutely wrong. damage cascade to happen. What sort of factors would affect the speed at which these different defects end up finding each other? What could you vary about a material or its environment to change the speed of these atomic diffusion jumps? Temperature. The dose rate, The temperature determines diffusivities. It also can change phases or crystal arrangements, like for the case of anything iron-based. It can take years for these defects to diffuse, to cluster up, and to form these super structures, and end up causing the damage that can lead to material property degradation. Grain boundaries, dislocations, all of those defects that we talked about last time, just to refresh your memory of what those are. We have been talking about zero dimensional defects like vacancies. We saw an example of a two dimensional defect, known as a grain boundary, where you can see this line. And then micro structure. Things that are bigger than on the order of atoms. The rate at which those neutrons come in can change the rates at which the defects cluster up. between different arrangements of atoms. And there can be three dimensional defects. Like inclusions of some separate face sitting in the material. Like the manganese sulfide we found in the Alcator fusion reactors power rotor. The movement in clustering of those defects can be quite strongly influenced by the presence of all those other defects. So again, the DPA actually tells us this part of radiation damage. What it doesn't tell us is everything else, and it's the stuff that happens here that can tell us will our materials fail in nuclear reactors? A 30% difference in the rate at which neutrons arrived at the nickel, and they get the same result in void swelling, at two and a half times the DPA. So if you want to answer the question, well, how much dose does it take to reach 3% swelling in nickel? Can't. Not just ranting against it, no I am, but I'm doing so with evidence, so it's justified. It's a very strong dose rate effect for material damage. answer that question, you don't have enough information. Even if you say, how much dose does it take with one of the neutrons at 600 Celsius in this one reactor? You can't answer that question. And a lot of the rest of nuclear materials data looks something like this. Now, I don't want you to worry about what the axes say. They're not readable because they're not important. What I do want to know is what's the quality of this data set you see? The best we can say how long it will take to get materials to the end of their useful life is anywhere from 10 DPA in light water reactors to 500 DPA for TerraPower's traveling wave reactor. So the trick is doing these experiments is extremely difficult and expensive. Just throwing something near the MIT reactor for a month, because we did this, we took a few hundred milligrams of copper, aluminum, and nickel. That cost $40,000, and that did about 0.002 DPA, or about the dose that you'd receive in a normal power reactor in one day. do right now is to stick them in a reactor called BOR-60 in Russia. Russia's got a fleet of sodium cooled fast reactors that can get you 25 DPA per year. And if your reactor is going to go to 500 DPA, you have to know whether or not your materials will survive. So what investor isgoing to be like, all right, here's $10 billion, but I can wait 20 years for a return on investment. No. I can. wait 20 years to start building the reactor, which means 40 years for a return on investment. Chances are, if someone's got $10 billion to give, they're going to be dead by the time they get a return. So what we really need to know is what is the full population of every single type of defect in an irradiated material? That's what I mean by damage. Did I show you guys this movie yet? The orange one? We've talked about vacancies in an abstract sense, but this is a movie of one of them actually moving about on the surface of germanium. You can see it in real time. The only reason these slides aren't up yet is because they're 300 megabytes, and I didn't have the bandwidth to upload that from my house. Now that I'm on campus, I can get a 300 meg presentation up there because it's full of movies. What sort of things could happen to these defects? So radiation produces all these crazy defects, then the DPA description is over. What could happen next? [INTERPOSING VOICES] MICHAEL SHORT: Sorry, Jared, and then-- yeah. case scenario, but that is indeed what happens in the end, and I'll show you some pictures of that actually happened. A void is nothing but a bunch of vacancies or a pocket of vacuum or gas in a material, and it all has to start with these single vacancies. As they cluster together, they reached this threshold in terms of free energy where putting a few of them together is not quite energetically favorable. We've actually seen these clusters or voids diffusing, so it's not like vacancies alone are the only thing that moves. diffusing, mostly in one dimension, but what you're seeing here is a TEM, or transmission electron microscope image, of one dimensional diffusion of a vacancy cluster. If you get a little bit of gas to stabilize that pocket of vacuum, then that pressure differential goes down and that void becomes a bubble, and that bubble is more stable. The other problem too is that most materials generate helium when you irradiate them with neutrons. Did we go over the what's called the N alpha cross-section? Does that sound familiar to anyone?  helium atoms have nowhere to go, they find the easiest place to sit, that happens to be pockets of vacuum. And what that actually does is stabilizes those voids so the curve I showed you back here. This is the case of free energy for a vacuum pocket of void, and that free energy gets lower and lower as you start to fill that void with gas. So as the voids fill with gas, they become more and more stable, and a lot of materials generate their own gas. Dislocation buildup can be caused by radiation. Normally, you would have to deform a material to create and move dislocations. But when you apply radiation, you can just create dislocational.direction. This is kind of cool. You've got a dislocation source right here. Every one of those lines you see is a dislocated, and you can see it's spiraling out and ejecting dislocation from this one little spot. Any combination of any combination of. small clusters can collapse into dislocations or the stress induced from irradiating things can cause more stress that can move more dislocation. You create what's called this network forest of dislocational that makes things a lot harder to deform. The trick that we didn't talk about yet, is when dislocated from different directions collide, they get stuck. And when they get trapped, you shift. And so all the time, you're creating dislocatives that are being emitted from different places and colliding with each other. the balance from slip to fracture, which means, like Jared said, it's easier to just break something, rather than plastically deform it. An increase in the Young's Modulus. Because if you remove some of the compliance from the material or make it stiffer by injecting all sorts of different defects, it takes more stress to impart the same strain. That might not be a bad thing on its own. Your materials get stronger, that sounds like a good thing, right? Not always because it doesn't just come as stiffening. Dislocation movement is irreversible. You can't just snap it back when you relieve the stress. By making something stronger and stiffer, you make it more difficult for those dislocations to start moving. And you can do that by throwing any defect in their way. Since radiation creates pretty much any and all defects, it's a great way to stiffen and strengthen the material. If something is stiffer and stronger, then the stress strain curve would be drawn more like that. goes up by one atomic position. Then you've got pieces of this dislocation that are not in this preferential slip plane, and they get stuck. So all of a sudden you go from a completely gliding-- or what we call glissile dislocation-- to one that's stuck, or sessine, those are the actual material science words that we use. And what it ends up leading to is a strong loss in ductility. At the same time as things get stronger and stiffer, they tend to get much less ductile. The fuel stayed down in the reactor with no way to pull it out. This is the reason why radiation damage is such an important field of study. You might not know anything has happened until you shut the reactor down and go to take out the fuel and realize that you can't because everything is as brittle as glass. And the scientists were freaking out, because only they knew that all of the radioactive materials came from a reactor that shut down in 1999 on one side of Kazakhstan. So they hired the cheapest truck drivers to go on the bumpy roads. the metal that all those guys thought was going to be ductile like metal was more brittle than glass. And any sort of bump would cause just complete shattering of this metal and catastrophic release of radioactive material. So this took them-- let's see-- I think Kazakhstan is smaller than the US. So who here has done a cross-country trip? How long it take you? AUDIENCE: Six days from Seattle to here. MICHAEL SHORT: OK, so this trip took them 13 days because they went slow. problems and no release of radioactive material. Pretty cool. What you want to happen is for dislocations to move on the easiest planes. And so you actually end up getting deformation in what's called slip plains, or the easiest directions for things to deform. And without going into any of the math or atomistics, I just want to show you some examples pulled out of, again, the fusion reactor. So this is a bar of some metal, some face-centered cubic metal, as you pull on it, like this, it will actually deform at about a 45 degree angles. is a piece of rotor steel from the same Alcator rotor where we found that inclusion. We were pulling it in this direction, and look what formed. All of these slip bands at 45 degree angles, showing you that just because you pull in something in one direction, doesn't mean it deforms in that direction. It deforms and little slices in the direction that dislocations can move the easiest. You get a mixture of bending and rotation to make it look like the bar is bending uniformly straight, but on the microscale, it's not. way to the outside of the material, which is pretty cool, and this is the process that you want to happen. Anything in the way of those dislocations, you don't start forming these slip bands, and you'd make it more preferable that the thing will just break and fracture. To show you some extreme examples of slip, that's when you have to go nano. So these are some pillar compression test that used a focused ion beam, which we will be using to top off our study of electron interactions with matter. and very weird compression. Not actually weird, if you know what's going on. There's lots more neat examples of this. If you don't push too hard, you can actually see these perfectly symmetrical slip planes at 45 degree angles to the axis of compression. And this is what you want to happen to nuclear materials because you're really trying to balance this between slip and fracture towards the direction of slip. That means that something will deform a little bit before it just shatters like those channel boxes from the Russian reactor. A phenomenon called pileup occurs when dislocations get in each other's way. This happens both near otherdislocations and near any other defect that gets in the way, like a grain boundary. For smaller materials you end up with more of this pileup, and they tend to be of a fair bit stronger, and a fair lot-- they can be less ductile, with some exceptions. And this ends up shifting, and this is called a pileup. It's like a traffic jam. what we call the ductile-brittle transition temperature. This is the property that people worry about for reactor pressure vessels. You would want the pressure vessel, which in cases the entire core of the reactor, to always be ductile. The worst possible situation is on the absolute last day of operation at the coldest temperature it could possibly be. So normally you'd be able to bend a coin, or if it's a one yen coin, you can bite through it. Not when immersed in liquid nitrogen. that it's got a certain amount of energy absorption capability, toughness, at a certain temperature. The way you test ductile-brittle transition temperature is what's called a Charpy impact test. It's probably the highest tech, lowest tech test I've seen. You simply hit things with a hammer. A very well calibrated, precise hammer. You have these little bars with a notch in them. The notch is to make sure that acts as a stress concentrator, and you know where the breaks going to happen. these out and you hit them with a very well calibrated hammer. And you can measure by actually turning this dial and letting the hammer turn it as it moves through the material. So it breaks right through thematerial, in this case, it's in a quenched or brittle condition. So what you can see is that if the hammer were to move through air with absolutely no drag, it would come back to the zero position. If they had encountered some resistance, like with a piece of steel in the way, it then measures the amount of energy in joules that piece of steel absorbs from the hammer blow. The larger that is, the better. By doing this test at a number of different temperatures, you can recreate this ductile-brittle transition temperature curve. So they'll take a few Charpy coupons, they will test them at, let's say, every 25 Celsius, get a bunch of points, draw the line through the points, and decide where is the material brittle. At what temperature will it become brittle? done by the same awkward feller who likes to stand there and not breathe, but you'll notice a very different result of this test. Doesn't look like it, but if you actually look at how much energy was absorbed, much, much higher. So something like 18 times more energy, and you can qualitatively see the difference between these two conditions by looking at the fractured surfaces. Something that's ductile would tear more like taffy, where something that's brittle would cleave or break in half much more smoothly. temperature curves, is this not just this part that you're worried about, it's that part. So even at high temperatures, things get less ductile. So it's a combination of temperature and number of defects. And if either one of these criteria fails, if you become too brittle at low temperature, or your total ductility at high temperature goes down too much, that's the end of life of your reactor vessel. This is one of the biggest problems in life extensions of light water reactors. is why. You have to be absolutely sure that your vessel, your primary containment, will survive. And we're not so sure because well, we jump to the part of the video that's got the Charpy coupons. We ran out. We only plan to put these vessels in service for 40 years, and folks put 40 years worth of these coupons, plus some extras, in the reactor vessel. What do you do when you run out of coupons? Anyone have any ideas, because I'm sure the industry would love to hear them. Vessel is made of thick carbon steel with a very thin liner of stainless steel. Stainless steel is there to prevent corrosion from the reactor water. If you were to take something out from the inside of the vessel, the part that gets the most damage, you'd be taking out some of the stainless steel, which is a problem. Any sort of chunk that is missing is where a crack is going to preferentially form, so you would weaken that vessel by taking a piece out. Michael Short: Can you make Charpy coupon or coupons that are similar to the status of the ones most recently taken out of the vessel, and then just put them in? That's what they're doing. So that's absolutely right. You've just probably recreated a year's worth of licensing work and ideas and in a class. But I just want to get back to Charlie's idea because that's what I think has to happen is you'd like to be able to take a piece out from the actual vessel and run a test on it. Every kind of defect takes energy to create. You either have to raise the temperature of a material or in our case, irradiate it. The energy of those incoming neutrons that bounces around different atoms and creates all these different types of defects. So those defects are storing energy in the material. And so if you think about how much energy does it take to destroy something, it would have to be the energy it's already stored plus the energy that you put into it during the destruction. The test can reach the failure energy. What if you could measure the stored energy? What if there was a way to know how many of each of those defects there actually were in a material? Well, we know there is. It's called differential scanning color imagery. It is a way of measuring the change in heat capacity of a material, where you take two small furnaces and apply a lot of heat to both of them. And you look at the difference in the amount of heat you have to put in to keep the two at the same temperature. can extort per degree Kelvin. If this material's got a bunch of defects already in it, then you should release that defect energy by heating it and that would take a little less energy to heat it up. There's a lot of problems with calorimetry, so we're actually using what's called nanocalorimetric. We're doing this process on nanograms of material and seeing if you can irradiate something and measure its stored energy. If you could, you could take a tiny little razor blade, take out the smallest sliver of the vessel-- smaller than a grain of sand. Not enough to cause a crack-- enough to measure its storage energy. Snipes are real. You pretty much have to be British to know it, because they hunt them there for sport, and apparently, they're delicious. That's actually where we get the term snipe because the actual size of the sniper compared to the sniper is about that. If you can shoot that bird, if you can get that shot, you're a snipe hunter. You're not looking for a bird that doesn't exist. It's what we call the ultimate snipe hunt. with a gun, you are an expert marksman and deserve the delicious and tiny treat that you've then blown apart with your bullet. So you can you know rain bird dust on whatever meal you've already prepared. That's what I like in finding these radiation damage defects too. Most defects are very, very small, and it turns out that-- first of all, the resolution of the screen is funny. I think I know how to fix that. Clone the screen and then jump back to presenter mode. Eugene Wigner and Leo Szilard said radiation stores energy by neutron collisions like cold working and amorphization. So we've dug up this original memo from the 40s, and said, let's do this for everything. Every defect has its unique amount of energy that it stores and creating it in some different amount of eV per defect. We've done some molecular dynamics simulations to show that this amount ofenergy stored is pretty pretty. It's a pretty big deal. When you irradiate something, we predict that it stores about 2% of its energy in radiation defense. So if you know the number of neutrons that hit, and you know that the amount of energy per neutron, you know how much you're looking for. You know what your signal should be. And to jump through to the whole idea of differential scanning calorimetry, it's like what I drew here, but a lot more legible. You simply heat two materials, one of which contains your sample, measure their temperature. The researchers used a DSC, or nano differential scanning calorimeter, that can heat about 10,000 times. The problem is that DSC induces a lot of artifacts in the signal that we couldn't separate from the noise. The bad news is that when you normalize all these curves, you get something that you can't tell if I drew it or my son drew it. Looks suspiciously like the doodles that he does, not scientific data, the researchers say. times faster than a traditional DSC. So you can get your energy out from smaller materials way faster than these artifacts can manifest themselves. Every one of these peaks here is going to correspond to one type of defect that's released at a certain temperature. And by extrapolating to a zero heating rate, you should know which type of defects they are. And if you know which defects you have and how many of each one, you know the full defect properties and material,. You should know it's material properties. Because we already know if you have this many dislocations, it's this brittle. It actually fits on a chip. There's one that we put our material on, and one as a reference that we both put in the accelerator being irradiated at the same time. This is what they actually look like. The scale bar here is 100 microns, and that transparent spot is a little bit of aluminum that we vapor deposited onto the calorimeter. Right there. That whole thing just went from zero to 450c. That pulse right there. It slowed down by a factor of 1,000. And so the way this process works, is we take our DSC chip, we put a mask over it. a millisecond. And the reason it took a second is because I've slowed down the video by 4,000 or by 5,000 times, and that little pulse of heat actually released some of the defect energy. We were able to see very clearly, the first time we heated the sample, this extra area corresponds to some sort of energy release. We then heated that same sample a whole bunch of times and made sure that it was always the same, which meant we had a fully relaxed material. The heating is so fast that the defects don't even have time to show up. We can go much, much smaller and just take out tiny pieces of the vessel and get the same information as you would from a Charpy test but on the nanoscale. So the question then is, where is the defect fingerprints? Where are those individual defects that we were looking for? Well, I think they're just popping up right here. The reason for that is we picked a very fast heating rate for our experiments. to find each other, annihilate, and release their stored energy. We need to repeat the experiments at some lower temperatures, see what the peaks are, but if you go too low, you end up getting a lot of noise in your signal. So we're just at the very first experimental stage of trying to see can we extend reactor lifetimes. But for now, it actually shows some sort of a trend, so it's just enough justification for us to buy one of these nanocalorimeters and start looking for real. we keep our reactors running in about two hours. I think that's the most compact introduction to nuclear materials I can possibly give you. As far as is it actually a line? Is it a curve? I am not as brave or stupid as some of the other folks that will draw an arbitrary shaped line through a single data point. So I'm not drawing a trend line yet. Yeah, any other questions? Yeah? AUDIENCE: Is it-- or I guess you're making the assumption that one little spot in the reactive pressure vessel to say what the rest of the vessel has been exposed to? MICHAEL SHORT: Oh, not at all. doing Charpy coupons of one place, which is what we do now, you can get a map. We don't have that information now, but if you take pieces from all over the vessel, then you get an actual 3D map. When some type of defect gets high enough in temperature that it goes from stuck to mobile, and as that moves, it encounters anything else. How do you know? You don't. You make measurements like these. Any other questions? Yeah? The properties of the vessel are highly dependent on, not just its composition, but the heat treatment that went to make it. If you heat that vessel, you both remove the radiation damage and remove the strengthening put in by the forging and heating process. So you would have, if-- again, if you let's say, replace the vessel you have a new reactor. It will react with all the other defects nearby, decimating the population of that defect and slightly depressing that of the others. the vessel too much, it's no longer a code stamp vessel. Pretty tricky spot that we're in, huh? But we're trying to science our way out of it. I don't want to keep you longer, but I'll open on Thursday with a little story about how mass attenuation coefficients can get you out of apartheid South Africa. I'm serious. And then we'll move into dose and biological effects. It's a couple minutes after. Well, it was just a few minutes.

ROUGE-1: 67.65, ROUGE-2: 64.88, ROUGE-L: 61.40
BERTScore: 68.70

==============================================
==================== [81/100] ====================
Summary:
According to the Chinese zodiac, your shÄ“ngxiÃ o is the animal assigned to your birth year. The most enduring one is that of the Great Race. As the story goes, YÃ¹ DÃ¬, or Jade Emperor, Ruler of the Heavens, wanted to devise a way to measure time. The first twelve animals to make it across the river would earn a spot on the zodiac calendar in the order they arrived. Because the rat was small and couldn't swim very well, he asked the bigger animals. for help. While the tiger and horse refused, the kind-hearted ox agreed to carry the rat across. Just as they were about to reach the other side, the rat jumped off the ox's head and secured first place. The ox came in second, with the powerful tiger right behind him. The rabbit, too small to battle the current, nimbly hopped across stones and logs to come in fourth. Next came the dragon, who could have flown directly across, but stopped to help some creatures she had encountered on the way. The traditional Chinese calendar is made up of two overlapping systems. Each year is associated with one of the animals in this order, with the cycle starting over every 60 years. The animals of the zodiac are associated with what's called the Twelve Earthly Branches, or shÃ­'Ã¨rzhÄ«. Another system, the Ten Heavenly Stems, or tiÄngÄn, is also associated with the animals of this zodiac. We hope you enjoyed the video. We'll be back with more from China in the coming weeks. The twelve animals of the Earthly Branches are matched with the five elements plus the yÄ«n or the yÃ¡ng of the Heavenly Stems. This creates 60 years of different combinations, known as a sexagenary cycle, or gÄnzhÄ«. So someone born in 1980 would have the sign of yÄng metal monkey. Someone born in 2007 would be yÄn fire pig. In fact, you can also have an inner animal based on your birth month, a true animal based in your birth date, and a secret animal based upon your birth hour. reflect their communities. So if you consult the Vietnamese zodiac, you may discover that you're a cat, not a rabbit. If you're in Thailand, a mythical snake called a Naga replaces the dragon. So whether or not you place stock in what the zodiac says about you as an individual, it certainly reveals much about the culture it comes from. The zodiacs of Vietnam, Thailand and the U.S. can be found at www.zodiac.com.

ROUGE-1: 73.13, ROUGE-2: 67.38, ROUGE-L: 68.68
BERTScore: 69.71

==============================================
==================== [82/100] ====================
Summary:
Professor: In almost all cases when you address atoms, you do two photon courses because a photon is scattered. You may think it's absorbed and emitted, but in reality, it is a two photon process. If you have any doubts about some subtleties about how is light absorbed and emits, the correct answer is always obtained from the two-photon picture. The lecture is part of MIT OpenCourseWare, a free online educational resource. To make a donation or view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu. And it is exactly the same perturbation theory we've used before. It's just-- there's one difference. Namely, we have two optical fields at frequency omega 1 and omega 2. So for the case of two-photon absorption, that means both photons are used or stacked up to go up in energy. We derived this result, and this was the end of lecture last week. And what we obtained in perturbative theory for the excited state, it's the same structure you have seen before. many terms do you get if you write down the Hamiltonian? No approximation without. How many do youget? AUDIENCE: Four. PROFESSOR: You have a plus dega for the electric field, sigma plus plus sigma minus for the atom. And then you have four combinations, two are co-rotating,. two are counter-rotting. OK. What we are doing here is second order perturbation theory with two optical fields. If you would not do any rotating wave approximation, how many terms would we get? if we don't make an approximation, we get 64 terms. But they're just all combinations, all combinations of frequencies. I said I'm only interested in the near-resonant terms. And then when we say we want to go up in energy in two steps, we absorb two photos. We don't have any emission of photons. These are all the counter-rotating terms. You have only the absorption of photons, and then we have four possibilities. Yes, I mean, you have a term where two photons are emitted from the ground state. lowest order perturbation, second order perturbedation theory, in two steps. But if you're asking, what is the transition probability? The transition probability, we have to get the probability to be in the excited state. And when we divide the probability, the amplitude squared by t, we get a rate. And this is Fermi's Golden Rule. It is exactly the same you have seen probably more than 100 times. But then-- and this is the only difference. signal photon-- the relevant matrix element is, because we have two steps, is the product of two matrix elements squared for step one and for step two. Because we have an intermediate step, we have to divide by the energy mismatch by the detuning in the intermediate state. But remember, in the one photon picture, Fermi's Golden Rule is the Matrix elements squared times the spectral function. So in this matrix element squared in frequency units, neglecting factors of 2, was the Rabi frequency. So therefore, very naturally, we want to define this as a two-photon Rabi Frequency. We've just cleverly defined our quantities. The rate to go from a to b is Rabi frequency squared, but it is the two photon Rabi frequencies. So therefore, our result looks almost indistinguishable from the result built on single photons. So in other words, if you were interested just in the physics of two levels-- Rabi oscillation, you name it-- you can just say the same thing happens. The only difference is that instead of having a coupling, we have stacked up the two photons. directly by a matrix element, we are now coupled by this two photon Rabi frequency. And all your equation, you know, everything-- you can consider line shape, spontaneous emission, saturation-- all the phenomena we have discussed for single photon are analogous. You just have to use the density of state calculated for the two photons. OK. So I started out by telling you about two photon processes, two photon absorption. But what is maybe even more important in the way how it is used in experiments are Raman processes. the atom-- the same hyperfine state-- but with two different momenta. Then it is a Raman process only in the external degree of freedom, in the motion away function. We need our intermediate state, which is often an electronically excited state. We are detuned. And now we have one photon going up and one photons going down. But if you work in molecules with a thermal ensemble, then you have certain states thermally populated and others not. And then it makes a difference whether you start from the ground state or the intermediate state. or from an excited state b. So in other words, what was previously one of the counter-rotating terms, where omega had a plus sign and omega two had a minus sign, now it becomes a resonant term because we have arranged our two levels a and b in such a way that the near-resonant process is that one. So actually, everything for the Raman process is completely analogous-- is completely covered, actually-- by what I wrote down for you in perturbation theory. It's just if you had kept all the 64 states-- to go up with one photon and down with one photons one was one of them. photon is emitted in a stimulated way and not absorbed. And therefore, our detuning is the detuning from the Raman resonance. The rate in Fermi's Golden Rule is the matrix element squared times the spectral density indicated by the delta function. The delta function is now at the frequency, which is given by the two-photon detuning. It would be an amazing coincidence if accidentally it would be in resonance with another one. But I would say, if you had a situation-- let's say, let's go to the moon. say in a molecule, which is a high density of state, the Raman process would be a rotation or vibration. And if you're unlucky and don't choose your lasers wisely, the two laser photons could get you high up into an electronically excited state. This may have some detrimental effect, depending what you want to do. But in general, I would say if you have more than one process, there is no interesting interference term. You just get two different rates. And you just have both simultaneously. They're not leading to the same final state. coherence. I want to now take it one level higher, where we talk still about two-photon processes but we are allowing one of the photons to be spontaneously emitted. Again, we don't have to learn new things. We just have to map it to knowledge we already have. I just want to sort of give you a clear understanding what this expression for the two-Photon rate is. Any other questions? OK. We can say the photon omega 2 cannot be absorbed by the initial state. It can only be absorbed because omega 1 mixes in. In perturbation theory with the field one, the state a has now a probability, given by this term, that it has now an admixture. And now, if we have sort of-- we have dressed up our state a with admixing for the near-resonant field some probability of state k into it. And this stressed state now has sort of a stepping stone here. And from this stepping stone, it can now absorb the photon omega 2. So that's how we should think about it. the virtual state-- to the final state b. And let me just point out what this virtual state is. Well, you know already everything about it because everything which can be known about it is what we have derived in our formula. I'm just interpreting the perturbation theory I've written down. And if I now call it a virtual state, there is nothing more you can ever know about this state than what was in this formula. But it's maybe helpful to summarize it. Because we have a resonant with frequency omega 2 in this situation. and such? Well, it is exactly the intermediate state k. And what is the population? If you had a two-level system, we sort of start with 100% amplitude in state 1. But here, our population is diminished by the probability at which we have it admixed the state. I think the picture I've just drawn for you is sort of helpful when we discuss now two-photon emission-- spontaneous emission. With two lasers, it's sort of simple. But with two-Photon emission, we have the situation that we start in. an excited state b. We have one laser, omega 1, and that's it. But we will find out that, eventually, the system populates the ground state. And one possible process is that it was first emitting a photon in a stimulated way, but the second photon, since we're not offering any extra stimulation, had to be emitted spontaneously. So in other words, you don't need to re-derive anything. You can just sort of use analogy to write down what is the spontaneous emission rate. spontaneous emission. The physics of spontaneous emission is that you can put one photon in each of the empty modes and you have to sum overall modes. And what was important was the density of modes at the frequency. And now the frequency is omega. So when we calculated the spontaneous rate-- emission rate-- the decay of the excited state k, we had an omega cubed dependence at the resonance frequency-- at the resonant frequency for the transition ka. But now we are interested in thedensity of states at frequency omega. factor. This may be even more relevant at least in the research which is done in my group and in other groups at MIT, are again Raman processes. If you can't reach the upper state with a single photon like people in [INAUDIBLE]-- they may just use two photons. But this is more limit because they don't have the laser, which can bridge the gap. In situations where you work with alkali atoms, we are often very happy with-- we have one resonant line and we can do all the laser cooling, everything we want. what we're doing with the atoms, cannot be done on the d1 or d2 line. And therefore, we often use a two-level system, which consists of two hyperfine states because then there is no broadening to do spontaneous emission. But I think you get the gist now, and it will become even clearer later on, that often when you do a transition between two ground state levels, a lot of the physics is the same as of a single photon. You just replace your single photon Rabi frequency by two-photon Rabi Frequency. But now with the benefit of having a very narrow resonance. most important aspect of two-photon processes 99% of the research people in our field are involved is actually in the form of Raman processes. I think as you realize when you go from the two- photon absorption to Raman process, there's nothing you have to re-learn. You just have to be careful with the signs of omega 1 and omega 2. And this probability is just re-writing in a different way what we are doing. So if I would ask you now what is the rate-- what isThe rate of the spontaneous Ramanprocess, well, it is the probability to be in the intermediate state. have used, is the Rabi frequency of the first step squared, divided by the detuning squared. So this is the probability to be in the excited state. Now, the spontaneous emission occurs with Einstein's a coefficient connecting the intermediate state to the ground state. And it doesn't really matter if the power is delivered by a laser or a light bulb. The rate for this process is the same. And this actually was the discovery by Raman, which was rewarded with the Nobel Prize. When we simply want to change the momentum state of an atom, we have two lasers. We go up and down. We are not changing the internal state. But it is still a Raman process because state a and b differ by the photon recoil. So that's also important for a lot of research within the CUA. It may have 2h [INAUDIBLE], two-photon recoil different. And therefore, as long as, in quantum physics, one quantum number is different, it is a different state. cycling transition. Well, when the atom goes up and then emits a photon, there is recoil involved. So actually what you're doing is on the cycling transition, you cycle it through many, many spontaneous Raman processes. So this is the correct description of resonant fluorescence and Rayleigh scattering. Any questions? Good. I've just mentioned that when we do Reyleigh scattering, we have to consider that the photons have momentum, and this takes us to another state. Let's now be a little bit more careful and consider what is the role of the momentum in the transition. now is I want to talk about recoil and Doppler shifts in a two-photon process and see how it will affect the line shape. All we have to do is-- or maybe let me back up. You should maybe consider what I've discussed so far, is the situation of an atom which has no motion. We could just fully focus on the internal degree of freedom. And just to remind you, we have discussed two ways how you can eliminate motion out of the picture. One is assume the atom has infinite mass. well, you give the atom an infinite mass by tightly connecting it to the laboratory. And this is what tight confinement in an ion or atom trap does. But now, we are kind of going beyond this restriction. We are now saying, OK, now we allow the atom to move. And we can deal with that by simply saying when the atom has a velocity v, we can transform-- we can just use the Galilean transformation. However, the atom, due to its velocity, sees a slightly different frequency. So therefore, we have our Lorentzian. If you have a single photon, you always transfer momentum to the atom. But if you have two photons, the two momenta can cancel. And this is actually a powerful method to avoid Doppler broadening in spectroscopy. It is as if we had a super photon, which drives one transition, but the momentum of this super photon is not the same. If k1 and k2 end up here with a minus sign, it may eliminate Dooppler shifts, maybe even completely. is now the sum or the difference of the two momenta of the photon. And if you wonder, how do you sum them up? What really matters is what is after the two photons have been exchanged, what is the total momentum transferred to the atom. And you see that if you have two-photon absorption, if the two laser beams are counter-propagating, thetotal momentum transfer is zero. If you have a Raman process where you absorb one photon and then emit it, the momentum transfer are zero, assuming similar frequencies. of methods of practical importance for eliminating the first order Doppler shift. Since hydrogen is of methological importance, measurements of-- fundamental measurements of the Lamb shift, comparisons with QED calculations, measurement of the Rydberg constant-- these are all done by hydrogen spectroscopy. But you cannot, of course, suppress the process where you absorb two photons from the left or from the right. And therefore, you have sort of a broad pedestal. So the pedestal is where you take one photon-- both photons from same side, whereas the Dooppler free peak is whereyou have photons from counter-propagating directions. line width-- so what is the delta, the line broadening you to the second order Doppler effect, in relation to the transition frequency? So just give me a second. Then this omega cancels and we have an expression which is sort of interesting. It is mv squared. It's the energy-- the thermal energy-- but since we have normalized it to the Transition frequency, it becomes now the Thermal energy relative to the rest mass of the atom. You would think, well, this must be really tiny. Well, it is tiny. The lifetime of the 2s state is actually due to two-photon emission. Two photons in series. This is the way how the2s state decays. You can't know for certain that the velocity distribution of the atoms in your laser beam is exactly at room temperature. You really have to go to low temperature, go to cryogenic temperatures. Or ultimately, if you can't correct for it, you would not be able tocorrect for it at roomTemperature. It is not limited at all by the natural lifetime of 2s transition. for the lifetime, which is a fraction of a second. They cool the hydrogen by collisions with liquid helium, cooled vaults, to maybe a Kelvin or so, three hundred times below room temperature. And this has been important to reach this precision. And still, I think, even at Kelvin temperature, the second order Doppler shift is one of the important-- is oneof the important systematics. OK. Any questions? Yes. Just-- very lightly-- I would have thought [INAUDIBLE]. PROFESSOR: That's correct. line, which is sufficiently sharp, sufficiently narrow, and also insensitive to magnetic fields and electric fields. But people who want to measure fundamental constants-- the Rydberg constant-- want to compare lame shift with first principle QED calculations. This is the case for hydrogen. And, actually, with some advance in the numeric calculation of wave functions and all that, it may also be possible to do it with helium. I think so far it hasn't kind of-- helium has not replaced hydrogen. It's still a big part of the universe. Audience: Going back to the two-photon Raman process where you had the second spontaneous emission, I just want to clarify. In all atoms other than helium and hydrogen, you would be limited by the infeasibility of many electron calculations. This is off resonance scattering. And if you ask me, when do you have a situation where you first absorb the photon and then emit it? I would like to know that. You always-- you should always use a two- photon picture. If you allow in your head any picture of first absorption then emission, that's where all the wrong answers come from. Photon in, photon out-- should be described together, unless you have some form of de-coherence which decouples the two processes. But that's a wonderful opening to our next chapter, namely coherence. To what extent-- we just discussed one aspect of it and we come back to this in this chapter-- to what extent is the photon a two-photon? In this last big chapter of this course, coherence in all its different manifestations. I think this is rather unusual. I don't know of any textbook or any other course where this is done. This is similar in spirit to what we did on line broadening. I felt I could create spatial connections by discussing all possibly line shifts and line broadenings together. And now I hope you will also see certain common traits if I discuss together all the different manifestations of coherence. So what we want to discuss is-- we start out by talking about coherence of a single atom. We can have coherence between two levels. qualitative features which come into play when we have three levels-- like lasing without inversion, like electromagnetically-induced transparencies, for those of you who have heard about it. On the other hand, I can reassure you, I don't think there's anything fundamental to be learned by going to four, five, and six levels, so we will stop at three levels. We can have-- so this is a single atom. But we can also have coherence between different atoms. And phenomena we want to discuss is superradiance. Atoms which I will not discuss this semester, and this is the situation of Bose-Einstein condensates and macroscopic wave functions. This is covered together with quantum gases in-- this is discussed in the context of quantum gases. So having these very different manifestations of coherence, I want to try now to give you a definition ofCoherence. But it's a bit difficult because I Want to cover with my definition all the cases I know. But with those examples in mind, for me coherence-- we have the phenomenon of coherent. Coherence exists if there is a well-defined phase. Atomic spectroscopy is an important technique and important tool for measurements. Energy levels can tell us something about magnetic fields through Zeeman shifts. But this is very deeply connected to coherence and the phase because the relative phase between two states is nothing. It's subtle but trivial at the same time. We want to get the most precision in a reproducible energy level. This is the situational of atomic clocks. We are interested in the energy levels. But pretty much when we use atomic Spectroscopy for any application, we areinterested in theEnergy levels. Coherence is the time integral over the energy difference between two levels. The phase evolved between the two levels is the difference frequency times time or time integrated dt. So therefore, when we are talking about coherence, how can we maintain longer coherence between energy levels? How can we create coherence in three level systems? This is actually intricately related to the fact that we can obtain more precise information about the energy levels. Anyway, this is a very general introduction to coherence. of spontaneous emission. The system involves with the following operator, and this is the operator which completely describes the interaction of an atom with the electromagnetic field. The fact that we have a unitary evolution with this operator is 100% or 110% true. But this operator will actually lead to final states of the photon field, which may not have a specific phase. And this is actually what I want to work out with you in-- maybe even today, I think ten minutes may be enough-- what is really the information-- the phase information-- which we have in a photon, which has been spontaneously emitted. If you ignore the position where the atom has scattered the light, then you have maybe optical path length differences. This is why quite often when we scatter light for many, many atoms, we're not even asking for the phase. So it's always possible, of course, to lose the phase by not controlling every aspect of your experiment. So B is always possible. But for so many reasons that I don't want to discuss it, but the measurement process is very relevant. And so, therefore, I would have answered C here. infinite mass-- no Doppler shift, we just put it. And we put it in a cavity that it can only interact with a single mode of the electromagnetic field. So this is a fundamental situation. And a lot of the general situations, you get by just summing up over many modes. It just messes things up. And this is more in the spirit of answer B, that you perform partial trace and average over many states. But let's now pinpoint what I think is intellectually the most important one, the pure situation where an atom is just talking to a one mode. pulse which has a pulse aimed between zero and pi. Depending what the pulse angle is, it will admix the ground state and the excited state. And in case of a pi pulse, we have 100% in the excitedState. But now, and this is what coherence is about, there is a very specific phase. And this phase phi comes from the laser. If you excite the atom with a laser beam but it has a phase shift, then the atomic wave function is phase shifted. Professor: We know for sure the atom is in the ground state. But the excited state with zero photon will actually do Rabi oscillation. Professor: If you regard ground and excited state as a two-level system, every quantum mechanical subtlety of the atomic system has now disappeared. But everything which was coherent, which was a phase which was interesting about the atom has been transferred to the photon field. Yes? Do you want to have an alpha e there also? Professor: Oh yes, please. the atom has been perfectly matched. Perfectly mapped onto the photon field. Phi-- we started out by phi being the phase of the laser. And if the laser is in a coherent state, in a homodyne measurement we can measure phi to any accuracy you want. This phase phi has been now perfectly imprinted into a two-level system for the atom. And now it appears mapped into aTwo-levelsystem for the photons. But if we are now doing a measurement either on the atomic system or on the photonic system, we are limited. this is what we want to discuss on Wednesday. And this is what I referred to as the fundamental limit of spontaneous emission because we have not lost any coherence here. It's just if the phase is only imprinted in one particle-- one particle quantum physics sets us a limitation. Oh well, we can read out the phase phi. OK. Any question? To be continued on Monday. Back to Mail Online home. back to the page you came from. Click here to read the full interview.

ROUGE-1: 61.26, ROUGE-2: 59.00, ROUGE-L: 56.92
BERTScore: 78.71

==============================================
==================== [83/100] ====================
Summary:
Lecture eight is about deep learning software. This is a super exciting topic because it changes a lot every year. As usual, a couple administrative notes before we dive into the material. Project proposals for your course projects were due on Tuesday. We're in the process of assigning TA's to projects based on what the project area is and the expertise of the TA's. So we'll have some more information about that in the next couple days I say. I want to get started. Remember to stop your Google Cloud instances when you're not working to try to preserve your credits. For assignment two you really only need to use GPU instances for the last notebook. For all of the several notebooks it's just in Python and Numpy so you don't need any GPUs for those questions. And the final reminder is that the midterm is coming up. It's kind of hard to think about, but we'll get those grades back to you as soon as we can.think. The midterm will be in class on Tuesday, five nine. It'll be sort of pen and paper working through different kinds of, slightly more theoretical questions to check your understanding of the material that we've covered so far. And I think we'll probably post at least a short sort of sample of the types of questions to expect. So just, Yeah, yeah, so that's what we've done in the past is just closed note, closed book, relatively just like want to check that you understand the intuition behind most of the stuff we've presented. Small tweaks on top of vanilla SGD, are relatively easy to implement but can make your networks converge a bit faster. We also talked about regularization, especially dropout. And we saw that this was kind of a general pattern across many different types of regularization in deep learning, where you might add some kind of noise during training, but then marginalize out that noise at test time so it's not stochastic attest time. And finally, we talked about transfer learning where you can maybe download big networks that were pre-trained on some dataset and then then use them to learn. fine tune them for your own problem. And this is one way that you can attack a lot of problems in deep learning, even if you don't have a huge dataset of your own. So today we're going to shift gears a little bit and talk about some of the nuts and bolts about writing software and how the hardware works. We'll also talk about several of the major deep learning frameworks that are out there in use these days. So first, we've sort of mentioned this off hand a bunch of different times, that computers have CPUs, computers have GPUs. This is a shot of my computer at home that I built. And you can see that there's a lot of stuff going on inside the computer. The CPU is the Central Processing Unit. That's this little chip hidden under this cooling fan. And the GPUs are these two big monster things that are taking up a gigantic amount of space. But the CPU is actually relatively small piece. It's a relatively small thing inside the case. So, maybe, hopefully you know what most of these parts are. The GPU is called a graphics card, or Graphics Processing Unit. These were really developed, originally for rendering computer graphics, and especially around games and that sort of thing. In deep learning we kind of have mostly picked one side of this fight, and that's NVIDIA. So if you guys have AMD cards, you might be in a little bit more trouble if you want to use those for deep learning. The downside of a GPU is that each of those cores, one, it runs at a much slower clock speed. and GPUs is this idea of memory. Right, so CPUs have some cache on the CPU, but that's relatively small and the majority of the memory for your CPU is pulling from your system memory, the RAM. Whereas GPUs actually have their own RAM built into the chip. There's a pretty large bottleneck communicating between the RAM in your system and the GPU. And for the Titan XP, which again is maybe the current top of the line consumer card, this thing has 12 gigabytes of memory local to theGPU. NVIDIA has this CUDA abstraction that lets you write code that kind of looks like C, but executes directly on the GPUs. It's actually really tough to write CUDA code that's performant and actually squeezes all the juice out of these GPUs. You have to be very careful managing the memory hierarchy and making sure you don't have cache misses and branch mispredictions and all that sort of stuff. So as a result NVIDIA has released a lot of libraries that implement common computational primitives that are very very highly optimized for GPUs. how it works and what are the basic ideas even if you're not writing it yourself. So if you want to look at kind of CPU GPU performance in practice, I did some benchmarks last summer comparing a decent Intel CPU against a bunch of different GPUs that were sort of near top of the line at that time. And these were my own benchmarks that you can find more details on GitHub, but my findings were that for things like VGG 16 and 19, ResNets, various ResNet, then you typically see something like a 65 to 75 times speed up when running the exact same computation on a Pascal Titan X. sort of caveat here is that you always need to be super careful whenever you're reading any kind of benchmarks about deep learning. And you kind of need to know a lot of the details about what exactly is being benchmarked in order to know whether or not the comparison is fair. So in this case I'll come right out and tell you that probably this comparison is a little bit unfair to CPU. But that being said, I think there are still pretty substantial speed ups to be had here. code on GPU, you should probably almost always like just make sure you're using cuDNN. If you're not careful you can actually bottleneck your training by just trying to read the data off the disk. Another common strategy is to use multiple threads on the CPU that are pre-fetching data off RAM or off disk, buffering it in memory, in RAM so that then you can continue feeding that buffer data down to the GPU with good performance. So that's kind of the brief introduction to like sort of GPU CPU hardware in practice when it comes to deep learning. be you have this sequential process where you first read data off disk, wait for the data, then feed the minibatch to the GPU, then go forward and backward on the GPU. And if you actually have multiple, like instead you might have CPU threads running in the background that are fetching data off the disk such that while the, you can sort of interleave all of these things. And thankfully if you're using some of these deep learning frameworks that we're about to talk about, then some of this is possible. The landscape of deep learning frameworks is super fast moving. In the last year TensorFlow has gotten much more popular. Caffe2 and PyTorch are new frameworks from Facebook that I think are pretty interesting. Paddle, Baidu has Paddle. Microsoft has CNTK, Amazon is mostly using MXNet. There's a ton of other frameworks as well, but I'm less familiar with, and really don't have time to get into. But it's kind of an interesting shift that we've seen in the landscape over the last couple of years. These ideas have really moved a lot from academia into industry. Deep learning frameworks enable you to easily build and work with these big hairy computational graphs without kind of worrying about a lot of those bookkeeping details yourself. Another major idea is that, whenever we're working in deep learning we always need to compute gradients. And we'd like to make this automatically computing gradient, you don't want to have to write that code yourself. You want that framework to handle all these back propagation details for you so you can just think about writing down the forward pass of your network and have the backward pass sort of come out for free without any additional work. In Numpy, you can just kind of write down in Numpy that you want to generate some random data. And it's really easy to do this in Numpy. But then the question is like suppose that we want to compute the gradient of C with respect to X, Y, and Z. So, if you're working in Nupy, you kind of need to write out a set of operations that you can do to get the result you're looking for. A. Combine A and Z to produce B and then finally we're going to do some maybe summing out operation on B to give some scaler final result C. Numpy is definitely CPU only. And you're never going to be able to experience or take advantage of these GPU accelerated speedups if you're stuck working in Numpy. So, kind of the goal of most deep learning frameworks these days is to let you write code in the forward pass that looks very similar to Numpy, but lets you run it on the GPU and lets you automatically compute gradients. So in this little code snippet, we've solved these two problems. We're running our code on the CPU and we're having the framework compute all the gradients for us. TensorFlow lets you train a fully connected network in just a few lines of code. You'll first have a bunch of code that builds the graph, then you'll go and run the graph and reuse it many many times. So here we're defining this X, Y, w1 and w2, and we're creating these tf.placeholder objects. So these are going to be input nodes to the graph. And then we're going to use those input slots which are now kind of like these symbolic variables. We're doing different TensorFlow operations to set up what computation we want to run. In the previous example, we were actually updating the weights outside of the computational graph. But now because we want these weights to live inside the graph, this operation of updating them needs to also be an operation inside the computationalgraph. So now when we run this graph and when we train the network, now we need to run the graph once with a little bit of special incantation to tell TensorFlow to set up these variables. And here, we're now only feeding in the data and labels X and Y and the weights are living inside thegraph. And then you might think that this would train theNetwork, but there's actually a bug here. The question is does tf.group return none? So this gets into the trickiness of TensorFlow. So when you execute the graph, and when you tell, inside the session.run, when we told it we want it to compute the concrete value from updates, then that returns none. That's just the way that updates works. So it's kind of some Tensor Flow magic that's going on there. Maybe we can talk offline if you're still confused. [student's words obscured due to lack of microphone] TensorFlow gives you some convenience operations that do that kind of stuff for you. So here we're using a. tf.train.GradientDescentOptimizer and we're telling it what learning rate we want to use. And now we call optimizer.minimize of loss and now this is a pretty magical. thing, because now this call is aware that these variables w1 and w2 are marked as trainable by default, so then internally, inside this optimizer, it's going in and adding nodes to the graph which will compute gradient of loss. In the previous example we were computing the loss explicitly using our own tensor operations. TensorFlow gives you a bunch of convenience functions that compute these common neural network things for you. So in this case we can use tf.losses.mean_squared_error and it just does the L2 loss for us so we don't have to compute it ourself. And in this example we've actually not put biases in the layer because we're not using biases. So another kind of weirdness here is that we had to explicitly define our inputs and define our weights and then like chain them together in the forward pass using a matrix multiply. that would be kind of an extra, then we'd have to initialize biases, we'd need to get them in the right shape. We would have to broadcast the biases against the output of the matrix multiply and you can see that that would kind of be a lot of code. So as a result, there's a bunch of sort of higher level libraries that wrap around TensorFlow and handle some of these details for Tensor Flow. And once you get to like convolutions and batch normalizations and other types of layers this kind of basic way of working, of having these variables, having these inputs and outputs could be a little bit unwieldy. TensorFlow is an open-sourceensorFlow framework. It's used by Google to train neural networks. The code example shows how to use TensorFlow to train a neural network. It uses the xavier initializer object to set up an initialization strategy for the data and labels. It also sets up variables for those with the right shapes that are kind of inside the graph but a little bit hidden from us. And in fact if you run this code, it converges much faster than the previous one because the initialization is better. There's a lot of different higher level libraries that people build on top of TensorFlow. And it's kind of due to this basic impotence mis-match where the computational graph is relatively low level thing. So that's what these various packages are trying to help you out and let you work at this higher layer of abstraction. Another very popular package that you may have seen before is Keras. Keras is a very beautiful, nice API that sits on Tensorflow. Top of TensorFlow and handles sort of building up these computational graph for you up in the back end. By the way, Keras also supports Theano as a back end, so that's also kind of nice. And in this example you can see we build the model as a sequence of layers. We build some optimizer object and we call model.compile and this does a lot of magic in theback end to build the graph. And now we can call. model.fit and that does the whole training procedure for us magically. that out to keep the code clean. But you saw at the beginning examples it was pretty easy to flop all these things between CPU and GPU and there was either some global flag or some different data type or some with statement. So there's actually like this whole large set of higher level TensorFlow wrappers that you might see out there in the wild. And it seems that like even people within Google can't really agree on which one is the right one to use. So Keras and TFLearn are third party libraries that are out there on the internet by other people. But there's these three different ones, tf.layers, TF-Slim and TF.contrib.learn that all ship with Tensor Flow. all kind of doing a slightly different version of this higher level wrapper thing. There's another framework also from Google, but not shipping with TensorFlow called Pretty Tensor that does the same sort of thing. And I guess none of these were good enough for DeepMind, because they went ahead and released their very own high level Tensor Flow wrapper called Sonnet. So I wouldn't begrudge you if you were kind of confused by all these things. But you have a lot of options, so that's good. but Tensorboard you can add sort of instrumentation to your code and then plot losses and things as you go through the training process. TensorFlow also let's you run distributed where you can break up a computational graph run on different machines. That's super cool but I think probably not anyone outside of Google is really using that to great success these days. A side note is that a lot of the design of Tensor Flow is kind of spiritually inspired by this earlier framework called Theano from Montreal. PyTorch from Facebook is kind of different from TensorFlow in that we have sort of three explicit different layers of abstraction inside PyTorch. So it has this tensor object which is just like a Numpy array. It's just an imperative array, it doesn't know anything about deep learning, but it can run with GPU. And we have a module object that is a neural network layer that you can compose together these modules to build big networks. It kind of looks a lot like Tensor Flow. PyTorch tensors are just like Numpy arrays. They run on the GPU so all you have to do to make this code run on GPU is use a different data type. In PyTorch you can define your own new autograd functions by defining the forward and backward in terms of tensors. So here, if X is a variable, then x.data is a tensor and x.grad is another variable containing the gradients of the loss with respect to that tensor. So this ends up looking quite like the Numpy case, except all theGradients come for free. PyTorch provides these optimizer operations that kind of abstract away this updating logic and implement fancier update rules like Adam and whatnot. So in the forward pass we can use both our own internal modules as well as arbitrary autograd operations on variables to compute the output of our network. And now the rest of this code for training this thing looks pretty much the same. Where we build an optimizer and loop over and on ever iteration feed data to the model, compute the gradients with loss.backwards, call optimizer.step. PyTorch provides pretrained models. And this is probably the slickest pretrained model experience I've ever seen. You just say torchvision.models.alexnet pretained=true. That'll go down in the background, download the pretrained weights for you if you don't already have them, and then it's right there, you're good to go. PyTorch also has, there's also a package called Visdom that lets you visualize some of these loss statistics somewhat similar to Tensorboard. a chance to play around with this myself so I can't really speak to how useful it is. Tensorboard actually lets you visualize the structure of the computational graph. And Visdom does not have that functionality yet. PyTorch is kind of an evolution of, kind of a newer updated version of an older framework called Torch which I worked with a lot in the last couple of years. It is pretty much better in a lot of ways than the old Lua Torch, but they actually share a much of the same back end C code for the back end. Torch is actually in Lua, not Python, unlike these other things. So learning Lua is a bit of a turn off for some people. Torch is also older, so it's more stable, less susceptible to bugs, there's maybe more example code for Torch. In PyTorch it's in Python which is great, you've got autograd which makes it a lot simpler to write complex models. In Lua Torch you end up writing a lot of your own back prop code sometimes, so that's a little bit annoying. different where we're actually building up this new computational graph, this new fresh thing on every forward pass. That's called a dynamic computational graph. One kind of nice idea with static graphs is that because we're kind of building up one computational graph once, and then reusing it many times, the framework might have the opportunity to do optimizations on that graph. So I'm not too sure on exactly what the state in practice of TensorFlow graph optimization is right now, but at least in principle, this is one place where static graph really, you can have the potential for doing this. optimization in static graphs where maybe it would be not so tractable for dynamic graphs. Another kind of subtle point about static versus dynamic is this idea of serialization. So with a static graph you can imagine that you write this code that builds up the graph and then once you've built the graph, you have this data structure in memory that represents the entire structure of your network. And now you could take that data structure and just serialize it to disk. And then you could later rear load that thing and then run that computational graph without access to the original code that built it. use one weight matrix, if Z is negative we want to use a different weight matrix. And we just want to switch off between these two alternatives. In PyTorch because we're using dynamic graphs, it's super simple. Your code kind of looks exactly like you would expect, exactly what you would do in Numpy. You can just use normal Python control flow to handle this thing. And the code is very clean, easy to work with. Now in TensorFlow the situations is a little bit more complicated because we build the graph once, this control flow operator. The problem is that because we only build the graph once, all the potential paths of control flow that our program might flow through need to be baked into the graph at the time we construct it before we ever run it. In this case this tf.cond.kind of needs to be an explicit operator in the TensorFlow graph. And now, so them you can see that we have this TF.cond call which is kind of like a Tensor Flow version of an if statement, but now it's baked in the computational graph rather than using Python control flow. have loops. We can just kind of use a normal for loop in Python to just loop over the number of times that we want to unroll. Now depending on the size of the input data, our computational graph will end up as different sizes. But that's fine, we can just back propagate through each one, one at a time. Now in PyTorch this is super easy. We just want to compute this same recurrence relation no matter the length of our sequence of data. TensorFlow this becomes a little bit uglier. And again, because we need to construct the graph all at once up front, this control flow looping construct again needs to be an explicit node in the TensorFlow graph. So in this case, for this particular recurrence relationship you can use a foldl operation and pass in, sort of implement this particular loop. But what this basically means is that you have this sense that Tensor Flow is almost building its own entire programming language, using the language of computational graphs. Super new paper being presented at ICLR this week in France. Initial impression was that it does add some amount of dynamic graphs to TensorFlow but it is still more awkward to work with than the sort of native dynamic graphs you have in PyTorch. So one option is recurrent networks. So you can see that for something like image captioning we use a recurrent network which operates over sequences of different lengths. In this case, the sentence that we want to generate as a caption is a sequence and that sequence can vary depending on our input data. the thing where depending on the size of the sentence, our computational graph might need to have more or fewer elements. So that's one kind of common application of dynamic graphs. For those of you who took CS224N last quarter, you saw this idea of recursive networks where sometimes in natural language processing you might, for example, compute a parsed tree of a sentence. So having a neural network that kind of works, it's not just a sequential sequence of layers, but instead it's kind of working over some graph or tree structure. point. So this type of thing seems kind of complicated and hairy to implement using TensorFlow, but in PyTorch you can just kind of use like normal Python control flow and it'll work out just fine. Another bit of more researchy application is this really cool idea that I like called neuromodule networks for visual question answering. So here the idea is that we want to ask some questions about images where we maybe input this image of cats and dogs, there's some question, what color is the cat, and then internally the system can read the question. dogs? Now we have maybe the same basic set of modules for doing things like finding cats and dogs and counting, but they're arranged in a different order. So we get this dynamism again where different data points might give rise to different computational graphs. But this is a bit more of a researchy thing and maybe not so main stream right now. But as kind of a bigger point, I think that there's a lot of cool, creative applications that people could do with dynamic computational graphs and maybe there aren't so many right now, just because it's been so painful to work with them. is this framework from Berkeley. Which Caffe is somewhat different from the other deep learning frameworks. You kind of just call into these pre-existing binaries, set up some configuration files and in many cases you can train on data without writing any of your own code. So, you may be first, you convert your data into some format like HDF5 or LMDB and there exists some scripts inside Caffe that can just convert like folders of images and text files into these formats. You need to define, now instead of writing code to define the structure of your computational graph, instead you edit some text file called a prototxt. inner product, we compute some loss and the whole structure of the graph is set up in this text file. One kind of downside here is that these files can get really ugly for very large networks. So for something like the 152 layer ResNet model, which by the way was trained in Caffe originally, then this prototxt file ends up almost 7000 lines long. So people are not writing these by hand. People will sometimes will like write python scripts to generate these prototext files. Just run the Caffe binary with the train command and it all happens magically. Cafee has a model zoo with a bunch of pretrained models, that's pretty useful. Caffe has a Python interface but it's not super well documented. You kind of need to read the source code of the python interface to see what it can do, so that's kind of annoying. But it does work. So, kind of my general thing about Caffe is that it's maybe good for feed forward models, it'smaybe good for production scenarios, because it doesn't depend on Python. Google has one major deep running framework, which is TensorFlow, where Facebook has these two, PyTorch and Caffe 2. Google's kind of trying to build one framework to rule them all that maybe works for every possible scenario for deep learning. This is kind of nice because it consolidates all efforts onto one framework. It means you only need to learn one thing and it'll work across many different scenarios including like distributed systems, production, deployment, mobile, research, everything. like running in production, running on mobile devices, PyTorch doesn't have a lot of great support. Instead, Caffe 2 is kind of geared toward those more production oriented use cases. TensorFlow is a pretty safe bet for just about any project that you want to start new, right? Because it is sort of one framework to rule them all. However, you probably need to pair it with a higher level wrapper and if you want dynamic graphs, you're maybe out of luck.

ROUGE-1: 47.84, ROUGE-2: 46.25, ROUGE-L: 45.09
BERTScore: 75.06

==============================================
==================== [84/100] ====================
Summary:
This is part 3 in our series on distributed word representations. We're going to be talking about vector comparison methods. To try to make this discussion pretty intuitive, I'm going to ground things in this running example. On the left, I have a very small vector space model. We have three words, A, B, and C. And you can imagine that we've measured two dimensions, dx and dy. And then you can see graphically that B and C are pretty close together. And A is kind of lonely down here in the middle. corner, the infrequent one. We can measure the Euclidean distance between vectors u and v if they share the same dimension n by just calculating the sum of the squared element wide differences, absolute differences, and then taking the square root of that. Let's look at that in terms of this space. So here we have our vector space depicted graphically, A, B, and C. And you can see that Euclideans distance is capturing the first perspective that we took on the vector space, which unites the frequent items. B and C as against the infrequent one A. As a stepping stone toward cosine distance, which will behave quite differently, let's talk about length normalization. Given the vector u of dimension n, the L2 length of u is the sum of the squared values in that matrix. And then we take the square root. That's our normalization quantity there. And A and B are now close together. Whereas B and C are comparatively far apart. And that has come entirely from the normalization step. we changed the space as I showed you before. So they're all up here kind of on the units here. And notice that the actual values that we get out are the same whether or not we did that L2 norming step. And that is because cosine is building the effects of L2norming directly into this normalization here in the denominator. There are a few other methods that we could think about or classes of methods. I think we don't need to get distracted by the details. their generalizations to the real valued vectors that we're talking about. And the other class of methods that you might see come up are probabilistic methods which tend to be grounded in this notion of KL divergence. Now I've alluded to the fact that the cosine distance measure that I gave you before is not quite what's called the proper distance metric. Let me expand on that a little bit. To qualify as a properdistance metric, a vector must be valued as a probability value. comparison method has to have three properties. That is, it needs to be symmetric. It needs to give the same value for xy as it does to yx. KL divergence actually fails that first rule. And crucially, it also needs to satisfy what's called the triangle inequality. It just happens that this distance here is actually greater than these two values here, which is a failure of the statement of the triangleequality. But this is also kind of a useful framework. different choices that we could make, of all the options for vector comparison, suppose we decided to favor the ones that counted as true distance metrics. Then that would at least push us to favor Euclidean distance, Jaccard for binary vectors only, and Jensen-Shannon distance if we were talking about probabilistic spaces. And we would further amend the definition of cosine distance to the more careful one that I've given here, which satisfies the triangle inequality as well as the other two criteria. And by this kind of way of dividing the world, we would also reject matching J Accard, Dice, Overlap, KL divergence, and symmetrical KL divergence. And so that might be a useful framework for thinking about choices in this space. Right, these shortcomings might be addressed through weighting schemes though. But here's the bottom line. There is valuable information in raw frequency. If we abstract away from it, some other information might come to the surface. But we also might lose that important frequency information in distorting the space in that way. And it can be difficult to balance these competing pressures. Finally, I'll just close with some code snippets. Our course repository has lots of hand utilities for doing these distance calculations and also length norming your vectors. the results for "bad" using cosine distance in cell 12 and Jaccarddistance in cell 13. And I would just like to say that these neighbors don't look especially intuitive to me. It does not look like this analysis is revealing really interesting semantic information. But don't worry, we're going to correct this. We're going. to start to massage and stretch and bend our vector space models. And we will see much better results for these neighbor functions and everything else as we go through that material.

ROUGE-1: 56.71, ROUGE-2: 54.84, ROUGE-L: 56.10
BERTScore: 74.12

==============================================
==================== [85/100] ====================
Summary:
liyan blake: William Wordsworth is kind of out there some of his contemporaries thought he was insane you know nowadays maybe he would be heavily medicated. There is something in the madness of this man which interests me more than the sanity of Lord Byron and Walter Scott so something about this man is more interesting than these other people maybe there are some celebrities nowadays who are just so weird that they borderline genius in a way just because they're so out there and there's people that come about that are just like them. anything else that we've seen before that it's almost like a new art form does that kind of make sense. He was an individual who you know was into art and was into eventually you know religion and such became a big part of his life but his as an artist you know he was a very prolific poet but he was also big-time into painting we'll see some of his paintings later on but also a new type of art form kind of relief fetching where you kind of sketch out a negative of what you should have. fetching into a metal which would be a long long time and so he fetches out these scenes he edges in his poems into it and so it takes a lot of time a very time-consuming as it says that's why on that page it talks about how it can be the most some of the most valuable pieces of literary history that that have survived. You'll see some pictures of some of those etchings later on but in essence you know some of your money is relief itched stamped. the boundaries on and really became the form the more bear of it and a front-runner so very interesting individual and just just out there mentally just that not that we with the stuff we read today isn't gonna be like man that guy was weird it's just his personality is so different from some of those just normal people that we read about that it's like everybody else this guy would probably be a rock star nowadays you know for whatever his profession would be he probably would just be out there and everybody just thinks it's funny okay and he's a very successful person. and your parents don't know just throw out William Blake you might be right okay very very famous individual so we'll be covering in the next couple days the lamb by William Blake. Little lamb who made thee thus thou know whomade thee gave the life and bid thee feed by the stream and o or the mead gave the clothing of delight softest clothing woolly bright gave these such a tender voice making all the vales rejoice. I'll tell thee little lamb I'llTell thee he is call it by thy name for he calls himself a lamb. ultimately about God made you little lamb God madeYou he gave you these things. He gave you your clothes he gaveYou that little voice that you have. He is called by thy name so he calls himself a lamb so Jesus God religion okay you are created by those things and you have been given those things he is meek in his mild he became a little child I a child and thou a lamb we are called by his name so even though I'm a man and you're a Lamb we are we are the same okay now could the lamb be a symbol for something else could it. the field but somebody that is passionate about their religion and their faith you know the nature and the common man the shepherd person of the flock or even a child in a sense of children so it's a very short one and it's one that I believe is pretty easy to to comprehend and understand okay. "I believe it is one of the easiest to understand and understand," he says. "It's one of those things that is very, very easy to understand. It's very simple to understand"

ROUGE-1: 69.70, ROUGE-2: 65.87, ROUGE-L: 66.80
BERTScore: 78.55

==============================================
==================== [86/100] ====================
Summary:
CÃº Chulainn, hero of Ulster, stood at the ford at Cooley, ready to face an entire army singlehandedly. The army in question belonged to Queen Meadhbh of Connaught. Enraged at her husbandâ€™s possession of a white bull of awesome strength, she had set out to capture the fabled brown bull of Ulster at any cost. Unfortunately, the King of Ulster had chosen this moment to force the goddess Macha to race her chariot while pregnant. In retaliation, she struck down him and his entire army with stomach cramps. CÃº Chulainn and Ferdiad met in Scotland while training with the renowned warrior ScÃ¡thach. When they returned to their respective homes, they found themselves on opposite sides of a war. The Queen was impatient to get her hands on the prize bull, so she goaded him and questioned his honor until he had no choice but to fight. The two faced off at the ford, matching each other exactly in strength and skill no matter what weapons they used. But CÃº ChULainn had one last trick up his sleeve: their teacher had shared a secret with him alone. She told him how to summon the GÃ¡e Bulg, a magical. spear fashioned from the bones of sea monsters that lay at the bottom of the ocean. Cu Chulainn called the spear, stabbed Ferdiad to death, and collapsed. Meadhbh seized her chance and swooped in with the rest of her army to capture the brown bull. At last, the men of Ulster were recovering from their magical illness, and they surged out in pursuit. But they were too late: Queen Meadh Bh crossed the border unscathed, dragging the brown Bull with her. broken heart, leaving behind a land that would remain ravaged by Meadhbhâ€™s war for years to come. â€œI will never forget you,â€ he wrote to his son. â€˜I will always love you.â€™ â€œYou are my son,â€™ he replied, â€œand I will always be your son.â€ â€œAnd I will never leave you, my son. I will forever love youâ€™, he said, â€˜even though Iâ€™m no longer your sonâ€™.

ROUGE-1: 62.45, ROUGE-2: 57.46, ROUGE-L: 59.59
BERTScore: 71.42

==============================================
==================== [87/100] ====================
Summary:
The Underworld is actually a lovely place to "live" It boasts historic charm and eccentric neighbors with eternal ties to the area. The community even has its own guard dog, Cerberus. With Cerberus, you get three for the price of one! Heâ€™s just not a big fan of anyone leaving. And who would want to leave anyway? This is the Styxâ€” itâ€™S like the subterranean riviera. But youâ€™ve been here before; it was the source of the Trojan War. your almost complete invulnerability, of course! The Underworld also features four other waterways: Acheron, the river of woe; Cocytus, river ofwailing; Lethe, riverof oblivion; and Phlegethon, a great source of natural light. Here, you'll join the ranks of royalty and heroes. Cadmus over there once slayed a dragon! And Patroclus is around here somewhere, along with lots of other friends and foes. Tisiphone here guards the portal. Ixion was once a king. When he didnâ€™t pay his wedding dowry, his father-in-law, Deioneus, stole his horses to get even. Zeus miraculously took pity on him, and invited him to a Mount Olympian feast. There, it soon became clear that the disgraced king was trying to seduce Zeusâ€™s wife, Hera. So, Zeus contrived a trap: a fluffy cloud that resembled Hera exactly. When Zeus had proof of Ixion having his way with the cumulus, well, you could say it was all nimbus from there. First generation of mortals, enjoying privileges like dining with the gods. When Tantalus reaches for food, the branches grow taller. And when he stoops to quench his thirst, the water recedes. At their fatherâ€™s order, they beheaded their husbands on their wedding night. They must fill this basin with water, but, the trick is, their jars are cracked, so it always... just... leaks away. Oh, but don't worry! No leaky appliances for you. down againâ€” all for trying to cheat death. As you can see, Achilles, the Underworld is full of exciting amenities. Here, you don't have to worry about brutal wars or painful cycles of revenge. You can finally just put your feet up and relax. It's a great place to take a break from your daily life. It also has a great view of the city of Athens, which is one of the most beautiful cities in the world. It is also a great spot to take some time off from your regular life and recharge your batteries.

ROUGE-1: 71.73, ROUGE-2: 64.81, ROUGE-L: 65.62
BERTScore: 68.38

==============================================
==================== [88/100] ====================
Summary:
Professor Martin: Fluorescence is the emission of light not associated with heat. Luminescence is the general term; fluorescence is a little bit more specific. There are different types of luminescence, and you'll get to see some of those varieties. Professor Martin: We love to wow you with images of fluorescent cells and cells in action. But I want to step back and actually show you how that all came about.. Where do these fluorescent proteins come from? What are we looking for? How much protein engineering was done to make these such an amazingly useful set of molecules. Luminescence is the interaction of a chemical with another chemical to give luminescence. Another pretty useful type of luminescent is bioluminescent. I've done a lot of scuba diving in my life. And there's nothing more exciting than a scuba dive where you're trying to find out what's going on under the water. It's a great way to get a sense of the depth of the water, and how the water is moving. I think that's the most famous luminol sort of example. Many marine organisms undergo bioluminescence. It's a biological reaction that causes luminescence, which is a more specific term for fluorescence. In a cuttlefish shown here in this image in the corner where they are brightly lit at night. And actually, it's just a whole party there at night in the ocean where all sorts of organisms are signaling to other organisms through biolominescence and reactions such as luciferase reactions. So those are both important. But what we're going to talk about principally is Fluorescence. And you'll see all these, like, little fireworks. The first thing to learn about fluorescence is how to spell fluorescence. It actually is fluor, F-L-U-O-R-E-S. I cannot tell you how many papers, scientific papers I read where they spelled fluorescence wrong. So make it look like you know what you're talking about andSpell fluorescence correctly. It's one of those-- there's two or three amazingly accurate ways to spell it. There's another C in there. There we go, we snuggled that in. common typos in people's slides. One of them is spelling fluorescence wrong and the other one is spelling complement wrong. fluorescence is a key point. It's the absorption of light energy by a molecule. Lambda excitation of a particular wavelength. Once that molecule has absorbed light, there's a very transient period until the molecule lets out energy in the form of light. And returns back to its ground state now. So that the photo physics of fluorescence involves the excitations of a molecule with light of one energy. That light energy is at When you excite a molecule, you'll take it to the excited state. It'll sit and vibrate there a little bit. Then it will kick back energy out at a longer wavelength. And for the majority of the fluorescence experiments that we do in biology, the wavelengths that you see emission at are in the visible range. So what we're going to see is the relationship for the electromagnetic spectrum. And then look at some fluorescent dyes that are very, very commonly used in biology. very often related to what's around it. Why is that the case? It's because the excited state may behave differently in different environments. That's why you might see fluorophores experience a change in their fluorescence as a function of their environment. Is that clear to everyone? So the molecular environments, if I'm a fluorophore and I'm in water, I'm going to feel pretty differently in my excited state. It's pretty dramatic when you see it. So here, say, when you mix ethidium bromide with DNA, and it could be in a cell or a lysate from a cell. we've got a gel that we've run DNA on. We might have a set of standards. And in other places, we're looking for the size of DNA. Remember that great experiment we saw where we saw how quickly small and large pieces of DNA ran through an agarose gel? So here is what the DNA gel would look like if you soaked it ethidium bromide. So here's the gel as a ladder of bands. But then let's say you wanted to do some work on a piece of DNA and maybe ligated you see DNA pieces at different wavelengths that have different mobilities based on size. can avoid it. The other way is simply to soak a dye into the gel. And the dye, because of the positive charge here, the counter ion gets displaced. And it gets attracted to the DNA and associates with it quite tightly. So that would be a way that you would observe DNA bound to dye in a gel. This fluoresces a pretty long wavelength. So this fluoreces this bright orange that's actually at about 605. So you can see, this is really in the visible range. 605 would be right around here.  ethidium bromide is a dye that can get into cells. And we can look at DNA within cells. Here's a picture of how it would look. It slides into the DNA. And you can see over here, the structure of DNA. Now, there's a big problem here. Because you can't use DNA ethidiumbromide. It's pretty toxic. And it's the fact, more, think of what the.molecules. think of. what the DNA intercalator would do. dye does when it gets to the DNA. What would that do to things like replication and transcription? It just kind of messes it up. And so these are toxic dyes that can only be used in fixed cells to do observations of cells. So we use it a lot. We need to be careful of it because if it gets absorbed through our skin, it could get into our cells. And it could interfere with replication and other cellular processes. Because it would accumulate on our cellular DNA. it's a natural product that's isolated from bacteria. And it has this structure that also makes it a DNA intercalator. It's used as a cancer chemotherapeutic agent because it interferes with cell division and proliferation. So we actually exploit that property. But only with cells that we want to kill or stop dividing. So you could picture, well, I don't want to use something that's going to interfere with cells if I'm doing live cell imaging. Because I'm going to have trouble with the properties of the cells. DAPI and HOECHST, H-O-E-C-H-S-T, were discovered in a bio company in Germany. They are different kinds of dyes that fluoresce on binding to DNA. You can in fact substitute ethidium bromide with these dyes. But they bind to DNA pretty differently. And when those moleculesbind to DNA in water, they don't fluorescence. But when they bind. to DNA they fluorescent an intense an intense light. cyan blue. So that's at a shorter wavelength from the ethidium bromide. So taking a look at this structure, does anyone want to explain to me how the molecules might bind to DNA? We know intercalation is perpendicular to the axis of the DNA. So where, looking at this, do you think these bind? A while ago when I was talking about the structure of DNA, I like to think of DNA as having two grooves, two places where things combine to it. And that's a minor groove and then this big trench is what's called the major groove. was in the major groove, it would be swimming around in that groove. It's almost too big. So what's really cool about these dyes is they slide in between into the minor groove. And they also make some contacts with the phosphodiester backbone. They're literally in the groove. But there's some opportunity for electrostatic interactions. And in fact, they bind in particular regions of DNA where there's AT, not GC. Those are the places where there're just the pair of hydrogen bonds instead of the trio. in those grooves and you're dissociating easily, you're not going to interfere so much with replication. Does that make sense? So it's a weaker force. Now, I moved this slide up. I realized he was in the wrong place in the deck. This is just an application of the DNA minor groove binder CEOCHST. And in this case, we're looking at three cells. These two are not actively dividing. But take a look at this cell, it's actually clearly in the state preparing for cell division. and brighter when the chromosomes are in the state they're in for cell division. So you know that there's not DNA running around everywhere. It's literally in very specific places with the cell. These dyes will bind also to other nucleic acids. But they don't bind so well. Because those don't have the really repetitive, double stranded nucleotide structures. But there are other dyes that bind much more specifically to RNA. But we won't discuss that one. And one question here. So, if you're looking at cells, you're trying to observe cells, where else in the cell are you going to see DNA? So we can see the nuclear DNA. them. So nucleic acids seem to be something that we can definitely pinpoint with fluorescence. We can see where it is. We could follow cell division. For example, upon adding things to a cell, can you see-- remember very, very early on, we showed you movies of cells dividing. You could do that with this kind of dye because it's a non-toxic dye. So, great, so far, so good. The key thing, though, about biology is we have so many other entities within a cell that we want to be able to track and monitor. And what we needed, what is absolutely essential are reagents to do that. Professor Martin will talk about antibodies, which are agents of the human adaptive immune system. antibodies have been exploited intensively to study biology. Professor Martin will also talk about the nuts and bolts of the immune cells. And how it mounts a response to disease and other features.to recognize carbohydrates. But they're a little bit harder to bind to antibodies. But nevertheless, those are useful. To recognize a protein in a cell, you need a particular entity that will bind to that protein and show you where it is through some kind of signal. The adaptive immune system is an amazing system where you can do combinatorial biology and basically recognize any target entity you're interested in. So we're going to focus exclusively on the B cells and the way that they mature to produce soluble antibodies, based on what they've been challenged with. And when you challenge a B cell population with a foreign entity, the B cell populations will go into gear to produce antibodies that very specifically recognize that foreign target, because in the human adaptiveimmune system, that might be a wonderful tool to get rid of that foreign entity. is you have a bunch of different B cells. And there's something you want to recognize. What you might do is challenge this population with the cytokine. And then you will end up with B cells that produce a lot of an antibody to a cytokine such as EGF. Now what's so special about antibodies? They're pretty big molecules. The molecular weight is pretty high. But the key thing about antibodies is that the majority of the structure stays fairly constant. When B cells mature, there's loads of rearranging in that variable section. We always draw antibodies as this V shape. And an antigen-- you've heard this word before-- it's a foreign entity that's foreign to the immune system. The antigen binding site is right here at the tips of the antibody. The C's designate constant regions. See C all the way through here. And V's represent variable regions, which I've shown you. And at the tip of the V's are the antigen binding sites. So you're going to see more about antibodies in theimmune system. of different antibodies in the human system. If we had a gene for every single different light chain and every heavy chain, you know, our DNA would be completely swamped by being dedicated to the genetic material for antibodies. So instead there is a particular system which provides little portions of the DNA structure that are in little pieces of variable components that can get zipped together through transcription and slicing events. And this is what's known as the BDJ system. And you'll hear more about that from Professor Martin. When you get a population of B cells that produce antibodies to a particular target, these may be what are known as polyclonal. People also tend to use a great deal of monoclonal antibodies, because they are a lot more specific. So let's say you want to visualize in a cell-- let's move straight to a real targeted application. We want to make an antibody that might recognize actin and a different antibody that may recognize tubulin to take a look at. The way you make antibodies is by injecting. the foreign agent or antigen that you want to make an antibody to. The organisms are adapted not to recognize their own proteins unless there's some disorder like an autoimmune disease. So you would inject the rabbit with a human epitope, so for example human actin, generate antibodies with a specificity for actin. Alternatively, you might want to made a different antibody for tubulin. You've really got two types of macromolecule that can be interacted with a fixed cell. method that's directed just at antibodies. Then you've got your population. And you can throw a fluorophore dye at it and chemically label it. So it's a good point there. There's a lot of work being done now with antibodies from different organisms, in fact, you'll see them from camels. And they're also ones from shark. And the reason why they're kind of interesting is that they sort of have mini antibodies that are much more useful for technology. So let's see what we can do here. We can do fluorescence experiments. DAPI gets into a cell easily. But what about antibodies? Can they cross the plasma membrane to get into the cell to label a target? What do you think? Who says yes? who says no? Good. OK. You guys don't say much. But I know you know the answer here. They just can't float into cells. They're too large. So you have to fix the cells on a glass side and permeabilize them, for example, with methanol so that the antibodies can gain access to all parts of the cell. an antibody to tubulin. And you can look at the various colors of the fluorescence emission. So fluorescence is extremely valuable for looking a biological systems. Many of these fluorophores shine so brightly they can be used to look at in single molecules. Professor Martin described to you single molecule DNA sequencing. That actually exploits very bright fluorophore that is so bright that you can see just a few of them in one place very, very clearly. OK, how am I doing? I just want to actually leave you with something. Technology. So you could almost picture-- with all of what we've seen so far, you couldalmost target any cell with an antibody that's specifically raised to a particular protein that's within the cell. So we can see-- in the next class we'll discuss what the limitations of that are. But we've already talked about the fact that we have to use antibodies with fixed, not living anymore, cells. So they are really dyes that can only be used in that way. DNA microarrays are just the size of just a microscope slide. On this slide through arranged technologies, you can literally spot 40,000 distinct sequences of DNA in grids to recognize. So these DNA microarray can be used for profiling genetic material or for profiling not just DNA, but RNA, and we'll see how at the beginning of the next class, in order to probe for particular stretches of DNA that might be disease related and have single nucleotide polymorphisms. And the DNA microarray experiments show you how you can use fluorophores attached to DNA sequences.

ROUGE-1: 58.18, ROUGE-2: 55.62, ROUGE-L: 54.07
BERTScore: 66.49

==============================================
==================== [89/100] ====================
Summary:
 RAFAEL JARAMILLO: Today we're going to discuss the many D's of thermodynamics. The D's indicate exact differentials, which is equal to infinitesimal changes in state variables. In materials thermodynamics, the most common transformations that we talk about are transformations that take place at constant pressure and constant temperature. So of the three D's-- lowercase d, lowercase Greek d, and uppercase Greek D-- this is the first one. Greek D is often the hardest for students to understand when you first encounter it. To illustrate the concept of transformation quantities, it helps to draw state function surfaces. For example, we could have the entropy of phase alpha drawn as a function of temperature and pressure. In material science, our most common independent variables are pressure and temperature, because those are often the easiest for us to regulate in the laboratory. But in thermodynamics, we have many different transformation quantities that we keep track of, and we're illustrating this for entropy. is a function of those independent variables that measures the transformation quantity for the transformation between two different phases. For example, in the case of water, the quantity of water in the solution is the ratio of the water volume to the volume of the solution. For the example, the total water volume is the sum of the volumes of the solutions of the two phases. The total water content is the product of the proportions of the different water volumes. For more information, see the Wikipedia article on water.

ROUGE-1: 38.18, ROUGE-2: 31.62, ROUGE-L: 27.11
BERTScore: 69.01

==============================================
==================== [90/100] ====================
Summary:
In this video I'm going to be going over lung oscilation specifically the sites of where you osculate. We're going to go over normal breath sounds versus abnormal breath sounds. You can access the quiz and the notes over here or in the description below. In the next video I'll be performing an assessment on a patient and show you how to listen with your stethoscope to these sides. I'll also show you where you should hear bronchial versus bicular. chest in this illustration you have your right lung and your left lung and how I set up this illustration is that I wanted you to be able to see what is over the lungs. Whenever you're listening with your stethoscope you need to know where your clavicle is and certain intercoastal spaces because they correlate to which lobe of the lung you are listening to. It's really important you find C7 to T10 whenever you're assessing which we'll go over in the oscilation sites because this will help you know. Listen directly on the patient's chest with the diaphragm of your stethoscope. When listening on women you want to have the woman raise up her breast so you can get underneath those sights. The tissue will muffle the noise and you won't be able to hear that. Remember that whenever you're listening to the chest you're going to listen to the both the front and the back side and note a full cycle of in inspiration and expiration and what's the sound quality. give you trouble because as we went through the anatomy you have your spine here and you have the scapula here. Whenever you're having the patient breathe you want them to breathe in and out through their mouth slowly so you can hear those lungs inflate and deflate. A lot of patients who may have breathing difficulties you'll have to take your time with them because they can hyperventilate easily and and make sure your patient doesn't get dizzy and just taking your time. the chest first and what I like to do is I find the clavicle and um we're going to start at the apex of the lungs the top of the lung and we're Going to get our diaphragm which is the big part of your stethoscope and you are going to place it right slightly above that clavicles where the Apex is. Then you'reGoing to listen there for a full inspiration and expiration and then you're going over and compare on the other side. you will listen here compare your side and then just go a little bit lower maybe into the third intercal space and just keep listening to those upper loes. We're going to start from top to bottom and compare sides and work our way down and we're Going to start right above the scapula right where the Apex is and we'll go over to the other side and compare and then we're done now let's look at our sides on posterior just like with anterior in the posterior. remember to get the best sound quality so you can hear so you're not listening over the shoulder blades because that will muffle your sound and you won't be able to hear. Just stay in between where the scapula and the spine is and we will just compare sides and inch our way down and you want to move around almost mid aill where you were moving before on anterior. There's three different types a tip for whenever you're trying to learn these normal breath sounds is to get a stethoscope listen to yourself or listen to others and get a start. rhythm down for how long inspiration expiration is and where these are located because that's the key with these three different sounds because they're heard in different areas throughout the lung field so let's go over them the first one is bronchial this is heard anteriorly only you're not going to hear this posteriorly anteriorly why because they are mainly hurt over the tracheal area with the stethoscope so up here in this area they are high pitched and loud and you will notice when you listen to them that the inspiration will be slightly shorter than the expiration. and discontinuous now first let's go over continuous what does continuous mean this is a extra sound that you're hearing that is lasting more than 2 seconds with a full respiration. The first type is called a high pitch polyphonic whe let the name help you okay so what is it it is mainly heard in expiration so when the patient's breathing out but it can be in Inspiration as well. The third type of continuous adventitious breath sound is called stri spider and this is heard on inspiration because what's happening is that the airway is being obstructed. sound and this is what Strider sounds like now let's go over the second type of breath sounds abnormal breast sounds called discontinuous This is an extra sound that you're hearing that is La lasting less than2 seconds okay first type um is coarse crackles crackles for nor Al has been known as rails so if you hear that that's what it means crackles rails they're interchanged just like ronai and Weis so course crackles they are mainly heard in Inspiration when the patient's breathing in. patient's breathing in and breathing out so that's why you're hearing it on inspiration and expiration now it can sound similar to a parac cardial friction rub how do you tell the difference um if you are wanting to know is this the lungs or is this this the heart just listen have the patient hold their breath. If you can still hear that harsh grading sound it's the heart because they're holding their breath their lungs aren't moving so you've rolled out the lungs. That is lung occultation and normal breast sounds versus abnormal breast sounds.

ROUGE-1: 47.98, ROUGE-2: 46.16, ROUGE-L: 46.83
BERTScore: 74.11

==============================================
==================== [91/100] ====================
Summary:
Professor Donald Kagan: We were examining Sparta, the most important, I think, of the early poleis. And I was describing the formal constitution of the Spartans, having mentioned the kings and the gerousia. The council of elders consisting of twenty-eight elected men over sixty and the two kings to create a body of thirty. Then there is the Spartan Assembly which consists of all the adult male Spartan citizens, and as in most states, it really originated from the idea of having the fighting men participate in decisions. mentioning that that assembly--you want to distinguish that assembly from what I'll describe shortly about the Athenian Assembly. In this assembly, it is true that all adult male Spartans were participants, and let me also say that they came to the meeting dressed in their military uniform. When a question was put to the Spartans, the way they responded was by shouting and banging on their shields. Whereupon, the presiding official would try to determine which side had the loudest noise. It's like a voice vote in one of our own meetings, only a little bit more colorful. It looks as though the debates in the assembly were probably infrequent. Some scholars go far too far in suggesting that there never was a debate. There are debates reported to us in Thucydides, which make it perfectly clear that they did. But it is worth pointing out that there is no evidence that there was ever a debate at the assembly in the first century BC, as some scholars have suggested. It's possible that the gerousia and the kings, in other words, the upper groups in society, if they agreed there would be no need to go. that so far as our information goes, the only people who spoke at those assemblies were the kings, the gerousia, or a group of people I haven't mentioned to you yet. In short, the average Spartan did not ever speak in the assembly, it appears. So it's not a democratic assembly, even though every single citizen is there, if he wants to be. Let me turn now to the ephors. These, according to Spartan tradition, were invented somewhat late in the development of the Spartan constitution. They were, in a certain sense, the overseers. was to keep watch on the kings and to see that the kings didn't do anything improper, illegal, irreligious, or anything of that kind. Some scholars have focused on that and suggested that, at least originally, that was what their main function was. I think by the time the Spartans appear to us in history, let us say late in the sixth century and fifth century, the ephors don't do that. I mean, they still have the technical constitutional requirement to do that, but that's not what they're up too. might be an offer of an alliance or it might be an order to do something or else war would follow, or a negotiation for peace, any of those things, first they would come to the ephors, of which there were five. I would say, in most cases, they would, unless it was very, very serious, give some sort of answer to it. But when it involved something fundamental like war and peace or alliances, then they would have to go to the assembly to get their approval. Aristotle tells us that the ephors were just any Joe Spartan, that they were ordinary people, not distinguished in any way. The idea was to sort of have a representation of the ordinary Spartan to carry on the functions that I have talked about. On the other hand, they were given the responsibility of seeing that the kings were in line and they had various techniques or various policies and processes which had them make judgments. They could go to Delphi and ask the god, if they were right in thinking something was wrong. If they came back the kings would be put on trial. about this accidental element in who becomes an ephor. All the Spartiates that there are, whether they are ordinary citizens, all the way up through king, are a small minority of all the people who are under the control of the Spartans. So, whatever the mixed character of the constitution was, when you look at the whole of Laconia and its possessions, it is very much an oligarchy. The Spartans normally will like to see other states oligarchically governed. They won't like democracies or any form of autocracy which in Greece typically took the form of tyranny. ancient Greeks referred to as the Spartans and their allies, which modern scholars have come to call the Peloponnesian League. It's an imprecise term because some of the members of the--let me say a better term for it would be the Spartan alliance, which is what pretty much the Greeks called it. Well, how did it come to exist? Again, as in most things in Greek history, the beginnings are shrouded in legend and are not absolutely clear, he says. Around 570 B.C. the Spartans suffered a defeat in the region of Arcadia. They defeated the town of Tegea, which is located just to the north of Laconia. It looks as though at that point, that somebody in Sparta came up with a bright idea which changed the nature of the Spartan situation, and also introduced something new into the Greek world at the same time. The Spartans had been successful apparently in turning around, to some considerable degree their defeat back in the seventh century. It's a very important state for the Spartans, not just because it's the neighbor right to the north of them, but because remember what I told you, if you want to get to Mycenae from Sparta you can't go across those mountains. So, its strategic importance is very great. The Spartans got into this war with Tegea and they claimed to have discovered the bones of the great Homeric hero, Orestes and taken it away. Also, there was a legend that maybe they propagated that showed up in some poetry we have. connect these Dorian Spartans with the legends of the great men of the Achaean world described by Homer. King Cleomenes who was one of the aggressive Spartan rulers who expanded the power of Sparta, said on one occasion, "I am no Dorian, I am an Achaeans." What's this all about? Well, it looks like as the Spartans begin to extend this league that I will be telling you about in a minute, they want to reduce the amount of resistance that they're going to get into. what the Spartans wanted them to do. But we have many occasions in which states refused to do so and even get in the way of the Spartans. So great was their respect in which they were held that not only did they command the armies, even though they had no navy and no naval tradition. They were even put in charge of the fleet, although they often had the brains to use other people who had more experience to do the actual leading. And so that will explain, in my opinion, some of the reasons for calling it a Peloponnesian League meeting. According to Thucydides, the fear of the Helots was at the core of it all. Their feelings towards the Spartans were as you might expect. If we take our whole army, leave town, go three days march away, how do we know we'll find anybody alive when we get back? That's always on their minds and Helot rebellions, although they don't take place every day, take place very sparsely, but they keep happening so that the Spartans think. the fear is never irrational. To that is added the permanent enmity of Argos, which never gives up the idea of returning to the great days of Pheidon with Argos as the dominant state in the Peloponnesus. So, the Spartans, of course, have a need of a collection of states that stand between them and their potential enemies of whom the Argives are the most important. Another thing that corrupts is the search for power beyond what is appropriate in the Spartan system. What they focus on is discipline and the state versus freedom, individuality, and even family. try to enjoy these things in spite of their being barred. Why? Because in a way, necessity becomes a virtue. That's what the Spartans did. Their way of life was imposed upon them by the decision to maintain their command of the Helots. After that it all makes perfect sense. Look what they had to give up, to do it. They said, of course, we gave that up, because that's what makes us the great people we are. It's the way we cope. Athens is located in the southeastern portion of the Greek peninsula. The city is Athens; the region in which they live is Attica. The people are Athenians and that's an important point I think I made too. Everybody who is a citizen who lives in Attica is an Athenian, no matter if he lives sixty five or seventy miles away from the city. He's still an Athens. And that's the system that was the Spartan way of life. I remind you again that even though this is very extreme and other Greeks say that they're not going to live that way. in the early days to grow wheat and other grains, but more to the point, it was very good for olive trees and for grapevines. As we will see when the Athenians begin to exploit all of their land, not just the bottom land that works for grain, but also the less desirable land and produced wine and olive oil, that was a source of agricultural wealth. Now, their own story about their past was something like this. They, unlike the other inhabitants of southern Greece, according to their story, never experienced a Dorian invasion. There's a tradition in Athens of an event called synoikismos. These exiles, we are told, were brought into the Athenian people and lived among them as Athenians. Similarly, there is nothing like the helot class in Athens. There are no serfs, there's no suppressed population waiting to get at their rulers, so that there's a kind of a historical good fortune, which says Athens is going to be without internal strife. I don't mean totally but to a great degree compared to the other Greek states. There is no set of local rebellions against the major city, no need to go to war. But in neighboring Boeotia, the chief city of Thebes, traditionally was at war trying to subdue the other major cities. Compare that to Sparta where it's obvious Sparta gained control of the Peloponnesus through war and that many of the people there were very unhappy with them, not to mention the Helots. It really, if you take the word apart, it means the bringing of households together. of Boeotia, in order to make themselves the boss and they never were fully successful in this. So, Boeotian is torn, to some degree, by this internal conflict, which makes it harder for Thebes to achieve the kind of power in its own home territory. Let's take a look at the earliest society of Athens as first we come to know it. The society we're talking about, this earliest society, is aristocratic. Aristocratic implies means ruled by the best, and best in that time means simply best by birth. and that means if you're going to be in the ruling group, in a dominant, aristocrat--the only way to get there is if your father was an aristocrat. Doesn't matter how rich you are, doesn't matter what a magnificent warrior you are. All that matters is birth and that is different from oligarchy which gives rule to a few but that usually means, I would say just about every case, that wealth plays a role. I don't mean that they didn't have aristocrats within an oligarchy, I'm sure that they did. as we see Athens move out of the aristocratic condition and into one that is more based on wealth, than it is merely on birth. Well, we are told that in the earliest times, Athens was divided up; the people of Athens were divided up into four tribes just as were all the other Ionian cities and the Athenians of course were Ionians. Most Ionians lived on the coast of Asia Minor or on the Islands of the Aegean. They sort of were an interesting middling group between the Dorians of the Peloponnesus and the Greeks of other types elsewhere. tribes contained, according to this tradition, three subdivisions that were called phratres. An easy way to translate phr atres is brotherhood. Notice it's again about family and birth. You are in phratre; you're in that phratrs, because so is your father and you inherit it. These phratmes were very important. I should have mentioned that the tribes had important religious functions that also the army consisted of four regimens, one for each tribe. These tribes had great reality for the Spartans. did have priests, but it didn't have a separate priestly class and during the aristocratic period, and I would say probably throughout its history, Athenian religion had the priesthoods. The chief religious places in the state were held by aristocrats, which in a primitive society in itself, gives them tremendous prestige and a lot of clout. Probably, although I'm not sure we have hard evidence on this, probably the phratres fought side by side in the tribal regiments as well. chief jobs in religion, they were the government, because as early as we can tell that there was a regime after the legendary kings are gone. The number one governmental organization, you might call it, is the council of the Areopagus; gets its name from the place where it meets. We don't know enough to know whether it was all noblemen or just the leaders of the clans or whatever, but that's where decisions were made. It's important though to realize that in these early days of the polis they probably had very little power. Little to decide and very little to do. Most of the real life of the state in the earliest days would have been out in the countryside where the overwhelming majority of the people lived. These noblemen would typically have held a lot of land and have been well to do, have had all the powers I've described, and were looked up to and were listened to. They would have led the military units into battle when that was necessary. If there was a quarrel between a couple of guys, they would bring it to a court. There was nothing like a written law code until the seventh century. Before that, if you wanted to get justice you went to a nobleman. If you want to go beyond that, you go to the Areopagus, which is made of noblemen. That's the picture in the earliest polis as best we can reconstruct it. It was pretty clear that it was right to have the noblemen do it, not just because they're aristocrats but because they would know what the law was. early seventh century, the date he gives us, of course we shouldn't put too much credence in it, it's too precise, but it's 683 B.C. On that occasion, we are introduced to a new thing, magistrates are chosen from the aristocracy to do various jobs in the city. In Athens, the magistrates were called archons, it means, in the most technical sense, rulers. One of these was called the War archon, polemarch, presumably he led the army. Next came the archon who was actually the most important archon and gave his name to the year. after these three major figures that I have mentioned to you, there was established a body of men called thesmothetes, which were six men whose functions were apparently strictly judicial. They presided over courts that you could to for specified purposes. Every one of these nine archons--they are sometimes referred to as the college of nine archon. They had a secretary which would have brought them up to ten, but only nine were true archons. They were elected from the aristocracy by the assembly of all Athenian adult males. than a year. The only thing in town that has continuity, that can develop power and influence over a period of time, is the council of the Areopagus. Aristocracies love equality; equality among aristocrats, and then tremendous inequality between them and everybody else. Yalies are very nervous about anybody sticking his head up above the crowd, because the question is always why not me? You have high expectations of yourself and so sometimes unless you're invaded by later religious ideas that the Greeks didn't have, you's not humble, you're vying for honor. what we have, not a monarchy, but a republic. Dominated insofar as it's dominated by anybody but individual aristocrats, by the areopagus. At some point in the history of that institution it consists now of men who have been archon. The year after their archonship they automatically go into the areOPagus and remain areopagites for life. Well, that gives the counsel of theAreopagus even more power and influence, because they consist now, exclusively after awhile, of people who've been chosen for their individual qualities. power of the Areopagus must have been enormous in this system. So the rich and the well-born, because they are pretty much the same in the early days of the polis, run the state in this official constitutional way. Then it comes to Athens as it did to every other Greek state, a little bit later it looks like in Athens, all of the change and turmoil that we've seen in Argos and Corinth and other place. If we are right in talking about something like a hoplite revolution, it occurs in Athens too. begins to engage in commerce to a greater degree than before, and in ancient handcrafted manufacturing. It leads to new wealth and new class distinctions, which are now based not on birth but on wealth. We hear new terms, not all of them new, a couple of themnew that come into the picture. The Eupatridae, the well-born, that's the old story and they were really only two, those who were and those who weren't. Now we hear about people called hippeis, and it means horseman, cavalryman. Hippeis are people who are not necessarily aristocrats. They are the poor; they don't own land. They live at the mercy of chance; they work for other people. The new thing, people called zeugitai, means yoke fellows. These were men who were sufficiently well off that they could own a team of oxen, two oxen who were yoked together to pull the plow. That would make them respectably well off farmers. We are talking about people of the hoplite class. Another theory is that they were indeed named that, because they were hoplites. It hardly matters which of the stories you prefer or whether you choose both; we're talking about the same people. This new class of independent family farmer has arrived in Athens, and as in other states is not satisfied with his position in the state, as his own importance to the state becomes greater and greater. We will come back to this story when we talk about Solon, but think about these changes as happening, as the next change that I want to tell you about occurs. in the year 632, an Athenian nobleman who had married the daughter of a very wealthy and powerful tyrant in Megara, right next door to Attica. Cylon, attempted a coup d'Ã©tat trying to establish a tyranny in Athens, just as his father-in-law had established one inMegara. Well, as the story goes, he tried his best to gain control of the city. But he couldn't, he was resisted by enough of his. opponents that he was defeated. The leader of the resistance was the family known as the Alcmaeonidae. They went up there, locked up Cylon and his supporters in the Acropolis, in a temple. You couldn't go into the temple for the purpose of killing somebody, that would be sacrilegious. Still if you're inside that temple and trying to avoid being killed, you still need food and drink. So, how could they manage it? Well, they took a cord, tied it to the temple, held onto the cord, and went down to the well and got their water. The Alcmaeonids were declared accursed and driven from the city. Later on we will hear they're back again and they're very important. But the curse continues to be attached to the family, and as we get to the last end of the last third of the fifth century and the Peloponnesian War is about to break out, the enemies of Pericles will pull out the curse of the AlcMAeonidae to use against him. For the moment, what we're talking about here I think is here's the first sign that we see of trouble in paradise. that there are the kinds of discontents that we have been talking about which find the leader in the form of a man who is an outstanding figure for some reason, who is willing to try to establish a tyranny. That it fails, I think, is an indication that the same forces haven't reached the power in Athens that they had reached in Megara, Corinth, Sicyon, and places like that. It's a warning about troubles ahead and I'll turn to those troubles in the next hour.

ROUGE-1: 55.40, ROUGE-2: 53.25, ROUGE-L: 52.54
BERTScore: 77.46

==============================================
==================== [92/100] ====================
Summary:
Ka-Yen: "I walked into MIT not knowing a single thing about nuclear energy" "I was like, I wish someone could have told me these things" "We're just kind of like-- it's a refresher. A couple of fun facts" "You guys are going to be starting up full cycle on Friday with really cool topics like stopping power" "There won't be a lot of crazy intense math because we just want to give you guys a break" "It's a very brief history in a nutshell" between 1895 to 1945, that's really cool people were developing nuclear science. So people like Madam Curie or like Fermi, et cetera. They were all designing this nuclear science, like they were developing it, which is pretty cool. Most of this development happened between 1939 and 1945. They've entered a phase of like, well, the war is over. Now what do we do with ourselves? So luckily we decided to redirect this science into using it for energy. In 1951, the first nuclear reactor to produce electricity was the experimental breeder reactor, the EDR1. The first nuclear powered submarine, the USS Nautilus, was launched in 1954. The real heyday of nuclear was actually between 1960 to 1975. People like Westinghouse were creating nuclear reactors. Currently, China, India, and South Korea, they are the main players in this game. They have 32 operate reactors operating at the moment, and have 20 more commissioned, like literally right now. Nuclear creates 75 times less carbon emission than coal does, and 35 times less than natural gas does. Nuclear power is able to provide a good baseload source. That means it can provide conserve energy at a really high level all the time. Other alternative forms of energy might be better for the environment, it might be safer, and things like that, but it's not really able to do this, right? Right? So this is why we kind of want to replace coal and natural gas with nuclear. About 21% of the reactors that are located and working in the United States are boiling water reactors. Light water reactors, or LWRs, are mostly broken up into two subcategories: boiling water reactor and pressurized water reactor. So how you guys can think about reactors is that honestly they're just kind of glorified steam turbines. So it's a really, really simple mechanism and we can walk through that right now. About what I've mentioned? Awesome. So now we'll talk a little bit about reactor types. the fuel core. So the fuel core is basically just a bunch of rods of uranium, sometimes it's clad in something like zirconium, and there's also control rods to help slow down the process. So uranium undergoes what? AUDIENCE: Fission. TA: Yes, fission. So what gets released during fission?AUDIENCE: Heat. TA. And? AUDience: Neutrons, awesome. So those three things are all flying around inside the reactor core at the moment. The heat obviously goes to create power. a second. But the neutrons come flying around. So those other neutrons can simulate other fissions, and the control rods are there to make sure that there's not too many fissions happening in the fuel core at a certain time. So this is just one loop of water, basically. So the water flows through the core and heats it up. It creates steam so the steam goes and spins a turbine. The turbine creates electricity. And it comes back and gets recondensed. That's literally it. The chances of leaking nuclear material into the environment exists. With BWRs there is a higher chance of leaking radioactive material. So that's one of the downsides of B WRs. Do you have a favorite nuclear power plant? Share your photos and videos with CNN iReport. Share your stories and videos of nuclear power plants at CNN iReporters. Visit CNN.com/sources for more nuclear news and stories from the U.S. and around the world, and follow us on Facebook and Twitter. The next kind of reactor that falls under the light water reactor category is the pressurized water reactors. So remember, BWRs comprise about 21% of the reactors in the United States. PWRs are actually more important, if you will, than B WRs. But they are functionally essentially the same, and it's just slightly more complicated. So over here we have our fuel core again, and here's the underside of a BWR. Like look at all those wires. I don't even know what they all do. But it's kind of insane. and again all it's doing is heating up water with its fission reactions. But this time this water is pressurized. So does anyone know why you would want to pressurize the water? Yeah? AUDIENCE: So it doesn't boil? TA: Yeah, exactly. So when you increase the pressure, you're also increasing the boiling point of the water. That allows you to function at even higher temperatures than if you're working with a BWR, which gives you more energy efficiency. the higher efficiency. But also the chance of leaking nuclear material into the violent becomes mitigated. Because you have two separate loops with the nuclear fuel being more isolated from the environment, if there is a breach between the condenser loop and the secondary loop, not a big deal. Nothing really bad happens. You'd have to have breaches in both the loops, which is very unlikely to happen. Yeah? AUDIENCE: What's the standard like operating temperature of these kinds of reactors? TA: I'm not completely sure, but if you Google it you should be able to find it very easily. OK. here is basically just showing that there are a lot of redundancy systems inside these reactors. We don't just have one single primary loop and if it fails, it fails. We actually have four at the same time, and this is just called the n minus two redundancy, something like that. So the next kind is something much cooler. It's got a heavy water reactor. Actually it's just a little bit cooler. But the main heavy water reactors that everyone can kind of think of on their minds is CANDU, which is the one that's located in Canada. Heavy water has a much lower absorption cross-section than light water does. This means that when neutrons are flying around in the reactor there is a chance of it hitting a fission product. But there's also a chance that the water that surrounds it will absorb that neutron. So if that neutron gets pulled out of the system you're not able to create any more fissions. This is actually kind of a bad thing because the whole point of nuclear reactors is to create heat and fission. So we don't want that neutron in the system. those neutrons to be absorbed. Because it's absorbing less-- because it has a chance of absorbing less neutrons as it undergoes its processes, you're actually able to use a lower enriched uranium. But the main downside is that, even though you're lowering your fuel costs, deuterium is really expensive. It's about 1,000 or so dollars per kilogram, which is kind of ridiculous because a kilogram of water is really not much at all, you know? So even though you're counteracting the lower fuel costs with higher water cost. Also, because you're using your reactor with lower enriched uranium, you actually have to change out your fuel more often. That fuel gets spent more quickly and I'll describe that in just a second, and therefore you just have to keep replacing it more often than you would for a normal light water reactor. Oh, I forgot to mention, but aside from that, everything else with the heavy water reactors and the PWRs, they're the same mechanisms. mentioned you guys before. But instead, now there's two little chunks of extra material. So do you guys know what the difference is between fissile, fertile, and fissionable material is? Cool. All right, so all right, let's start with fissiles material. Fissile material is basically just the material that is willing to undergo fission with a thermal neutron. So basically when the thermal neutron gets absorbed by this fissable material, it's going to undergo a fission. Makes a lot of sense, right? plutonium 239. There's four in total, but those are the two most important ones. So this is the main fuel that is inside a nuclear reactor, but it's not all just U235. So an example of fissionable material that's inside the other reactors at the same time is U238. If a U238 absorbs a thermal neutron, it is not going to do much. But if it absorbs a neutron of about like, I would say, like 2 meV, then it's more willing to undergo fission. U238 absorbs a neutron, becomes U239, undergoes a beta decay to come neptunium. U238 then undergoes one more Beta decay to become the beautiful plutonium 239. If we start with thorium 232 instead, becomes thorium 233. This is another fissile material by the way, through a series of beta decays. So that's what breeder reactors are doing. They're adding extra chunks of uranium 238 andextra chunks of thorium232 into the reactor. If one of the neutrons-- so imagine-- if you're looking at the little fuel core, there's a bunch of neutrons that are flying around and heat and other isotopes and things like that. Some neutrons will go and create other fissions with the material that's hanging out in the red. But other neutrons might escape, and when they escape, instead of going into the water dissipating, they instead create more fissile material. So you can understand why this is a kind of an attractive idea, is that you're creating your own fuel. In the 60s we discovered that we have a lot more uranium ore than we thought we did. And after that discovery, people were not nearly as interested in breeder reactors. The primary objective for these new designs of reactors is to make them cleaner and safer and more cost effective. Keep them robust yet sustainable, and also make them more resistant to people being able to divert materials into creating nuclear weapons. So yeah. Here are the six kinds of generation four reactor types that were deemed to be the most promising. fast reactors, very high temperature gas reactors, and supercritical water-cooled reactors. "I don't know all that much about these and I don't want to like spew out information that might potentially be false," he says. "A lot of people in Mike's group are working on molten salt reactors so you guys can go ahead and ask them about that" "Hopefully he will post the slides online and you guys just click it and there's a awesome source all about these different kinds of reactors" it all just theory? TA: I'm pretty sure that they were just kind of proof of concept stage right now. Like there aren't any that are producing electricity in the United States, at least. In the rest of world, there's only about 440 reactors spread around 30 countries and produces only 14% of the global electricity. The main players are still, you would imagine, coal and natural gas. So this is actually even worse in the rest-of-the-world. The main reason why we're a little bit hesitant to start using more nuclear power is because of safety issues. None of us can argue that nuclear is like 100% safe. It actually does have some dangers associated with it. After a nuclear accident you can see a pretty steep decline in the amount of nuclear reactors that are being commissioned. And again Fukushima, once again, with the number of reactors being commissioned after the accident just declines dramatically. The main things that are holding us back is just social, economic, and therefore like government hesitance to use nuclear power. The Three Mile Island reactor is a PWR located in Pennsylvania. During this time it underwent a core meltdown. The cause of this is just the fact that there was some kind of mechanical or electrical system that prevented coolant water from being pumped into the primary system. So because there wasn't enough water coming to cool up the core, the core began to overheat. So as the temperature of the core rises, the pressure also rises. So they notice this and they're like, oh, shoot, we got to fix that. A valve in a nuclear reactor became stuck. The valve was open and water was leaking out of the primary loop. When the water leaked, the pressure dropped and the reactor shut off coolant pumps. The reactor continued to operate again but the valve was still open and there was still water leaking out. It became stuck and they didn't realize that it became stuck because their equipment and their instrumentation wasn't able to detect that. So they shut the valve down and the pressure was released. But the valve remained open. the core is getting hotter, but then they also took out the water that is usually used to cool the reactor core, so again it's also getting hotter. So this combination of events led to a core meltdown. So the core melted down, the reactor wasn't able to operate anymore. But luckily at Three Mile Island there was containment that prevented radioactive isotopes from leaving the system. But they realized that they didn't get much dose at all. They collected about a total of 1 milligram more dose than usual. So to put that in perspective, an x-ray is six milligrams. quite realized this, but the coolant pumps in the reactor were also powered by the nuclear reactor being generated. So that was unfortunate, and they realized that this is a bad thing. So the reactor starts to go supercritical. So when they realize that the reactor was creating a lot more fissions than it should have been creating, they decide to insert the control rods. So thank goodness we have these high absorption control rods to slow things down, right? For some reason, I'm not completely sure why they did this. that caused the first explosion. Then, for some reason like a couple of minutes later, there's a second explosion. They're not completely sure why the second explosion happened. It could have been like building up helium or just a ton of other fission reactions. There was a lot of radioactive isotopes being spread into the environment. So that kind of stunk, but it did stop the whole reaction. Because a super critical mass was all blown apart, it was no longer super critical. It was fine. 28 highly exposed reactor staff and emergency workers die from this radiation or from thermal burns during this time. Officials also believe that there is about 7,000 cases of thyroid cancer that occurred because of Chernobyl. They're pretty sure it was Chernobyl because these are all cases that happened in people who are less than 18 years old. No one really lives near Chernobyl at the moment. It's kind of been deemed unlivable because these radioactive isotopes literally went everywhere in this environment and it's not safe to live there. we see that there are animals coming back now now. If you look on NationalGeographic.com there's like little deer roaming around Chernobyl. But it's been about-- how long has it been, like 30, 40 years? People aren't advised to live here still. So Chernobyl was terrible. Questions? Yeah? Audience: What does it mean for a reactor to go supercritical? TA: Oh, yeah, sorry. When I say supercritical it just means that there's way too many fission reactions happening. Next reactor accident that we were alive for, which is cool, was Fukushima Daiichi. This is a very similar problem, as you can see that in all these instances of the reactor incidents, it's just kind of like the fuel core was misbehaving and we weren't able to get enough coolant water to it. So following the earthquake, these coolant pumps broke. They're like, oh, that's OK. What we can do is we have backup generators to continue running the pumps. We're all good. The reactors at Fukushima Daiichi began to explode. There was radioactive isotopes being spread out all around the country. No one was directly hurt by burns or radioactive exposure. Reactor accidents are actually pretty rare. If you think about it, it's been over 100 years since the first nuclear reactor was built in the United States. It's been a long time since there's been an accident at a nuclear power plant in the U.S. since the mid-20th century. That's the last time there was a nuclear accident. about 60 or 70 years, we have 440 reactors operating around the country. There's three main accidents that have happened. But because these are the things that people get ingrained into their mind, people think that nuclear reactors are incredibly dangerous. And that's why we have this social hesitance, which is why we aren't able to get enough government funding and why there's all these bureaucracy loopholes to jump through. Makes sense? Yeah. Another issue that's associated with nuclear power is nuclear waste. So what in the world do we do with it? The main issue is, what do we do with all this material? So this material that comes out is pretty radioactive and it's also incredibly hot, so it can be dangerous if someone decides to come and eat it. The primary way of disposing of the spent fuel is putting it into spent fuel pools. This is an OK solution, except for the fact that, again, we just have way too much spent fuel to be able to do this. So the next solution was something called dry cask storage. Yucca Mountain is the primary push by the U.S. to find a deep geological repository somewhere in the United States. People in Nevada weren't happy about this, they're like, why are we getting tossed on nuclear waste? We don't even have nuclear reactors in Nevada. There was a lot of opposition. And because of the social opposition there was government opposition and many loopholes we had to jump through, and so it was just becoming a huge disaster. It's been abandoned, as you can see from this lovely Google picture. figured out all that well. There is one other kind of way of dealing with nuclear waste, which is repurposing. So basically you take the spent fuel and you chemically separate out any material that could be continued to be used. This is actually something that France and other places in Europe, and Russia and Japan, they use repurpose quite a lot. For some reason the United States doesn't do it. It's not economically sound. So yeah. You guys have any questions about anything I've mentioned, about deposition of nuclear waste? Almost done. The economics of nuclear power is actually a really complicated topic and it changes depending on who you talk to. Building reactors takes billions of dollars. It also takes tons of time. The main reason why we can't get nuclear up and running is because it's a huge chunk of money, like I mentioned before, it takes a while to get your profit back. If you look at this chart over here, which is breaking up the cost of nuclear, you can see that nuclear is not nearly as economic of a source of electricity generation as any other of these ones I mentioned. energy per kilowatt hour, I believe-- gigawatt hour? Kilowatt Hour. You can see nuclear, coal, and natural gas. So this giant white chunk over here refers to fuel. So if you can look at nuclear power, the majority of cost actually doesn't come from nuclear fuel at all. It's just about $0.01 per kiloatt hour. As compared to natural gas, which the majority. of the costs of electricity actually come from the fuel. other forms of electricity. People buy the electricity that's cheapest, not necessarily the Electricity that's best for our grandchildren or something like that. Yeah, so that's why nuclear power isn't more of a thing, and that ends my pretty lengthy slide show. So do you guys have any questions about anything I mentioned? If you guys are interested about any of these topics, I recommend going to NRC.gov. They have a lot of really cool information. That's basically where I got the majority of my information for the slide show, and it is a reliable source. NRC.gov with less grains of salt than usual. Or if one of these things really piqued your interest, you guys can take 22.04, which is really cool class that's offered here I think this spring, and if not next spring. But basically it's called nuclear power society. It's taught by a guy named Scott Kemp. He talks about all these things and in a lot of detail and slower. So yeah, cool. So thank you guys so much for coming. I know you guys could have slept an extra hour.

ROUGE-1: 55.61, ROUGE-2: 52.38, ROUGE-L: 50.61
BERTScore: 65.25

==============================================
==================== [93/100] ====================
Summary:
Professor Steven Smith: I want to talk today about Aristotle's discovery of America. This will probably come as a surprise to some of you that Aristotle discovered America, but I will get to that in a minute. In many ways for Aristotle, as it is for every student of politics, the most difficult issue one confronts is the problem of faction. Smith: Aristotle's proposal for a mixture of oligarchy and democracy seems, in many ways, to anticipate James Madison's call for a government where powers must be separated. any sensible reader of Aristotle would reach is that Aristotle, in fact, discovered the American Constitution 1,500 or 2,000 years before it was written. This may seem surprising to you, since of course Aristotle lived long before. But that may simply be our own prejudice to think that my friend at the CUNY Graduate Center, Peter Simpson, has argued in a paper that I found quite convincing. I say, it may just be our prejudice that he didn't, but it may be true. like ours or even identical to ours existed at some point in the ancient past, in the far distant past that Aristotle knew about. But Aristotle's mixed constitution differs from ours still in certain important respects. Aristotle understands the mixed constitution as a balance of classes--the one, the few, and the many. For Aristotle, it is not the liberty of the individual so much as the functioning or functional well-being of the city that is the highest priority. He clearly understands, in many ways, the virtues of private property and of commerce. people par excellence--the Phoenicians would be the best regime. Aristotle could never endorse the view stated by a famous American president that the business of America is business. The political partnership, he says, must be regarded for the sake of noble acts performed well. He would have been critical of the American tendency to organize into clubs, what we call political parties. These political clubs or parties use their influence to incense the populous, using their power to whip up dangerous passions that tend to make politicians closer to demagogues than to statesmen. Aristotle was not without his own critique of the American constitution and American political culture. There is, obviously, much in the American regime that Aristotle would have found admirable, even though it does not conform to his idea of the best regime. In these parts of the Politics, Aristotle offers a serious challenge to existing Greek traditions and patterns of political education. Every bit, in many ways, is far reaching as Plato's Republic. In the first place, he tells us the purpose of Aristotle's Republic is directed not at the people, but at the best men. to war, but in fact to peace. The citizen of the best regime, he says, must be able to sustain war if duty requires, but only for the sake of peace and leisure. Leisure does not simply mean rest or inactivity, but leisure is necessary for education or what he sometimes calls by the term philosophy. By philosophy, he seems to suggest not so much the capacity for abstract or speculative thought, but rather a kind of liberal education that he regards to be the preserve of the megalopsychos. The megalopsychos, the gentleman, whatever else he is, is not a philosopher in the strict sense. He is a person of some inherited wealth, chiefly landed property, but whose way of life will be urban. He will be a member of what we might call the urban patriciate. We can begin to see how Aristotle's best regime differs from Plato's intransigent demand for the rule of philosopher-kings. The gentleman is, in many ways, for Aristotle, the ideal recipient of this form of education, of liberal education. Aristotle tells us he is slow to act, unless something of great importance is at stake. He repays favor with interest so as not to be under any obligations to others. He speaks his mind without fear or favor, somewhat like the New York Times, because to dissemble would be beneath him. He may occasionally hurt others, but this is not done out of deliberate cruelty. He will possess beautiful but useless things, suggesting the possession not only of wealth, but of a kind of cultivated aesthetic sense. megalopsychos walks slowly, because to hurry is undignified, is tall and speaks with a deep voice. Most importantly, you might say, what distinguishes the gentleman as a class from the philosophers is a certain kind of knowledge or practical intelligence. The gentleman may lack the speculative intelligence of a Socrates, but he will possess that quality of practical rationality, of practical judgment necessary for the administration of affairs. Aristotle calls it by the term phronimos, that I have on the blackboard. same thing, obviously, as speculative or philosophic intelligence. The phronimos is the person who is able to grasp the fitting or the appropriate, the appropriate thing to do out of the complex arrangements that make up any situation. Such a person embodies that special quality of insight and discrimination that distinguishes him or her from people, again, of more theoretical or speculative cast of mind. How is this quality of judgment, of practical wisdom, of horse sense, how is it acquired? Aristotle tells us that this kind of knowledge is most appropriate to politics. knowledge of how to act where the purpose of action is acting well. This kind of knowledge entails judgment and deliberation. We only deliberate, Aristotle says, over things where there is some choice. We deliberate with an eye to preservation or change, to making something better or to preserve it from becoming worse. It is the skill possessed by the greatest statesmen, you might say, the fathers of the constitutions, as it were, who create the permanent framework in which allows later and lesser figures to handle change. The quality of practical judgment phronimos, practical wisdom, was developed, I think, in a beautiful essay, without any explicit reference to Aristotle, by the English political philosopher Isaiah Berlin. Anyone here ever heard of Isaiah Berlin? Not one of you? Famous, famous English philosopher, died a number of years ago in the late â€˜90s. He wrote a wonderful essay called Political Judgment. In it he asks, "What is the intellectual quality that successful statesmen possess that distinguishes their knowledge from all other forms of rationality and knowledge?" Like Aristotle, Berlin distinguishes a kind of practical skill possessed by the greatest minds, political minds at least. He says it's quite different and from what he calls the great psychological novelists, from that possessed of the greatest philosophers and scientists. "What are we to call this capacity?" Berlin continues. "Practical reason, perhaps is a sense of what will work and what will not. It is a capacity for synthesis rather than analysis, for knowledge in the.public life, which successful statesmen have" sense in which trainers know their animals or parents their children. Aristotle describes this political knowledge as phronimos. How is this knowledge acquired? Are we just born with it? Do some people just have it or is it a product of experience? Aristotle doesn't say, but I think the answer is clearly some of both. It is a quality, as I agree with Berlin, possessed by some of the great psychological novelists. I mention the names of some of them in this article. Berlin: Does Aristotle have a political science, a science of politics? If so, what is it about? What distinguishes it from all other studies is the concept of the regime, of the politea, he says. Berlin: For Aristotle, politics has a priority to all the others, because as he has argued, man is the political animal. To be a political is to have the skill of judgment, discrimination and practical reason, Berlin says. It is also a virtue of great statesmen, he adds. animal means first to possess speech or reason that allows us to participate in a community or a way of life governed by shared standards of justice and injustice. It is our logos, our reason that makes a community possible and also expresses or creates a certain latitude or indeterminacy in how our behavior distinguishes us from other species. To be a political animal, for him, is to engage or to engage in conflict and conflicts over justice. It's precisely, he believes, this latitude that makes political communities not only sites of agreement over shared standards, but also, as he says, sites of moral contestation. Aristotle: To be human is to be part of that conversation. Most people today are attracted to the study of politics because they are interested in things they've read about in newspapers or seen on TV. To refuse to participate in that conversation, to declare oneself an outsider to it, he says, is either to be below humanity or above it. It is a debate over the very nature of justice, to refuse to engage in that debate is to deny humanity's right to know. The study of politics is not for the sake of knowledge for its own sake, says Aristotle. All political action aims at preservation or change, he says. When we act, we seek to preserve or to change. Political science exists for the reason of the human good, he adds. It helps to make it better or prevent it from being better or worse, he writes. The Politics is published by Oxford University Press, priced Â£16.99, with a print run of 2,500 copies. Aristotle's political science is ultimately the supreme science of statecraft. It requires not only theoretic acumen, but political judgment and the kind of practical knowledge that Aristotle discusses at length. The statesman is the founder of regimes, laws, and institutions. They provide the constitutional framework within which we, later figures, operate. It is the ability not only to keep the ship of state afloat, but allows the greatest statesmen to guide the ship, to steer it safely to port. Without a distinctive method for obtaining and organizing knowledge, we are all just groping in the dark. To some degree, Aristotle refuses to play the methodologist's game. In a well-known passage from the Ethics, he says that our discussion will be adequate if it achieves clarity within the limits of its subject. There will always, he suggests, appear to be something ad hoc about the methods used in the study of politics. We will have to let the method fit the subject, rather than demanding the subject matter fit a kind of apriori method. These four questions are intended to guide inquiry, to shape and direct inquiry. They are not intended to yield sure or certain results, but to guide and inform statesmen and citizens in the U.S. The political scientist must have a grasp of the best regime, given the most favorable circumstances. He must also know something about the techniques of reform and persuasion, what we might call the area of political rhetoric by which existing regimes can be brought closer to the best. And he must have some knowledge of how to render any regime, no matter how imperfect, more stable and coherent. Aristotle's political science stays entirely within the orbit of ordinary speech. He adopts standards of proof appropriate to people in debates and assemblies, in courts of law, in council rooms and the like. The language of Aristotelian political science is the language of man, the political animal. Today, it seems, political scientists are more concerned with advancing the abstract truths of science and claims about creating a methodologically rigorous and pure science of politics. Aristotle takes his stand from within politics and the regime of which he is part. Most contemporary political scientists tend to be liberals. Their values are liberal values. This raises a question. Whether the relation between contemporary political science and liberalism is merely accidental or whether there is some intrinsic, some necessary connection between them. One might do well to ponder which political science is really more scientific--Aristotle's, which is explicitly and necessarily evaluative or that offers advice and exhortation to the statesmen and citizens about how to care for their regime, says Julian Zelizer. the back door. On Friday, let me just remind you, Il Principe. We'll study Machiavelli. On this very partisan note I conclude. On Thursday, we'll study the life of the Italian statesman and play a game of chess with him. We're going to see how well he can play the game of poker. I'm looking forward to it. I hope you'll join us for the game on Friday night at 8 p.m. ET on CNN.

ROUGE-1: 55.03, ROUGE-2: 50.67, ROUGE-L: 47.51
BERTScore: 63.60

==============================================
==================== [94/100] ====================
Summary:
SNLI is the Stanford Natural Language Inference Corpus-- MultiNLI, and Adversarial NLI. The premises are all image captions from the image Flickr30K data set. SNLI is an important genre restriction that you should be aware of when you use the data set, says Christopher Potts. The associated paper is Bowman, et al., 2015. It was written by Sam Bowman, who was my advisor in the NLP group at the University of California, San Francisco. think about training systems on this data. All the hypotheses were written by crowdworkers. Unfortunately, as is common with crowdsourced data sets, you should be aware that some of the sentences do reflect stereotypes. I think this traces to the fact that crowdworkers, trying to do a lot of work, are faced with a creative block. And the way they overcome that is by falling back on easy tricks, and some of those involve stereotypes. It's a big data set. It has over 550,000 training examples. And it has dev and test sets. unanimous gold label. And we rate the overall human level of agreement at about 91.2% for the gold labels. The overall Fleiss kappa measured interannotator agreement was 0.7, which is a high rate of agreement. And then for the leaderboard, you can check out this link here. Sam has been good about curating all the systems that enter, and you can get a sense for which approaches are best. It's clear at this point, for example, that ensembles of deep learning methods are the best for this problem. crowdworker had to come up with three sentences. One definitely correct -- that's an entailment case. One may be correct-- that is our gloss on neutral. And one definitely incorrect, which isOur gloss on contradiction. So you can see here that there's an attempt to use informal language connecting with informal reasoning, common sense reasoning in the prompt here. And then those get translated into our three labels for the task. And here are some examples from the validated set. And I think they're sort of interesting, because you get high rates of agreement, but you do find some examples that have a lot of uncertainty about them. There's discussion of this in the paper. It's a tricky point. What we say for SNLI, using these simple examples here, is that both of them are in the contradiction relation. The reason we call them contradiction is because we make an assumption of event coreference, that we're talking about the same boat in the same event. And therefore, the locations contradict each other in a common sense way. And the second example is an even more extreme case of this. Ruth Bader Ginsburg was appointed to the Supreme Court and I had a sandwich for lunch today. Of course, they could be true together. true together. But they couldn't, in our terms, be true of the same event. And for that reason, they get the contradiction label. If a premise and hypothesis probably describe a different photo, then the label is contradiction. That's kind of anchoring back into our underlying domain that you might have in mind. We can mark progress on SNLI, because Sam has been curating that leaderboard. And you can see that very quickly, the community has hill-climbed toward systems that are superhuman, according to our estimate. of new data. So a very rapid rise in system performance, and then basically monotonic increase until 2019, when we saw the first systems that were, in these restrictive terms, better than humans at the SNLI task. Let's move to MultiNLI, which was a kind of successor to SNLI. This was collected by Idina Williams and colleagues, including Sam Bowman. The train premises, in this case, are going to be much more diverse. They're drawn from five genres-- fiction; government reports, and letters and things; the Slate website. MultiLNI is an interesting early example of being adversarial and enforcing our systems to grapple with new domains and new genres. It's another large data set, slightly smaller than SNLI. But actually, the example lengths tend to be longer. And once again, I would say that we can have a lot of confidence. There was a high rate of agreement. 92.6% is the traditional measure of human performance here. For MultiNLI, the test set is available for download. MultiNLI was distributed with annotations that could help someone kind of do out-of-the-box error analysis. What they did is have linguists go through and label specific examples for whether or not they manifested specific linguistic phenomena. We also have things like whether there are belief statements, conditionals, whether coreference is involved in a nontrivial way, modality, negation, quantifiers-- things that you might think would be good probes for the true systematicity of the model you've trained. incredibly productive. How are we doing on MulitiNLI? So again, we're going to have our score over here and on the x-axis, time. We have that human estimate at 92.6%. And since it's on Kaggle, we can look at lots more systems. But nonetheless, you can see that the community is rapidly hill climbing toward superhuman performance on this task, as well. This does not necessarily mean that we have systems that are superhuman at the task of common sense reasoning, which is a very human and complex thing. One particular very machine-like metric, which gives us our estimate of human performance here. Still, startling progress. And then finally, adversarial NLIs, kind of a response to that dynamic that looks like we're making lots of progress. But we might worry that our systems are benefiting from idiosyncrasies and artifacts in the data sets, and that they're not actually good at the kind of human reasoning that we're truly trying to capture. And that gave rise to the Adversarial NLI project. in the abstract, but rather with the goal of fooling state-of-the-art models. That's the adversarial part of this project. And this is a direct response to this feeling that results in findings for SNLI and MultiNLI, while impressive, might be overstating the extent to which we've made progress on the underlying task of common sense reasoning. So here's how the dataset collection worked in a little more detail. The annotator was presented with a premise sentence and one condition, which would just correspond to the label that they want to create. The train set is a mix of cases where the model's.pair is independently validated. So in this way, we're kind of guaranteed to get a lot of examples that are very hard for whatever model we have in the loop in this process. And so what we're hoping is that as we progress through these rounds, these examples are going to get harder and harder in virtue of the fact that the model is trained on more data and is getting better as a result of seeing all these adversarial examples. predictions were correct and where it was incorrect, because sometimes in that loop, the annotator was unable to fool the model after some specified number of attempts. Adversarial NLI is exciting because it's given rise to a whole movement around creating adversarial datasets. And we just recently published a paper that's on the Dynabench effort, reporting on a bunch of tasks that are going to use approximately adversarialNLI techniques to develop datasets that are adversarial in lots of domains. These in the Dynasent dataset from our previous unit on sentiment analysis. And here's the Dynabench interface. And I guess I'm just exhorting you, if you would like to get involved in this effort, it's a community-wide thing to develop better benchmarks that are going to get us closer to assessing how much progress we're actually making. And then finally, there are a lot of other NLI data sets that I didn't mention. So let me just run through these. SNLI and MultiNLI into Turkish. XNLI is a bunch of assessment data sets that is dev-test splits for more than a dozen languages. Those are human-created translations that could be used to benchmark multilingual NLI systems. So there's a wide world of tasks you can explore, and I think that makes NLI a really exciting space in which to develop original systems, and projects, and so forth. And those could be interesting for seeing how well a model can grapple with variation that comes in very specific and technical domains.

ROUGE-1: 70.73, ROUGE-2: 68.11, ROUGE-L: 67.49
BERTScore: 70.76

==============================================
==================== [95/100] ====================
Summary:
In a perfectly competitive market, the firm is a price-taker. No matter how many units they produce, they're just going to be able to get that same market price. Their marginal revenue curve will essentially just be a horizontal line like this. But in an imperfectly competitive market. If they just produce a bunch of their product, the price that they get in the market is likely to go down. So they will have their own firm-specific demand curve. If the demand curve is downward-sloping like that, the marginal revenue. curve is also likely to be even more downward- sloping. be rational for the firm to do? Well, once again, it would want to produce the quantity where the marginal cost is equal to the marginal revenue. But you see something interesting here. If they produce at this quantity, notice the price that they can get in the market is much higher than that. And because we see a situation where price is greater than your marginal cost, versus in a perfectly competitive market where you see that price is equal, that that is the optimal quantity. But because you have this gap, that people are willing to pay more than that marginal cost. You still aren't going to be able to produce any more.

ROUGE-1: 46.46, ROUGE-2: 43.81, ROUGE-L: 46.25
BERTScore: 71.00

==============================================
==================== [96/100] ====================
Summary:
Eric Joisel, a master origami creator, died on Sunday, sadly. Today is about rigidity again, and in particular, something called infinitesimal rigidity. This is going to be a very useful tool. It still captures essentially generic rigidity, but in a different way-- in a linear way. It's a lot easier to work with algorithmically. And it's also a lot of fun to play with, especially if you know how to do it yourself. Rigidity is really about the lack of motion. So let's define the idea of infinitesimal motion, or first-order motion. I want to take such a motion, essentially, take its derivative with respect to time, And evaluate that derivative at time 0. And then this notion will, stated in terms of motions-- you can think of it as a first derivative of a motion. This is a fancy way of saying the following picture-- I'd like a motion which is some path in the configuration space. can think about this in the absence of a motion. If the motion exists, surely you can take this derivative and evaluate it. But if there's a way to get started moving, that doesn't actually mean you could actually move. I'm just defining an infinitesimal motion to be a velocity vector for every vertices, such that this property holds. This is a dot product between two vectors. If you have two vectors, a and b, you take their their direction or derivative of v. dot product, this is just something like this. You take the x-coordinates. You multiply them together, and so on. Add them up. And we're going to need some linear algebra. That's one useful linearity thing. So these are where the configuration places vertices v and w. So this should be true for each edge v w on the graph. This is a vector C of v minus C of w. It's a vector that would point from w to v in the configuration. right part has no real intuitive meaning, but it involves this thing-- some velocity vector for w-- and the velocity vectors for v. It's actually a very intuitive relation. Basically, we want to understand how this length changes to the first order. So this is a dot product in d of w-- that vector-- dot product with C of v minus C of w. It turns out dot product corresponds to projection. I'm projecting onto this one. That's how you'd write it algebraically. And same deal over here. general, we want this thing to equal that thing. And if you rearrange terms, that's the same thing as this property. I just take this one minus this one, and set it equal to zero, and you get that. OK, so this is some intuition. Maybe it makes sense, maybe not. In the end, this is all I care about. And it's useful to realize that it's a first derivative of a motion, because what that implies is that if there's a motion-- a real, honest to goodness motion-- then there's an infinitesimal motion. the same statements. This you prove just by taking a motion and taking its derivative. This is identical to that. So this is useful because if we can ever find something and show that it's infinitesimally rigid, then we've determined that it'm rigid. Question? STUDENT: [INAUDIBLE] dot product [INAudIBLE] at a left right turn is 0, or that the terms are at 90 degrees to each other? PROFESSOR: Yeah, this dot product basically means these two vectors are at90 degrees toeach other. this way, but they're equivalent. All right, so how do we tell whether something's infinitesimally rigid? Because somehow that's useful to us. Well, there's a saying that everything is linear to the first order-- sort of a tautology. And all you need to observe is that this constraint is linear in what we don't know. So I want to know is there some set of velocity vectors d of v, and d of w, for all the vertices, so that these constraints hold. is a linear equation. The fancy way to write this is as a matrix equation, if you want. My matrix R is going to have a row that has a whole bunch of zeroes. And then at some point, it has basically various versions of this vector. But because this is one equation, but in two dimensions, there's two parts to all these vectors. Two dimensions that'll look something like this-- why did I change the order? I think it's two dimensions. right. OK, this is not very amazing. It's just there are going to be four terms in two dimensions in this equation, because we've got d of v times this vector. So there's a x-coordinate vector, and the y-coordinates vector,  and in d dimensions, there will be d of them. Here in two dimension, I've got the x- coordinate of the vector,. So this will end up getting multiplied on the right hand side by d of. v. know the configuration. We just want to know is there some set of velocity vectors such that the rigidity matrix times this is equal to zero? This is called the set of d's i for which this is possible. It's called the null space of this rigidity-- null referring to that 0, or the kernel. The set of all infinitesimal motions is thenull space of that matrix, also known as the kernel of the matrix. And so what? Well this lets us use a bunch of theorems in linear algebra. There's a fun theorem called the rank nullity theorem from linear algebra. It says if you have a matrix, you take its rank-- which is another quantity-- and its nullity, and you add them together, it will be the number of columns in your matrix. In two dimensions, ideally your nullity is-- if you want rigidity, your Nullity should be 3. So this is telling us something we already knew, but essentially for free, which is kind of fun, if you know all thislinear algebra. it's another way of thinking about essentially everything we've seen. And if you know linear algebra, it's useful. Otherwise, I'll tell you how we can use it. OK, one mathematical thing we can do is give another definition of a generic point set. Last class we talked about one definition of generic, which was that you forbid all non-trivial polynomial or algebraic rational equations on your points. This definition will be easy to think about if you're used to linear algebra. say 3, and I choose k rows-- the same number of rows and columns. I look at those elements in the intersection, that's a square matrix. That's a minor-- that 3 by 3 square submatrix is called a minor. So there's a whole bunch of minors, but it's only finitely many. It's not easy to check. You take all the minors of your rigidity matrix. And here I'm imagining the complete graph, so there's tons of edges. So this'll be independent linkage. I'm saying is if it's non-zero for some choice of C, then it should be non- zero for this choice ofC. And if you find such a configuration C-- or I guess we call this a realization C-- then that C is generic. So it's not useful in a computable way, but it's a definition. It's a little bit nicer. And now there's a bunch of fun facts about infinitesimal motions. I'm sorry. and rigidity, and the relation to the generic case. So there as we have before, this definition is not quite the same, but it's effectively the same as the last one. Almost every configuration is generic. So if you want to tell whether a 3D graph is generically rigid, you take a random realization in 3D. You compute the rank of this matrix generalized to the 3D case. You see is it 3 n minus 6, and that will tell you whether that generic realization is infinitesimally rigid. so important, because it's so easy algorithmically. Things become a lot easier. Let me draw you one example just to show what happens at non-generic points. I've actually drawn this example before. These three points are collinear. And you can work out there is some minor that is 0, but shouldn't be. And it's allowed to move straight up or down-- anything perpendicular to this segment. That's always true. If you take a segment, and you move one vertex but not the other perpendicular to the segment, that's a valid infinitesimal motion. segment, I get 0. So this length is not changing to the first order. And this is really necessary. To the first Order, you can't really distinguish this guy actually moving up, and therefore getting slightly longer versus this guy moving along a circle centered at that point, which is a valid motion. But it's pretty accurate. And if you perturb this example, infinitesimal rigidity will give you the right answer. This is an example where inf initesimal flexibility is a little weaker than having a motion. reverse holds. If there's a motion, there's always an infinitesimal motion. If you're infiniteimally rigid, you're always rigid. That example is rigid, but not inf initesimally. OK so far? That's the more technical part of the lecture. Question? STUDENT: Will [INAUDIBLE] be square matricies? PROFESSOR: The rigidity matrices are almost never square. The minors are going to be square, because we told them to be. that's another good question. What happens if I add more edges than this many? The rank just won't go up. Any edges you add will add redundant constraints, and so the rank can never go above this value. You need at least this many edges to get there, and we know we can get there with that many edges. You could make it a super-tall matrix if you want, but you're not going to increase the rank. All right, let's use this for something more fun. So maybe go over here. Tensegrity-- so this is in some sense an extension of rigidity theory to a whole other theory called tensegrity theory. Don't think he invented tensegrities, but he invented the word. And they are things like this-- here's a tensegrity built and given to me by Bob Connolly. And it has well, I guess, there are three kinds of edges physically. There are the springs, There are these struts, and there are these wire cables. And its rigid. It's a little flexible, just because the springs aren't perfectly stiff, like all springs. And we're going to model the three kind of edges. Tensegrity is a generalization of a linkage and where we allow three kinds of edges. We can have cables, which is the length can decrease, but it can't increase. And there are struts, which are the reverse-- you can increase but not decrease. Seems like a useful generalization, especially because people build things they actually use struts and cables. Like you look at most bridges-- tons of cables around. I think I have an example here. There's this guy, Ken Snelson, who makes a whole bunch of cool tensegrity sculptures. look up. It has this really cool, sixfold rotational reflectional symmetry. I could stare at this for hours. So we want to understand those structures. This one's also rigid, hopefully. It's been standing for 40 years. So what can we define in this generalized setting of tensegrity? We want motions. We want generic rigidity. And we want infinitesimal rigidity, too. Well, all but one of them carry over to this. OK, we can define a configuration space. The problem is, there's no notion of generic rigidity. For example, this is a generically flexible linkage. We all know it. These are things they can expand, but cannot contract. Then this configuration is rigid or flexible? Flexible, yeah. The white part is a one degree of freedom linkage, and if you move this thing in a particular direction, indeed, this increases and that increases. Check it. Now I take my yellow chalk and add struts. Maybe I'll put some arrows on it to make it more obvious. This one is rigid. The only way to move the square-- or in fact, any generic convex configuration-- is one of these pairs has to get shorter. So we lose generic rigidity. But infinitesimal rigidity still works, and generic configurations are still meaningful. It's just that they're not all the same. There's not, in this case, for four vertices, there's two kinds of generic configurations. So it makes life a little harder. But let's say this part will work well. dot product, and I claim this is really measuring-- it's a number, and it's measuring the sign's change in length of that edge. So if C of v minus C of w dot product with d of v plus d of w is greater than or equal to 0, that's the property I want for struts. That says it gets longer or stays the same to the first order. Now of course, in reality it might get slightly shorter, but not in the first derivative. I have linear equations. I also have linear inequalities. So in fact, I can write it as some other matrix R prime. Actually, it's the same matrix. R prime times d is greater than or equal to 0. This is the general form of a linear program. You can write an equality constraint in this world just by taking it and its negation. That forces them to be equal to zero. All you need to know is it there are fast algorithms to solve this, also. Rigorous linkage is something called equilibrium stress. Stress, for me, is just a real number assigned to every edge. And here I'm going to use the word edge to mean bar, strut, or cable. And then there's the equilibrium condition, which is that if I take the sum over all vertices w, where v w is an edge, the weighted vector C of v minus C of w-- so I forgot to mention we're assuming we have some configuration of our tensegrity. vertex like this one, and saying OK, well, I take all of the incoming, whatever. Let's think of all the edges incident to that vertex. I weight them by this number. And I'm going to draw arrows here to signify what this means intuitively is that this edge is pushing with a really big arrow. This is an arrowhead of size 3. Try to draw it to scale. Then, of course, this vertex will not move subject to those forces. These forces balance out. doesn't actually matter which order I do these in. And if I end up back where I started, that means the total force is 0 as a vector. That's the force polygon. It's a geometric condition, if you will, that each vertex is stationary. That is the notion of being in equilibrium. And this is just the algebra to write that down. Now what the heck does this thing mean intuitively? If your tensegrity is going to be rigid, somehow the edges can prevent a motion. And intuitively, what that means-- I'm going to say this right-- so this is like an edge pushing really hard away from itself, against the vertices. Theory of duality goes back to Roth and Whiteley, 1981-- good year. If you can find a stress that is nonzero on every particular strut or cable, then all of those things are effectively bars. So if there is such an equilibrium stress, then it's not quite the case that you're rigid, but you are rigid on that edge. Every infinitesimal motion holds the length of that edge fixed. It effectively acts like a bar in this configuration. That's what this theorem says. A spiderweb is something where every edge is basically a cable. The reason it holds in tension is all of the edges can have a positive stress, and it will be in equilibrium. In spiderwebs, in fact, this is the same-- these two-- rigidity and positive stresses are the same thing. This is a brand-new result from this summer at [? OSMI ?] by Robert Lang and Alex Bateman. Here's a little example of an origami tessellation, this fold. There's been a lot of excitement about origami tesselations since the mid '90s. Chris Palmer revitalized them, and then tons of people are looking at them. And there's this cool algorithm for building them. So you take some tessellation like these squares, and triangles, and hexagons-- some collection of polygons. You shrink all of them a little bit, but all by the same amount. And then you twist them alittle bit, all the same Amount. Then you just connect the dots. I want to tell you one more cool thing about stresses and tensegrities-- yet another characterization of stresses, which is polyhedral liftings. A polyhedral lifting is going to work if I have a non-crossing configuration. So it's going to be a z-coordinate z of v for each vertex v such that each face remains planar. Because I forbid crossings, I end up decomposing space-- the plane here-- this only works in two dimensions. This is one thing that does not generalize to arbitrary dimension. In general, you're going to have a lot of non-triangles. Those should all remain planar. One thing you can do-- there's some freedom here. If you have any lifting or, for example, you could not lift them at all. Set all the z-coordinates to zero. That's fine. You could also just lift everything onto some other plane, and generally have a rigid motion of freedom. You can lift.of triangles here. This guy can be lifted however it wants in this particular picture. can't translate around, but you have one two-degree two-rotational freedoms, I think. So say remove rigid motions by forcing the outside face to lie in z equals 0. So in this particular example, this guy can go to any value, positive or negative, but that's it. Now, this is a lot like stresses-- in fact, it's identical to stresses. It's probably not obvious, but just like stresses where you could set everything to 0, here you can also setEverything to 0. This is called Maxwell-Cremona Theorem.  Maxwell proved this, or claimed it in 1864. Theorem is there's a one-to-one correspondence between the equilibrium stresses and polyhedral liftings. A positive stress corresponds to a mountain, which is the same picture upside down. A zero stress corresponds. to a flat angle-- doesn't have to be horizontal, but it has to be flat. So it could be like this. I'm going to need this in a moment proving the next thing. It's really hard to see. That's a valley edge here. prove this theorem, but it would be fun to actually see it in action. You compute an equilibrium stress, which is easy to do by linear programming, and draw-- you can directly construct from that the 3D lifting, which would be kind of cool. So far we've been allowing crossings, except for this very last theorem. Now we begin this section where I forbid crossings between the edges, just like what that picture was. Prevent this, and this is a constraint on the configuration space now. configurations where no two edges cross. This is a smaller version of our old configuration space. I'm not going to define it formally. It's a bit messy. But it's not too nasty. Question? STUDENT: What if you have one of those diagonals and switch it to be in relation to each other [INAUDIBLE]? PROFESSOR: You want this picture and-- STUDENT, Either one. Or-- that's crossing-- not allowed. linkage. And a linkage is locked if its configuration space is disconnected. So this would be kind of sad news if you're looking for motions. It means you cannot get from everywhere to everywhere. There are some locked configurations that cannot get back to start. And the Carpenter's Rule Theorem is about one case of that. It was essentially my Ph.D. thesis, so paper in 2000 by Bob Connolly who made that tensegrity, [? Gunta ?] [? Rota] ] and me. And it says that if we have a linkage, and say we take a configuration of that linkage, let's say it's of maximum degree 2, so every vertex has at most two edges coming out of it. Then there's a motion of that. linkage that straightens out-- so if you have maximum degree. 2, you have paths, and you might have some cycles. You might have many of them, and it's going to straighten all the paths and convexify all the cycles. the chain. I could take this one, find a motion that straightens the chain. For convex cycles, it's a little less obvious, but it's also true. There's one catch which I didn't say here. I need to add outermost. When you have nesting like this, you're in trouble. This guy is not going to get straightened out. It could be super long. It may not have room to straighten out inside that convex chamber. So these guys will come along for the ride, but they won't actually getting straightened. The outermost guys will get straightening and convexified. we actually proved the theorem-- so this was open for a long time. People thought this was true. And the key to proving it is by making the theorem stronger. Some of them have to stay the same, because they're edges. They are bars in there. They can't change in length. But everything else will increase. Now there's a couple reasons why this is useful. One is that it says you don't have to worry about crossings. That really makes life easier, because crossings are hard to think about. as we had given. It's also going to have a strut between every other pair of vertices. That says that all pairwise distances must increase or stay the same. What I want to prove is that this tensegrity is flexible. If I can prove that it's always flexible-- well, until the end, which is when everybody's straight or convex-- then I'll have proved this theorem. So while this theorem is about actual connectivity of configuration spaces, it says paths and cycles have connected configuration spaces. Claim this tensegrity is infinitesimally flexible, meaning it is not rigid. And that will imply that there's at least an infiniteimal expansive motion. And then you have to use some fancy tricks-- not fancy, some tricks I don't want to talk about. You basically integrate that vector field, and that will give you an actual expansive motion and straight or convex. But how do we actually prove this thing? Let's not worry about that. The interesting part is show that at least infinitsimally, this tense grity moves a little bit. to show that it's flexible. But it's rigid if and only if this is true. This will actually always be true-- the corresponding linkage is rigid. If I turn them all into bars, this thing's not moving at all. So fact, this second condition doesn't really matter. What matters is the stresses. Now stresses always exist. But I claim actually pretty much all the stresses have to be 0, at least on the cables and the struts. So this will be implied by every equilibrium stress is 0 on all struts and cables. this thing to hold for any of the struts and the cables. And therefore, in some sense, none of them are fixed, and therefore, you're actually flexible. That's implied by this duality statement. This will be true if and only if every polyhedron lifting is flat. So I guess in our case, it will be 0, because the outside face sets all the z-coordinates to 0, so everything else will have to be in that plane. So these are equivalent statements. All I need to prove is that every polyhedral lifting isflat.  equilibrium stress has to be less than or equal to 0 for every strut. Less than orequal to 0 corresponds to a valley edge or flat edge. Now in this linkage, almost all the edges are struts. There's a few that are bars, this, like, little path is a bar. Those could be valleys or mountains. We don't know. But everything else must be a valley or flat. For flat, we're good. We're happy. We want all the edge in this picture to be flat. That seems a little tricky. In a typical case, we're going to get a polygon. Wherever it has a convex angle, you get a mountain here. Every polygon has at least three convex vertices. But there is another situation which can happen, which is, like, you have-- in the maximum z-coordinate you might have a couple of bars at the top. This is all in maximum z. And so when you slice below, you don't actually get a wholepolygon. might actually only get something around here. But again, you can't get from here to around there without some mountain. It's hard to even imagine, because it can't happen. So that's the one way it can happen. You can't have strict valleys, but you could have them all 0. So in fact, the one case where you can have stress is when you have all of this outside stuff flat. And then inside you don't know. I can prove, using this generalized lemma, that that's not possible. all of these regions are locally flat. And therefore, this whole outside face has to be flat. Therefore, I'm particular. I can't have a reflex vertex, because then this side would have to all be flattened. So then the whole thing is flattened. Also straight this can happen. I think with straight, you don't get any stress. Here you can actually have a lifting. Actually, all these guys would be below the plane, because everything's a valley. This would be like an actual valley, where you have a village or whatever. That can happen, but only when the boundary of your valley is convex. And so that proves the theorem. dimensions, and maximum degree 2. We can think about what happens with degree 3. Then you can get locked things. What happens in three dimensions? Then you Can't get locked Things. What happen in four dimensions? then you can't get Locked Things. Oh, and why is it called the Carpenter's Rule Theorem? Because this is a carpenter's rule. And in a car Carpenter's rule, actually, all the edge lengths are the same. But as far as we know that doesn't make this theorem any easier to prove. still buy them at the hardware store. That's it. You can't buy them online. You have to buy them from the store. They are not available online. They can be bought at the store, but you have to pay for them in cash. They're not available on the internet. You must buy them in the store to get them. You cannot buy them on the Internet. They must be bought from the hardware stores. That is it. They have to be bought in the stores.

ROUGE-1: 59.42, ROUGE-2: 57.10, ROUGE-L: 56.95
BERTScore: 70.46

==============================================
==================== [97/100] ====================
Summary:
Chess has been known as a tool of military strategy, a metaphor for human affairs, and a benchmark of genius. Our earliest records of chess are in the 7th century, but legend tells that the gameâ€™s origins lie a century earlier. Supposedly, when the youngest prince of the Gupta Empire was killed in battle, his brother devised a way of representing the scene to their grieving mother. Set on the 8x8 ashtapada board used for other popular pastimes, a new game emerged with two key features: different rules for moving different types of pieces and a single king piece whose fate is decided by the king. The game was originally known as chaturangaâ€“ a Sanskrit word for "four divisions" After the 7th century Islamic conquest of Persia, chess was introduced to the Arab world. Medieval trade along the Silk Road carried the game to East and Southeast Asia, where many local variants developed. In China, chess pieces were placed at intersections of board squares rather than inside them, as in the native strategy game. And historian al-Masâ€™udi considered the game a testament to human free will compared to games of chance. By 1000 AD, the game had become part of courtly education. Chess was used as an allegory for different social classes performing their proper roles. The relatively weak piece of advisor was recast as the more powerful queenâ€“ perhaps inspired by the recent surge of strong female leaders. This change accelerated the gameâ€™s pace, and the 15th century saw it cohering into the form we know today. In Japanese shogi, captured pieces could be used by the opposing player. With the Enlightenment era, the game moved from royal courts to coffeehouses. Chess was now seen as an expression of creativity, encouraging bold moves and dramatic plays. The emergence of formal competitive play in the late 19th century meant that strategic calculation would eventually trump dramatic flair. Today, chess software is capable of consistently defeating the best human players. But just like the game theyâ€™ve mastered, these machines are products of human ingenuity. And perhaps that same ingenuity will guide us out of this apparent checkmate.

ROUGE-1: 69.10, ROUGE-2: 66.35, ROUGE-L: 60.83
BERTScore: 74.96

==============================================
==================== [98/100] ====================
Summary:
presenting okay share your screen that's what I'm doing oh you are okay hopefully it is yeah stop sharing yeah you should be sharing my screen under your camera until I can decide if I click on slideshow this is still show my camera uh it does I guess I can minimize it do screen sharing are you recording too yeah great baseball back yeah I mean it's my first time giving my lecture so I'm as good as I can be do you want that cheers I mean I have to write something to hear me okay okay you know that it works. a kid but I have like admins responsible because I don't need a sections foreign [Music] thank you okay let's see what's going to happen what are we supposed to be in the cereal and we are both presenting our place it's not happening. homework one is going to be due next Tuesday so probably start that if you haven't already um the quiz for the week is due on Tuesday. It's almost 7 10. maybe like maybe two minutes at least yeah yeah we will get started in a few minutes. this week will probably go live tomorrow uh not quite sure yet but you'll try to get it up as soon as possible so I guess like without further Ado let's Jump Right In. I'm gonna go somewhat into detail into what representation learning is and I think this should sort of cap out the last few weeks of deep learning um and probably give you a more comprehensive understanding of what deep learning actually is doing. So I guess before we jump into deep learning let's talk a bit about shallow learning so say you have the classical machine learning problem and the way it is set up is you have some input X and you extract the features from this input. X and you pass it into some model that is going to be parametrized by some data to get an output y. Keep in mind that this sort of theta is. going to contain all of your learned parameters so if you have a neural network this would contain all. of your weights biases any other things that you might want to learn if this is say a regression model this would just contain the weights and maybe a bias term if it's if if one is there. might not be something that you can so let's say that you're working on a problem of predicting the price of a house from a house so your X can be a house you can really put that into your model right you would have to extract some information about the house. This information can be things like the number of rooms in the house uh the size of the house how old it is that can be categorical variables like does it have a pool back here or a basement any of that. Once you extract these relevant features you can get your output y or you canget a prediction Y. close to the true level as possible so just to sort of recap uh the machine learning pipeline you start with an input X you extract all the relevant features from it um and then you push those into a machine learning algorithm should get an output Y and you sort of optimize based on that so I guess now we defined this feature extractor or something that we need to we this is something thatWe need to Define right so and you might imagine that different kinds of problems will have different kind of feature extractors so if your data is arranged in say a table. row directly right or you can also maybe take a column depending on however the data is arranged in this tabular format but what if your input is something complex like it can be text audio images right how do you extract all the relevant features from such a complex input? So since this is a CV class I'm going to go over the CV example and turns out that there are special feature extractors for images so this is sort of what classical machine classical CV look like you people would come up with all of these like different kinds of feature Extractors. be an svm with learned weights for example now something you have to notice is that this feature extractor is something that you. have to program yourself this is not something that's being learned right now it's something that. you come up with yourself based on your intuition about the problem whatever you think might be the most relevant features for this problem right. If you want if you have a task that has to do with the colors in an image this sort of these features won't really do anything because this gives you edge information right. You have to define a different feature extracter does that make sense. really fast and this is also kind of a compromise solution in the sense that you are learning the weights of your model but you're still hand programming the feature extractor yourself. As of right now only the second half is automatic the learning of the weights we are still defining the features ourselves. This is sort of where deep learning comes in so deep learning says that hey we don't need to hand program feature extractors we can all we can learn those as well. We can learn the entire pipeline from feature extraction to um training and you could just need to pass in this like raw image input and it will spit out an output. of the pipeline so one example of this is you can use a something called a convolutional layer again don't worry about what a con layer is that is something that we will teach you guys next week but it is a neural network layer that can extract features from an image. This extractor has parameters that can be learned sensor of something like something like hog which is sort of a very stationary in the sense that it doesn't really change. You can learn this feature extractor and you can then pass these features into a learned algorithm so in in Post-its in both steps of this process you're learning something right. what if you combine them and that's exactly what a neural network is a model that combines with feature extraction and output prediction and it learns everything from the data so hopefully it just sort of gives you some context as to why deep learning has been sort of taking off and classical machine learning is not as used and areas like Vision anymore because deep learning allows you to sort of automate this entire process from end to end and in a sense what you're really doing is you're learning a representation of your input right so your features are a way to represent what that input looks like. lot of information does anyone have any questions about any of the any of this uh in case nudge I'm gonna pass the my country Verona who will talk about transfer learning okay yeah so now that we've sort of gone over an overview of what representation learning is we'll talk a little bit about what transfer learning is and what the benefits might be. When we train a model from scratch which we don't usually do a lot of the times uh it takes a lots of time compute and training data so to just to give you an idea of how much data is often necessary to train a pretty good model even just a few thousand examples is often not nearly enough. but luckily huge models have already been trained before so the sort of question is can we leverage them in some way and the answer is yes absolutely. Many of these pre-trained models are frequently used all the time and so we can take a look at how and why we might want to use them. If we train a model from scratch our model parameters or our weights are randomly initialized in the beginning and then we update them gradually through an optimization algorithm such as stochastic radio descent or something like atom. Without transfer learning we might have to train these two models separately from scratch. earlier is very costly in terms of time compute and data so the idea is can we do better and so when we learn something we often find in general you know just like us ourselves what we can use what we've learned already and apply them our skills and our knowledge to other domains right so just to give a little example let's say we have a convolutional neural network trained for a single or a single user. We can apply the same idea to our neural networks so as an example. simple computer vision task like a cat versus dog classification or some sort of object detection and again no worries if a convolution is sort of familiar we'll cover convolutions and CNN's in much greater depth very soon. So for example um each of these models should be able to for example capture how low-level features as Arya mentioned such as the general shape the edges the patterns and the colors in the lower layer so the more earlier layers of our neural network. Then once we've moved on and we've gone towards the later layers they should be can to capture some higher level features like the abstractions of the cats versus the dogs people's faces or some of the major objects. at the end we reach to a close to final level of the attraction that we fought and just for a slightly more concrete example let's say we train a residual neural network on the imagenet data set. We want to figure out what aspects of this network is already shared among the other ones and we want to keep that shared information and then basically use that kept information for our other models. How might we actually go about this um and so in other words like how do we actually transfer or do transfer learning? so we can add and train the later layers to basically customize them in a way that sort of satisfies the tasks that we want to perform on uh for the second task. The layer weights of a trained model are not changed when they are reused in a downstream task and by freezing layers you might imagine we're not really modifying the weights or parameters and so that backward pass that we talked about earlier is what we're going to use to train the layers. So we generally want to keep those General shapes textures patterns but our abstractions might be a bit different depending on the type of tasks. in the past few lectures can be basically avoided so the speed of our model increases by a lot by doing this um just sort of a note is when you're trying to freeze certain layers be careful of where you're freezing your your model so if you freeze layers too early on um that's basically sort of useless like this can lead to pretty inaccurate predictions because you're not really understanding the low-level edges for example. The more data that we generally have for our Downstream task the more that we can unfreeze the layers of our original data original model and then fine-tune them again for our specific second task. um and the similarity of the new data set to the original data set so for example in the case one where you have um a small small data set or a lot a large data set. Since it's larger we have more confidence that we won't overfit if we fine-tune. On the other hand if we have a smaller data set even though it's similar to theOriginal model it's not a good idea sometimes to fine tune because you can definitely overfit. And then in the third case in which you have like a smallsmall data set and then it's pretty different from the first task um. you can probably um fix some of the initial layers but you don't want to really fine tune and then at the very end you have a very large second data set but it's very different from the first task so you can probably just change it from scratch. In practice it's mostly beneficial toinitial your weights from the pre-trained patient model okay so um before we sort of get into embeddings um just some practical advice so just a few other things to keep in mind when you're performing transfer learning. In terms of neural networks embeddings are pretty important so they are often described as lower dimensional learns continuous Vector representations of discrete variables. Embeddings are useful because they can reduce the dimensionality of your categorical variables for example and meaningfully represent them in the transform space. In this photo example they've decided to use teasney for thedimensionality reduction so taking the embedding Vector dimensions and mapping them to a 2d space in this case um plotted they also plotted the embeddeddings and then they color coded based on the genre of the book. to embeddings to something called a latent space so we often prefer to work with lower dimensional data. High dimensional data is embedded in a lower dimensional space latent space and a lot of the time latent space is sort of interchangeable with like an embedding space. One of the reasons that high dimensional data or high dimensional spaces can be bad is because if the data is naturally a high dimensional the high dimensional space is bad for the embedding. So what we offer is what we often call the curse of dimensionality. lower dimensional structure it's going to be very sparsely spread out in your latent space as you can imagine um in high dimensional spaces so a lot of the times you want to be careful about yeah I don't know you can sort of draw something yeah but you don't need to work with the entire 3D space. This sort of goes back to the idea of of course dimensionality because you can see that all of these points occupy a very small region. This is an example that I came up with so say that you have the 3D. space but your data is along this line now yourData is basically has a one-dimensional structure right. of space in 3D right so the idea is that if we can directly work with the significant somehow find a way to represent this line using just one variable instead of three and so here's let's say the XYZ coordinates that's going to be better because like a high dimensional data can be very complex we want to avoid that as much as possible thanks okay. One way is to learn and embedding as part of our neural network for our Target task so this sort of allows us to get in a bedding that's nicely customized for our particular task but it may take longer than training the embedding separately. for other tasks again embeddings they're sort of just like what we talked about earlier the broad ideas that we're trying to um represent our data in meaningful ways. So here's sort of an example um honestly it'ssort of like I don't know we talk about we don't really quite talk a lot about soft soft Max but um you can sort of see how there's different ways like we have um one hot Target probabilities. So um I didn't do this do my run this part what's up the target Boston oh yeah um oh so this example. as a 70 784 dimensional Vector plus 25 to 784. You train this using a soft Max loss because soft Max is the loss that is used for classification. Once you train this model you can take um can you see my cursor you can once this model has been trained these three like set up neurons in the middle of the model can then be used to identify a digit in an image. It's basically because it's a loss function don't worry too much about it so the idea is that. used as an embedding for this mnist image so once this model has been trained this the weights must have learned something meaningful right so this means that we could just take some of these layers in the middle take the output of that as a representation of this 20 dimensional 28 by 28 dimensional image okay. Here's sort of an example of some of the results from training networks from scratch versus applying some sort of transfer learning um from a paper so in this example the authors compared pre-changed convolutional neural networks for audio classification using transfer learning and they found that the retrained models with transfer learning applied actually achieved better accuracy classification accuracy than retraining the network from scratch. major advantages of pre-trained networks so a lot of the time pre- trained networks are trained on very very large data sets and oftentimes again more data means better representations. Pre-compute and store our embeddings instead of using the original High dimensional data which can again save aA lot of time and Storage okay and so here's just a very very broad summary so without transfer learning we're basically trying to learn two separate tasks and train our model separately um but without transferlearning we'reBasically trying to learning two separate task and trainour model separately. then with transfer learning we basically apply the knowledge that we've learned from one pre-trained network and apply that to the second task and so we've talked about two main techniques for doing that freezing some layers and fine-tuning our our Patriot Network. So very broad once again you basically just apply your knowledge um and try to transfer that to another task instead of relearning everything. We'll go into some details and examples of this in action but especially um I know this is not an NLP course we talk more about CV but transforming learning is especially huge in NLP. of words once you've pre-trained you can understand syntax so you can imagine in tasks for natural language processing it takes a lot of time if you want to retrain an entire network so using pre- trained networks and using transfer learning is a really really good idea. Not only does that apply to NLP it applies to almost other domains every other domain xcp yeah okay so we will transition to the next part of the lecture which is going to be on self-supervised free training. notion of a loss that sort of Compares how far apart this prediction is from the ground truth label y right and your goal is to optimize the network such that this error decreases and your model is trying to output something that is very close to the actual labels y . so in a sense your training process is receiving supervision from the labels your super your labels are guiding what the model must learn and some examples of and and this whole process is called supervised learning like the name suggests. Some examples of supervised learning can be your typical classification problem like the one that we just showed where you classify digits. 16b I think you might have seen regression in those classes um there are other examples of object detection segmentation we will discuss those in the coming weeks. Even without any labels we can still learn something meaningful about the structure of the raw data how many have you guys taken 16b before so yeah you may have you might recall something called PCA from the class of principle component analysis it's actually one of the most common unsupervised learning algorithms out there. If you remember correctly you just input some data Matrix into that algorithm and it splits out those principles common inductors. any labels into that algorithm you just feed in the data Matrix. If you remember from the 16v car one thing that you did was to you you took the audio signals from the words that you would pass to the car and you would cluster them together again. There was there were no labeling involved you just took each audio signal um projected it down to two dimensions and clustered them with other points so yeah it turns out that dimensional eruption with PCA clustering etc etc are common examples of unsupervised learning. draw like decision boundaries based on that but even if you don't have any labels the model can still learn that okay these points are dripping up together they're forming clusters and this is still like meaningful information that themodel can learn. So yeah hopefully it's sort of this picture makes clear the difference between unsupervised and supervised learning so the examples that we have discussed so far when we were going about transfer learning was supervised pre-training so we take these large models that were trained on say something like imagenet and usually these models like a resnet are trained for the image net classification task. Large data sets are helpful for learning more generalizable representations. English Wikipedia has hundreds of millions of text tokens in that but you can find like a trillion tokens on the internet of text right so if you try to harness all of this information and maybe you can learn better representations, this goes beyond CV as well. Since this is classification is a supervised learning problem you have a label associated with each of theeach of the images in the data now we mentioned before that large data sets can be helpful. using that and turns out this is a pretty good idea also but it turns out that these large data sets are usually not labeled you can you could like scrap text or image or images from the web but you can't really label them automatically right so a lot of the time you're working with unlabeled data. We want to see if we could use unsupervised learning techniques to the sum level data sets and learn representations using that and this is also appealing because labeling in general is a very time consuming and tedious process. Gathering good labels is simply a very very hard process and so that the question that research has asked is if it could do unsupervised representation learning and indeed we can. So the valency provides representation learning is done is to play to something called self-supervised learning. The name suggests that the data is receiving supervision from itself you still don't have any labels with the in the data set. But what you can do is you can create labels from those images and train in a supervised manner. part or property of the input from any observed or unhidden part of the Input. This information can be hidden across time or space. We will go over some examples soon and actually we will have an entire lecture dedicated to self-supervised learning for um Envision in a few weeks so we'll double deeper in that lecture Cube so again some more terminology before before I go on to examples. In a discussion of transfer learning we have been referring to two different tasks as task one and task two which is you know not a very descriptive name. name so the task on which you train the representations you know what what we have been referring as to cast one for so long is also called a pretext task. The task that the representations are transferred down to are also known as a downstream task now different domains we have different kinds of Downstream tasks. In computer vision this can be something like you learn the representations from some pretext tasks and you'll use those representations for image classification or object detection or semantic segmentation or whatever for NLP this could be somethinglike text classification machine translation document summarization question. means but yeah just wanted to show that great training is a very broad topic and self-supervised learning algorithms can be applied to different domains. So I guess we can delve into examples now so this was a paper that was published in 2017 and it was called jigsaw what the authors do is they take an image they take some part of the image and divide it into a three by three grid so you get nine patches. Shuffle the patches around and ask the model to predict the original order. a very easy way to like cheat this process right so which is why you might see a non-perfect written image a any questions about this task before I move on yeah so what they did is they actually take they took the representations from this pre-text task and tested it on classification and protection um Downstream tasks. It turned out that this was sort of the best pre- text task at the time and it actually and then it actually sort of bridged the gap between supervised and self-supervised learning in a sense. and I think they just took the thing that created that as like a frozen feature extractor representations that way another task is something called broadnet uh it's sort of a similar idea but instead of predicting let's say a shuffle order what you do instead is you take an image you you rotate it by some number of degrees and which is selected from zero 90 degrees 180 or 270 degrees. You ask the model to predict the rotation angle from the from this rotated image and the hope is that. branch is still going to be the same in each image so the hope is that the model can learn some of that information is that a single image might have different kinds of objects and it might have to learn to focus on something like the object's orientation location pose type etc etc. Instead of just focusing on again low level details I think this sort of next example makes it more clearer so on the left hand side you have a model that was trained in a fully supervised manner and when you look at what is focusing on on a given image it's looking at a single part at at one time. On the right hand sideyou have this model using the rotation prediction task and instead of focusing on a single parts it's looked at multiple Parts at the same time. if you look at this image on the bottom right it's looking at the eye of the cat and sort of it's not at the same time to see if there's like a relationship between those two and in the image of a dog it's. looking at both the body of the dog and the face at the. same time. It's trying to discern some sort of relationship between the two so maybe this is a way to like qualitatively show that this also provides learning algorithms are trying to learn something much more Beyond supervised training turns out that this example is not constrained to just CV you can also do SSL with NLP. this can be done is you could predict a word from its surrounding context so say if you have the sentence the dog with the man you could try to predict the word bed from dog and dog because a dog should kind of imply that the word bit is associated with it so this approach is called a continuous bag of words model. There are many other ways to train virtual back models one example is skip Ram so instead of predicting aword from a context you instead predict the context from a word so you like kind of like flip the model upside down.  SSL can also be applied to audio it's a very broad sort of paradigm and I think the currency of the art and audio classification is Wave 2 Vector Q which I think came out a few years ago okay so what if we go back to this idea of where to work we are predicting a single word from some surrounding context right. What if you predict a word from the entire sentence that it is a part of and as I think I think you might imagine that this white this might work better because the sentence will give you more context than just like those two surrounding words. you can try to predict multiple words from a sentence and what when what happens is that you call these like multiple words a masked word and your goal is to predict the masked word from the rest of the sentence. There's a very famous model in an NLP called bird which takes us to the next level uh the bird is something called a Transformer model you don't need to know what Transformers are yet we'll have a lecture on that later in the course. Verge Texan these sentences that have like Mass birds and it tries to predict what those Mass birds are. words are it actually goes a step further it actually takes in two sentences instead of one and it protects the best words for both of them and at the same time it also predicts the order of photosynthesis. So it learns a word level and a sentence level embedding now bird was a huge success in MLP and I think bird is sort of what kick-started the interest in um self-supervised learning back in CV because this this idea of SSL and CV kind of like died down a bit in 2015 2016 2017. the slide is it turns out that the current state of the art for CV is actually very similar to Burke so that's a teaser for the lecture that we discuss Advanced Techniques and as software CV. I just want to point out that this specific lecture doesn't have any homework but there is a homework for this entire cluster which is the high Crush notebook that should be due next Tuesday even though this lecture doesnâ€™t have homework I mentioned before that there will be a lecture on on Advanced SSL for CV. and that will have a homework so if you ever need to review uh the topics from this lecture so to work on that homework this slide deck should be up on the website again if you feel free to do that. That is it for today a second pause. Back to the page you came from. The slide deck for this lecture is now available on our website again. Click through the slide deck to see the rest of the lecture. The lecture will be available again on the site later this week.

ROUGE-1: 74.78, ROUGE-2: 72.09, ROUGE-L: 71.23
BERTScore: 80.54

==============================================
==================== [99/100] ====================
Summary:
"Chat GP" was the tool or the the AI that really made people understand this is different now. So hopefully after this lecture you'll you understand kind of the basic idea and also somehow understand the BET right the bet that open Ai and Ilia the head researcher did in terms of what actually would lead to CHP and how in hindsight it might be quite easy but it was a really daring bad not obvious at all at the time that this would actually work out. "Chat GPT" is the third lecture on Foundation mulative AI. of fun and just to quickly go through our course schedule as well a little bit right so today is January 16 uh and next time we'll talk about stable diffusion image generation and then we'll talks about emerging Foundation models basically Foundation models generative AI in the commercial space H we'll have two guest speakers and thenWe'll end with the lecture on AI ethics and regulation as well as a panel okay so what have we talked about before we started off H with an introduction a short high level intuitive answer to what is foundation M generativeAI. GPT relies on a lot of tricks and Engineering insights and breakthroughs that we're not going to cover. We apply this self-supervised learning where we learn without label data so we can get as much data as we want because there's no human being in the loop. What we get from this you know by learning from observation and learning from the data directly is a very contextual and relational understanding of meaning. We'll talk about something that's extremely engineering heavy in you know chat GPT. be useful for you without getting into all the engineering details but of course in real life those engineering details really really matters and are very very hard to get right and that's something that we won't really dive into in this lecture because that's just when you bring something up certain scale and you have to paralyze a lot of machines Etc and think about high parameters it's a whole science so it's not trival at all but it's kind of hard to teach in a course like this. Force things to comply to Simple Rules right it kind of abandons our ability to understand and compress what we're seeing and deals with that chaos directly. That's why AI is so powerful and so humanlike um so also like when I talk about this in CHP we try to make very high level um statement but of course the nuances matters. I think it's quite interesting uh I took this quote from a general from the 18 and 1700s and he says this quote that P Theory which sets itself in opposition to the mind. in War uh and Wars don't comply to rules first off so you know everybody has a plan before they get hit in face basically. So you know as people start shooting at you and you have this fog of War of you don't know what's going on there's no simple rules to help you there and also what he says this in terms of the mind he says like well actually he's realized by working with soldiers that soldiers and human beings our mind we're not good at acting according to rules that we try to memorize. Chat GPT stands for generative pre-trained Transformer and this is a I mean a good description of what this uh actually actually means. GPT can basically solve a really wide array of tasks for us anything that can be phrased in terms of text language it can. it can basically solved and now as well when with gp4 ET becomes uh it's able to handle multi modalities but it's it's extremely powerful so let's try to break this apart well first off what does this name actually stand for. is um and I think also if you look at the the two different three different concepts here they're also almost corresponding length in terms of how important and influential they are in making chat GPT work so chat part we we'll cover last it's the kind of the least important one in some sense H the Genty pre-trained is the self supervised step of how you train this and arrive at this uh model and then the Transformer is the basically the engine behind it in somesense and so let's start with this generative pre-train. so we have a sequence of words and and then we're just going to try to predict uh the next word based on previous words so let's say we have uh we start with i here as input. Then we want to someh predict the Target right so we know we know or the computer knows somehow by just downloading the text that what this whole sequence is but when it trains this AI model it hides part of it right so it just inputs I to the AI model and then it's supposed to do something with it. We're going to create scores or predictions for all words in the L like in the human you know vocabulary in the English vocabulary that sounds extremely expensive and it is quite expensive and so I have different tricks to make this work. Then it kind of gets it right and then you give some positive feedback back. Then you give this feedback to to the model it's called back propagation so you given some feedback through model it should push the score or the probability distribution for the correct one to be bigger or larger. then reduce all other ones so you know the next time it sees uh the same example or a similar example it actually does better and you know this is just one single example but you accumulate all of these directions and information across a batch of examples that you see at the same time. So it takes small small steps to getting a a better and better distribution and a more itic distribution of what word will come next given previous words and you do this in a batch on tons of examples and of course you know we have unlimited amount of data. like a a specific token that says we're happy until we complete a complete sentence for example. Like a a a token that say we'rehappy until we finish a sentence. You have to generate one thing at a time but of course training is is much faster because then you can just you don't need to generate and run on your own input. You just run look at the input that you get yet but here you actually have to look at. the prompt generate the next word add it and run it again so it's kind of expensive. we talked about this a little bit before and now you know if it's really good at predicting the next word based on previous words we can give it interesting prompts and it can start solving interesting tasks for us. If you try this for CHP right it does so it basically has killed a lot of different research Labs that focus on a specific task because now it does all of this really really well and I mean this is basically from a modeling perspective this is chdp in a nutshell okay. CTP was trained at a scale with an amount of data and parameters that we never seen before. Just training the final model cost around $5 million just in in Compu electricity bills right that's how huge and much compute they spent on this. It's a very very simple approach but it's it's a certain scale that's that's never been seen before and really that's what a big part of open eyes is to open eyes to new ways of looking at the world and seeing the world. bet and and the research there is like well you know we've been doing this language modeling for quite some time trying to understand Language by predicting the next word based on previous words and we're using it for certain things but I mean know very few thought and were convinced that if you just scale this up big enough it will become a multitask Sol and show humanlike Intelligence and that this actually really will work. People talk a little bit of this emerging abilities because also it's not linear right like you start adding and putting putting more and more compute and parameters. well we're just going to go all in and just make this bigger and bigger and big and and and then like in hindsight like maybe it makes sense but it could have been a case like it wouldn't work and then people like oh that's a stupid bet like why would you think such a simple idea and approach would lead to to such sophisticate intelligence but it did okay so we covered thetive pre-train part right so uh you know we've now said how we basically are going to uh train our model but how does this model look like like how did this kind of engine look like. Transformer part is extremely extremely important so there's a debate a little bit what was the most influential part of making uh CHP and large language model possible uh Transformer is definitely a significant part of it and and I'll let you judge for yourself but uh I think it's less important than the actual modeling perspective that we've we've come up with okay so in order to understand the Transformer we're going to start to thinking about how we can process sequences so text is just sequence of words. some intermediate embedding or feature here one and and then it uses the that in a second step to uh predict the next word okay we go on and thenIt uh looks at the second word so I I lookas went but of course to be able to do a good job you also wants to able to incorporate the previous word and the features from there so you kind of also processes and includes into the second Vector both the previousword and the current word to create a new representation of the whole sentence so far. is that for every step here that's label with the same uh digit you know they can all be done in parallel. This is key because in in deep learning we use this uh um computer is called gpus. If we can make multiple steps into single step in parallel this is a single cost. We want to run things in parallel as much as possible so here basically you know this be a cost of four because all these different numbers can be run in parallel uh so this would just be acost of four and then of course processing this whole sequence will be a costs of nine. these are extremely extremely popular and a version of them called uh lstm long short-term memory networks um it performs really really well and some people say it performs you know almost better than Transformers a lot of times. But they just take them longer to train because we're going to realize why it one a point but they work really really good and also notice here somehow that uh this was very very intuitive for researchers to say like well text we read text from left to right we process words one at a time and therefore our models should be able to learn effectively from them. things flow forward this in kind of this sequential way right so to get from uh you know for the information from I to go to the information prob being processed step number nine basically right when you want to predict the period has to travel eight or nine steps here to to to uh be used so let's think about this a little bit start we start off now in a Transformer which basically starts off the same way so we we let the first we know we just process the first word uh and we prict the next Target based on that. when to the Target so we kind of we're we're not going to enforce this quential structure we're just going to directly let the information flow from the previous word to the current word Etc right what we've seen so far. The important thing to notice here right before when we were processing things sequentially you had to wait for the previous step to finish to do the next step. Here you don't because here everything is processed independently. Every Target somehow has a a node or sorry an edge to the previous words so they can all be run in parallel they don't need to. to wait for anything they basically kind of re redoing all the work somehow for every step because they all have this added to the previous words so all of these steps now like none of the steps have to wait for each other right there's no independency they can just go Direct to the the the source and use that information and of course you know we do this for the whole sequence and um again to reiterate right so for the last Target all ofThese computations can be done in parallel right they they're somehow aggregated at the Target. in parallel it's the same step and this is true for all of these steps yes this sense when we compute a output distribution over all the words later like as a prediction we talked about the first thing know oh yeah yeah sorry sorry so exactly this this works only during training now right okay and I'll come to that actually later so this is onlyDuring training where we can optimize this way okay but that's also yeah that's a great question butthat's also like something that's uh in uh in deep learning we basically almost I mean the training is the most expensive part uh. and it's going to be much faster to run so it's much less uh uh well that's a modification but uh it's a little bit less sensitive in a sense. We care about both being fast uh and yeah I mean but somehow H this is going toBe much much faster. to train than a recurr network so you're going to get much much better performance and then the difference in deployment is less uh significant okay but during training we can do this because we not upend the words we just see them in the sequence. I mean what's the biggest difference somehow right one of them the top Rec Network looks very structured right this has kind of a strong bias of of processing things sequentially the bottom looks very chaotic and it looks like Ah that's just a lot of connections it probably is pretty hard to make sense of the sequence given that it's all FedEd you at the same time uh so it's may be surprising that one works better another one you know one that definitely kind of needs more data to start learning useful things. sees the first and then Financial but in a Transformer you know in the below here like if the only thing you see is the word and they're all F to you know for for if you look at the prediction we going to do at at step number nine if you see all these words the same time right there's some kind of comp like you can permute all the words and you basically see the same thing so there's no sequ there'sNo sequential structure and force and Transformer whatsoever. just you know words there's no sequence anymore because everything is connected in Transformer but recur not there is still the sequence by how by virtue of how things are processed so how we solve this that is that for for the Transformer we're just going to add to each word a positional encoding so we just add the position again. The Transformer has to figure out if the sequence matter it should use that information even but it now has that information at its disposal because we're going to encode a sequential structure. It's like seeing all the words in a book at the same time like it's fast but it's very confusing. figure out by a small you know number how things are actually oriented so like if you go to the movies and you think in terms of of frames you can sit down and digest the whole movie in one second it's like super efficient but you're seeing all the frames you know flash at the same time and then after like in your own head you have to put them in a sequential order if it's useful as you know understand the plot of the movie which typically is right but there not like the transformer has to learn that implicitly. if you read a book or you watch a movie if you want to understand the end part it might be good to kind of go back and look at the the start starting part of the book or something you know or or it's good if you remember that information but probably you know if you don't remember you have to go back to look it up. In a Rec Network Rec Network because we're processing things uh sequentially here so to for something to be used like to for for information about the first uh word in the sequence. of work was done to make that work better but the nice thing with Transformer is that it has a direct connection so if it's a very strong kind of recurring uh thing that the first word and last word correlate somehow it can pick up on that very quickly and make that edge very very strong and kill out other edges. So you can basically incorporate long distance information in this sequence very efficiently because there is no real sequential structure but when we force the sequential structure and Curr Network it's much harder because then we need to remember that as we process things. be efficient and work well so now we're just going to look at the F last part which is the chat part um so you know you you you train this model now that you call DPT 3.5 or something and now you want to turn turn into chat GPT right so we have a really uh good model basically we've done 99% of all the the work that's that's required and a lot of people still kind of debate how important this last step is but open is it does a difference. The model now has been trained on a vast amount of data from you know any Source on internet you can imagine right so novels Wikipedia Facebook posts uh you know anything basically but how you how users are going to use this is through some chat bot right so it's dialogue like human dialogue is what they call it. We're going to find T the parameters only on human dialogue data so it can hone in its parameters and focus on a specific use case okay so we do that and we're even one step closer and so now we're working we work even better. would really good if you understood what's not helpful dialogue and what's helpful dialogue so you can just give us helpful dialogue. Another problem is that we're somehow too greedy so when we train things to predict the next word based on previous words all we care about is to give the most likely next word. We should be a little bit more long-term optimizing because if you give a whole sentence we. care about the the quality of that sentence that's what we want to optimize for. are going to use this and interact with it in ways that maybe it doesn't really correspond perfectly to its training data so it's going to uh see things I haven't seen before so there might be a kind of a distributional shift between how people use it and what it's been trained on. No AI model is is perfect so maybe it accumulate some error as it start adding words and it's just going to go off a little bit and it will add a word after word so it adds aword after word. just goes off a little bit like here for example when you say you know I went to the financial and then just you know some small error happens and it goes off the road to restaurant like somehow you know they started seeing that okay now it's basically go Haywire because it went off and it's in a different space than it's been trained on. So somehow we want to be able to say like well if you find yourself you know alittle bit off the the the path you should be can to find your way back to be as as robust as possible. possible to be as useful as possible okay so uh these are the the the three different things we want to address right what's good and bad dialogue. We want to be more robust and learn to solve correct and this is where we're going to do reinforcement learning from Human feedback. That's what open AI does on chtp and this was very very hyped for a long time but now people talk less about it uh okay so what do we do well we have a great model that's been fine tune on dialogue and it's able to generate really good answers still. to any prompt that we have so let's say we and this is very cheap to do so we have you know a million prompts that we found online now we run our model four times on each prompt with different random seeds we we sample four different answers so now we have 1 million prompts with four uh candidate answers okay and then we're going to say that we're pretty rich so we's going to pay people to actual human beings to label these they're going. to rank this this uh prompt or the answers that these models produce to these prompts. we don't want to use them too much so here again we're going to go to reinforcement learning and say to deep learning in Ai and say well we now have 1 million prompts with four ranked answers but why don't we train now a AI model a new AI model basically to simulate a human being assessing assessing the quality and ranking these prompts. So um we'regoing to now take this model this robot basically right to look at a prompt and generate an answer and then and then it tries to predict the score that a humanBeing would give to this uh answer this prompt right so just learn to imitate human beings ranking these answers. good or bad dialogue so we've solved that okay and the last two problems we are going to solve by using reinforcement learning so what is reinforcement learning well we talked about this a little bit before but uh something is very important and characteristics of reinforcement learning is this delayed feedback so uh in reinforcement learning we're going to allow it to start generating things right it generates a word puts it in its own input and it reruns itself so it becomes a longer longer sequence one over at a time so we start off with this I and we now have a probability distribution. There is no instant feedback so we're on our own and only when we you know we reach some uh predefined token like a pier for example then we stop and then we give uh our sequence that we produced to this robot and then it tell robot like hey is this good or bad. Only at the very end when we're like Hey we're done we give it to the robot and he scores it then we get the feedback okay. Why is this why is this difficult well it's difficult because let's say we do this again so I mean when we produced.two and again there's no at this point thereâ€™s no feedback we don't know if we're doing a good job or not. I went to a walk period I mean uh at least it's a pretty good sentence it's like medium score at least but let's say we now generate I went to lip I row row period. That's not not a very good sentence. It doesn't make any sense basically it's is a very very bad score uh but you know a big part of reinforcement learning now is how do you make sense of this information you have two signals you start off doing the the same Step at the first step and then they diverge what would actually caus one sentence to be better than other one. is about like how do you figure out what actually helps you reach your goal and optimizing your score function even if it's delayed um okay so another thing in doing this that's very very important it's exploration versus exploitation so let's say now basically that our model has seen these two different cases and have received two feedbacks right. In one of these you will got a pretty good score and in one uh you know in the lower here you got apretty bad score. Let's say we rerun this model again and it it went from I to went and then it kind of it remembers a little bit what we've seen. far so if we go down this path to I went to a walk then at least we know that going to do a decent job and better than this alternative that we've seen. But the problem with this is that if we do this you know we're not going to see anything new we're just going to explore and explore the the things that already have received feedback on they we already know St pretty well. We're not we're nevergoing to do really good to do better because we are just only going to exploring the sequence that's we already have seen H. example you might again find a much better solution that's much more optimal and that that's what you want to accomplish. In order to generate you know this exploration you you know want to be a do a very very targeted exploration around language is still kind of make sense so the robot gives you good feedback and you actually can start you know making progress so that's also why you uh open is able to use reinforcement learnings because they have a really good model and language already and they're only really exploring the fringes of the knowledge this model model already has. gratification actually leads to very non- GRE and and independent robustness so these are the consequence of applying reinforcement learning where you only get feedback at the very end so there's less you know supervision right you're more on your own. H deal with an uncertainty of not having constant feedback you have to figure out things by yourself which leads to you being more robust and also again in reinforcement learn here the only thing we care about is the signal at the end so we don't care about making the best next step. We care about optimizing the whole output so we're now addressing these things. just constantly doting on them H it leads to kind of more robust uh people Okay so we've solved our problems uh we used human I mean we actually paid human beings for label data which is not maybe that like goes against our principles here but but but we still did it because open AI is Rich so they paid people to label things but then they want you know they didn't want to spend too much money so they created an AI to replicate the the job of the human beings H but then at least they got a you know robot or computer model and now is able to say what's good or bad dialogue okay. want to be more robust and and and be able to self correct so we use reinforcement learning to optimize and make this robot happy so we've we've now addressed all these things and and we got an even better model okay but now we have an evenBetter model but we already had a good model to start with so why stop here right why don't we just use this model now to generate uh new answers that are even uh better answers and then you give these answers now to human beings to score them right and train a new robot to imitate this scoring. well because if you now have a better model you kind of want to you want to go to the human beings and get more feedback that's more relevant to this model because this model now is is doing better than the previous one. I think open a runs this two or three times um okay cool. We can just run this step uh and do it all again and you know you can done you can do this as much as you want of course uh maybe with some uh you know decreasing returns I don't know exactly. so to summarize what's the big fuss well just predict the next word based on previous words that's basically it. Who knew that this is going to work at the scale that uh you know and reach reach this kind of intelligence that we're seeing uh was quite hard. Transformers allows us to leverage more data and train quickly because we can paralyze paralyze all these steps in during training and uh then uh when we've done this we have a really really sophisticated model and we spent 99% of our time in computer on on this Transformer. incorporate human feedback and reinforcement learning to get even uh a little bit more of performance out of this okay um again uh obviously self super learning in Foundation models are at the core of of CHP um uh also maybe I mean uh generative a versus self-supervised learning U maybe it's useful to kind of um I mean the difference between entive Ai and self superlearning is not clear uh and people use it typically I mean there is more the difference is more clear when it comes to uh the research space but people say that CH P generative AI or ex Strang uses s super learning. and self Suess learning care more about both aspects somehow somehow. Next time we will talk about uh we'll do a similar Deep dive into stable diffusion there will be self supervised learning and Foundation mod an AI but uh I think it's going to be slightly more conceptually interesting um so should be a lot of fun and yes please go to the website for more information Etc and if you have any questions feel free yeah can I something can I assume that probability on that after there changes based on the subject of the totally yes yes yes great question okay. train to generate the distribution. The more the longer sequence and the more context or the longer prompt you have the more specific prompt the more Peak your distribution will be. So the more information the model have around your specific context in use case the more it knows how to collapse into a space that you want to know about right? So if you just say you know if you start sampling the model with no prompt it's going to generate so the most common starting points on the Internet or something just like random text. it's going to be able to collapse and create distribution that's much more targeted uh so is if it doesn't have data run a context or about you and your interest as a person it it won't be able. to tailor to you right they cannot create Magic out of thin air it can only do the best of The Prompt and knowledge has so far. It's also why data is so important to have around you right and good prompt Etc and it's alsowhy this prompt engineering to be. able to create the best prompts to get what you want. Model generating is reinforc learning because itates the response yeah that's a great Point actually okay so yes in this what we talk about right now basically we had a few models involved. We talk about reinforcement learning supervised learning and self-supervised learning right so exactly the robot that just H try to replicate the the human beings putting scores on the um uh answers that we generated prompts yes that's train using self uh supervised learning right because you have these labels now that you want to replicate. The Transformer is based on how a normal person learns right when you're learning a new content you to Rel it with everything else you know yeah so I'm just I mean this yeah okay uh so the question is basically is the Transformer inspired by research about how we our kids learn right how the brain works yeah I mean you're going to find a lot of work around you know making those connections and uh then there's a huge debate in in like the Deep Learning Community is that is that actually true is it kind of wishful thinking and in hindsight we make this connection right. I do too right you for around similarities to how our own brain works and some people are like oh that's not you know we have to be very very careful because we kind of compare. I think that there's strong connections right but like what came first I actually think that uh people have some intuition they tinker and they try things and then suddenly something work and they work on intuition and actually theory is very much hindsight so some engineer played around with things actually theer was from Google right so we build a Transformer. well this reminds me of this and this uh so there was definitely no strong like this is how kids learn and then we replicate that it the more I would say the more likely description of how the Transformer came about was just Engineers tinkering out and trying things and then it it just like oh this works now and they are not prbly completely conscious themselves about what they were inspired by you know so does that mean that we not have collaborations neuroscientist yeah it means that the collaboration with neuroscientists in deep learning is is quite quite rare actually. word mask it and try to predict it based on the surrounding words um yeah the answer to that is we used to do that way and it works better uh but due to engineering you can Bas basically kind Transformer you can maybe this can be like a homework for you but if you look at Transformer Works uh if you mask a word uh then you will like then you'll only um okay I if you do this you know if only predict the last word based on previous words you can make this okay attention. so you can okay this maybe any like you have this tensor product you can Define this m Matrix High dimensional matrix product in a way that's efficient. So you can basically in a single goal predict the target like you can you know you have a sentence you can run the whole sentence and predict the next word based on previous word. If you do Mass language modeling you cannot do that then you basically have a full attention you can attend forward and backwards but you can only run the targets that you you masked. each Target by itself but if you mask then you maybe mask like 15% of the words and then it's it's only like that's only 50% then in terms of getting that feedback uh so it just in end of the day it means that uh when you try this empirically doing it aut agressively and this trick to be able to use the each you know each word is a target itself just leads to better performance at this task of generating export based on previous words uh so yeah so it's I guess it's engineering empirical okay it's not as in an Ideal World if you have unless compute you would have. oh actually works better given the same amount of compute yeah does that give you some sense of answer we can talk more about it offline as well. What are like the main challenges of these models nowadays and are there other like language models that are like better but they do like more expensive than or like this is like the best um yeah I think. I mean we want to able to rely on it as much as possible and if they if they don't behave like we want them to we don't want to make up things right. you like ask a factual question and they give us something that's wrong and they're confident about it maybe that's bad so like I think what we're starting to see is that they um are very humanik even it's in its mistake they're like well they're somehow they're biased are we going to talk about this like they have stereotypes around things. They also like we do I mean they suffer from wishful thinking and some type of imagination where they rather be you know make you happy than being completely truthful. The model will be able to digest some input generate some output and then you know digest that input generate more output and stuff like in this kind of planning step uh it becomes has much much better abilities so you can basically instead of having a single go at your prompt if you can you know have a few tries and improve on itself and only get give you the response after it's done this internal internal processing it will be to do much better and then like again if you throw in some tools there it can search internet to get more information. These are reinforcement learning techniques of how to do planning well so how to incorporate planning is something that people talk about a lot and then of course multimodalities. It's not hard to see that this idea of predicting next word based on previous words corresponds really well to videos just to kind of predict the next frame based onPrevious frames uh and why aren't people doing it well. videos are suddenly a next level in terms of compute what it needs because they have tons of videos a frame is very expensive because it's a high dimensional picture or image. the World by looking at videos right you can even sort to understand how human beings work even better because you can see people being upset or sad or happy whatever right in in a video and start picking these cues up. You can connect the vision part to the text part and get a multimodality model that's able to do both in a really really sophisticated way uh also something that I think these these people are working on all right thank you thank you for your time and good luck with your book.

ROUGE-1: 72.67, ROUGE-2: 70.66, ROUGE-L: 70.89
BERTScore: 73.40

==============================================
==================== [100/100] ====================
Summary:
K-means GMM and EM are our first two unsupervised algorithms. We're going to try and generalize what happened there so that we can use it in many different settings and move on from there. The big idea we encountered was this idea that photons that we were trying to fit Gaussians to, maybe three Gaussian that look like that. Don't worry about if you don't remember the details, just roughly what we're dealing with. We've kind of got our hands dirty with k- means and GMM. of a latent variable. And the latent variable in this setting, if you remember, was this fraction of points that come from a source. So we didn't know how many points were coming from each one of those light sources that were out there. We had to estimate that. Once we estimated that, then we would be able to go back and fit all the different parameters that are there. So-- and the fraction of Points, we also had to figure out the linkage, the probability that every source was coming from a point. And then we could do the estimation. that is, what's the probability of these points belong to cluster one, this point belongs to cluster two, so on? And then once you have that, you then solve some estimation problem that looks like a traditional supervised learning. So the decomposition is quite important. And we're going to try and kind of abstract that away. And then we would estimate the other parameters. That's what I mean by a kind of traditional supervised thing. It doesn't mean that that's what we're doing there. Maximal likelihood is just a framework. It happens to be the framework that we use throughout most of the class. There are others in machine learning by the way. But this is the one we're going to use. So before I get started on the rundown, any questions there? I'll start to write. Oh, please. Yeah, for things we start by casting the views, what is the first step in GMM? What do we guess? We could guess randomly an assignment of every point to the cluster, the probability. some other heuristic guess. That was what was going on in the k-means++. We have a smarter initialization. Once the process is started, we just keep running those two loops again and again, and hopefully, it will improve. And we'll capture in what sentence it improves. You'll see this weird picture of a curve that we go up, and that's going to be the loss function. Awesome. OK, so we're going to look at the EM for latent variable algorithms, and this is where it applies. This is what it's for is dealing with various different notions of latent variables. What they're doing, basically, is they have that decoupling property. If we knew this thing that we couldn't have observed, then, all of a sudden, it becomes a really standard statistical estimation problem. That's the real key idea. We can abstract all the algorithmic details into EM same way we did for the exponential family stuff, OK? Now, before we get started, I want to take a technical detour. And so it's really important that we have signposting here because you'll say, why is this guy drawing here? The algorithm will be used in the next step. It will actually, in some sense, be the entire algorithm. I want to make sure that you understand this key result, which is convexity and Jensen's inequality. Those are the things that we're going to think about as we go through it, OK? I'm going to try and show it to you in pictures because I think it's weird. These weird pictures? The technical detail is I want you to understand this in the simplest way. the most intuitive way to understand the basic cases. If you already know it, don't worry. It's just another proof that you'll see. Then this will allow us to go to doing the EM algorithm as MLE. And what I mean is we're going to be able to write down a formal loss function, a likelihood function, right? That's what MLE is. We write down this loss function. Then we maximize the likelihood. Then I'm going to come back, and I'mgoing to put GMM into this framework. And this will answer some of the questions that we kind of intuitively, kind of heuristically answered. so it would give us a principle to solve for all the weights. We'll go through what we call factor analysis, OK? And factor analysis is another model. The reason I want to show it to you is it's different than GMMs, so it occupies a different space, and it will kind of force you to look at the kind of decisions you're making, right? What are you doing? And then we almost certainly will not have time for this today, but I combine the notes, and we'll go continue to go through them on Wednesday. you modeling here? And in particular, we'll model a situation where traditional Gaussians couldn't fit the bill because we're modeling something that's huge and high dimensional. And by comparing these two and what's similar to them, hopefully, you get a pretty good sense of what EM is and all the different places that it runs. All right, OK, so far, so good? So if there are no questions, we're going to go right into our technical detour, which will lead, then, into the EM algorithm as MLE. A set is convex if for any a and b element of omega, the line between them is in omega, OK? So what does that mean? So let's draw the picture first, and we'll draw the math. Here's the convex set. So it means no matter how I pick a-- here's a-- and no matterhow I pick b, the straight line between. them, the geodesic between them, is in a set. OK? Now, we're going to apply this to functions. this, OK? So the shaded region here-- so this function, by the way, is going to be f is equal to x squared. It's a parabola, kind of a bowl-shaped function, right? Now, no matter how I pick the points-- and clearly, I should really only have to worry about picking on the edge. So if I pick a point here, a, and I pick another point b, the line between them goes here, all right? It's not necessarily a straight line across. I'll just say there's a point z that's going to live in the middle, and this is b lives here. Let me erase 0 and 1 because we don't really need them. Their values are kind of unimportant to us. We'll draw a. All right, awesome. Now, what is this function? Well, this is a-- I think it's x minus looks like this. And then its graph is everything up here. And this is not convex for the same reason. said was a function graph, and the other one, you didn't. The function graph was open to the top, but that shouldn't be really disturbing. All right, so what does this mean? Means for all Lambda element of 0, 1, f of a plus 1 minus Lambda f of b is an element of omega. It means that if I take any z that's on the path, lambda a, to 1 minus lambda b, then it had better be the case that z is greater than f of z. make sense? Just translating the definitions directly. In more cryptic language, we usually just tell you every chord is below the function. Here, that's not case. I just found two points so that the chord between them is actually below thefunction. So it's not convex. And intuitively, the reason I drew these shapes is that convexity for shapes probably makes more intuitive sense, 2D shapes. But now, hopefully, you see they're really the same thing. If f is twice differentiable and, for all x, f double prime of x is greater than 0, then f is convex, OK? So this says these functions really are bowl-shaped, right? Second derivative being positive means that they have this kind of positive curvature that looks like the U's. Their first dimension-- first derivative goes up and down, but they're kind of always trending. It's negative on the left-hand side, positive on the right-handside. out a Taylor series for this. f double prime-- see the a, a minus z square. OK? And this a to a is just something in a, b. So I'm saying there's some point on the interval where this is true, OK? Same thing for b. This isn't super important for your conceptual understanding, by the way. Like, this is just to show that you can do what you want to do here, that this makes sense to you. OK, minus z squared, handled it. Now, I claim it's convex. take what is the obvious thing to do. I'm going to multiply this by lambda. I have to make a statement about this, right? That's what's in my definition above, OK? Well, that's just the same as adding f of z for Lambda, plus 1 minus Lambda. So that's good. That appears. That shows that this thing, this inequality, holds, f ofZ. Please. Oh, so you've seen the double [INAUDIBLE],, is that [INAudIBLE]? Yeah, this is Taylor's theorem. Great question. So what's going on here if you remember Taylor's theorem is you can keep expanding, and then you have the last term, which is the remainder term. The remainder term says, there exists some point that lives in a to b such that this holds with equality. By the way, this is really not important for your conceptual understanding. You can freely forget this and just use the fact, this fact, in the course, OK? OK, stalling done. Any more questions? Awesome. is, otherwise, this thing, which we actually do care about, is strongly convex. This definition feels like it comes from space aliens otherwise. So for example, f of x equals x squared, which I told you was in my head. Well, this gives me a simple test, right? Its second derivative is 2. That's greater than 0. It is the prototypical strongly conveX function, OK? You also saw those This is to make this parameter sometimes with the curvature one. Doesn't really matter, but OK. Jensen's inequality is a test for convexity. Compute the derivative. You'll see. But it's the one that looks like the two bumps, right? It's a quartix. So that's what it looks like. And if you have a stronger condition, you can get this strong or strict conveXity, OK? All good. Now, if I've done my job well, this mysterious-looking statement, once I show you the connection, you go, oh, OK, that makes sense. something about convexity, but it's got a fancy name, and it's so useful. The expected value of f of x is greater than f of theexpected value of x so long as f is convex, OK? Why the heck would this happen? Let's take one example. Suppose x takes value a with prob of lambdas. Then x takesvalue b with prob 1 minus Lambda. Then what is it saying? It's saying the expected value is equal to f of a plus 1 minus lambda f of b. That's exactly the definition of convex. I pick a curve, one way to define a curve. And that curve is going to be as a result of sweeping some parameters in a high-dimensional weird space. But basically, it says, no matter how I pick the parameters of that curve, anywhere that lives on this thing, that's a probability distribution. This inequality holds. That's going to allow me to build a lower bound for my function, and I'm going to hillclimb using it. We'll see that in just a minute. do something fancier if you want something that's a full probability distribution. This holds even if E is a continuous distribution. The reason you'll always get the inequality the right way is you'll draw the picture of the function and see the chord is always above it. We actually don't want to use a convex analysis. We'll stop at kind of high school calculus. Sound good? All right. Now, everything is defined in the literature traditionally for convex. If you take convexAnalysis, it's the way we define things. convex function here because we're maximizing likelihood. And this is just notational pain, right? Like, if we were-- maybe we should have minimized unlikelihood. So we need concave functions. And what are concave function? g is concave if and only f minus g is convex. So if I take a chord of this function-- that's a chord-- it's below. Which is what I should hope. If I flipped it upside down, the chord would be above. Cool. conceptualize it is we solve for some hidden parameter. We solve, and that gives us an entire family of possible solutions. Let me draw the picture after I give you the formal set, OK? Oops. All right, so EM algorithm has max likelihood-- I'll actually put MLE. There's some theta that lives out there. We have some data, i from 1 to n. These are our data points. We take a log of the probability that we assign to the data given our parameters. structure. P(x; theta)-- this is a generic term, right? This is just one of the i terms-- says the function factors this way. Looks like a sum over z, where z is our hidden or latent variable. So we have to sum or marginalize over all the possible choices of z. This is basically saying, I don't know what z is. I have some probability distribution that I can compute over my data and z given theta. And this will get me back a probability for x. sorry, probability for x. Is that clear? Yeah, ask a question, please. So where is the z going to go again? Like, is that property of the parameters [INAUDIBLE]?? Yeah, wonderful question. In a real sense, when we make a modeling decision, and we say, there exists some structure out there, like there exists a probabilistic assignment between photons and point sources. One version of the prior is, I tell you exactly where every photon comes from. That's clearly a very strong prior. models. In GMM, this was exactly the z there. The notation isn't an accident. It's the same z. So that's one. We'll have more examples later. But I want to get through the algorithm in this abstract form, and we can shoehorn more things into it. And what I'll do afterwards is put GMM right down in this language. We need a couple more things. Please. Back to Mail Online home.back to the page you came from. what is probability of x parameterized by theta actually represent in this case, in that photon example? Yeah, exactly. So remember, if you-- I think it was said yesterday by someone here on that side of the room. So I don't know if that's spatial recognition helps you in the last lecture. But it was like, imagine I was guessing all the photon models that were out there. And then what I'm thinking about is what I want over that is that, across all those thetas, no matter how I instantiate z, each one gives me a different probability distribution. I can sum them up, and that tells me. that from the supervised days. We just inserted z and said, well, there's this wild z that we can't observe, but it somehow constrains x. It means that x-- like, the relationship between theta and x. And that's what the model does. Awesome question. Very cool. These are wonderful questions. I'd much rather answer these than badly draw the pictures that come next. We're going to get to those pictures no matter what, so there's really no saving us. All right, let's get to the bad pictures. have-- and I apologize. I will use a bunch of colors. I hope this is OK for people to see. If not, let me know. This is my loss function, l(theta), OK? So this is-- I'll write that in black there. This Is l( theta) here. Now, remember, it's not a nice concave or convex function, right? We wouldn't expect it to be. We would hope, because we're going to minimize it, that it's concave. weird bends. So how does the algorithm work? We start with an initial guess. Then what happens is this is mapped up to here, which is l of theta t. This is just the value of the loss that I currently have. I suspect there's something up this way I'd like to get. That's all we're after. We settled for that in KMM, for k means, and we're going to settle forThat in GM, OK? So we had to settle-- that's another way of copping out and saying, we hadto settle for these local iterative solutions. The problem of optimizing over all those z's seems daunting, directly optimizing the l's. So instead, what I'm going to do is I's going to come up with a local curve, OK, and I'mgoing to call this curve Lt of theta. Now we'll pick Lt, usually, to be some nice convex function, something that's easy to optimize, right? So we're going to try and get that kind of easy-to-optimize function. And then what we're Going to Do: Find its local maximum. about the algorithm, but hopefully, it's clear what's going on. Easy-to-train surrogate, and we kind of slowly hillclimb with that easy- To-Train surrogate, alternating back and forth. And this is what we were doing in K means. And just so it's super clear here, phi t plus 1-- this is nothing more than the argmax over theta of Lt of theta-- means I do the optimization on the surrogate curve that I created. curve, L of t. And then the M-step, and together, EM, set phi t plus 1 equal to argmax phi Lt(phi). Cool. Just could you reiterate? Like, why are we not using gradients on the original turbulence? Right, so we could imagine doing some kind of gradient descent here, but it's not clear how to deal with this marginalization that happens in the middle. So if we did some marginalization or some sampling, we could do something that looked like that. But it's because we have this decomposition. just means I have an internal solver that's fast and I kind of trust, and I have something on the outside that's a latent variable that I'm like splitting up the modeling. It's one of a number of decomposition strategies. Doesn't mean it's the only way to solve it, though. Cool. All right, so the question is, how do we construct L of t? And I claim we know everything else. So we'll come back to that claim in a second. be thinking because I told you that Jensen's will have something to do with this. Now, what we're going to do to put it in the form where Jensen's could be used looks wholly unmotivated. But it's to shoehorn into what we's doing, and there's some motivation, but it's kind of opaque, let's say. So here, I'm just introducing Q. This is true for any Q, right? Let's not worry about support issues. Let's just put in something that divides by 1-- seems sort of unmotivation to do this. Jensen, such that it's a probability distribution over the states such that the sum over Q(z) equals 1, and Q (z) is greater than or equal to 0. OK, why? Because now I can make my argument one line. That's the real reason. So how does it work? Yeah, good. So we have this character-- copy-- in here. This can also be written as an expected value, where z is distributed like Q of this weird-looking quantity. thing, sorry. Dammit, I forgot a log. OK. What's Q? Q is this function that we picked up here. And this is going to define our curve. Now I've turned this into an expectation, and in one line, I'm going to be able to turn it into a lower bound that works no matter how I pick it up. So this is less than. P(x, z; theta) over Q(z). This is Jensen, OK? Log is concave. applying it to the negative of it, it's exactly the same piece, but it reverses the inequality. So this is just because Q(z) is a discrete distribution, and the definition of expectation is, this is a bunch of numbers that sum to 1. This is an expectation with respect to some distribution, in particular, the one where z(i) occurs with probability Q of z, z( i). That's it. It's, again, just symbol pushing. difficult to read. Q is something that I've artificially introduced. If you pick a Q that satisfies this, I have a way of lower bounding this function, getting a family of lower bounds to it. It's so that I can construct those curves that come later, because now this function is going to be much nicer to optimize, but we haven't quite gotten there yet. OK? So this whole thing is-- this gives a family. This is just what I was saying there. So you're right ahead of it. because, term by term, it's going to be less than or equal to. Now, it doesn't satisfy all our requirements, because we have to make it tight. So I have to pick a certain Q to make this operational. That's the piece. Go ahead. Would then start and then Q has to be greater than 0? Yeah, yeah. So, yeah, I said I was going to ignore the support. But right now, I have a way of going term byterm from the likelihood function and getting lower bounds. And it'll be a lower bound no matter where I am, OK? We can imagine just for the sake of this lecture that it's strictly greater than 0, so I don't run into weird things about what I mean by divide by 0. Here, because I'm controlling the multiplication ahead-- ahead of time, it does make sense, but you're right to point that out. All right, so now how do we make it tight? So what we have to do is that we want to make Jensen's inequality tight. And the idea is if what's inside is constant-- imagine there was a constant inside, that this term was constant for all the different values of z-- then the expectation clearly doesn't matter, right? value, alpha, and then you would get a sum over all the alphas that were there. So as long as this term is a constant-- that is, it doesn't depend on z-- I'm in business, all right? So what that means is I want to pick Q such that log P of x, z; theta over Q(z) equals C. And c is equal to log P x of theta, OK? So let me make sure this is clear. Note-- this just means "note well," and B-- I just use it reflexively just to signal. Each data point is going to get its own different Q, which is the log of how likely this thing is, OK? And we picked those for each i. Because we did this term by term, we can pick that Q-- Q1, Q2, Q3, all different. And we pick them all so they satisfy this equation. OK? This thing has a very famous name, so I'll write that while I kind of stall for more questions. So what we've defined here is called the Evidence-based Lower BOund, or the ELBO. So hopefully, that picture makes sense. We have this opportunity to pick these bounds, and we'll use them in a second, so it'll hopefully become more clear exactly what we're kind of optimizing for here. What we're going to do is we'll see how we pick the Q(i)'s and all the rest in aSecond. But this is basically saying that it satisfies the two properties that we had before. Then we need to find a lower bound. Oh, no. So these are both on the original loss. These are just saying, this is the Lt here, capital L. Each one of these is capital L, basically, right? And then this one here is saying that, at that particular point for that t-th instantiation,. this is where we are. Yeah. All right, so the wrap-up is as follows-- this is how-- we can now write down the algorithm and the kind of full generality with mathematical precision, although it may still be a little bit opaque. So this says that you're going to pick the Q(i) distribution that says, what's the probability that's most informed. have some theta at some time. You know the data point that you're looking at. And you say, what are the most likely values of the cluster linkage-- as we were talking about before, the source linkage-- for this particular point? You get a probability distribution over those. You set them to Q(i)z. That's really what's going on. It's your estimate of how likely that is. Theta t plus 1 equals argmax over theta of Lt( theta), which equals Lt(theta) That gives me a new guess of parameters, which defines-- you get a new curve, a Q(i) for each one of what's going on. And I'm inconsistent with the semicolons too. So you move this. So there's a good visual distance. This is an x, this is a Q, and theta is our current guess. All right, why does this terminate? And it's basically for something that's kind of not very interesting or satisfying, but it does. sequence that is monotonically increasing or nondecreasing, OK? So it's possible that it would grind to a halt. But eventually, it has to be strict. And so to derive a counterexample, you would just find a likelihood function that had those two bumps. And you would run it in that particular lower bound setting. And what it will do is it will gradually hillclimb. And this is actually not great. Like, it can't go back downhill, right? It's got to just continue to go up. So in summary, what we saw here is we derived EM as MLE as promised, OK? So just to recap what happened here, we started with this notion around Jensen's and convexity. We wanted to use concave functions, which are these kind of downward-facing things. Those are the loss functions because we wanted to maximize them. The reason that was important is we had to do this back-and-forth iteration. Given a set of parameters, we were going to find a surrogate. That surrogate was going to be concave. entire curve because we wanted to optimize it. So it wasn't enough to find a point in a lower bound. We needed to find the whole thing that was underneath it so we could run our argmax step. And that was the setting where we would learn all of the parameters and estimate that in a way that was hopefully nice and easy to do. It's a lot of notation because we're abstracting out a huge number of things that we're doing. We'll run through an example of that. But in the end, it's not so bad, right? You take the Q(i)'s. And this way, set the thetas, do a descent on them, or ascent in this case. OK. All right, so let's see it for our Gaussian mixture model. Please. For this, [INAUDIBLE] this termination condition event. Oh, so the termination condition is not really important, or in the classical sense. The thing is that it's nondecreasing so that, eventually, there's a convergent subsequence of it. see if the loss of the likelihood function is not changing too much. Depends on your data, depends on the problem. Sometimes if you have only a small amount of data, you want to get to machine precision and 10 to the minus 16. And so that's the way you decide when to do it. This just says that it's not going to oscillate wildly. It's a very weak statement I'm making. Yeah, please. Can you explain what specific part of this is linked to the MLE sort of aspect of it? model, where we were saying, the way we're going to think about the world was to maximize the likelihood. That's less disturbing to this group than it is to, I guess, generally worldwide who think about this, because this is the only framework we've used in the course. We started with l(theta) as what we were optimizing, and then we derived this as a set of concerns. We didn't get to a global optimum. So I don't mean that we definitely guaranteed that we got the maximum likelihood estimation, just that you can phrase what's going on as MLE. sense? Yeah, yeah. Awesome. Thank you for the question. Why is this tight? Which one? Oh, it's tight because we went through this small piece here, which was that if we selected it as a constant in this particular way-- so before we could pick any Q and it was a lower bound, as long as we did this, then actually this line was no longer an inequality but was actually exact equality. And it depended, though-- that selection of Q depends on theta and x. Cool. EM for mixtures of Gaussians, or we call them GMMs, sorry. All right, so what's the E-step? Huh? Yeah, I'm just going to copy down the thing. So let's get the generic algorithms. Let me get thegeneric algorithm. Allright, just so we have it on the screen. So here's our warm-up-- not really awarm-up because we're almost out of time, but here's-- remember, if we saw how this worked-- P x(i) and z(i). size or variance, mu j. All right, z(i) is our latent variable. What does EM actually do here? So what is EM? EM is very general. You can instantiate it, right? SoWhat does it mean here? Now, what actually happened here when we wanted to understand-- what was the probability? This says, the probability that i, the i-th component, belongs in j given what we've observed about x( i) and what we know about the cluster shapes and their frequencies. The last time that said we had these two bumps, which were our two Gaussians, let's say, in one dimensions that looked like this. This was mu 2 sigma 2 square. And the question is, you give me a point here. How likely is it to belong to 1 or 2, to cluster1 or 2? Right? That's basically what we're asking. What's the probability that at this point, this i-th point here, comes from 1 or2? phi 2 was hugely bigger than phi 1, right-- a billion points came from the second source. So to automate this, this is Bayes' rule. It just weighs those two probabilities and tells us what should happen. That's it. We ran through exactly those calculations last time. All right, let's take a look at the M-step now. We have to compute derivatives. I want to highlight only one thing here because it's something that causes people pain when they do their homeworks. So we're maximizing here over all the parameters, phi and mu and sigma, sigmas, sorry, all the covariants. This whole thing, we're going to call fi. This is fi of theta. It hides a ton in our notation, all right? So this thing is-- let's write it out because the gory details will help us. Oh, please. You have a question. Do you mind defining what theta is? Do you want to define it? is latent and what is not? Yeah, so in our terminology, z is just latent. So I'm giving you the intuition that it's something that's hidden or not observed. But formally, it's just going to be anything that's a z. z is latent. That's our definition. Please. So the fi is just like the ELBO [INAUDIBLE].. Exactly right. Yeah, this is exactly the instantiation of what we had above. We reasoned about this through ad-hoc reasons last time, but it is exactlyThe ELBO that we're now going to minimize with derivatives. Now, that's how this whole method works, just abstracted three orders of magnitude more than it should be, OK? So let's see that piece. The z(i) that said we're summing over? Yeah. That's going to be-- so I'm just using that notation to make sure it's clear that it depends on the i. It's actually just a z that you're suming over. And it's summing. over all of the different clusters that are possible there, all the different sources. so on? You could also-- we'll see later-- replace it with an integral if you had something really fancy that was there. P z(i) j-- to compute that, remember, we expanded it by Bayes' rule. We had, if you knew you were in a cluster, how likely is the data point? And then we had a term that said, how Likely is the cluster? And those were the two components that we used. So I glossed over this really, really quickly because it was the same calculation we did last time. functions that we put in and broke down by Bayes' rule. It's exactly the same. You've got it perfectly. All right, so let me write out this monstrosity just because it will be potentially-- it has been in the past educational. Who knows if it's educational in the future, and the future being, like, two seconds from now? Allright, I'm going to use a notation, and hopefully it doesn't confuse you-- Q(i) equals z j. So this is the piece there. equal to the sum over j-- because now I'm summing over the cluster centers, right? The z(i) notation was still very abstract-- wj(i), which was summing. over this part here, log-- and help us all, 1 over 2 pi-- this is a covariance, 1/2. This is the exp of Oh, I decided to write this in four general things. Why do I care about that? Oh,I see why. OK. Transpose sigma inverse x( i) mu j times phi j. This is a Gaussian distribution with center j. I did use a higher dimensional covariance because it's something you're going to have to compute. The notation doesn't change except for this is what the Gaussian looks like instead of a square. And then there's the phi j, which is just multiplied times this horrible expression. And this exp parentheses is so I don't have to write it in superscript, right? Just expo the function, just a bad habit that I have. always use brackets for this. It's historical, and I would love to beat it out of myself if it were possible. Does the covariance depend on j? Right now, the covarianance does not depend on z. So it depends on j. OK? All right, so now we can compute some fun derivatives, OK? So let's compute mu j of fi of theta. We have to estimate some fun derivative of mu j. That's it. Yeah, good catch. the mean, right? Now. And I'm going to do it-- actually, I'mgoing to do something slightly harder. So apologies if you wrote that down. Let's do this. It'll be just one extra line because it's all linear. OK. So what this becomes is sum equals 1 to n. This is over all the data. I get mu j here, mu j, times-- and then it's going to be wj, and I am going to drop terms inside the log that obviously have nothing to do with mu j. sorry. doesn't depend on mu either, so I'm left with these terms. Please, go ahead. Oh, what is the physical meaning of the fi here? fi? fi is just the term here in a a function. It is the likelihood function after we've picked Q at the particular iteration. So it's just notation so I don't have to write this monstrosity every time. Yeah, but here, it's-- It's the ELBO. OK. It's exactly theELBO. going on. This is 1/2, and this is a minus. w(i)j is multiplied by it. It's going to be this times this thing plus. Yeah, sorry. Thank you for the notational issue. Yeah. Cool. All right, we're in business. So what happens now? Well, some mechanics that almost certainly will introduce bugs and you will catch, and it'll be great. That's learning happening there and me making mistakes, OK? and we computed this before, and it's just a matter of computing the derivatives. The one that I actually care about showing you, by the way, is phi j, so let me just jump to that because we only have a minute or two left. And I want to show you what happens in phiJ. So phi J is constrained. Would you mind showing [INAUDIBLE] scrolling up? Sure. No, wait. I just want the last one. OK, sure. show this one thing, phi j is constrained. You need a Lagrangian, OK? No, you haven't seen it? That's fine too. If you want, I'll post notes about how to compute Lagrangians as well. I don't actually know when anyone learns anything. Anytime I say something like that, my students always get upset with me, so I should just stop. But I assume you've seen it before this moment, how about that? so if you just take this and compute the derivative, it doesn't account for the constraint. So you have a bunch of numbers that must sum to 1. But what if the gradient is perpendicular to the line? Like, its wants to push you only perpendicular and has no component moving you along the line, right? In that case, this is still a critical point. It's still potentially a minimum. Does that make sense? Because it's not telling you that there's a minimum to your left and right. It's along the line, OK? So the question is, how do you encode that information that you want to kind of screen off information that's orthogonal to the line? And I'll write up a little note to show this whole thing. What you do is you introduce this thing called Lagrange multipliers. And if you haven't seen them, don't worry. These are super easy to teach. Just say this-- it's just an extra term here. And this multiplier is basically the thing that screening off things that are orthogonally to these constraints. that's OK. You get to screen that off. And I'll just post a one-page write-up for you. Please remind me in the thread, and I will definitely do that. If you don't do that, you'll get the wrong answer. That's also a motivation to learn it. And so what ends up happening here is you get something that says, I get sum i goes from 1 to n w(i)j over phi j plus lambda equals 0. And this implies that phi of j is equal to 1 over Lambda sum i equals 1. When you have a constrained probability distribution, you have to use a Lagrange multiplier. In this case, it makes total sense, though, because these numbers have to sum to 1. So if you don't have a normalization constant here, you're adding up a bunch of numbers which individually sum up to n, right? The sum over all of them is n. And this is just the principle that tells you, you must normalize them by this n factor, OK? So all I care that you take away, if you've seen this a thousand times, is that you understand. before, don't worry. If you've never seen this before, I just want to flag for you, when you minimize a function that's constrained to make sure you use Lagrange multipliers. You do not need to spend a bunch of time on them. Just have a little light bulb to go off that says, OK, I've got to look up how to do it in this case. That's all I care about, OK? And you'll trace through it in the notes. Please. So this minus lambda is going to be equal to 1/n. So I'm just going to write the final expression. Maybe that would be less-- yeah. So also, why is it [INAUDIBLE]? Because it's a probability distribution. So again, the issue here is phi j is constrained by the model. So if we go back to this model, this is a constraint onphi j. So whenever you have a probability. distribution, a multinomial probability distribution, it's not just that the phi i's. are nonnegative, which the constraint-- we're almost ignoring-- but it's that the phi i's equal 1. So you couldn't, for example, set your probabilities to be 0.5 and 0.8, right? They have to add up to 1 here because it's a multinomial. So that means these phi j's-- we have constrained them to equal to 1. And it shows up in this extra term here, which is the Lagrange multiplier. haven't seen this before, it'll look quite mysterious. But what I was trying to do is I'm not going to teach you the Lagrange multipliers in this class. I'll put up something. But the piece is here that it gets you back to an expression which makes sense in this setting. And you needed something to average over because these numbers sum up to something that looks like n. If you just compute it naively, you'll get something that doesn't make any sense. the same j's. No, but [INAUDIBLE]. Which line? Just says phi j i. Oh, oh,Oh, I see. I see, I See, Isee. Sorry, sorry, sorry. Thank you for the clarification. Apologies for that. Yes, it's this constraint here. Sorry,. this is the constraint that was in our head. Yeah, and it just makes a mysterious reappearance here, all right? All right, awesome. OK, so what is the message that I want you to take away from this? in a different way. We started with that convexity piece so we could get an intuition for what these functions look like. And then we went through the EM algorithm, which we formalized as kind of back and forth with using these curves over time. Once we had those curves, what was happening was we would pick and optimize on those curves. The Q(i)'s played a starring role. Those became our w's here, and they kind of add nastiness to all of the equations. They just add little weights and expectations everywhere. MLE for the entire quarter on those properties. Then we introduced a ton of typos to keep you on your toes. And then the second thing that I would tell you to do is when you have constraints, you have to know how to optimize them. You don't need to know the general theory of how you optimize against nonlinear constraints, but you should review how to do it. And so then we saw the two things that I cared about to highlight. One is how to find means, and these are just weighted means. do this when you have something that sums to 1. It's not more complicated than what I wrote here, but make sure independently you go through it and ask questions. In the next class, as I said, what we're going to see is this notion of factor analysis. And that is going to tell us how to apply EM to a different kind of setting, which, at first glance, will look kind of impossible to do without a latent variable model. And I think that's all I want to say.

ROUGE-1: 67.02, ROUGE-2: 65.02, ROUGE-L: 64.30
BERTScore: 78.61

==============================================
