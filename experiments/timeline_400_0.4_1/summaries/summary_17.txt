Machine learning is about how to acquire a model and acquire the parameters of a model, from data and experience. In the next few lectures, we're going to work through a sequence of different takes on machine learning that are going to highlight different subsets of the big ideas on this topic. We'll see today exactly how data kind of goes through the mill and gets turned into a model. And we'll see more in-depth examples and more structured examples of these kinds of problems later on when we talk about applications. In a real classification problem, you have to smooth if you're going to use Naive Bayes. Every method is going to have a different incarnation of this. If I crank k to zero, I'm not going to smooth at all, and I'm going to fit my data very well. But the k that's going to be most accurate on my training data is zero, because that's what actually fits the training data best. We're talking a bit about this starting next lecture, but you're eventually going to make your errors.