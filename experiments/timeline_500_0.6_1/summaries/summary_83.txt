Coded imaging is a co-design between how you capture the image and how you process the image. The concept of a position or superposition applies to all three types, shadows- or refraction- or reflection-based techniques. We'll see how-- we already have some projects that are inspired by biological vision. And we'll see it in a taxi zipping very fast, which is a clever way to take a photo. And I believe Santiago-- where's Santiago? Oh, yeah, his triangle-- the piston. The problem is that when you use a box function to take a photo, some of the lower frequencies are actually being set to 0. The culprit here is really this box function, which is equivalent to-- when you release the shutter, opening the-- release your shutter button-- opening the shutter and keeping it open for exposure duration and closing it. So what if you change that? What if you open and close it in a carefully chosen binary sequence? So for some time, the shutter was open, then shutter's closed. It's open for sometime. Again, it's closed, open for quite some time. And so on. So at the end, you still get just one photo. But now something magical has happened because first of all, if you look at this number one, you'll see that it's not the same as before. It seems to have these replicas. Lenses are very carefully designed by camera makers to be the same plane where you put your aperture. When you change your f-stop and decrease it and increase it, it's all happening in the center of projection. When it's in focus, it doesn't really matter what the code is, so the photo will be half a square, so you're talking about the light, so half a light, right? And that's why you have some dust on your lens and so on, unless you have the lens on your front. that, or just a software. There are methods you can employ. You need to find this 7-by-7 pattern or even the previous case, the 52 pattern. Take a Fourier transform to see if it's flat. If it's not flat, you go to the next one. So 2 the 52 is pretty challenging. But even if you use a cluster, it's still a pretty big number. So you can start with some code and do a gradient descent and so on. In astronomy, you have circular convolution because they use either a mirror or one mirror. If you put two tiles, you'll get really horrible frequency response. So if you're tiling that up-- RAMESH RASKAR: It's impressive, that's saying [INAUDIBLE] It's not a brute-force search. It was an intelligent search. We came up with our own code called RAT code, R-A-T, which is after three quarters. It's a very clean and beautiful and smoother course work. The effect is very low, though, remember. So maybe you have a pixel and get blurred by 10 pixels or [INAUDIBLE]. It's not a global effect. So this picture, maybe-- this particular diagram is misleading because it seems like this point is going to go all the way. But this is very narrow. And the blur is only about 10 pixels, no matter where you [INAudIBLE]. So maybe that was the matter. Doug's question is, what's the benefit of this? Ramesh Raskar: Compressed sensing is taking a photo and compressing it. He says the idea is to take a single photo and then recover it in a compressed way. Rasksar: If you're on 2 megapixels, then you need to take 2 million [? pics] All right? So the claim this group made at Rice University was that if I wanted a million-pixel image, I don't have to really take a million readings, he says. Rasa: I can take this picture effectively with just 10,000 pixels but recreate a million pixel image.