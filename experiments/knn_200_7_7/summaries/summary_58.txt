The Fourier transform is of any function that's either a product of those or a convolution of those kind of base functions. We're going to talk about the convolution theorem, noise and filtering Shannon-Nyquist sampling theorem and spectral estimation. Next time, we're going on to spectrograms and an important idea of windowing and tapering, time bandwidth product, and some more advanced filtering methods. And there may be, if there's time, I'll talk about a little trick for removing the line noise from signals. using this Matlab function FFT. In order to do this properly, you should first circularly shift. You have to take the time series. And actually, the FFT algorithm is expecting the first half of the data in the second half of that data vector. So that's what this looks like. Here is a cosine at 20 hertz. And you can see if you take the fast Fourier transform of that, you can. see that what you see is the real part as a function of frequency. Fourier transforms have an interesting property about scaling in time and frequency. If a signal had 10 times as much amplitude, the power would be how much larger? If you have a signal like this that's periodic at about 5 hertz, you can see a series of peaks. If you take that same function and you make it go faster-- so now, it's at about 10 hertz-- the Fourier transform is exactly the same. It's just scaled out. So the faster something moves in time, the more stretched out the frequencies are. stretching it out by that same factor. OK? All right, so that was just a brief review of what we covered last time. And here's what we're going to cover today in a little more detail. These are functions where you have a function. You take the Fourier transform of it. You get a different function. OK, so there are pairs of functions that are essentially for transforms of each other. A square wave like this has a Fourier transforms that's this funny function a set of peaks. If you take the four transform of that, you would get this square wave. Shannon-Nyquist theorem: Any signal that has discrete components and frequencies is periodic in time. As you make the width in time narrower, the bandwidth in frequency gets bigger. Wiener-Khinchin theorem: Time is sampled discretely at regular time intervals. The full width at half max of that peak is 12 hertz. The Fourier width of this in time is just 1 over the width of [AUDIO OUT] So you have to take the full width. transform of a Gaussian is just a Gaussia. If I make that Gaussian pulses in time narrower, then the Gaussian in frequency gets wider. And inversely, if I make the pulse in time wider, than the Gaussia in frequency space gets narrower. So this concept of time bandwidth product in the physical world is what gives us the Heisenberg uncertainty principle. The power spectrum of a signal is just the Fourier transform of the autocorrelation of the signal. could calculate the Fourier transform of that. And that's capital Y of omega. And then we have some other function, x of t, And its Fourier transforms, X of omega, and another function g of tau. So remember, we can write down the convolution of this time series, x with this kernel g as follows. So y of t equals this integral d tau g of Tau X of t minus tau, integrating over all tau -- that's a convolution. topic, let's talk about Gaussian noise. The Fourier transform of noise and the power spectrum of noise. And we're going to eventually bring all these things back together. OK? All right, so what isGaussian noise? So first of all, Gaussian Noise is a signal in which the value at each time is randomly sampled from a Gaussian distribution. So here's what that sounds like. Sounds noisy, right? OK, I just wanted to show you what the autocorrelation function of this looks like, which I think we saw before. Using these methods, you can pull tiny signals out of noise at a very bad signal to noise ratio, where the signal is really buried in the noise. So it's a very powerful method. And we're going to spend more time talking about how to do that properly. All right, so let me spend a little bit more time talk about the power spectrum of noise, so that we have a better sense of what that looks like. So remember, I told you if you take a sample of noise like this and you estimate the spectrum of it, you compute thePower spectrum of one sample of Noise. problem with that? Why might that be a bad idea? Yeah. But there's sort of a general principle that we just learned that you can apply to this problem. You can take a signal like this, Fourier transform it, multiply it by a square window to suppress high frequencies. What is that equivalent to? What would be the corresponding temporal kernel that that would correspond to? It would be convulsing your function with a sinc function. It turns out that's-- the reason you wouldn't normally do that is that it mixes the signal across all time. spectrum of that we can correctly read out from the power spectrum how much variance there is per unit frequency in the signal. All right, let's talk about filtering in the frequency domain. So we're going to talk about how to smooth things in frequency domain with kernels. What would a high-pass filter look like? So would it pass high frequencies suppress low frequencies? You've probably heard of it, but what would a band filter like? It would just be big in the middle and then go to 0 at higher frequencies. that the signal is periodic in time. Discretely sampled in time means that the Fourier transform is periodic. There's another copy of that spectrum sitting up here at 1 over the sampling rate. The sampling rate needs to be greater than twice the bandwidth of the signal. If you sample a signal at too low a sampling rate, you see that it has a different part of the spectrum contaminating the top of your Fourier transforms. That overlap is called aliasing. And now, if I do this zero-padding trick, I can perfectly reconstruct the signal I'm sampling at every time point. of zeros between and make it a longer vector. And then when we inverse Fourier transform this, you can see that you have a longer array. So you can essentially increase the sampling rate of your signal after the fact. Pretty cool, right? Again, it requires that you've sampled at twice the bandwidth of the original signal. Yes. And that kind of kind of thing. It's pretty cool. And it's very useful in a lot of applications. And you can do that from nearly all applications.