==================== [1/100] ====================
Summary:
John ESSIGMANN: I measure my blood sugar at different times during the day. Gluconeogenesis technically means new synthesis of glucose from non-carbohydrate precursors. The medicine I take is called Metformin. It has a number of targets, but one of them is one of the enzymes, called PEPCK, Pyruvate Carboxykinase, that's in the gluconeogenic pathway. The liver provides a constant stream of glucose to organs that absolutely require it, like our brain.

ROUGE-1: 28.97, ROUGE-2: 26.69, ROUGE-L: 28.97
BERTScore: 70.94

==============================================
==================== [2/100] ====================
Summary:
In this lecture, we introduce and develop the concept of independence between events. If I tell you that a certain event A has occurred, this will generally change the probability of some other event B. In such a case, we say that events A and B are independent. We will then proceed to define the independence of a collection of more than two events. Finally, we will close with an application in reliability analysis and with a nice puzzle that will serve as a word of caution about putting together probabilistic models.

ROUGE-1: 62.59, ROUGE-2: 60.96, ROUGE-L: 62.59
BERTScore: 82.29

==============================================
==================== [3/100] ====================
Summary:
In today's video i'll show you the importance of de-gassing your bread dough as it's fermenting. No matter how gentle you try to handle your dough you will always de-gas it if only a little bit in today's comparison video we'll make 4 breads they will be made from the same dough but they will all be treated differently. The first one of the four breads will be left alone from the beginning of fermentation until it's baked. The final one will be folded shaped and degassed three times and we won't be fermenting them for the same amount of time.

ROUGE-1: 11.35, ROUGE-2: 11.05, ROUGE-L: 11.35
BERTScore: 70.42

==============================================
==================== [4/100] ====================
Summary:
Of the nearly 11,000 amendments proposed in the centuries since, only 27 have succeeded. The founders of the United States were trying to create a unified country from thirteen different colonies. For an amendment to even be proposed, it must receive a two-thirds vote of approval in both houses of Congress. To actually change the Constitution, the amendment must be ratified by three-quarters of all states. Americans today are the most politically polarized since the Civil War, making it nearly impossible to reach a broad consensus. Court justices are unelected and serve for life once appointed, this is far from the most democratic option. Interestingly, the founders themselves may have foreseen this problem early on. In a letter to James Madison, Thomas Jefferson wrote that laws should expire every 19 years rather than having to be changed or repealed. Although he believed that the basic principles of the Constitution would endure, he stressed that the Earth belongs to the living, and not to the dead. He wrote that every political process is full of obstacles that distort the will of the people.

ROUGE-1: 46.04, ROUGE-2: 43.88, ROUGE-L: 42.26
BERTScore: 64.38

==============================================
==================== [5/100] ====================
Summary:
Tamaso POGGIO: I think it's a golden age for intelligent applications. We are still very far from understanding how people can answer questions about images. This is one of the main focus in the center, really. How does your brain answer simple questions about this image? About what is there? And what is this? Who is this person? What is she doing? What's she thinking? Let me tell you a bit more about the background here. This idea of merging brain research and computer science in the quest to understand intelligence. looking at the face. And make models of what's going on. And, of course, we want these models to respect the neural data, ideally the MRI data. And do the job of recognizing faces as well as human do. So we are getting there. I'm not saying we have the answers, but we have at least models that can be tested at all these different levels. So that's kind of the ideal situation, from the point of view of what we want to do in the center.

ROUGE-1: 26.32, ROUGE-2: 25.49, ROUGE-L: 24.15
BERTScore: 56.80

==============================================
==================== [6/100] ====================
Summary:
Chef Todd Moore shares with you the seven basic skills that I think everyone should have to cook food consistently in the kitchen and be proud of the results. The chef test highlights the skills that everyone should possess if they want to learn to cook anything at any time and be confident that it'll always come out great. If you already have all seven of these skills and cooking techniques great you can work for me on the other hand if you only have one or two ofthese skills that's still fantastic.

ROUGE-1: 7.65, ROUGE-2: 7.17, ROUGE-L: 6.03
BERTScore: 61.55

==============================================
==================== [7/100] ====================
Summary:
as a nurse you want to be familiar with heart blocks and in this review i'm going to be talking about third degree heart blocks also known as a complete heart block. This type of heart block is the worst of all blocks and the reason is occurring is because electrical signal from the atria isn't making it to the ventricles. The person could be born with it so it could be congenital or the person has severe heart disease or they have a myocardial infarction or they're taking some type of medication. could progress to death so what you want to do is activate that emergency response system and this will get a team in the room to help you now some treatment that can be given to that patient is that atropine can be administered to help that heart pump more efficiently or the patient could be connected to a temporary pacemaker which will again get that heart beating correctly so we can maintain cardiac output. Eventually the patient will need a permanent pacemaker implanted okay so that wraps up this review over third degree heart block.

ROUGE-1: 45.71, ROUGE-2: 44.63, ROUGE-L: 45.71
BERTScore: 67.01

==============================================
==================== [8/100] ====================
Summary:
The 24th lecture of 188, before last one. The idea behind these two lectures is to look at advanced applications, where we have covered a good amount of the material in the ideas behind those applications. We will not quiz you on these application lectures, on the final exam, or anything like that. It's more meant to give you more perspective rather than extra study materials for the final. So far, I've looked at foundational methods for search, for acting adversarial environments, for learning to do new things, and for dealing with uncertainty, noisy information. DeepMind's AlphaGo can predict who will win from a certain situation in Go. The game is much harder to solve than chess or Tic-Tac-Toe. The branching factor in Go is much larger than in chess. A neural network can be trained to evaluate the value of a position. This gives you a lot of data that can be used to decide who is likely to win in a given situation. The first thing being learned is a policy network, which is deciding which moves to play against. even longer. It could be that by using human knowledge, you're in some kind of based enough attraction. I don't know if that would be the case or not, but that's a possibility. It also depends on how much randomness you have in your exploration. If you have enough randomness, then initialization will have much less effect than if you have limited randomness. How good can this system get? Is it even possible to learn good Go players by just playing against yourself? That's something people did not have an answer to until this experiment was run. We have four control channels, two in each joystick. A collective is the action for the main rotor collective page. It's the average angle of attack as the blade goes through the air. The tail rotor has a variable pitch also, and that pitch allows you to modulate how much thrust you get from the tail rotor. If you want to fly forward, you've got to rotate nose-down and then you can accelerate vertically in a helicopter frame. But vertically, the helicopter frame will now be partially forward and partially up, and up compensates for gravity. able to look ahead only two seconds, rather than needing to look beyond that. A value function tells us, OK, how good is it to end up here? We also have a reward at each time tick. The fastest we flew this helicopter was close to 55 miles per hour, so almost highway speeds. The algorithm's only this big, so it's pretty fast for something of this size. And then once you've recovered, let it learn on its own and let it switch to recovery mode. autonomous car drive a desert race. It's a time trial type race. There's no other cars that you have to overtake, but you're kind of on your own and try to do it as fast as possible, 150 mils off road. Well, it's on a road, but it's this kind of road that is not like a regular road. So it's pretty hard to distinguish road from non-road, and if you steer off the road, you might lose your car if you go down some kind of ravine. Four cars finished the 150-mile Berkeley autonomous car race in 2005. What goes onto the cars? There is IMU, like right on a helicopter, a lot of computers. Lasers, where you shoot out laser beams. Cameras, radar, control screen, steering motor. How do you decide with path to follow? Often, your sensor readings will tell you if there might be obstacles or not.. A camera will be better at that than a LIDAR. Somebody needs to tell you what is road, what is not road. The devil is really in the details, in the long tail of special events that can happen when you're driving. In urban environments, there's even more need to recognize, not just road versus not road. A lot of progress has been made this is video from 2013. This was before deep neural networks were heavily used for this kind of thing. It's only getting better to recognize what's in scenes, thanks toDeep neural networks. Instead of classifying into which categories in the image, you would classify each pixel, as to what is in each pixel. That way, you get a semantic segmentation. is between 10 and negative 2 and 10 negative 3 per 1,000 miles of human driving. In green is the Google slash [? wave ?] mode disengagement. It's when the driver decides they want to take control because they don't trust the autonomous system right now to avoid an accident. And we see that it's going down how often that needs to happen, but still a bit removed from where humans are at. Where does this data come from? If you test in California, you have to report this data to the DMV.

ROUGE-1: 13.75, ROUGE-2: 12.93, ROUGE-L: 13.07
BERTScore: 62.29

==============================================
==================== [9/100] ====================
Summary:
Price of good 1 has gone up substitution, income these are the effects and overall. When P 1 goes up subs because of substitution effect x 1 will. Come down. And for income also because of income effect it will come down. While inferior goods substitution effect quantity demanded would come down while income effect is. Up. So, theoretically speaking what is happening? The price of good1 is increasing and if these two are true then the quantity demanded ofgood 1 is increasing such good are called Giffen good. Can you give me an example its very very difficult to find Giffan good in real life why?

ROUGE-1: 21.14, ROUGE-2: 20.37, ROUGE-L: 21.14
BERTScore: 74.68

==============================================
==================== [10/100] ====================
Summary:
which we are to for next week and here and I'll talk about that actually week from today because it's callay on Monday so it will get behind but if we get any further behind I'll have to make it up sometime the but if you don't have that you be copies available upstairs is it c um come to my office okay to dany's office he doesn't have copies of it there that's six six upstairs in the first floor immediately after CL and then on the next Friday I will talk about the parts in the in the inquiry that were assigned and also a that essay of of the oral concept. and who does not have the right to vote and what the conditions on it are maybe we want to free it from that of course what I'm thinking of eventually um is that that that would be one motivation for introducing an idea like the origal position that say it's a way of conceiving how con power might be exercised. No point in criticizing someone for something they didn't intend to do okay well I think it's stop so remember there's no class here Monday so the next class here will be next Friday.

ROUGE-1: 6.76, ROUGE-2: 6.64, ROUGE-L: 6.70
BERTScore: 69.32

==============================================
==================== [11/100] ====================
Summary:
David Kaiser: particle cosmology is a new subfield within physics. He says it studies the smallest units of matter, the fundamental forces and elementary constituents of matter. Kaiser: The field is doing pretty well these days by other measures. Its annual budget just within the U.S. is on the order of $1 billion a year, roughly, he says. It is really a booming, booming subject of study, Kaiser says. The field literally didn't even exist 45 years ago, he adds. In the 1950s and 1960s, theorists were trying to put together highly symmetric models to account for things like the nuclear forces. These nuclear forces are self-evidently of short range, unlike gravitation or electromagnetism, which can extend arbitrarily long distances. The question of mass turns out to have been on many specialists minds in the 50s and '60s, but as embedded in quite different-sounding conversations. So let's look a bit more at some of the proposed solutions to this issue. In Einstein's theory, the unit strength of gravity is set by some universal constant, the same constant G. Brans and Dicke were wondering was, what if that unit strength is actually not a constant? What if the strength ofgravity could vary across time and space? So one way to represent that variation was to say that this unitstrength of gravity, Newton's so-called constant, actually could vary because it was actually a dynamical field. And they put in very cleverly this extra dimensionless constant, a fudge factor, that they labeled by the Greek letter omega. Their version would depart from the ordinary behavior from general relativity. The idea is that this new form of matter, this new field phi, is extended throughout all of the universe through every nook and cranny of space. All of matter interacts with phi. It's almost like a new ether, you might say. And then the fact that phi is extended everywhere and is interacting universally is what they thought would take into account Mach's idea that the local inertial effects, the effects of this strength of local strength of gravity. At the time, Carl Brans and his advisor Robert Dicke were working on a new form of matter. Jeffrey Goldstone was among the first to show that a certain kind of characteristic shape for a potential energy function could break the symmetry of the nuclear forces. The Higgs field is responsible for giving everything else the masses that we measure, including those force-carrying particles. The equations for the governing nuclear forces could retain all the fancy symmetries for which these new particles were introduced to reinforce that symmetry at each point in time. An induced mass coming from this spontaneous symmetry breaking. So now, again, you can have your symmetries and your short range. You can have his cake and eat it too. That was a lovely idea being introduced right around the same time as Brans-Dicke also as one way to try to get to this question of why do objects have mass. So these two communities saw very different things even though they use the same Greek letter phi. They were embedded in different kinds of conversations. A paper is considered technically renowned if it accumulates at least 500 citations in the scientific literature. Each of these papers-- the Brans-Dicke paper and the Higgs papers-- became technically renowned within fewer than 20 years. These papers were setting their own fields on fire. And yet, there's almost no overlap. These two communities were quite separated during this 20-year span. So you can see more than 500 each. In fact, it's 1,083 distinct papers doing the citing if you add up all the ones between these two plots. over 2% of the author pool-- cited both Brans-Dicke and Higgs usually in separate papers, but actually cited them in any of their work, again, over that first 20-year period. These are just ways to say that these two subfields really were not strongly interacting. In 1979, two separate theorists working independently of each other actually suggested that the two fields might be literally the same, not just comparable or worth considering side by side. How people assess them or what they thought they were good for was changing over time. more than just the letter that they chose. There was a lot of what we might have considered similarities. And yet, the two sets of ideas really were treated so separately. By the end of the '70s, things did not look very good for Brans-Dicke gravity experimentally. In fact, Einstein's theory was not highly favored, and that's why everyone else started paying attention on the gravity side of the field. So we might wonder, well, was it changes in data? Did experiments force a new evaluation? asymptotic freedom. And actually, it's the reason why our friend and colleague here at MIT, Frank Wilczek, received the Nobel Prize. So this was work introduced by Frank and his then advisor David Gross, and independently by a different very young grad student at the time, David Politzer. And what they found was that the strength of the strong nuclear force, that QCD force that we talked about quite a bit at the end of last class session, that the force actually decreases with the energy scale. start showing up regularly on the general exams for physicists across all fields, all specialties. So now you have more and more students in their PhDs responsible to have learned something in neighboring subfields. And you see a market response as well. You see a flood of new graduate-level textbooks on general relativity on gravitation and cosmology-- twice as many published in the 1970s versus the 1960s. And in fact, even of those 1970s books, the vast majority came really in the later '70s, in the wake of these pedagogical reforms. a continuous unitary symmetry, which is like saying you could rotate the electron field by any continuum amount, and the equations remain unchanged. The photon only has to mop up a relatively simple symmetry, the U1 gauge symmetry. Whereas SU2 was what I was pointing to when I was referring to the weak nuclear force. That's a more complicated symmetry structure. And that's the symmetry group that these force-carrying particles-- the W and the Z particles-- are invented to enforce. In 1979, Anthony Zee and Lee Smolin introduced a whole new model where they didn't only cite Brans-Dicke and Higgs, they literally united them. They wanted to ask why gravity appears to be so weak compared to all the other forces. So the idea was that this local strength of gravity, Newton's constant, which goes 1 over this phi squared, would get anchored to a very small value when phi gets stuck at a relatively large value. And so when this dynamical field, this field phi, skitters around the universe, it eventually reaches some kind of lowest equilibrium state. setting the inverse gravitational field strength. So why is gravity so weak? They suggested maybe it's because it's arising from some broken symmetry. Much like the Higgs-Goldstone mechanism, the field is dynamical, but it's getting stuck. Only in the broken-symmetry phase do we experience a phenomena that we are used to. So gravity gets stuck being weak because its local strength is arising through the Brans-Dicke field getting accurate in a symmetry-breaking potential. Few physicists today think Brans-Dicke theory of gravity best describes our Universe. Interest in the field grew even as it was getting experimentally less and less favored. One of the leading contenders for our understanding of the very early universe does exactly the kinds of things that Smolin and Zee had been doing, trying to unify the Brans and Higgs field. The idea that we're picking single theories and that they replace each other, I think, just misses this fine structure. Lee Smolin and his generation just was importantly different from the very excellent training that people like Tony Zee had had even just a mere 10 years earlier. And in turn, these new folks, especially people like Mike Turner and Rocky Kolb, went on to become real institution builders in their own right. So in fact, they were accelerates. Not only had they been trained to think carefully at this new interface, they helped really accelerate the trend. So it's gone from really, really just never done for nearly 20 years to now remarkable if people even question it. the hall from Alan's. And by a quirk of the old building 6, we had the same key. A single key would open the whole hallway. Couldn't get rid of it now. And one time, my parents were visiting. And I basically broke into Alan's office. They couldn't believe me when I described what it was like to try to work with this person. So I actually broke into his office to show them the safety violation, fire code violation, horror show that was the den of entropy. So that's a true story.

ROUGE-1: 20.14, ROUGE-2: 19.15, ROUGE-L: 19.28
BERTScore: 58.22

==============================================
==================== [12/100] ====================
Summary:
Frida Ghitis: Ferdinand Magellan may have been the first person to actually circumnavigate the globe. She says Spain and Portugal had their eyes on the same prize: trade routes to the Spice Islands. When a Portuguese defector claimed that a westward route existed, King Charles made him captain of a Spanish armada, she says. Ghitis says Magellan's legacy lingers: galaxies and space programs named after him, and he was celebrated in Spain. of the "Victoria" sailed into harbor in southern Spain in September 1522.

ROUGE-1: 17.48, ROUGE-2: 13.88, ROUGE-L: 12.94
BERTScore: 60.28

==============================================
==================== [13/100] ====================
Summary:
Ani was a real person, a scribe from the Egyptian city of Thebes who lived in the 13th century BCE. His Book of the Dead, a 78-foot papyrus scroll, was designed to help him attain immortality. Ani's epic journey begins with his death. His body is mummified by a team of priests who remove every organ except the heart. It's then stuffed with a salt called natron and wrapped in resin-soaked linen. In addition, the wrappings are woven with charms for protection and topped with a heart scarab amulet.

ROUGE-1: 25.56, ROUGE-2: 24.23, ROUGE-L: 25.56
BERTScore: 68.27

==============================================
==================== [14/100] ====================
Summary:
Judy Hoyt: We're going to discuss the accurate control and placement of active dopant regions through a process called dopant diffusion. The placement of those regions determines many of the so-called short channel characteristics of MOSFETs that we'll talk about. The doping of other materials, not just the silicon itself, but of the polysilicon gate affects things like gate depletion and limits how well the gate voltage controls the channel potential, Hoyt says. The equation numerically, essentially, for an arbitrary doping profile is 1 over the integral of the carrier concentration minus the background concentration. of cases where there are analytic solutions. We talked about the diffusion of a Gaussian profile with a fixed dose. We apply this diffusion to a constant surface concentration. And finally -- we talk about the diffusion of a complementary error function, which we apply for a constant level of surface concentration. The diffusion of this error function can be applied to a fixed level of surface concentration, or a constant level of substance on the surface, for example.

ROUGE-1: 3.62, ROUGE-2: 3.14, ROUGE-L: 3.27
BERTScore: 67.55

==============================================
==================== [15/100] ====================
Summary:
Atas model shows what happens if aggregate demand increases and firms respond to this by saying we want to make more output. As people demand these higher wages shortening our supply curve decreases basically all the way back to essentially where it was before. The price of tuition to Missouri State goes down but my wage is fixed under contract right and so they're gonna have to pay me the Saints of tuition declines and my input prices stay the same that's bad for them and bad for all of the firm's too.

ROUGE-1: 4.64, ROUGE-2: 4.40, ROUGE-L: 4.64
BERTScore: 56.42

==============================================
==================== [16/100] ====================
Summary:
As a nurse you play an important role in teaching the parents about car seat safety and this education actually starts at birth before the child even goes home from the hospital in their first car ride. In this lecture we're going to concentrate on the main concepts that you need to know as a nurse and for exams first let's talk about the four types of car safety restraints that you can use in a motor vehicle. The back seat of the car is actually the safest place for a child 12 and under. level not one inch below it okay so if you would like more free quiz questions you can access the link below and don't forget to access the other videos in this pediatric nursing series. Thank you so much for watching and have a great day. Back to the page you came from. Follow us on Twitter @CNNNursing and @cnnnursing on Facebook and @CNNHealthNursery on Instagram. For more pediatric nursing videos, visit CNN.com/nursery.

ROUGE-1: 11.41, ROUGE-2: 9.86, ROUGE-L: 9.85
BERTScore: 61.10

==============================================
==================== [17/100] ====================
Summary:
Machine learning is about how to acquire a model and acquire the parameters of a model, from data and experience. In the next few lectures, we're going to work through a sequence of different takes on machine learning that are going to highlight different subsets of the big ideas on this topic. We'll see today exactly how data kind of goes through the mill and gets turned into a model. And we'll see more in-depth examples and more structured examples of these kinds of problems later on when we talk about applications. is going to be unique. It's going to have to be at least one pixel off of something else you've seen. There's a lot of inputs that are really noisy, and you're training set, they might be hard, expensive to label, because they're noisy. And then at test time, you're going to make mistakes because machine learning is not perfect. We can look at other kinds of patterns. We could look at how many connected components of ink there are. What's the aspect ratio? How many loops are there? machine learning methods get better at doing that. We'll talk about that in a couple weeks when we talk about narrow nets. There's tons of classification tasks. It's probably the most widely-used application of machine learning. In model-based classification, rather than directly learning from errors that you make in the world from experience, instead we're going to learn by building a model from our data, and then doing inference in that model to make predictions. After today we'll look at the model-free methods. The Naive Bayes assumption is an extremely radical assumption as far as probabilistic models go, but for classification, it turns out to be really effective. The model itself might look something like this, where the class is the cause, and it independently causes each of those features. And that means when you go to make a prediction, it decomposes into a product of a bunch of different feature conditional probabilities, and we'll see examples of that and unpack the inference for that. Machine learning is something called empirical risk minimization. The main worry is that you-fit is that over-fit in picking the parameters of your model. Optimize your training set in the hopes that quantity will remain optimized. This is like downloading all the answers from past years, and you go and optimize all those answers. We'll see some concrete examples up now and this will be a little abstract, but we'll see more concrete examples in the next couple of lectures. All right, we're going to get started again. the thing we're trying to do is to fit a curve to this data. So you say, what is the fit? Is the fit getting as close as possible to the last dot? So what is my constant approximation to this? Does anybody want to hazard a guess? Let's call it five. OK, did I fit something about this data? Yeah, I felt something about the data. I fit basically it's mean. Did I capture the major trends? No. All right, let's try again. Let's fit a linear function. It's close, right? It's a better fit than the constant function. Notice that when I went to linear function, the space of hypotheses grew. Instead of just lines, now it's like lines with slopes and intercepts. In Naive Bayes probabilistic models, over-fitting usually shows up as zeros in your probability table. In other methods, it's actually going to show up in totally other ways. So let's figure out some ways to do that, to just illustrate what it would like to look like. We could take that polynomial and limit the degree of the polynomials. Using it under a hypothesis, you can also shrink the hypothesis space, so you can fit less under it. We already know one kind of over-fit to limit that. The maximum likelihood estimate, or relative frequency estimate, is used in machine learning. It says, OK, the probabilities are just the counts in the training data. For each probability I assign to red, and one minus that goes to blue, I can compute the probability of D. This is something you could try writing out for yourself. Of all of those probabilities, the one that matches the frequency of the data is the one. that maximizes the probability. of theData. But in practice, you need some smoothing. CS281A is an open-source computer program. It can be used to test computer models. CS281A uses a Bayes rule to find the parameters which maximize the product of this, which is what we were doing before. But there's this extra term, p of theta, which says, if I want to know what parameter or what probability is most likely, I need to weigh the likelihood of the data against how likely I think that parameter is in the first place. This is actually, due to Laplace, hundreds of years ago now, who's a philosopher who kind of worried about things. In a real classification problem, you have to smooth if you're going to use Naive Bayes. Instead of computing odds ratios on the maximum likelihood, I can instead do some smoothing and see after that smoothing, what has the biggest odds ratio? And suddenly things that only occurred once, they don't percolate to the top, because they haven't occurred enough to overwhelm that flat prior that I'm associating them with. So this is the top of the odds ratios for ham on the left, and favoring spam on the right. Some of these maybe make sense. Like, there it is. In general, your model is going to make errors. In spam classification, we found out that it wasn't enough to just look at words. For digit recognition, you do sort of more advanced things than just looking at pixels. You can add variables into your Naive Bayes model, but we'll also talk in the next few classes about ways to add these more flexibly and also induce these right, right? All right, I'm going to stop there for today and as you go, please come and grab some more candy.

ROUGE-1: 13.26, ROUGE-2: 12.33, ROUGE-L: 12.24
BERTScore: 64.89

==============================================
==================== [18/100] ====================
Summary:
in this video we're gonna talk about how a country can gain from exporting goods or services through international trade. We're gonna look at how consumer surplus producer surplus and total surplus are going to change when we introduced the idea of trade in allowing Chile's copper manufacturer producers to trade on the global market. The world price of copper is five thousand four hundred and forty dollars a ton. Because the world price is higher than the price in Chile Chile will export copper. There is a shift of some of the consumer surplus is going to go to the producer surplus.

ROUGE-1: 14.64, ROUGE-2: 13.69, ROUGE-L: 13.40
BERTScore: 67.04

==============================================
==================== [19/100] ====================
Summary:
Thiazide tells us that this medication works in the early part of the distal convoluted tubule that's found within this nephron. This transporter is called the sodium chloride co-transporter and it is considered a cyanide sensitive transporter so hence why this drug works so well. While loop diuretics are a lot more effective than a thiazide diuretic but the thiazid does provide a nice diuresis effect. They're less effective in patients who have a compromised GFR a go merrill ER filtration rate.

ROUGE-1: 4.67, ROUGE-2: 4.40, ROUGE-L: 4.67
BERTScore: 63.50

==============================================
==================== [20/100] ====================
Summary:
Future John Green tells you that in a stunning turn of events the 2020 presidential election will be won by - Harry Styles. I know that he's English and under 35 but we're going to change the constitution to make it possible. Because… that’s how much we love Harry Styles in 2020. The Major Recession of 2008 - 2012. A mixture of public and private activities that tilted towards short-term economic thinking, speculation and irresponsible spending. The Wall Street Wamboozle, the Financial Fartstorm. In 2008 Obama’s election seemed a political watershed and not just because he was the first African American president. He appealed to young people and minorities, and he harnessed the power of social media to communicate with supporters, and get out the vote. So Obama promised to change the culture of Washington. He would end partisan squabbling…. sorry. I guess the author of the Mystery Document, if I’m wrong I get shocked. No more shocks. The getting shocked part of my life has come to an end. Obama wanted a foreign policy based on diplomacy, he wanted to reduce inequality and increase access to health care. He also wanted to end the wars in Iraq and Afghanistan and, as critics mocked, reverse global warming. So how has he done? Not bad either. For instance he launched diplomatic outreach to the Muslim world, but a lot of this was more rhetoric than action. And he did keep some of his campaign promises, for instance he signed into law the Lily Ledbetter Fair Pay Act, which made it easier for women to sue. depends on who you ask. Among 9 large studies, 6 found that the stimulus did have a positive effect on growth and employment, 3 found that it had little or no effect, and economists are equally divided. The stimulus is estimated to have saved about 3 million jobs, but it also increased the deficit quite a bit. Liberal economists see America’s current 7% unemployment rate as evidence that the Keynesian policies should have gone further, while conservatives say that the Stimulus exploded the federal deficit and debt. The 111th congress was one of the least productive in American history. Unwillingness to compromise precipitated a series of mini-fiscal crises over things like the budget and raising the debt ceiling. The Tea Party is right that the founding fathers would be astonished by the extend of the American government and the extent to which it’s involved in the lives of Americans. We have to ask ourselves again, “What does freedom really mean?” Can you be free when you live in poverty or when you’re one injury away from bankruptcy? Can you being free when the government can go to a secret court to read your text messages? Crash Course World History has been on the air for two years. The show celebrates two successful years of teaching history. This has been one of the great professional joys of my life and I’m so grateful to everyone that has helped make the show and everyone who has watched it. Thank you again for watching, and as we say in my hometown, “Don’t forget to be awesome.” You can find a full list of your reading for Crash Course Literature in the doobly-doo.rolling.

ROUGE-1: 29.44, ROUGE-2: 27.86, ROUGE-L: 27.05
BERTScore: 60.40

==============================================
==================== [21/100] ====================
Summary:
Simple graphs are directed graphs where the arrows have a beginning and an end. A directed graph might have a self loop, an edge that starts and begins at the-- starts and ends at the same vertices. A simple graph has a nonempty set, v of vertices, and it has a set E of edges, but the edges now are somewhat different since they don't have beginnings and ends. An edge just has two endpoints that are in V, and we don't distinguish the endpoints.

ROUGE-1: 8.36, ROUGE-2: 7.79, ROUGE-L: 8.26
BERTScore: 72.59

==============================================
==================== [22/100] ====================
Summary:
Robotics is a really cool and important direction for the future. I really believe that in the future we will have AI assistance whether they are embodied or not to act as our guardian angels. These agents will help us with cognitive and physical work. With AI we will see such a wide breadth of applications for instance these technologies have the potential to reduce and eliminate car accidents. We have three types of learning and you have seen different aspects of these methodologies throughout the course we have supervised learning, unsupervised learning and reinforcement learning.

ROUGE-1: 2.13, ROUGE-2: 2.04, ROUGE-L: 2.13
BERTScore: 64.13

==============================================
==================== [23/100] ====================
Summary:
hair up grab an apron let's go now with the new chefs in placelet's go Tatiana okay Gordon knows it's critical that Tatiana is familiar with the inner workings of the kitchen. I just can't wait to get to work and prove to my mom and my sister that I can do this I think the message is clear nobody scared to walk through that door and get their hands dirty in that kitchen no we're not tomorrow is a big day let me tell you I need everyone on their game good night guys get some sleep thanks. ramsy you're my boy dude what the [ __ ] have you done stop no no no listen [__ ] donkey Danielle come here I want you to stop but if the restaurant goes your hous is going go wow um and how much money did you put in um probably like 1,000 bucks probably like 2,000 dollars.ramsy: "I'm sorry. I'm so sorry. It's just the way it is. I don't know what I'm going to do. I just want to go home"

ROUGE-1: 47.58, ROUGE-2: 42.20, ROUGE-L: 40.26
BERTScore: 62.69

==============================================
==================== [24/100] ====================
Summary:
HONG LIU: Last time, we talked about this IR-UV connection between the bulk and the boundary. Now let's talk about some further aspects of the duality. HONG LIu: Once you realize there's such relation, since the two sides are completely different objects, so the game is that you really have to do lots of guess work. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu. HONG LIU: There is a conformal symmetry of a d dimensional series SO d, 2. And on this side, there's precisely the same group, which is isometry of Ads5. In N equals 4 super Yang-Mills theory, we discussed last time there are six scalar fields. You can rotate them each other. And this can be considered as coming from the D3 brane. So essentially, you have eight supercharge of the [INAUDIBLE]. So this all together is 32 real superchargers. expanding 1 over N squared. So as we said before, we often do dimensional reduction on S5. Then G5 divided by R cubed, again only related to N given by pi divided by 2N squared. These relations are often useful in the future. So now let's look at [INAUDIBLE] limits of this relation. So classical gravity limit is the same as QFT, Quantum Field Theory in curved space time. But your matter field can fluctuate, h bar equal to 1. a general correspondence between some conformal field theory and some AdS gravity theory. HONG LIU: Yang-Mills theory lives on Minkowski space. And then you say you can imagine that this is the boundary, this relation is related to the bulk and the boundary. And this is a postulate based on that fact. AUDIENCE: So if it's a sort of postulate that's just thinking about it, it's not required that the theory live on the boundary of AdS. HONG LIU: Given this mapping, any operator is due to a bulk field. So for local operator on the field theory side, we can immediately ask questions related to operators on this side. And ask the story about the field on the gravity side, and ask what's happened. We can start developing the relations. So here, I will try to deduce the answer to this question by starting from this relation. Let me actually call it capital Phi. So we've talked about before GS string coupling can be considered as the expectation value of the dilaton field.

ROUGE-1: 9.60, ROUGE-2: 9.12, ROUGE-L: 8.65
BERTScore: 69.18

==============================================
==================== [25/100] ====================
Summary:
Bolek Wyslouch: How do you convert a given physical system with all the forces, et cetera, into some sort of fixed form, fixed type of notation? We will discuss various interesting-- even though the system is very simple, just two masses, a spring, a little bit of gravity on top of that. The way they behave could be extremely complex, but it can be understood in terms of very simple systematic way of looking things through normal modes and normal frequencies. into a set of equations. So we have a mass, m, hanging from some sort of fixed support, another mass here, same mass for simplicity. We connect them with a string, and we know everything about this system. The spring is initially at its rest position such that when the two pendula are hanging vertically, the spring is relaxed. But if you move it away from verticality, theSpring either compresses or stretches. We assume that this is an ideal system, highly idealized. The magenta is normal mode number 2. And blue and the red are the actual pendula. And the motion of blue and red is simply a linear sum of the two. And this is exactly what-- this is the computer simulation that shows you that one of them is going up, the other one down, et cetera. This is for the certain combination of initial conditions. I could go change initial conditions in my program and have a different behavior. But whatever happens, I would be able to-- it will always be a combination of thetwo motions. BOLESLAW WYSLOUCH: I could put it with me some spaceship, and go to a place where the gravity is different, right? Why not? So what would happen? So if gravity changes, then basically what will happen is both this term and that term will change. So let's try to see what happens on the Moon. It's a little bit not completely clear what's going on, but you see, actually the motion is kind of strange. It looks kind of messy, doesn't it? equations. Let's look at these equations here. This is mass 1 and mass 2. So I can rewrite those solutions a little bit different. And what you get is x1-- x1 of t is equal to minus x0 sine of omega 1 plus omega 2 divided by 2 times sine omega 1 minus omega 2 divide by t. So again, we did zero physics here. We just rewrote the simple trigonometric equations. But what you see is something interesting here. There is-- we have those two frequencies which are playing a role. like this. OK? So there are in fact two-- when you look at this picture, you can see two frequencies. One which is clear the oscillation of the-- high-frequency oscillation. But there's also this kind of overarching frequency of much smaller frequency, and this is what corresponds to a difference of two things. So we see this here. We see it on the pendula. But now what we are going to do is we're going to try to hear it, right? So this is a demonstration which maybe it works, maybe not. BOLESLAW WYSLOUCH: You can force mathematically, force the normal modes from sort of early on, to instead of, so far, when we talked about pendula, we describe their motion in terms of motion of number 1. It turns out we can rewrite the equation into some sort of new variables, where, so-called normal coordinates, where you'll simultaneously describe both of them and then kind of mix them together to have a new formula. All you need to do is break this one, modify its frequency.

ROUGE-1: 11.61, ROUGE-2: 11.18, ROUGE-L: 11.52
BERTScore: 61.32

==============================================
==================== [26/100] ====================
Summary:
GILBERT STRANG: This is the second of the three basic partial differential equations. We had Laplace's equation, that was-- time was not there. Now time comes into the heat equation. We have a time derivative, and two-- matching with two space derivatives. So I have my function. My solution depends on t and on x, and I hope I can separate those two parts. This is exactly like the way we solved the ordinary systems of differential equations: We pulled out an e to the lambda t. Fourier series tells us how to find these Bk's. We're talking about a partial differential equation. We have numbers depending on time and decaying rapidly, and something depending on x. So at time 1, if I drew a picture, suppose the heat is, the temperature starts out through the whole bar at 1. But with this kind of time decay, a little later in time, it's going to be something like that. It'll be way down at the ends, pretty low in the middle. So that's what solutions to the heat equation look like.

ROUGE-1: 25.41, ROUGE-2: 24.63, ROUGE-L: 24.46
BERTScore: 70.25

==============================================
==================== [27/100] ====================
Summary:
James W. SWAN: I hope everybody saw the correction to a typo in homework 1 that was posted on Stellar last night and sent out to you. The TAs gave a hint that would have let you solve the problem as written. But that's more difficult than what we had intended for you guys. So maybe you'll see the distinction between those things and understand why one version of the problem is much easier than another. So we've got two lectures left discussing linear algebra before we move on to other topics. because you didn't do pivoting-- you'd like to do pivoted in order to minimize the numerical error. Or you need to reorder inorder to minimize fill-in. As an example, I've solved a research problem where there was something like 40 million equations and unknowns. If you reorder those equations, then you can solve via Gaussian elimination pretty readily. But if you don't, well-- my PC had-- I don't know-- like, 192 gigabytes of RAM. The elimination on that matrix will fill the memory of that PC up in 20 minutes. And you'll be stuck. model I showed you last time works. If the chip is in a particular cell, then at the next level, there's a 50/50 chance that I'll go to the left or I'll going to the right. So the probability that I'm in a certain cell at level i is this Pi plus one. And there's some sparse matrix A which spreads that probability out. It splits it into my neighbors 50/ 50. And we'll see the simulation that tells us how probable it is to find the Plinko chip. Yes? Eigenvectors of a matrix are special vectors that are stretched on multiplication by the matrix. They're transformed. But they're only transformed into a stretched form of whatever they were before. For a real N-by-N matrix, there will be eigenvector and eigenvalues, which are the amount of stretch. Finding eigenvector-eigenvalue pairs involves solving N equations. We don't know how to solve non-linear equations yet. So we're kind of-- might seem like we're in a rough spot, but I'll show you that we're not. Eigenvalues and eigenvectors seem like special sorts of solutions associated with a matrix. If we understood them, then we can do a transformation. Here are some examples of the diagonal elements of a diagonal matrix. See if you can work out the eigenvalues of that matrix. Anyone want to guess what they are? Try to make sure you can do it on your own. If you couldn't do this, that's OK, but you should try to make your own practice on this. Eigenvalues can be interpreted in terms of physical processes. This quadratic solution here has some eigenvalue. It's not unique, right? It's got some constant out in front of it. So add the first row or subtract the second row. And then we'll compare. This will just be a quick test of understanding. Are you guys able to do this? Sort, maybe, maybe an answer, or an answer for the eigen value. Is that too fast? Are you OK? No. There are many times when there's not a complete set of eigenvectors. And then the matrix can't be diagonalized in this way. So there's an almost diagonal form that you can transform into called the Jordan normal form. There are other transformations that one can do, like called, for example, Schur decomposition, which is a transformation into an upper triangular form for this matrix. And we'll talk next time about the singular value decomposition. All right. Have a great weekend. See you on Monday.

ROUGE-1: 15.35, ROUGE-2: 14.35, ROUGE-L: 14.63
BERTScore: 63.21

==============================================
==================== [28/100] ====================
Summary:
A random variable is a number that's produced by a random process. The number of faulty pixels in a monitor is also produced from an unpredictable randomness. The event that C equals 1, that's an event that-- it's a set of outcomes where the count is 1 and it has a certain probability. There are 3 possible outcomes among the 8 outcomes of heads and tails with 3 coins. The probability that C greater than or equal to 1 is 7/8. And when the outcome is translated into a real number that you think of as being produced as a random variable, it's what the random variable does. hold in circumstances where pairwise does hold. So this is good to know. We'll be making use of it in an application later when we look at sampling and the law of large numbers. Back to Mail Online home.back to the page you came from. Back To the pageyou came from, back to the pages you came From. Back then, the page was: "The first page of the first week of the second year of the Second World War. The first page was the first day of World War II. The second was the second day of the First World War."

ROUGE-1: 13.08, ROUGE-2: 10.35, ROUGE-L: 11.12
BERTScore: 59.58

==============================================
==================== [29/100] ====================
Summary:
s gawan and the Green Knight um I believe this is the last piece where we don't know who the author is where it's unknown um I find the background interesting and that through textual Clues they're able to figure out who wrote it. I think straight off we can say that that's probably gow or sir GA however you want to say it okay then you have the villain or the dams and all as we come through the story try to put these titles with certain characters. good person away with the forbidden fruit you know something similar we could maybe connect uh down the road but it's very similar to to those so um so go and the green. I hopefully you enjoyed it um really story-wise we're done with knights uh. It's a very similar story to the one we did with the knights. It was a very different story but it was very similar. I hope you enjoyed the book. I'm glad you read it. I'll see you next week.

ROUGE-1: 7.39, ROUGE-2: 6.37, ROUGE-L: 6.32
BERTScore: 63.75

==============================================
==================== [30/100] ====================
Summary:
YouTube boy Robert teaches you everything in the kitchen. We have blueberries strawberries Kiwis red beets yellow beets pineapples right in fruit and cucumber this is the equipment you'll need for today you don't need one blender sheet trays mason jars parchment paper aluminum foil a spice grinder a bowl with a strainer and a plastic spatula all right so what you're gonna want to do first is cook off your beets we're gonna soften them up I said that when we blend them. with salt so they could be added to savory dishes and that's how you please have you made it this far thank you for watching if you liked the video then go ahead and like the video give it a thumbs up. Don't don't worry about the finger just give it an thumbs up and I'll see you next time [Music]  "I'll See You Next time" is a weekly video series on CNN iReport.com. Visit CNN.com/Video each week for a new video.

ROUGE-1: 43.06, ROUGE-2: 38.75, ROUGE-L: 39.43
BERTScore: 63.06

==============================================
==================== [31/100] ====================
Summary:
Vital Signs are pain oxygen saturation temperature heart rate respirations and blood pressure. The six Vital Signs are rated on a scale of zero to 10 with zero being no pain at all and 10 being the worst pain they've ever had. Here in a second I'm going to show you how to actually count the heart rate using the radial artery. I'm also going to go over how to take a blood pressure reading. I'll be back in a few minutes with the next Vital Signs video. Mark now we're listening for whenever it stops and whenever it stopped that's our diastolic okay it stopped right at 65 so his blood pressure is 114 over 65 so that is how you check bottle signs now whenever you're done remember to let the patient know what their bottle signs were and um do hand hygiene and clean your equipment before you go to the next patient so be sure to check out all my other videos on nursing skills and thank you so much for watching and for all your support.

ROUGE-1: 19.83, ROUGE-2: 17.57, ROUGE-L: 18.20
BERTScore: 61.67

==============================================
==================== [32/100] ====================
Summary:
Grenade algorithm uses a minimal set of three-point correspondences to solve the camera pose estimation problem in the grenade formulation. The disadvantage of this particular formulation is that it ends up with a four degree polynomial which means that it could give up to a total of four possible solutions. The question becomes whether can we find the solution directly from any four point correspondences such that the solution is unique? The answer is yes and it was formulated by quan at all in a paper that was published in the 1990s. The epmp algorithm mitigates the problem of the linear endpoint algorithm that was shown earlier on by quan and lun that was published in the year 1999 which has cubic complexity in the order of the number of points. The objective is actually to find out the relative transformation between the camera frame and the world frame. We'll first look at the case where these four control points are non-coplanar control points this means that these four Control points will not lie on a plane. We will then use the same relation for the 3d points in the camera coordinates. forms a plane then this is also a degenerate case and that's the end of today's lecture thank you mx equals to zero. Mx is the letter that starts with the letter "m" and ends in "x" mx is also the letters that start with the letters "n" and "o" mX is the word that begins with "n", and ends with the word "n". mx means "one" and n is the number of a person or object.

ROUGE-1: 5.93, ROUGE-2: 5.06, ROUGE-L: 5.10
BERTScore: 64.05

==============================================
==================== [33/100] ====================
Summary:
Markus Klute: If there is a time dilation effect due to gravitational fields, then there's also a redshift which is of gravitational fields. He asks you to estimate the magnitude of this effect. Klute says the speed of light is pretty fast, 3 times 10 to the 9 meter per second. And this distance is only 22 and 1/2 meters, so we find that this is a tiny, tiny,tiny effect, he says. But nevertheless, experimentalists at Harvard tested this effect in the 1950s and '60s.

ROUGE-1: 39.72, ROUGE-2: 36.58, ROUGE-L: 39.72
BERTScore: 71.50

==============================================
==================== [34/100] ====================
Summary:
During the semester we have a few recitation instructors they help with the students during the recitation section. During those sections your the the instructor will solve a similar problem like what is actually covered during the same during the lecture and that give the students another chance to look at more example and to get for media will get used to the calculation which we carry how for the first time during the the lecture. We did not record the Recitation sections during the fall semester in 2016 on the other hand we included problem-solving videos from Professor with Busha.

ROUGE-1: 67.77, ROUGE-2: 66.22, ROUGE-L: 67.77
BERTScore: 85.45

==============================================
==================== [35/100] ====================
Summary:
In this video, we're going to compute some useful quantities for the exponential random variable. The CDF of x is the probability that X is less than or equal to little x. We use the standard formula, which is minus infinity to infinity t times fx of t dt. For this, if you evaluate the balance, 0 makes this 0, and 0 to get 1 over. And so the expectation is 1 over lambda, and so the variance is part c, so OK, so far so good.

ROUGE-1: 8.43, ROUGE-2: 7.36, ROUGE-L: 8.24
BERTScore: 68.58

==============================================
==================== [36/100] ====================
Summary:
Professor: Can you explain the physical significance of the crystal momentum? Professor: The information about the momentum can be encoded in these spatial variation of the phase of the wave function. Professor: A central property from the Schrodinger equation is at the time variation d dt of p is equal to the expectation value of minus d the potential of x d x. The momentum expectation value is time independent, so it can be written in the form of e cubed, equal to e to the minus i upon h bar p l. the imaginary part of SI complex conjugate derivative, with respect to x, which is the current, in the x direction of SI. And we need this to be imaginary, or we will get no current. So we need the wave function to be real. So if q were zero we would get zero. And the current depends on both the part defined mod 2 pi over l, and the integer, which tells you how many factors of 2pi over l did you have to subtract off to get into that fundamental domain. we just give up on quantum mechanics and say it totally failed? And so this is a totally reasonable question, and I want to emphasize something important to you. That model led to a prediction, which is that if you put a capacitor plate across a perfect crystal, then you would get no current flowing across. And that is manifestly what happens with copper. But the experimentalist comes back to you and says look dude. That is a ridiculous model because the copper isn't in fact perfect. So how do you test the model? Well there are two ways to test-- to deal with the situation. situation, it depends on the system. And exactly how it depends is something that is an active area of research. So we know that these block oscillations are true. We see them in all sorts of different systems that are analogous. But it's one that turns out to be surprisingly difficult to tease apart. So don't throw away the model. Observe that you've modeled the wrong system. If you find a system that fits your-- that is-- that shares the assumptions of your model, that's when you ask did it work. down here in the ground state, and looking back at that band, we know that the band for that ground state looks like this. So, here it is. There's our electron. It's sitting in the lowest energy eigenstate. Is it moving? Well, it's in a stationary state. Is the expectation value of the position changing in time? No. It has some meaningful, well defined time variation of its position expectation value. In order to induce the current, I must put the electron into a higher energy state and in a particular superposition of higher energy states. In order for light to scatter off a crystal, you must have electrons in superposition states so that they can have a dipole and absorb and radiate that energy. In order for that to happen, the light has to excite an electron across the gap. Light along wavelength will not have enough energy toexcite an electrons across this gap into the next band to allow there to be a current, which could oppose the electric field. So we have these two materials which one has the larger band gap? Diamond, because it's transparent. In three dimensions, the gaps are not the same. That they do not remain constant. There's one that changes, one that doesn't. And then this guy has five. One, two, three, four, five. The story changes in a dramatic way. The deformation is where you have a sphere and you stick out your arm. So it's no longer symmetric top. So here we can have states crossing. And there's no nodes here in three dimensions. Because there's nothing preventing states from different-- in different multiplates from having the same energy. When we filled those first two bands, well, there is the first-- so the first band is now filled. And back here , we had an insulator because we had filled bands separated by gap. The gap between the filled band and the next available band. This is actually called a band insulator. Because there are other ways of being an insulators. And this is why Matt wasfing at me. So the answer is that there isn't one answer to that. But what we need is the non-zero band. The probability of finding the particle at point A is given by chi a squared. And similarly, the probability that we find the second particle at b is this thing norm squared. But we also studied the symmetric configuration, which was equal to 1 over root phi, root 2. This should be a correct description of many experiments, this should be totally awesome. But it's deeply disconcerting, because I could've taken these particles, put them in this entangled state, and sent one particle off to a distant planet. And my sister measures this second particle and determines what state it's in. Einstein created a thought experiment which we're going to study in detail next week called the EPR experiment. He left Germany in 1932 December, about three weeks before Hitler took power. And he did so with decisiveness and dispatch and a head of almost all of his. German-Jewish physicist colleagues and those German physicists for whom the Hitler regime was unacceptable. The three of them talk about it. They write the paper and they put it out. And I want to share with you, actually, a really lovely description of the way the problem was represented in a way by a book that I recommend to all of you. Einstein, Podolsky, and Rosen argued that the EPR paradox suggested that quantum mechanics was incomplete. They said that if you can perform a measurement, you know that quantity absolutely. But you can't do the-- so on the one hand, quantum mechanics says you can’t know physical reality to this level of precision. And on the other hand, the fact that you can do that measurement violates the relativistic picture of reality. But the question is whether or not the framework of quantum mechanics is somehow unsatisfactory in any formal sense.

ROUGE-1: 13.87, ROUGE-2: 13.33, ROUGE-L: 13.43
BERTScore: 59.80

==============================================
==================== [37/100] ====================
Summary:
First up the proper way to chop fresh herbs to get maximum flavor chopping herb the secret is to chop them not bruised them now basil this is a soft herb so treat it with some respect when people go mad chopping herbs all the goodness comes out on the board. Tip to get the flesh out of a Kiwi this is simply cut the fruit in half and scoop out with a teaspoon try it it really works I absolutely love these peppers now they have the most amazing sweet delicious flavor with a really nice crunchy.  texture and the most exciting thing about the peppers is that they're just as delicious raw or cooked to identify the perfect pepper must be smooth and firm and not a wrinkle inside. A great tip to check if a pineapple is ripe is to pull a leaf out from the top if it comes away easily it's ripe and ready for slicing a great tip for getting meat or fish to cook faster is to score it which allows the heat to penetrate quicker this also allows mayonnaise to be absorbed more deeply.

ROUGE-1: 38.88, ROUGE-2: 38.35, ROUGE-L: 38.88
BERTScore: 63.37

==============================================
==================== [38/100] ====================
Summary:
hey everyone it's sth register nurse rn.com and in this video we're going to be going over our weekly inlex practice question. Let's see what our question says a patient who has a health history of uncontrolled hypertension coronary artery disease and diabetes militis is prescribed to take propanolol. The question asks which statement by the patient is correct about this medication propano wal that they're Going to be taking. The answer is that the patient should take the medication every morning with grapefruit juice and monitor their blood glucose level closely.

ROUGE-1: 12.51, ROUGE-2: 10.83, ROUGE-L: 12.12
BERTScore: 65.52

==============================================
==================== [39/100] ====================
Summary:
This is part 2 of a guide to clinical reasoning or how to create an accurate differential diagnosis from a patient's presentation. In the first part I reviewed a practical five-step bedside approach to Clinical reasoning. In this part I will demonstrate how to use this approach with an actual patient case at the student level. I present this patient to you the same way in turn might present the patient to his or her attending on rounds or to their colleagues during a morning report or teaching conference as I present the case I'll keep a running list of the key features of the presentation so they will seem like I am doing step 1 acquired data. The epigastrium would obviously be the most critical anatomic region to include organs that physically lie directly underneath it. Pancreas and small bowel diseases of the stomach which caused acute abdominal pain are many but most commonly are gastritis and peptic ulcer disease in the pancreas. The major structures are of course the liver and gallbladder along with other components of the extra hepatic biliary system. The spleen can cause pain with either a splenic infarct or asplenic abscess. Each diagnosis listed one at a time and review each individual key feature to decide if it impacted the probability of the diagnosis and what that impact was. Here is our framework once again and here are our key features how does one start this process the brute force method would simply be to take each diagnosis listed and review it one by one. Now that we have a framework we move on to the final and hardest step applying the key features to that framework so here is our Framework once again. Here are our Key features. that will increase the likelihood of. establishing the correct diagnosis sooner in outpatient hospital course you. That will. increase the chance of establishing the right diagnosis sooner. that will increase. the likelihood that you will be seen by a doctor sooner in hospital. that you. will be more likely to be admitted to hospital for treatment. that. will increase your likelihood of being seen by doctors sooner in the hospital. and that. you will have a better chance of being treated. of being diagnosed with a condition that is more serious.

ROUGE-1: 15.10, ROUGE-2: 12.39, ROUGE-L: 12.35
BERTScore: 61.14

==============================================
==================== [40/100] ====================
Summary:
Danqi Chen is one of the foremost researchers in question answering. She is the professor at the Princeton University. Danqi once upon a time was the head TA of CS224N. She's quite familiar with the context of this class. So today I'm very happy to introduce to you some of the fundamentals in this field, as well as on cutting edge and state of the art topics. So here's my plan for this lecture. I'm going to spend the most of this lecture focused on one type of question answering problems called reading comprehension. like 10-ish minutes to talk about a more practical, and in my opinion, more exciting problem called open domain question answering. Question answering, or, let's say QA in short, is one of the earliest NLP tasks, and the early systems can even date back to the 1960s. And, the question and answer has enabled a lot of really useful real world applications. For example, today if you just put your question in a search engine like Google, you can actually click on the correct answer, which is actually our concise answer. Question answering is probably one of those fields that we have seen the most remarkable progress in the last couple of years driven by deep learning. So in this lecture, I will be mostly focusing on the text based, or textual question answering problems. Another class, bigger class of the question Answer problems is called visual question answering. So if you have interest in these type of problems, I encourage you to check out those problems, but I'm not going to dig into these problems today. So next, I'm going to start with a part 2, reading comprehension. Reading comprehension has been viewed as a very important test bed for evaluating how well computer systems understand human language. This is really just similar to how we humans actually test the reading comprehension test to evaluate how well we actually understand one language. So this is also the way that we actually post questions to test the machine's language understanding ability. It actually has been formally stated back in 1977 by Wendy Lehnert in her dissertation. She says that, since questions can be devised to query any aspect of text comprehension, the ability to answer questions is the strongest possible demonstration of understanding. is actually called a semantic role labeling. So basically try to-- given one sentence, given one word, "finish" trying to figure out who did what to whom and when and where. By converting all these kind of semantic role relations, we can also just apply the reading comprehension problem and give you the correct answer. So next, I'm going to introduce this Stanford Question Answering Dataset called SQuAD. So if you are going to develop for the final projects, you will need to use this dataset. If you remove the context-to-query attention, the performance will drop to 67.7 F1 score. And then if you remove this part, it will drop a 4-point F 1 score. So, OK, we can actually use BERT for our reading comprehension. So you just have this input attention into BERT. And BERT can give you the hidden vector hi that can actually represent the hidden. vector that's corresponding to the context word ci. OK, so next, I'm going to talk about BERT, how to use the BERT model to solve this problem. yeah, I guess I'm just a little worried about who comes up with the test cases? Who determines what the right answer is? I mean, we will have more discussion of toxicity and bias coming up very soon, including actually Thursday's lecture as well as a later lecture, not specifically about QA though. OK. Next person is-- Thank you for the lecture. Yeah, my question is also related to the open domain question answering. So I was just wondering how much of the learning side of domain sort of generalization or domain alignment techniques can be combined with language level, like question answering? The key difference between the generative model and the extractive model is that for generative models, you can actually leverage more input passage together and do the generation. So for this model, there isn't any retrieval. So you can always find the answer from the question, right? So this model really has you relying on all the parameters you memorized, all the questions you've answered. And then generative Models are you're remembering the whole question and you try to retrieve the memory when you answer the question. The model is very large, like 11 billion parameters. So the parameters are basically trying to memorize a lot of information that has been.information. So by just taking this input, it has to just rely on the parameters to infer this answer. So it's actually very hard to-- yeah, it's a definite balance between memory and the generalization from it. All right, thanks. Do you want to call it a night or do you want one more question? Either way, yeah.

ROUGE-1: 9.69, ROUGE-2: 9.40, ROUGE-L: 9.17
BERTScore: 61.28

==============================================
==================== [41/100] ====================
Summary:
 homework two is out now. What the default projects will be, uh, for this class. Um, and you guys will get to pick whether or not you wanna do your own construction project or the default project. And those proposals will be due, um, very soon, er, in a little over a week. Are there any other questions that people have right now? Yeah. The assignments, [inaudible] are they limited to TensorFlow? asked the question if, if the assignment is limited toTensorFlow. I'm pretty sure that everything relies that you're using Tensor Flow. Last week we discussed value function approximation, particularly linear value function approximations. Today we're gonna start to talk about other forms of valuefunction approximation in particular, um, uh, using deep neural networks. We're mostly not gonna talk so much about enormous action spaces, but we are gonna think a lot about really large state spaces. And so, instead of having a table to represent our value functions, we were gonna use this generic function approximation where we have a W now, which are some parameters. Deep neural networks represent the Q function. linear value function is often really works very well if you're the right set of features. But there are all sorts of implications about whether or not we're even gonna be able to write down the true p- um, value function. So, one alternative that we didn't talk so much about last time is to use sort of a really, really rich function approximator class. The problem is, um, that the number of data points you need tends to scale with the dimension. Instead of having our full x input, we're just gonna take in- we're gonna direct different parts of the x input to different neurons which you can think of just different functions. We think that often, the brain is doing this. It's trying to pick up different sort of features. So, we want to sort of extract features that are relevant for deciding whether or not a face, for example, is a face or not. This means also that rather than computing this sort of variance in translation, you can do this all the way across the image. DQN, deep Q-learning addresses these is by experienced replay and fixed Q-targets. Experienced replay, prime number if you guys have heard about this, if you learned about DQN before is we're just gonna stroll data. So, even though we're treating the target as a scalar, the weights will get updated the next round which means our target value changes. So this is nice because basically it means that you reuse your data instead of just using each data point once, you can reuse it and that can be helpful. that it does is it has fixed Q targets. Um, so to improve stability, and what we mean by stability here is that we don't want our weights to explode and go to infinity which we saw could happen in linear value function. We're gonna fix the target weights that are used in the target calculation for multiple updates. So, instead of always update- taking whatever the most recent one is, we're just gonna fix it for awhile and that's basically like making this more stable. Replay is hugely important and it just gives us a much better way to use the data. Double DQN is kind of like double Q learning, which we covered very briefly at the end of a couple of classes ago. Greedy Policy is where we average networks, average reward networks, and then use one of the Qs as the target for the other network. Then we update Q2 with 50 percent probability, we pick the next action from the next network, this is a pretty small change. back to the Mars Rover example. So, let's say you get to choose two replay backups to do. Vote if you think it matters which ones you pick, in terms of the value function you get out. If you pick backup three, so what's backup three? It is, S2, A1, 0, S1. So that means now you're gonna get to backup and so now your V of S2 is gonna be equal to one. So you've got to back-propagate from the information you're already [NOISE] have on step one to step two.

ROUGE-1: 8.81, ROUGE-2: 8.28, ROUGE-L: 8.36
BERTScore: 66.94

==============================================
==================== [42/100] ====================
Summary:
 salt makes up a tiny part of any bread though which has a huge effect on it and most bread is made with salt nowadays. salt has a tightening effect on the gluten it strengthens the dough and makes it more cohesive as yeast consumes the sugars in the dough. salt helps with controlling fermentation it draws moisture through the cell walls of yeast in a process called osmosis. salt can help with preserving the color and flavor of flour unbleached flour has carotenoid pigments which give the crumb of our bread the creamy color and a wheaty aroma. it's rising more slowly whilst the one on the left is already collapsing. the one in the right is still pushing on. what did you think of this experiment did you learn something new let me know down in the comments see more videos like this one click right here that's all i have for you today thank you for watching i'll see you in the next one. i'll be back with a new video in a week or so. I'll let you know what it's about.

ROUGE-1: 16.29, ROUGE-2: 14.67, ROUGE-L: 14.40
BERTScore: 58.13

==============================================
==================== [43/100] ====================
Summary:
In this section, we're going to talk about the relativistic Doppler effect. We make good use of our space-time diagrams, which we discussed earlier. The question is how is this being observed by an observer which is moving with a relative velocity v with respect to the source? So we have to apply Lorentz transformation. And we find then-- this is a little bit of an algebra exercise here-- that the period now is given by 1 plus beta over 1 minus beta square root of that times tau.

ROUGE-1: 32.62, ROUGE-2: 31.29, ROUGE-L: 32.62
BERTScore: 72.64

==============================================
==================== [44/100] ====================
Summary:
Hollywood Legend Will Smith owns a team in the new E1 racing series that aims to prove the potential of electric power in the Marine industry. The nine teams have the same boat but they're working out how to push the tech and try to get ahead of the competition. The boats can reach 50 knots that's around 93 km per hour so how do they reach those speeds? The key bit here is getting up on the thin bits of the foil and staying above the water to have the speed that's right. attracted some big name investors despite only being in his first year. There are challenges ahead can it keep those celebrity backers and can it build a big audience for this high-tech reing. I think the ground workor for this Championship is amazing you know the names behind it now are incredible. I've heard some good rumors of teams coming in for next year as well so I Think the format is really exciting I think a lot of people are really interested in excited about the new technology and also the sustainability message.

ROUGE-1: 20.42, ROUGE-2: 19.60, ROUGE-L: 18.31
BERTScore: 60.69

==============================================
==================== [45/100] ====================
Summary:
Marginal rate of substitution of good 1 with respect to good 2 is infinity. When we are increasing the amount of 1 good to bring what will happen using this, if we use the monotonicity. What we are talking about is an indifference curve of a person who exhibit, whose preference exhibits convexity. To get 1 good you will have to give up the other good, both what we are assuming that both these items are good, means they give certain satisfaction or certain you know utility to the person. good 1, how much the other person is willing to give up, the another good, but we have to measure in terms of per unit of good 1. So, that is why in that case MRS is going to be, let us say in other word, let's see if we just do it mathematically, the original bundle is x y. Change is x plus delta x and y plus delta y, and what would be the slope, what we are certain about that.

ROUGE-1: 24.44, ROUGE-2: 23.62, ROUGE-L: 23.16
BERTScore: 63.36

==============================================
==================== [46/100] ====================
Summary:
in this video we're going to discuss what externalities are in economics. An externality is when you do something that affects the well-being or the good of another person or a company but you're neither harmed or rewarded for what you did to that person so the externalities can be positive they can be negative. A negative exTERNality is where you've harmed someone you've done something to somehow impose a cost on someone or some some company or something and you haven't reimbursed that person. where you have a negative externality like pollution or something like that it would be overs supplied relative to what is socially efficient or optimal. Where you have an over-supply of something like pollution, for example, you would have it over supplied in a way that would be socially efficient and optimal. For example, if you have pollution, it would have to be over supplied to avoid it becoming a problem. This would be a way to reduce the amount of pollution or other negative externalities in the environment.

ROUGE-1: 25.49, ROUGE-2: 19.77, ROUGE-L: 19.43
BERTScore: 65.17

==============================================
==================== [47/100] ====================
Summary:
Political philosophy is the oldest of the social sciences. It can boast a wealth of heavy hitters from Plato and Aristotle to Machiavelli, Hobbes, Hegel, Tocqueville, Nietzsche. The study of the great books or great thinkers of the past can easily degenerate into a kind of antiquarianism, into a sort of pedantry, says Professor Steven Smith. But these works provide us with the most basic questions that continue to guide our field, he says. "The ideas of John Maynard Keynes, both economists and political philosophers, when they are right, are more powerful than is commonly understood," says Smith. unnecessary or redundant. It would wither away. Political philosophy exists and only exists in that... call it "zone of indeterminacy" between the "is" and the "ought," between the actual and the ideal. This is why political philosophy is always and necessarily a potentially disturbing undertaking. Those who embark on the quest for knowledge of the best regime may not return the same people that they were before. But there is some compensation for this, I think. The study of political philosophy may be the highest tribute we pay to love.

ROUGE-1: 8.45, ROUGE-2: 7.64, ROUGE-L: 8.18
BERTScore: 62.38

==============================================
==================== [48/100] ====================
Summary:
Ahern: I have never had an exam where I had fewer questions. There were maybe 10 questions I got on the exam and that was for a class of this side. I find most students are honest. I've only had a handful of situations where in this class, where I've had dishonesty as an issue. The only students I've ever had with serious dishonesty issues actually were in smaller classes interestingly enough. But it has happened here and I do have taped evidence when it does happen. So that's why I do it. Ahern: I hope everybody got how I start my lecture. I don't live consciously, I just blurt it out. Thank you for your feedback. That's not a lot of feedback, but I do appreciate feedback and I'm always happy to listen to what you have to say about exam formats. And I do take suggestions. The suggestion about having other possible choices is one, as I said, I've done and I won't rule out. But other thoughts or feedback, I'm open to 'em, very much appreciate that. Ahern: Using genetic techniques today, it's very easy to alter the genetic code for any of these proteases and change which amino acid is presence at any given place. Researchers have changed, for example, a serine residue of 221, which is the serine, gives it its name, to an alanine. Or changing the histidine position 64 to anAlanine or changing aspartic acid at position 32 to analine. And when they do that, and they compare the activity, so this is the log of Kcat. So Kcat of course is a good measure of velocity and the wild type enzyme has an activity up here. Ahern: There are other types of proteases that behave very much like S1, well like serine proteases. One of these classes is known as cysteine proteased. Ahern: This class of protease is essentially identical to that of theserine protease, at least for our level of understanding. He says the aspartyl proteases, at first glance, look somewhat different. But those similarities aren't all the way through like we see with the cystine prote enzymes, he says. One of these is an enzyme we've been talking about some already, that's the carbonic anhydrase. Carbonic anHydrase can catalyze the conversion of a million molecules of substrate into product per second, per enzyme. The basic mechanisms are the same. We created a nucleophile, the nucleophile attacks the carbonyl group, the peptide bond breaks, and the pieces go their way. This business of creating nucleophiles is not unique to proteases. There are other enzymes that use nucleophile and generation of nucleophile in their catalytic mechanisms. Most enzymes have a fairly narrow pH range where they work that's ideal. Most of our body tissues are at a pH of 7 to 7.4. At pH 9, this enzyme is far more active than it is at pH 7, indicating that a very, very important step is the removal of that proton. The faster the nucleophile can form, the faster the enzyme is going to be. If the enzyme structure is stable at pH 10, the enzyme will be better at 10 than at 7. Because it's easier to make that nucleophile at 10.

ROUGE-1: 13.34, ROUGE-2: 12.57, ROUGE-L: 12.69
BERTScore: 61.12

==============================================
==================== [49/100] ====================
Summary:
AA and I are going to show you how to make vanilla extract so easy so yummy so good for all the things that you would use it for cakes whatever really really good isn't it. All you want for this is about 1 oz or roughly 30 G of vanilla beans so they'll be you know long Dobby whacker things and just cut them up into small pieces. Store this in a dry cool place and just as I said just shake once a day for at least a month preferably 2 to 3 months.

ROUGE-1: 32.65, ROUGE-2: 32.08, ROUGE-L: 30.61
BERTScore: 66.41

==============================================
==================== [50/100] ====================
Summary:
RAFAEL JARAMILLO: Let's talk about intermediate phases and line compounds. He recalls intermediate phase in a three-phase system. He draws a free-energy composition diagram in such a case. Jaramillo: All possible common tangents are going to converge at the same point. He says this type of structure is a Laves compound, which is also known as Laves Laves, or Laves' compound. It's a broad structure, he says, and it can be used to develop new materials. agencies around the world have developed in the last century. There are certain silicon-based bronzes that have been developed for that application. Silicon's not an intermediate phase, but it is a line compound. The solid silicon phase appears to have no equilibrium solubility of copper. Doping semiconductors is why we're able to talk to each other over Zoom. The fact that you can dope some metals into silicon is as important as it gets. It's not just an academic point. Without doping, there is no semiconductor devices. The transmitters and receivers of all modern telecommunication devices, including your phones, are based on what's called III-V semiconductors, such as gallium arsenide. Silicon carbide is a refractory-- some people will say it's a ceramic. Some people say no because it doesn't contain oxygen. It's used for grinding, so it's of enormous industrial importance. It also is an emerging semiconductor material for high-power electronics. In 50 years from now, if the idea of a power substation is a thing of the past, it will be due to silicon carbide. we have these composition variables. We're familiar with that. The equilibrium condition, the equilibrium condition dG equals 0 satisfied by common tangents. Now let's imagine two line compounds. B3A2 and B4A3. How did I come up with that? Well, I sketched an imaginary phase diagram, and then I had to follow through on my sketch. And the point is not the complicated thing. It's really, I have some two-phase region down here at low temperature. RAFAEL JARAMILLO: I want to introduce this and get this in your minds. Let's imagine reacting metal M with 1 mole of oxygen to form an oxide. So zM plus O2 gas reacting to form MzO2. What's z? How do I determine z? Anybody? Does anyone know some oxides? Name for me a common oxide that you know. And these oxides are line compounds. That z is not a variable. We're going to use this property of being line compounds in Wednesday's lecture.

ROUGE-1: 15.37, ROUGE-2: 13.73, ROUGE-L: 14.33
BERTScore: 60.39

==============================================
==================== [51/100] ====================
Summary:
A random variable can take different numerical values depending on the outcome of the experiment. Some of the possible numerical values of a random variable will be more likely than others. We will describe these relative likelihoods in terms of the so-called probability mass function, or PMF. The PMF is also sometimes called the probability law or the probability distribution of a discrete random variable. We use a subscript, X, to indicate which random variable we're talking about. And it has a probability. And in our case this probability is equal to 1/2.

ROUGE-1: 12.48, ROUGE-2: 12.10, ROUGE-L: 12.22
BERTScore: 72.99

==============================================
==================== [52/100] ====================
Summary:
Protein three-dimensional structure and its implications for the binding of small molecules such as drugs. How can we use these basic motifs to recognize other macromolecules, other proteins and nucleic acids? We have these motifs that we could find, weight matrices for them by aligning lots of sequences. Now instead of aligning sequences, let's see what we can do by mutating both the protein part and the nucleic acid part. And then we know from the three dimensional structure that it interacts mainly with the middle nucleotides. sequence that you're interested in is present. And what you do is quantitate the fluorescence of the zinc finger protein indirectly by the binding of the covalently-attached phage to the antibodies, which are fluorescently labeled by [INAUDIBLE] fluorescence. But how you relate that to the binding constant we had in the previous slide is the subject of this slide number eight. Now we call this the apparent equilibrium association constant because these experiments, just like many binding in living cells is not at equilibrium. groove of the DNA. And the reason the textbook is wrong, first of all, it emphasizes the non-helical part of the zinc finger. In contrast, the textbook where it does the sharp right hand turn and in some way poorly schematized there, it goes coaxial to DNA. That's not what happens. The helices are more or less direct extensions down from the dimerization region of the protein maintaining almost perpendicular to the DNA axis. But again, so on the left is the three tandem repeats, and on the right is a dyad axis. into two major classes. Class 1 is the single letter amino acid code [? CEL, ?] so forth, cysteine, glutamate, and so on. Class 2 is structurally dissimilar to Class 1, but they are similar within the class. You can arrange to make a new amino acid by carving the pocket the amino acid recognizes and grafting on the appropriate nucleotides. You have to have feedback, synchrony, so on that you can basically program the almost digital nucleic acid world inside the cell. not inside the cell. But the whole complex gets internalized. Still, topologically, it's as if it were outside the cell when it's inside this little vesicle. It has to get through that membrane. But now the pH change that happens when this vesicles goes in the cell, part of the natural cell biological processes causes some act. The seven-mer complex of proteins does yet another conformational change and turns into this hairy beast that allows the lethal factor to get into your cell and kill it. of six angstroms of difference between the predicted structure and what it actually is by the more precise methods up higher on this. As you get to 1 Angstrom or better in your accuracy, as you can get from NMR and X-ray crystallography, you now are in a position to study catalytic mechanism and design and improve ligands, such as drugs. There may be a day where we can do this all from ab initio prediction or modeling at very great distances. But for now, modeling atvery short, say, 80% to 90% amino acid similarity is important. letter is the new amino acids. So for example, D67N means a [? sparcade ?] at position 67 and wild type changes to an asparagine. And that causes a drug resistance in the HIV, with unfortunate consequences for the patient. We can take-- now, making mutations in polymerases is not entirely of negative consequences. And I'm going to show you a really beautiful example where a DNA polymerase, you want to change it so that it can now handle what would normally be an inhibitor. There are ways that you can program, and conditional, proteins. You can regulate under what conditions the protein is expressed or not or active or not with an entire domain, or with single nucleotide polymorphisms. Another way is by modulating the activity of the proteins from the outside with drugs or drug-like molecules and chemical kinetics. In the case of the zinc finger, we made an altered specificity. We made new zinc fingers with bind to completely new trinucleotides. With the DNA polymerase, by changing one amino acid, we could make it now accept almost four logs better. increases the risk of Alzheimer's, and probably increases cardiovascular fitness through ApoE refers to its involvement in cholesterol metabolism and transport. The ancestral form of this, for example, found in chimpanzees at nearly 100%, is this arginine 112, instead of what's now common in human populations was cysteine 112. One explanation for that might be that our nutritional standards have changed. We now eat a lot more fatty things. And so maybe this was something that was-- this bad allele, E4, was good in chimpanzees that have different diets or lifespans. The idea of chemical diversity, in a way I hope nicely connects to where we've been with RNA arrays. RNA arrays, and the double-stranded RNA array that we used earlier in class today, can be generated in a commentorial sense. Solid phase comes up again and again in arrays. It's very obvious why you have a solid phase. You want to be able to address it by its positions in x and y on the array. And it's a fantastic way of getting purification of your products simply by washing rather than doing complicated purification procedures. is kind of the big race or bake-off between the different methods. But unfortunately, over decades, it's still hovering around 77% for secondary structure and about 25% for ab initio three-dimensional structure. Then even if you have the three- dimensional structure at adequate accuracy, getting the ligand specificity is problematic. We'll pick up this thread right after a break and carry on to actually how we get the three dimensional structure, whether it's predictive or experimental, and the computational tasks.

ROUGE-1: 20.17, ROUGE-2: 19.61, ROUGE-L: 20.13
BERTScore: 57.71

==============================================
==================== [53/100] ====================
Summary:
More than half of large US firms plan to use AI within the next year to automate tasks that were previously done by staff in a bid to cut costs boost profits and make their work more productive. The New York Times reports that generative AI could automate activities equivalent to 300 million full-time jobs around the world. open ai's chief executive that's Sam mman says governments will need to assume the bulk of responsibility in supporting workers AI labor market disruptions and the question will employees just end up training AI systems only to them be replaced by them.

ROUGE-1: 4.92, ROUGE-2: 4.78, ROUGE-L: 4.92
BERTScore: 61.46

==============================================
==================== [54/100] ====================
Summary:
foreign I'm really excited especially for this lecture which is a very special lecture on robust and trustworthy deep learning by one of our sponsors of this amazing course themus AI. Themis AI is a startup actually locally based here in Cambridge our mission is to design advance and deploy the future of AI and trustworthy AI specifically. I'm especially excited about today's lecture because I co-founded Themis right here at MIT right here in this very building in fact this all stemmed from really the incredible scientific innovation and advances that we created right here. Sadhana is a machine learning scientist here at Themis Ai and the lead TA of the course this year. She'll be teaching us more about specifically the bias and the uncertainty Realms of AI algorithms. Sadhana: Over the past decade we've seen some tremendous growth in artificial intelligence across safety critical domains in the Spheres of autonomy and Robotics. But there's another question that we need to ask which is where are these models in real life a lot of these Technologies were innovated five ten years ago but you and I don't see them in our daily lives. We tend to over sample samples with darker skin color and therefore the model learns them better and tends to do better on them. We can use the above algorithmic bias mitigation method to try and solve these problems and more so we just went through how to mitigate some forms of bias in artificial intelligence and where these Solutions may be applied. We talked about a foundational algorithm that Themis uses that UL will also be developing today and for the next part of the lecture we'll focus on why uncertainty is important and how we can estimate it.

ROUGE-1: 6.40, ROUGE-2: 6.15, ROUGE-L: 6.25
BERTScore: 66.02

==============================================
==================== [55/100] ====================
Summary:
HONG LIU: So if you want to compute, say, some scattering amplitude from alpha to beta-- so alpha's some initial state and beta's some final state. Say alpha consists of momentum p1 and PN-- or pm, and beta, say momentum p m plus 1 and pn. And then you can get this scattering amplitude just by taking your momentum-space correlation function, OK, for the n points. So this is obtained by doing a Fourier transform. So any questions on this? Yes? AUDIENCE: So can you explain again why this diagram, like, you have one branch and then there's a loop? Klein-Gordon equation, if you interpret it as a wave equation, suffers some-- suffers from some difficulties. So Dirac proceeded trying to correct those difficulties, to overcome those difficulties. It turns out that the Dirac equation solved the first problem, OK, but didn't really solve the second problem. So nowadays, we interpret this this is the-- gives the field theory for-- OK, so of course, Dirac didn't know this, so essentially, he discovered this beautiful theory for the wrong motivation.  Dirac's idea of a Lorentz covariant equation was a "stroke of genius," he says. He says it would have to have a relativistic wave as its solution, and at least the wave should have a type of solution. But Dirac says it could also have a Hermitian solution, which would make it more general. Dirac: "There was nothing like this before. Just even from a mathematical point of view, it's purely, purely imaginative, OK?" frame, partial prime square-- OK, so this means in the prime coordinates-- minus m square and phi prime evaluated at the x prime, there must be a Lorentz frame. OK, trivially, you could do that just by definitions. So now we want to show that the Dirac equation has the same property, OK, and that is much more nontrivial. Again, it's really ingenious, ingenious, yeah, but we see, actually, it works.

ROUGE-1: 7.20, ROUGE-2: 6.38, ROUGE-L: 6.71
BERTScore: 64.97

==============================================
==================== [56/100] ====================
Summary:
The US Supreme Court is the highest federal court in the United States. The job is for life, barring resignation, retirement, or removal from the court by impeachment. So far, six justices have been foreign-born, at least one never graduated from high school, and another was only 32 years old when he joined the bench. Most presidents nominate individuals who broadly share their ideological view, so a president with a liberal ideology will tend to appoint liberals to the court. Most rejections have happened when the Senate majority has been a different political party than the president. A US Supreme Court justice is expected to be, in the words of Irving R. Kaufman, "a paragon of virtue, an intellectual Titan, and an administrative wizard" Of course, not every member of the Court turns out to be an exemplar of justice. Each leaves behind a legacy of decisions and opinions to be debated and dissected by the ultimate judges, time and history.have held the position, not one has yet been removed from office as a result of an impeachment. One of their roles is to protect the fundamental rights of all Americans.

ROUGE-1: 47.13, ROUGE-2: 45.04, ROUGE-L: 36.39
BERTScore: 61.99

==============================================
==================== [57/100] ====================
Summary:
Jake Xia: This is the second time we are having this class. The purpose of this course is really to give you a sampling menu to see how mathematics is applied in modern finance. We will be doing a bit more polling along the way, mainly to get feedback of how you feel about the class. And so hopefully, this will give you enough information to decide this is a field you would like to pursue in your future career. The class will be held every Tuesday and Thursday afternoon from 2:30 to 4:00. On his first day at Morgan Stanley he asked a question about volatility. His desk quant look at him, said-- this is supposed to be options trading desk, so he look at me puzzled. So instead of answering my question, he handed over a training manual for new employees and new analysts. He opened the training manual and looked it through. He actually found his answer. At Morgan Stanley this is not called vega, it's called kappa. So now, I remember to call it kappa, which is actually a Greek letter. I did that in the last 20 years. So the point I'm trying to tell you is, before you dive into any details of mathematics or any concept in finance in this class, just bear in mind, this is a field developed in. the last mostly 30 years, or even shorter. And what you really need to ask questions is-- it's not really is it right or wrong in mathematics, is it wrong in physics? So, how the concepts are established and defined and verified. After 1933 Glass-Steagall legislation, there were two main types of banks. Commercial bank is supposedly, you're taking deposits and lend out the money. Investment bank supposed to focus on the capital markets, raising capital, trading, and asset management. But obviously, after 1999, the Glass- Steagall was repealed. There's no longer that. Some people blame that, and probably for a very good reason, for the cause of 2008 financial crisis. But I want to tell you how currently investment banks are organized. Risk management, nowadays, becomes pretty widespread responsibility. It's not just the corporate treasury's responsibility. Even if you are not a finance guy, you work in a corporate, you just do you import, export, or building a factory, you have to know, actually, what the exposure is. Let's talk about market making. If it's a simple transparent product, everybody pretty much knows where the price is. But if it's not transparent, so what do you do? So, if instead of asking you where Apple is, probably you're going to tell me $495 today. that liquidity, and then takes the risk. They manage the book by balancing those Greeks, which I mentioned earlier. Gamma is really the change of the portfolio. Take the derivative to the delta, or to the underlying spot. Delta is the first order. So gamma, now you have curvature or convexity coming in. And theta is really-- nothing changes in the market. Nothing changes in your position. How your trading book is carrying or bleeding away money. And on top of that, what are the tail risks? What are the events that can actually get you into big trouble? So people use value at risk. There are many examples mathematical relationship which gives you the arbitrage opportunity. Fundamental analysis, you're really trying to understand what's going on in the world. And there are special situations. Some companies are going through particular difficulties, assets are priced very cheaply. So, math is very useful in risk management, which I will give you more-- which is very much a very interesting and challenging area. It's easy to observe a stock in the market, but when it comes to more complex products, they just take one step forward on the complexity, which is the option. Risk management is not a purely mathematical question, but yet, math plays a very important role to quantify how much exposure you have. Trading is really all about how do you risk manage, have the discipline, and how to manage your losses. A lot of people with math background, or in general, people are looking for the so-called holy grail trading strategies. The robotrader, a robotic trader, is a dream. It has its place or its use, but it's a fast evolving market. You have to constantly either upgrade your research and adjust your strategies. If your bank account balance is $800, your choice will be very different from someone has $100,000 in his bank account. Market cycles are typically very long, but people tend to have short memories. How do you really build models? Is the market really efficient? What part is efficient? How do we really apply those theories in our day-to-day risk management or trading activities? So learn the math, learn the finance first, but keep those questions along the way when you are learning. VasILY STRELA: [INAUDIBLE] mentioned that, Apple trades, that now it's $494.4 Yeah, just a couple of [inaUDIBLE]. Well, first of all, no offense to people who were [INAudIBLE], but I just wanted to give an example of [INA UDIBLE]. AUDIENCE: [inaudIBLE]. VASILY STREELA: --because he was working in our group, and it just will give you a little bit of an idea what we will be talking about. what we had, we had the noisy observation of broker data and it was coming out at different non-uniform times. So, we decided to use Kalman filter and to study how it can predict. And that's one of the nice graphs [INAUDIBLE] produced, which again, we will use this strategy and the Kalman filters which he constructed in our e-trading platform in Moscow. Just to remind, the website is fully functional. We will be posting a lot of materials there. Probably most lectures will be published there.

ROUGE-1: 22.28, ROUGE-2: 21.05, ROUGE-L: 20.49
BERTScore: 59.38

==============================================
==================== [58/100] ====================
Summary:
Climate change is changing us from the inside out in the UK one in four adults and one in 10 children experience mental illness and there's growing evidence that dealing with a changing climate is adding to that burden. In 2022 we had the hottest year on record where daytime temperatures soed over 40° for the first time in history the past hour or so we've had the UK Met Office issuing its first ever red warning for extreme heat after the 2022 heat wave. Charles and a team of researchers set out to study how the extreme heat affected people's well-being over half of the people they spoke to experienced negative impacts on their mental health. people use that as a way to cope with stress so this is very beneficial social connection is a really big one as well. We are not separate from our environment we are connected not just to the world around us but of course to one another and it and it is only in working with one another that we're going to be able to move forward [Music]"It's a very exciting time for us. We're looking forward to it," says singer-songwriter. "It's going to give us a lot of energy. It's a really exciting time"

ROUGE-1: 32.60, ROUGE-2: 29.33, ROUGE-L: 28.68
BERTScore: 65.42

==============================================
==================== [59/100] ====================
Summary:
Adam Martin: How do you go from something you're interested in learning about an organism to actually identifying genes and mechanisms that are important for that? Martin: The two heroes of today's lecture will be the roundworm, Caenorhabditis elegans, and the fruit fly, Drosophila melanogaster. He also highlights a couple important vertebrate-model organisms-- the zebrafish and the mouse. Martin: Most of them are fairly small, and they're easy to house large numbers of them in a lab. In a forward genetic screen, you're looking for a phenotype that you would expect if you affected a certain process, if you disrupt a process. The goal in genetics is to identify a mutation that alters a gene function that gives you a phenotype. In the way we can induce mutations is by using some type of mutagen. We could have some sort of chemical mutagen that increases the error rate in DNA replication, or we could use radiation to induce DNA damage, which accelerates the frequency of mutations. Drosophila larvae has segments that alternate between smooth cuticle and hairy cuticle. Because there's a lot of hairlike projections here, it reminded the researchers of a hedgehog, and so this mutant became known as "hedgehog" The hedgehog gene was the founding member of an entire signaling pathway that plays important roles in human development and also, human cancer. There are now a number of drugs that are being developed to target the hedgehog pathway, and one was approved back in 2012 for use in treating basal-cell carcinoma. Robert Horvitz's lab identified a pathway of genes that were involved in cell death. Researchers in the C. elegans field started isolating these cell-death-abnormal mutants. They then mutagenized these ced-1 mutants, and they are homozygous, meaning they are in this case, hermaphrodites. And so they're essentially looking for mutants in this animal that will affect the death process that will be present in the remainder of the generations. Adam Martin: circadian rhythm is a behavior. We are awake during certain parts of the day and are asleep at night. If you're hidden from the light-dark cycle, you continue this cycle for some amount of time. Martin: There's something intrinsic in our system such that we want to exist on this 24-hour wake-sleep cycle. He says the Nobel Prize-winning researchers identified a gene called "period" that is associated with familial advanced-phase syndrome, which is a sleep disorder.

ROUGE-1: 12.86, ROUGE-2: 11.57, ROUGE-L: 11.93
BERTScore: 59.78

==============================================
==================== [60/100] ====================
Summary:
In this chapter we will discuss two applications, one price control and second taxation, so right. Sir, does this slope of this graph denote anything price demand upon, some price upon some quantity? So, wait little later we will talk about that that topic, right now we are just talking about movement and shifts, the direction of movement. We are not talking about the slope. So, what is price control what do we mean by price control? Price control is how we can regulate the prices of the goods in the market. The farmers like people who are putting in more effort, but not getting the proper returns of their effort that is why. It is to incentivize the production for a few like for wheat or if we talk if there is a new production of potato and if we put price floor on potato. So, it will incentivize production and they can serve the market better. But even when we have proper distribution, why cannot government buy these the items that government needs to provide to poor at the market price and give it to poorest, just a point that you should ponder.

ROUGE-1: 11.61, ROUGE-2: 11.26, ROUGE-L: 11.49
BERTScore: 68.50

==============================================
==================== [61/100] ====================
Summary:
The size of the ribosome is similar to the size of a rhinovirus. There are many features in this part of the sequence that are very important for translation. Exonucleases might end up chewing up your transcript, but that probably suggests that the messenger RNA has been retired and it's going to retire to a better place. And this, once again, plays other functional roles with respect to being recognized as a transcript and helping to get out of the nucleus of the cell. The structure of a transfer RNA is folded up the way ribonucleic acids are. The 3 prime hydroxyl group of the last ribose within this ribosomal sequence is where the amino acid that's going to be loaded into your protein is attached. One of the loops has a special name. It's called the anticodon loop. It comprises three nucleotides that are complementary to the nucleotide in your messenger sequence. So there is specificity throughout that whole thing, and it's not just bystander stuffing. would be degraded. The missense mutations are the more serious ones because you end up with a full length protein that might have a mistake in it. Am I being clear enough to everyone? Yeah? Good. OK, I am going to tell you that I'm handing over the baton to my colleague, Professor Martin. He'll take over on Monday. And these will be the lectures that will occur. I think this field is fascinating. Once you get used to the mechanics of it, it's really cool to think of how you go from DNA to RNA to folded proteins.

ROUGE-1: 7.54, ROUGE-2: 7.04, ROUGE-L: 7.40
BERTScore: 57.20

==============================================
==================== [62/100] ====================
Summary:
Professor Donald Kagan: We are living in the early years of a polis sometime in the eighth century B.C. The date that's sort of typical for the general phenomenon of colonization coming out of the mother cities of Greece is 750 roughly. But in fact, the earliest date according to Greek tradition, if my memory is correct, was something like 773 where the Greeks date the foundation of what they thought was the earliest colony they ever established -- a place that they called Pithaecusa. Greeks were terrified of the sea for very good reason. The most widely cited reason is simply the desire to acquire farmland. The desire for commerce would have been also important. The Greeks would have had to be damn fools to have settled there without that being in their minds, although some of the places where they settled leave us puzzled, and have the ancients puzzled, too. It doesn't exist, Istanbul. Winston Churchill never conceded that it was Istanbul till the day he died. gotten the permission from your city to go forward, and you go to the Delphic Oracle. Next thing, you got to go home and you have to write up what amounts to a charter of foundation for the city. Recruiting is tremendously important because you need to have a certain number of settlers to make the settlement viable. So however many that is, that is what you try to recruit and you recruit typically at a time when it's easy to get people together so you can tell them the story. Syracuse is an independent polis, autonomous, self-governing, whatever regime it wants. It is not a subject of anybody, not Corinth or anybody else. The most typical, the usual, everything else is an exception is that there are friendly relations between the mother city and the apoikia. Corinth sent out a lot of colonies, which is why we know something about their arrangements. The first battle of the Peloponnesian War was a battle between Corinth and Syracuse. Kagan: The question is who gave permission for a colony to go in the mother city. The best guess and that's the only thing we have. These would have been aristocratic republics at this stage of the game. Corinth always needs that kind of stuff, so we sell you our wheat, you sell us your pottery, you selling good wine that we can't grow yet and maybe never will be able to grow in our neighborhood, so on and so forth. Everybody--all of this is voluntary on both sides of every agreement. coast of Asia Minor on the west, and even around on the bottom and to some degree on the north, and on the islands in the Aegean. So, there has been a Greek--what's the word I want? There is an expansion of the Greek world already by the tenth century, and these folks are now settled down. I might point out that the way the Greeks did their immigration into Asia Minor actually had a pattern so that you can go from north to south and you will find some consistency. as powerful as it used to be, far from it. It has been conquered by now by other peoples. In the sixth century, I think it's around--imagine around 550 or something like that, the Greeks settle a single colony in the Delta of the Nile of Egypt at a place called Naucratis. Going west, would you believe, when you get into what is now Libya, there was a very important Greek colony of Cyrene and that whole region was called Cyrenaica and it was a Greek. You can see Greek and Roman temples there to prove it. is seen to be a tremendously valuable safety valve to the Americans, first as colonists, and then as independent people. Americans didn't have the kind of terrible class warfare and the terrible warfare within cities that the Europeans had experienced throughout most of their history. I mean, fundamentally, Kansas is a colony in a certain Greek sense, all of these places are. So, that's part of the story of why America had the very lucky early history that it had. And that is the proper introduction to the next topic, which I'll discuss next year. No not--it seems like a year, but it's next Tuesday actually.

ROUGE-1: 13.83, ROUGE-2: 13.16, ROUGE-L: 13.35
BERTScore: 61.09

==============================================
==================== [63/100] ====================
Summary:
Instructor: We are asked, which of the following correctly identifies the areas of consumer surplus, producer surplus, tax revenue, and deadweight loss in this market after the tax? So pause this video, have a go at it. Even if you struggle with it it will make your brain more attuned to when we work through it together. All right, now let's work through this together. And I just want to sort of understand what's going on here before I even try to answer their questions.

ROUGE-1: 16.31, ROUGE-2: 16.15, ROUGE-L: 16.31
BERTScore: 70.34

==============================================
==================== [64/100] ====================
Summary:
Sir Gawain, nephew of King Arthur, was invited to a party at Camelot. A towering knight riding an emerald steed burst into the room and proposed a game. The Green Knight declared he would allow the bravest warrior present to attack him with his own axe. If they could strike him down, they would win his powerful weapon. However, the knight would be allowed to return that blow in one year and one day. Gawain tried to forget this bizarre vision, but despite the strangeness of the knight’s game, he was determined to act honorably.

ROUGE-1: 24.43, ROUGE-2: 21.68, ROUGE-L: 22.14
BERTScore: 69.18

==============================================
==================== [65/100] ====================
Summary:
well welcome back everybody to uh the last lecture 162. this is kind of a a special lecture um i did get some requests for more information about distributed storage and quantum computing and so i think we're going to do that. i want to make sure that we talk through the chord algorithm since that's a i think relatively simple thing to understand and is uh very cool and applied pretty much everywhere. At the very end of uh last lecture we were talking about key value stores and uh the cool thing about keyvalue stores is they're very simple in interface excuse me. clean way to distribute them throughout the system without having to know pretty much all of the nodes that are participating so this seems like a strong ask when you think about it if there's hundreds or thousands or millions of servers down here and we have to somehow um consistent with consistent hashing figure out which node to go to without going through a master directory and such that all these nodes don't know about each other. So this is basically going to be a mechanism to divide our space up and we'll talk you through that in the next slide and then i'm going to show you how the chord algorithm lets you get by with only knowing essentially a logarithmic number of nodes. will tell you that there are subsequent versions of cord which uh when you're doing this routing and you have a lot of options here see how we have many places we could go. One of the things we can do with chord is we can use chord to store locations of data rather than the data. We can actually take locality into effect to some extent in chord and um and make our routing less like bouncing back and forth across the planet randomly and more like working our way physically toward the thing that we're interested in. have a service guarantee that says we'll get a response within 300 milliseconds uh for say 99.9 percent of the requests okay and so that's part of the way that the chord algorithms are adapted in a read real cloud service. Security is kind of dealing with actions of a knowledgeable attacker who's really trying to cause harm and we want to make sure that they can't really screw us up. quantum computing as well so we can i know there was some of you asked some questions about that so i'm going to leave this topic unless there's more questions okay. about by using new techniques and the distinction between protection and security i think is an important one because protection is the set of mechanisms that we talk about in this class. Security is basically using those mechanisms to prevent misuse of resources so for instance virtual memory is a mechanism that can be used for protection security policy would be making sure that when we use virtual memory we don't let malicious processes or different processes owned by different people use the same memory and have a potential for screwing each other up. that a user who's making changes to the system is really who they claim to be data integrity is making sure that the data hasn't changed okay so that's important confidentiality is makingSure that theData is read only by authorized users so that often involves encryption of some sort. Non-repudiation is a surprisingly important thing that people don't often talk about which is that if one sender makes a statement and they uh send a message or whatever they can't later claim that well i didn't really send out somebody malicious did. hash function is one where you take data and you run it through a hash function and you get a bunch of bits out of it. If you change the data even slightly you end up with a good hash function with something that essentially roughly half of the bits change. What makes this secure is that it's not possible for somebody to come up with another source that matches the hash function. So we can use hashes to prove later that you know after the transmission has happened that the data is authentic. is a is a good one to be talking about um what we know is the following the metadata is uh among other things the public key of an owner hashed okay and so all of these signatures have to be signed by the owner and anybody can verify that um the data that's in here was put in there by the right owner okay so that gives us integrity and providence it means that we can know that none of the data in here could have been put there by an adversary so that's the first um thing that we know and the second thing is of course we can put arbitrary encryption on top of this as well to make it private. The vision here really is of pretty much everybody using data capsules everywhere okay and if you can get that to happen then you could potentially have a very interesting scenario here. We're working with roboticists and machine learning folks to put their data and their models for grasping and so on inside of data capsules and as a result they can reside securely in the edge in say your robots or whatever in a way that can't be breached. If any of you want to come work on this project come talk to me uh separately we have plenty of places we can talk to you. actually investigated if you were to build uh that factoring algorithm and you could do it as quantum circuits that could run on a quantum computer what would that look like. We actually investigated ways of optimizing that and we could actually look at performance of different options for the shortest factoring algorithms. So we built a cad tool to do that so i i don't know i think it's a pretty interesting area right now and there's a lot of interest in it all right so um sorry i kept you guys way over but this is the last lecture i figured if anybody was interested we talked about key value stores.

ROUGE-1: 12.02, ROUGE-2: 11.75, ROUGE-L: 11.55
BERTScore: 67.97

==============================================
==================== [66/100] ====================
Summary:
Early astrologists did not recognize the lymphatics so they thought there are only three system there is a branch of portal or this branch of puerto bean. Originally doctors thought that every corner these three things are present and they call it portal triad. But later on of course the new it is not portal Triad it is portal triads. The liver is really working is that right that blood is again there are two input system hepatic arterial input and what was this portal venous input. coming here what is this cystic duct and now all this together is called common bile duct it is coming behind the do denim of course come into pancreas. Common bile and pancreatic duct come together and open here in Tudor denim at the employ of weatr here pancreatic juices and bile will come down other right again the relationship right and left the Patek duck and - what is the common hepatic duct meeting with the sister making what isThis.

ROUGE-1: 25.21, ROUGE-2: 24.18, ROUGE-L: 25.06
BERTScore: 61.83

==============================================
==================== [67/100] ====================
Summary:
So in the next portion of today's lecture we're going to talk about how we can modify the policy gradient calculation to reduce its variance. In this way we'll obtain a version of the policy gradients that can be used as a practical reinforcement learning algorithm. The first trick that we'll start with is going to exploit a property that is always true in our universe which is causality causality says that the policy at time t prime can't affect the reward at another time step t if t is less than t prime. variance we just uh sorry we often don't use the optimal baseline we typically just use the expected reward but if you want the optimal baseline this is how you would get it all right so to review what we've covered so far we talked about the high variance of policy gradients algorithms. We talked about how we can lower that variance by exploiting the fact that present actions don't affect past rewards and we talked about how we can use baselines which are also unbiased.

ROUGE-1: 13.16, ROUGE-2: 12.75, ROUGE-L: 13.02
BERTScore: 68.71

==============================================
==================== [68/100] ====================
Summary:
Today we're gonna talk about learning in the setting of games. What does learning mean? How do we learn those evaluation functions that we talked about? And then, er, towards the end of the lecture, we wanna talk a little [NOISE] bit about variations of the game- the games we have talked about. So, uh, how about if you have- how about the cases where we have simultaneous games or non-zero-sum games? And an example of that is rock, paper, scissors. Can you still be optimal if you reveal your strategy? how learning is applied to these game settings. And specifically the way we are using learning for these game. settings is to just get a better sense of what this evaluation function should be from some data. And, and that kind of introduces to this, this, um, temporal difference learning which we're gonna discuss in a second. It's very similar to Q-learning. Uh, and then towards the end of the class, we will talk about simultaneous games and non-zero-sum games. can actually, like, roll two dice and based on the outcome of your dice, you move your pieces various, various amounts to, to various columns. Uh, there are a bunch of rules. So your goal is to get all your pieces off the board. But if you have only one piece and your opponent gets on top of you, they can push you to the bar and you have to start again. So, so what are some features that you think might be useful? Remember the learning lecture? Yes. So, so that was my model. And now, the question is where do I get data? Like where and because if I'm doing learning, I got to get data from somewhere. So, so one idea that we can use here is we can try to generate data based on our current policy pi agent or pi opponent. And then from these episodes, we want to learn. These episodes look like state action reward states and then they keep going until we get a full episode. One thing to notice here is, is the reward is going to be 0 throughout the episode until the very end of- end of the game. do these specific things that you would wanna do or these differentiating factors about it. So, so picking features, it's an art, right, so. [LAUGHTER] All right. So lemme, leMme move forward cause we have a bunch of things coming up. All right so, so this was just an example of TD learning but this is the update that you have kind of already seen. And then a lot of you have pointed out that this is, this is similar to Q-learning already, right? The idea of learning in games is old. People have been using it. In the case of Backgammon, um, this was around '90s when Tesauro came up with, with an algorithm to solve the game. And then more recently we have been looking at the game of Go. So in 2016, we had AlphaGo, uh, which was using a lot of expert knowledge in addition to ideas from a Monte Carlo tree search and then, in 2017, we have AlphaGo Zero, which wasn't using even expert knowledge. Minimax sca- strategy seemed to be pretty okay when it comes to solving these turn-based games. But not all games are turn- based, right? Like an example of it is rock-paper-scissors. You're all playing at the same time, everyone is playing simultaneously. The question is, how do we go about solving simultaneously, okay? So let's start with, um, a game that is a simplified version of rock- Paper-Scissors. This is called a two-finger Morra game. think minimax. So agent B should be min- minimizing this. agent A should be maximizing this. That's, that's what we wanna do. But with the challenge here is we are playing simultaneously, so we can't really use the minimax tree. So, so I'm going to limit myself to pure strategies. So right now I will just consider a setting- very limited setting and see what happens. So then player B is going first, player A is minimizing and then player a is maximizing. With probability p, like, if we're doing like ordering, like one of the two answers might- will come out, [inaudible] it'll be either one or two. So, uh, the thing is these two end up being equal. So no matter what your opponent does, like you're gonna get the best thing that you can do. So in expectation when- you're saying when you are choosing p? Yes, so I'm treating p as a variable that I'm deciding, right? The key idea here is revealing your optimal mixed strategy does not hurt you which is kind of a cool idea. The proof of that is interesting. If you're interested in looking at the notes, you can use linear programming here. So next 10 minutes, I want to spend a little bit of time talking about non-zero-sum games. In real life, you're kind of somewhere in between zero-sum and collaborative games. So, let's motivate that by this idea of Prisoner's dilemma.

ROUGE-1: 11.03, ROUGE-2: 10.70, ROUGE-L: 10.96
BERTScore: 68.96

==============================================
==================== [69/100] ====================
Summary:
The famous example was posed by Comte de Buffon back in the 18th century. It marks the beginning of a subject that is known as the subject of geometric probability. The problem is pretty simple. We take a needle that has a certain length-- l-- and we throw it at random on the plane. The needle might fall this way, so that it doesn't cross any line, or it might fall that way, and it ends up crossing one of the lines. If the needle is long enough, it might actually end up crossing two of the Lines. unit cube. So you throw points. Some fault inside. Some fall outside. You count the frequency with which the points happen to be inside your set. And as long as you're throwing the points uniformly over the cube, then the probability of your complicated set is going to be the volume of that set. You estimate the probability by counting the frequencies with which you get points in that set, and so, by using these observed frequencies, you can estimate the volume. It turns out that these days, physicists and many engineers use methods of this kind quite often and in many important applications.

ROUGE-1: 17.31, ROUGE-2: 16.56, ROUGE-L: 17.14
BERTScore: 68.13

==============================================
==================== [70/100] ====================
Summary:
Professor: We're describing interaction between the electromagnetic field and atoms. Professor: I want to show you what are the tools to treat those infinity source divergences in a consistent and a systematic way. "I can reproduce this result by going to infinite order in perturbation theory," he says. "Who of you have actually seen those kind of diagrammatic tricks and summation? A few, OK. So it's maybe nice to see it again. But for those who haven't seen it, welcome to the magic of diagrams" at the end of the class on Monday, I told you, well, let's simplify things. Let's get rid of those temporal integrations and multiple integrals by simply doing a Fourier transform. And so therefore, we introduced the Fourier. transform, or the Laplace transform, of the time evolution operator. And this iterative equation where we get the nth order by plugging the n minus first order on the right hand side, this turns now into a simpler algebraic. iterative equations for the Fouriers transform. Z is the energy. And it is the initial energy. If it's a ground state and a resonant photon, we have a problem. The other parts are simple. They don't have any divergences. They are not resonant and such. So what we want to do is now, in some way, give special treatment, factor out the problematic terms. And for the easy part, which has no divergence, we can make any kind of approximation we want. But the resonant part, this needs special attention. light scattering. I just go now and apply to an excited atomic state. So the state we are interested in is the atomic state b and no photons. And the property of the atomic. state is obtained when we know the function Gb of Z. And this is the matrix element between state B0B0 and the time. evolution operator. So we are calculating, of course, the Fourier transform of the time evolution of the state b by the. Fourier. transform through the resolvent G. The real part is this matrix element squared, but double sum. But what we use is the principle part of it, which is well defined in the theory of complex functions. So the imaginary part gets us Fermi's golden rule. And the real part has actually-- remember when we discussed the AC Stark shift. And such AC Stark shifts which appear as self energies, as energy shifts created by the state, this is nothing else than the famous Lamb shift. But remember, we worked so hard with diagrams to make sure that the triangle-- first the square, and then the triangle. we calculate here-- has no resonant structure at the energy Eb. So therefore, we can neglect the energy dependence of that and simply replace the argument E by the energy we are interested in, namely energies close to Eb. This replace, neglect E and set, or replace the dependence by E, by taking the value at Eb. And we obtained, as promised, the imaginary part, which we can approximate by Fermi's golden rule. If we now Fourier transform back and obtain the time evolution of this state, it no longer evolves with theenergy Eb. It has a shifted energy by this self energy. And this is called the radiative shift. But in addition, because of the imaginarypart, it has now an exponential decay.

ROUGE-1: 12.38, ROUGE-2: 12.01, ROUGE-L: 12.34
BERTScore: 63.50

==============================================
==================== [71/100] ====================
Summary:
Inflationary cosmology is a relatively new subfield that's known as cosmic inflation. It's a framework for trying to understand the evolution of our universe over a huge expanse of time. It uses tools at the interface, not just of Einstein's general theory of relativity, but also ideas about particle physics and high energy phenomena. The asterisks are to remind you there's a set of strictly optional lecture notes on the Canvas site which go into a little bit more detail of some of these parts from the lecture. Astronomers have been trying to explain the structure of the universe for 100 years. One of the tools, the conceptual ingredients, is some theory of gravity. This is the geometry of a warping spacetime, where you quantify things like gradients of space and time. And this is what he had to learn from his friend Marcel Grossmann to learn about the structure and behavior of space time and the universe as governed by Einstein's general theory of relativity. It's a reminder of the need to take this deceptively simple form and apply it to our everyday lives. Astronomers like Edwin Hubble in Southern California were able to collect information about the distribution of distant galaxies. Hubble found this remarkable trend that the further away from us a given galaxy was, the faster it tended to be moving away. Lemaitre was one of the first to start thinking about playing that filmstrip backwards to say if things are moving further apart from each other on average today, and if the universe in general is expanding today, then was it, in fact, smaller at earlier times? In the late 1940s, a trio of physicists began trying to fill in this picture, this primeval fireball picture. They realized that if the universe was very hot and dense at early times, then the conditions in which these elementary particles would find themselves should be quite different than what we find commonly around ourselves today. At early times in cosmic history, the universe should've been opaque. You literally wouldn't have been able to see anything because the mean free path of any given photon would be very, very short. 20 years later, two radial physicists working at Bell Labs, Robert Wilson and Arno Penzias, were using a new horn antenna sensitive to radial microwave and radial band frequencies. This should've been among the most precise instruments available on the planet for that band of the spectrum. And they couldn't get rid of a residual hum. This residual hum in your receiver consistent with an energy of about three degrees above zero, three degrees Kelvin, was really the leftover photons, that remnant hot radiation from the Big Bang. The idea was the whole universe is filled in the early times with very high energy particles that are at early, early times too high energy to form stable, electrically neutral atoms. And so from every part of space, from every single direction in the sky, those photons began to move freely at this single moment in time. And it's like sitting in a bathtub full of these photons. And they're just losing their energy as the overall size of space continues to grow. So the photons aren't coming from that direction of sky the way we think of with point-like sources. There's a galaxy there, a quasar, a particular bright star in our neighborhood. In the '20s and '30s, Edwin Hubble measured a much quicker average rate of expansion than what we have mostly settled on today. The picture was enough to get a small number of people to pay attention to Georges Lemaitre's otherwise quite obscure mathematical solutions. And it was only when paired with observations most famously from Hubble-- Hubble actually had a number of assistants, and other groups began contributing as well. So this is a, I think, safe to say, remarkably successful set of ideas that eventually becomes called the Big Bang model. These convenient coordinates. Then you have to be a little more clever to adopt your clock to make things, again, actually really simple. This is actually called conformal time. That might remind you of our beloved friends, the 19th century Cambridge Wranglers. At least my beloved friends. We looked briefly at the Wrangler stuff at these conformal mappings. We're really doing a Wrangler-ish thing here, very similar idea, to adopt coordinates for the time, for the rate at which we think clocks should tick. According to Einstein's equations, the shape of space could either have a positive geometry where it closes back on itself like the surface of a sphere, an open or negatively curved geometry, or a flat geometry. What controls which geometry you have is this ratio of the actual amount of stuff per volume, the actual density of matter and energy per volume. Robert Dicke introduced this conundrum in 1969, so soon after the discovery of the cosmic microwave background radiation when people began to take the Big Bang model more and more seriously. Alan Guth was studying high energy physics and therefore not gravitational cosmology. He liked Tony Zee, accidentally heard some talks about some of his early work in gravitation. He was not originally asking questions about the cosmos, but he was haphazardly encountering some of those questions. If there were a time during which the matter that's filling the universe could be temporarily stuck in a metastable state in which it had some non-zero potential energy, that could have implications for the global shape of space and not just for the behavior of elementary particles. we thought there was an origin to all of time, this Big Bang surface, at tau equals 0. And if you add up the time between tau and when those photons begin to travel freely, there was only a fixed horizon distance. It was much smaller than the smoothness scale that we could measure empirically. Well, if inflation happened, there should've been a very brief period before what had previously been called the Big Bang. So now the horizon distance is larger because there was more time that we hadn't yet taken into account. why the universe is so messy is actually because Alan's been generating the mess in his own office, and it's expanded to cosmic scales. So if you want to study that part of today's lecture, it's probably the most important lesson, you'll ever take away. And I'll be glad to stay a bit longer if people have questions. Again, I'm sorry for running late. Feel free to drop off if you need. Any questions on that? The photos in Alan's office are on Canvas.

ROUGE-1: 14.57, ROUGE-2: 13.84, ROUGE-L: 13.44
BERTScore: 59.46

==============================================
==================== [72/100] ====================
Summary:
The Peloponnesian War was fought in 431 BC. After the war, Spartan power had grown to an unprecedented degree. For the first time there were lots of Spartans, who had lots of money. The Spartans had choices that they could take. They could either stay in the Pelop onnesus, or they could contest it in their power to control the entire Greek world in the east. Or they could have some control of the Aegean and the Hellespont. Spanish Armada was heading for England trying to gain control of the island for the Pope and Catholicism and one thing and another. A great wind came up and it blew the ships out of their path and wrecked many of them. So, from that day forward there sprang up the legend in England of the Protestant Wind, which had come along to save the new English faith against the forces of the Pope. Well, if they can invent a Protestant Wind I think it's okay for me to speak about the democratic snow that fell on Phyle. Lysander wanted to send a big army to restore the oligarchs to put his own people back in power. Sparta wanted to deprive Lysander of his power and influence and restore a more normal situation in Sparta. The Spartans did vote to send an army in there to deal with Thrasybulus, but they did not put Lysander at the head of the army or even one of his people. Instead King Pausanias was sent out to do the job. They worked out an agreement whereby a moderate group of ten would be chosen in Athens. A Roman historian of the first century B.C. wrote the following about Thrasybulus: "If excellence were to be weighed by itself, apart from luck, I believe I would rank this man first of all" A few years before 180 A.D., Pausanias the great travel writer of antiquity, wrote his guide to the famous and historic places of ancient Greece. "His is the first grave and after it comes that of Pericles," he says, "in every way the greatest of all famous Athenians"

ROUGE-1: 7.10, ROUGE-2: 6.46, ROUGE-L: 6.70
BERTScore: 55.06

==============================================
==================== [73/100] ====================
Summary:
The coherent state has a simple definition, simple but subtle. It's an eigenstate of the annihilation operator, and it has a complex eigenvalue alpha. The person who popularized those states was Glauber, and he got amply rewarded for that. We are now using the coherent states to look at any other quantum state of the electromagnetic field, any statistical operator which describes photons by forming the diagram matrix element of the statistical operator with alpha. And now we realize that coherent states are not as wonderful as I believe. which is less fuzzy than the coherent state. So this fuzziness here is the intrinsic uncertainty of quantum physics. But then we will immediately start with non-classical states. And that is, well, if this area is determined by Heisenberg's uncertainty relation, what can be maybe deform the circle into an ellipse, and these are three states of light. That's what you're going to do in the second half of the class. But before I do that, I want to be a little bit more accurate about quasi-probabilities. Vladan Vuletan: Coherent states, as I've just shown you, are very classical. They've always a g2 function of 1. And attenuation is not changing it. So a coherent state with an expectation value of 1 photon is not a single photon. But of course, there are ways how you can get single photons. And this is, well, you start with single atoms. Namely, if you have a single atom in the excited state, it can emit only one photon. So that's a way how we can create non-classical states of light. The Hanbury Brown Twiss experiment was the first experiment which really looked at g2 functions correlations. It was the beginning of quantum optics and modern experiments with light. The classical limit is always a limit of high intensity, so at any given time, you have a ton of photons. If you put a light bulb into a cavity or couple the light from a light bulbs into a fiber, the light becomes spatially a single mode. That's the only way how you can distinguish a lightbulb from a laser beam. The way we can distinguish from a thermal state and a coherent state is through the g2. Colin says there are actually more different light sources that just the laser and the thermal light source. There are LEDs or semiconductor devices, which provide photons with interesting statistical properties. OK. We have to stop. Colin. I'll see you on Wednesday. Back to the page you came from."Could we do most of experiments if we just had thermal sources that were very single mode, so to speak?"

ROUGE-1: 8.61, ROUGE-2: 8.15, ROUGE-L: 7.96
BERTScore: 62.90

==============================================
==================== [74/100] ====================
Summary:
This lesson will first dive into some signal Theory and then move on into things that we're more familiar with things like deconvolutions and using Transformers for next note prediction. The first thing we want to talk about is how can we sample and quantize a continuous time signal. We then go into some geometric signal Theory with Transformers and finally how how we can kind of generate sounds using these. The next thing we're going to kind oftalk about is changing forms. We'll talk about the SARS ADC algorithm and how it's used to convert digital signals to analog. is less than double of the highest frequency present aliasing will happen. This asserts that you need at least two samples per period. aliasing is the byproduct of poor sampling. A lower wave resolution will result in a modified output signal as compared to the original input that we're trying to process. There's a lot of literature about um aliasing effects including spatial illnessing. The aliasing phenomenon is incredibly interesting this happens both visually and auditorily. It's a very prevalent problem in any problem. that can tie in to reconstructing signals right um we we are also going to talk about um using deconvolutions. We talked about the unit architecture very thoroughly used for image segmentation we talked about it in our survey of uh computer vision techniques. This is something that uh that is kind of going to come back in terms of how we can reconstruct signals so the inner product and projections are an application of inner products where one vector can be projected onto another Vector and you can you can kind of see what the projection is based on. is that as our our basis differs as long as these are orthogonal vectors and they span the complete basis of a certain Vector we're able to reconstruct this Vector. The idea behind the the last two sections here was to give you motivation for for how signals work and how kind of classical reconstruction can occur using math that we're all familiar with. The next step here we want to use deep learning for reconstruction right where we are are reconstructing a low quality audio to high resolution audio. are the original Pachelbel's Canon um as you can see this does deviate a bit but honestly it sounds pretty good. The Transformer model is able to do this next note next sequence prediction pretty pretty well. So yeah there's a a lot to do in this field um a lot of really cool things happening um and yeah I hope you guys learned something about uh about generative audio today and are inspired to kind of give some of these things a try yourself. thank you guys for tuning in have a good one.

ROUGE-1: 11.54, ROUGE-2: 10.70, ROUGE-L: 10.94
BERTScore: 64.32

==============================================
==================== [75/100] ====================
Summary:
Professor: The amygdala is closely connected to the basal forebrain. Professor: The abnormal brain connections that we know occur, at least many types of schizophrenia. He says the earlier the lesion, the greater the plasticity, the more chances of sprouting the connections that are the basis for this idea. In green, there are the very widespread catechol-oligosynaptic projections, which show the extent of the brain's plasticity. In blue, the acetylcholine containing neurons that you see in the medial septum, which we mentioned last time. Early in evolution, there was no dorsal striatum. It was a link between the olfactory, [INAUDIBLE],, and motor control. And we also know the outputs of that region go to hypothalamus and subthalamus. They influence the endocrine system and motivational states by these projections. They also have some connections in the midbrain, where they can influence the stacking patterns, especially locomotion. If the prefrontal cortex is functioning abnormally because of sprouting of these axons, then binding to the receptors will move it more towards the normal.

ROUGE-1: 6.15, ROUGE-2: 5.24, ROUGE-L: 4.98
BERTScore: 57.96

==============================================
==================== [76/100] ====================
Summary:
Learn how the solar cell device converts sunlight, the input energy, to some usable output energy, which is in the form of electricity, typically, from a solar panel. Learn how to minimize the amount of light reflected or not absorbed into maximizing amount of life that's actually absorbed. Learn about the duality of light, or how to think about light as a particle, or alternatively, as a quantified particle. Use the weekly Newsquiz to test your knowledge of stories you saw on MIT OpenCourseWare. Invisible light is interacting with a very specific type of electron inside of our system. When we start looking at the wavelength dependence of absorption inside of a material, you can have, for example, in the visible range, a decreasing depth of penetration of the light with increasing energy. With x-rays, it's the exact opposite. It's because you're dealing with different types of electrons and the material. And we use that information to calculate engineering relevant parameters such as reflectance of light off of a surface. If I add a coating, for instance, to a window that increases the reflectivity, then the amount of light that is able to escape from the inside to my eyes decreases. With normal incident light, there is a beautiful symmetry involved. So just the same way that I'm losing the ability to see inside, the folks inside are also losing the able to see out. So it's important to think about these processes, both in terms of their reflectance as a percentage and the magnitudes of the light involved. very simple yet very powerful formulation that describes not only the interaction of light with the solar cell material but also light through the atmosphere, light the water, many other forms of optical absorption. And for that, I'd like to call Joe up for a quick demo that will allow us to actually plot out Beer-Lambert's Law. What we're going to be doing is taking many sheets of material. This is just some polyethylene material, a little bit discolored. And we'll be inserting these panes of plastic in the middle. And as we increase the thickness of the plastic, applying good pressure in between to minimize the reflectance. another factor of 2. Why not? There's kind of this sense that it should be exponential. What don't we add some more filter in front, and we'll see what exactly this comes out to be. OK, so we notice that we have some exponential character to be decay of the intensity of the transmitted light through a medium. And the amount that's absorbed is following another trend, which is just 1 minus that. So it's the amount of light that'sabsorbed is following a curve looks something like that. by some sort of scattering intensity within the medium-- and this sigma here can refer to a variety of processes. If we increase the total thickness, we're going to decrease the total amount of light coming through via that exponential function. The alpha, obviously, is going to be very different for our atmosphere than it was for these little polyethylene sheets. Because the nature of the scattering and absorption processes are very different. for the atmosphere than for here, the density of the material and so forth. We're going to look at two different materials, silicon and gallium arsenide. We'll calculate the thickness necessary to absorb 90% of the incoming light at 550 nanometers. Most of these solar cells that you see of crystalline silicon are on the order of 100 microns, a little thicker. But for technological reasons, which we'll get to, you need about that thickness to absorb a lot of light. And I'll pass around some of the materials right here so you can get a sense of how thick they are. 10% of the light that didn't make it, that's going to get reflected back. So if you absorb 90% of. the light on the first pass, you'll absorb 99% on two bounces, right? Or in one bounce, rather, and two trips, two optical path links through the material. So methods to improve optical absorption- generally, these are called light trapping. We also call them light management as a more general term that includes reflection and absorption inside of the. material. Most often, depending on the angle, you have what is called total internal reflection. The record efficiency solar cell that was announced this past year in gallium arsenide was achieved because of good light management. To engineer front and back surface reflectances, you really have to carefully select your refractive indices and your materials if you put on either side. If we go to a refractive index material of minus 1.3, will we change the reflectivity at all? It depends, but the answers here are shown, for this particular system. The absorber is the material, our photovoltaic material, the ones absorbing the sunlight and ultimately going to be generating the charge. So we want to ensure good light trapping inside it. There are fancier ways of light management as well that don't involve light trapping necessarily but light manipulation or even semiconductor manipulation. If we can eliminate the longer wavelength stuff out here, which is heat, performance of most solar cell suffers when they get hot. And so if we manage to do spectral up converting or reflect that long wavelength light away from our device, we can improve performance. surface of a material, let's say right here, then you can cause each node, each point within your material, to lag by an increasing amount, so that your wave front now bends. And that will cause the light, essentially, if you trace through the points of maximum intensity, say the pink, you'll see that the light is bent. And so it's really exciting. There's stuff coming up every day on light trapping and light management. Mostly it's for photonic devices. But they can be transferred over into solar cells as well.

ROUGE-1: 14.78, ROUGE-2: 13.95, ROUGE-L: 14.30
BERTScore: 61.30

==============================================
==================== [77/100] ====================
Summary:
Professor Steven Smith: I want to look at two sets of issues. One is Locke's theory of the constitutional state, particularly focusing on the role of the executive, vis-a-vis the legislative branch of government. The other is thinking about Locke and the American regime and the current state of political philosophy, modern contemporary American political philosophy. Smith: Locke doesn't endorse necessarily one particular form of government from any other. He is an advocate of what we have come to call limited government, of constitutional government. The many faces of modernity are working themselves out. We are but a moment in the kind of comprehensive self-dissatisfaction that is modernity. A return to Lockeanism, in many ways, is not so much a cure for the pathologies ofmodernity. I would suggest that those pathologies are themselves already rooted in the pathologically of Locke. I will end on that sober note and encourage you to take Rousseau's advice about loving one's country seriously on Tuesday.

ROUGE-1: 5.69, ROUGE-2: 5.42, ROUGE-L: 5.52
BERTScore: 65.39

==============================================
==================== [78/100] ====================
Summary:
JACK HARE: Let's do a little recap on electron cyclotron emission. We expect to have multiple different peaks, even from a single particle. These peaks are going to be occurring at frequencies. And we can say this is m equals 1, m equals 2,. m equals 3. And they're evenly spaced. And so, we have these peaks here. But if we neglect that, the frequency depends only on the magnetic field. So, if you see some emission at some certain frequency, then you know that it's been emitted by a region of plasma which has this magnetic fields. what we want to do is measure very small temperature fluctuations. We want to measure temperature fluctuations within the plasma that are maybe on the order of 1% of the baseline temperature. And that 1% is actually extremely hard to measure. And this is because the noise is just too high on these systems. But there are some clever tricks that we play where we use correlations. And I'll talk now about what exactly these correlations are and how they provide us with information that allows us to get a signal out. The idea here is that there was some region over which, in the transverse direction perpendicular to your collection volume, you have a very narrow scale. You can actually collect from a very small region on the order of 100 microns. And if it collimated that beam, that would mean there'd be a focus point at some distance f away-- if this lens has a focal length f, then it will diverge afterwards. So, because of reciprocity, that means that, as opposed to launching rays this way and seeing where they focus, we have rays coming from this. The technique is incredibly powerful because it's enabled people to measure, again, delta on the order of 1%. Someone called it nominative determinism, and they've done it on 1%. And it's used in a variety of applications, but this is an example of what these angle brackets are doing. There are actually lots of different ways of doing this, but there are a few different ways to do correlations, and I'm not going to go into them, but I will give you a citation at the moment. Bremsstrahlung is a term used to describe a type of radiation in a nuclear reactor. It involves electrons being deflected and breaking and emitting photons. There are lots of different ways of doing this, and Hutchinson lists a few of them. What's remarkable about all of these approaches is they all give the same answer with a very slightly different coefficient. But, in some sense, although it's important to get the exact coefficient, it doesn't matter exactly which one of these techniques you use. from the point of view of this course, it makes no difference. Yeah, I think it's kind of remarkable that it doesn't make any difference. So, again, if you want the full treatment, go have a look in Hutchinson. And there's also a long treatment in Jackson of this same problem. I'm just going to quote some results. I kind of already spoiled it now. It's here. For the Maxwellian average, because we can have all sorts of different distribution functions, but our plasma tends towards a Maxwellian. The bremsstrahlung is the irreducible minimum amount of emission from your plasma. Cyclotron emission is a very specific frequency. This is everywhere inside your plasma at all frequencies, like a black body kind of spectrum here. We're going to talk about lots of other effects which produce emissivity which is higher than the bremstrahLung. And that is all you need to do Problem Set 3. Any questions about this? Yeah. And then there will be differences in speed of propagation and things like that. Jack Hare: I don't know if people are using it as a diagnostic. I've not heard of someone using it. But synchrotron light is used as a source of X-rays for diagnosing many other things. So it's interesting in its own right. But I'm not interested in [INAUDIBLE] This is a diagnostics course. JACK HARE: Any questions online while we pause? We're going to do free-bound radiation or recombination radiation. where we have a range of different discrete energy levels that the electrons can occupy. These energy levels are labeled by the principal quantum number n. And the energies of these levels are given by this unit, Ry, which is the Rydberg z squared of our ion over n squared. Up here, infinity, this is ionization. If your electron gets this much energy, it becomes free again. And so, what we're going to see in our spectrum is that this is only allowed if the electron energy fulfills this equation. JACK HARE: We'll go into some ways of actually making some use out of all this stuff in a moment. One use of this is a diagnostic called bolometry. It cares not at all about the detailed spectrum of what the emission is. It just wants to know how much power is being radiated by the plasma. And so, we can say, OK, well, that part of the plasma is clearly radiating too much. What can we do about it? That's what bolometry is trying to measure. have a thick block some distance in front of it so it can't see the plasma. It's the heat transport kappa grad T that gives us the time constant for thermal conduction through the substrate from the absorber to the resistor. The larger tau is the slower our measurement of the radiated power is going to be. And if tau gets very large, because we've got a very thick substrate here, or it doesn't have very good heat transport, then we're going to have a very poor time resolution.

ROUGE-1: 16.19, ROUGE-2: 15.41, ROUGE-L: 15.02
BERTScore: 66.31

==============================================
==================== [79/100] ====================
Summary:
So, last time we were starting to talk about the sort of the general overview of what reinforcement learning involves. We introduced the notion [NOISE] of a model, a value, and a policy. Can anybody remember off the top of their head what a model was in the context of reinforcement learning? So what we're gonna do today is, sort of, um, build up for Markov Processes, up to Markov Decision Processes. And this build, I think, is sort of a nice one because it allows one to think about what happens in the cases where you might not have control over the world. The question was was if it's possible to have self-loops? Um, could it be that this is sort of circulator defined [NOISE] in this case. Is it ever actually possible for, uh, that matrix not to have an inverse or does like the property that like column sum to one or something make it not possible? It's a good question. I think it's basically never possible for this not to has an inverse. I'm trying to think whether or not that can be violated in some cases. Markov Decision Processes are the same as the Markov Reward Process except for now we have actions. So, the agent is in a state they take an action, they get immediate reward, and then they transition to the next state. The advantage of this is that each of the iteration updates are cheaper and they'd also will be some benefits later when we start to think about actions. Now, if we think about our Mars Rover MDP, let's just define there being two actions being A1 and A2. before we do this let's think about how many policies there might be. So there are seven discrete states. In this case it's the locations that the robot. There are two actions. I won't call them left and right, I'm just going to call them a_1 and a_2. Then the question is how many deterministic policies are there and is the optimal policy for MDP always unique? So kind of right we just take like one minute or say one or two minutes feel free to talk to a neighbor.

ROUGE-1: 5.40, ROUGE-2: 5.22, ROUGE-L: 5.11
BERTScore: 64.82

==============================================
==================== [80/100] ====================
Summary:
Professor: angular momentum is a set of operators that provide observables, things we can measure. He says they're particularly important for systems in which you have central potentials. Professor: If you have two energy for every system except for every energy except for 0, you have a problem. You know the problem, if you can uniquely characterize the states of the system, then you can learn more about the physics of this state, he says, and you can also know more about physics of a circle.

ROUGE-1: 7.95, ROUGE-2: 5.53, ROUGE-L: 6.20
BERTScore: 59.10

==============================================
==================== [81/100] ====================
Summary:
In order to do that, I basically have to do the integral. So here it is. We have psi of x and t. It's integral dk phi of k e to the ikx minus omega of kt. If you want to see the distortion, you have to keep that [INAUDIBLE]. We'll do that in a week from now. And then, you say, look. There's lots of things making it look like a difficult integral, but it's not as difficult as it looks.

ROUGE-1: 15.65, ROUGE-2: 15.13, ROUGE-L: 15.65
BERTScore: 62.97

==============================================
==================== [82/100] ====================
Summary:
There are three common uses of a rotation matrix. The first is to represent an orientation. The second is to change the frame of reference of a vector. And the third is to rotate a vector or frame. To demonstrate these, I will use these three coordinate frames, representing the same space with different orientations. To help you visualize these frames in 3 dimensions, I'll use my handy tinkertoy frame. In the next video, we will learn how to represent the angular velocity of a frame.

ROUGE-1: 23.67, ROUGE-2: 23.19, ROUGE-L: 23.67
BERTScore: 67.50

==============================================
==================== [83/100] ====================
Summary:
Coded imaging is a co-design between how you capture the image and how you process the image. The concept of a position or superposition applies to all three types, shadows- or refraction- or reflection-based techniques. We'll see how-- we already have some projects that are inspired by biological vision. And we'll see it in a taxi zipping very fast, which is a clever way to take a photo. And I believe Santiago-- where's Santiago? Oh, yeah, his triangle-- the piston. The problem is that when you use a box function to take a photo, some of the lower frequencies are actually being set to 0. The culprit here is really this box function, which is equivalent to-- when you release the shutter, opening the-- release your shutter button-- opening the shutter and keeping it open for exposure duration and closing it. So what if you change that? What if you open and close it in a carefully chosen binary sequence? So for some time, the shutter was open, then shutter's closed. It's open for sometime. Again, it's closed, open for quite some time. And so on. So at the end, you still get just one photo. But now something magical has happened because first of all, if you look at this number one, you'll see that it's not the same as before. It seems to have these replicas. Lenses are very carefully designed by camera makers to be the same plane where you put your aperture. When you change your f-stop and decrease it and increase it, it's all happening in the center of projection. When it's in focus, it doesn't really matter what the code is, so the photo will be half a square, so you're talking about the light, so half a light, right? And that's why you have some dust on your lens and so on, unless you have the lens on your front. that, or just a software. There are methods you can employ. You need to find this 7-by-7 pattern or even the previous case, the 52 pattern. Take a Fourier transform to see if it's flat. If it's not flat, you go to the next one. So 2 the 52 is pretty challenging. But even if you use a cluster, it's still a pretty big number. So you can start with some code and do a gradient descent and so on. In astronomy, you have circular convolution because they use either a mirror or one mirror. If you put two tiles, you'll get really horrible frequency response. So if you're tiling that up-- RAMESH RASKAR: It's impressive, that's saying [INAUDIBLE] It's not a brute-force search. It was an intelligent search. We came up with our own code called RAT code, R-A-T, which is after three quarters. It's a very clean and beautiful and smoother course work. The effect is very low, though, remember. So maybe you have a pixel and get blurred by 10 pixels or [INAUDIBLE]. It's not a global effect. So this picture, maybe-- this particular diagram is misleading because it seems like this point is going to go all the way. But this is very narrow. And the blur is only about 10 pixels, no matter where you [INAudIBLE]. So maybe that was the matter. Doug's question is, what's the benefit of this? Ramesh Raskar: Compressed sensing is taking a photo and compressing it. He says the idea is to take a single photo and then recover it in a compressed way. Rasksar: If you're on 2 megapixels, then you need to take 2 million [? pics] All right? So the claim this group made at Rice University was that if I wanted a million-pixel image, I don't have to really take a million readings, he says. Rasa: I can take this picture effectively with just 10,000 pixels but recreate a million pixel image.

ROUGE-1: 9.38, ROUGE-2: 8.70, ROUGE-L: 8.30
BERTScore: 65.15

==============================================
==================== [84/100] ====================
Summary:
Prof: You know why I am dressed up? When I do this course and when I do the first half of the French course I do a lecture on the bourgeoisie, the middle classes. Middle class was a form of self-identity that was constructed in the way being a worker was constructed, or being a noble. When you look at me dressed like this, please try to think, knowing me a little bit as you do, why it was that it meant a lot to dress like this in the nineteenth century. In the nineteenth century one of the things that happens with the French Revolution and with Napoleon is that the middle-class values seem to be something to be emulated. In using and indeed insisting on the term "middle classes," what I'm suggesting is the enormous complexity of the middle class. There wasn't just one middle class, yet the middle classes shared some cultural values and symbols in common and when challenged by ordinary people could snap back in an extremely cohesive class-based manner. The word "bourgeois" has really more cultural connotations, maybe, than objective or social categorization. The French Revolution, and here's an important point, I guess, opened the way by removing legal blocks in very many places to the career open to talents. The bourgeoisie did anything but that. Work was part of how they believed to get ahead, and getting ahead is what they wanted to do. Of course, it was always in the nineteenth century sort of classic to poke fun at bourgeois culture, and in some cases the lack of it. But there's been an awful lot of good work done on the middle classes. class lived without passion, and were philistines, and that sort of thing. The middle class formed voluntary associations, and many of these were for extremely charitable purposes, particularly in Britain. The Society for the Protection of Cruelty to Animals, these sorts of organizations really are one of the classic examples of bourgeois voluntary associations doing good things. They also get together to hang out with each other and sort of try to gauge who has more money than the other, and they get together for social reasons in the coffeehouses of England. In France after the Paris Commune of 1871 they start building churches in the working class districts perched on the edge of cities. Religion for the middle classes has a greater role in their lives than in working class cities. The old Hanseatic port cities of German, the German free cities that would become part of unified Germany in 1871--northern German cities in general, like Bremen, and Lübeck, and Hamburg above all. Barcelona is a really natural economy based on important economic relations between its hinterland and the world. times, as you know, in the French Revolution--;the French revolutions, and in the revolutions of 1848. These folks are here, too. This is your basic petty bourgeoisie. People are always dumping all over them needlessly. If you've ever read the great French novelist--;he was paid by the word, but Balzac is really the novelist of the bourgeoisie. When he describes Paris and the seventeen to nineteen percent of the population who are increasingly living in the western part of Paris, he describes it as a jungle. The notion of childhood, childhood didn't exist for ordinary people. Nobles did not send their children to public schools or even to private schools. The idea of a children's room, of having your own room or a room shared with a sibling, was something that was just inconceivable for the majority of Europeans. The middle class wants to be seen rather like the Dutch in the seventeenth century. They wait in line to go to theatres. This is all Daumauau, the piece that you're obliged to swallow after dinner. In the last one minute thirty-five seconds that remains to me, the bourgeoisie, the middle classes, want the right to bear arms. They want to be in the national guard. The national guard might hypothetically be there in case there was an invasion of France or Germany by, I don't know, some distant place, the Fins or something most unlikely. But the main reason they wanted to join the national Guard was to be able to vote. You had to be defined as a property-owning citizen to have the rightto vote. these bourgeois panicked and start going into a house full of very ordinary people and simply shooting them all. The light lines disappear with Daumier. He did another one of these after a massacre in 1848 in Rouen and it's been lost. We don't have it. The rue Transnonain, where this happened in the center of Paris, simply disappeared. It didn't quite disappear from the collective memory of people thinking about Parisian things. In conclusion, the middle classes extremely vary. They share much. They have a common material culture. They want to vote.

ROUGE-1: 18.86, ROUGE-2: 18.21, ROUGE-L: 18.03
BERTScore: 61.87

==============================================
==================== [85/100] ====================
Summary:
Researchers have confirmed a second smaller space Rock smashed into the sea off the coast of West Africa creating a large crater during the same era. Scientists say it would have caused a tsunami at least 800 M High to tear across the Atlantic Ocean. The asteroid that's believed to have wiped them out 66 million years ago was not the only one researchers have confirmed. The discovery is exciting that it happens to be potentially close to the same time as the chicku event known to be the the main cause of the extinction event that killed the dinosaurs.

ROUGE-1: 38.76, ROUGE-2: 35.80, ROUGE-L: 31.78
BERTScore: 63.39

==============================================
==================== [86/100] ====================
Summary:
In automotive design Dynamics plays a very important part because it's not rigid body Dynamics it's a bunch of rigid bodies with springs the Springs are called starts with an S suspens suspensions right and there's a trade-off between how comfortable the ride is and how tightly the car handles. In Dynamics there two sides to it one is how will its various degrees of freedom behave over time if you you know stretch it and let it go and it goes twang you know boing right and you want to figure out how it goes in time that that's analysis. I'm referring to something with no Dimensions but with a finite Mass you know that someone asked me the other day and I just want to be sure to say this. Let's say that you have a particle Point Mass heading that way some direction and let's define its velocity we'll call it a v p okay so I have um two questions both of which you probably know the answers to the first is what is the angular momentum of that particle just from your memory go ahead say it aha. This is a silly term but these are the two conditions yeah Q is fixed right now it just so happens that we often take angular momenta momenta about things like this point of this door about this point so AQ is z everything's good right or you know we're parallel so it vanishes but you know often it's not parallel so you need to be careful that's the point I want to make okay this term will crop up later uh and we'll we we'll it's a pesky term so way account for it or we get rid of it yep. that stuff let's let's examine it from a uh from a basic you know intuition point of view from what we studied so far first of all when is linear momentum conserved forget this in general linear momentum is conserved when what condition occurs no external Force right so let's study this guy this particle as it moves around does it feel an external Force let's do a free body diagram on this particle um o Point p as the particle moves around kind of intuitively which direction is it accelerating in kind of cental right. would have to do one of two things I would have had to either calculate this term or calculate or make you know make my frame attach it to the truck. I've just done it in a very precise way okay so in the end there's no surprise the whole point is to show you they could be surprises but be careful any questions about this all right snap quiz in the next 3 minutes I want you to calculate for me the final velocity literally 3 minutes because I have toDo the dumbbell problem. of the frame what I have now is two particle masses basically a dumbbell and they're attached rigidly by a massless bar massless and I scoot them across and it's rotating it's hurling through through you know across this rink. I'm going to try and identify understand the behavior in fact I'll make it even more complicated by attaching two rockets get it Rockets right to this thing. The Rockets are designed such that they always Point North all right so they always point in in the horizontal Direction in the on the Whiteboard. We're going to do some free body diagrams then we'll figure out the accelerations of both particles and we'll write f is equal to Ma and we have differential equations we'll make sure we have as many equations as we have unknowns. We'll do that but we'll do it without using any moment of inertia Concepts okay so let's write it out so we know that uh let's calculate so the what's the first thing we need to do we'regoing to write f  for both particles.

ROUGE-1: 12.62, ROUGE-2: 12.33, ROUGE-L: 12.28
BERTScore: 64.06

==============================================
==================== [87/100] ====================
Summary:
Andrej Karpathy: In this module, I'm going to briefly introduce the idea of differentiable programming. Differentiable programming is closely related to deep learning. It allows you to build up an increasingly more sophisticated model without losing track of what's going on. So let's suppose you want to do image classification. We need some way of representing images. To fix this problem, we introduce convolutional neural networks which is a refinement of fully connected neural networks. So here is an example of ConvNet in action. In NLP, words are discrete objects and neural networks speak vectors. So whenever you're doing NLP with neural nets, you first have to embed words, or more generally, tokens. So we're going to define an EmbedToken function that takes a word or a token x and maps it into a vector. And all this function is going to do is it's going to look up vector in a dictionary that has a static set of vectors associated with particular tokens. But the meaning of the words and tokens depends on context. So this representation of the sentence is not going to be a particularly sophisticated one. A simple RNN works by taking an old hidden state, an input, and a new hidden state of the same dimensionality. LSTMs, or long short term memory, were developed to solve this problem. So now we have our sequenced model on RNN which produces a sequence of vectors, and the number of vectors depends on how long the input sequence is. So suppose we want to do classification, we need to somehow collapse that into a single vector. So you can intuitively think about this as summarizing the collection of vectors as one. There's three common things you can do. Transformers are a way of combining different types of networks into one. They can be used to solve problems in language modeling. They use something called self attention, which means that the query is actually going to output the input vectors. So if self attention takes a sequence of input vectors, then it's going to stick the first vector into the query vector for y and then compute the attention, x2 and x4. So in other words, I've basically generated a sequence where all n squared of all the objects, all squared of the vectors, where I've allowed them to communicate with each other.

ROUGE-1: 14.67, ROUGE-2: 13.40, ROUGE-L: 13.73
BERTScore: 64.96

==============================================
==================== [88/100] ====================
Summary:
Professor Amy Hungerford: Today it is my great privilege and pleasure to introduce Andrew Goldstone, a TF in this course. Andrew is a fourth-year student in the Ph.D. program in English, and he is writing a dissertation on the autonomy of the work of art in modernism. On the syllabus it says that I would be presenting a lecture on censorship in this slot, but that's been suppressed. Next week I'd like you to finish the novel and then read his essay, "On a Novel Entitled Lolita" T.S. Eliot's "Gerontion" is a spoof of Nabokov's "The Old Man and the Gull" Eliot says poems should be autotelic, that means they should be an end unto themselves. Eliot in some ways comes very close to the kind of ideas about art that Nabokovsky holds. The idea that art is its own law, that it responds to no other purpose than art's sake, is important to Nabokovan. The novel has as its only purpose to afford aesthetic bliss, he says, and this goes along with sexual convention. imitate any style; at the same time, a scrupulous attention to the banality of everyday life and all its detail; yet, the constant use of a superimposed structure. In Ulysses, famously, Joyce puts the narrative of the Odyssey on top of a day in Dublin, or in Joyce's earlier novel, A Portrait of the Artist as a Young Man, a linear narrative in which a young boy grows up is structured as a series of structurally paralleled chapters. Fourthly, Joyce loves puns. So does Nabokov. Nabokov's novel is a kind of parody of real randomness. The artificial has taken the place of the real in the novel. Nothing is initially known to make sense; everything has to be figured out and reinvented. In America, Nabokov says he had to invent this book afterword to America. That he didn't know it already existed is a terrible state of discontinuity with the world. But it has a payoff, which is kind of a payoff in it. Nabokov says the American landscape is already a work of art, already part of a European memory. "Inutile loveliness" is kind of the key word of Nabokov's technique, and he says the novel has as its only purpose to provide aesthetic bliss. So, a European artist actually appears again there, with Claude Lorrain, but kind of made strange: given that knight's move, given a new twist. So--instead of familiar, incorporated into this profoundly strange, vast landscape that gets Humbert's most appealing rhetoric. violent knight's moves, like skipping past the mother's death. Somehow this is skipped past, that--the sobs in the night. There's a kind of lost paradise of European culture which he can't get back, even with this spectacular effort in English. So, that suggests that it's not all to the good; it hasn't been saved by taking up these knight's move techniques; there's still a record of damage. And you should be skeptical of it, but then you should also ask yourself whether you can really do completely without it.

ROUGE-1: 15.01, ROUGE-2: 13.83, ROUGE-L: 13.60
BERTScore: 64.23

==============================================
==================== [89/100] ====================
Summary:
NORVIN RICHARDS: Today is phonetics, which means that today we begin making funny sounds at each other. One standard way of talking about different kinds of speech sounds is to talk about where in the vocal tract the flow of air can get obstructed. So for example, there are what are called bilabial sounds. These are sounds which are made with both lips. And so that's what you do for the sounds that are at the beginnings of words like "paint" and "bath," and "mouth," and well, "wipe" English doesn't have a bilabial fricative, but there are languages that do. In English, we have a labiodental "f" with our lower lip against our teeth. In Japanese, your teeth are not involved. English has a nasal stop, "k" and "guh," and we've got velar stops in English, "nnnn" We've got a velar stop in English -- "m" -- is that nasal voiced or voiceless? Voiceless. Uvulars are kind of like "k" except more so. Retroflexes are very popular in India, and Australia, and Indonesia. Pharyngeals involve constriction near the pharyngeal wall. Appants are not stops, and they're not nasals. They involve gesturing towards each other in each part of your vocal tract, not enough to make enough to cause turbulence in the airflow. And for some reason, the dental stops are still red. I don't know why. this exercise next time. As we go along, I'm going to be asking you to read things in IPA. So I'll start putting IPA on the slides more and more. So start trying to familiarize yourself with it and get to where you're familiar with at least the symbols for sounds that we use in English. Do you want me to read the rest of them? I'll do some more IPA. OK, so what's the second one? STUDENT: "Sue says he's a bad egg."

ROUGE-1: 5.29, ROUGE-2: 4.89, ROUGE-L: 5.01
BERTScore: 59.04

==============================================
==================== [90/100] ====================
Summary:
Expectation is a basic question that will come up again and again when we look at random variables and probability theory. We're imagining n independent flips of a coin with bias p. The probability of heads is p. It would be biased in favor of heads if p is greater than 1/2. And we want to know how many heads are expected. So what's the expected number of heads? Well, we already know-- we've examined the binomial distribution B n,p.

ROUGE-1: 19.54, ROUGE-2: 18.43, ROUGE-L: 15.40
BERTScore: 71.67

==============================================
==================== [91/100] ====================
Summary:
Aristotle was born 384,15 years after the trial of Socrates. He was sent by his father to go to college. Unlike most of you, Aristotle did not spend four years at the Platonic Academy. He remained attached to it for the next 20, until the death of Plato. Unlike his intellectual godfather, Socrates, who wrote nothing but conversed endlessly, Aristotle wrote disciplined and thematic treatises on virtually every topic. He collected constitutions, 158 of them in all, from throughout the ancient world. Aristotle says man is, by nature, the political animal. He says participation in the life of the city is necessary for the achievement of human excellence. A person who is without a city, he says, who is apolis--without a city--must either be a beast or a god. The city is natural in that it allows human beings to achieve and perfect what he calls their telos, that is to say their end, their purpose. But there is a second sense for him, in some ways, in which he says the polis is by nature.

ROUGE-1: 6.73, ROUGE-2: 6.32, ROUGE-L: 6.25
BERTScore: 58.15

==============================================
==================== [92/100] ====================
Summary:
Mathematically, a consumer is trying to maximize his utility. And this utility maximization has to be done with respect to some constraint and the constraint the budget constraint we take P 1 x 1; P 2 x 2 should be less than or equal to I. In real life, it is possible that a person derives some satisfaction from having some money left in his pocket, but the way this problem has been framed here the person’s satisfaction depends only on his level of consumption of good 1, and good 2.

ROUGE-1: 8.97, ROUGE-2: 8.69, ROUGE-L: 8.97
BERTScore: 69.92

==============================================
==================== [93/100] ====================
Summary:
MIT OpenCourseWare is a free, online education platform. MIT OpenCourse Ware courses are free to download and use. Use the weekly Newsquiz to test your knowledge of stories you saw on CNN.com. The weekly News Quiz pits students against each other to test their knowledge of events in the news. The winner will receive a free copy of MIT Open CourseWare for their next class. Back to the page you came from. Click here to return to the newsquiz page. The Rolex Center is such an iconic building that it also serve a kind of a prestige function, to put the institution on the map in terms of it's a statement. We have a student center here at MIT. People go there to do their banking, their eating, their meeting, and so forth. So we could spend a lot of time on these, but really crisply refining and thinking about the concept is very, very important. So let me very quickly go through the refrigerator case study to show how do we transition from concept to design. When you think about a refrigerator, it's really about preserving food or reducing the spoilage rate of the food. So beside chilling or keeping the food cold, we could irradiate the food or dry it. The key idea is start thinking in this abstract way, and all of a sudden all of these other possibilities become possible. EPFL's Olivier De WECK: Food is pretty essential for humans, this is one of the areas where humans have been very creative. There's a lot of ways to do this. The NASA approach is basically described in the system engineering handbook in the SE engine as step 3 called logical decomposition. So the idea that we need to partition the system and then derive lower-level technical requirements. And then do functional and performance analysis to see whether you have enough detail. And if yes, then you can select that as a baseline, if not, you might have to go back to the red box, which means that architecture didn't work. We have to look for a different decomposition or different architecture. of thinking, these seven principles have been extracted. And then you can say, well, which of these do I feel really resonate with me? All right. Let's move to some of the structured processes for creativity. So the first one is probably the simplest and the one that's used the most. This is known as a morphological matrix. The idea there is that you try to define what are the key features, factors, or decisions that you have to make when you define a concept or an architecture. set. So now be unchained, and within the constraints that are set by the competition, come up with different concepts. And in the homework, what I ask you to do in A3 is try out at least two different techniques, a structured one and an unstructured one and then compare the results. And this will be due in two weeks, and you will have to do it in two hours. And so, in the next two weeks you will be doing your homework.

ROUGE-1: 13.75, ROUGE-2: 11.98, ROUGE-L: 11.57
BERTScore: 56.23

==============================================
==================== [94/100] ====================
Summary:
then we are going to continue with the second part of the lecture today which focuses on the problem what actually happens if the gaussian assumption that i have about my constraints doesn't hold. As you will see in some small examples having this outliers in your optimization problem is something which hurts dramatically which actually screw up your solution. Already a few outliers can lead to a environment model which is completely unusable for doing any navigation task so where the geometry of what you computed doesn't fit to the real world geometry anymore and one of the questions actually how to handle that. have also experienced and if you look to those poses over here in the poses down here how those individual structures match um if you just apply let's say scan alignment you may say this may match so maybe someone has opened the door which was closed before or here is a door now closed which was open all the other scans map actually quite well. If you put already ten wrong ones in there it's quite likely to screw up it was one hundred which is still a very small number compared to 3000 or just a small fraction it will actually end up in dramatic mapping errors. here that by changing this function you can't get much better behaviors kind of deciding which function to use for the underlying optimization problem is not on it's not always an easy and easy choice so this requires some expert knowledge some good intuition on coming up with the way with one of those functions. Next week which is the last week of the term i will briefly talk about front ends and give kind of a short summary on what typical front ends exist obviously we're not going to all the details as we did that here.

ROUGE-1: 9.38, ROUGE-2: 9.17, ROUGE-L: 9.38
BERTScore: 65.45

==============================================
==================== [95/100] ====================
Summary:
John Stuart Mill is the principle expositor of neoclassical utilitarianism. The rights-utility synthesis signals that we're looking for an attempt to put together both a commitment to utilitarian efficiency that's grounded in science on the one hand, and respect for individual rights that's grounding in the workmanship ideal on the other hand. At the same time, more or less, there were very important developments in moral philosophy that I just want to alert you to. The doctrine that I'm mentioning here is the doctrine that would come to be called emotivism.  neoclassical economists didn't want to do that because they were actually concerned with quite another problem. The problem they wanted to solve was to understand the behavior of markets. They wanted to be able to more precisely to predict what prices were going to be in markets. So moving from cardinal to ordinal utility is going to turn out to have huge ideological consequences, which I'm going to unpack for you towards the end of today's lecture. These indifference curves cannot cross. Can anybody tell us why? Why can't they cross? Wait for the mic. same utility even though they're different indifference curves. Prof: You're on the right track, but what's the problem with their crossing? Student: Because you say I-2 has utility of two, I-3.5 has Utility of two-point-five, but at that point where they intersect they both have to have the same utility. If we're saying that we're indifferent among all the things on this curve we can't have it cross because then we're say here, right, two- point-five is preferred to two. John Rawls: The trouble with utilitarianism is that it doesn't take seriously differences among persons. He says classical utilitarianism says, "Well, if taking all of your utility increases overall net utility then we should do that, because we don't care who has the greatest number of the greatest happiness" John Rawls' argument is half-right, he says, because the truth is that's the classical utilitarianists' doctrine. John Rawl's Theory of Justice: The Case for Justice, the Case for Liberty, and Other Essays, is published by Oxford University Press, priced £16.99. which the radical fangs of classical utilitarianism have been ripped out and it is now a doctrine that is very friendly to whatever status quo happens to be generated in a market system. So it ceases to be this radically redistributive doctrine, and in the process imports into utilitarianism a very robust, some would say, hyper-robust doctrine of individual rights. We'll see how that played out in political theory when we come to look at John Stuart Mills' harm principle next Monday.

ROUGE-1: 13.32, ROUGE-2: 12.36, ROUGE-L: 12.42
BERTScore: 63.94

==============================================
==================== [96/100] ====================
Summary:
HONG LIU: Today, we talk about chiral fermions. He says the Dirac equation requires, actually, psi to have four components. But there are two ways to reduce it, and one is called the Majorana fermion, he says. HONG LIu: You don't need four components to be able to transform under Lorentz. You just need a smaller unit, OK? He says this tells you that at least two components already can transform. to impose in this basis. And this is now independent of massless or massive particles? HONG LIU: Yeah, yeah, yeah. Yeah, this is-- yeah. Good? So this concludes our discussion of the Majorana spinor. Do you have any questions on this? Yes? AUDIENCE: So is the orthogonal component of this Majorana species-- like, possible-- in the chiral one, like, psi L, and then you [INAUDIBLE] and then psi R. just reverse one direction or reverse two directions, OK? That seems also to be a discrete symmetry. And indeed. So if you just change the directions, say, in the x direction, that's also a discrete. And if you only change the direction in both x and the y direction, That's also an independent symmetry. But if you change-- if you do the reflection in two directions,. that's equivalent to a 90-degree rotation. And so it's part of the continuous symmetries. And now, when you change all three directions compared to change one direction, you differ only by changing two directions.

ROUGE-1: 5.61, ROUGE-2: 5.11, ROUGE-L: 5.40
BERTScore: 65.48

==============================================
==================== [97/100] ====================
Summary:
The best-case scenario for expansionary fiscal policy is when there are lots of underemployed resources in the economy. By increasing spending, the federal government can try to counteract falling aggregate demand. In one scenario, government spending doesn't have to be as large as the fall in "C," or consumption, to counteract the recession, and that's because of the multiplier effect. But, as always, shifting lines on a graph is much easier than shifting around real resources in a multi-trillion dollar economy.

ROUGE-1: 30.09, ROUGE-2: 28.77, ROUGE-L: 30.09
BERTScore: 67.40

==============================================
==================== [98/100] ====================
Summary:
hey everyone it's sarah thread sterner sorry and calm and in this video i'm gonna demonstrate how to wear and take off a mask. One common mistake that people make is that when they wear the mask they will wear it under the nose. When removing the mask it's important to remember that the front of the mask is considered contaminated. Don't forget to check out the other videos in this series on how to put on and remove a mask including how to apply a mask and how to remove it. nursing skills series series: Nursing skills series. Learn how to become a nurse in the UK by taking part in this series. Visit www.nurseryskills.org.uk for more information and to join the series on Facebook and Twitter. For more information on the series, visit nursing skills series: nursing skillsseries.com. For information on nursing skills in the U.S., visit nursingskits.com or call 1-800-273-8255 or go to NursingSkits.

ROUGE-1: 34.74, ROUGE-2: 24.30, ROUGE-L: 24.82
BERTScore: 58.04

==============================================
==================== [99/100] ====================
Summary:
In this lecture, we're going to talk about how neurons function and how researchers are able to control that function in order to modify behavior. And this is going to involve also sort of understanding how certain antidepressants, like Prozac, work. And then we'll end by talking about how researchers did this experiment to wake up the mouse. And it all starts with something that I told you about at the beginning of the semester, which is that the plasma membrane separates distinct compartments the outside of the cell from the cytoplasm. of signal known as an action potential. In order to have an electrical signal propagate, we need some sort of electrical property that the cell has that enables this. In a resting state, the cell's resting potential is negative 70 millivolts. If the cell is not getting stimulated by something like a neurotransmitter, the resting potential will be negative 70 million. Stephen suggested opening the sodium ion channels, which would depolarize the cell and make this situation less positive. And so if you open these channels, positive ions are going to flow out. A nerve cell fires an action potential and how it propagates along the entire cell length. In the case of the sciatic nerve, this has to happen across an entire meter, OK? That's a very long distance to propagate this change in electrical signal, at least for a cell. And so we're going to talk about the mechanism. And I'm going to start at the beginning, when this action potential initiates. This is a voltage gated sodium channel. And you can see, it's closed because of this red rod that's a positively charged alpha helix. you to test the function of the neuron in the behavior of an organism. So, in this case, this mouse, the light is shined into its brain, and they're testing a specific type of neuron that is involved in arousal of the mouse. And it's going to wake up right now. There it goes. It woke up. You see now its muscle activity is going, OK? So you can test thefunction of specific nerve cells using this approach, and it's because you have a light-sensitive sodium channel.

ROUGE-1: 11.15, ROUGE-2: 10.65, ROUGE-L: 10.83
BERTScore: 65.89

==============================================
==================== [100/100] ====================
Summary:
In this problem, we're going to be dealing with a variation of the usual coin-flipping problem. But in this case, the bias itself of the coin is going toBe random. And we're told that the expectation of this bias is some mu and that the variance of the bias isSome sigma squared. And what we'll be asked is find a bunch of different expectations, covariances, and variances. We'll see that this problem gives us some good exercise in a few concepts, a lot of iterated expectations.

ROUGE-1: 5.64, ROUGE-2: 5.32, ROUGE-L: 5.57
BERTScore: 72.07

==============================================
