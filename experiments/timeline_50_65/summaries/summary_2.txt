The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT Open CourseWare ocw.mit.edu. For confidential support call the Samaritans on 08457 90 90 90 or visit a local Samaritans branch, see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255. No? Nothing? All right. OK, so the story so far is basically three postulates. The first is that the configuration of a particle is given by, or described by, a wave function psi of x. Yeah? So in particular, just to flesh this out a little more, if we were, say, the universe, we would say that the size of the universe is proportional to the number of particles that are in it. And we would also say that this is the same as the mass of the entire universe. And so on. in 3D, for example-- which we're not. We're currently in our one dimensional tripped out tricycles. In 3D the wave function would be a function of all three positions x, y and z. If we had two particles, our wave functionwould be a. function of the position of each of them. We have two particles and a wave function, but we don't have a 3D wave function. We don't know how to make a wave in 3D. We can make one in 2D. particle. x1, x2, and so on. So we'll go through lots of details and examples later on. But for the most part, we're going to be sticking with single particle in one dimension for the next few weeks. Now again, I want to emphasize this is our first pass through. This is not the end of the story. It's just the start of a new chapter in the history of particle physics. We'll be back in a few weeks with more details. our definition of quantum mechanics. Once we use the language and the machinery a little bit, we're going to develop a more general, more coherent set of rules. But this is our first pass. Two, the meaning of the wave function is that the norm is that it is the same as the norm. And three, it is possible to make a quantum wave function that is different from the norm but not different enough to be consistent with quantum mechanics, which is what we're trying to do. squared psi of x, norm squared, it's complex, dx is the probability of finding the particle- There's an n in their. Finding the particle-- in the region between x and x plus dx. OK? And third, the superposition principle. If If If is a particle, then if it is not, then it is. So psi squared itself,norm squared, is the. probability density. OK, OK? OK? The probability density of a particle is the density of the particle. So the probability density is the particle density. there are two possible configurations the system can be in, which in quantum mechanics means two different wave functions that could describe the system given psi 1 and psi 2. Two wave functions could describe two different configurations of the system. For example, the particles here or the particles in the image could be particles 1 or particles 2, or particles 3 or particles 4, or even particles 5 or particles 6. The system could be in either of these configurations, or in a combination of the two. The result is known as the Schrödinger equation. over here. It's also possible to find the system in a superposition of those two psi is equal to some arbitrary linear combination alpha psi 1 plus beta psi 2 of x. No questions? Nothing? Really? OK? So some things to note-- so questions about those before we move on? No questions about that? No question about that at all? No Questions? Nothing at all at all?!?!?!? OK?!? You're not paying attention, are you? You don't know what I'm talking about? You're going to make he threaten you with something. This is not trivial stuff. OK. So some things to note. The first is we want to normalize. We will generally normalize and require that the integral over all possible positions of the probability density is equal to 1/2. The second is that we will require that we normalize over the entire probability density. The third is we will need to take into account the fact that we are dealing with a very large number of probabilities. of x norm squared is equal to 1. Total probability that we find the particle somewhere had better be one. This is like saying if I know a particle is in two boxes, because I've put a particle in one of the boxes, I know it's in one. It's just saying that the total probability of finding a particle somewhere is one, not two, or three, or even four. It is the same as saying the probability that you'll find a person is one in a million. boxes. If it's less, then the particle has simply disappeared. So probability should be normalized. I just don't remember which one. Then the probability that it's in the first box must be 100% or one. And basic rule, things don't just disappear. So it should be 100%. If it isn't, then it must be in the second box or it must have disappeared. It should be in either box. If not, it should have simply been in the third box or the fourth. And this is our prescription. So a second thing to note is that all reasonable, or non stupid, functions of x are equally reasonable as wave functions. OK? So this is a very reasonable function. It's nice and smooth. It converges to 0 infinity. And it's got all the nice features. It is a reasonable wave function. And this is the prescription. It’s a veryreasonable function. The nice features are: It'sNice and smooth, It converged to 0 Infinity, It's got the nice nice nice properties. properties you might want. This is also a reasonable function. It's a little annoying, but there it is. And they're both perfectly reasonable as wave functions. This on the other hand, not so much. So for two reasons. First off, it's discontinuous. And as you're going to show in your.properties you may want, this is not one of them. And it's also not a very good way to get rid of it, as you'll see. problem set, discontinuities are very bad for wave functions. So we need our wave functions to be continuous. The second is over some domain it's multi valued. There are two different values of the function. That's also bad, because what's the probability? It's the norm squared, but if it two, it's not. The third is that the function is not continuous, but it is multi valued, so there are two values of it. That is also bad. values, two values for the probability, that doesn't make any sense. What's the probability that I'm going to fall over in 10 seconds? Well, it's small, but it's not actually equal to 1% or 3%. It's one of those. Hopefully is much lower than that. So all reasonable functions are 1-2-1, and that's what we're going to use in this case. We're not going to say it's 1-3% or 1-4%. We're just saying it's a very small probability. equally reasonable as wave functions. All states corresponding to reasonable wave functions are equally reasonable as physical states. There's no primacy in wave functions or in states. However, with that said, some wave function are more equal than others. OK? And this is why some wave functions have more equal states than others, for example, in a state. This is also why some states are more reasonable than others in a wave function, such as in the case of a state with a high degree of realism. important, and coming up with a good definition of this is going to be an important challenge for us in the next couple of lectures. So in particular, this wave function has a nice simple interpretation. If I tell you this is psi of x, then what can you tell me about the particle whose wave function is the psi ofx? What do you know? AUDIENCE: [INAUDIBLE]. PROFESSOR: It's here, right? It's not over here. Probability is basically 0. this guy? Less informative, right? It's less obvious what this wave function is telling me. So some wave functions are more equal in the sense that they have-- i.e. they have simple interpretations. So for example, this wave. function continuing on infinitely, this Wave function doesn't tell me where the. where the wave is going to end. That's a different type of wave function. It doesn't have to be the same as the one that's going on right now. particle is, but what does it tell me? AUDIENCE: Momentum. PROFESSOR: The momentum, exactly. So this is giving me information about the momentum of the particle because it has a well defined wavelength. This one, I would also say is more equal than this one. They're both perfectly physical, they're both completely physical, and that's what we're looking at. We're looking for a particle with a well-defined wavelength. We want to know what its momentum is, because that's where the information comes from. but this one has a simple interpretation. And that's going to be important for us. Related to that is that any reasonable function psi of x can be expressed as a superposition of more equal wave functions. We saw this last time in the last section of this article. We will return to this topic in the next section of the article. Back to the page you came from. Click here to read the next part of the story, which includes a look at the first part of this week's article. the Fourier theorem. Take any wave function which is given by some complex valued function, and it can be expressed as a superposition of plane waves. 1 The Fourier theory said look, take any wave function-- take any function, but I'm going to interpret in the language of quantum mechanics. 2 The Fourier tyranny said look, take any function, but I'm going to interpret in the language of quantum  mechanics. Over 2pi in our normalization integral dk psi tilde of k, but this is a set of coefficients. e to the ikx. So what are we doing here? We're saying pick a value of k. There's a number associated with it, which is going to be an a magnitude and a tilde. We're going to say pick a number of k of a magnitude of 2pi, and that number is k. That's what we're doing here. e to the ikx is equal to cos kx plus i sin kx. This is a periodic function. And that's the magnitude and phase of a plane wave, e to the ikx. A phase is the magnitude of a wave, and a phase is its magnitude and magnitude. These are periodic functions, so e to the kx is a periodic function. E to the kx is also known as the phase of the plane wave. It is the magnitude and phone of a wave. functions. So this is a plane wave with a definite wavelength, 2pi upon k. We know what its momentum is. Its momentum is h bar k. Any function, we're saying, can be expressed as a superposition by summing over all possible values of k, all possible different wavelengths. That make sense? Fourier didn't think about it that way, but from quantum mechanics, this is the way we want to do it. It's a more equal wave function in the sense that it has a definite wavelengths. to think about it. It's just a true statement, It's a mathematical fact. Similarly, I claim that I can expand the very same function, psi of x, as a superposition of states, not with definite momentum, but of states with definite position. So what's a state with a definite position? AUDIENCE: Delta. PROFESSOR: A delta function, exactly. So delta of-- well, what’s aState with a specific position? x0. goes bing when x0 is equal to x. But I want a sum over all possible delta functions. That means all possible positions. And I need some coefficient function here. Well, the coefficient function I'm going to call psi of x0. So I want to say that x0, dx0 is a sum of all the possible positions of x, x. That's what I call the sum of the delta functions of x and dx0. And that's why I'm calling it x0 psi. is this true? Is it true that I can take any function and expand it in a superposition of delta functions? Absolutely. Because look at what this equation does. Remember, delta function is your friend. It's a map from integrals to numbers or functions. So this integral, is an integral. And it's a superpositional integral. So it can be expanded into any other function. It can be used to create any other superposition. It is possible to do this with any function. The value of this integral is what you get by taking the integrand and replacing x by x0. Set x equals x0, that's when delta equals 0. So this is equal to the argument evaluated over x 0. Over x0 we have a delta of x minus x0 - this is what the integral looks like. The value of the integral is the result of taking the integral and replacing it with the delta. This is the integral of the delta over x.over x0-1. Any arbitrarily ugly function can be expressed either as a superposition of states with definite momentum. OK? And this is going to be true. We're going to find this is x.at x0 is equal to x. at x0. That's your psi of x. At x0, x is a state with definite position and definite momentum, and at x.0, it's a state of definite momentum and definite position, and so on. That is x0 at x, and x at x is x, so x is the state of x, which is x's momentum. a general statement that any state can be expressed as a superposition of states with a well defined observable quantity for any observable quantity you want. In 2D, this is a perfectly good vector, right? Now here's a question I want to ask you. Is that a superpositional? Yeah. I mean every vector can be written as the sum of other vectors, and it can be done in an infinite number of ways. So there's no such thing as a state which is not a superosition. Every vector is a superposition of other vectors. It's a sum of other vector. So in particular we often find it useful to pick a basis and say look, I know what I mean by the vector y, y hat is a unit vector in this direction. And now I can ask, given that these are my natural guys, the guys I want to attend to, is this asuperposition of x and y? Or is it just x or y? Well, that's a superposition. Whereas x hat itself is not. So this somehow is about finding convenient choice of basis. But any given vector can be expressed as a superposition of some pair of basis vectors or a different pair. There's nothing hallowed about your choice of based. But there's nothing Hallowed about the choice of a basis. And there's no need to be Hallowed, just Hallowed. And that's the way it should be, I think. I think that's how it's supposed to be. no God given basis for the universe. We look out in the universe in the Hubble deep field. So there's no natural choice of basis, but it's sometimes convenient to pick a basis. This is the basis for our understanding of the universe, says David Wheeler. He says it's not a natural choice, but a convenient one. It's a basis for us to see the universe as we see it, he says. The universe is not God-given, he adds, it's a choice we make. the direction of the surface of the earth. This is the direction perpendicular to it. So sometimes particular basis sets have particular meanings to us. That's true in vectors. This would be slightly strange. Maybe if you're leaning. And similarly, similarly, and similarly, this is along the earth and this is perpendicular to. It's a bit strange, but it's not that strange. It just has a very different meaning to us, I think, than it does to other people. this is an expansion of a function as a sum, as a superposition of other functions. And you could have done this in any good space of functions. We'll talk about that more. These are particularly natural ones. They're more equal. This is ones with different definite values of position, these are ones that are more equal to each other. They have different definite positions of position as well as definite positions. They are not equal to one another, they just have different positions. different definite values of momentum. Quickly what's the momentum associated to the plane wave e to the ikx? AUDIENCE: [INAUDIBLE]. PROFESSOR: h bar k. Good. So now I want to just quickly run over some concept questions for you. So whip out your clickers. OK, we'll do this. We'll go to the top of the page and ask you questions about the concept of a plane wave and a plane kx. Professor: How do you know whether the particle is big or small by looking at the wave function? AUDIENCE: [INAUDIBLE]. PROFESSOR: All right. Two particles described by a plane wave of the plane wave. All right, let's try this again. So how would you interpret this wave function. e.verbally. PROFessor: e. Verbally. How do we know if a particle is large or small? e. verbally. form e to the ikx. Particle one is a smaller wavelength than particle two. Which particle has a larger momentum? Think about it, but don't say it out loud. And this sort of defeats the purpose of the clicker thing, because now I'm supposed to be able to know without knowing. I don't know why I'm doing this, but it seems like a good idea to try and figure out what's going on in the universe. I'm not sure why I decided to do this, though. you guys saying anything. So instead of saying it out loud, here's what I'd like you to do. Talk to the person next to you and discuss which one has the larger AUDIENCE: [CHATTER]. All right. Cool, so which one have the larger momentum? Audience: A. PROFESSOR: How come? [INTERPOSING] A. Professor: How do you know which one is the larger? A. Professor: I don't know. Smaller wavelength, higher momentum. If it has higher momentum, what do you just intuitively expect to know about its energy? It's probably higher. So this is an important little lesson that you probably all know from optics and maybe from core mechanics. Shorter wavelength thing, higher energy. Usually higher energy as well. Very useful rule of thumb to keep in mind, I think, as you go through this. I hope this helps you understand it a little bit better, too. in mind. Compared to the wave function psi of x, it's Fourier transform, psi tilde of x contains more information, or less, or the same, or something. Don't say it out loud. OK, so how many people know the answer? Awesome. And how about you? Do you know how particle one works? If so, please share your knowledge with us in the comments below or on Twitter @CNNOpinion. If you don't, please send us a photo of your particle one. many people are not sure. So talk to the person next to you and convince them briefly. All right. So let's vote. A, more information. B, less information. C, same. OK, good you got it. So these are not hard ones. This function, which is a sine wave, is a good one to try out. It's a good way to test your knowledge of a subject. It gives you a good idea of what to look for and what to ignore. of length l, 0 outside of that region. Or f is made up of a wide range of wavelengths. Which is closer to true? f has a single well defined wavelength for the most part? It's closer totrue. This doesn't have to be exact. f is not the same thing as f, it's just a different name for a different type of molecule. It's a type of light that has a different wavelength for different parts of the universe. It doesn't need to be exactly the same as f. of wavelengths? Think it to yourself. Ponder that one for a minute. OK, now before we get talking about it. Since we don't have clickers, but I want to pull off the same effect, and we can do this, because it's binary here. I'm going to try to make it look like I'm looking at it from a different angle. I'll let you know how it turns out when we get to the next part of the story. Back to the page you came from. want everyone close their eyes. Just close your eyes, just for a moment. Or close the eyes of the person next to you. That's fine. And now and I want you to vote. A is f has a single well defined wavelength. B is f is a wide range of wavelengths. And I want everyone to vote on A is F. A. is F, B is F and A is A. F is A, A, B, B. B. is B. of wavelengths. So how many people think A, a single wavelength? OK. Lower your hands, good. And how manyPeople think B, a wide range of wavelengths? Awesome. So this is exactly what happens when we actually use clickers. It's 50/50. So now you guys need to talk to the people on the other side of the room. It will be interesting to see how they react to the different types of images we show them. It'll be fun to find out. person next to you and convince each other of the truth. All right, so the volume sort of tones down as people, I think, come to resolution. Close your eyes again. Once more into the breach, my friends. So close your eyes, and now let's vote again. f f ff f f back to Mail Online home. Back to the page you came from. Follow us on Twitter @MailOnline and @CNNOpinion and @dailymailopinion. of x has a single, well defined wavelength. And now f of x is made up of a range of wavelengths? OK. There's a dramatic shift in the field to B, it has a wide range of wavelength, not a single wavelength. That is, in fact, the correct answer. And that is, of course, what we should be thinking about when we're talking about f of X, which is a very broad range of light. But we're not going to get into that right now. OK, so learning happens. That was an empirical test. So does anyone want to defend this view that f is made of a wide range of wavelengths? Sure, bring it. So, the sine wave is an infinite, and it cancels out past minus l over 2 and positive l over 1. That's why it's called a "sine wave" and not a "f wave" or a "wave" or "f-wave" It's an infinite wave. over 2, which means you need to add a bunch of wavelengths to actually cancel it out there. If you only had the thing of a single wavelength, it would continue with a single wavelengths all the way out. In fact, there's a nice way to do it that doesn't require a lot of wavelengths at all. It's just a nice, simple way to make it look like you're using a whole bunch of different wavelengths at the same time, which is what we're doing. say this. A sine wave is continuous, and it's continuous everywhere, right? It's also differentiable everywhere, because it's a cosine. So if yo you take a superposition, what can you say about it's? You can say that it's differentiable and continuous. And that's what we're trying to do with the sine waves. We want to say that they're continuous and differentiable. And we can do that with the cosine, which is continuous. of sines and cosines, do you ever get a discontinuity? No. So how would you ever reproduce a thing with a discontinuous using sines or cosines? Well, you'd need some infinite sum of sines. That function is continuous, but its derivative is discontinuous. So it's going to take an infinite number of sine and cosine to reproduce that little kink at the edge. Yeah? AUDIENCE: Yes, yes, that's what it is. So a finite number of sines and cosines doesn't mean finding an infinite number. Because over a finite region [INAUDIBLE]. PROFESSOR: That's true, but you need arbitrarily-- so let's talk about that. That's an excellent question. It's a very good question. I'm glad you asked it. It was a good question, and I'm happy to answer it. The answer is that you need to find an arbitrarily large number of sines and cosines. question. That's a very good question. The question here is look, there's two different things you can be talking about. One is arbitrarily large and arbitrarily short wavelengths, so an arbitrary range of wavelengths. And the other is an infinite number. An infinite number is silly, because there's a limit to what you can do with it. But an arbitrary number is also silly, as there's no limit to how long it can stay on the light spectrum. It's just an arbitrary amount of time. continuous variable here k. You got an infinite number of wavelengths between one and 1.2, right? It's continuous. So which one do you mean? So let's go back to this connection that we got a minute ago from short distance and high momentum. That thing looks like it has one. It's a continuous variable here. It has one wavelength. It looks like there's one wavelength there. It doesn't look like there is one variable there, but there is. In order to reproduce that as a superposition of states with definite momentum, I need arbitrarily high wavelength. Why do we need to arbitrarily high momentum modes? Well, it's because of this. We have a kink.particular wavelength. But I claim, in order to reproduce that as an arbitrary superposition, we need wavelength modes. And why do I need arbitrary high wavelength modes? It's because I have wavelength modes that I want to reproduce. I want wavelength modes to reproduce superpositions of states that have definite momentum. And this feature, what's the length scale of that feature? It's infinitesimally small. In order to reproduce that, in order to probe it, I'm going to need a momentum that's arbitrarily large. So it's really about the range, not just the number. But it's very, very exciting to be a part of this project, and I'm looking forward to seeing what the future has in store for us. It's going to be very exciting. you need arbitrarily large momentum. To construct or detect an arbitrarily small feature you need arbitrarily big momentum modes. Yeah? AUDIENCE: Why do you [INAUDIBLE]? Why don't you just say, oh you need an arbitrary small wavelength? Why wouldn’t you just phrase that [INAudible]? PROFESSOR: I chose to phrase it. I’m not sure why I did. I just chose to say it, and that’s what I did, and it worked. that way because I want an emphasize and encourage-- I emphasize you to think and encourage you to conflate short distance and large momentum. I want the connection between momentum and the length scale to be something that becomes intuitive to you. So when I talk about something with short momentum, I want it to feel like short distance. I don't want to make it seem like it's a big deal. I just want you to be able to connect the dots and think about it in a way that makes sense. features, I'm going to talk about it as something with large momentum. And that's because in a quantum mechanical system, something with short wavelength is something that carries big momentum. That cool? Great. Good question. So earlier you said that any reasonable wave function, a possible wavefunction, does this. Well, we're going to say that it does. That's because that's what quantum mechanics is all about. It's all about momentum. We're talking about momentum in quantum mechanics. that mean they're not supposed to be Fourier transformable? PROFESSOR: That's usually a condition. We don't quite phrase it that way. And in fact, there's a problem on your problem set that will walk you through what we will mean. What should be true of the Fourier transforms? That's what we're trying to figure out. That's why we're asking you to look at the problem set and see if you can figure out what we are talking about. in order for this to reasonably function. And among other things, being able to have a Fourier transform where you don't have arbitrarily high momentum modes is going to be an important condition. That's going to turn to be related to the question of how do we get to a more efficient Fourier Transform? We're going to have to find out how to get to that point. We'll have more to say about that later on in the show. We hope you'll join us for the rest of the program. to the derivative being continuous. That's a very good question. So that's the optional problem 8 on problem set 2. Other questions? PROFESSOR: Cool, so that's it for the clicker questions. Sorry for the technology fail. So I'm just going to turn this off in disgust. that's really irritating. So, I'm going to go back to my desk and work on the next set of problems. I'll be back in a few minutes with the next question. today what I want to start on is pick up on the discussion of the uncertainty principle that we sort of outlined previously. The fact that when we have a wave function. with reasonably well defined position corresponding to a particle with reasonably. well. defined position, it didn't have a well-defined position. It didn't. have a position that was well defined. It had a position which was not well defined, so it was not a well defined particle. It was a particle that was not in the same position as the particle. reasonably well defined momentum and vice versa. The certainty of the momentum seems to imply lack of knowledge about the position. So in order to do that, we need to define uncertainty. So I need to defined for you delta x and delta p. So first I need. to define for you Delta x and Delta p. Then I can talk about the relationship between momentum and uncertainty. I can then talk to you about the relation between the momentum and the uncertainty of the position, for example, or about the difference between the two. just want to run through what should be totally remedial probability, but it's always useful to just remember how these basic things work. So consider a set of people in a room, and I want to plot the number of people with a particular age as a function of the age of the people in the room. That's what I'm trying to do here. It's a very simple problem. It doesn't require a lot of complex thinking. It just needs to be a simple way of plotting the numbers. age of possible ages. So let's say we have 16 people, and at 14 we have one. And at 16 we have 3. And that's 16. At 20 we have 2. and at 21 we have 4. And then at 22 we have 5. and that's 5. And so on and so on until we get to the age of 22, when we have 6. and then 7. and 8. and 9. and 10. and 11. and 12. and 13 and 14 and 15 and 16. So what's the probability that any given person in this group of 16 has a particular age? I'll call it a. It's the number that have age a over the total number. If you grabbed one of these people from the room with a giant Erector set, and pull out a person, and ask them what their age is, what's most likely they'll have? Audience: 22. On the other hand, what’s the average age? Well, just by eyeball roughly what do you think it is? So around 19 or 20. be 19.2 for this. But if everyone had a little sticker on their lapel that says I'm 14, 15, 16, 20, 21 or 22, how many people have the age 19. 2? None, right? So a useful thing is that the average need not be an observable value. This is a useful. thing to know about people. It's a good way to get to know people, and it's a great way to learn about people's personalities. The average age of a person in quantum mechanics is 19.4. This notation is going to stick with us for the rest of quantum mechanics. How did I get the average? I'm going to define some notation. The average age, how do I compute it? That's what I got. That's how I got the average age. Oops, 19. 4. That was what Igot. That is how I compute the average Age of a Person in Quantum Mechanics. It's going to come back to haunt us. We're going to have to get used to it. So we all know this, but let me just be explicit about it. This is equal to the sum over all possible ages of a times the ratio of Na to N. And so that's all I've written here. But notice that I can write this in a nice way. So in this case, I'd go 14,14, 16, 16,. 16, 17, 18, 19, 20, 21, 21. 21, 22, 22,. 22, 23, 24, 25, 26, 27. with a ratio of Na to n total. That's just the probability that any given person has a probability a. a times probability of a. So the expected value is the sum over all possible values of the value times the probability to get that value. Yeah? This is the best way to do it. It's not perfect, but it's better than the alternative, which is to say it's not at all clear what the answer is. And it doesn't have to be perfect. same equation, but I'm going to box it. It's a very useful relation. And so, again, does the average have to be measurable? No, it certainly doesn't. And it usually isn't. So let's ask the same thing for the square of ages. What is the average of a squared? Square the ages. You might say, well, why would I ever care about that? But let's just be explicit about it. So following the same logic here, the average value of thesquare of the ages is. It's just a squared, right? 14 squared, 15 squared, 16 square, 16 squared,16 squared. So this is going to give me exactly the same expression. So over a of a squared probability of measuring a. And more generally, the expected value, or the average value of some function of a. The expected value of a is the average of a number of different things. For example, it's the probability that a will be a certain number of times larger than the number that it is. a is equal-- and this is something you don't usually do-- is equal to the sum over a of f of a, the value of f given a particular value of a. It's exactly the same as the probability that you measure that value in the first place. A is equal the sum of f and a, times the probability of measuring that value. It is the same for a and f, or f and the probability you measure it with, or over a and a. logic as averages. Is a squared equal to the expected value of a squared? Audience: No. Professor: Right, in general no, not necessarily. So for example, suppose we have a Gaussian centered at the origin. So here's a. Now a now a. So is the average value of this Gaussian the same as the average of all Gaussians? The answer is no, it's not. It's different. But it's the same thing. isn't age, but it's something-- I don't know. You include infants or whatever. It's not age. Its happiness on a given day. So what's the average value? Meh. Right? Sort of vaguely neutral, right? But on the other hand, if you take a squared, very few people have a squared. Very few people. Have a personal essay to share with the world? Submit at CNN.com/soulmatestories. For confidential support on suicide matters call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or click here. as zero. Most people have a squared as not a 0 value. And most people are sort of in the middle. So in this case, the expected value of a, or the averagevalue of a is 0. The average value of the squared is 0, so the day is a day. The day is also a day, so it's not a day at all, it's a day in the week. That's the way it works in the U.S. and it's the same in the UK. average value of a squared is not equal to 0. And that's because the squared has everything positive. So here we have a distribution where its average value is 0, but its width is non-zero. So how do we define the width of a distribution? This is going to be like our uncertainty. How happy are you today? Well, I'm not sure. How unsure are you? How happy do you want to be today? You're not happy today. You're unsure. you? Well, that should give us a precise measure. So let me define three things. First the deviation. So the deviation is going to be a minus the average value of a. So this is just take the actual value of. a and subtract off the averagevalue of a, and that's how we get the figure for the number of people in the U.S. who are in the military. That's how you get the total number of military personnel in the United States. That’s how you measure the total military population. So we always get something that's centered at 0. Well, what's the average value of 7? AUDIENCE: 7. PROFESSOR: OK, good. So that first time, we're going to try to get something centered at 7. The average value. of a minus it's average value is 0. So we're always going to start with 0. We're always trying to get 0. so that first, we'll try and get 7. We'll see how that goes. term is the average value of a. And that second term is theAverage value of this number, which is just this number minus a. So this is 0. Yeah? The averagevalue of a number is 0, and the average of this variable and that variable is theaverage value of that. So that's what we're looking at here. That's why it's 0. The average of the number and the number of the variable are 0, so that's why we're talking about 0. variable, but that's 0. So deviation is not a terribly good thing on average, because on average the deviation is always 0. That's what it means to say this is the average. So the derivation is saying how far is any particular instance from the average, and if you average, it's not very good. And if you're not average, then it's probably not a very good thing at all. So that's what we're trying to say here. We're looking at the average deviation. those deviations, they always give you 0. So this is not a very good measure of the actual width of the system. But we can get a nice measure by getting the deviation squared. And let's take the mean of the derivation squared. So the mean is the average of the deviation and the mean squared of the average deviation. That's what we're trying to get at, and it's a very nice measure of how wide the system is. It's not a perfect measure, but it is a good one. mean of a minus the average value of a squared. This is what I'm going to call the standard deviation. Which is a little odd, because really you'd want to call it thestandard deviation squared. But whatever. We use funny words. So now what does it mean if the. mean of a plus the average of a and the squared. value of the mean is less than 1? That's what we call it. The standard deviation squared is 1 less than the mean of the squared value. average value of a is 0? It means it's centered at 0, but what does it mean if the standard deviation of a are 0? So if thestandard deviation is 0, one then the distribution has no width, right? Because if there was any amplitude away from the average value, then that would give a non-zero strictly positive contribution to this average expectation, and this wouldn't be 0 anymore. So standard deviation is0, as long as there's no width. And just as a note, taking this seriously and taking the square, so standard deviation squared, this is equal to the average value of a squared minus twice a times the average of a quantity squared. So this is an alternate way of writing the standard deviation. OK? So we can either write it as a squared plus 2 or as a square plus 2. But if you do this out, it's going to be equal to a square minus 2 average value and a squared. That's just minus twice the averagevalue of a quantities squared. And then plus average value, squared. in this fashion or this fashion. And the notation for this is delta a squared. Different probability distributions are going to give me different delta a's. So one thing that's sort of annoying is that when you write delta a, there's nothing in the word delta a. OK? So delta a is the uncertainty in a given some probability distribution. It's going to be the square root of the standard deviations squared. OK, that's what I mean by an uncertainty. So when I talk about an uncertainty, what Imean is, given my distribution, I compute the standard deviation. notation that says which distribution you were talking about. When you have multiple distributions, or multiple possible probability distributions, sometimes it's useful to just put given the probability distribution p of a. This is not very often used, but sometimes it is very helpful when you're doing calculations just to keep track of which one you're talking about and which you're using for a given distribution. For example, if you're trying to work out the probability of a given value of a, you might want to put the value of the value you're looking for in the form of a probability distribution. track. Audience: So really it should be parentheses [INAUDIBLE]. PROFESSOR: Yeah, it's just this is notation that's used typically, so I didn't put the parentheses around precisely. Everyone cool with that? Yeah, questions? AUDIENCE: [INAudIBLE] delta a squared, right? PROFessor:Yeah, exactly. OfDelta a squared. Yeah. Other questions? Yeah? Audiences: What's the number of a square root of two? to alert you to the stupidities of this notation. So any other questions? Good. OK, so let's just do the same thing for continuous variables. I'm just going to write the expressions and just get them out of the way. So the average value of some is the same as the average of some other values. So that's what we're going to do here. Now for continuous variable. We're just writing the expressions. We don't need to worry about the variables themselves. x, given a probability distribution on x where x is a continuous variable, is going to be equal to the integral. And similarly for x squared, or more generally, for f of x, the average value of f ofx, or the expected value of x given this probability distribution, is also equal to x minus infinity to infinity. I shouldn't use curvy. I should just use x. The probability distribution of x times x. is pretty useful, or pretty typical, orpretty typical. probability distribution of x times f of x. So this is all just mathematics. And we define the uncertainty in x is equal to the expectation value of x squared minus the expected value of X quantity squared. And this is delta. In direct analogy to what we had before. We define delta as the difference between the expected and the actual value of the quantity squared, and we call it the uncertainty. This is delta, and this is the uncertainty of the distribution of the quantities squared. All of that is just straight up classical probability theory. And I just want to write this in the notation of quantum mechanics. If you see me dropping an exponent or a factor of 2, please, Please, please tell me. So thank you for that. Given that the the square root of the exponent is 1.x squared, the exponent of the factor of 1 is 1:1. x squared, which is 1/1.x square, or 1/2. The exponent of this factor is therefore 1/3. system is in a state described by the wave function psi of x, the average value, the expected value of x. The typical value if you just observe the particle at some moment, is equal to the integral over all possible values ofx. The probability distribution, psi ofx, is the average of all the possible values. The expected value, x, is equal to the integral of x, which is the expected value of x if you observe it at some point. The probability distribution is given by the norm squared of the wave function times f of x minus infinity to infinity. And similarly, for any function of x, the expected value is going to be equal to the integral dx.norm squared x. And same definition for uncertainty. And similar definition for expected value of a function of a given value of x. For example, for the probability distribution of a wave function, the expected value is the integral of the probability distribution of the wave function. again, this notation is really dangerous, because the expected value of x depends on the probability distribution. So there are a couple of ways to improve this notation. One of which is to write the expectedvalue of x in the state psi, so you write psi as a subscript. Another notation that will be helpful is to use the notation for the state of the system, which is called the state pyschotic state, or state px, and this notation will be used for that. come back-- you'll see why this is a useful notation later in the semester-- is this notation, psi. And we will give meaning to this notation later, but I just want to alert you that it's used throughout books, and it means the same thing as what we're talking about. It's a notation that's used in books and is used throughout the course of the semester. It is used to indicate that something is not what it appears to be, but what it actually is. the expected value of x given a particular state psi. OK? Yeah? AUDIENCE: To calculate the expected. value of momentum do you need to transform the-- PROFESSOR: Excellent question. OK, so the question is, how do we do the same thing for momentum? If you want to compute the expected value. of momentum, what do you have to do? Do you have a Fourier transform to the wave function? So this is a question that you're going to answer on the problem set and that we made a guess for last time. just think about what it's going to be purely formally. Formally, if we want to know the likely. value of the momentum, the likely value the momentum,. it's a continuous variable. Just like any other observable variable, we can write as the integral over all possible values of momentum from, and it will be the same as any other variable. It's a constant. It can't be written as a function of momentum, but it can be used as an integral over its possible values. let's say, it could be minus infinity to infinity. The probability of having that momentum times momentum, right? Everyone cool with that? This is a tautology,right? But we need to know if we have a quantum mechanical system described by state psi. This is what you mean by probability. It could be zero to infinity, but it could also be infinity. It's possible that it could even be one or more. We need to find out if we've got it. of x, how do we can get the probability that you measure p? Do I want to do this now? Yeah, OK I do. And we need a guess. We made a guess at the end of last lecture that, in quantum mechanics, this should be dp minus dp. We make a guess that this is dp plus dp, and we call it dp-dp, or dp -dp. But we don't know what dp is, so we try to guess. infinity to infinity of the Fourier transform. Psi tilde of p up to an h bar factor. The Fourier transforms p norm squared is equal to the probability of measuring the associated momentum. So that's a Fourier Transform norm squared of infinity to infinity. The p norm is the probability that the momentum associated with the transform is greater than or less than infinity. That's the pnorm squared of Infinity to infinity to Infinity to Infinity, or h bar factors to h bar Factor. guess. That's a guess. And so on your problem set you're going to prove it. OK? So exactly the same logic goes through. It's a very good question, thanks. Other questions? Yeah? Audience: Is that p the momentum itself? Or is that the probability? PROFESSOR: So this is the probability. OK, so that's a good question. So that's what we're going for. OK. So, that's the answer. of measuring momentum p. And that's the value p. We're summing over all p's. This is the probability, and that's actually p. So the Fourier transform is a function of the momentum in the same way that the wave function is afunction of the position, right? So this is p. The probability is the sum of p's and the value of p is the momentum. The Fourier Transform is the same thing as the wavefunction, but with a different shape. a function of the momentum. It's norm squared defines the probability. And then the p on the right is this p, because we're computing the expected value of p. That make sense? Cool. Yeah? AUDIENCE: Are we then multiplying by p squared if we're in a race? Do you know the answer to that question? If so, please share your answer in the comments below. Back to the page you came from. Click here to read the full transcript of this interview. doing all p's? Because we have the dp times p for each [INAUDIBLE]. PROFESSOR: No. So that's a very good question. So let's go back. Let me phrase it in terms of position, because the same question comes up. Thank you for asking that. Look at this. Let's go to the next question. Do you have a question for me? If so, please contact me at jennifer.smith@mailonline.com. This is weird. I'm going to phrase this as a dimensional analysis question. This is a thing with dimensions of what? Length, right? But over on the right hand side, we have a length and a probability, which is a number, and then another length. That looks like x squared. So why are we getting something with. dimensions of length, not something with dimensions. of length squared? And the answer is this is not a probability. It is a probability density. Psi of x is a pure number, no dimensions. So this has dimensions of one over length. So that was our second postulate. The probability to find the particle between x and x plus dx is p of x. Psi of X is the probability of finding a particle between X and X plus x plus x. This is the number of particles that can be found between these two points. It's called p of X. It is a number that has dimensions, which are one overlength. So it's a number of dimensions. dx squared is the probability of finding it in this domain. And so what we're doing is we're summing over all such domains the probability times the value. So this is the difference between discrete, where we didn't have these probability densities, we just had numbers, pure numbers and pure numbers. It's a very different way of looking at the world, and it's very different from the way we look at the universe in terms of probabilities. We're looking at probabilities of finding something in a particular domain. pure probabilities. Now we have probability densities per unit whatever. Yeah? Audience: How do you pronounce the last notation that you wrote? PROFESSOR: HowDo you pronounce? Good, that's a good question. The question is, how do we pronounce these things? So this is called the expected value of x, and it's called the probability density of x. The probability density is the number of units of x that are expected to be true. It's the probability of x being true. or the average value of x, or most typically in quantum mechanics, the expectationvalue of x. This is the same thing. The psi is just to denote that this is in the state psi. And it can be pronounced in two ways. You can either say the expectation value of X, or the expectation of x in theState psi. This would be pronounced one of two ways, or psi x psi. But they mean the same things. It's just a different way to say it. the same thing. Now, I should emphasize that you can have two ways of describing something that mean the same thing, but they carry different connotations, right? Like have a friend who's a really nice guy. He's a mensch. And so I could see he's a good guy. But I could also see that he was a bad guy. And that's a different thing. So I could have two different ways of saying it, and they're both valid. nice guy, I could say he's [? carinoso ?], and they mean different things in different languages. It's the same idea, but they have different flavors, right? So whatever your native language is, you've got some analog of this. This means something in a particular mathematical language for talking about. This is the same thing in a different language, but with a different flavor. It doesn't mean what you think it means, it's just a way of saying it. quantum mechanics. And this has a different flavor. It carries different implications, and we'll see what that is later. We haven't got there yet. Yeah? AUDIENCE: Why is there a double notation of psi? PROFESSOR: Why? Roughly speaking, it's because it's a different type of quantum mechanics. We'll see later. Yeah, we'll get to that. We've got a lot of work to do, but we're going to get to it. because in computing this expectation value, there's a psi squared. And so this is to remind you of that. Other questions? Terminology is one of the most annoying features of quantum mechanics. Yeah? AUDIENCE: So it seems like this [INAUDIBLE] variance is a really convenient way of doing it. How do you get there? How do we get to the point where we know how to do it? What do we do? What does it look like? What is it like? is it the Heisenberg uncertainty works exactly as it does for this definition of variance. In order to answer that question, we need to actually work out the He Eisenberg uncertainty relation. So the question is, look, this is some choice of uncertainty. You could say, "Well, it's just a choice of the uncertainty." Or you could say "It's the uncertainty relation" or "The uncertainty relation is the difference between the uncertainty and the uncertainty of the choice." or "There's no difference between these two." have chosen some other definition of uncertainly. So why this one? And one answer is, indeed, the uncertainty relation works out quite nicely. But then I decided to go with the fourth root of the expectation value of x to the fourth minus x toThe fourth and take that. And that's how I came up with the definition of 'uncertainty' that I used. And it's a good one, too, as it turns out to be a very good way of looking at uncertainty. think important to say here is that there are many ways you could construct quantities. This is a convenient one, and we will discover that it has nice properties that we like. There is no God given reason why this had to be the right thing. I can say more, but I don't want to give the impression that I'm saying that this is the only way to do things. I'm just saying that it's a convenient way of doing things, and that's all I'm going to say. but I don't want to take the time to do it, so ask in office hours. OK, good. The second part of your question was why does the Heisenberg relation work out nicely in terms of these guys, and we will study that in extraordinary detail. We'll see that. So far, we've got a pretty good idea of what's going on, but we're going to have to wait and see what the results are in the next few years. But so far, it seems to be going well. we're going to derive it twice soon and then later. The later version is better. So let me work out some examples. Or actually, I'm going to skip the examples in the interest of time. They're in the notes, and so they'll be posted on the web page. By the end of the week, we'll have a new version of this article. We'll post it on our website. It will be updated as we get more information about the new version. way, the first 18 lectures of notes are posted. I had a busy night last night. So let's come back to computing expectation values for momentum. So I want to go back to this and ask a silly-- I wantto make some progress towards deriving this relation. So, let's go to the next 18 lectures and I'll be back in a day or two with a new set of notes to show you what I've learned so far. I'm looking forward to it. want to start over on the definition of the expected value of momentum. And I'd like to do it directly in terms of the wave function. So how would we do this? So one way of saying this is what's the average value of p. Well, I can phrase this by saying that p. is the number of times that p is greater than or less than the average of p and p. That's the way I would phrase it. I think that's a good way to start. in terms of the wave function the following way. I'm going to sum over all positions dx. Expectation value of x squared from minus infinity to infinity. And then the momentum associated to the value x. So it's tempting to write something like this down to think maybe there's some some sort of secret. But I'm not sure what the secret is, and I don't think I want to know. So I'm just going to go with the flow and try to make it as simple as possible. Professor: Are we ever in a position to say intelligently that a particle-- that an electron is both hard and white? Audience: No. Professor: No, because being hard is a superposition of being black and white, right? Are. Are we. Can we? This is a tempting thing to write down. It's like writing down x.p of x.P of x-p of X-P of Y-P. We can't do it. We don't. we ever in a position to say that our particle has a definite position x and correspondingly a definite momentum p. It's not that we don't get too, it's that it doesn't make sense to do so. In general, being in a. definite position means being a superposition of a. number of particles in the same place. This is the case in the case of a particle with a definite. position x, and a. momentum p, with a position x. and a momentum. p. having different values for momentum. And if you want a sharp way of saying this, look at these relations. They claim that any function can be expressed as a superposition of states with definite momentum, right? Well, among other things a state with definite position, x0, can be written as x0. A state with a definite position of x0 is called a "superposition" of states. This is a way of expressing the fact that a state has a definite momentum. The problem set is a delta tilde of k. e to the ikx.a superposition, 1 over 2pi integral dk. If you haven't played with delta functions before, you will on the problem set. We have a problem that works through a great many details. I'll call it the "Delta Tilde of K. E to the Ix. A Superposition" problem set, and it's a bit of fun to play with. The problem set includes a delta function, an integral function, and a superposition. But in particular, it's clear that this is not-- this quantity can't be a delta function of k, because, if it were, this would be just e to the ikx. And that's definitely not aDelta function. Meanwhile, what can you say about the continuity structure of a deltafunction? We'll have to wait and see. We'll be back in a few minutes with the answers to your questions. Back to Mail Online home. back to the page you came from. Is it continuous? No. Its derivative isn't continuous. Its second derivative is not continuous. None of its derivatives are in any way continuous. They're all absolutely horrible, OK? So how many momentum modes am I going to need to superimpose in order to reproduce a function that has this sort of structure? An anterograde function. An anorak function. And so on. Anorak functions. And on and on and so on, until I get to the point where I think I've got it. You can never say that you're in a state with definite position and definite momentum. In fact, I'm just going right down the answer here. e to the ikx0.infinite number. And it turns out it's going to be an infinite number with the same amplitude, slightly different phase, OK? So you cannot be in a position with definite momentum, definite position. You cannot be a superposition of states with arbitrary momentum, and vice versa. So you can never be a state of definite position, definite momentum or definite momentum and definite position at the same time. this doesn't work. We want some good definition of p given that we're working with a wave function which is a function of x. What is that good definition? We have a good definition. So this does not work. So what we want is we want someGood definition of the momentum. We have some good definitions of p and we want to use them to work with the wave function. This is a good example of how to use these good definitions. We can use these definitions to get a good idea of momentum. couple of hints. So this is what we're after. Hint the first is that a wave-- we know that given a wave with wave number k, which is equal 2pi over lambda, is associated, according to de Broglie and according to Davisson-Germer experiments, to a particle. So hint the first. We're after a wave that is associated with a particle, and we know how to get it. We know that it's associated with the number k. So having a particle with momentum p is equal to h bar k. That's e to the iks. And if I have a particle -- a wave, with wave number k or wavelength Lambda associated particle, that's p to the Iks. Yeah? But in particular, what is a plane with wavelength lambdas or wave numbers k look like? That's a plane. That is a wave. And that is an associated particle. So that's a wave with momentum k or a Lambdas particle. a wave, a plane wave e to the iks, how do I get h bar k out of it? Note the following, the derivative with respect to x. Multiply by h bar, divide by i, derivative withrespect to x e to ikx. That's suggestive. And I can write this as p e to the iks. So in particular, if I want to get hbar k, I can multiply by h bars and divide by  i. of h bar are. Delta x delta p is h bar. If you're ever in doubt, if you just remember, h bar has units of momentum times length. It's just the easiest way to remember it. You'll never forget it that way. So if h bar is a bar, it's a bar of momentum. If it's not, it is not a bar. So it's called a h bar, and it's the same as a bar with a bar length. momentum times length, what are the units of k? 1 over length. So does this dimensionally make sense? Yeah. Good. So dimensionally we haven't lied yet. So this makes it tempting to say something like, well, hell h bar upon i derivative. Well, that's not true. That's not how it works. So we're going to have to be a bit more precise. We'll say that momentum times length divided by length number momentum is the unit of momentum. with respect to x is equal in some-- question mark, quotation mark-- p. Right? So at this point it's just tempting to say, look, trust me, p is h bar upon idx. But I don't know about you, but I find that deeply, deeply unsatisfying. So let me ask the question: Is p equal to p in some other way, or is it just a question mark or a quotation mark in the middle of the word p? question slightly differently. We've followed the de Broglie relations, and we've been led to the idea that using wave functions that there's some relationship between the momentum, the observable quantity that you measure with sticks, and meters, and stuff. And this operator, this differential operator, h bar upon on i, is what we use to measure momentum. We use this operator to measure the momentum of a wave, which is a function of the direction of the wave, and so on. derivative with respect to x. Momentum is about velocities, which is like derivatives. By the way, my notation for dx is the partial derivative with respectto x. Just notation. So if this is supposed to be true in some sense, what is momentum have to do with a derivative? Momentum. is about velocity, and a derivative is about the ratio of velocity to mass. Moment. is the ratio between velocity and mass. It is about speed and mass, and it is a derivative of momentum. Mass times derivative with respect to time, velocity. And this ties into the most beautiful theorem in classical mechanics, which is the Noether's theorem, named after the mathematician who made it famous. Times mass. Mass times derivative. withrespect to time,. velocity. So what does it have to do with the derivative with. respect to position? And it's the same with mass times velocity, right? Times mass, velocity, position, time, position. And it works the same way with time and position. Noether's theorem underlies an enormous amount of classical mechanics, but also of quantum mechanics. Noether, incidentally, was the one who discovered it. And just out of curiosity, how many people have seen Noether's conjecture in class? That's a sin. That's so sad. That is a sin, that is so sad, that's such a sad, sad sin. It's a terrible, terrible sin. I'm so sorry, I'm sorry. I just want to know if you've seen it. a mathematician. There's a whole wonderful story about Emmy Noether. Ville went to her and was like, look, I'm trying to understand the notion of energy. And this guy down the hall, Einstein, he has a theory called general relativity about curved space times. And how that has something to do with energy. That's a great story. And that's the story of Emmy and Ville, and how they got to know each other. It's a wonderful story. do with gravity. But it doesn't make a lot of sense to me, because I don't even know how to define the energy. So how do you define momentum and energy in this guy's crazy theory? And so Noether, who was a mathematician, did all sorts of beautiful stuff in the 1930s and '40s. But he was a bit of a weird guy. He was a little bit crazy, but he had a great mind. And so he came up with this crazy theory. algebra, looked at the problem and was like I don't even know what it means in classical mechanics. So she went back to classical mechanics and, from first principles, came up with a good definition of momentum. This turns out to underlie the underlie underlie most of our understanding of the universe and the universe's laws of motion. It's a very exciting time to be alive in the world of quantum computing, says Professor David Wheeler, who has been at the forefront of the field for 20 years. To every symmetry is associated a conserved quantity. For example, translations. x goes to x plus some length l. This could be done for arbitrary length l, or translation by this much or that much. These are translations. What symmetry is? Well, for example, translation by l goes to l plus x plus x. This is a symmetric quantity. What is it? It's a quantity that is conserved. And it's conserved by Noether. Noether's idea of conserved quantities and symmetries has had enormous far reaching impact. Time translations, t goes to t plus capital T. Energy, which is time independent. Rotational symmetries. x, as a vector, goes to some rotation times x. What's conserved by virtue.is associated to translations? Conservation of momentum, p dot. Time translational symmetry. Energy. And rotations. x goes to x plus some rotation time x. x is the time independent energy of time translations. Energy is the energy of Time Translational Symmetry (TTS). TTS is a conserved quantity. of rotational symmetry? AUDIENCE: angular momentum. PROFESSOR: Angular momentum. Rock on. OK So quickly, I'm not going to prove to you Noether's theorem. It's one of the most beautiful and important theorems in physics, and you should all study it. But let me just convince you quickly that it's true. I'm going to show you why it's a beautiful, important, beautiful theorem. I'll be back in a few minutes. in classical mechanics. If I do an experiment here and I do it here, I get exactly the same results. And this was observed long before Noether pointed out why it was true in general. What does it mean to have transitional symmetry? It means that, if I do a test here and a test there, I can get the same result in both places. I translate the system into a different language. This is called 'transitional symmetry' and it is a type of symmetry. and nothing changes. That's what I mean by saying I have a symmetry. You do this thing, and nothing change. OK, so imagine I has a particle, a classical particle, and it's moving in some potential. This is u of x, right? And we know what the equations of x are. Cool? That’s what we’re trying to do here. We’ve got a symmetry, so we can’t change it. We have to wait and see what happens. motion are in classical mechanics from f equals ma p dot is equal to the force, which is minus the gradient of u. That's f equalsMa in terms of the potential. In this case, there's no gradient of 0, so the force is not the same as the potential, it's just the difference between the force and potential. The force is therefore the same, but the potential is not, so there's a difference between potential and force, and it's the force that determines the force. The only potential that has full translational symmetry in one dimension is translation invariant, i.e. constant. Noether's theorem. Less trivial is conservation of energy. I claim and she claims-- and she's right-- that if if you do an experiment here, do I get the same thing as doing my experiment here? OK? What's the force? AUDIENCE: 0. 0 gradient. So what's p dot? Yep. Solid. OK. What's 0.0 gradient? Yep, solid. the system has the same dynamics at one moment and a few moments later and, indeed, any amount of time later, if the laws of physics don't change in time, then there must be a conserved quantity called energy. And that's Noether's theorem. So, if you have a system that behaves in the same way at different times, you must have an energy that is conserved in some way. That's the principle of Noether’s theorem, which is the basis for the law of conservation of energy. This is the first step, but this still doesn't tell us what momentum exactly has to do with a derivative with respect to space. We see that there's a relationship between translations and momentum conservation, but what's the relationship? So let's do this. I'm going to define an operation called "momentum conservation" This is a new way of thinking about momentum conservation. It's a way of looking at the relationship between momentum conservation and translations. This is an example of how momentum conservation can be used to understand translations. translate by L. And what translate by L does is it takes f of x and it maps it to f of X minus L. So this is a thing that affects the translation. And why do I say that's a translation by L rather than minus L? Well, the reason is that L is a translation of f of f. And f of F of f is the number of letters that make up a word. So, for example, f of L is the length of a letter that makes up the word "L" point-- if you have some function like this, and it has a peak at 0, then after the translation, the peak is when x is equal to L. OK? So just to get the signs straight. So define this operation, which takes a function of x and translates it by. It's called the translation operation, or the translation of x by L. It takes x to translate a function into L, and then L to translate x back to x, and so on. F of x minus L can be written as a Taylor expansion around the point x. Around the point L equals 0.L, but leaves it otherwise identical. So let's do Taylor expansion for small L. Solet's consider how translations behave on functions. And this is really cute. Let's see how it works for a small function called f of X minus L. F of x plus L is written as f of x and L is f of f and L. And we can see how this works for small and large functions. this is equal to f of x minus L derivative with respect to x of f of X plus L squared over 2 derivative squared, two derivatives of x. Right? I'm just Taylor expanding. Nothing sneaky. Let's add the next term, actually. Let me do this on a whole new board. All right, so we have translate by L on f ofx. Now Taylor expanding minus L. derivative withrespect to x. of f plus L squares over 2-- I'm not giving myself enough space. with respect to x squared times f of x minus L cubed over 6 derivative cubed with respect to X plus dot, dot,dot. Everybody good with that? But this is a series that you should recognize, a particular Taylor series for a particular function. It's a Taylor expansion for a specific function, and you should know how to use it. The series is called the Taylor expansion of a function, or a Taylor series, and it's a very simple one to understand. the AUDIENCE: Exponential. e to the minus L derivative with respect to x f of x. Which is kind of awesome. So let's just check to make sure that this makes sense from dimensional grounds. So that's a derivative withrespect to x as units of 1 over 1 over 2 over 3 over 4 over 5 over 6 over 7 over 8 over 9 over 10 over 11 over 12 over 13 over 14 over 15 over 16 over 15. That's the exponential. e-to-the-minus L derivative. length. That's a length, so this is dimensionless, so we can exponentiate it. Now you might look at me and say, look, this is silly. You've taken an operation like derivative and exponentiated it. What does that mean? And that is what it means? [LAUGHTER] OK? So we're going to go to the next step in the story, which is the next part of the book, which will be published in the spring of 2015. do this all the time in quantum mechanics. We're going to do things like exponentiate operations. We'll talk about it in more detail, but we're always going to define it in this fashion as a formal power series. Questions? AUDIENCE: Can you transform operators from one space to another? PROFESSOR: Yes, we can. And we can do it in any way we want. We just have to know how to do it. We don't have to go into great detail. Oh, you totally can. But we'll come back to that. We're going to talk about operators next time. OK, so here's where we are. So from this what is a derivative with respect to x mean? What does a derivative With respect to X do? Well a derivativeWith respect x does the same thing as a derivative of x with respect x. That's what a derivative is for us. We'll talk about that in the next segment of the show. Back to the page you came from. to x is something that generates translations with respect to x through a Taylor expansion. If we have L be arbitrarily small, right? L is arbitrarily small. What is the translation by an arbitrarily small amount of f of x? Well, if L is arbitrary small, we can drop all of the translations by an arbitrary amount. If L is large enough, we drop all translations by a certain amount of x. We can then say that the translation of f to x is a translation of x by f. The derivative with respect to a position is something that tells you, or controls, or generates infinitesimal translations. And if you exponentiate it, you do it. So the derivative with. respect to x is telling us about infiniteimal translations, and the change is just Ldx.the higher order terms, and it's not a change in the position of x, it's just a change to the derivative of x to the position it's in. It's just the same as saying that x is in the same position as the position in which x lies. many, many, many times in a particular way, you get a macroscopic finite translation. So this gives us three things. Translations in x are generated by derivative with respect to x. But through Noether's theorem translations are associated to conservation of momentum. So you shouldn't be so worried about translations in x. In fact, they are associated with momentum, so you should be very happy with the translation you get. And so on and so on, until we get to the end of this article. In quantum mechanics, the derivative with respect to x is related to the momentum. "We're very interested in the action of things on functions, not just in positions, but on functions of position," he says. "It shouldn't be totally shocking" that in quantum mechanics the derivative is linked to momentum, he adds. 'It's really not totally shocking,' he says, "that we're interested in this kind of thing. It's not surprising that it's related to momentum' in some particular way. Similarly, translations in t are going to be generated by what operation? Derivative with respect to time. That seems plausible. Derivatives with. respect to, I don't know, an angle, a rotation. So derivative with respect. to time from Noether's theorem is associated with conservation of energy. that seems plausible, and so is derivative withrespect to an angle or rotation. And so on and so on, until we get to the end of this article. That's going to be associated with what? angular momentum? But angular momentum around the axis for whom this is the angle, so I'll call that z for the moment. And we're going to see these pop up over and over again. But here's the thing. We started out with these. We start out with this. We're going from here to this. And it's not going to get any easier or any less difficult. It's just going to take some time. three principles today, and we've let ourselves to some sort of association between the momentum and the derivative like this. OK? And I've given you some reason to believe that this isn't totally insane. Translations are deeply connected with conservation of momentum. Transitional symmetry is deeplyconnected with conservation momentum. And an infinitesimal translation is nothing but a derivative with respect to position. Those are deeply linked concepts. But I didn't derive anything. I gave you no derivation whatsoever of the relationship between d dx and the momentum. in quantum mechanics, p is represented by an operator, it's represented by the specific operator h bar upon I derivative with respect to x. And this is a declaration. OK? It is simply a fact. And when they say it's a fact, I say it is. And I'm not going to back down. I'm going to say it. I'll tell you what I think. And you can't stop me, OK? I'm telling you, I'm saying it. mean two things by that. In quantum mechanics, momentum is represented by derivative with respect to x times h bar upon i. Secondly, it is a fact that, if you take this expression and you work with the rest of the postulates, momentum can be expressed as a function of time and space. In other words, it can be said to be the product of time, space, and momentum. This is the result of the theory of quantum mechanics. It is also the case that momentum can also be expressed in terms of the time/space ratio. of quantum mechanics, including what's coming next lecture about operators and time evolution, you reproduce the physics of the real world. You reproduce it so well that no other models have even ever vaguely come close to the explanatory power of quantum mechanics. OK? It is. It is so good that no one has ever been able to explain it to you. It's so good, it's like a miracle. You can't understand it, but you can understand it. You just have to look at it. a fact. It is not true in some epistemic sense. You can't sit back and say, ah a priori starting with the integers we derive that p is equal to-- no, it's a model. But that's what physics does. Physics doesn't tell you what's true, it tells you what is a fact, and that's the way to look at it. It's not a fact in the sense that it's true in the way that we think it is. a priori did the world have to look like. Physics tells you this is a good model, and it works really well. And to the degree that it doesn't fit the data, it's wrong. OK? This isn't something we derive. This is something we declare. We declare that this is not the world as we know it. It's a different world. And we're trying to figure out how to make it better. We're not trying to make the world a better place. We call it our model, and then we use it to calculate stuff, and we see if it fits the real world. [LAUGHTER] I love MIT. I really do. So let me close off with the following observation. Out, please, please leave. Thank you. We live. We are MIT. We don't live at MIT, we live at home. We're MIT people, we're not MIT scientists, we are MIT people. And we live in MIT. in a world governed by probabilities. There's a finite probability that, at any given moment, that two pirates might walk into a room, OK? [LAUGHTER] You just never know. But those probabilities can be computed in quantum mechanics. And they're computed in the following ways. They're computed the following way in the world of quantum mechanics, which is to say, there's a probability of two pirates walking in at the same time. [APPLAUSE] And that's how quantum mechanics works. ways as we'll study in great detail. If I take a state, psi of x, which is equal to e to the ikx, this is a state that has definite momentum h bar k. Right? We claimed this. This was de Broglie and Davisson-Germer. Note the following, take this operator, and write it in a new way. This is the new way of looking at the state of a state. We'll study this in more detail later in the article. and act on this wave function with this operator. What do you get? Well, we already know, because we constructed it to have this property. P hat on psi of x-- and I'm going to call this psi sub k of x, because it has a definite k-- is equal. We already know this because it's a property of the wave function. And we know that k is equal to 1, so we can use this operator to get the result we want. to h bar k psi k of x. A state with a definite momentum has the property that, when you hit it with the operation associated with momentum, you get back the same function times a constant, and that constant is exactly the momentum we ascribe to that plane wave. A plane wave is a plane wave that has the same momentum as the state it is in. The state of the wave is known as the plane wave state. The plane wave has the momentum of the state in which it's in. Is that cool? Yeah? AUDIENCE: Question. Just with notation, what does the hat above the p [INAUDIBLE]? PROFESSOR: Good. So the hatabove the P is to remind you that P is on a number. It's an operation. It is a rule for acting on functions. We'll talk about that later in the show. Back to Mail Online home. back to the page you came from. The Daily Discussion is a weekly, offbeat look at stories you saw on CNN.com. in great detail next time. But here's what I want to emphasize. This is a state which is equal to all others in the sense that it's a perfectly reasonable wave function, but it's more equal because it has a simple interpretation. Right? The probability that I measure the momentum is the same as the probability that the wave function measures the momentum. The probability of the wave being in a state where it is in a certain position is the exact same as that of a state in which it is out of position. to be h bar k is one, and the probability that I measure it to be anything else is 0, correct? But I can always consider a state which is a superposition. Psi is equal to alpha, let's just do 1 over 2 e to the ikx. k1 x plus x plus k1 y plus y plus x is a state. The probability that this state is anything other than a state is 0. This state is called a "superposition" 1 over root 2 e to the minus ikx. Is this state a state with definite momentum? If I act on this state with the momentum operator, do I get back this state times a constant? No. That's not what we want. We want this state to be a constant. We call this i sub s-- if we do that, we get this state. We'll call this state i sub i s if we don't want to call it i sub ik s. interesting. And so it seems to be that if we have a state with definite momentum and we act on it with momentum operator, we get back its momentum. If we have. a state that's a superposition of different momentum and We act on. it with a momentum operator,. this is the case. And this is what happens when we use the momentum operator to get back momentum of a state. We get back the momentum of the state that we are acting on with the momentum. operator. gives us h bar k 1, this gives us hbar k2. So it changes which superposition we're talking about. We don't get back our same state. So the action of this operator on a state is going to tell us something about whether the state has definite value of h bar 1 or h bar 2. It's not the same state, it's just a different superposition that we get from the operator. We can't go back to what we were before. the momentum. And these coefficients are going to turn out to contain all the information about the probability of the system. This is the probability when norm squared that will measure the system to have momentum k1. And this coefficient norm squared is going to tell us the probability that the system will have a momentum of k1 or more. The probability that this will happen is known as the "momentum squared" (MPS) The MPS is a measure of the momentum of a system, and it can be used to predict future outcomes. we have momentum k2. So I think the current wave function is something like a superposition of 1/10 psi pirates plus 1 minus is 1/100 square root. To normalize it properly psi no pirates. And I'll leave you with pondering this probability. See you guys next time. [APPLAUSE] CHRISTOPHER SMITH: We'll be back next week with a new episode of The Daily Discussion, with a look at the latest developments in the world of quantum computing. We've come for Prof. Allan Adams. He's the man behind the scenes at the Royal College of Music. He has been a professor for more than 30 years and is a great admirer of the female form. Here he tells the story of his love for the fairest of dames, and of the tragic deaths of some of the most beautiful women he has ever met. He says: 'I see lovely shows of lovely dames. And descriptions of ladies dead and lovely nights. Of lovely nights' eyes, of foot, of eye, of brow. I see the antique pens do but express the beauty that you master now. So are all their praises but prophecies of this, our time. All you prefiguring. But though they had but diving eyes-- PROFESSOR: I was wrong about the probabilities. [LAUGHTER] [LAUGHLY] [Laughter] Laughter.] Laughter. Laughter! Laughed. Laughed! Laughs. CHRISTOPHER SMITH: But though they had but diving eyes, they had not skill enough you're worth to sing. For we which now behold these present days have eyes to behold. [LAUGHTER] But not tongues to praise. [APPLAUSE] It's not over. You wait, you wait, it's coming. It's coming, I'm telling you, you're going to hear it from the top of my voice. It'll be great. It will be great, I promise you. princes shall outlive this powerful rhyme. But you shall shine more bright in these contents that unswept stone besmear its sluttish tide. When wasteful war shall statues overturn and broils root out the work of masonry. Nor Mars his sword. Nor war's quick fire shall burn the living record of war. But war'squick fire shall burning the living history of the world. And the world will be a better place for having had it in the first place. your memory. Gainst death and all oblivious enmity shall you pace forth. Your praise shall still find room, even in the eyes of all posterity. So no judgment arise till you yourself judgment arise. You live in this and dwell in lover's eyes. [APPLAUSE] CHRISTOPHER SMITH: Verily happy Valentine's day. VerilyHappy Valentine’s day, all of you. You are loved by all of us, and we love you. upon you. May your day be filled with love and poetry. Whatever state you're in, we will always love you. Signed, Jack Florian, James [INAUDIBLE]. [LAUGHTER] PROFESSOR: Thank you, sir. Thank you. [APPLAUSE] CHRISTOPHER SMITH: Now we go. We'll be back in a minute. We're going to go to the next station. We've got a few minutes left.