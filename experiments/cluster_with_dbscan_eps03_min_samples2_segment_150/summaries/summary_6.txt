and we also have a bias term that gets added to the output of moving each window on each location of our input we refer to it as a volume simply because it sort of looks like a cube. If you have a whole bunch of filters then you're going to end up stacking up all of the different outputs from taking each one of your different filters and running it over your input and you get something that has a number of channels in the output. Think of it like that I I don't really think of it as like a layer. CNN is where you have like an image like a person in it and you need to Output another image except each pixel has basically been like labeled with a person. In that case your output is the same size as your input which gets a little bit weird and we'll talk about that more later how you because at face value that would be like super inefficient all of your convolutions are on these just huge inputs. If you want to decrease the size of this volume because it can get quite unwieldy you can do pooling simply just looking at each. a little timeline here starting from uh alexnet and moving forward. laneet is something that was created quite a while ago. Alexnet in 2012 was a a big groundbreaking feat in that it proposed stacking layers of convolutions Max poolings following it up by fully connected layers and coming up with not a very deep network. This kind of uh turned a lot of heads when it achieved a around 17 error rate on imagenet. Inception Nets were proposed in 1990 by Yen lacun and he he kind of pioneered that pattern for today. The next slide should have an updated drawing that's hopefully a lot easier to understand than the previous one. This has a convolutional layer followed by a Max pooling layer. Three dense layers are following this last stack of convolutions and Max pooled. The motivation behind this is you want a deeper neural network. It computes a little bit better because computers evolve CPU power is able to handle these high order Matrix computations. The next slide is a visualization of how you have multiple layers that are stacked they're pulled together. so these are some things that these models wanted to optimize over time accuracy performance and model size um model size is something that has a trade-off if you get too big you lose out on other metrics like accuracy. performance is something directly corresponds to depthwise convolutions and mobile nuts for Edge Computing and things like that. You want to drastically reduce the number of computations that you want to do yep that is basically everything for today thank you guys for coming oh and there will also be a quiz. Rohan: I want to start today by sort of recapping what we talked about last Tuesday. I apologize that was kind of a rough introduction that was uh that was me making a couple of last minute edits that probably hurt more than they helped. Rohan: When you have images and a CNN you can simply just do convolutions instead of your normal matrix multiplication on a vector. When we do a convolution operation we treat it like a layer like with standard dense neural networks. We can still take partial derivatives of our loss with respect to our parameters.