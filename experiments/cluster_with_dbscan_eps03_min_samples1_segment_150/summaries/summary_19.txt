Professor: We're just start with a short review problem on rugged landscapes. And then we'll get into the core topic of the class, which is evolutionary game theory. And we'll discuss why it is that you don't need to invoke any notion of rationality. Then we'll try to understand this difference to human decision making, professor says. The course is part of MIT OpenCourseWare. To make a donation or view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu. know what a Nash equilibrium is in the context of game theory versus an evolutionary stable strategy in this context. And we'll say something about the evolution of cooperation and experiments that one can do with microbial populations in the laboratory. Are there any questions before I get started? All right, so just on this question of evolutionary paths, on Tuesday we discussed the Weinreich paper where he talked about sort of different models that you might use to try to make estimates of the path that evolution might take. Each time that an individual divides, it has a 1 in a million probability of mutating. And that's a per base pair mutation rate. Originally when we discussed this, we were talking about just mutations, maybe A's and B's. But now, what we're going to have is just a genotype. And I'll show you what I mean by that. I'm going to give you some fitness values just so that we can be clear about why it is that there might be different paths. short genome that's string length 2. So we're assuming that this is relative fitness as compared to the 0, 0 state. And the question is, what's going to happen eventually? And in particular, what path will be taken on this landscape here? You can start thinking about it while I write out some possibilities that we can vote for, and I'll give you a minute to think about it. So don't-- Are there any questions about what I'm trying to ask here? All 1,000 individuals are in the 0, 0 state. There are initially no mutants in the population. But they're just replicating at some rate. Every now and then, mutation's going to occur. Now one thing we have to answer is whether these are nearly neutral mutations. Verbally yes or no? Ready? Three, two, one. AUDIENCE: No. PROFESSOR: No, right. And that's because we want to ask for, if it's nearly neutral, is the magnitude of S times N much greater or much less than 1? If they're much greater than 1, as is the case here, then we're in a nice, simple regime. Professor: If we start out with all 0, 0, and then one mutation [INAUDIBLE]? And if that mutation-- are we assuming that that mutation is 0, 1 and then figuring out how to fix it? Professor: You have to keep track of lots of different things, and which regime we're in and so forth. If you had one copy of each of these two mutant individuals in the population, that's the answer to what is the probability that this0, 1 mutant would fix in thePopulation. a minute. But if you don't understand what's going on, it'll take you an hour. Yes? No? Maybe? Well, I'll give you another 20 seconds. Hopefully, you've been thinking about it while we've been talking. All right, do you need more time? Why don't we go ahead and vote? I think it's very likely that we will not be at the kind of 100% mark, in which case you'll have a chance to talk about it and think about it some more. a group of D's and a group of B's here, which means that everybody-- AUDIENCE: Let's fight. PROFESSOR: All right, so everybody thinks that everybody agrees with them, but you just need to look a little bit more long distance. So turn to a pseudo-neighbor. You should be able to find somebody there. It's roughly even here, so you should be can't find someone. So I don't see much in the way of vibrant discussion and argument. a group, so don't be too disappointed if you don't get finished there. But I do want to see kind of where we are. Ready? Three, two, one. OK, so it still is, maybe, split roughly equally between D and maybe a B-ish and some C's. All right, does somebody want to volunteer their explanation? Yes. And you're saying, all right, maybe because of the extra, that 1, 0 is somehow more fit than 0, 1. some relative rates or ratios for which reason? Audience: Well, I took 0.02 and then 0.1, which is 1/5. And then I decided that that should be around what it is, but slightly less, because there's also a chance that [INAUDIBLE]. PROFESSOR: OK, yes. I think the arguments there-- there's a lot of truth to the arguments that you're saying. Yeah, it's a little-- right. from 0, 0 to 0, 1. I first checked S, N and it's non-neutral. So probably [INAUDIBLE] S. So the probability for that first path would be the S for 0,1, so it's 0.02, which is 1/50, multiplied by the probability that the other 1, 0 would die out. So this is like these problems that we did a couple weeks ago, where we said, you imagine in the population you have a couple different kinds of mutants. if we ask, we're going to start with an entire population at 0, 0, and now these mutations will be occurring randomly at some rate. And we're trying to figure out the relative probability that it's going to take kind of one path or another. Do you see the difference between these two questions? So indeed, this is the correct answer to a different question. And so it'sgoing to end up being D. And now we want to try to figureout how to get there. Because I think it is a bit tricky. It's when S1-- AUDIENCE: [INAUDIBLE]. PROFESSOR: Yeah, that's right. All right, so established-- when we say established, what we mean is that this corresponds to saying that this probability that we talked about before this X sub i is approximately equal to 1. So this question is, how many individuals do you have to get to in the population before you're very likely to fix? And what we found is that that number established went as 1 over the selection coefficient. One is the time between the time to fix, which went as 1 over S log of NS, right? So we can ignore clonal interference if this is much larger than that. No clonal interfered corresponds to mu N log NS much less than 1. Is that right? Did I do it right? OK. So and once again, there are multiple S's, and it's easy to get kind of upset about this. But you can just use whichever S would be-- which S would you want to use to be kind of-- of those two steps-- going to 0, 1 or 1, 0. And in particular, this is like a chemical reaction, where we have some chemical state here. And what we know is we know the ratio of those rates. And that's everything we need to know to calculate the relative probabilities of taking those states. So this is how we get 1/6 instead of 1/5. Because this thing is1/5 of that. So it's like 1, and then 1, 5. And this is actually, in principle, not quite answering the question that I asked. or something like that. I'll think about that when designing. Problems. In this system, 0, 0 eventually becomes 1, 1. So we are guaranteed that we will eventually evolve to this peak in the fitness landscape. And of course, there are non-zero probabilities of going backwards. It's just that they are reduced. Over long time scales, there's going to be an equilibrium that distribution over all. And actually, you can prove, for those of you who are interested in such things, that over long time Scale. these states, where the probability of being in a particular state will-- it goes as the fitness. It scales as the relative fitness to the Nth power. So we talk about these fitness landscapes as energy landscapes. And indeed, in this regime where you have small mutation rates, then it's going to be a detailed balance. And it's actually a thermodynamic system. So then in that case, you can make a correspondence between everything that we normally talk about, where fitness is like energy and population size is like temperature. cohered at this peak in the finished landscape. And so what we have is we have r is relative fitness 1 and 1.02. The rate of going forward, well, we sample mutations at a rate mu. And this is mu only, because we don't have to worry about going up the landscape. We just have the 0, 0 and the0, 1 states, just so we donâ€™t have to worrying about going down the landscape, for example. So if you want to calculate a problem going from 0, 1 to0, 0, then [INAUDIBLE] that would just be-- I guess I'm not sure. big number is our problem. So we should be able to figure this out, though. Because this new r is 1/1.02. So for example, have 1 minus 1.02 to the 1,000. All right, so this is a negative number, but this is also negative number too. We end up with 0.02-- AUDIENCE: 200. PROFESSOR: Is it 200? Yeah, you're keeping only the first, which, since it's much larger than 1, it's bigger than 200. Professor: I think that you did it 1.02 to the 100 rather than 1.01 to the 1,000. AUDIENCE: 4 times 10 to the 8. PROFESSOR: Yes, sorry, I was just saying this doesn't-- so this is why I'm saying you always check to make sure that your calculation makes any sense at all. But it's not this, right? Audience: yes, [INAUDIBLE]. PROFessor: Yeah, because this didn't make sense, because it was of the same order as-- well, this would be larger than 1 over N, so it's totally nonsensical. fixation of a neutral mutation. This is a deleterious mutation. It's not even nearly neutral. So it has to be much less than 1 over N, right? So this whole thing is 10 to the minus 10, or something like that? All right, any other questions about how to think about these sorts of evolutionary dynamics with presence of mutation, fixation, everything? Yeah. Can we handle a situation where [INAUDIBLE] interference is important at this point? PROFESSOR: Yeah, so this is what you do in rate, you don't even do successive fixations. So it may be that neither state ever actually fixes, because it could be that the 1, 0 state is growing exponentially, but is a minority of the population. And it has a lot of the same behaviors, in the sense of exponential suppression of probabilities as a function of the depth and the width of the valley you're trying to traverse. And there's some very nice papers, if you're interested in looking at this stuff. syllabus that I mentioned. I think the most important thing to stress when thinking about evolutionary game theory is just that this point that we don't need to assume anything about rationality. Instead, you simply have mutations that sample different strategies. And then you have differences in fitness that just lead to evolution towards the same solutions of the game. So it's evolution to the game solutions, so the Nash equilibrium, for example. And the more fit individuals spread in the population. And somehow, you evolve to the same or similar solutions. we have a 0, 0 state that has some fitness. 0, 1 has a higher fitness, and so forth. But in general, these fitness values may depend upon what the population composition is. And in that situation, then you want to use evolutionary game theory. For example, you can have situations where the population evolves to lower fitness. So it's just important. If the fitnesses depend on composition-- this is the population compositions-- then you cannot even define a fitness landscape. Just knowing the fitness of a pure population is not actually enough information to know that it's going to be selected for. It's still possible that in a mixed population, the genome 0 may actually have higher fitness than the genome 1.1. And once you kind of study these things, it's kind of clear that once you study them, you can't really tell what the fitness is of a population. The key is to look at the whole population, not just one or two, and try to find out what it's like to live in that population. it can happen. But then it's easy to then go back to the lab and forget that it's true. I think that the more formal evolutionary game theory thing-- these two-player games that you guys just read about-- I think they're important because they tell you what are the possible outcomes of measurements or of systems, even in the most simple situation where everything's linear. Now, when things are not linear, of course you can get even richer dynamics. But in this case, we'll see how this plays out. practice, you basically get the categories of outcomes that we saw there. So it's what you would get if you just had some two-player game like they study in game theory, but in a population of 1,000 or whatnot. You just made a bunch of random pairwise interactions. And then you had them do that again over time. And it's really importing the kind of approach, or the nomenclature, from conventional game theory and then immediately applying it to populations where you just assume that all the individuals have equal probability of interacting. The payouts that you read about in Chapter Four are kind of what would happen in that sort of situation, where everybody's interacting with everybody else with equal probability. Depending upon the strategy that these guys are following, you get different payouts. And this is telling us about the payout that the A individual gets depending on what he does, and depending upon what his opponent does. Now, we're not explicitly saying what the payout to the B individual is, but we're assuming that this is a symmetric game, so you could figure it out by looking at the opposite entry. a fitness, whereas B also gets little a fitness, because it's a symmetric game. So the case it's different is when we're in the diagonals. And from this framework, you can see that there are going to be already a bunch of kind of non-trivial things that can happen, even in this regime where everything's linear. And the probably best well-known of these is this Prisoner's Dilemma, which is the standard model of cooperation in the field of game theory. be in trouble, et cetera. So the idea of the prisoner's dilemma is that if you set up these jail sentences in the right way, then it could be the case that each individual has the incentive to confess. And you can come up with some reasonable payout structure that has that property. And we'll call this-- so this is for individual one, say and individual two. So there are different strategies you can follow. And do you guys remember from the reading slash my explanation how to read these charts? just to remind ourselves, what is the Nash equilibrium of this game? And I know that you read about it last night. Well, use your cards. Is it C or is it D? Or is there no Nash equilibrium, you can flash something else. So at least we have a majority that are D, but it's not all of them. And I think this is basically a reflection-- and D. So these are good things, OK? These are years off that you get as a result of doing one thing or another. is indeed the Nash equilibrium. It's to do this strategy D that we're saying here. All right, now the question is why? And part of the challenge here is just understanding how to read these charts. Now, if you look at this chart, you say, well, gee, that is a shame. Because 1 is just not the biggest number you see here. And indeed, the important point to note here is that if both players had followed this strategy C for cooperate, D for defect, then both individuals would be getting fitness 3. So the problem here is, it's always better to play D. In a Nash equilibrium, if everyone's playing that strategy, then nobody has the incentive to change strategy. So if you're in this state, what you have a choice of is to switch to the cooperate strategy, which would be the D strategy. The question is whether you as an individual would have the incentives to switch. And the answer is no, because you have control over this rows. The column is specified by the rest of the population, and you can't do anything about it. General, in terms of game theory, we like it when the mean of these two is smaller than this one. That's why you're asking, right? Exactly, because that's right. So yeah, so that's a slightly more complicated situation, because in that situation, then, if you had two rational agents, say, playing this game, then you could alternate cooperation and defection. And that would actually be the ultimate form of cooperation in such a game, because you could actually get a higher payout by alternating. cooperator and for the defector. Do you understand? So what should these things look like? I'd like to encourage you to-- I'll give you 30 seconds to try to draw what this should look like. This is going to be the expected payout for a lone individual given the rest of the population is following some fraction of cooperator. DoYou guys understand what I'm asking you to do? Because I'm a little bit concerned that there are very few plots in front. are lines. But you can imagine that the only thing that's important are how these lines cross each other. So for example, there are only a few different things that can happen. You can have one strategy that dominates, which is what occurred here. And surprisingly, that does not mean that that strategy is higher fitness, in the sense that you may evolve to a state of low fitness. That's what's weird. YouCan have coexistence, or you can have bi-stability. terms of these lines if we draw them? So this is payout as a function of the fraction that is playing the A strategy. Should the lines cross? Yes or no? Ready, three, two, one. AUDIENCE: Yes. PROFESSOR: Yes, and indeed, in principle, the math that we do in all these situations is kind of super simple. Yet it's easy to get confused about what's going on in all of these situations, says the professor. you to be influenced by this. So think about it for 30 seconds. Do you need more time? Let's go see where we are. Ready, three, two, one. All right, so most of the group is agreeing in this case, neither are the Nash equilibrium. Does that mean that this game has no Nash equilibrium? Yes or no, verbally-- ready, 3, 2, 1. AUDIENCE: No. PROFESSOR: No, it does not mean that. This game has a Nash equilibrium and indeed, all games like this have Nash equilibria. In a population, if you have genetic A's and genetic B's that are each giving birth to their own type, then you evolve to some coexistence of genotypes. Whereas in this situation over here, we have coexistence. Does not matter where you start. So long as you have some members of both A and B in the population, you'll always evolve to the same equilibrium. And indeed, one of the things that we've been excited PROFESSOR: Exactly, so the Nash equilibrium mixed strategy plays A with probability. In many cases, isogenic populations of microbes can exhibit a diversity of phenotypes as a result of stochastic gene expression and bi-stability. Another question is, what is the evolution explanation for why that behavior might have evolved? Now in general, we cannot prove why something evolved, but we can make educated guesses that make experimentally testable hypotheses. And for example, in the experiment that we've been doing, we're looking at bi-modality in expression of the galactose genes in yeast. you make the mutants that always turn on or always don't turn on these genes, then they're actually playing game where you get this exact thing. So that's saying that maybe the wild type that follows this stochastic, mixed strategy may be implementing the solution of some game. There are other possible explanations to this. In the coming weeks, we'll talk about this idea of bet hedging-- that given uncertain or fluctuating environments, it may be advantageous for clonal populations to have a variety of different strategies to cope with that uncertainty. equal to this guy. So that's what I just said-- that it doesn't matter what you do. If everyone else is doing p star, you have the same fitness. That's saying it's a Nash equilibrium. Whereas there's another interesting kind of statement here, that you can't unilaterally increase your fitness by switching. That you don't have the incentive to change strategy. It's true that you're not dis-incentivized. So it's not a strict Nash equilibrium, but it's an equality. not the definition of that. But this thing is true, which means that it's a Nash equilibrium. And if you have questions about this, I'm happy to answer it. It's explained in the book as well. We are out of time, so I should let you go. But good luck on the exam next Thursday. If you have Questions and you want to meet with me, I am available on Tuesday. So please let me know. I'll be happy to talk to you.