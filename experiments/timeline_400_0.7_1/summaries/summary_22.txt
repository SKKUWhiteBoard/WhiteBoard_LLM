Robotics is a really cool and important direction for the future. I really believe that we are moving towards a world where so many routine tasks are taken off your plate. I like to think of robots as as the machines that put computing in motion and give give our our machines in the world the ability to navigate and to manipulate the world. We have artificial intelligence which enables machines to see to hear and to communicate and to make decisions like humans and then we have machine learning and to me machine learning is the key. is about learning from and making predictions on data and this kind of application of machine learning is Broad it it applies to cognitive tasks and physical tasks but regardless of the task we can characterize how machine learning works as using data to answer questions that are either descriptive predictive or prescriptive. In the context of robots we have three types of learning and you have seen different aspects of these methodologies throughout the course we have supervised learning and unsupervised learning and then we have reinforcement learning which is about learning. Robots have a cycle that most often consists of three steps we have perception a perception step we have a planning and reasoning step and we have an action step and so this is what we are going to talk about today. We use data this is manually labeled data that gets fed into a convolutional neural network and then the labels are used to classify what the data is so for instance for this image we may have classifications like car duck Road and we do this so that when the system when the car sees a new image the car could say oh this is a this is ducks on road now. to do given input reinforcement learning is causing a huge revolution in robotics. Reinforcement learning is concerned with how intelligent agents ought to take action in an environment in order to maximize the notion of a cumulative reward. In order to get the simulation to drive a real robot we actually need to think about the Dynamics of the robot and so in other words we have to take into account what the vehicle looks like and its kinematics what are its Dynamics and so it's really cool because really we are now able to train in simulation. In 1995 a Carnegie Mellon project called nav lab built a car that was driven by a machine learning engine called Alvin and Alvin drove this car all the way from Washington DC to Los Angeles. The car was in autonomous mode for a large part of the highway driving but there was always a student there right ready to um to take control and the car did not did not drive inonomous mode when there were when it was raining or when there was a lot of congestion or when the car had to had to take exits. Now 1995 is a long time ago right I mean it's before many of you were born. This work um computers needed about 10 minutes to analyze an image can you imagine okay so how do you go from that to enabling an autonomous vehicle to drive at 90 kilometers an hour well um what they did was they they developed some very fast solutions for paring down the image to only the the the aspects that they needed to look at. They assumed that there were no obstacles in the world which made the problem much easier because all the car had to do was to stay on on the road. This has been a game changer for autonomous cars and we're getting back to the connection between hardware and software. Alexander: We have very effective and Deployable solutions for robot cars that move safely in Easy environments where there aren't many static nor moving obstacles. Many companies and research teams are deploying and developing self-driving cars. Many of these preconditions revolve around certainty in perception planning learning reasoning and execution before we can get to Robo taxi but we can have many other robot solutions that are much that that can happen today. Alexander: We can use deep learning and reinforcement learning to take us from images ofroads onto steering and throttle and what you can do with this is really great. Alexander developed the Vista simulator. The Vista simulator can model multiple agents multiple types of sensors and multiple types. of agent to agent interaction. The solution also allows us to to localize the the vehicle so it's really super exciting okay so we can. We can get this human-like control but assuming light control requires a lot of data and I've told you at the beginning that we have to be careful with the data. From this from this data this data is processed and it's from thisData we can learn to maximize the likelihood of particular control signals for particular situations.  liquid networks are Dynamic causal models and I want to show some more examples that explain how these models are Dynamic ozone models. These are models that essentially test the data that we have used to train a human pilot to drive a drone. We're able to extract decision trees from these kinds of solutions and these decision trees provide understandable explanations from human understandable explanations. This is really important for safety systems all right so let's see some examples of the data we've used to test this data and we've had a pilot drive a Drone to test these models. that yields models that generalize to unseen scenarios essentially addressing a challenge with today's neural networks that do not generalize well to unseen test scenarios because the models are so fast and and compact you can train them online and on edge devices. We have one project that is looking at whether we can understand the lives of whales and so what do I mean by this so here is an example where we have used a robotic drone to find whales and look at what they do and track them and here is some some clips from what the system is able to do. your dimensions and can create a bespoke shoe just for you. All the all the clothing all the items in our environment can kind of awaken our clothing could become robots. The temperature could get adjusted automatically by monitoring people's comfort and gesture. Just-in-time Holograms could be used to make the virtual world much more much more realistic much more connected and so here they're discussing the the design of a new flying car and let's say we have these flying cars and then we can integrate these cars with the it infrastructure.