The third lecture on Foundation mulative AI will cover chat GPT. Chat GP was the the tool or the the AI that really made people understand this is different now. Next time we'll talk about stable diffusion image generation and then we will talk about emerging Foundation models basically Foundation models generative AI in the commercial space. The lecture on AI ethics and regulation as well as a panel will end with the lecture onAI ethics andregulation. The final lecture will be on the bet that open Ai and Ilia the head researcher did in terms of what actually would lead to CHP and how in hindsight it might be quite easy. GPT relies on a lot of tricks and Engineering insights and breakthroughs that we're not going to cover here. We have a robot or AI model here that's able to take a prompt and an answer and then give it a score like let's say between one and five and say how good is this. What we solve now is that we we know what's good or bad dialogue. We spent 99% of our time in computer on on this preaching this Transformer to predict the next word based on previous words. make very high level um statement but of course the nuances matters and I think it's quite interesting uh I took this quote from a general from the 18 and 1700s and he says this quote that P Theory which sets itself in opposition to the mind and what he meant was that he's a general so he fights in battles and War and at the time people loved to come up and theorize around War like we should have certain rules and how soldiers should behave in fighting and stuff like that but he's like well I've been in War uh and Wars don't comply to rules first off. Genty pre-trained is the self supervised step of how you train this and arrive at this model and then the Transformer is the basically the engine behind it in some sense. Transformer has much less and has to relearn a lot of this data but since we have so much data and we can afford that we can train on a scale that we haven't seen before so that's also why this works so well so now we have a language model that can train this model. We're just going to directly incorporate information from I and when to the Target. know we know or the computer knows somehow by just downloading the text that what this whole sequence is but when it trains this AI model it hides part of it right so it just inputs I to the AI model and then it's supposed to do something with it. So you you basically would allow the model to uh guess and then maybe it's off right and then you can give some negative feedback uh and then when it gets it right you can given some positive feedback right so this is the high level uh what we want to accomplish. We're going to create scores or predictions for all words in the L like in the human you know vocabulary in the English vocabulary that sounds extremely expensive and it is quite expensive and so I have different tricks to make this work. The first version it was using 175 billion parameters and just training the the final model cost around $5 million just in in Compu electricity bills right that's how huge and much compute they spent on this and uh again so it's a very very simple approach but it's Â a certain scale that's that's never been seen before. a good job you also wants to able to incorporate the previous word and the features from there so you kind of also processes and includes into the second Vector both the previousword and the current word to create a new representation of the whole sentence so far. Then it uses that to to kind of predict the the next Target okay we go on and we do the same thing um and uh of course we do this for whole sent and I think what's this sounds maybe trival but the thing that's important to notice here is that for every step here that's label with the same uh digit you know they can all be done in parallel. these are extremely extremely popular and a version of them called uh lstm long short-term memory networks um it performs really really well and some people say it performs you know almost better than Transformers a lot of times but they just take them longer to train because we're going to realize why it one a point but they work very really well. For new networks memory is very hard so it's hard for networks to remember things so let's say you know that that if you read a book or you watch a movie if you want to understand the end part it might be good to kind of go back and look at the the start starting part of the book or something. in parallel it's the same step and this is true for all of these steps yes this sense when we compute a output distribution over all the words later like as a prediction we talked about the first thing. The training is the most expensive part uh because then you op you optimize and and you do back propagation to update update your parameters which is very very expensive when You' when you kind of uh when it's done you freeze it and you don't update things more and it's going to be much faster to run. more data to start doing a good job but there's also another thing that we're uh you know really forgetting here right so in a recuit network things are processed one at a time so the the model can figure out that you know Financial comes after the because it sees the first and then Financial but in a Transformer you know in the below here like if the only thing you see is the word and they're all F to you know for for if you look at the prediction we going to do at at step number nine if you see all these words the same time right there's some kind of comp like you can permute all the words and you basically see the same thing so there's no sequ. The model now has been trained on a vast amount of data from you know any Source on internet you can imagine right so novels Wikipedia Facebook posts. How you how users are going to use this is through some chat bot right so it's dialogue like human dialogue is what they call it. We want to be able to hone in and focus and adjust itself a little bit by training only on human dialogue so we going we going to go and collect the best data we have of human dialogue from whatever source that we have. about is to give the most likely next word but if you want to generate a sentence right you don't really care about optimizing the likelihood of the next word you you care about the accumulated likelihood of your whole sentence. So somehow we're too greedy we should be a little bit more long-term optimizing. The more the longer sequence and the more context or the longer prompt you have the more specific prompt the more Peak your distribution will be because the more information the model have around your specific context in use case the more it knows how to collapse into a space. is where we're going to do reinforcement learning from Human feedback uh and that's what open AI does on chtp and this was very very hyped for a long time but now people talk less about it uh okay so what do we do well we have a great model that's been fine tune on dialogue and it's able to generate really good answers still uh to different prompts so uh we'reGoing to run this model now on a collection of prompts and we're Going to generate four. delayed feedback so uh in reinforcement learning we're going to have our our starting point of a really good model but we'regoing to allow it to start generating things right it generates a word puts it in its own input and it reruns itself so it becomes a longer longer sequence one over at a time so we start off with this I and we now have a probability distribution and we decide what to go for next and we go with went and then we have a few options again and we we take a next step two and again there's no at this point there're no feedback we don't know if we're doing a good job. gratification actually leads to very non- GRE and and independent robustness so these are the consequence of applying reinforcement learning where you only get feedback at the very end so there's less you know supervision right you're more on your own and you have to H deal with an uncertainty of not having constant feedback. Okay so we've solved our problems uh we used human I mean we actually paid human beings for label data which is not maybe that goes against our principles here but but but uh we. Collaboration with neuroscientist in deep learning is is quite quite rare actually. If you look at Transformer Works uh if you mask a word uh then you will like then you'll only um okay I if you do this you know if only predict the last word based on previous words.and then it it just like oh this works now and they are not prbly completely conscious themselves about what they were inspired by you know so does that mean that we not have collaborations neuroscientists yeah. Lang models are very humanik even it's in its mistake they're like well they're somehow they're biased and they have stereotypes around things. They suffer from wishful thinking and some type of imagination where they rather be you know make you happy than being completely truthful. They do like more expensive than or like this is like the best um yeah I think so what are some what areSome challenges of these large Lang models well uh one challenge is to uh make them behave like we want them to. Reinforcement learning techniques of how to do planning well so how to incorporate planning is something that people talk about a lot and then of course multimodalities. It's not hard to see that this idea of predicting next word based on previous words corresponds really well to videos just to kind of predict the next frame based onPrevious frames. Of course it's more expensive again because it has to run for longer and stuff but it's very very useful. of course it is more expensive because it's a high dimensional picture or image but clearly you can learn a lot about the World by looking at videos. the text part and get a multimodality model that's able to do both in a really really sophisticated way uh also something that I think these these people are working on all right thank you thank you for your time. The next step is to get a model that can do both the text and the video part in a way that's really sophisticated, I think that's something that we're working on right now. Thank you for all your time and I'll see you next week.