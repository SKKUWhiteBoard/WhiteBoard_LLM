Third lecture on Foundation mulative AI. Next time we'll talk about stable diffusion image generation. We'll have two guest speakers and then we'll end with the lecture on AI ethics and regulation as well as a panel. We apply this self-supervised learning where we learn without label data so we can get as much data as we want because there's no human being in the loop. There's no limit how much we can scale this up and what we get from this by learning from observation and learning from the data directly is a very contextual understanding of meaning. Force things to comply to Simple Rules right it kind of abandons our ability to understand and compress what we're seeing and deals with that chaos directly that's why AI is so powerful and so humanlike. I took this quote from a general from the 18 and 1700s and he says this quote that P Theory which sets itself in opposition to the mind and what he meant was that he's a general so he fights in battles and War and at the time people loved to come up and theorize around War. so we have a sequence of words and and then we're just going to try to predict uh the next word based on previous words so let's say we have uh we start with i here as input. Then we want to someh predict the Target right so we know we know or the computer knows somehow by just downloading the text that what this whole sequence is but when it trains this AI model it hides part of it right so it just inputs I to the AI model and then the model is supposed to do something with it. We're going to create scores or predictions for all words in the L like in the human you know vocabulary in the English vocabulary that sounds extremely expensive and it is quite expensive and so I have different tricks to make this work.then it kind of gets it right and then you give some positive feedback back and we're going to kind of do this. Then we're going to pay pay actual human beings to score them and say are they good or not. We want them to be a little bit politically correct at least at least right and and and we don't want to rely on it as much as possible. like a a specific token that says we're happy until we complete a complete sentence for example um and this is kind of expensive to do because you have to generate one thing at a time but of course training is is much faster. How to incorporate planning is something that people talk about a lot and then of course multimodalities so it's not hard to see that this idea of predicting next word based on previous words corresponds really well to videos just to kind of predict the next frame based onPrevious frames. CTP was trained at a scale with an amount of data and parameters that we never seen before so this is a a a year old now but this is I think this was 3.5 or something the first version it was using 175 billion parameters and just training the the final model cost around $5 million just in in Compu electricity bills. Transformer has much less structure and has to relearn a lot of this structure but since we have so much data and we don't need to have labeled data we have we have. is that for every step here that's label with the same uh digit you know they can all be done in parallel so everything at step two here can be do in parallel they don't need to wait for anything. This is called a recurrent new network when we process things this in a sequential way H we try to Pary as much as possible but your current process depends on the previous the previous step and things flow forward this in kind of this sequential way right so to get from uh you know for the information from I to go to the information prob being processed step number nine basically right when you want to predict the period has to travel eight or nine steps here to to to uh be used. and it's going to be much faster to run so it's much less uh uh well that's a modification but uh it's a little bit less sensitive in a sense uh we care about both being fast uh and yeah I mean but somehow H this is going to be much much faster to train than a recurr network so you're going to get much much better performance and then the difference in deployment is less uh significant okay but during training we can do this because we not upend the words we just see them in the sequence we can doing this. just you know words there's no sequence anymore because everything is connected in Transformer but recur not there is still the sequence by how by virtue of how things are processed so how we solve this that is that for for the Transformer we're just going to add to each word a positional encoding so we just add the position again. The Transformer has to figure out if the sequence matter it should use that information even but it now has that information at its disposal because we're going to encode a sequential structure. It's like seeing all the words in a book at the same time like it's fast but it's very confusing. if you read a book or you watch a movie if you want to understand the end part it might be good to kind of go back and look at the the start starting part of the book or something you know or or it's good if you remember that information but probably you know if you don't remember you have to go back to look it up. In a Rec Network Rec Network because we're processing things uh sequentially here so to for something to be used like to for for information about the first uh word in the sequence to be use the last step here. good or bad dialogue so we've solved that okay and the last two problems we are going to solve by using reinforcement learning so what is reinforcement learning well we talked about this a little bit before but uh something is very important and characteristics of reinforcement learning is this delayed feedback. If it doesn't have data run a context or about you and your interest as a person it it won't be able to tailor to you right they cannot create Magic out of thin air it can only do the best of The Prompt and knowledge has so far. is about like how do you figure out what actually helps you reach your goal and optimizing your score function even if it's delayed um okay so another thing in doing this that's very very important it's exploration versus exploitation so let's say now basically that our model has seen these two different cases and have received two feedbacks right. In one of these you will got a pretty good score and in one uh you know in the lower here you got apretty bad score. The robot that just H try to replicate the the human beings putting scores on the answers that we generated prompts. gratification actually leads to very non- GRE and and independent robustness so these are the consequence of applying reinforcement learning where you only get feedback at the very end so there's less you know supervision right you're more on your own. H deal with an uncertainty of not having constant feedback you have to figure out things by yourself which leads to you being more robust and also again in reinforcement learn here the only thing we care about is the signal at the end so we don't care about making the best next step. We care about optimizing the whole output so we're now addressing these things. The Transformer is based on how a normal person learns right when you're learning a new content you to Rel it with everything else you know yeah so I'm just I mean this yeah okay uh so the question is basically is the Transformer inspired by research about how we our kids learn right how the brain works yeah I mean you're going to find a lot of work around you know making those connections and uh then there's a huge debate in in like the Deep Learning Community is that is that actually true is it kind of wishful thinking and in hindsight we make this connection right. the World by looking at videos right you can even sort to understand how human beings work even better because you can see people being upset or sad or happy whatever right in in a video and start picking these cues up. You can connect the vision part to the text part and get a multimodality model that's able to do both in a really really sophisticated way uh also something that I think these these people are working on all right thank you thank you for your time and good luck with your book.