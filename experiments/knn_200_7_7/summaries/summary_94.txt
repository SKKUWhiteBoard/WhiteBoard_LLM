SNLI is the Stanford Natural Language Inference Corpus-- MultiNLI, and Adversarial NLI. SNLI is a big data set. It has over 550,000 training examples and 10,000 examples balanced across the three classes. MultiLNI sets up, you are forced to train on those training examples. and then test on entirely new genres, such as Berlitz travel guides from the "9/11 Report," says Christopher Potts, an NLP expert. to the fact that the genre is kind of restricted. We had about 60,000 examples that were additionally validated by four other annotators. They had high interannotator agreement. So given that validation, about 60% examples had a unanimous gold label. And we rate the overall human level of agreement at about 91.2% for the gold labels. That's the measure of human performance that's commonly used for SNLI. But down here at 78 is the original paper. That was from an era when deep learning systems were really not clearly the winners. in the Atlantic Ocean." You might ask, of course, those could be true together. They should be neutral, not contradiction. The reason we call them contradiction is because we make an assumption of event coreference, that we're talking about the same boat in the same event. And for that reason, they get the contradiction label. If a premise and hypothesis probably describe a different photo, then the label is contradiction. That's kind of anchoring back into our underlying domain that you might have in mind. Overall, that results in that large data set. And you can see that in subsequent rounds, the model is going to be expanded to include previous rounds of data, in addition, possibly, to other data resources. So with respect to the best model for each round, the test set is as adversarial as it could possibly get. The model has gotten every single example wrong. And Adversarial NLI is exciting because it's given rise to a whole movement around creating adversarial datasets. SNLI and MultiNLI into Turkish. XNLI is a bunch of assessment data sets that is dev-test splits for more than a dozen languages. Those are human-created translations that could be used to benchmark multilingual NLI systems. So there's a wide world of tasks you can explore, and I think that makes NLI a really exciting space in which to develop original systems, and projects, and so forth. And those could be interesting for seeing how well a model can grapple with variation that comes in very specific and technical domains.