John Guttag: This is the 60002 course, or if you were in 600, the second half of 600. The main topic of the course is what I think of as computational models. The course is really less about programming and more about dipping your toe into the exotic world of data science. The final exam based upon all of the above will be a test based on experience writing object-oriented programs in Python, preferably Python 3.5. The lectures will be-- and maybe I'm speaking euphemistically-- a bit faster paced. Science is moving out of the wet lab and into the computer. We'll talk about three kinds of models-- optimization models, statistical models, and simulation models. An optimization model is a very simple thing. We start with an objective function that's either to be maximized or minimized. We then often have to layer on top of that objective function a set of constraints, sometimes empty, that we have to obey. We use these things all the time. Today you really can't avoid using optimization algorithm as you get through life. A greedy algorithm, as we'll see, is not guaranteed to give me the best answer. There is no algorithm that provides an exact solution to this problem whose worst case running time is not exponential in the number of items. But that should not make you sad because while there's no perfect solution, we're going to look at a couple of really very good solutions that will make this poor woman a happier person. The winner will be greedy by value, happens to find a better answer, 424 instead of 413. The problem is to find a vector v that maximizes the sum of V sub i times I sub i. I want to get the most valuable V I can get subject to the constraint that if I look at the item's dot weight and multiply it by V, theSum of the weights is no greater than w. The power set of a set includes the empty subset. It includes the set that includes everything and everything in between. It's pretty obvious that this is going to give you a correct answer. You're considering all possibilities and choosing a winner. Python uses something called timsort, which is a variant of something called quicksort. Timsort has the same worst-case complexity as merge sort. The problem is that a greedy algorithm makes a sequence of local optimizations, chooses the locally optimal answer at every point, and that doesn't necessarily add up to a globally optimal answer. John Grimson: With greedy algorithms, you can get stuck at a local optimal point and not get to the best one in the world. The best answer is to always get the best answer. Lambda is used to create an anonymous function, anonymous in the sense that it has no name. Lambda does is it builds a function that evaluates that expression on those parameters and returns the result of evaluating the expression. My view on lambda expressions is if I can't fit it in a single line, I just go right def and write a function definition because it's easier to debug. But for one-liners, lambda is great. Let's look at using greedy. So here's this function testGreedy, takes foods and the maximum number of units. TestGreedys.that chooses a burger, the pizza, and the wine for a total of 284 happiness points, if you will. If we use greedy by cost, I get 318 happiness points and a different menu, the apple, the wine, the cola, the beer, and a donut. I've lost the pizza and the burger. I guess this is what I signed up for when I put my preferences on. And here's another. And so I picked up some names and the values. This is just the menu we saw.