PhilipPE RIGOLLET: What I want is to have a small bias, hopefully a 0 bias. If this thing is 0, then we see that the estimator is unbiased. But we'll see that it's actually maybe not enough. Something that's slightly better is the risk, really the quadratics risk, which a small variance. If you reduce one too much, then the variance of the other one is going to increase. That happens a lot, but not so much, actually, in this class. is expectation of-- so if I have an estimator, theta hat, I'm going to look at the expectation of thetahat n minus theta squared. And so for example, if the quadratic risk goes to 0, then that means that thetaHat converges to theta in the L2 sense. So the risk is really telling you how much fluctuations I have around my expectation if unbiased. So when theta of the risk, the theta that you have here if you're unbiased is really the expectation. So that's really just the variance. for sum of independent random variables, now it's time to wake up. So we have the variance of something that looks like 1 over n, the sum from i equal 1 to n of Xi. So it's of the form variance of a constant times a random variable. We would like somehow to say that this is the sum of the variances. And in general, we are not allowed to. But we are because my Xi's are actually independent. And that's by independence, so. is very close to 0.5, I'm very happy. When theta gets farther, it's a little bit annoying. So now the thing with the risk of this guy is that it will depend on n. So as n increases, it is going to look more and more like this. It's the same curve divided by n. And so now I can just start to understand that for different values of thetas, now I'm going to have to be very. close to theta is equal to 1/2 if I want to start saying that Xn bar is worse than the naive estimator 0. 5. to be the same. So here, I'm going to get some bias, but the variance is actually going to be much better, because I get to average all the coordinates for this guy. As n increases, the variance decreases, like 1 over n or theta, 1 minus theta over n. And so this is how it happens in general. In this class, it's mostly one-dimensional parameter estimation. But if you do, for example, non-parametric estimation, that's all you do. what a confidence interval is. And so we fixed a statistical model for n observations, X1 to Xn. The parameter theta here is one-dimensional. Theta is a subset of the real line, and that's why I talk about intervals. A confidence interval of level 1 minus alpha-- so we refer to the quality of a confidence intervals is actually called it's level. The closer to 1 it is, the better the confidence interval, and the closer to 0, the worse it is. So we know from the central limit theorem that Xn bar minus p divided by square root of p1 minus p converges in distribution as n goes to infinity to some standard normal distribution. This is by definition of the quintile of a standard Gaussian and of a limit in distribution. We know that this is just the probability that the absolute value of sum just take the largest possible value for p1minus p, which makes the interval as large as possible. So this by now, hopefully after doing it three times, you should really, really be comfortable with just creating this confidence interval. another couple times in your homework. So just make sure you're comfortable with this. That's one of the basic things you would want to know. Are there any questions? Yes. OK. So it's important, because now we're going to switch to the real let's do some hardcore computation type of things. So that's what the function here-- the function you're interested in is 1 over square root of X1 minus X. So what does this function look like around the point where you think P is the true parameter? Its derivative really is what matters. and so you feel like you're a little more-- you have a more precise answer. Now, if you really need to be super-conservative, then you're actually going to go with the P1 minus P. So depends on-- I mean, there's a lot of data in statistics which is gauging how critical it is for you to output valid error bounds or if they're really just here to be indicative of the precision of the estimator you gave from a more qualitative perspective. When we do maximum likelihood estimation, likelihood is the function, so we need to maximize a function. And if I give you a function, you need to know how to maximize this function. Sometimes, you have closed-form solutions. You can take the derivative and set it equal to 0 and solve it. But sometimes, you actually need to resort to algorithms to do that. And so there's actually a way to compress it by just looking at the basically function distance or vector distance between probability mass functions or probability density functions. true theta star, the one that generated some data, X1 to Xn, in an iid fashion. The goal of knowing thetaStar is so that you can actually know what P theta Star is. So in a way, what does it mean to have two distributions that are close? It means that when you compute probabilities on one distribution, you should have the same probability on the other distributionPretty much. So what we can do is say, well, now I have two candidate distributions. And so here is the strategy to implement our goal. If we have continuous random variables-- so by the way, I didn't mention, but discrete means Bernoulli. The max of those two guys, if this maximum is equal to 0-- I have a maximum of non-negative numbers, their absolute values. So what it means is that the two densities have to be the same pretty much everywhere, which means that the distributions are the same. That's the formal way of saying it. But let's go to this definition-- which is gone. the positive integers, non-negative integers. And so now we have also the continuous ones, such as Gaussian, exponential. And what characterizes those guys is that they have a probability density. So the density, remember the way I use my density is when I want to compute the probability of belonging to some event A. The probability of X falling to some subset of the real line A is simply the integral of the density on this set. That's the famous area under the curve thing. for yourself that graphically, this I can represent as an area not under the curve, but between the curves. Now, this guy is really the integral of the absolute value. So this thing here, this area, this is 2 times the total variation. The scaling 1/2 really doesn't matter. It's just if I want to have an actual correspondence between the maximum and the other guy, I have to do this. So we have this definition. And so we have a couple of properties that come into this. PhilipPE RIGOLLET: The fact that you need two definitions of the [INAUDIBLE],, is it something obvious or is it complete? PHILIPPE Rigollet: I'll do it for you now. So let's just prove that those two things are actually giving me the same definition. So what I'm going to do is I'm actually going to start with the second one. I just don't want to have to write indices all the time. A star is the set over which the function delta is non-negative. If I start adding something to A, the value goes lower. The integral over A of delta is less than the integral over the set of X's such that delta of X isNon-negative of Delta of X, dx. That's an obvious fact, just by picture, say. And that's true for all A. It's actually still be true, even if there are extreme cases, like in this case. was-- if this was a constant, that would still be true. Just need to make sure that there is someplace where it is, but that's about it. So it's a distance. It's symmetric, non-negative, equal to 0, if and only if the two arguments are equal, then it satisfies the triangle. If it's not satisfying this thing, it's called pseudo-distance or quasi-distance. Or just metric or nothing at all, honestly. another notion of distance that sort of has the same properties and the same motivations as the total variation distance. But for this guy, we will be able to build an estimate for it, because it's actually going to be of the form expectation of something. And we're going to able to replace the expectation by an average and then minimize this average. So this surrogate for total variationdistance is actually called the Kullback-Leibler divergence. But it has some roots coming from information theory. don't bother with maxima or anything. I mean, there is something like that, but it's certainly not as natural as the total variation. And so it's just very hard to manipulate, like this integral of absolute values of differences between probability density function. So it's very difficult. But if you can actually-- and even computing it between two Gaussians, just try it for yourself. And please stop doing it after at most six minutes, because you won't be able to do it. here. The problem is that-- actually the star here should be in front of the theta, not of the P, right? That's P theta star, not P star theta. But here, I still cannot compute it, because I have this P thea star that shows up. And that's now where the log plays a role. If you actually pay attention, I said you can use Jensen to prove all this stuff. You could actually replace the log by any concave function. That's called an f divergence.