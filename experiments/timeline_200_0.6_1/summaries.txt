==================== [1/100] ====================
Summary:
John ESSIGMANN: I measure my blood sugar at different times during the day. Gluconeogenesis technically means new synthesis of glucose from non-carbohydrate precursors. The medicine I take is called Metformin. It has a number of targets, but one of them is one of the enzymes, called PEPCK, Pyruvate Carboxykinase, that's in the gluconeogenic pathway. The liver provides a constant stream of glucose to these organs that absolutely require it, like our brain. the night, is to take this drug that will prevent the switch to produce more and more sugar by gluconeogenesis. The drug will stop the switch from producing more sugar to producing less sugar. It will also prevent the production of more sugar from the body's own production of sugar. This is called the 'gluconeogenesis inhibitor' and is used in the treatment of diabetes and obesity. It is a drug that stops the switch between the two processes from occurring. It also prevents the body from producing too much sugar.

ROUGE-1: 45.30, ROUGE-2: 30.98, ROUGE-L: 31.54
BERTScore: 67.45

==============================================
==================== [2/100] ====================
Summary:
In this lecture, we introduce and develop the concept of independence between events. If I tell you that a certain event A has occurred, this will generally change the probability of some other event B. In such a case, we say that events A and B are independent. We will then proceed to define the independence of a collection of more than two events. Finally, we will close with an application in reliability analysis and with a nice puzzle that will serve as a word of caution about putting together such a collection. probabilistic models. Probabilism models are models based on a set of assumptions about the future of the economy. The models are based on the assumption that the economy will continue to grow in the future. They can be used to make predictions about future growth. For more information, visit: http://www.cnn.com/2013/01/29/30/science/features/top-10-most-futile-probabilities-in-the-world/story/story.html.

ROUGE-1: 63.01, ROUGE-2: 50.14, ROUGE-L: 50.41
BERTScore: 70.32

==============================================
==================== [3/100] ====================
Summary:
In today's video i'll show you the importance of de-gassing your bread dough as it's fermenting. No matter how gentle you try to handle your dough you will always de-gas it if only a little bit in today's comparison video we'll make 4 breads they will be made from the same dough but they will all be treated differently. The first one of the four breads will be left alone from the beginning of fermentation until it's baked. The final one will be folded shaped and degassed three times and we won't be fermenting them for the same amount of time. why are you punching it punching is actually quite aggressive and you should never punch your dough the best thing to do is deflate it by pressing it gently as the dough ferments the gas pockets inside the grow larger and larger and the membrane of dough between those pockets can tear and the pockets of gas can fuse into larger pockets. If this process keeps going undisturbed the crumb of the bread can end up with large bubbles surrounded by denser areas of dough this of course not always a bad thing some high hydration breads are specifically made to have that texture as we punch down or deflate the dough the Gas pockets break down and split up resulting in a more tightly packed and even chrome structure. proof i tried to shape them similarly as i could so that the main difference between these breads would be the steps that we took or skipped now degassing folding and shaping is not just about what the crumb will be like it's also a way of controlling fermentation. After punching your dough down it starts fermenting more rapidly this is because the old built up carbon dioxide actually slows down fermentation so knocking the old gas out makes these ferment more rapidly okay it's time to bake these three and now we can compare the results. worst and you should not be making bread like that if you want to use this method it should be fermented for much longer and perhaps go in a higher tin at the end of the day it's all up to you make your bread the way you like it make it fit your style and taste experiment try different methods don't just follow recipes ask questions and if you ever get stuck check out more videos in the principles of baking playlists you might find some answers there so what do you think of degas thing do you degas your bread though let me know down in the comments and don't forget to read the blog post linked in the video description.

ROUGE-1: 40.56, ROUGE-2: 39.98, ROUGE-L: 40.56
BERTScore: 67.81

==============================================
==================== [4/100] ====================
Summary:
When it was ratified in 1789, the U.S. Constitution provided a way for the people to alter the constitution itself. Of the nearly 11,000 amendments proposed in the centuries since, only 27 have succeeded. For an amendment to even be proposed, it must receive a two-thirds vote of approval in both houses of Congress. To actually change the Constitution, the amendment must be ratified by three-quarters of all states. To do this, each state can either have its legislature vote on the amendment, or it can hold a separate ratification convention. The U.S. hasn't passed an amendment since 1992. The Bill of Rights includes some of America's most well-known freedoms. The first ever proposed amendment was on the verge of ratification in the 1790s. Today, there are many suggested amendments, including outlawing the burning of the flag, limiting congressional terms, or even repealing the Second Amendment. While many enjoy strong support, their likelihood of passing is slim. Americans today are the most politically polarized since the Civil War, making it difficult to pass amendments. nearly impossible to reach a broad consensus. The late Supreme Court Justice Antonin Scalia once calculated that due to America's representative system of government, it could take as little as 2% of the total population to block an amendment. Interestingly, the founders themselves may have foreseen this problem early on. In a letter to James Madison, Thomas Jefferson wrote that laws should expire every 19 years rather than having to be changed or repealed. Although he believed that the basic principles of the Constitution would endure, he stressed that the Earth belongs to the living, and not to the dead.

ROUGE-1: 62.93, ROUGE-2: 59.03, ROUGE-L: 62.04
BERTScore: 73.15

==============================================
==================== [5/100] ====================
Summary:
50 years ago, John McCarthy and Marvin Minsky coined the term artificial intelligence. Progress has been made, especially in the last 20 years. But we need different expertises. Not all in computer science, but in other ones. And so, this was the people that we put together from different labs, from neuroscience, from computer science,. from cognitive science, and from a number of institutions in the US. Especially MIT and Harvard. Let me tell you a bit more about the background here. This idea of merging brain research and computer science. cover of a Nature supplement, on artificial intelligence and machine learning. I think it's a golden age for intelligent applications. We are still very far from understanding how people can answer questions about images. And we would like to know to have a system that does that. But also, to know how our brain does it. So that's the science part. It's not enough to pass the Turing Test. In In Nature, David Wheeler looks at the future of artificial intelligence, and how it will affect our lives. this case, to have a system that does it. And we want to compare your model, our system, with measurements on the brain of people, or monkeys, also during the same task. So that's what we call Turing plus, plus questions. And part of the rationale about it is, this is kind of a more philosophical discussion. I personally think that it's very difficult tohave a definition of intelligence, in general. There are many different forms of intelligence. What we can ask is questions about, what is human intelligence? Because we can study that. able to answer how people do understand images. We start with vision. We are not limited, eventually, to vision. But in the first five years of the center, that's the main focus. And answer the question about images. And we want to understand how the answers are produced by our brain at the computational, psychophysical, and neural level. It's ambitious. And I think there are probably, in terms of having all these different levels, levels of really understanding from the what, where, the neuroscience, to the behavior.

ROUGE-1: 46.08, ROUGE-2: 43.58, ROUGE-L: 44.42
BERTScore: 65.00

==============================================
==================== [6/100] ====================
Summary:
Chef Todd Moore shares with you the seven basic skills that I think everyone should have to cook food consistently in the kitchen and be proud of the results. If you already have all seven of these skills and cooking techniques great you can work for me on the other hand if you only have one or two of these Skills that's still fantastic why because I know you'll want to add other skills and learn to cook basic methods know the methods behind all written recipes then you'll be making your cooking a winner every single time. like to cut things up you'll be using fresh vegetables uh anyway uh second in my chef test to anticipate when oil is about to smoke now the skill here is understanding the convective cooking process. When the chef notices the oil starting to change from being perfectly smooth to beginning a convection process then adds the protein product to the pan just before there's visible smoke this is where you get the splattering reaction in the pan. If you give me a chicken breast with a beautiful brown plate appeal that shows your ability to control heat so that the item develops color but doesn't lose moisture or burn you fail this test. one that's lost moisture one that's burned one that shows the lack of involvement in the preliminary steps of the sauté process Chef test number four here's the answer thicken a liquid to make a sauce. Without an understanding of how starches thicken it's difficult to make consistently great sauces this is a skill of someone that really knows how to cook number five Chef test softly poach an. If you give me a cup of milk that looks like mashed potato Poes or cottage cheese you failed this test. egg well this shows the moist convective process and it means that the Chef should have an understanding of the difference between boil simmer and poach a common mistake of Home cooks and chefs alike for that matter is always boiling items boiling is not a cooking method once you understand how to control the reaction of liquid in a pan you'll be able to perform a poach of a very delicate item like eggs without making all busted up egg drop soup so you pass this test when you give me a nicely poached egg one that looks like it should be in a magazine. and it's dry it's much smaller in its uh cooked State than it was in its raw State because of the drying effect of the oven this Chef doesn't know how to retain moisture in a dry cooking process Chef test number seven how to tell when a grilled steak is done I mean the best test that I can think of for this is to hand a chef three steaks ask them to cook them to order cook me one rare one medium one well done a lot of people can't do this how you do this. every single time because understanding these methods will allow you to make sense out of any recipe or not even use a recipe. Your increased understanding of how different cooking techniques work not what to cook but how the techniques work and then you'll be creating the things that you want you want them to be. Make sure you get a seed at my webinar [Music] and then come back again and again to try and create the things you want to create. You'll be able to create them again andagain and again.

ROUGE-1: 41.25, ROUGE-2: 39.46, ROUGE-L: 38.16
BERTScore: 65.38

==============================================
==================== [7/100] ====================
Summary:
Third degree heart blocks also known as a complete heart block this type of heart block is the worst of all blocks. Electrical signal from the atria isn't making it to the ventricles. The person could be born with it so it could be congenital or the person has severe heart disease or they have a myocardial infarction or they're taking some type of medication that they become toxic on like digoxin. What is the treatment for a heart valve problem now what is the treating for a third degree heart block? third degree heart block well with this your patient's usually going to have some signs and symptoms because whenever the heart is beating like this it's not going to perfuse your body. Some treatment that can be given to that patient is that atropine can be administered to help that heart pump more efficiently. The patient could be connected to a temporary pacemaker which will again get that heart beating correctly so we can maintain cardiac output and then eventually the patient will need a permanent pacemaker implanted. block and if you'd like to watch more videos about heart blocks in this series you can access the link in the youtube description below. Click here to read the first video in the series about a heart block. Read the second video to learn more about the heart block and how to block it. Click the third video to see the next video about the block and learn about the different types of block that can be used to block a person's heart. The third video is the final video of the series and is about the blocking of a heart valve.

ROUGE-1: 54.43, ROUGE-2: 43.85, ROUGE-L: 42.90
BERTScore: 64.90

==============================================
==================== [8/100] ====================
Summary:
The final contest, which is due tonight, is to design an agent that plays together with another agent to try to collect food pellets while not getting eaten by ghosts. submissions for that, your last chance to submit are tonight at midnight. And on Thursday in lecture, we'll discuss the results. What else is left? I think there is a project due next week. There is still a section this week. And I think that homework is all wrapped up, but you would still have a self-assessment of your last homework that will be due next. And then there's a final exam the week after that. be mostly on advanced applications. The idea behind these two lectures is to look at advanced applications, where we have covered a good amount of the material in the ideas behind those applications. We will not quiz you on these application lectures, on the final exam, or anything like that. It's more meant to give you more perspective rather than extra study materials for the final. So far, I've looked at foundational methods for search, for acting adversarial environments, for learning to do new things, and for dealing with uncertainty. Today's state-of-the-art in Go is that there are computer players better than the best human players. But actually, if you went back to March 2016, that was not the case yet. So how do you make an AI for Go? Let's go back to what we were looking at in lecture on games, MiniMax. MiniMax is about solving games in adversarial environments. And you reason about it. And in what it did, we had to update this graph that you see at the very beginning of the course, where we had already checkers fully solved. For a game like Tic-Tac-Toe, you will find out that you can force a draw, and that means fully solving the game. For Go, this is actually pretty hard to do, and it's even much harder than chess. And why? Let's take a look at chess. It's a 19 by 19 board, so there's 19 times 19 positions to choose from in the first move. And then one less, of course, next move. But the branching factor is enormous. So if you tried to run an exhaustive search through this kind of game tree, it's not going to work. DeepMind's AlphaGo is a computer program that can play the game of Go. It uses a deep neural network to learn how to search for the best moves. It can also learn to predict who is likely to win from a given situation. DeepMind is now working on a system that can learn to play Go without human help. It's called AlphaGo Zero, and it's being developed by DeepMind's Sergey Brin and Yann Leibovitz. It will be unveiled at the World Economic Forum in Davos this week. moment, ?] another [INAUDIBLE] PROFESSOR: There is something called fictitious play. In fictitious play, you kind of play against yourself in a slightly more complicated setting than this. So I believe it includes this, the result. By playing yourself, you're guaranteed to reach an equilibrium. Actually, what reaches the equilibrium is the average version of all your past selves. So rather than your actual current network being the equilibrium solution, it's the average of all past. AlphaGo Zero has no prior knowledge. It starts at a pretty, actually, negative elo rating. Loses all the time initially. It's playing itself, but then gets tested against a set of players. After 21 days, it goes past where AlphaGo Lee Sedol was. And then it was still creeping up after 40 days. Go, even though it's a master game, in principle, has a solution. Once you reach that level, essentially, there's no further to go, because you solved the game. With reasonable compute power, it traverses the whole tree. Even with alpha beta pruning, I don't think that'll happen anytime soon. It's a really big tree. If you do a more kind of brute force style approach-- not 100% brute force. It might be. But pretty much no one would say less than 20, and most people would say 50 or more. And that's maybe when we reach human level play. But that's a given. Now, with infinite computing power, for sure. Then you can definitely solve it. even longer. But the more brute force style approach, where you don't have good value functions, you don’t have good policy functions, was expected to take decades before we reached compute levels that can do that. It could be that by using human knowledge, you're in some kind of based enough attraction. For a local [? optim, ?] that maybe not as good as another one that might be out there. I don't know if that would be the case or not, but that's a possibility. Some examples in a few other problems settings soon. And then the reinforced learning on top of that to further improve. That's kind of the standard way to solve a problem. From a research point of view, it's very interesting to see where you can get from scratch. OK, switching gears to helicopters. Here's a motivating example. How do you get a helicopter to do this autonomously? And by the way, this is done autonomously here, but how do we get to something like this? like this? Well, what does it mean to fly a helicopter? What are the challenges? There's two key challenges. One is tracking where the helicopter is at any given time, because if you don't know where it is, you'll not be able to control it very reliably. And then the other thing is to decide what to do, what controls is sent to the helicopter. Typically, have a remote control, which has two joysticks. You send controls from that to the helicopters. S1.1: How do you control a helicopter? We have four control channels, two in each joystick. A collective is the action for the main rotor collective page. It's the average angle of attack as the blade goes through the air, which modulates how much vertical thrust you generate. There is cyclic controls, longitudinal and latitude cyclic control, which determine the difference in angle from back and left right. So that way, you can generate a torque that allows your helicopter to roll or pitch based on how much differential thrust. pretty good. And then we run it on our helicopter. So this is our helicopter, indeed, flipping, which is great. It's moving more than we want it to move. And it went into the trees. So let's think about what happened here. What happened in the real world is we're trying to follow this path that we design where the maximal reward is. And so we had asked it to fly a path that's not flyable. So it starts deviating from that path. As it deviates, what it learned in the simulator becomes less and less relevant. saw it making these wild motions, overcompensating. It pushed the controls so hard that the engine died. The engine just couldn't push it, died. You lose control over your helicopter, more or less, at that point. Then what happened is our human pilot took back control to try to save the helicopter. And believe it or not, they actually saved this. It landed a little harder than you want to land, but it landed on its feet and it could be recovered from that. the helicopter to follow a path that's not flyable. So how do we get a specification of what we should be flying? Well, we could learn the trajectory from these as noisy observations. What methodology do we have for that? Hidden Markov models. If we collect paths from a human pilot and then ask the helicopter to fly those paths, they tend to be noisy. But if we collect many demonstrations, we figured, then, this set of demonstrations captures the essence of what it means. have something we don't know that evolves over time, but we have some noisy measurements of it, we can run an HMM to recover what we actually want. We use something called dynamic time warping. So what does that do? You can align two trajectories. After you do that, then you can run the inference and hidden Markov model, just standard based net inference, which, in this case, was just a guess. Then you run dynamic time Warping, which aligns each trajectory with the hidden one. But in the process, also aligns all the demonstrations, because they're all aligned with this one reference. is an extended common filter/smoother, which is a forward/backward path, similar to what we covered, but done for continuous variables rather than for discrete variables. Let's then re-infer, through probabilistic inference, what the hidden state might be. Keep repeating this till we reach some fixed point, and that will be our target for our helicopter to fly. What does this look like? Here is, in white, the target found through the hidden Markov model inference, and in color, still the demonstrations. We have collected data to learn a dynamics model for the helicopter. We can now penalize our award, penalized for deviating from the target. And then we can run reinforcement learning in simulation, let's say, in this learn simulator to find a good controller and run it on the real helicopter. The controller we learn in simulation is still a little optimistic about really following that path. So while we fly the helicopter, we'll do depth-limited search to improve what we have. able to look ahead only two seconds, rather than needing to look Ahead much further. A value function tells us, OK, how good is it to end up here? We also have a reward at each time tick. And our search over those two seconds is what results in the control we apply. Here's what we get. So fully autonomous. Takeoff, flipping over during takeoff. Hover. So this method can also learn to hover, no problem. Then it goes into forward flight and it's going to do something called split [? us, ?] where you do a half roll, half loop. The fastest we flew this helicopter was close to 55 miles per hour, so almost highway speeds. The algorithm's only this big, so it's pretty fast for something of this size. Inverted flight. Knife edge fall. Stall turn again, coming out tail first. Hurricanes are fast backward flying circles. And then now are actually some of the hardest maneuvers to execute on. Why is flying 55 miles an hour not harder than this? Well, when you do something like this and hear the tick tock, the hardest maneuver in this air show. Berkeley PhD student Woody Hoburg set up the helicopter to learn from scratch. Hoburg shut it off whenever it starts tilting itself, so it lands on some pretty wide landing gear so it's more stable. He was able to have it learn to hover reliably with the only human input being shut off when it looks like it might start doing something dangerous. But that was the onlyHuman input required. We did not push that further to flying those maneuvers. There is some work to be done. at OpenEye, there's been some work on robots learning to do back flips. And that was kind of one step further. It wasn't just shutting it off. You would watch your robot try things. And human input would be not specifying a reward function, which is very hard to do for things like back flips, just like it was hard here. But what they did is they said, the human watches it and says, which one is better or worse among a set of them? it has more time, and if it already has a recovery controller, then you can imagine that. And Claire Tomlin's group here at Berkeley has done some work in that direction, where they have a safe controller and a learned controller. And the learning controller is learning on its own while the safe controller keeps things in check so the helicopter doesn't crash. So what we used there is a model-based reinforcement learning method. So we learned a dynamics models for simulator from data that was collected. To learn a good controller in the simulator, we used something called iterative LQR. is a separate linear feedback controller for each time slice. And the way you learn that feedback controller is by doing a forward pass to see what your current sequence of controllers achieves. And then you can do a backward pass, which is, essentially, a value attrition pass over that same trajectory to find the optimal sequence of feedback controllers. So essentially, value iteration, but in a continuous space. A continuous space is always harder to represent things, so that's why you make a simplifying assumption. We assume that we are just going to use a sequence of linear controllers. follow a new path. Along that new path, we linear the dynamics, because dynamics' not really linear. We approximate it linearly. We do another backward pass along that, and keep repeating this until it's converged. Once we've done that, we have value functions everywhere and we have linear feedback controllers everywhere. If there is no wind, you can actually just run the linear feedback control. It will be fine. But if there's some wind gusts that could throw you off, you want to use the value functions and the two second look ahead against those value functions. Walking tends to be harder than flying for robotic control. If you're flying, you're up in the air. Everything is the same. Unless there's some weird air flows, that's the only thing that really changes. When you're walking, the surface could change all the time. A lot more change in your environment. Here's an example of how hard this can be. This is a video from 2015, there was the Doppler Robotics Challenge, which was held in Pomona, just east of Los Angeles. of Los Angeles. People had two years to work on this. And what did the robot have to do? It had to, essentially, drive a car or walk, but driving the car was recommended. Then get out of the car, walk a little bit, open a door, grab a drill, drill a hole, walk some more. So doesn't sound that complicated. But actually, it turned it's very complex to get a robot to do that. And so it did not sense correctly what is going on in the world and so did not react correctly. or not you're already making contact, and making contact or not. You can be very close, but not have contact. It's a very subtle thing. You don't have contact, you don't get to apply any forces. So it's very hard to do this. Now, what's changed recently in the past few years is that through advances in deep learning, it's been possible to better map from raw sensory information to controls you might want to apply. And ultimately, it learns to walk. The reinforcement learning algorithm can be reused directly onto other robots and can learn to control these other robots. This can work directly for building video games. You build video games, you want your main character to move in a realistic way. You can have it sequence together motions like these and dynamically simulate how they interact with the world, rather than key frame every little detail. The reward function is the closer your head is to standing head height, the better. So sitting is better than lying on the ground and standing is even better. High level control problem, that's actually a star search. If you have a cost function for this terrain, what would the cost function be? Where do you want to place your feet? Well, you maybe don't want to be next to a big cliff. The three on the ground-- the support triangle of that-- if you project down the center of mass of the robot, she'll maybe fall within that support triangle, because then it won't fall over. So there's a bunch of considerations you might have. When we thought about this problem, we had 25 features we came up with that we thought matter. When you run the search, or the value iteration, which is, more or less, equivalent to find a path across this terrain. But if you choose the trade-off between the features differently, you'll find different paths. So reward learning. How you do reward learning, you demonstrate a path. Demonstrating doesn't mean just drawing a line. It actually means choosing a sequence of footsteps that it executes on, and assuming it does well. It assumes you have a low level controller, but that's well understood how to do that. Stanford robot becomes first vehicle in history to drive 132 miles by itself. Five robots remain on the course. To finish, they must wind through a treacherous mountain pass. After months of tireless effort, there's a lot at stake. The first time it's ever been done, autonomous vehicles. A vision they all share will now be put to the test. The Dartmouth Grand Challenge is held every year at Dartmouth University in Dartmouth, Dartmouth, New Hampshire, and Dartmouth College in Hanover, New York. work, and was very impressive that, in fact, four cars finished the 150 miles. That's a Berkeley entry. Only motorcycle in the race. Now, what goes onto those cars? There's a few different things. There is IMU, like right on a helicopter, a lot of computers. The GPS compass. Regular GPS to get position. Lasers, where you shoot out laser beams. And based on how long it takes them to get back, you know how far away the nearest obstacle is in that direction. With a camera, you can often look further ahead. LIDAR sends out a laser beam, measures how long it takes to get back. Raw measurements might give you 12% false positives. With HMM, you get 0.02%false positives of where there might be obstacles.an obstacle. It would see that the readings are different and decide it needs to steer around that, hopefully. If you're an urban environment, there'll be a lot more obstacles. A lot of progress has been made this is video from 2013. So after 2005, 2005 was a desert race. The Google Self-driving Car Project has been working on self-driving cars for a few years. This was before deep neural networks were heavily used for this kind of thing. It's only getting better to recognize what's in scenes, thanks toDeep neural networks. So what does it tell us? Well, the devil is really in the details, in the long term. The future is very bright for self- driving cars, but we have a long way to go before they're ready for prime time. tail of special events that can happen when you're driving. You can measure progress by just demo videos, which is one way, and it gives you some kind of feel for what's going on. But the 2013 video is already very impressive. So another way to measure progress is to see how are these cars doing relative to human drivers. So left and right are the same plots, but the ride is on a log scale so you can see more detail. It's a number of events per 1,000 miles driven. Red there is human fatalities. Then yellow is human injuries. is between 10 and negative 2 and 10 negative 3 per 1,000 miles of human driving. In green is the Google slash [? wave ?] mode disengagement. It's when the driver decides they want to take control because they don't trust the autonomous system right now to avoid an accident. And we see that it's going down how often that needs to happen, but still a bit removed from where humans are at. Where does this data come from? If you test in California, you have to report this data to the DMV. so many decisions. If they're gigantic, use a lot of power. That's a problem. Let's see what we can do to build smaller networks to make decisions. What else did we not cover yet? Personal robotics. I want to spend a little more than two minutes on that, so let's keep that for Thursday. that's it for today. Bye. [SIDE CONVERSATIONS] [Side CONversation] [sideconversation.com: Do you know more about this topic? Email us at jennifer.smith@cnn.com].

ROUGE-1: 46.27, ROUGE-2: 43.97, ROUGE-L: 42.09
BERTScore: 72.37

==============================================
==================== [9/100] ====================
Summary:
So let me say here just the repetition, normal, inferior. Let us say we are talking about price of good 1 has gone up substitution, income these are the effects and overall. When P 1 goes up subs because of substitution effect x 1 will. Come down. And for income also because of income effect it will come down. So, overall it comes down. While inferior goods substitution effect quantity demanded would come down while income effect is Up. Up. Can you give me an example its very very difficult to find Giffen good in real life why? Sir, like if Gucci is a brand and it is. Prices comes down by significant amount. No one could buy a Gucci, it is at that level. only because of it is prices. I am not certain about this statement then when price of these goods would come down then people would not buy what you are saying. No, no if some purse is very expensive like 10 lakh rupees and it symbolizes your status. And other day it comes down to 1 lakh rupee. Then there is no point that the set of people who were consuming that purse that good for 10 lakhRupees to show their status would buy the same purse at 1 lakh Rupees because it will become more common. During Irish famine the potato was Giffen good because people were using most of their income to buy potato because that is what they would consume. So, when the price of potato went up they could not even spare little bit of money for meat and other food products. To get enough calorie; they had to increase the consumption of potato. But the problem is with this the second requirement that income effect is larger than the substitution effect. Typically this is not fulfilled that is why we have very-very hard time getting finding out, figuring out Giffsen good in an economy.

ROUGE-1: 53.74, ROUGE-2: 52.50, ROUGE-L: 53.74
BERTScore: 75.55

==============================================
==================== [10/100] ====================
Summary:
which we are to for next week and here and I'll talk about that actually week from today because it's callay on Monday so it will get behind but if we get any further behind I'll have to make it up sometime the but if you don't have that you be copies available upstairs is it c um come to my office okay to dany's office he doesn't have copies of it there that's six six upstairs in the first floor immediately after CL and then on the next Friday I will talk about the parts in the in the inquiry that were assigned and also a that essay of of the oral concept. and the compact of government and I'll talk about that in a moment and the latter is actually is a compact which I'll mention but it's a Act of fiduciary Trust on the part of the people now the idea is that for a regime to be legitimate LX view has to be such that beginning in this state of equal right which is to state ofequal political jurisdiction now and that you have to keep in mind because it allows for a society and various forms like families and tribes and so on and even tribal band it's not about political jurisdiction. The way in which he described absolutism of the kind of he's objecting to is going to be thrown out um and the has if his premises are correct more arguments than he needs. If you're rational you're not going to agree to submit yourself to an abolute monarchy or any form of abute arbitary power and then and there other restrictions so if we go through it will turn out that aism in the form which he's attacking it gets thrown out by these restrictions. Mo's view is that although of course one is bound I'm sorry one is Born Into into society as a matter of social fact biological fact and so on one is not obligated through the political institutions until one gives at least some consent to a regime. He's here opposing filmer who believe that people are born into a society and that they are naturally subjected to it as a result of growing up in it. He argues that people have as were no choice they are bound to a particular regime. the Age of Reason some form of consent now it's unclear the form in which is tast whether it's an oath of fidelity to the crown upon inher say the family property or whatever it's not expressly said. There's a distinction between express consent and P consent Express consent incorporates us into society as full member and as a Perpetual or presumably taxic consent does not do this. The point for us that's important is that when you read hum's account of the original contract he gives arguments against unlocks View and you have to ask yourself how effective is K's argument against each of these two parts. legitimate form of regime and the other is the conditions under which. particular individuals become bound to say the regime of England as opposed to the. regime of France. How does that happen and you want to ask in H's case which of these two and possibly both are his or effed okay then I will go on with this other question. I want to talk a bit of uh today and it may seem as if I'm getting bogged down in some points of n only theory of constitutions and so on but pension history. exclusion crisis of 1679 and 81 um the original part of the second CH was written it believe about 79 and 880 and then other chapters that were were added in 81 83 and two chapters added after. Now by definition a mixed Constitution is a constitution in which two or more constitutionally defined agents let's say share in and each have a part in What L calls the legislative power that is the supreme power in the constitution is the Legislative power. In the English case of course it's the crown and Parliament so we're only actually dealing with two agents in this case and neither is supreme so we want to say that they are coordinate powers. means that is there's no legal framework within which that is within the Constitution for settling the conflict there is no way to do it at law. In paragraph 168 he says if there is a conflict of the sort then the people have the right to appeal to Heaven which is a euphemism for for go to war that is Civil War and uh the power then refs to them and they have theright of resistance I'll come for that the moment now I might mention that in our constitution there are devices that tend to prevent this sort of conflict from happening. of Andrew Johnson although didn't past and it tends to make it politically impossible for president to persist over a period of time and a long drawn that conflict of with Congress so I might say that today checks then has this effect and comparable things were not available in the 17th century you had not yet institutionalized these various devices. Mar's problem is to justify existence of the crown in this kind of situ situation now now the source of Lock's constitutional Doctrine the source and thought is a book where at least is belied to be uh a book and many evidences of this. before the view of next con Constitution and he says that the crown is in a powerful sense uh Supreme 151 now so much for Lock's problem and an indication how he attempts to answer it View and then I'll go into this in some more details now the significance of this for us is the following which I will go on some that later namely that we want to make a distinction implicit in in Lock's View and in aon's view between constituent power and ordinary power. Now by constituent power I mean the power of the people to determine the form of the Constitution oh it is the power that is exercised by the making of the or placing the political Authority in a certain form of regime. This is a compact between the members of the political Community to do something they need to establish political Authority. It is not the contact and not a contract is another term not favor term with the government or with the Agents of the government. We want to think St from the establishing of political Authority in whatever form the majority shall decide it shall take unless within the social contact with some Proviso that it has to be greater or other than a majority so that action that takes place in the second part will be a fedu will be the exercise of this fiduciary power U. it doesn't make the king for example the compact citizens with each other and there is in fact no such contract contacted government in LW and there isn't in h either but other contract doctrines some sometimes as a talk with a both but here there's only the one contact. The concept of Mages power as a fiduciary power the point of that I think is to emphasize the constituent power of the people. The people always had this right had this constituent power it isn't and cannot be alienated and that in the case of a conflict between the various coordinate agents that it establishes in the form of theim. power as a p power it connects up with the idea that political Authority is the right of making laws only for the public good says that the very beginning in three since given all of the constraints on parties to the social compact it can not be given uh for any other purpose now I don't know whether I ought to do this I might Ting out kind of what the form of thesocial compact might be. We think it just as AAL and express uh consent we hereby compact with one another each with all and all each it's better to unite into more non political Community or political society. to comply with the loss of political power as defined say in section three political power of the purose of community. We cannot act irrationally so this has to be rational agreement it doesn't violate any any Clauses of or duties that are consequence of fundamental law of Nature and so on. I think I'll skip over that um but it's sort of an exercise I believe to try to uh write it down now I'm want to say where two about mck's view was not accepted by the other wigs. changed his mind he thought perhaps it was not all together safe never knew in England the English were regarded in those days as very unstable people uh and not now we think of them as how and settled down or any rate 200 years after that they we regard as a model and longer of stability and and political common sense. Mark was afraid well who knows uh may be different I don't want people know what I said in the past it might be unsafe. He didn't want to have to flee to Holland again but his view was that Charles II then had violated his trust. government is dissolved people are now free to establish a new Constitution and to change the powers of government. Mark says nothing about the details of of this process that is how does he Enis that this constition power is actually to take place he doesn't give any institutional account of how he supposes actually might be done laon is also vague on this he says something has the idea that it would begin in the county courts and they organized there and would then they presented Des sent from there to a parliament. in that case but the implications are quite are quite uh obvious in some sense this is inly radical U Democratic Doctrine or it could be although I don't pain that either of them or actually what we would think of today is either Republicans Or democrats of come to that in in a moment. The point is is not surprising those that the wigs rejected this do and no doubt they did so partly because of the radical implications if thought through of L's View and it might have been a politically unappealing Doctrine so far as in might estimate. Nation than the other now why did L refuse to alter his view I think we have to assume that he didn't change his mind and he persisted in the doctrine that he formed earlier in 79 and 880. I think partly because his views are more radical than the standard view of his college that that would be one reason but also because he felt I think that it was inconsistent now there isn't this view in the trus but if one sort of HS it through perhaps one can see that it is any rate in danger of being insistent. he found in lawon and of which he gave a very clear and re statement is consistent and it presents he thought a more or less adequate account of the basis of sovereignty in a constitutional regime. I think in a way that this is one of his main contributions is to see the importance of Bon's view which otherwise no one paid very much attention to and it might easily get passed Into Obscurity was a rather long involved in someone academic book and came out at a time when there was an interest in its view. protected it's the importance of this notion now I'm not I want to mention at the end I gu about the last for some minutes um I'm going on to mention a witness in lock view from from our standpoint. The fact that is clear from paragraphs say 138 to 40 particularly 40 and 157 to8 that Mark is presupposing and taking for granted that only a few people vote. Mark is not arguing that point one way or the other taking it for granted and also when he talks about property he's not attempting to justify property in the sense of explaining it and justifying it. The right to vote is only shared by a few people now the question is that L lawr to argue that beginning with a state of equal right and going through all these agreements the contact of society would take place consistent with all these other constraints. How could that come about and we don't have a clear explanation in L of how that might come about. We don't know who is included among the people uh when M talks about it excludes a lot of people excludes those that are dependent or some kind of servant. certainly thought that everyone those most people had what we might call Freedom of opportunity had some opportunity to accumulate the amount of of land and me tackle in order to be able to vote so it was not let's say cast system which was uh one could not by social institutions cross from one to to the other. But it would probably hard for most people um and what I'm looking at it from the standpoint of those who are born into a family that say doesn't have a right to vote how can one account for that on this scheme? form of a regime that excludes most people from actually voting I we might say adding on the condition provided that everyone has or most people have the opportunity to mer and gain and to acquire that amount. I believe that Mark more or less achieve his objective in this book which is to give an argument per it's easy to argue against but to give a coherent argument for the right of resistance in mixed Constitution. It isn't a criticism of what M does in terms of his aim but from another point of view we want to free the notion of constition power from being exercise subject to historical conditions. and who does not have the right to vote and what the conditions on it are maybe we want to free it from that of course what I'm thinking of eventually um is that that that would be one motivation for introducing an idea like the origal position that say it's a way of conceiving how con power might be exercised. No point in criticizing someone for something they didn't intend to do okay well I think it's stop so remember there's no class here Monday so the next class here will be next Friday.

ROUGE-1: 57.78, ROUGE-2: 56.28, ROUGE-L: 56.09
BERTScore: 77.22

==============================================
==================== [11/100] ====================
Summary:
David KAISER: Today we're going to be talking about the kind of invention or the hybridization of a whole new subfield within physics that now is often called particle cosmology. It studies the smallest units of matter, the fundamental forces and elementary constituents of matter. It asks about what role they might have in shaping, really, the fate of the entire universe. The field is doing pretty well these days by other measures. Its annual budget just within the United States is on the order of $1 billion a year. On average, there are on average two new physics papers, two new preprints posted to the central preprint server archive.org every hour of every day just in this subfield. That's averaging over 24 hours a day, seven days a week. So it is really a booming, booming subject of study. And I find that all the more astonishing since this field literally didn't even exist 45 years ago. So this is a $1 billion area of study with devoted colleagues all over the world, not just here in the United States. or particle physics and that it somehow this set of ideas that bubbled up in the mid-1970s of that we'll look at today-- that that compelled researchers to change their whole field of study. And so there's a lot going for that explanation, but it's also, I think, really, really quite incomplete. So if we start using the kinds of tools that we've been working on together this whole semester, we can dig in a bit more and try to uncover some of the additional factors that were at play in especially in the early years of this field. Einstein was inspired by some of Mach's writings on this. Mach himself didn't call it Mach's principle. But it was attributed to Mach by Albert Einstein as early as 1918. So from the early days of the study of general relativity, it was often framed as a question. Do we have to think about the distribution of matter throughout the whole universe in order to make sense for why this block slides down this inclined plane at a certain rate? Local inertial effects, are they somehow tied to cosmological distributions? In the 1950s and '60s, a number of high-energy theorists were trying to put together these highly symmetric models to account for things like the nuclear forces. These nuclear forces are somehow mediated by particles exchanging certain kinds of force-carrying particles. There were other instances of that, cousin models, that were getting a lot of attention throughout the 1960s for the other main nuclear force, for what's called the weak force rather than the strong force. That is to say the force that causes things like radioactive decay. Self-evidently of short range, unlike gravitation or electromagnetism, which, in principle, can extend arbitrarily long distances. The nuclear forces really exert themselves across nuclear dimensions, very tiny fraction of the size even of a single atom, let alone macroscopic scales. So the idea was could have finite range nuclear forces if these force-carrying particles had a very large mass. That will make it very unlikely for that force to be felt across a verylarge distance because of the whole set of ideas about virtual particles. uncertainty principle. All well and good, but the problem was with these new fancy highly symmetric models of the nuclear forces. So you can have one or the other. You could have a short-range nuclear force that does not have any of those fancy symmetries. So this was a pretty substantial challenge. It got lots of theorists very exercised over the 1950s and especially 1960s, which is really like, why do these particles have mass at all? Can we account for mass of these elementary particles in a self-consistent way? The Brans-Dicke theory of gravity was published in 1961 by Carl Brans and Robert Dicke. Their idea was to try to go back to this notion of Mach's principle and more thoroughly account for it. Even though the ideas were bubbling up around the same time and often published in the same journals, they still were embedded in quite different research traditions and conversations. Theories of mass came from members of the gravitation and cosmology crowd on one side and the high-energy particle physics community on the other. for that within a quantitative theory of gravity. So they wanted to modify Einstein's general theory of relativity in a very specific way to try to address this question of mass as it had been articulated around Mach's principle. So their idea was to introduce a whole new kind of matter, a newkind of particle in nature. They labeled it with the Greek letter phi. And now the idea was that instead of having a single constant unit strength of gravity labeled by Newton's constant capital G-- that's the G that's in like Newton's force law. Geometer's tool of quantifying the warping of space and time is called the Ricci curvature scalar. multiplying that is this constant, this unit strength of gravity in Einstein's theory. So what Brans and Dicke do is say, well, let's replace G by 1 over phi. So now 1 over G becomes phi in the Lagrangian or in the action for gravitation, where in principle phi, the local strength ofgravity could change across time and space. their version would depart from the ordinary behavior from general relativity. The idea is that if omega is a very small number of order 1 or a fraction of 1, then, in some sense, it doesn't cost very much. So as omega becomes larger and larger, the field becomes more and more wobbly. And so, inSome sense, you're stiffening up the trampoline. It's like saying you can have quite dramatic differences in the local strength of gravity because this field phi could be wobbling. field is much less likely to vary either over space or time. In the limit that omega becomes arbitrarily large, then phi, in a sense, can't afford to vary at all. The kinetic energy cost is too high. If the field doesn't change at all, it acts like a constant. So they had this very clever fudge factor, a coupling constant, so that, in principle, the local strength of gravity could be changing all the time. But the amount of that variation could be controlled by this one new parameter in the theory. Jeffrey Goldstone was one of the first to suggest the idea of nuclear forces mediated by the exchange of particles. Goldstone's work was published in the same journal as the Brans-Dicke work, but embedded in a separate conversation. The equations for the governing nuclear forces could retain all the fancy symmetries for which these new particles were introduced to reinforce that symmetry at each point in space and time. The Higgs field is responsible for giving everything else the masses that we measure, including those force-carrying particles. seek its equilibrium. The governing equations maintain the symmetry, but the symmetry is broken spontaneously when the system relaxes to some lowest energy state. So now once this scalar field, once this what we now call Higgs field gets anchored or gets stuck in one of its local minima, it now acts like it has a molasses. It actually is stuck at a nonzero value of its field. Instead of being stuck at the origin, it's stuck at some non zero value. At the level of the equations alone, they have zero mass. They should be exactly as massless as the photon. But unlike the photon, these newer force-carrying particles interact with this new scalar field. They start acting as if they have a large mass. It's an induced mass coming from this spontaneous symmetry breaking. It got a lot of attention, as I'll say more about in a moment, because it offered the first concrete quantitative alternative to Einstein's general theory of relativity in nearly half a century. In 1979, two separate theorists working independently of each other suggested that the two fields might be literally the same, not just comparable or considering side by side. Alex asks, was it an accident that both parties chose phi? Not really, I see something come up in the chat. And so what's changed over time? That's what we'll pick up on in the next part of the show. Back to the page you came from. Click here for the next episode of The Physics Show. It was not a rule but a pretty widespread convention by that point that a field that had no spin-- so a scalar field-- would often be labeled by the Greek letter phi. The Greek letter psi was often reserved by this point for spin 1/2 particles. So the notation isn't super surprising that it was so similar. But the rest of it that is a new hypothetical state of matter, it pervades all of nature, everything else interacts with it, that's what gives rise to mass. more than just the letter that they chose. There was a lot of what we might have considered similarities. And yet, the two sets of ideas really were treated so separately. So we might wonder, well, was it changes in data? Did experiments force a new evaluation? No, not really. Let's look at the gravity side first. So I mentioned that part of what got the gravitation community so excited about Brans-Dicke gravity was it now gave them something very tangible, very specific to try to test for. objects like the Viking Mars spacecraft and so on. By the end of the '70s, things did not look very good for Brans-Dicke gravity experimentally. That is all the tests were easily consistent with the predictions from Einstein's theory within experimental errors. To match all of these increasingly precise new experimental measurements, Brans' Dicke theory was not highly favored. In fact, Einstein's looked really good. So that's on the gravity side. Meanwhile, as most of you probably know, there was literally zero experimental testing of Brans's theory. evidence, a big fat goose egg nothing in favor of the Higgs-Boson until July of 2012, or if you're extra generous, maybe December of 2011, the first hints experimentally. So it wasn't a new experiment. The main story that's mostly given is actually hearkens to changes in ideas and, in particular, on the particle physics or particle theory side. And these are brilliant and beautiful ideas. These ideas are well worth appreciating. I just don't think of the whole story. asymptotic freedom. And actually, it's the reason why our friend and colleague here at MIT, Frank Wilczek, received the Nobel Prize. So this was work introduced by Frank and his then advisor David Gross, and independently by a different very young grad student at the time, David Politzer. And what they found was that the strength of the strong nuclear force, that QCD force that we talked about quite a bit at the end of last class session, that the force actually decreases with the energy scale. The effects that Frank Wilczek, David Gross, and David Politzer were talking about would be noticeable exponentially higher energies, right? Well beyond anything that can be achieved even today, let alone in the 1970s. So it's suggested that if one could ever get to really super crazy high energies, you might see some very qualitatively different behavior among nuclear particles-- really cool, a very interesting set of ideas. The present-day experiments at the Large Hadron Collider are here. idea from asymptotic freedom. The force strengths look like they might converge. It's not just that these two get stronger with high energy, and this one gets weaker. The idea was that maybe all of these highly symmetry mediated forces that we see as very different at these low energies-- they have very different behaviors and characteristic strengths-- maybe they're all signs of a single force. That would unite these three forces of nature into a single one modulated by a single strength, a single effective charge. That was called GUTs. the 16 GeV, rather than 10 to the 3 GeV. So this became a natural reason-- this is the main argument-- for particle theorists to ask about things like a very high-energy cosmology. And the phrase that was often used at the time, a gendered term, was a cosmology would provide the so-called poor man's accelerator, the poor person's accelerator. And so this becomes the main reason that's usually given, the main kind of cause for why these two previously quite separated fields of study-- gravitation and particle theory-- were somehow merged. In the late '60s and early '70s, physicists saw a really dramatic change in the kind of infrastructure for the discipline. High-energy particle physics was the field that had the most to lose or that lost the most during this reversal of fortune. And the job scene was most hit, partly because its budget was most dramatically cut. And so when physics is getting hit harder than any other field, you have a net outflow by a factor of 2 just within the field. the discipline, including explicitly more focus on gravitation and cosmology. So that means that more and more departments, including very elite trend-setting departments across the country, start rushing to offer new graduate courses in general relativity. Questions on that field, really for the first time in the U.S., start showing up regularly on the general exams for physicists across all fields, all specialties, not just those who wanted to study relativity. And you see a market response as well. You see a flood of new graduate-level textbooks on general relativity on Gravitation and Cosmology-- twice as many published in the 1970s versus the 1960s. vast majority of those came really in the later '70s, in the wake of these pedagogical reforms. So remember that big report comes out in 1972. You start seeing curricular changes as early as '73, '74. By '75, '76, '77, you start seeing, in some sense, the market respond with many textbooks being really rushed into print. Some of these textbooks were basically mimeographed lecture notes. And now there's very, very fancy books published in a more typical way. for more than half of my life, to his great chagrin. He's won a number of awards, gold prizes and that big award-winning fella. But the award that I take most pleasure in is the fact that he won Boston's Messiest Office. So yes, we'll work on that. Let's see. Fisher says, on the chart of interactions with the field strengths, are those groups? Yes. Fisher, thank you. That's right. So I was avoiding the nomenclature, but you're quite right. a continuous unitary symmetry, which is like saying you could rotate the electron field by any continuum amount, and the equations remain unchanged. The photon only has to mop up a relatively simple symmetry, the U1 gauge symmetry. Whereas SU2 was what I was pointing to when I was referring to the weak nuclear force. That's a discrete symmetry. It's a more complicated symmetry structure. And that's the symmetry group that these force-carrying particles-- the W and the Z particles-- are invented to enforce. broken at lower energies, they take on different features. It's another example of spontaneous symmetry breaks. And that's super cool and fun and lots more to be said about that. But that is, indeed, where that nomenclature came from. Any other questions on that? OK. Anyone else want to share stories of Alan's messy office? No, going once?OK. Then let me press on for the last-- the last part is pretty short, so the last little part, and we'll have time for more questions and discussion after that. There's a direct coupling between this new hypothetical field and this geometrical structure, the local curvature of space and time. And so this is really, again, playing the role of the varying unit strength of gravity. That's in place of Newton's constant G. If that field can vary, then you better include its kinetic energy with, Again, some fudge factor. that's all the Brans-Dicke stuff. And give that field its own potential energy with that very specific shape, that symmetric double-well type shape. Even the electromagnetic force is exponentially stronger than the gravitational force. The force between an electron and a positron when they're close together is exponentially higher due to their Coulomb attraction compared to their gravitational attraction. So why is there such a strange hierarchy? Why such a huge divide in the average strength of gravity compared to these other seemingly elementary forces? And so that could be. And so if phi becomes stuck at some large nonzero value, either plus or minus, then the square of that will be some large number, some large positive number. setting the inverse gravitational field strength. So why is gravity so weak? They suggested maybe it's because it's arising from some broken symmetry. Much like the Higgs-Goldstone mechanism, the field is dynamical, but it's getting stuck. Only in the broken-symmetry phase do we experience a phenomena that we are used to. So gravity gets stuck being weak because its local strength is arising through the Brans-Dicke field getting accurate in a symmetry-breaking potential. physicist with whom he again kind of accidentally wound up swapping apartments happens to have been immersed in gravitation and cosmology. And as Tony recalls, he found these stacks of preprints all around the apartment that looked interesting. He'd been an undergraduate at Princeton, Tony had. And there, he studied a little bit of gravity with John Wheeler for his undergraduate thesis. So by the mid to late '70s, he's now asking questions at this interface between his formal training in high-energy particle theory and gravitation. Lee Smolin was the other person who independently introduced that broken-symmetric theory in 1979-- same year as Tony Zee. He was actually, from the start, combining the two fields, both in the courses he took and eventually with his advising team for his thesis and for his dissertation itself. So unlike this accident of trading apartments in Paris and reading a few preprints, more and more members of Lee Smolin's generation were going through a training like his, partly by design, in the wake of the National Academies report. Few physicists today think Brans-Dicke theory of gravity best describes our Universe. But the theory is still very much alive today. In fact, interest in the field grew even as it was getting experimentally less and less favored. The idea that we're picking single theories and that they replace each other, I think, just misses this fine structure, says David Weinberger of the University of California, Los Angeles. He and Weinberger will look at inflation next time on inflation. does exactly the kinds of things that Smolin and Zee had been doing, trying to unify the Brans-Dicke and Higgs field. And in fact, there were a bunch of concrete changes-- some of them geopolitical, the ramping up the Vietnam War, worldwide economic crisis, huge changes in policy priorities within the United States. All these things on a huge range of scales are helping to mold what's going to seem natural or, quote/unquote natural, for younger people to consider doing. in turn, these new folks, especially people like Mike Turner and Rocky Kolb, went on to become real institution builders in their own right. So in fact, they were accelerates. Not only had they been trained to think carefully at this new interface, they helped really accelerate the trend. So it goes from who even thought of it to who wouldn't even try that? What counts as natural can shift in a pretty short time scale. And as we've been seeing throughout the whole term and including today, those shifts can be driven as much by things well outside of the physicist's control. the hall from Alan's. And by a quirk of the old building 6, we had the same key. A single key would open the whole hallway. Couldn't get rid of it now. And one time, my parents were visiting. And I basically broke into Alan's office. They couldn't believe me when I described what it was like to try to work with this person. So I actually broke into his office to show them the safety violation, fire code violation, horror show that was the den of entropy. So that's a true story. soon, everyone. Soon, everyone will be able to play together again. Soon. Everyone will be playing together.soon. Everyone. Will be. Playing together again soon.soon,everyone. Everyone, playing together againsoon.soon,. everyone. soon, everyone, will be. playing together once again. soon.everyone. will be Playing Together again.soon! everyone. will. be.playing together soon. soon! Everyone. will play together soon! everyone will.be. playing again soon! soon.

ROUGE-1: 41.19, ROUGE-2: 38.83, ROUGE-L: 38.67
BERTScore: 65.95

==============================================
==================== [12/100] ====================
Summary:
Frida Ghitis: Ferdinand Magellan may have been the first person to actually circumnavigate the globe. She says Spain and Portugal had their eyes on the same prize: trade routes to the Spice Islands. When a Portuguese defector claimed that a westward route existed, King Charles made him captain of a Spanish armada, she says. Ghitis says Magellan's legacy lingers: galaxies and space programs named after him, and he was celebrated in Spain. of the "Victoria" sailed into harbor in southern Spain in September 1522.

ROUGE-1: 17.48, ROUGE-2: 13.88, ROUGE-L: 12.94
BERTScore: 60.28

==============================================
==================== [13/100] ====================
Summary:
Ani was a real person, a scribe from the Egyptian city of Thebes who lived in the 13th century BCE. His Book of the Dead was a 78-foot papyrus scroll designed to help him attain immortality. Ani's epic journey begins with his death. His body is mummified by a team of priests who remove every organ except the heart, the seat of emotion, memory, and intelligence. It's then stuffed with a salt called natron and wrapped in resin-soaked linen. The wrappings are woven with charms for protection and topped with a heart scarab amulet. can imagine him happily tending his crops for all eternity. Can't imagine him being happier than when he was tending to his crops. Can imagine him growing his crops all day and all night. Couldn't imagine a better way to spend the rest of his life than in the fields. Can picture him growing crops all night and all day long. Could imagine him tending his crop all day, all night, all day. Could he be happier than he was right now? Could he ever be happier?

ROUGE-1: 34.15, ROUGE-2: 25.37, ROUGE-L: 29.48
BERTScore: 63.27

==============================================
==================== [14/100] ====================
Summary:
JUDY HOYT: We're going to begin this lecture on handout number 14. We'll be moving now to chapter 7. This will be our first lecture on chapter 7 on the topic of dopant diffusion and profile measurement. So far, we've discussed a number of major topics, including the fabrication of wafers themselves and cleaning, point defects in silicon. During the next few lectures, including this one, we'll discuss the accurate control and placement of active dopant regions. In semiconductors or in silicon, we typically don't have a cube or a chunk of material. We're usually measuring the resistance of a thin sheet in the near surface region. The resistivity of the cube is given by, essentially, the electric field divided by the current density. The sheet resistance is just given by rho over the resistivity over xj. So that's a simple way and a convenient way of calculating resistance of various structures in semiconductor devices. The resistance of the regions that are extrinsic to the device, such as the contact resistance, the source and drain resistance, should be no more than about 10%. There's a fundamental physical limit on how much dopant we can put in the silicon and how much it will be electrically active. We need to find new ways to activate dopants to higher levels if we're going to be able to manage this design tradeoff. Being able to scale the device really amounts to, in the front-end processing to a large extent, to being able to control very precisely the shape of the doping profiles where the dopants end up. And what I'm going to spend some time in the next few slides is giving you examples from the present literature on device scaling. detailed device physics, but it's just to give you a flavor for why studying dopant diffusion is such an important topic. So let's go on to slide number 8 and talk about a topic called the short-channel effect. And this basically takes place when the distance between the source and drain-- that is the channel length L-- becomes comparable to the MOS depletion width in the vertical direction. And then that the source-drain potentials themselves from the sources and drain regions end up having a strong effect on the control of the current in the device. down these three terms, roughly, to calculate the threshold voltage. In the short-channel case, that threshold voltage equation has to be modified to a certain extent. And, in fact, the third term, which is represented on the second equation by the bulk charge QB prime over WLC ox. That term ends up being smaller than it would be in the long- channel case. And this QB prime is smaller, and that ends up affecting-- that third term being smaller affects the Vt. threshold voltage for a given device. But you get better leakage current control. So you can scale the device to a smaller L effective. So, again, this is an example of how you need to control the doping profiles in order to optimize the device design. Let's go on now to slide number 12. And this is sort of an extreme case of scaling, where we're trying to scale the MOSFET gate length down to 25 nanometers dimensions. And in the central region here underneath the channel, you see these p-type doping contours. It looks sort of like butterfly shaped. is not that sensitive to the vertical junction depth, as you can see by comparing the diamonds to the stars. So this lower variation of the Vt with L effective or with channel length allows a larger design window, which we need because there's always going to be some process variations in the channel length across the wafer. And this enables the technologists to push the channellength down to smaller dimensions. So it's not so much a fundamental improvement in device performance, but it really enables you to manufacture circuits with these shorter channel devices. refer to different lateral source-drain gradients. For lateral gradients larger than about 4 nanometers per decade, the Vt roll-off is just too large. The threshold voltage is approaching 0. You wouldn't be able to make a 25 nanometer MOSFET-- so, again, illustrates the importance of controlling the lateral doping profile and of controlling diffusion processes themselves. So given that brief introduction to the electrical effects, let me go on now on slide number 15 and talk about dopant diffusion fundamentals. really become large. In silicon IC processing, there are two different steps that we refer to in diffusion historically. The first step was so-called predeposition. And what this refers to is that you had an initial step in which the dopants were introduced into the silicon wafer with a required integrated dose into the substrate. In the more modern technology, it's usually done by ion implantation, which is a process that we're going to discuss later and is covered in detail in chapter 8. Dopants are typically introduced at their solid solubility limit. At 1,000 degrees, you can get something like 3 to 4 times 10 to the 20 electrons per cubic centimeter by introducing arsenic into the lattice. If you introduce more arsenic than that, it may still be below the solidsolubility, but you won't get any more electrons. It's not electrically active. It may not precipitate until you get up into the 10 to 21 range. People eventually came up with a number of models to try to explain how it is you can. get more arsenic in the lattices if it doesn't precipitate. Dopant diffusion is described by Fick's first law, which describes how the flux or the flow of dopant depends upon the doping gradient. When the concentration gradient goes to 0, essentially, the dopant or the atoms are uniformly distributed, say, in the solid, and the flow would stop. Later on, we'll talk about the more atomistic diffusion mechanisms and effects of dopants in the silicon lattice. We're going to consider macroscopic first-- macroscopy models for diffusion. In the thin oxide regime, we get a straight line that's just a constant number of the diffusion through the oxide. And again, in that case it's a concentration profile that's not changing with time. In the limited source case, we consider that we have the dopant in this region, and it has a fixed dose Q. And we're going to introduce it as a delta function at the origin. And then we're Going to let it diffuse and diffuse out. And as it turns out, the C-- if diffusivity is a constant, it diffuses into the shape of a Gaussian. given by that constant dose Q divided by 2 times the square root of pi Dt times the exponential of minus x squared over 4 Dt. So that's what's known as a Gaussian profile. And the important consequence of this are that one, of course, the dose Q remains constant. That means then that the peak concentration-- so the concentration at the origin-- is going to decrease according to the squareroot of Dt over time. So the peak Concentration goes down and the width of the profile or the diffusion distance from the origin increases. In semiconductor processing, linear scales for dopants are not all that useful. We often care about how the dopant falls off over many, many orders of magnitude of concentration. If we can assume that there's no dopant loss through evaporation or segregation at the surface, we have a relatively simple trick for solving this. See what the broadening actually looks like on slide number 28 and talk about the second case, which is a fixed dose Q, just like we talk about, constant in time. that the annealing takes place over a long time so that the initial profile is reasonably can be reasonably approximated by a delta function compared to the final profile. If those two assumptions are hold, then we can essentially solve it by assuming that we have virtual diffusion. We have a symmetric diffusion with an imaginary delta function of equal dose Q on the left-hand side. So, in fact, if we go on to slide number 27, that same the graph is shown at the top. surface where we have no loss from the surface. Again, it's a Gaussian profile. So let's go on to slide number 30. And the third case, essentially, that we can solve analytically is called the case of an infinite source. And what this is essentially an infinite. source of dopant which is made up of small slices, essentially each diffusing as a. Gaussian. So that equation at the bottom of slide 30 shows that the concentration in this infinite source case can be given by the sum of all those Gaussians. along the x-axis. That exponential squared over 4 Dt. So we're summing up all these Gaussians at the bottom of slide 30. The solution which satisfies Fick's second law is written down at the top of slide 31. The concentration is actually equal to concentration C prime over 2 times the quantity in square brackets 1 minus the error function of the argument x over2 times the square root of Dt, where the second equation and third gives you the definition of what we mean by theerror function. function is what the shape of this profile can be calculated according to. So let's look at slide number 32, which, again, the error function solutions are made up of a sum of Gaussian delta function solutions. And what you see is that here in this plot, the initial profile is shown in the dashed line in green. The subsequent profiles are time t equals t0 in black, 4t0, in blue, and 9t0 in red. And that the dose beyond x equals 0 continues to increase with annealing time in this infinite source sort of solution. above the solid solubility of the dopant. Then, in that case, at the surface of the silicon wafer the concentration of the dopamine is fixed. And the dose is given by this integral, which can be done integrating from 0 to infinity. So, again, now we see that this dose or the number of the integral of these curves on the right-hand side is increasing with time according to the square root of Dt. So we're getting a higher and higher dose into the sample. side the two different types of classical processes that we talked about in terms of their diffusion profile shapes. On the left is the predeposition case where we have, say, a constant surface concentration, assuming the pre-dep was being done by a gas phase in diffusion. And that at the different times, you can see the twice square root of Dt is 0.1, 0.5, and 1 micron. And so you see what's happening over time at the same time. shorter time. We have a certain peak concentration. That peak concentration is then falling or dropping for the second profile. And the profile is broadening, and then it falls again, and the profile broadens further. So that's for Q equals a constant, integral is constant, and left-hand side is for the surface concentration is a constant. That's just to get your eyes calibrated for complementary error function versus a Gaussian type of solution. Let's go on to slide number 35 and talk a little bit about dopant diffusion coefficients themselves. The placement of dope regions is critical because it determines many of the characteristics of short-channel MOSFETs. The time evolution of a doping profile, if the case is simple, is governed by a fixed loss-- the so-called diffusion equation. That's why we spent so much time calculating in great detail dopant diffusion, as we'll do over the next three or four lectures.right values. One way to check that, of course, is to back to slide 35 and actually compute directly with a calculator the diffusion coefficients. of cases where there are analytic solutions. We talked about the diffusion of a Gaussian profile with a fixed dose. We apply this diffusion to a constant surface concentration. And finally -- we talk about the diffusion of a complementary error function, which we apply for a constant level of surface concentration. The diffusion of this error function can be applied to a fixed level of surface concentration, or a constant level of substance on the surface, for example.

ROUGE-1: 36.81, ROUGE-2: 35.57, ROUGE-L: 34.48
BERTScore: 71.83

==============================================
==================== [15/100] ====================
Summary:
"We were looking at our atas model and we had real GDP a real output whatever you want to call it doesn't really matter we had our price level that aggregate demand short-run aggregate supply long- run aggregate supply and we were at some full employment level of output which we called YF" "In essence what this was saying you'll recall is that we said hey on an average prices have gone up 10% but remember that in the short run these input prices are fixed therefore input prices stay the same output prices are increasing people's real wages are actually declining" We're going to see a decrease in aggregate demand right there's a stock market crash exchange rates change foreign income Falls whatever it is it's causing aggregate demand to decline. So we see output begins to decline we see unemployment increase and we see employment decrease. And so we kind of go once again from point A to B to C so we return to C here at this full employment level of output unemployment Falls to this natural rate of unemployment employment Rises the only thing that's different is the price level Falls to 80 it takes fewer green pieces of paper to buy the same goods and services at sea than it does at eight now how often do you see prices falling generally pretty often are not very often not veryoften all right. important anymore so if these guys over here you're kind of going from A to B to C right same thing over here. What could we do if we want to return the economy to full employment what could we change. We could do this oops wrong direction all right I mean that's an option is what I'm saying. But doing that returns you to fullemployment but it also increases the price level right and remember I said if we think of this model dynamically is that not that this is the pricelevel but this is more like inflation than we've just gone permanently from one rate of inflation to a rate offlation. much higher rate of inflation whatever this guy up here is you know 120 or whatever he is a higher rates of the prices are increasing faster similarly if you have a increase in your short-run aggregate supply curve it's the exact same thing. If we make the model dynamic at a lower rate inflation let's look at our changes in long run because remember when we said the long-run changes it brings the short- run with it so here's our real output there's our price law here's a go get them in that supply long where that good supply is. Garrett: We're going to see this change in long-run aggregate supply. We're seeing an output increase from YF to Y 2 similarly you're seeing the price level fall or like I said if you want to make the model dynamic. We make a whole lot more stuff today than we did 20 years ago but what do we generally see about price level or the price levels lower today No so here's what we typically see happening we're seeing aggregate or we're saying our long- run aggregate supply curve increase. we said for most of the 20th century this guy was about 3% now we're wondering is he maybe 2% I'll have to see but our real business cycle model over here said we're gonna see these ups and downs in economy are gonna see periods where it's increasing. We've got this general long-run trend that's going up at some point 2 percent 3 percent 1 percent 4 percent 12 percent whatever the number is. For most of human history it was this right it's some really low level of output. it's gonna be trust me I've been doing this for 20 years questions on the AAAS wanna yes so that's what we're going to talk about when we talk about fiscal policy and monetary policy. Changes in taxes and changes in government spending are also pretty obvious right if your taxes go up and the government doesn't give you more goods and services for that you have less stuff. If taxes go down and thegovernment doesn't change the amount of services that they give then you have more money in. your pocket right so you can change people's wealth by changing their taxes or by changing the services that they're getting in exchange. Keynes comes along and says famously and the long run we're all dead in other words yes eventually we'll get back to a but why wait why not go ahead and do something change aggregate demand and get you here to see because there's really no difference between a and seeing anyway other than the number of green pieces of paper it takes to buy the goods and services.

ROUGE-1: 35.19, ROUGE-2: 34.13, ROUGE-L: 35.06
BERTScore: 71.71

==============================================
==================== [16/100] ====================
Summary:
As a nurse you play an important role in teaching the parents about car seat safety and this education actually starts at birth before the child even goes home from the hospital in their first car ride. In this lecture we're going to concentrate on the main concepts that you need to know as a nurse and for exams first let's talk about the four types of car safety restraints that you can use in a motor vehicle. The back seat of the car is actually the safest place for a child 12 and under.

ROUGE-1: 7.06, ROUGE-2: 7.00, ROUGE-L: 7.06
BERTScore: 64.70

==============================================
==================== [17/100] ====================
Summary:
Machine learning is about how to acquire a model, from data and experience. In the end, we want to build good systems. Where do you get accurate systems? You get them from good models. Good models come from good data, and we're going to look at that last part now. What we are going to do today is we're Going to start with model-based classification, and, as an example of that, we'reGoing to work through some details of how the Naive Bayes models work. takes on machine learning that are going to highlight different subsets of the big ideas on this topic. We're going to have a couple running examples. One of them is that spam classifier that pulls out all the emails you don't want from your email. And something like digit recognition, we'll start to give you a window into how other vision tasks work. We'll see more in-depth examples and more structured examples of these kinds of problems later on when we talk about applications. "To be removed from future mailings, simply reply to this message and put Remove in the subject" "99 million email addresses for only $99" "I know it was working pre-being stuck in the corner, but when I plugged it in, hit the power, nothing happened" "Had an old Dell Dimension XPS sitting in the corners and decided to put it to use." "I'm beginning to go insane. I know this is blatantly off-topic, but I'm beginning-to-go insane" very much an individual question which emails you want to receive or not. The boundary between what is actually spam, unsolicited commercial email, whatever, and emails you just don't want, this can be a fuzzy boundary. What is it about the top two emails that let you conclude that they're spam, and how could we automate this? Well, machine learning is going to do some amount of work, but something has to power this. There has to be something about those first emails that's going to give you the clues that something's fishy here. In practice, for actual spam detection, a lot of the evidence of spam versus harm comes not from the word or even the content of the email in any way, but rather, its relation to other things in the ecosystem. For example, is the sender of this email in your contacts? Well if it is, this is probably not spam, even if it's got some sort of marginal contents. Has this email been widely broadcast within a short amount of time? Your email account can't tell this, but your email account provider can. these features, and then some match is going to happen in the middle where we're going to build a model and make predictions. We want to be able to predict labels of new images that are not the ones we've already seen, OK? So that's actually subtle, but it's super-important. We are not, like this is not-- This is not the sort of the Pokemon collection task here. We have to collect every digit, every image, right? Every image you see of a digit. is going to be unique. It's going to have to be at least one pixel off of something else you've seen. So you can't just collect all the data. You can get data that is similar, but then, in the end, you're going to need to generalize. What features might you use to detect digits? Well, somebody puts a grid of numbers. Your eyes and your visual processing system is already doing all kinds of processing. People will think about computer vision, replicate some of that processing. really noisy, and you're training set, they might be hard, expensive to label, because they're noisy. And then at test time, you're going to make mistakes because machine learning is not perfect. So people think about computer vision, think about invariances. What are better? We're just not all even going to agree on what the heck that's supposed to be. We need to find a way to make computer vision more accurate and more reliable, and that's where machine learning comes in. representations that if the thing gets tilted or it's a little bit lighter. It's not the exact pixels being on that we care about. But the pixels are something we could use. We could look at how many connected components of ink there are. What's the aspect ratio? How many loops are there? It's increasingly the case, especially for problems like this, that we feed in low-level features like pixels, and higher level features like edges. We'll talk about that in a couple weeks when we talk about narrow nets. some account activity and you want to red flag accounts that are suspicious. Automatic essay grading, auto grading, this can be a machine learning problem. Customer service email routing. You'd like to automate the routing of that. Review sentiment. Here's a bunch of reviews of my product. Which ones are good and which ones are bad? Have they gotten better in the past 10 days since the new announcement? And so on. You can do that with classification. You gotta do that before you can do things like translation. In model-based classification, rather than directly learning from errors that you make in the world from experience, think like reinforcement learning model-free. The Naive Bayes assumption is an extremely radical assumption as far as probabilistic models go, but for classification, it turns out to be really effective and it goes something like this. You build a model where the output label and the input features are random variables. There's going to be some connections between them, and maybe some other variables too that might help you build a better model. A general Naive Bayes model places a joint distribution over the following variables, y, which is your class, and some number of features, which you get to define. You're going to have to write code which extracts them from your input. So if your spam feature is, have more than 10 people received this email in the past hour? The machine learning will do the work to connect the probability of that taking on a certain value up to the class. And that means when you go to make a prediction, it decomposes into a product of a bunch of different feature conditional probabilities. The Bayes net is a model that assumes all the features are conditionally independent, given the label. For each feature-- which is each kind of evidence-- we're going to need to compute a bunch of conditional probabilities for each class. As I change the parameters of the model, different things are going to blink in and out as I think this is spam now, or ham now. So those numbers, collectively, will determine which predictions it makes. So it has to come from data, which parameters we want. 1 to 0 is equally likely. If you're looking at lots of round numbers, maybe it's 0. You can think about why that might be. So these come from data. And this actually underscores the point that depending on the data, depending on where you are, it depends on what you are looking at. And that's what we're trying to figure out here in this article. We want to know what you think is most common in real data. Or are they all equally common? So 0 might be common. How you collect the data can shape the distributions that you are imagining are going to exist at test time. In addition to the prior probability of each label, we can compute things like, what is the probability that pixel 3 comma 1 is on, given each class? This isn't a distribution over on or off. These are just the probability of that pixel for each class. And it's going to be some number. So for example, the pixel in that position might be pretty likely for the number six, but pretty rare for thenumber one. that comes in is going to get a probability for each class. And there's going to be a race to see which class wins in terms of probability. So what am I going to do? I'm going to have to see the words that come in, but I'mgoing to, in the end, compute two things. Whichever one is bigger, that's going-to be my prediction. If I want to know the probability that I assign, I have to take these two numbers and divide them by their sum. In this example, 2/3 of the emails are ham, and 1/3 are spam. This underscores that just because there's some distribution that your data reflects, and then there's the real world. And if there's major, major systematic ways in which your data and the distribution it was drawn from in its construction do not match the distribution in thereal world, you're going to have issues. One major issue you can have is reduced accuracy. And in spam, the most likely word is the. word free. predict 2/3 chance of ham. All right. The terms that are going to show up on the left here are. going to be the evidence terms for each word as it comes in. The thing on the right here is the product of all of these terms. What, minus 1.1? So, so far, we think it's ham because the log of that product is higher. Allright, next word came in. Gary. Remember, Gary is not particularly likely under either distribution. model, the way they're aggregated is multiplying their conditional probabilities. Gary, would you like to lose weight while you sleep? And if you look at this now, it thinks it's spam. Somewhere in there, somewhere around lose weight it changed its mind. You can see, weight is a pretty strong indicator. Apparently so is sleep. OK. So this is what it's like to be a Naive Bayes model. Features come in, you aggregate all of the weak evidence, and then you output. be weighed, and that's what's going on here in the conditional model. It's actually very common when you're multiplying probabilities to just add log probabilities instead. In the end, when you want to turn it into probabilities, you do need to sum them. And summing the logs won't do that. You need to do a sort of log sum, which one way to do that is to convert them back to probabilities by taking exponentials. That's actually not the way you would do it. You would sort of shift them by their minimum or their maximum as appropriate. word depends on the class and also the previous word. This Is a better model of language. If you started, if you did prediction in this, and you cranked out a pretend document, it would look significantly more like a real email than if you just did a bag of words. Will it be more accurate for classification? It really depends. In general, it will be a little more accurate, but at a cost of having significantly more complicated conditional probabilities to estimate. All right. Let's take a break now. We are now into the machine learning section which means we are done with the spooky Halloween time ghost-busting section. But I have candy. Come up and grab some, please. I'm not allowed to take it home. [NO SPEECH] All right, we're going to get started again. Let me say, your candy consuming I would rate as middle of the road. You can come back up to the-- at the end of the class if you would like to grab more. Allright, so let's talk about training and testing. So we talked a little bit about we want to build classifiers. We're going on the basis of data. How the heck am I supposed to know what pixel 7 comma 3 is for the number eight? I've got to get that from the data. Machine learning theory is based on trying to say something precise about the connection between what's going on in your data and this future used to which you're going to put the classifier to. The main worry is that in picking the parameters of your model, you do a really good job of capturing that training data, but it doesn't generalize. This is like you download all the exams from past years, and you optimize. You learn all those answers, and then you go to the final exam and it's totally, totally different questions that look nothing like those. You go through an experimentation cycle, it looks something like this. Get your model and learning already, and then you're going to learn the parameters. parameters are things like what's the probability of pixel 73 for the number eight? Then there's hyper-parameters, like, do I want to have features for the lowercased version of the words in case I've seen the word, but never uppercased? Right? These are questions about, is this or this orthis going to work better? You always know you're training data. The question is, do you generalize? This can happen to your classifier too, so you always want to test your performance on data that was not used to train it. And there can be a slow leak of your test data into your training data if you're not careful. So you try not to peek at the test set, and that's another reason why I say don't test your classifiers on the test data.to see that today. we have held-out data, which gives you something you can peek at. I ran 20 experiments. How did they go? Am I doing well? Is this thing good enough to release? You need to have some metric, and there's a lot of possible metrics. An easy one is accuracy. For how many of these emails did I make the correct decision? Fraction of instances predicted correctly, but actually, that's actually not a great metric for spam detection. Any ideas why? What's wrong with accuracy? cost-- of different kinds of mistakes may not be the same. And so accuracy isn't always what you want. What you really want, is you want a utility here. You want to know what was my utility, and you should have different costs for these things. There are also cases like machine translation, where you're always going to be a little bit off, a little word here or there, but there's a difference between being completely off and a tiny bit off. And again, we're going talk a lot today and next time about over-fitting and generalization. Spam detection is, in some ways, a very poor example of a canonical classification problem. The problem here is not that you're test accuracy is low, but your training accuracy was also low because you didn't learn anything. We'll investigate these things formally in a few lectures. I had a really good question during the break, which I want to answer for everybody, which is, couldn't you just defeat this Naive Bayes spam classifier by pasting the word Gary 100 times to the end of your offer to lose weight while you sleep? Spam is being generated by people who are trying to defeat spam filters. Spammers are going to double down on what's working. And so if you have features that are like, did the same email get sent to a lot of different people? What do spammers do? They're going to start modifying that email in some templated way. Now you have some feature that detects templates. Now there's sort of an arms race here. and so in that sense, in a sense, there's a spam arms race. over time, spam classification doesn't actually look like a standard classification problem because it's adversarial. OK, so in these images, you want to fit the hat right. You don't want it to be too small, because if you over-fit, you're not going to be able to generalize. Here's an example of this tradeoff. In general, we're going to do discrete classification. But for this example, let's imagine the thing we're trying to do is to fit a curve to this data. the data points of the squared distance or something. So what is my constant approximation to this? Does anybody want to hazard a guess? Let's call it five. OK, did I fit something about this data? Yeah, I felt something about the data. I fit basically it's mean. Did I capture the major trends? No. All right, let's try again. Let's fit a linear function. It's close, right? It's a better fit than the constant function. Notice that when I went to linear function, the space of hypotheses grew. than the quadratic. It's about fitting your data to the point where the patterns that you are capturing are ones which generalize to test, and that's a tricky balance. Over-fitting shows up not just on these continuous functions. It also shows up on discrete functions. And so, you can't basically just judge by your training accuracy. You need some measure of whether you've gone too far in the fitting process. And in this case, we talked about hyperparameters. A hyperparameter could be something like, what's the maximum degree of polynomial I'm allowed? In Naive Bayes, the numbers are the numbers two and three, let's say, are equally likely. The. probability of southwest, which occurs once in ham and zero in spam, is not zero in ham. It's really dangerous to give things probability zero. Words like Gary, except when I look at my data, it's actually a mess. It turns out, there are a bunch of words in this data which occur in spam once, and it could occur in once and occur in Spam zero. of over-fitting, where the exact details of which sample points you drew when you collected your data get captured in a way that doesn't generalize. In Naive Bayes probabilistic models, over- fitting usually shows up as sampling variance. For other methods, it's going to show up in totally other ways. OK. To do better, we need to smooth, or regularize, our estimates. So let's figure out some ways to do that, to just illustrate what it would look like to limit over-fits. you shrink a hypothesis space, you fit less. Using it too much, you under-fit. So let's take a look at the distribution of a random variable, just to sort of show why we need to do these kinds of things. We can do elicitation, right? You can ask a human. You can go to a doctor and say, hey, I'm building a classifier. What fraction of people with meningitis will present with a fever? And a doctor can give you a guess. You could also do that empirically. of patient treatment or something like that. And this is basically what learning does. You take your training data, you take the trends out of the training data. The simplest version of this is for each outcome to look at the empirical rate. So, for example, if I am a jelly bean-counting robot, and I am trying to figure out in this vat of jelly beans, how many reds versus blues there are, and it's two reds and two blues, well, what can we do? In practice, you need some smoothing. But we want no surprises to our model. We want our model to assign probability to events it's never seen. So that one errant pixel or word that is rare doesn't completely torpedo an otherwise very nuanced balancing of evidence. All right, so what was the maximum likelihood estimate? You have to work this out, right? Maybe we can just go back and do it real quick. OK. So let's say r is my probability of red, and one minus r isMy probability of blue. What is the probability of D.for red. of this data? Well, it's basically I got an r, and then I got another r. And then I've got the other thing, which is one minus r. So as I change the probability of red, this term, the likelihood of the data, is going to go up and down. And the balance, the point where that's going to be maximized you can sort of, if you set it up carefully, take derivatives, find the extreme point, you'll get the relative frequency answer out. two reds, there's three. There's those ones, plus my pretend red. And instead of one blue, there're two, because I have my pretend blue. Now what do I get? I get 3/5 and 2/5. Red is still winning, but this distribution has gotten flatter. And if there had been zero blues it would no longer be given probability zero. So pretty reasonable. We can do better. And so if I add zero, if I take Laplace's extended method and I addzero, then I just get my 2/3, 1/3 estimate from red, red, blue. there's 100 blues. Now how many reds do I have? Well, I do my computations as if I had 102 reds and 101 blues. And suddenly, even though there are still more reds than blues, in my posterior estimate here, it's pretty close to 50-50. So as I crank up k, I have a stronger prior, and I fit less. If I crank downk, I fit more, and so I now have a dial which can trade off the amount of fitting against generalization. example, I can go into my spam, and instead of computing odds ratios on the maximum likelihood-- or empirical relative frequency estimates-- I can instead do some smoothing. And suddenly things that only occurred once, they don't percolate to the top, because they haven't occurred enough to overwhelm that flat prior that I'm associating them with. So this is the top of the odds ratios for ham on the left, and favoring spam on the right. Some of these maybe make sense. Like, there it is. Free is probably in there somewhere. If you see money, that's a good sign that it's spam. But you might be wrong. Sometimes things surprise you, and that's why it's always good to like actually look into your model and see what has been learned here? Is there something that I can learn about this problem from what the machine has learned about the problem? All right. We talked about tuning. So let's say I build my Naive Bayes model for spam, for digits, whatever. I've got my features. Let's say they're mostly words and pixels. On your projects, you'll see you can do better. And I have some tuning to do. In general, your model is going to make errors. So we learn our parameters from the training data. We tune them on some different data, like some held-out data, because otherwise, you'll get crazy results. And then eventually, you're going to take the best value, do some final tests, test run. We're talking a bit more about features, because I think it's important for when we start to get to neural nets, where the stories here are going to change. In general, in general, you're going to need more features. In spam classification, we found out that it wasn't enough to just look at words. For digit recognition, you do sort of more advanced things than just looking at pixels, where you look at things like edges and loops and things like that. Try to do things that are more advanced than just pixels, like looking at loops and edges and edges, and try to look at other metadata from the ecosystem as well as just words. are invariant to rotation and scale and all of that the vision folks think about. You can add these as sources of information by just adding variables into your Naive Bayes model. We'll also talk in the next few classes about ways to add these more flexibly, and also ways to induce these. All right, I'm going to stop there for today, and as you go, please come up and grab some more candy. Thank you. Back to the page you came from.

ROUGE-1: 43.63, ROUGE-2: 41.88, ROUGE-L: 40.81
BERTScore: 62.71

==============================================
==================== [18/100] ====================
Summary:
in this video we're gonna talk about how a country can gain from exporting goods or services through international trade. We're gonna look at how consumer surplus producer surplus and total surplus are going to change when we introduced the idea of trade in allowing Chile's copper manufacturer producers to trade on the global market. The world price of copper is five thousand four hundred and forty dollars a ton. Because the world price is higher than the price in Chile Chile will export copper. There is a shift of some of the consumer surplus is going to go to the producer surplus.

ROUGE-1: 14.64, ROUGE-2: 13.69, ROUGE-L: 13.40
BERTScore: 67.04

==============================================
==================== [19/100] ====================
Summary:
Thiazide tells us that this medication works in the early part of the distal convoluted tubule that's found within this nephron. This transporter is called the sodium chloride co-transporter and it is considered a cyanide sensitive transporter so hence why this drug works so well. While loop diuretics are a lot more effective than a thiazide diuretic but the thiazid does provide a nice diuresis effect. They're less effective in patients who have a compromised GFR a go merrill ER filtration rate. Thiazide diuretics can increase uric acid levels which can lead to gout attacks. These drugs alter how the proximal convoluted tubule deals with your ate and it actually increases how urate is reabsorbed which can increase your gas levels and lead to gaol attacks so you may need to monitor those uri acid levels. High uric Acid levels for a male tends to be anywhere anything greater than seven and four females greater than six. If you see a uricacid level of 15 that is not good that means that they have high uric acids levels. These medications can do is they can be prescribed a lot of times with ACE inhibitors and this can help actually increase the function of the heart and help the patient feel better. Thiazide diuretics can be used in the treatment of renal calculi which are those renal stones that are composed of calcium now let's talk about nursing responsibilities the side effects and education pieces for the patient who may be taking a thigh-high diuretic so whenever you have a patient taking a thiazide you really want to be watching out for signs and symptoms of dehydration. is you can look at their vital signs how is their blood pressure if it's hypotensive low that's the salts less than 90 that probably means that we've removed a little bit too much fluid volume from their blood also the heart rate will be increased as well. A lot of patients with heart failure may be on these medications and we want to teach them to weigh themselves every day and to write it down to keep track. If they've gained more than like three pounds in one day that could mean that they're retaining fluid and they may be having heart failure exacerbation and will need to go to their doctor. on digoxin and their potassium level goes too low it can increase the risk of digoxin toxicity. A normal lithium level is about 0.5 to 1.2 millimoles per liter so remember these two drugs if we go into these hypo conditions either hyponatremia or hypokalemia with those it can cause toxicity. No exams love to ask about the hyper conditions that these drugs can cause our hyper hyper Cal C Mia the high calcium level hyperuricemia. the high uric acid level and hyperglycemia again teach your diabetic patients to monitor their blood glucose really closely while taking a thigh. Avoid giving doses of diuretics at night because we want our patients to sleep at night we don't want them up using the bathroom all the time so make sure you're not doing that. orthostatic hypotension this is where the when the patients maybe they've been sitting or lying down they get up they can fall they become dizzy you want to teach them to change position slowly. weight or losing weight so we play a huge role with that as well okay so that wraps up this review over thighs I diuretics. thank you so much for watching don't forget to take the free quiz and to subscribe to our channel for more videos. Back to the page you came from. Follow us on Twitter @CNNOpinion and @bbcopinion. Follow our Facebook page and our YouTube channel for all the latest from CNN.co.uk and CNN iReport.

ROUGE-1: 30.23, ROUGE-2: 28.44, ROUGE-L: 29.33
BERTScore: 63.91

==============================================
==================== [20/100] ====================
Summary:
Future John Green tells you that in a stunning turn of events the 2020 presidential election will be won by - Harry Styles. We’re going to change the constitution to make it possible. Because… that’s how much we love Harry Styles in 2020. The U.S. was facing what turned out to be the 2nd worst economic crises in the past 150 years. The Wall Street Wamboozle, the Financial Fartstorm. And the U.N. Security Council. The Financial Fartstorm that began in late 2008 was a mixture of public and private activities that tilted towards short-term economic thinking, speculation and irresponsible spending. First, there are the Federal Reserve’s policies of keeping interest rates freakishly low in response to the 2001-2002 recession. And this, combined with unscrupulous mortgage lenders, encouraged people to buy houses that they could not afford. Back then you could buy a house with a so-called NINJA loan which sadly this did not involve mutant ninja turtles or pizza. Traditionally, people in this situation can’t borrow hundreds of thousands of dollars, but in the early 2000’s, these loans were giving the benign sounding designation “subprime” All this created a classic housing bubble, which was doomed to burst. With the interest on government Treasury Bills effectively zero, investors had to look elsewhere for better returns. This led to the idea of issuing securities – these bond-like instruments that were backed by mortgages. The thinking was that the interest people paid on their mortgages would supply the underlying value of the security. When the mortgages turned bad, these securities became toxic assets. When banks stop lending, business can’t function. The stock market collapsed, with the Dow Jones Industrial Average dropping from above 14,000 to around 8,000. By mid-2009 more women than men held paying jobs for the first time in American history. And World Trade cratered and that led to unemployment and misery worldwide. The event that triggered the chaos was the failure of the investment bank Lehman Brothers in September, just 2 months before the presidential election. In 2008 Obama’s election seemed a political watershed and not just because he was the first African American president. He appealed to young people and minorities, and he harnessed the power of social media to communicate with supporters. He appeared to break Republicans’ solid hold on the south, and also raise TONS of money. Also, he was on the cover of US Weekly. You didn’t see Martin Van Buren on thecover of USweekly. What’�s that? It didn”t exist? Of course it existed! he won Virginia, and North Carolina and Florida, and his supporters represented a coalition of African Americans, and Hispanics, white liberals and, especially, young people. “For everywhere we look, there is work to be done. The state of our economy calls for action, bold and swift. And we will act, not only to create new jobs, but to lay a new foundation for growth.” “We will build the roads and bridges, the electric grids and digital lines that feed our commerce and bind us together. We’ll restore science to its rightful place. We will harness the sun and the winds and the soil to fuel our cars and run our factories’ Obama promised to change the culture of Washington. To be fair, he did end the squabbling, it became full blown yelling. He also wanted a foreign policy based on diplomacy, he wanted to reduce inequality and increase access to health care. He wanted to end the wars in Iraq and Afghanistan and, as critics mocked, reverse global warming. That’s a tall order. Some would say not great either. The getting shocked part of my life has come to an end. Hopefully in Crash Course Literature when I get things right I’ll get a puppy and when I getting things wrong I'll get a rainbow! For instance he launched diplomatic outreach to the Muslim world, but a lot of this was more rhetoric than action. He signed into law the Lily Ledbetter Fair Pay Act, which made it easier for women to sue when they had been systemically underpaid. And speaking of women he appointed two of them to the Supreme Court, Elena Kagan and Sonia Sotomayor. He also followed through on his promise to end the war in Iraq, although to be fair the Bush administration had really set him up for success there. Obama has been criticized internationally for backing off his promise to close the Guantanamo Bay detention camp. But the Obama administration has deployed far more unmanned drones to kill suspected militants around the world. Despite provoking outrage on the left and the right, Americans generally appear to support the use of drones and extra-legal assassination of accused terrorists. Obama was fortunate to have a Democratic Congress for his first term in office, so he could push through a lot of legislation. In the end, the recovery act cost $787 billion - more than the government had spent on a package of programs ever. The stimulus is estimated to have saved about 3 million jobs, but it also increased the deficit quite a bit. Liberal economists see America’s current 7% unemployment rate as evidence that the stimulus’ Keynesian policies should have gone further. Obamacare aims to reduce the number of Americans without health insurance by making it easier and less expensive for the uninsured to buy it privately. The Affordable Care Act is arguably the most significant piece of social legislation since Medicare. It seeks to move the United States into the ranks of countries with universal health care. government insurance plan and the government will subsidize those who can’t afford insurance. In 2012 the core of the law was upheld by the Supreme Court when they ruled that thiants was a constitutional use of the government’s taxing power. Not one Congressional Republican voted for Obamacare, and many used it to campaign against Democrats in the 2010 mid-term elections. One of these responses was The Tea Party, a reference to the Boston Tea Party and an acronym for Taxed Enough Already. The Tea Party is very concerned that deficits are out of control and that rising government spending is going to ruin America. Bolstered by 80 or so new Tea Party congresspeople, the Republicans took control of the House in 2010 and John Boehner became the Speaker of The House. All these Tea Party freshmen took their mandate to cut taxes and reduce spending very seriously, and that made it difficult for Boehner to compromise with the Obama administration. In fact, the 111th congress was one of the least productive in American history. ceiling. Things that Congress used to be able to hash out back when their business was governing not ideological rigidity. Meanwhile, the economy has slowly added jobs and looks halfway decent at the moment mostly because Europe looks so bad. That qualified questioning yay is about the last word I have to say on American history. We have to ask ourselves again, “What does freedom really mean?” Can you be free when you live in poverty or when you’re one injury away from bankruptcy? Can you being free when the government can go to a secret court to read your text messages? job to protect you not only by having a standing army but also making you wear your seat belt? Those are ultimately ideological questions, but we have to grapple with them in a real practical way. And the great story of American governance is compromise. But that is also often been the tragedy of American Governance. So if you’ve learned anything this year, I hope its been that the American story that we find ourselves in now isn’t entirely novel. And I think we have much to learn from those who came before us, both from their successes and their many, many failures. Crash Course World History has been on the air for two years. The show celebrates two successful years of teaching history. This has been one of the great professional joys of my life and I’m so grateful to everyone that has helped make the show and everyone who has watched it. Thank you again for watching, and as we say in my hometown, “Don’t forget to be awesome.” You can find a full list of your reading for Crash Course Literature in the doobly-doo.rolling.

ROUGE-1: 61.03, ROUGE-2: 58.20, ROUGE-L: 56.49
BERTScore: 67.90

==============================================
==================== [21/100] ====================
Summary:
Simple graphs are directed graphs where the arrows have a beginning and an end. A directed graph might have a self loop, an edge that starts and begins at the-- starts and ends at the same vertices. A simple graph has a nonempty set, v of vertices, and it has a set E of edges, but the edges now are somewhat different since they don't have beginnings and ends. An edge just has two endpoints that are in V, and we don't distinguish the endpoints. There have been repeated studies that are cited in the notes that show again and again that when they survey collections of men and women and ask them how many sexual partners they have, it's consistently the case that the men are assessed to have 30% more, 75% more. We're going to come up with a very elementary graph theoretic argument that says that this is complete nonsense. The most recent study that we could find was one that's mentioned in 2007 by the US Department of Health. And the statistician who collected the data knew that the results were impossible. David Frum: We can use a simple graph structure to represent who got together with whom in any given population of men and women. He says there's a fixed relationship between the average number of partners of men, the average degree of the M vertices and the average degrees of the F vertices. Frum says this has nothing to do with behavior, or promiscuity, or lack of it. It's simply a reflection of the ratio of the populations, he says, and people are lying.

ROUGE-1: 23.77, ROUGE-2: 22.20, ROUGE-L: 23.42
BERTScore: 64.34

==============================================
==================== [22/100] ====================
Summary:
Robotics is a really cool and important direction for the future. I really believe that in the future we will have AI assistance whether they are embodied or not to act as our guardian angels. These agents will help us with cognitive and physical work. With AI we will see such a wide breadth of applications for instance these technologies have the potential to reduce and eliminate car accidents. We have three types of learning and you have seen different aspects of these methodologies throughout the course we have supervised learning, unsupervised learning and reinforcement learning. Boris Katz did an experiment a few years ago where they took regular objects and they put them in a different context. With this significant change in context the performance of the top performing imagenet algorithms dropped by as much as 40 to 50 percent. So keep this in mind as you think about deploying or building and deploying deep neural network Solutions. There's another thing um that is very critical for for autonomous driving and and for robots you have heard a beautiful lecture on adversarial attacks well it turns out you can attack very well. The images that get fed from the camera streams of cars are fed to the decision-making engine of the car. Machine learning is very powerful for building perception systems for robots but as we employ machine learning in the context of robots it's important to keep in mind the scope when they work when they don't work and then it'simportant to think about what my what kind of guard rails we might put in place at the decision time so that we have robust Behavior. "With all small perturbations you can turn the stop sign into a yield sign and you can imagine whatkind of chaos this would create on a on a physical Road" Reinforcement learning is concerned with how intelligent agents ought to take action in an environment in order to maximize the notion of a cumulative reward. This differs from supervised learning and not needing a labeled input or in not needing labeled input output pairs so in this example the agent has to learn to avoid fire and it's very simple it gets a negative reward if it goes to Fire and a positive reward when it gets to water and that's essentially what what this approach is like you you do trial and error and eventually the positive rewards dominate the negative rewards. years ago and so these techniques that did not do so well back then all of a sudden are creating extraordinary possibilities and capabilities in our agents now this is a simple simulation in order to get the simulation to drive a real robot we actually need to think about the Dynamics of the robot and so in other words we have to take into account what the vehicle looks like what are its kinematics and its Dynamics and so here is a vehicle that is running the policy learned in simulation so it's really cool because really we are now able to train in simulation. they get the position of the other vehicles on the track but only only so they get this position from an external localization system but they only know where the vehicles within their field of view are. I think that these these advancements in robotics are really enabling the possibility that you saw in the first Slide the possibility of creating many robots that can do many tasks and much more complicated tasks than what we see here. What I want to talk about next is the autopilot how do we take these pieces together to enable a self-driving vehicle. In 1995 a Carnegie Mellon project called nav lab built a car that was driven by a machine learning engine called Alvin and Alvin drove this car all the way from Washington DC to Los Angeles. The car was in autonomous mode for a large part of the highway driving but there was always a student there right ready to um to take control and the car did not did not drive inonomous mode when there were when it was raining or when there was a lot of congestion or when the car had to had to take exits. Now 1995 is a long time ago right I mean it's before many of you were born. This work um computers needed about 10 minutes to analyze an image can you imagine okay so how do you go from that to enabling an autonomous vehicle to drive at 90 kilometers an hour well um what they did was they they developed some very fast solutions for paring down the image to only the the the aspects that they needed to look at. They assumed that there were no obstacles in the world which made the problem much easier because all the car had to do was to stay on on the road so it's really super interesting to think about how visual processing improved from one frame per 10 minute to 100 frames per second. vehicle we deployed and in fact we had the public ride our vehicle in 2014 we have vehicles at MIT we have a lot of other groups that are developing these vehicles now before we had lidar we had sonar and nothing worked when we had Sonar. With lidar that problem went away so all of a sudden a powerful accurate sensor made a huge difference all the algorithms that were developed on Sonar and didn't work started working when the later was introduced it's really exciting um okay now when we think about autonomous driving there are several key parameters that emerge. Alexander: We have very effective and Deployable solutions for robot cars that move safely in Easy environments where there aren't many static nor moving obstacles. Many companies and research teams are deploying and developing self-driving cars. Many of these preconditions revolve around certainty in perception planning learning reasoning and execution before we can get to Robo taxi but we can have many other robot solutions that are much that that can happen today. Alexander: We can use deep learning and reinforcement learning to take us from images ofroads onto steering and throttle and what you can do with this is really great. completely different driving environments and driving situations and you don't need new parameters you can go exactly directly to what the car has to do so in other words we can learn a model to go from raw perception and here you can think of this as pixels from a camera. The other thing we feed the vehicle is noisy Street View maps so these are not the high definition maps that are usually created by autonomous driving labs and companies and so you can do this to directly infer a full continuous probability distribution over the space of all control. Vista simulator can model multiple agents multiple types of sensors and multiple type of agent to agent interaction and so the the Vista simulator has been recently open sourced you can get the code from vista.csel.mit.edu and a lot of people are already using the system. The decision engine has about a half a million parameters and I will challenge you to figure out if there are any patterns that associate the behavior of the vehicle with the state of the neurons. Peril at the same time and then have a look at the attention map so it turns out this vehicle is looking at the bushes on the road in order to make decisions. standard deep neural network and we have asked this network to solve this problem and the attention map of the network is really all over the place you can see that the network the the Deep neural network solution is very confused but check out something else the data that we collected was summertime data and now it's fall so the background is no longer green we have we don't have as many leaves on trees and so the context for this task has completely changed by comparison the the liquid network is able to focus on the task and is not confused. This kind of this kind of ability to transfer from one set of training data to completely different environments is truly transformational for the capabilities of machine learning. that yields models that generalize to unseen scenarios essentially addressing a challenge with today's neural networks that do not generalize well to unseen test scenarios because the models are so fast and and compact you can train them online you can training them on edge devices and you can really see that they are beginning to understand the tasks that they're given so you can see that we're really beginning to get at the semantics of what these systems have to do. We have one project that is looking at whether we can understand the lives of whales and so what do I mean by this? Machine learning can be used to look for the presence of language which is a major sign of intelligence. We are trying to understand the phonetics the semantics and the syntax and the discourse for whales. We have a big data set consisting of about 22 000 clicks. Using machine learning we can identify coded types. We can identify patterns for Coda exchanges and we can we can begin to really ask ourselves how is it that that that Wales exchange information and if you're interested in this problem please come see us. that model to run on edge devices or on huge devices uh you have seen that many of our Solutions are Black Box Solutions and sometimes we have brittle function we have we have easily attackable models. There is so much opportunity for developing improved machine learning using existing models and inventing new models. If we can do this we can create an exciting work world where machines will really Empower us will really augment us and and enhance us in our cognitive abilities and in our physical abilities so just imagine waking up enabled by your personal assistant that figures out the optimal time. Robots can help us with cognitive and physical work. There's the garbage ban the garbage bin that takes itself out. After a good day when it's time for a bedtime story you can begin to enter the story and control the flow and begin to interact with the characters in the story. These are some possibilities for the kind of future that machine learning artificial intelligence and robots are enabling. I'm personally very excited about this future with robots helping us with Cognitive and physical Work but this future is really dependent on very important new advancements that will come from all of you. Thank you very much and uh come come work with us.

ROUGE-1: 34.28, ROUGE-2: 33.10, ROUGE-L: 33.37
BERTScore: 61.68

==============================================
==================== [23/100] ====================
Summary:
hair up grab an apron let's go now with the new chefs in place. I just can't wait to get to work and prove to my mom and my sister that I can do this I think the message is clear nobody scared to walk through that door and get their hands dirty in that kitchen no we're not tomorrow is a big day let me tell you I need everyone on their game good night guys get some sleep thanks thank you very much chefs oh my God this is amazing last night Tatiana and her team eagerly learned a few of the new recipes. spaghetti meatballs absolutely delicious and then finally pizzas four of them Margarita prito zucchini done with the shrimp and the meat lovers and again we have a massive asset there in that pizza Cen and we're going to take advantage of that yeah dig in let's go oh my gosh this is so beautiful m oh my God I am thrilled this is amazing this is like the menu of my dream Oh my God the pizza are incredible ohMy God I love that I know I'm excited for the new menu.

ROUGE-1: 52.19, ROUGE-2: 51.29, ROUGE-L: 52.19
BERTScore: 71.66

==============================================
==================== [24/100] ====================
Summary:
HONG LIU: This is a key relation between the bulk and the boundary. The more you go to the interior of the space time, then corresponding to the lower energy process when viewed form the field theory. So here, the same process is happening here compared to happening here, and here corresponds to the IR process, and the [INAUDIBLE] boundary corresponding to UV process. This is the IR-UV connection between the Bulk and the Boundary. It's called the IR/UV connection. the boundary theories. And also, this gives you an intuitive understanding where does this actual dimension come from from the field theory point of view. Then from a field theory perspective, this actualdimension can be considered as a geometrization of the energy scale. So any questions regarding this? Good. So now let's talk about some further aspects of the duality. The duality is that once you realize there's such relation, since the two sides are completely different objects, so the game is that you really have to do lots of guess work. HONG LIU: We have N equals 4 super Yang-Mills theory. And then here, you have type IIB string in Ads5 times ds5. On this side, there is a conformal symmetry which we explained before because this is a four dimensional theory. On the right hand side, we still have some SO 5, S5. So this is more like a space time symmetry. From field theory point of view, this is also space time. This is also global symmetry. And there's also global internal symmetry. HONG LIU: So there's a 4 supersymmetry, which just comes from N equal to 4. But the conformal symmetry generates another 4. So all together, you have eight [INAUDIBLE] as the supercharge. And similarly, you find-- I will not do this side. But in this case, for example, the low energy limit. Let's just talk about the lowEnergy limit of this theory. So this all together is 32 real superchargers. The low energy limit, as we said before, just has to be super gravity. But the interesting thing is that by definition, the supersymmetry on the gravity side is actually local. So if you look at this correspondence between each other, then you actually see a pattern. So the isometry is a subgroup of diffeomorphism. So why we are only talking about isometry? Why we don't talk about other parts of the diffeomorphicism? So what's special about the isometric? But let me just save time. asymptotic geometry of the space time. So these are not ordinary diffeomorphisms. So-called large transformations is that they don't go to the Identity at infinity. And of course, this is precisely the large gauge transformations which leaves the asymptotic invariant. So in a sense, these large gauge. transformations can be considered as the global part of thediffeomorphism. So any questions on this? Yes? AUDIENCE: What does it mean that those those are the large transformations? HONG LIU: The gauge transformation in the Yang-Mills part, you don't see it. Gauge freedom is just redundant freedom. You never see it on the other side. The ordinary gauge transformation is just corresponding to redundancy of degrees of freedom. But precisely due to this remark, those things which really map to the global symmetries in the field theory can be considered as a global part of the local symmetry on the gravity side. So even on thegravity side, in some sense, you should think of them as global symmetry. HONG LIU: Conformal symmetry of the component of the field is the Minkowski space. So on this side, you have isometry of AdS, and on the other side you have conformal symmetry. And any internal gauge symmetry, say if you have some u(s) global symmetry here, then this will be mapped into a u(1) gauge symmetry. That is the gauge symmetry being gravity side. And it's always the case that global supersymmetry here would be corresponding to the local supers asymmetry here. previously we said, from the relation of the d-brane, so the G Yang-Mills square here is related to the 4 pi GS here, string coupling. So the N is the gauge group N. I should say the flux N. And then here is corresponding to you have SU(N). So this R, this curvature radius is related. to the alpha prime squared and the gs in this way. And so on this side, the dimension parameter is given by R squared divided by alpha prime. the relation between the parameters. So on the gravity side, we said these are the two parameters. And of course, you also have this N. And we can also, instead of using GS, as we said before, you can also use the Newton constant. So the 10 dimensional Newton constant is length dimension eight. Then the dimensionless parameter would be GN divided by R to the power 8. And the GN is related to the GS and alpha prime by this formula. So now you can just use this relation to exactly translate this into Yang-Mills coupling. expanding 1 over N squared. So as we said before, we often do dimensional reduction on S5. Let me get a five dimensional Newton constant. So fivedimensional Newton constant is equal to the 10 dimensional Newton Constant. And the difference is the volume of S5, we wrote this down before. And then from here, you can just work out. G5 has dimension 3. Then G5 divided by R cubed, again only related to N given by pi divided by 2N squared. The classical gravity limit is the same as QFT, Quantum Field Theory in curved space time. So gravity does not fluctuate. But your matter field can fluctuate, h bar equal to 1. So in the type IIB super gravity, there are many, many such kind of matter fields, and this is all in the unit of R. And here, when I write these relations, I have all set h barequal to 1, and then alpha prime should go to zero. So this means the string effect is not important. they all should be treated quantum mechanically. It's just that you should consider this small. So let's consider what this means. So GN small as a dimensionless parameter, this translates into field theory side if we use this relation. So that means N goes to infinity. So this is the large N limit of the Yang-Mills theory. And then alpha prime goes to zero. This is consistent that on the gravity side, the fluctuation in the geometry is very small. And now, we see that the decoupling of the string effect requires on the field. theory side the strong coupling. This is also something roughly we said before. If you look at just those [INAUDIBLE] diagrams, of course you don't see a space time interpretation. And I already alluded before that the continuous surface can emerge if that diagram becomes sufficiently complicated. The strong coupling, then the diagram with many, many vertices will dominate. And then the most dominated diagrams are those diagrams with not a lot of vertices. And they essentially are going to continue to limits. side is simple, we can just deal with quantum field theory in the curved space time, which we know how to do. But on this side, it's highly non-trivial because this is an infinite coupling limit. So this will tell you that the strong coupling limit is described by classical gravity. So that means that we can actually use classical gravity to, in principle, solve problems which are strongly coupled. So also, of course, there are corrections beyond this. So quantum gravity corrections on this. side, so this is a classical gravity limit if you take those parameters to go to zero. essentially the semi classical gravity limit because we still treat the matter fields essentially as quantum. So from now on, so we will mostly just consider the semi-classical gravity regime in the gravity side. And also, I will often use the phrase which applies to the general correspondence, and not necessarily just N equal to 4 super Yang-Mills theory and the type IIB string theory. I just use the language assuming there's a general correspondence between some conformal field theory and some AdS gravity theory. you can imagine that this is the boundary, this relation is related to the bulk and the boundary. And this is a postulate based on that fact. Yes? AUDIENCE: I thought one of the motivations for thinking about the holographic duality was to try to escape [INAUDIBLE] theorem. And all of a sudden, it strikes me, so we're trying to get on the boundary spin to massless particles. Then they will also exist in the bulk. HONG LIU: Sorry. In the field theory side, there's no massless spin to particles. on that. You can say I don't need to worry about that whether this is on the boundary or bulk, et cetera. These are just some different theories. I want them to be the same. HONG LIU: But, as I said last time, if you believe this bulk and boundary relation, then this is powerful because then, you can immediately deduce that the Yang-Mills theory on the S3 times time then is related to the gravity theory in the global AdS. will give you a direct way to argue that. Also, in your p-set, you have checked this holographic bound. And so that's a confirmation of this. Yes? AUDIENCE: So what does the massless [INAUDIBLE] field on the right map to if it's the same representation of SO(d, 2)? HONG LIU: Sorry. Say it again. We are going to talk about it. So even though this relation was discovered in '97, actually in the '80s, people already worked a lot to consider this type to be supergravity on this space. On the string theory side, you always have this dilaton. And on the N equal to 4 super Yang-Mills theory, that's a local operator. And it turns out that operator is mapped to this Dilaton. So I won't go through those details. But let me just mention the most important such kind of mapping for these two theories. And actually does have consequences for the general story. So the mostimportant mapping. And then you can immediately see they actually map to certain representation of operators. theory side, we have this SO6 gauge symmetry. Then we have the SO6 conserved current. And it turns out this, on the gravity side, just maps to sO6 gauge field. And then another universal operator on the field theory side is the stress tensor. And this is mapped to-- turns out, to the metric perturbations. It's a deviation from the AdS metric. But physically, this is also natural. Physically, alsonatural. a few minutes. So now, given this mapping, any operator is due to a bulk field. Then you can ask some immediate questions. For example, the quantum numbers of these operators will map to the quantum number of the bulk fields. And that's something I said you can check their symmetries. So do you have any questions regarding this? So for local operator on the field theory side, so once we have this mapping we can immediately ask questions related to operators on this side, and try to ask what's the counterpart on the other side. we will discuss a bit later. But now let me discuss another natural question. And the natural thing to do is to deform your original theory by adding this operator to the Lagrangian. So this phi 0 is often called the source. So immediate question you can ask-- and when phi0 is equal to constant, then this corresponding to a change in the coupling for this operator. But in general, you can make it space time dependent. And then this deforms my theory away from the original theory. And if this operator is not there, then you just add the new coupling. operators coupling without if we say phi 0 is a constant? HONG LIU: Sorry? AUDIENCE: If phi0 is a Constant? Hong LIu: No. O is the operator. It's the local operator. There is no other operator this operator O coupling with. The meaning of operator is that O is a sum of the product of fields. So example is O in the scalar field theory. If a scalarField theory has a gauge field, then I can write O as trace F squared. guesswork is based on some very small clues. Good physicists do is that they can see non-ordinary things from ordinary things. So here, I will try to deduce the answer to this question by starting from this relation. Let's forget about p for pi. And now, we've talked about before GS string coupling can be considered as the expectation value of the dilaton field. Let me actually call it capital Phi. And similarly, for space time like AdS with a boundary, and the value of this dilaton can be identified. with the value of the dilaton at the boundary of AdS. HONG LIU: Phi in principle can fluctuate. And its expectation may also be able to fluctuate in the space time. But the only sensible way to talk about expectation value is to. talk about its value at the Boundary. It's the same thing for flat space. And in the AdS, which is also space time with a boundary, than we can associate the constant parts of the expectation value as the value at. the boundary. HONG LIU: We have established a connection between the Yang-Mills theory coupling with the value of phi at the boundary of AdS. If we deform the Lagrangian, say, change this coupling, deform the boundary by changing the coupling, which corresponds to you add some delta G. And this corresponding to you essentially change the boundary value of dilaton because these are related. The bulk field phi due to O has a boundary value phi 0. Any questions about this? Yes? methods. Now I'm saying because I already know it's true. But in real life, what you will do from this example, you will say, ah, this must be the case. Then you will start trying to find examples to check it. And we will describe it later. I will not contradict myself in my later discussion. So if we assume this, I can also use this to argue. I can use this identification to make star and star star natural for any duality, not only N equals 4 super Yang-Mills theory and type IIB gravity. J mu. For simplicity, let me just take it to be u(1). Then I can deform the boundary theory by adding a source for this J mu. And a mu is the source. And then according to this identification, the A mu must be A mu-- we should be able to identify it as the boundary value of some bulk field, A mu evaluated at z equal to 0. So if this is true, there must exist a vector field due to this vector field. And this must correspond to the boundaryvalue of that. Now I want to argue this is a gauge field. and the field theory. And that also tells you that if you have a theory which due into a higher dimensional theory, and then that theory has a stress tensor, then this bulk theory must have gravity. So you can say, if any field theory is due to a theory of one higher dimension, that theory must involve gravity-- nothing about quantum gravity. Let's stop here. We're not going to get into quantum gravity right now, we're just going to talk about the theory of gravity.

ROUGE-1: 46.73, ROUGE-2: 45.10, ROUGE-L: 43.79
BERTScore: 72.14

==============================================
==================== [25/100] ====================
Summary:
Bolek Wyslouch: How do you convert a given physical system with all the forces, et cetera, into some sort of fixed form, fixed type of notation? Bolek: Once we understand two, we will then generalize to infinite number of oscillators, which is actually-- so this model, which consists of weights hanging under the influence of gravity plus the springs will be then used for many applications of the concepts later in this course. Boleslaw: We can come back to that initial conditions and impose some initial conditions. The coordinate system is this. When we start talking about the system in principle in the case of somewhat larger angles, you have to worry about vertical positions as well. So let's look at what are the forces acting, for example, on this mass, the mass, which is-- if it's displaced from a vertical position. Temporarily, let's introduce an angle here to characterize this displacement from vertical. And then there is a tension the spring, which has to be calculated such that we understand the acceleration of this object. can be ignored. The force of spring depends on the difference of position x1 minus x2. If you move mass 1, the spring force is in the right direction, minus kx. So there is no motion x1, so we can conclude from here the T cosine1 is approximately equal. Yes? AUDIENCE: How do you know which way [INAUDIBLE]?? BOLESLAW WYSLOUCH: Excuse me. The spring is connected to mass 1. And the force of the spring on mass 1 is k times however the spring is squashed. Most of the terms have to do with a motion of mass 1 itself. Mass 1 is its own pendulum. And mass 1 is feeling the effect of the spring force. Mass 2 also is mostly driven by its own gravitational force of itself plus the spring depends on the position of x2. But there is this coupling term that depends on position ofmass 1. So both of them feel the neighbor on the other side, right? All right, so this is the set of two coupled equations. It's like an oscillator of position acceleration with a constant term. me do everything. Let's write down everything in the matrix form, because it turns out that linear matrices are very useful for that. So let's introduce to them and show vector, which consists of x1 and x2. So we will be monitoring the change of this x2 as a function of time. We will introduce a force matrix k, which is equal to k plus mg over l minus k here. And then we need a third matrix, mass matrix, which simply says that masses are mass of first object is m. as X, the second derivative of the vector capital X, is equal to minus m to the minus 1, this matrix, multiplying matrix k and then multiplying vectors x again. So instead of repeating writing, all the x1s, x2, et cetera, instead I just stick them into one or two element objects. I use matrices to multiply things, and if I want to know x1 and x2,. I can always go, OK, the top component of vector x, lower component of vectors x gives me the solution. Simple. Right? So let's try to use this terminology to find solutions. BOLESLAW WYSLOUCH: The physics answer is to find fixed frequency modes us such that the system, the complete system, oscillates at one frequency. This is so-called normal mode. It turns out that every of the system will have a certain number of frequencies, normal modes, that would-- the whole system would oscillate at the same frequency. So I propose that-- so of course, we use the usual trick that anytime we have a solution in complex variables, we can always get back to real things by taking a real part. So I have to do-- so I plug this here. So Z double dot is simply equal minus omega squared times Z. OK? And this term is a proportionality constant at any given moment of time. So it goes through the matrix multiplication. So you can just delete this. You can divide both sides. You have signs here. And then I have an equation which is a linear matrix equation, which is M minus 1 K times vector A. And I can rewrite it a little bit again. So this is the equation which we need to solve. to obtain the solutions to at least one normal mode, and we expect that there will be two normal modes, because we have two masses. So mathematically, the way to find out the oscillating frequency is you take a determinant of m minus 1 K minus i omega squared must be equal to 0. So let's try to see how to calculate things. So I take a big object like this. And so in this element here, I have to multiply this matrix times that. The only variable which we have to change parameters of this matrix-- you know, the spring constant and the mass this affects is given. So the only parameter here, which I can change, or adjust, or find is omega square. So I will try all possible matrices of this type until I find one or two that have a determinant equal to 0. But if I find them, this would correspond to the normal frequencies. We need to find which parameter omega sets this to 0, and then this is a pretty straightforward calculation. is basically equivalent to the following equation g over l plus k over m minus omega squared must be equal either to plus or minus. Right? I took a square root of both sides. There are two solutions which corresponds to plus here. The other one corresponds to minus here. So we have a-- so what this says is that if I set my frequency to g over. l, then it will be-- I will be able to set things up such that it oscillates forever at this frequency, one fixed. frequency forever. This is a frequency. It does not depend on the strength of the spring. How is it possible? Somehow spring is irrelevant for this motion. And it turns out that there is a very simple oscillation, easy to see, if basically that this is the frequency of a single pendulum. So basically, you got both pendula going together, each of them happily oscillating by themselves. And the spring is completely irrelevant forthis motion. If I cut it off, the motion will not change. It just happens that two identical pendula are going at their own natural frequency. so it's stretch from both sides. And the whole system oscillates at the same frequency, and because of this additional force of spring, the frequency is actually higher, it's larger. It oscillates faster. All right, so that's the first step in understanding the system. We now know that there are two oscillations and two normal frequencies. The next step to finish our understanding of the system in a mathematical way, to describe it fully, I have to know what is the shape of oscillations. In principle, we know, now, at the end of the day, I still want to know how much 1 moves, how much 2 moves. So we have to put it all together. We have identified the frequency and the kind of, in the matrix notation, shape of the node. But of course, the final solution is a linear superposition of all possible normal modes. And then you calculate a shape of a normal mode. Is that clear? Any questions at this time? Right? The shape, 1 and 1, and 1 minus 1 is fixed, because these are the shape of normal modes, which corresponds to those frequencies. And the superposition of x1 plus x2 gives you the most general combination of possible motion. So if I write this down now in terms of position of number 1 and number 2, so I have a position of X1 as a function of time. In general, it will look like this. It will be some sort of constant alpha, cosine omega 1 t plus phi. The magenta is normal mode number 2. And blue and the red are the actual pendula. And the motion of blue and red is simply a linear sum of the two. And this is exactly what-- this is the computer simulation that shows you that one of them is going up, the other one down, et cetera. Now, is there a way to disable one of the normal modes? How would you disable a normal mode? Is there a quick way to set things up such that the second normal mode, whichever you choose, doesn't show up in their equations at all? AUDIENCE: You said [INAUDIBLE]. BOLESLAW WYSLOUCH: Hmm? Audience: [INAudIBLE] BOLesLAW: Yeah, so what you do, is you just change the initial conditions. So you set it up at T equal to 0. I have initial conditions that basically favor or demand that only in this general equation either alpha or beta is equal to0. no shifting of energy from one to another. So you can have all kinds of motions by simply adjusting initial conditions. And those motions can be done a very different way. So do you know-- so this is how we can have different shape of motion, depending on the initial condition. Is there another way for me to change the way this system behaves? Let's say I have exactly this system, and I want to change, for example, the frequency of oscillations. How will I do it? It could be a very expensive proposition, yes? could put it with me some spaceship, and go to a place where the gravity is different, right? Why not? So what would happen? So if gravity changes, then basically what will happen is both this term and that term will change. So let's say, in fact, do I have it in this one here? Yes. Solet's say I do again. So now, let's take it to, for example, Jupiter. Jupiter, g, is much larger. So what do you think will happen when we go to Jupiter? the fact that the energy was moving from one to the other. Do you think this transfer of energy will be faster or slower? Two omegas closer to each other. Any guesses? AUDIENCE: Smaller. BOLESLAW WYSLOUCH: Take kind of longer. Let's see what happens, right? So we go on the rocket, and nowadays, you don't have to go to the rocket. Just remove one comment. And I went from about 10 meters per square second to 25 meters persquare second. now go to the Moon, which has much lower gravitational acceleration. Let's see what happens. It's a little bit not completely clear what's going on, but you see, actually the motion is kind of a little strange. Look at the red one. The red one is stopping. Then it's going halfway out. It looks kind of messy, doesn't it? And so it doesn't show up here very well, because the parameters have changed so much that I have-- I have those fixed pictures which are-- just a second. the frequency of how the energy shifts from one to the other. And also you can see the frequency going up and down for the same exact conditions. This is now, just a moment, this is a Jupiter. So Jupiter, you see that the frequency itself it's much higher. And the energy transfer between the two things takes longer. On the Moon however, the oscillations actually look really weird. It's kind of, you know, the two frequencies are so far away, and it's really not even a nice oscillatory motion. center mass of the system or just one of the two --? BOLESLAW WYSLOUCH: This one, I think, this one is just one. Actually, the one-- on the difference-- it normally doesn't matter. What matters this is the frequency and how these move to the other. OK? Let's just forget about it. Just keep it. So let me now talk about this thing, which is called beat phenomenon, because when you look at the motion of one of those objects, or the difference between them or whatever. Omega 1 plus omega 2 divided by 2 is like omega, right? 100 plus 105 divided by two is about 100. Whereas this one here carries information about the difference of frequencies-- 100, 102, the difference is 2, which is very small. At Jupiter, those two frequencies are actually very close to each other, because everything is dominated by the gravity, and we have a very weak spring. So we have-- so this term here-- it basically oscillates at the frequency of omega, of thefrequency of the individual pendulum. like this. OK? So there are in fact two-- when you look at this picture, you can see two frequencies. One which is clear the oscillation of the-- high-frequency oscillation. But there's also this kind of overarching frequency of much smaller frequency, and this is what corresponds to a difference of two things. So the system oscillates. So one of those pendula, either of them, is moving fast. But it's going faster. It's amplitude is larger, and after some time, it slows down to 0. There's this kind of frequency of energy moving from one to the other, which is something called beat. So we see this here. We see it on the pendula. But now what we are going to do is we're going to try to hear it, right? So this is a demonstration which maybe it works, maybe not. So let me-- it will work, OK? So we have two speakers. And they basically go on very, very similar frequencies, all right? They both work at similar frequencies. And so when I switched on, you should hear-- hear the sound. they have an amplitude of 1. And clearly, you see that they have a different frequency. So if you take two of those together, same amplitude, just slightly different frequency, and you simply make a linear-- superposition of the two, you will get exactly the beating effect. And this is something that, again, happens very often. There's another demonstration here. I have two tuning forks, and they are very similar frequency. They are coupled because I gave this guy some initial condition. In the experiment, energy is being transferred by this air oscillating here. The coupling goes through the air to the sound here, right? And they have very similar frequency. So they are nicely coupled. But what we can also do-- we can [TONE]. Right? So they're both going.going. Then I stop it. But there's still sound, because the second one picked up some energy, and it took off. Of course, you don't see them. BOLESLAW WYSLOUCH: I don't have to go to Jupiter to modify it, because this one is just a little mass here, right? [TONE] Ah, cool. So now, this thing is probably-- I know it's a period, a fraction of a second,right? Yes? AUDIENCE: Should both of those sine and cosines have Ts in their arguments? BOLESlaws: Of course always. They are both time dependent, yeah. sort of early on, to instead of, so far, when we talked about pendula, we describe their motion in terms of motion of number 1. It turns out we can rewrite the equation into some sort of new variables, where, so-called normal coordinates, where you'll simultaneously describe both of them and then kind of mix them together to have a new formula. So you do change of variables. So instead of keeping track of x1 and x2 independently, you define something which I called u1, which is simply x1 plus x2. equations, which I conveniently erased and make a sum or difference, it turns out that this coupling kind of separates. So I will end up having two separate equations for this one. So in general, the equation of motion would be-- would look like, so let's say I can write down m x1 plus x2. And this immediately-- and it looks-- if I now write it in terms of normal coordinates, then I have that m u1 double dot is equal to simply minus mg over l, u1. The determinants needed no matrices, no nothing. We just added and subtracted the two equations, and things magically separated. So you can always have a linear combination of parameters for arbitrary size coupled oscillators system where you combine different coordinates, and you basically force the system to behave in a way in which it induces the single oscillation, single frequency. So this is a very powerful trick, but usually for most cases, you can do that only after you have solved it, after you've found out normal modes, et cetera. then you can say, ha, ha,. I can I can introduce normal variables and make things simpler. But at the end of the day for complicated systems that work is the same. But for simple systems like this one where there is a good symmetry, you can do it. Anyway, so I think we are done for today. And on Tuesday, we'll continue with forced oscillators. All right? Thank you. "I think we're done for day one. We'll continue on Tuesday," he said.

ROUGE-1: 45.19, ROUGE-2: 43.93, ROUGE-L: 43.55
BERTScore: 60.30

==============================================
==================== [26/100] ====================
Summary:
GILBERT STRANG: The heat equation is the second of the three basic partial differential equations. He says the dependence on t is fast decay, and if K, as K gets larger, later terms in this sum, the decay is really fast. Strang: The term that decays most slowly, k equal 1, there'll be a B1, an e to the minus, pi squared t. The heat is flowing around in the bar, and where is it going? The bar is approaching freezing. ends are kept at freezing, and the inside of the bar, whatever heat is there at the beginning, is going to flow out the ends. So I'm freezing it at both ends. The temperature is escaping out of the center. So maybe I start with-- here is my bar from 0 to 1, and I'm keeping it frozen. F for frozen, f for frozen at that end. So u at 0 and x, I'll say it'd be 1. This way is x. have to find these numbers. And those numbers, of course, the numbers are always found by matching the initial conditions. T greater than 0 uses those Bks. And we're again faced with a Fourier series problem. And I'm finding the coefficients, so that this will match 1, the initial condition. And then, for t greater. than 0, solution u will be, as we said, the sum of these Bk's, which come from the initial. conditions, come from this-- Fourier coefficients. We have numbers, we have something depending on time and decaying rapidly. We're talking about a partial differential equation. So at time 1, if I drew a picture, suppose the heat is, the temperature starts out through the whole bar at 1. But with this kind of time decay, a little later in time, the Temperature's going to be something like that. It'll be way down at the ends, pretty low in the middle. So that's what solutions to the heat equation look like. And this is the step of finding the coefficients in our infinite series of solutions. differential equation. We have a whole function to match, so we need all of those. And Fourier series tells us how to do that matching, how to find these Bk's. So that's a separate and important question, Fourierseries. Thank you for your time. Back to Mail Online home. Back To the page you came from. Back into the article you came From. The story behind the story: Click here to read the full transcript of this article. Back onto the page of the story you come from.

ROUGE-1: 48.15, ROUGE-2: 44.03, ROUGE-L: 44.33
BERTScore: 61.03

==============================================
==================== [27/100] ====================
Summary:
MIT OpenCourseWare continues to offer high-quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourse Ware at ocw.mit.edu. The following content is provided under a Creative Commons license. Your support will help MIT Open courseWare continue to offer free, high- quality educational resources in the U.S. and around the world. For more information on MIT Open CourseWare, visit opencourseware.org. maybe you'll see the distinction between those things and understand why one version of the problem is much easier than another. But we try to respond as quickly as possible when we notice a typo like that so that we can set you guys on the right course. So we've got two lectures left discussing linear algebra before we move on to other topics. We're still going to talk about transformations of matrices. We looked at one type of transformation we could utilize for solving systems of equations. Today, we'll look at another one, the eigenvalue decomposition. This course moves at a pretty quick pace. We don't want anyone to get left behind. Speaking of getting left behind, we ran out of time a little bit at the end of lecture on Wednesday. That's OK. There were a lot of good questions that came up during class. And one topic that we didn't get to discuss is formal systems for doing reordering in systems of equations. We saw that reordering is important. In fact, it's essential for solving certain problems via Gaussian elimination. be stuck. It won't proceed after that. So it's the difference between getting a solution and writing a publication about the research problem you're interested in and not. So how do you do reordering? Well, we use a process called permutation. There's a certain class of matrix called a permutation matrix that can swap rows or columns. So if I want to swap columns, I multiply my matrix from the right, IP transpose. If I swap the rows and then I swap them back, I get back what I had before. This is a form of preconditioning. It's always done via Gaussian elimination if we want an exact solution. You're studying one of them in your homework assignment now, where you know the matrix is banded with some bandwidth. So you don't do elimination on an entire full matrix. You do it on a sparse matrix whose structure you understand. We discussed sparse matrices and a little bit about reordering and now permutation. I feel like my diffusion example last time wasn't especially clear. So let me give a different example of diffusion. seen The Price Is Right? This is a game where you drop a chip into a board with pegs in it. It's a model of diffusion. The Plinko chip falls from level to level. It can go left or it can go right with equal probability. So the probability that I'm in a particular cell at level i is this Pi plus one. And there's some sparse matrix A which spreads that probability out. It splits it into my neighbors 50/50. And we'll see the simulation that tells us how probable it is to find the Plinka chip in a certain column. values for a couple of elements of this matrix. But this is a sparse matrix. It has a sparse structure. It models a diffusion problem, just like we saw before. Most of physics is local, like this, right? I just need to know what's going on with my neighbors. And I spread the probability out. I get this nice diffusion problem. Here's something to notice. This probability distribution always seems to flatten out. It becomes uniform. It turns out there are even special distributions for which A times A times that distribution is equal to that distribution. For a real N-by-N matrix, there will be eigenvectors and eigenvalues. They're special vectors that are stretched on multiplication by the matrix. The amount of stretch, however, is unique. It's associated with that direction. And that describes the eigenvector-eigenvalue pair. But because there's N equations for N plus 1 unknowns, that means they're not unique. We don't know what an eigen vector is uniquely. We can only prescribe its direction. But we'll find them in a second. a matrix is also the sum of the eigenvalues. These can sometimes come in handy-- not often, but sometimes. Here's an example I talked about before-- so a series of chemical reactions. We want to know how the concentrations of A, B, C, and D vary as a function of time. And our conservation equation for material is here. This is a rate matrix. We'd like to understand what the characteristic polynomial of that is. The eigen values of that matrix are going to tell us something about how different rate processes evolve. The characteristic polynomial looks like this. What are the eigenvalues of the rate matrix? What is this eigenvalue 0 correspond to? What's that? OK. Physically, it's a rate process with 0 rate, steady state. What physical process does that represent? It's something evolving in time now, James Swan says. He asks the audience to guess what 0 is and what it means. The audience's guess is that it means 0 is a solution. It's 0. Minus k1 is another solution. The eigenvalues can be interpreted in terms of physical processes. This quadratic solution here has some eigenvalue. I don't know what it is. But it involves k2, k3, k4. And this is a typo. It should be k5. And so that says something about the interconversion between B, C, and D. Is that too fast? Do you want to write some more on this slide before I go on, or are you OK? Are there any questions about this? No. We want to know the eigenvector of the rate matrix having eigenvalue 0. This should correspond to the steady state solution of our ordinary differential equation. Can you do that? Can you find this eigen vector? Try it out with your neighbor. See if you can do it. And then we'll compare results. Are you guys able to do this? Sort of, maybe? Here's the answer, or an answer, for the eigenector. It's not unique, right? It's got some constant out in front of it. James W. Swan: Try this example out. See if you can work through the details of it. I think it's useful to be able to do these sorts of things quickly. Here's a matrix. It's not a very good matrix. But it's all 0's. So what are its eigenvalues? It's just 0, right? And they're 0. That eigenvalue has algebraic multiplicity 2. Can you give me the eigenvectors of this matrix? Knowing what those eigenvectors are requires solving systems of equations. If I know the eigenvalues in A, then I can easily diagonalize my system of equations, right? So this is a useful sort of transformation to do. We haven't talked about how it's done in the computer. These are ways you could do it by hand. There's an alternative way of doing it that's beyond the scope of this class called-- it's called the Lanczos algorithm. And it's what's referred to as a Krylov subspace method. in a lot of cases. You can prove-- I might ask you to show this some time-- that the eigenvectors of a symmetric matrix are orthogonal. They're also useful when analyzing systems of ordinary differential equations. So here, I've got a differential equation, a vector x dot. So the time derivative of x is equal to A times x. And if I substitute my eigendecomposition-- so W lambda W inverse-- and I define a new unknown y instead of x, then I can diagonalize that system of equations. There are many times when there's not a complete set of eigenvectors. And then the matrix can't be diagonalized in this way. So there's an almost diagonal form that you can transform into called the Jordan normal form. There are other transformations that one can do, like called, for example, Schur decomposition, which is a transformation into an upper. And you'll find out that this same sort of analysis can be quite useful in nonlinear systems of nonlinear equations. triangular form for this matrix. We'll talk next time about the singular value decomposition, which is another sort of transformation one can do when we don't have these complete sets of eigenvectors. You'll get a chance to practice these things on your next two homework assignments, actually. So it'll come up in a couple of different circumstances. I would really encourage you to try to solve some of these example problems that were in here. Solving by hand can be useful.

ROUGE-1: 32.70, ROUGE-2: 30.92, ROUGE-L: 30.59
BERTScore: 70.70

==============================================
==================== [28/100] ====================
Summary:
A random variable is a number that's produced by a random process. The number of faulty pixels in a monitor is also produced from an unpredictable randomness in the manufacturing process. One example is a system that you're watching and you're going to time it to see when the next crash comes, if it crashes. That number is produced by this random process of whether the system works or not. It's called a random variable because it's unpredictable that it happens in some random way. It can also be called a non-random variable, because it can't be predicted. that really is modeled in physics as random is when you have a Geiger counter, you're measuring alpha particles. And if I flip coins then the number of heads in a given number of flips-- let's say I flip a coin n times. OK what is abstractly a random variable? Let's look at that example of three fair coins. So each coin has a probability of being heads that's a half and tails being a half. Or alternatively you could think of flipping the same coin three times. heads is a number that comes out of this random process of flipping the three coins. Another one is simply a [? 0-1 ?] valued random variable where it signals 1 if all 3 coins match in what they come up with, and 0 if they don't match. One of the things that's a convenient use of random variables is to use them to define various kinds of events. The event that C equals 1, that's an event that-- it's a set of outcomes where the count is 1 and it has a certain probability. We think of the outcomes in the sample space as the results of a random experiment. They are an outcome and they have a probability. And when the outcome is translated into a real number that you think of as being produced as a result of that outcome, that's what the random variable does. So formally, a random variable is not a variable. Or it's a function that maps the sampleSpace to the real numbers. And it's got to be total, by the way. It's a total function. Usually this would be a real valued random variable. I look at the event that R is equal to a, that's an interesting event. And it's one of the basic events that R puts together. If you knew the answer to all of these R equals a's, then you really know a lot about R. That's why this little topic of introducing random variables is also about independence because the definition of independence carries right over. Namely, a bunch of random variables are mutually independent if the events that they define are all mutually independent. could say explicitly where it comes from as an equation. It means that the probability that R1 is equal to a1 and R2 is equalto a1. And the definition then of mutual independence of the random variables R1 through n, Rn holds is that this equation it holds for all possible values, little a1 through little an. If I have IA I know what A is, and if I have A is. And it means that really I can think of events as special cases of random variables. number of heads we can ask whether the event M, which is the indicator variable for a match-- the random variable M-- and the indicatorvariable IO are dependent or not. Now both of these depend on all the three coins. IO is looking at all 3 coins to see if there are an odd number of heads, M is looking to see whether they're all heads or all tails. And it's not immediately obvious that they're independent, but as a matter of fact they are. this can have value 0 and 1. If R is independent of S then R is really independent of any information at all that you have about S. And of course the notion of k-way independence carries right over from the event case. If I have k random-- if I have a bunch of random variables, a large number much more than k, they're k- way independent if every set of k of them are mutually independent. of f of S, any transformation of S by a fixed non-random function. course as with events we use the 2-way case to call them pairwise independent. If we have k coins and Hi is the indicator variable for how coin I came out, whether or not there's a head, now O can be nicely expressed. The notion that there's an odd number of heads is simply the mod 2 sum of the Hi's. And this by the way, is a trick that we'll be using regularly that events can be defined rather nicely in terms of doing operations on the arithmetic values of indicator variables. makes the k plus 1-- k plus first. And the reason why any k of them were independent was discussed in the previous slide when we were looking at the events of there being an odd number of heads and a head coming up on the i flip. For a bunch of major applications this pairwise independence is sufficient. It's harder to check mutual independence. You've got a lot more equations to check. We'll be making use of it in an application later when we look at sampling and the law of large numbers.

ROUGE-1: 52.78, ROUGE-2: 49.68, ROUGE-L: 49.59
BERTScore: 72.82

==============================================
==================== [29/100] ====================
Summary:
s gawan and the Green Knight um I believe this is the last piece where we don't know who the author is where it's unknown um I find the background interesting and that through textual Clues they're able to figure out who wrote it. It's interesting when they talk about some writer character character character is whatever that word is SAR Gowan as a ruthless bloodthirsty Warrior um we really don't see him in that regard. Throughout the story of seral when we again come back to what a knight truly is. if you look down at the bottom of uh uh uh well it's actually on 176 now he comes in and addresses everybody and everybody gets kind of kind of quiet uh because this is a huge monstrous man with a monstrous Axe and he saysi come to uh speak to the person in charge and off Arthur King Arthur says that would be I and he goes I've come to search you based on reputation remember how we talked about the the honor okay people don't do you know if the knights do something it's a reflection of Arthur and Arthur as we know from all of our you know illusions of movies and cartoons and stuff that you know he is a good guy. your reputation Royal sir is raised up so high and your castle and Cavaliers are accounted the best the mightiest of male clad men in mounting fighting the most warlike the worthiest the world has bred most Valiant to VI with in viral contest and as chivalry is shown here so I am ass assured at this time I tell you that has a track here so he goes on in great detail say I've come here because of the reputation did you notice some of those alliterations sprinkled throughout there hopefully it did. I so a game but to see if people here are as good as their word and so he says on page 177 that I am here not for war and I shall offer to him this fine axe freely that they strike a blow in return for another. Arthur says oh well surely you just this is ridiculous but I will do this if this is what you truly want I'll do it and we all know that Arthur based on what we know of him from the past you know is true to his word. see a big difference uh Raper and this guy big difference okay and so he says I will do this and I will take the axe um where's the actual beheading there on line 182 or so uh they're kind of getting the groundwork going goes when I have taken the blow after you have duly dealt it then you may keep your Covenant and call on me and if I waft you no words then well may you prosper stay long in your own land and look for no further trial so if after the deal I'll tell you where you can find me I will give you my name there are no tricks here. bath he didn't know that he was going to have to marry that woman did he no would he have still done it well how much does he value his life you know probably. The Green Knight graciously stood on the ground with his head slightly slanted he even got down exposed his neck the naked neck for the business now doe go gripped his ax gathered up and slashed down and what happened well line 203 the fairhead fell from the neck struck the floor and people spurned it as it rolled around. his Steed snatched the bridal stepped into the sturup and swung a loft holding his head in his hand by the hair he settled himself in the saddle as steadily as if nothing had happened to him though he had no head. Then the head will obviously have to tell him his name and where you can find him are you envisioning this cut the head off the body walks over I mean you've seen it comically where a headless body is looking for a head on the ground right. will be able to pick it up and still live and survive and so oh crap this is not going to turn out well. The Knight tells him you have a year to find me you can find me I the Knight of the green Chapel green Chapel no kidding Everything Green line 232 233 come or be called a coward and it's not just sir GNE being called a cowardly we've got to understand that mindset who would that be calling a coward Arthur and everybody else the Knight came here specifically to challenge the best that Earth has ever bred. mind um in this you know kind of lengthy introduction just to set up the fact that this guy is having some supernatural abilities that the normal person like probably GNE does not have. So that will lead us into uh into the uh the coming up here with him looking for the night so at the bottom of 181 uh he's gone off on his journey had a year and a day to find it and throughout the book you I'm sure there are tons more Adventures probably more of those uh you know uh battles or actions. you receive the the hunter the owner of the house the husband says whatever you receive you must give to me that seems kind of weird what possibly could he receive while he's there well we find out that the wife really kind of starts to come on to him over time okay real flirty she's she's a temptress okay very seductive uh she gives him a kiss what does he do when the husband comes home that day cuz the husband's going to share his his food share his everything with him as long as GNE you share with me. you know of his pact uh with King Arthur to be a good individual. She eventually does give him a green girdle um a green corset a a sash some sort of clothing that he can wear under his stuff and she gives that to him and he accepts it okay which isn't necessarily so bad. She says you wear this and no harm will fall upon you that's about the best thing you can say to somebody who's getting ready to go get hit in the head with an axe. up my sleeve come time to get that shot in the head um and so he does leave and he keeps that GLE for himself um and doesn't give that away page 185. He roamed looking for this man he roamed up to the roof of that rough dwelling then from that height he heard from a hard rock on the bank beyond the brook a barbarous noise. What it clattered amid the cliffs fit to cleave them apart as if a great sight were being ground on a grindstone. thing and so he hears it you know happening and um so he screams out and the and the um and the Green Knight comes he says by there said one on the bank above his head and you shall swiftly receive what I once swore to give you. He chastises him and tells him take off your helmet uh and offer no more argument or offer noMore argument or.thing and he gets ready to hit him and it's one of those kind of like you've had friends before probably have come up to you and go like that. action than I did when you whipped off my head with one stroke no s GNE by God who gave me a soul the Grievous gash to come I Grudge you not at all strike but the one stroke and I shall stand still and offer you no hindrance you may act freely I swear but page uh not page line 401 uh the dawnless man would have died from the blow but go glanced up at the Grim axe beside him as it came shooting through the shivered shivering air to shatter him. that upsets him obviously it's calling into question his his loyalty his OES his his manhood um he says do it again I will not flinch go on game on 185 187 excuse me um I shall stand your stroke not starting at all till your axe has hit me um gaw waited unswerving with not a wavering limb but Stood Still as a stone or the stump of a tree. Then again the Green Knight began to GD so now you have a whole heart I must hit you May the high Knighthood which Arthur conferred preserve you. celebrate was it New Year's is that what it is we'll come back and celebrate this cold New Year I'm not mad at you so now we need to go back and look remember the archetypes we talked about we have the the protagonist the antagonist who is the real villain of this piece is there a villain in the Green Knight? The Green Knight's ultimate purpose is simply to challenge challenge King Arthurs and his crew and see if they truly are as honorable as they say as legendary as Legend has as the stories have it. so he's the protagonist but yet I don't think uh you know the whole good vers bad protagonist you know hero villain protagonist antagonist it's kind of a a mdl you know very murky we don't understand exactly who it is. We do have the Damsel in Distress we have that woman the temptress um the sexual being that's trying to corrupt the hero um and take him down the path maybe uh satanic in some degree with regards to trying to lure the good person away with the forbidden fruit.

ROUGE-1: 53.47, ROUGE-2: 52.14, ROUGE-L: 52.62
BERTScore: 64.21

==============================================
==================== [30/100] ====================
Summary:
hey what's going on YouTube boy Robert and my mission is to teach you everything in the kitchen now earlier this week at work I learned and I was wondering what are the fruits and vegetables I can turn in the salt as well. Today we have blueberries strawberries Kiwis red beets yellow beets pineapples right in fruit and cucumber this is the equipment you'll need for today you don't need one blender sheet trays mason jars parchment paper aluminum foil a spice grinder a bowl with a strainer and a plastic spatula.

ROUGE-1: 27.87, ROUGE-2: 27.37, ROUGE-L: 27.87
BERTScore: 66.38

==============================================
==================== [31/100] ====================
Summary:
The six Vital Signs are pain oxygen saturation temperature heart rate respirations and blood pressure. Before you start you want to perform hand hygiene and provide privacy to the patient and tell them what you're going to be doing. If they do have pain ask them the quality what does it feel like and where it is at so hi Ben my name is Sarah and I am your nurse and I'm going to get your Vital Signs and I'll be getting your hand hygiene as well as your hand movements. first thing I want to ask you what your pain rating is are you having any pain rate on a scale of0 to 10 yes pain in my shoulder and it's a three okay and what is it feel like it's just a sharp pain when I raise my arm okay now I'm going to get your temperature there's several ways you can take a temperature every facility has a different system set up so use what they have but you can taking it orally you can takes it axillary you cantake it tanic in the ear or you can taken it temporally or rect um rect is the preferred route usually on your pediatric patients but in adult patients normally we do it orally. we're going to do turn your thumb Omer on make sure you're using the proper sleeves if you have any sleeves for it clean it everything like that follow your hospital protocols and have the patient lift up their tongue and put the probe underneath the tongue and have them close the mouth with the tongue over the probe and hold it there until it beeps a normal temperature is about 97° fit to 99° F okay and take the thermometer out and read it and his temperature is 98.2 and then clean it properly per Hospital protocol. In a second I'm going to show you how to actually count the heart rate using the radial artery. While I'm counting the heart rates I count that for 30 seconds if it's regular and then the next 30 seconds I count the respirations which I look at the rise and the fall of the chest and that equals one breath. If you tell a patient you're going to count their respirations they change the rate of breathing so it's good to conglomerate those two together so you can get a more accurate reading. groove right there or you can use the brachial artery which is in the bend of the arm where the anticubital fosset area is. You're going to use the diaphragm of your stethoscope and you're just going to place it over where you have heard that brachian artery and then you're going on to blow the cuff up to about 180. A normal pulse rate in an adult is 60 to 100 beats per minute okay the heart rate I got 60 and his respiration were 16 now we are going to get his blood pressure. to 200 mm of mercury or until you don't hear that braak your artery anymore okay we're blowing it up to about 200mm of mercury. We're listening for that first sound and that first s sound will be our top number of our blood pressure which is our systolic. That is how you check bottle signs now whenever you're done remember to let the patient know what their bottle signs were and um do hand hygiene and clean your equipment before you go to the next patient so be sure to check out all my other videos on nursing skills.

ROUGE-1: 54.20, ROUGE-2: 51.62, ROUGE-L: 51.40
BERTScore: 74.74

==============================================
==================== [32/100] ====================
Summary:
so we saw that the three-point correspondences are needed to solve the camera pose estimation problem in the grenade formulation. The disadvantage of this particular formulation is that it ends up with a four degree polynomial which means that it could give up to a total of four possible solutions. In order to choose the correct solution at least the fourth point is needed here so what we usually do here is that if we choose the grenade algorithm we'll use the three point to solve for the p3p problem and given that camera pulse of rnt because we also know k. i will talk about the linear four-point algorithm that was published in the 1990s. We have a system of three polynomials equation from the cosine rule where s1 s2 and s3 are the unknown depth of the three points. Each equation is only a function of our two unknowns so we can see that any three of this combination would give us one fourth degree polynomial which we denote as g x. There's no guarantee that two separate equations would be the same solution and solution would be considered as correct solution. furthermore we have three polynomial equations with the same unknown variable so there's no guarantee that all this are going to be the same solution due to noisy data and probably the most important part is that we cannot profit from this data redundancy which should increase the stability. In this case here because get solutions doesn't agree well due to the noise so it means that the solution is not stable at all and a better solution here is proposed by uh kwan and lan in the paper published in active tipami in the year 1999. any of the unknowns in the the depth where we simply write it as s i square over here so this can be derived in in this way so here i wrote out all the six combinations of the polynomial equations f i j over here we can see that each one of this equation it's a just a function of two unknowns. When we can factorize out all these coefficients as a matrix and the knowns which are x 4 x 3 x 2 x and 1 can be written as a vector over here 0 0 and as a result we'll get a three by five matrix and a five by one vector. over here which is in the form of a x equals to zero uh we have seen this homogeneous linear equation many times so now this means that we get this form of equation over here. A t which is written as a t equals to 0 over here and what it means is that we simply have to solve for the unknowns over here so this matrix here is known and the unknown contained in this particular vector here and we know that since a is a three by five matrix uh at most have a rank of uh three this is the same as solving ax equals tozero. s1 we know that t5 here is actually a vector that is made up of the same entry but of different order so x4 x3 x2 x and 1 of different entry. We know that by observation any two elements the product of tij is going to be equal to tk and tl for this constraint to be valid where i plus j must equal to k plus l. We can substitute the respective components of t5 into this particular constraint to get this equation over here. three by one vector it consists of lambda squared, rho squared which are the unknowns that we want to solve. Taking svd of b we get the left singular factors multiplied by the singular values as well as the right singular vector matrix over here. The solution would be the one that corresponds the last column of v over here so once we have solved for the null space vector y using the svd what we can do is to proceed on to solve for lambda and rho because we know that y 3 over here is equals to a lambda square. rho square equals to y 2 which we can take this divided by this to cancel away Lambda one of the lambdas here to get the ratio of Lambda over rho. We can do the same thing by y1 divided by y2 where rho cancels off and we will get the same ratio so there are two possible solutions. After we obtain the ratio we can substitute it back into this equation over here which i have gotten from the two null space basis vectors e4 and v5 respectively earlier on when we solve for t5. where we can solve for since we know that x equals to s1 squared. Once s1 is solved we can back substitute s1 into the polynomial equation of f i j s i and s j equals to zero. After we have gotten all the unknown depths we can do the same thing to to apply absolute orientation to recover the camera pose as in the grenade algorithm and here what's interesting here is that because we have four point four point we can get all the depth in this way. correspondences and we can see that because rho and lambda here can be determined in a unique way and uh x here can also be determined  in the unique way where we simply take out the average of this because all the illusions are going to be quite similar or quite close to each other. As a result we'll get the unique solution provided that the four points are not degenerate so uh in this linear four point algorithm the the there will still be two degenerate cases. as what we have seen earlier on now uh it happens that the linear four-point algorithm can also be applied to more than four points so for example when n equals to five when there are five point correspondences and in this particular case uh we uh we will end up to have a system of polynomial equations that is in this form a uh t equals to 0 where t here still remain as a 5 by 1 vector that consists of x that we saw earlier on where x here is simply equals to s 1 square. equation we can stack them all up so one two all the way to six equations and we end up with a coefficient matrix with an a matrix of of dimension 6 by 5. in order for non-trivial solution to exist then this guy here better be of a maximum of rank four so what we can do here is that we can take the svd of a and this will give us u sigma v transpose where we simply the vector that corresponds to the least singular value in sigma. The epmp algorithm mitigates the problem of the linear endpoint algorithm that was shown earlier on by quan and lun that was published in the year 1999. The algorithm has cubic complexity in the order of the number of points that is used to form a. The cubic complexity here becomes a limiting factor for us to apply for this particular algorithm to a number of point correspondence which is significantly large now in 2006 the paper published by vincent lapati which is called the epMP algorithm was first published. proposed by lapati in the year 2006 is that instead of using every single point correspondences that is given to us the the core idea is that here we'll make use of all these points to define four control points. Even for a very large n the number of control points still stay constant as uh fall. So now this control point becomes our unknown so that we also need to solve for in addition to the camera rotation and translation where these 3d points they are given and they are known. now we have two equations over here in terms of uh in terms. of the control points and all the known uh parameters because this is just a projection of one single point i over here. Since each point correspondence gives us two independent equations what this simply means is that we need to stack them up into 2n by 12 matrix which we call m to solve for the 12 by 1 unknown of control points in this homogeneous linear equation. The number of basis solutions that we can get from solving the equation mx equals to zero over here depends on the size of m and which in turn depends on. the number of point correspondences that we have. that parameterize the four unknown control points in the camera coordinate frame and we'll make use of the known distance between the control points to solve for the unknown beta over here. We note that the distance between any two of the points are always going to be the same regardless of the reference frame. Since we have four points and all together we would have six constraints over here we have all together six pairs of distances over here one two three four five and six the six distances which we can put together into this weighted sum equation. for the camera pose using a set of control points using four control points in particular and we saw that this uh it's uh the complexity is a linear in terms of the number of points which is much easier to compute then we also saw the degeneracy cases for the camera post estimation problem in particular. If all the points plus the camera center forms a plane then this is also a degenerate case and that's the end of today's lecture thank you mx equals to zero. Mx equals zero.

ROUGE-1: 32.61, ROUGE-2: 31.49, ROUGE-L: 31.64
BERTScore: 73.86

==============================================
==================== [33/100] ====================
Summary:
Time dilation is a change in the light frequency. If there is a time dilation effect due to gravitational fields, then there's also a redshift which is of gravitational fields. The way to think about this is first to say, OK, now the light-- the delta t equals the light to travel-- is l divided by c. The change in velocity is g, acceleration. So the Doppler shift then is c divided by l, which is the speed of light. And I would like you to get a feeling. How big can this effect be, the effect of redshift here? the frequency, the new frequency, divided by the initial frequency. And that can be approximated by 1 plus delta v over c. So we find that it's 1 plus g times l over c square. Now the speed of light is pretty fast, 3 times 10 to the 9 meter per second. And this distance is only 22 and 1/2 meters. But nevertheless, experimentalists at Harvard tested this effect. So Pound, Rebka, and Snider in the 1950s and '60s were able to show this very tiny effect.

ROUGE-1: 72.00, ROUGE-2: 68.07, ROUGE-L: 57.52
BERTScore: 81.34

==============================================
==================== [34/100] ====================
Summary:
During the semester we have a few recitation instructors they help with the students during the recitation section. During those sections your the the instructor will solve a similar problem like what is actually covered during the same during the lecture and that give the students another chance to look at more example and to get for media will get used to the calculation which we carry how for the first time during the the lecture. We did not record the Recitation sections during the fall semester in 2016 on the other hand we included problem-solving videos from Professor with Busha.

ROUGE-1: 67.77, ROUGE-2: 66.22, ROUGE-L: 67.77
BERTScore: 85.45

==============================================
==================== [35/100] ====================
Summary:
The CDF of x is the probability that X is less than or equal to little x. We use the standard formula, which is minus infinity to infinity t times fx of t dt. The integral of u to the a t is 1 over a times e to the t. The derivative is what's going to go in that integral. The CDF is evaluated from 0 to infinity, but then you take the limit as x goes to x. It's not going to going even if you try all kinds of u substitution. Infinity. So for the limit, notice that x increases as x goes to infinity. And this exponential decays. So they're kind of competing for each other. But the exponential is going to win because it decays way faster than x. And so this first term is going. to go off-- the limit isGoing to go to 0. All right. For this, if you evaluate the balance, the infinity makes this 0. And 0, you're going to get 1 overlambda. So that's 1 over lambda. the limit as x goes to infinity-- the exponential will beat x squared. No matter what polynomial we put in there, the exponential's going to win. We're given that x1, x2, and x3 are independent and identically distributed. They're exponentials with rate Lambda. We are asked for the PDF of z, which is the max of x1,. We take the CDF and then take the derivative, right? And so we have 1 over Lambda squared for the variance. of structure as before. If z is less than 0, x1, x2, x3 are positive-- non-negative. And so this is the probability that if you get little z less than0, you're not going to have any probability there. And if z is greater than or equal to 0 is where it gets interesting. We need to do something special. So the special thing here is to recognize that the probability of the max being less than orequal to z is actually also the probability. of each of these random variables individually being more than or less than z. events are equivalent and this is true. By independence we can break this up. And we get-- these are all CDFs of the exponential and they all have this form. Plug this in here. And then, try to take the derivative to get the PDF. Let's see. So it's going to be the same, like this for z less than 0. For z greater than or equal to 0, it's Going to be 1 minus e to the minus lambda z cubed. So it's going to be-- Notice the similarity between this and this. The only difference is this has a 2 lambda in there. That means that w is an exponential random variable with rate 2 Lambda. You can also take the derivative of this and find that you get this. OK, so we're done with the problems. We computed some interesting quantities for the exponentialRandom variable in this. So then the PDF isgoing to be an exponential, whatever it is for an exponential.

ROUGE-1: 42.40, ROUGE-2: 40.42, ROUGE-L: 38.94
BERTScore: 70.93

==============================================
==================== [36/100] ====================
Summary:
Professor: Can you explain the physical significance of the crystal momentum? Professor: Let me answer that in a slightly backward way. Let's step back and think about the momentum, and ask what the momentum is. Professor: If you have a wave function, sine of x, such that, the expectation value of the wave function is x, then the momentum of that function is 1/x. The momentum is the same as the speed of light, which is the speed at which light travels through the air. in the state SI of x in the stateSI is equal to x naught, and the expectation value of p in theState SI is p naught. Then if you want to change the momentum, increase momentum by h bar k, the way to do that is to take SI and build a new wave function, SI tilda. And then the expectationvalue of x is the same. So, the information about the momentum can be encoded in these spatial variation of the phase of the wave function. The momentum is the thing that commutes with p or with x by i h bar. Another way of talking about the momentum is that it governs the spatial variation of the phase of the wave function. The crystal momentum is defined from beginning, from the following property. If we have a potential v of x, which is. invariant under shifting, by one lattice spacing, by some l, v of X, then this tells us that the energy. operator is invariant if we shift by l. The eigenfunction, or the eigenvalue of our wave function, under translations by l, is a quantity that can be determined simultaneously with knowing the energy. If you have q, which is 0, and you increase it to pi over l, that value is effectively the same as the value minuspi over l. But that's really strange because that means that q itself, it's not strictly conserved. It's conserved mod 2 pi overl. When you have momentum conservation, momentum is strictly Conserved if there's no force. And even if there is a force, it is increasing control by the force as you turn on the force. just constantly increases. For the crystal momentum, that's not the case. You turn on a force, it increases according to the conservation law. But it's not increasing constantly. It's periodically defined. So it increases then it ends up at a smaller value. It increases and ends up in a phase. So developing an intuition for the crystal. momentum, I think, is best done by just playing with examples. And you'll do that more in the course on solids, which I encourage you all to take. Because it's really beautiful stuff. glossing over in the entire story here. So, is u of x a real function? Well, so when we started out asking what are the eigenfunctions of the transit by l operator, all we showed was that, and I'm going to do this on a separate board just to make it clearer. Tell me if this turns off, because it kept bumping. OK. So we've determined is that if we take q l is equal to alpha, then Phi sub q if eigenvalue is written in the form e to the i q x u sub q of x, where this is periodic. In describing a particle, we should use Cartesian coordinates, or should we use Spherical coordinates? Well it can't possibly matter. And so you'd better make sure in any description of your system that changing your coordinates doesn't change your results. And here, that's exactly what's going on. And that's the difference. The difference is that when you fold them up, you're imposing this periodicity and you're labeling the eigenfunctions by q and the overall number of k phases that you're subtracting off. the imaginary part, h bar over 2 m i. Well, hbar over m times the imaginary part of SI complex conjugate derivative, with respect to x, which is the current, in the x direction of SI. And we need this to be imaginary, or we will get no current. You show this in a problem set, if you have a pure, real wave function, for example. A single real exponential, that's decaying, as on the wrong side of a barrier. we want the imaginary parts, that's going to be e to the I over m. And then we're left with u squared of x. So this is the current, but we have to do it-- we had take advantage in order for this to be sort of clean, we had to take advantage of u being real. Everybody cool with that? Now there's one last twist on this, which is that if I have k-- if I've got q. If I have q, and I want, I can always write it as some q naught plus n pi over l. function not by single number q, but by q naught and an integer n. n is an additional integer, and what it's telling you is how many times did you have to shift back to get into that fundamental zone between pi and minus pi. So the current depends on both the part defined mod 2 pi over l, and the integer, which tells you how many factors of 2 Pi over l did you subtract off to get to that fundamental domain. So to specify a state, I don't just have to specify q NAUGHT, I also have to specifying N. upon m u squared of x. So we get a contribution from the crystal momentum and from which we're in. OK? So sort of an elaborate story to answer the phase question. Yeah? AUDIENCE: [INAUDIBLE] PROFESSOR: Good. So here we had SI-- so SI-- I'm sorry. I should have done this for Phi. But I meant this wave function, right. This is Phi, this is Phi q. So from here we're going to get the imaginary part. function of q, not q naught, but so here's pi over l. Here's 2pi over l, Here's 3 pi overL. And I need to do this carefully, because it's incredibly difficult to get the straight. OK. So for every value of q there's an allowed energy. But it's different than it would have been for the free particle. And then we do the same thing for the next state. And it looks like this. And now imagine what happens when we take this, and we it over one two. to plot u with respect to k instead, would that just be a parabola dotted line? If so, why do we not have really-- PROFESSOR: If we just wanted-- sorry. Say it again? AUDIENCE: E as a function of k instead of q. PROFessor: Oh. But k is not a well-- so what is k? K is just defined as h bar squared, k squared upon 2 m is equal to e. So this doesn't tell you anything. this diagram is telling you is which e's are allowed. If you put on a capacitor, played across your perfect lattice, you don't get any current. So the particle, the charged particle in your lattice just oscillates back and forth in a block oscillation, running up the band, and down the band. The question is could you explain again how imperfections and a lattice leads to actual conduction? The first question is given that that's obviously not what happens in real materials, why don't you explain it? we just give up on quantum mechanics and say it totally failed? And so this is a totally reasonable question, and I want to emphasize something important to you. That model led to a prediction, which is that if you put a capacitor plate across a perfect crystal, then you would get no current flowing across, you would just see that the electron wave packets oscillate. And that is manifestly what happens with copper. But the experimentalist comes back to you and says look dude. That is a ridiculous model because the copper isn't in fact perfect, it's messy. the theory side, because I'm a theorist and you should not let me in a lab. But I collaborate with experimentalists, so they're nice people. They're very good physicists. So here's something you can do. You can build a system that has exactly a periodic potential. It turns out it's very difficult to do this with quantum systems. But what you canDo it with lattices not of atoms, but lattices of dielectric. That equation can be put in exactly the same form as the Schrodinger equation for the time evolution of a wave function. To handle an electric field, you need the potential to be constantly varying. Instead of making it just perfectly periodic, let's make the index ramp just a little bit. In this experiment, so as the wave packet moves along, what's discovered is that the position-- if I draw the x as a function of t, so now the role of t is being played by the distance it's moved along the wave guide. It exhibits beautiful block oscillations. And this has been proved in a very small number of real honest quantum mechanical systems. this part of the field right now is we know that it's true, but we want to see it. We want to feel it, so various people around the world are working on making a truly beautiful demonstration of this bit of physics. But, the basic question is how robust is this. And the answer is it's not robust at all. But which you can tell because everything in the real world has enough impurity that it conducts. Or as an insulator. Yeah. And that's actually, it depends on the lattice. situation, it depends on the system. And exactly how it depends is something that is an active area of research. So don't throw away the model. Observe that you've modeled the wrong system. If you find a system that fits your-- that is-- that shares the assumptions of your model, that's when you ask did it work. And it worked like a champ. OK. So now let's talk about real materials. This is going to close up our discussion bands and solids. But that's OK. There are lots of questions and they were good questions. This is an extremely brief. But I want to ask you the following question. What happens in the following three systems? So first, imagine we take why don't we take a system with built out of single wells, which have some set of energy eigenstates, and then we build the periodic array out of them. What do we expect to see when we build a lattice? We expect that this is going to-- that these states are going to spread out into bands a funny way Yeah and let's just talk about the 1 d potential. single electron, and let's put it in the system. What will happen? Well if we put it into the system, what state will this single electron fall into? Yeah one event. But which state? AUDIENCE: [INAUDIBLE] PROFESSOR: Yeah, if you kick the system around, you let it relax a little bit. It's going to fall down to the ground state. You have to couple to something else like hydrogen has to be coupled with an electromagnetic field to decay. atom is hydrogen, just for-- this doesn't actually happen, but just imagine-- in particular what it means is it has the ion, the nucleus is charge plus 1. And so in order for the system to be neutral, I must have one electron for every well. So if I put in the n electrons I need to neutralize a system, where do those n electrons go? Yeah, they fill up the first band. And if we let the system relax with lowest energy configuration, every state in this lowest band will be filled. This system is in an energy eigenstate. In particular, it's in a completely antisymmetrized configuration, because they're identical fermions. If we want to induce a current, what do we have to do? Yeah. We have put them in a superposition. But where's the next allowed energy eigenestate? Next band. So it's on the next band. It's in the next energy eigestate. The next allowed Energy Eigenstate is in the second band. macroscopic amount of energy. Well, it's not macroscopic. it's large. It's not infinitesimally small. That means that there's a minimum amount of. energy that that incident light must have in order to excite the. electron in the first place. Crystals are transparent unless you look at sufficiently high frequencies. If you looked at low frequencies, your crystal should be transparent. Well that's really interesting. In particular, we immediately learn something cool about two different materials. Consider diamond and copper. These are both crystals.  spin in one dimension is little-- I'm lying about spin. Electrons spin up, and electrons spin down, will generically have different energies. In 3D, this isn't such a big deal, because those splittings are tiny. But in 1D they can't. So I mean, that's also not exactly true, but it depends on exactly the details of the system, is what I wanted to get to. Curse you. But do you really want me to get in spin? Man. the story changes in a dramatic way. There the gaps are not the same. That they do not remain constant. And then we turned on an interaction which was the energy costs, the energy penalty for having angle momentum in z direction. Which added an l z term to the energy. And what you found is that as a function of the coefficient, which I think we called epsilon, of that perturbation of the energies of the energy was equal to l squared over 2 i plusepsilon. LZ: States from different multiplates, with different values of l, had energies that could cross as a function of the strength of the deformation of your system. LZ: There's no nodes here in three dimensions. There's one that changes, one that doesn't. And then this guy has five. One, two, three, four, five. And what we found here is that these guys could cross. And this split into, so this is the [INAUDIBLE] l equals 1. So l equals zero. we add in a lattice we get bands again. The structure's a little more intricate because it depends on the momentum. But these bands now can overlap. OK. Everybody see that? Because there's nothing preventing states from different-- in different multiplates from having the same energy in three dimensions. There's no nodes here that tells you have to keep the ordering constant. Now we turn on the multiple particle potential, and they can interact, they can overlap, and that's what happens. is the length of the energy of the last electron that you put in. How much energy do you have to give the system, do you. have to add the system to excite the electrons into excited states, in. particular into superpositions so that the electrons can move? AUDIENCE: [INAUDIBLE] PROFESSOR: Yeah. Preposterously small amount. An amount that goes like one over the number of particles. So in the continuum limit, it's zero. There's an arbitrarily nearby energy. called a band insulator. Because there are other ways of being an insulators. So what determined the exact band structure in for a 1D periodic potential? Two properties. One was l, the periodicity. And that came in the q l and k l. And the second is the detailed shape of the potential. Now in three dimensions, the things that are going to determine the potential are not just the distance between atoms, but you have a three dimensional lattice. And so when you solve the problem for the energy eigenvalues is a function of now the three different components of the crystal momentum, you'll get a different set of equations. the atomic orbital structure of the individual atom, the crystal structure, and the resulting band structure. You will almost always find overlapping bands in three dimensions in sufficiently high energy. What we need is one of two things. We need either the band gap coincidentally is ridiculously small, or we need a free particle, which is a conductor. But that's sort of stupid. But a better answer would be, well, can you have a system where there are bands in one dimension? And this is why Matt was barfing at me. but you didn't have one electron per potential well? And yeah. You could orchestrate that in lots of ways. Now it involves orchestration. So it's not the generic system that we were talking about here. But you can't orchestrate it. So spin is a useful thing that gives you an extra handle. If you have twice as many states per well then you can have half a band filled. That's one way to do it. Then it becomes dependent on details of the system, which is what I didn't want to get into. The temperature controls an energy scale for a real material. If you have a hot piece of copper, then the lattice is wiggling around. And every once in a while, an ion can hit one of the electrons and excite it, give it some momentum. And so there's an available reservoir of energy for exciting individual electrons. So when I say small, that doesn't mean anything. I need to tell you small compared to what.what that means. OK. Delta e is very small. Now delta e has dimensions. It has units. excited above the gap. The probability goes as e to the minus delta e over kt. At very low temperatures, if the gap isn't 0, then this is 0. It doesn't happen. But at large temperatures, the denominator here is large. If the temperature is large compared to the width of the gap, than this is a thermal fluctuation. And as a result, you constantly have electrons being excited up, cruising around, falling back down. And they can ask-- and both when asked, although not quite in this language, how likely are you to get an electron up here? small number. And e to the minus of a small number is close to 1. So at high temperature, you're very likely to excite electrons up here. This is called a semiconductor. And there are notes on the Stellar web page that discuss in a little more detail what I just went through and show you how you build a transistor out of a semiconducting. OK. So that finishes us up for the band gap systems for periodic potentials. And that's pretty good for 15 minutes of work. It's not bad. Photonic crystals are periodic arrays of dielectrics. They have bands of allowed energy and gaps of disallowed energies where no waves propagate through. The structure of a photonic crystal on the surface of a butterfly wing makes it shiny and blue. It looks like it's a crystal reflecting in a specific frequency. At some sharp blue. And the reason is, it is exactly this form. If you look at it under a microscope, you see little rays of protein which have different dielectric than air. and metallic without actually being shiny and metallic. And it's not a pigment, so it doesn't absorb light and decay over time. It's like the best thing you could ever do if you wanted to be a shiny, fluttery, flying thing. OK. So that's it for band gaps. And I want to move on to the remainder, the last topic of our course. Which is going to be entanglement and quantum computation. And here I need to give you one quick observation. The probability of finding the particle at point A is given by chi a squared. This is normalized, so when we integrate against it, we get 1. And similarly, the probability that we find the second particle at b is this thing norm squared. And it's independent of what a is. But we also studied the symmetric configuration, which was equal to 1 over root phi, root 2. And this tells us something totally awesome. We either find it at chi of a or chi. So there's a factor of one half. Quantum physicist David Wheeler: Measurement of one particle tells you something about the second particle. Wheeler: I could've taken these particles, put them in this entangled state, and sent one particle off to a distant planet. And my sister measures this second particle and determines what state it's in and is immediately determined what state the first particle is in over in this distant planet Zorg, right? So that's deeply disconcerting, he says, to those of us who have studied quantum mechanics up to this point. yet another moment of serious discomfort. How can something here dramatically change the state, the configuration, the initial configuration, of a particle arbitrarily far away? Isn't that deeply concerning? And if you think about relativity, this should be all the more deeply disconcerting. So there was a person that roughly this time, a little earlier, who was troubled by this problem. And his name was Einstein. And so one of the things that's kind of amazing is that he created a thought experiment which we're going to study in detail next week. who have taken courses in [INAUDIBLE]-- and I'm sure that's all of you because of the GIRs. So I'm very used to microphones, but not in this context. OK. Is this-- yeah, it's on. Can you hear me? All right. So there are lots of ways to slice the story of Einstein by the time he reaches the EPR experiment, which is Einstein, Podolsky, and Rosen for the three people who actually wrote the paper. Hard to find. It's really sweet. Jeremy Bernstein, who is a physicist. A physicist and writer. He's in his eighties now. He lives in Aspen. He worked with CERN for a number of years. He wrote for the New Yorker. Bell had a friend named, I think, Bartelstein. Who had two quirks. An unusual color sense and a taste for mismatched socks. Bell used to say, if you saw one leg and that sock was pink, you knew to a certainty that the other sock was not pink. I think-- I'm trying to remember who this is originally attributed to. Same thing. If you have a coin and you cut it in half down the-- so you've got two coin shape disks. And you see the head that you know somebody-- somebody at some other casino is cheating by tossing in the half coin that only has a tail on it. So there are lots of ways to represent this. And many physicists being very witty indeed have come up with different metaphors for it. if you're sort of approaching it naively. What Einstein, Podolsky, and Rosen argued was actually something a little bit-- in fact, the paper comes to an end on that note of queasiness. And they have definition for what reality is. And that is something whose-- if you can perform a measurement, you know that quantity absolutely. But you can't do the-- so on the one hand, quantum mechanics says you can’t know physical reality to this level of precision. they claimed was a paradox. And this paper was published. And it received a range of reactions from indifference by younger physicists who said, we don't care that it's weird. And most notably Niels Bohr found this paper really troubling. And he spent about six weeks, apparently, discussing this and trying to come up with a response to it. And what he responded was essentially that-- in some ways, it was in some way a paradox, as well as a good thing. Einstein had argued that the EPR paradox suggested that quantum mechanics was incomplete. Bohr essentially responded in effect that Einstein's description of quantum mechanical explanation was inadequate. The experiments were done, and I imagine are still being done, as sort of demonstrations. And they showed that Bohr's interpretation was correct and that yes, quantum mechanics produces results that are non-local just as Allan described to you. And that the world really is as strange as people first glimpsed in 1925, '26, and '27. stupid. He was Albert Einstein. But he was aesthetically incapable of pursuing this new physics in ways that were possible under the research possibilities of the time. And that is what I would leave you with. Physics is an aesthetic as well as an intellectual pursuit. So thank you all. [APPLAUSE] Back to Mail Online home. Back to the page you came from. Follow us on Twitter @dailymailonline and @MailOnlineernews. Back To the pageyou came from, back to the Daily Mail home.

ROUGE-1: 45.56, ROUGE-2: 43.64, ROUGE-L: 42.53
BERTScore: 67.77

==============================================
==================== [37/100] ====================
Summary:
The proper way to chop fresh herbs to get maximum flavor is to chop them not bruised them now basil this is a soft herb so treat it with some respect when people go mad chopping herbs all the goodness comes out on the board I want the goodness left inside the basil place them all inside one another with the largest leaf at the bottom and it's almost like rolling a cigar large one at thebottom small ones in the center and then look place them down together just roll them nice and gently don't bruise them step one rolled ready to slice sharp knife imperative fingers tucked in the bottom part of your knuckle is the guide between you and the herbs. bunch of coriander hold it down and just lightly shave the leaves off the stalls bunch them up together and then just again let the knife do the work tuck the fingernails in and just chop once and once only don't hack it just chop it you can always identify when you bruise the herb when you've removed the herbs off the board that's a big green patch mmm full of flavor and none of the goodness is left on the chopping board if you have fruit that's not perfectly ripe the tip is to put a banana in a paper bag then add your unripe fruit. lemon squeeze a little bit of lemon juice and that instantly gets rid of the heat fresh lemon juice for perfect ball potatoes always start them off with cold water and never boarding water this way by the time the center's are the potatoes are cooked the outside won't be falling apart my tip to get the flesh out of a Kiwi this is simply cut the fruit in half and scoop out with a teaspoon try it it really works. A great tip to check if a pineapple is ripe is to pull a leaf out from the top if it comes away easily it's ripe and ready for slicing.

ROUGE-1: 60.61, ROUGE-2: 59.67, ROUGE-L: 60.61
BERTScore: 81.76

==============================================
==================== [38/100] ====================
Summary:
In this video we're going to be going over our weekly inlex practice question. Let's see what our question says a patient who has a health history of uncontrolled hypertension coronary artery disease and diabetes militis is prescribed to take propanolol. If you have provided the patient with education about this new medication which statement by the patient indicates your teaching was effective. If I miss a dose it is important that I double the next dose to prevent potential side effects. I will immediately stop taking this medication if I experience cold hands or feet. correct so before we do that let's analyze this scenario some things should be jumping out at you for instance the patient's health history and they have a history of uncontrolled hypertension which is high blood pressure. They also have coronary artery disease and diabetes malius. Now let's talk about that drug propanolol that's what they're prescribed now let's think back to pharmacology this is the generic name of the drug generic names tend to have the same letters for the ending and and the ending for this is ool which drugs end an ool.  Beta receptors do they increase a process called glycogenolysis what it means is that whenever a patient has hypoglycemia the body tries to correct that. If they're taking a beta blocker that is blocking that response they're not going to have that classic Tac of cardia so they may later on their sugar will drop so much and it may be too late before they can treat it. Now Beta two receptors where are these mainly located they are located in various places number one your lungs you have two lungs that's how I remember beta 2. increase that blood sugar naturally with that process so you have this double-edged sword you have where they're not going to be able to notice their blood glucose. If a patient misses a dose of their beta blockers they don't need to double the dose they need to take it as soon as they remember unless that next dose is due. If the patient is already diabetic taking insulin probably that's what we assume and um so they have to monitor their blood sugar especially with these non-selective beta blockers so that is our answer now. look and see why D is wrong this patient says that they're going to stop their beta blocker immediately if they experience cold hands and feet well this is a normal side effect with these non-selective beta blockers. You would never just immediately stop taking a beta blocker they need to be tapered off of this because if they just all of a sudden quit taking that medication they can go have cardiac death or something worse can happen so that answer is wrong for that reason okay so that wraps up this inlex practice question.

ROUGE-1: 51.45, ROUGE-2: 50.05, ROUGE-L: 50.21
BERTScore: 74.13

==============================================
==================== [39/100] ====================
Summary:
This is part 2 of a guide to clinical reasoning or how to create an accurate differential diagnosis from a patient's presentation. In the first part I reviewed a practical five-step bedside approach to clinical Reasoning. In this part I will demonstrate how to use this approach with an actual patient case at the student level. I present this patient to you the same way in turn might present the patient to his or her attending on rounds or to their colleagues during a morning report or teaching conference as I present the case I'll keep a running list of the key features of the presentation. The patient is a 75 year old woman presenting with epigastric pain for four hours. The pain is relatively well localized to the midline in the region between her ankus and xiphoid process. There did not seem to be any particular trigger and the duration from initial onset to its maximal intensity of 8 out of 10 was about 45 minutes. She had moderate nausea it has refused to attempt to eat or drink anything since the pains onset because she is concerned that it will concert a vomit which she has not yet done. include hydrochlorothiazide 25 milligram daily and below to pain 5 milligrams daily metformin 500 milligraphic daily thymine 100 milligrap daily and folate one milliggram daily in her social history. She is an elderly woman a piercer stated aged in moderate discomfort secondary to abdominal pain her temperature is 99.8 heart rate 110 blood pressure 132 over 80 respiratory rate 26 and oxygen saturation of 98% on room air h ee and t. She has smoked one pack per day for 40 years for her family history. The patient is a 75 year old woman with abdominal pain for four hours. She has hypertension diabetes moderate alcohol use smoking and is drinking water from a newly drilled well. The patient was oriented to person place time and situation. She was fully conversant and appropriate speech and language. She had normal cranial nerves 2 through 12 normal patellar and brachial reflexes one plus bilaterally thorough strength testing and gait were deferred due to patient discomfort and exam petite for her labs. well on exam she is MA in moderate distress she has a borderline temperature tachycardia and tachypnea. She has a non distended abdomen that was soft with no rebound severe epigastric tenderness and guaiac negative. The key test results are a white blood cell count to 15 normal basic metabolic panel mildly increased indirect bilirubin modestly elevated lipase normal troponin and CK and an EKG with only sinus tachycardsia. primary symptom using semantic qualifiers and ending with the highly relevant diagnostic data using clinical syndromes when possible. For this patient we would start with mrs. Smith is a 75 year old woman with multiple cardiovascular risk factors and alcohol use presenting with acute constant epigastric pain. We would then group together the white blood cell count borderline fever tachycardia and tachypnea as sirs or the systemic inflammatory response syndrome. The soft abdomen and lack of rebound would be grouped into the collective descriptor of absent peritoneal signs and we would also include the elevated lipase. Step four adopt a framework as I discussed in part 1 of this video series no problem representation has only one correct framework the organization of a particular framework may just appeal more to some people than others in general when the primary problem is some form of abdominal pain most people find an anatomic framework works best particularly one which subdivides the abdomen into quadrants or regions in which a disease of a specific organ is listed within the region under which it lies. The epigastrium would obviously be the most critical anatomic region to include organs that physically lie directly underneath it. pain from a pulmonary embolism can be referred to the abdomen although it more typically is to the right or left upper quadrants and not the epigastric. Now that we have a framework we move on to the final and hardest step applying the key features to that framework so here is our framework once again and here are our key features how does one start this process the brute force method would simply be to take each diagnosis listed one at a time and review each individual key feature to decide if it impacted the probability of the diagnosis. There is PUD in the absence of an ulcer perforation there is not a very reliable means of distinguishing PUD from gastritis on clinical grounds. Wiles certainly can become contaminated with enteric bacteria but for this to happen with a brand new well it would imply that they literally drilled it into a patch of pre-inoculated earth. Without knowing more details about the wells location seems quite unlikely depending upon the specific pathogen her severity of illness could certainly be consistent with a severe form of this. The patient does have numerous risk factors and the combination of epigastric pain and nausea is not an uncommon way for acs to present particularly in a either a woman or a diabetic. The unremarkable lfts in and of themselves rule out acute hepatitis a paddock abscess usually has symptoms localized to the right upper quadrant and is also associated with lft abnormalities. A normal light bass cholecystitis also typically causes right upper Quadrant symptoms and signs along with elevated alkaline phosphatase although it's not enough to make the diagnosis likely enough to seriously consider. A pulmonary embolism can cause abdominal pain but as with acs would not be expected to cause abdominal tenderness. The patient has no major risk factors for RPE and has no shortness of breath. There are no causes of four hours of epigastric pain in which we would expect the troponin or CK to be abnormal even in the event of RPE. It's possible to present with a PE with just pain this case is just not what a PE looks like either in its classic presentation or even atypical variations. that the patient had an acute MI it really is too soon for these enzymes to become elevated and so therefore they probably should not be key features. The guaiac negative stool was critical in establishing the problem representation in step three. The history of the newly drilled well depending on where you are in your training is the most interesting. The combination of acute abdominal pain nausea and a possible contamination of well water is all consistent with heavy-metal poisoning specifically arsenic and lead this brings up an important point. element does not fit into the framework yet still seems to be a key feature the framework must be incomplete in this case I would add another category of diagnosis to our four existing categories of epigastric right upper quadrant left upper quadrants and chest that fifth category is acute abdominal pain secondary to systemic toxic metabolic problems. The four major members of this group are heavy metal poisoning a rare genetic disorder called acute intermittent porphyria another virgin etic disorder called familial Mediterranean fever and finally angioedema for any of these to be the final diagnosis this patient would need to have an atypical presentation of a rare disease. The most likely diagnosis for this patient is acute pancreatitis. pancreatitis is associated with her heavy alcohol use. It explains her nausea her distress the vital signs her tenderness on exam leukocytosis and is the best explanation for the elevated lipase. The only key feature arguing against it is the fact that the pain is not made better or worse with changes in position which as I suggested earlier is not likely to be a highly sensitive or specific finding. This is a relatively classic presentation of a common disease and therefore our leading diagnosis also known as the provisional diagnosis. atypical presentation those diagnoses which are rapidly fatal if missed for which this could plausibly be a presentation. Finally any diagnosis that is specifically suggested by an unusual element of the presentation even if the diagnosis itself is rare common disorders which could be a typical or atypical Presentation include gastroenteritis food poisoning and either gastritis or peptic ulcer disease which I have grouped together because I think it's very difficult to tell the difference between them without endoscopy don't miss diagnosis for this presentation would include a bowel infarction and acute coronary syndrome. involves the provisional diagnosis and as you move further down the list ideas start to diverge a little bit I would certainly expect most experienced doctors to identify pancreatitis as the leading diagnosis in this case so that concludes part 2 of 3 of this video series on the clinical reasoning. I hope you found it interesting and useful while the approach I presented here is not the only one in use I guarantee medical trainees that if you consciously employ it while on the wards you impress your peers and evaluators and more importantly create a more accurate differential.

ROUGE-1: 49.86, ROUGE-2: 48.13, ROUGE-L: 46.63
BERTScore: 72.60

==============================================
==================== [40/100] ====================
Summary:
Today is the day that you have to have done the mid-quarter survey by. Hundreds of people have, but if you haven't, this is your last chance to get the half-point for that. Final project proposals are due. We really encourage you to try and hand them in on-time or nearly on- time. And then today, delighted to have our first invited speaker. And there is a reaction paragraph talking about something that the speaker talks about. There is also assignment 5, which we're giving you one extra day for. Danqi Chen is one of the foremost researchers in question answering. She was the head TA of CS224N once upon a time. So she's quite familiar with the context of this class. Here's my plan for this lecture. So first, I would give a brief introduction of what is question answering, and what kind of problems that people are studying today. Then I'm going to spend the most of this lecture focused on one type of question answering problems called reading comprehension. And at the end of the lecture, I'm hoping to spend hopefully like 10-ish minutes to talk about a more practical, and in my opinion, more exciting problem called open domain question Answer. able to handle more complex questions like how-to questions. People actually really like to ask questions on these digital assistants. Ask a question is actually the second most used case. Only ranks after listening to music and before the check the weather and set up. The best way to prevent illness is to avoid being exposed to this virus. And to help prevent the spread of COVID-19, you can do the following. If you just click this link and read through the article. So this is also one type of the question answering problems. Question answering is probably one of those fields that we have seen the most remarkable progress in the last couple of years driven by deep learning. Almost all of the states are question answering systems today built on top of the end to end training of the deep neural networks and the pre-trained language models such as BERT. In this lecture, I will be mostly focusing on the text based, or textual question answering problems. So basically, we are trying to answer questions based on text.timer. the unstructured text. There are many other really big question answering problems. And each of them can be really like a subfield in NLP and they actually have very different challenges and also model designs. So basically we wanted you to question build answering systems to answer questions that can answer questions over a very large database. So to solve this problem, some approaches need to take this question and convert this question into some kind of logic forms. And another class, bigger class of the question Answer problems is called visual question answering. So this problem basically requires both understanding of the questions and also images, and is actually a very active field between the computer vision and NLP. dig into these problems today. So next, I'm going to start with a part 2, reading comprehension. I just want to quickly check if there are any quick questions I can answer before I start us on part 2. OK. So let's talk about the reading comprehension then. So reading comprehension is a basic problem that we want to comprehend a passage of text and answer questions about the content. So here is one example. So basically to answer this question, so you need to find this sentence, like, in 1861, Tesla attended this school where he studied. he studied German, arithmetic, and religion, and only German is a language. So the answer to this question should be German. OK, here is another example, OK? Another passage of text. And the question is, which linguistic minority is larger, Hindi or Malayalam I think 5 seconds. OK. So next I'm going to talk a little bit so why do we care about this problem? So why do you care about the reading comprehension problem? It has actually many useful real-world practical applications. Reading comprehension has been also viewed as a very important test bed for evaluating how well computer systems understand human language. So this is really just similar to how we humans actually test the reading comprehension test to evaluate how well we actually understand one language. And also there is another interesting and important reason that reading comprehension is important. So in recent few years, some researchers actually found that, OK, well, there are many other NLP tasks. So we also reduce them to a reading comprehension problem. Personal subject, Barack Obama. So we want to fill in what is-- fill in this question mark and figure out, OK, where Barack Obama was educated at. So one way to solve this problem is basically trying to convert this relation into a question. So where did Barack Obama graduate from? And taking all of that relevant piece of text and then by applying a reading comprehension problem. Then basically, we can find out-- the correct answer should be Columbia University. That is also the output of this information extraction system. And another example is actually called a semantic role labeling. sets have been also collected, basically runs this size around 100K. So 100K is actually very important to train these neural models. So for these datasets-- so the passages is like a single paragraph selected from the English Wikipedia, which usually consists of 100 to 150 words. And the questions are crowd-sourced, basically like from Mechanical Turking. And this is a very important property of the dataset, is that each answer is a short segment of text, or we called it span in the passage. Stanford, so it's called Stanford Question Answering Dataset. Today, after four or five years now, so SQuAD still remains the most popular reading comprehension data set. So it's actually very clearly a high quality dataset, but is also not a very difficult dataset. So today, basically the SQuad dataset itself has been almost solved, and the state-of-the-art already exceeds estimated human performance. So we can see that there is an exact match score between the predicted answer and any of the gold answers. the F1 score would be taking the max. Danqi, one question you might answer is, so if you can do other tasks like named entity recognition or relation extraction by sticking something on top of BERT and fine tuning for it or do it as a question answering, does one or the other method work better and by how much? That's an interesting question. So I haven't really seen the-- OK. So there has been some claim, OK, that all the tasks can be converted into question answering task. But I'm not sure if there is really a very fair comparison. answer to that. So next, I'm going to talk about how to build neural models for reading comprehension. And in particular, how we can build a model to solve the Stanford Question Answering Dataset. I also to just quickly mention that because there are many different papers that actually use different notions to refer to the same thing, so starting from-- so I'mgoing to use the passage, paragraph, and context, and also question and query basic interchangeably. OK. The answer must be a section of text in the passage. So the output can be just written this way. We are going to predict a start and end. So start and then end would be within the range between the 1 and the N. So it's basically just two checkpoints-- sorry, two end points of the answer. So SQuAD has been collected beginning late 2016. So after 2016, there have been-- there are two families of neural role models to solving this SQuad data set. So pre-trained language models for these kind of reading comprehension problems. So here are the two-- the illustration of these two families of the models. So on the left is an LSTM-based models with attention, and on the right is the BERT model. And then we need to fine-tunel this model for the reading comprehension task. So I'm going to walk us through hard to build this model step by step, and hopefully with that, you'll have a good understanding of how this model works. this model from the bottom to the top, it actually can be decomposed into many different layers. So the idea here is that OK, let's take the context part of the passage in question. We need to encode them separately. So to do this, so this model basically proposed to use a concatenation of the word embedding as well as the character embedding for each word in the context and the query. And then we just concatenate them and pass this to a highway network. LSTM model from another direction. So we just need to concatenate the two hidden representation in two directions. And finally, we can get a contextualized representation for each single word in the context. And we can do a similar thing for the question representation. I also want to quickly mention, because I mentioned the sequence to sequence model, we cannot really do these bidirectional LSTMs for the two sequences because the decoder is an autoregressive model. But because here we don't really care about the generation, so we can just use two bid Directional L STMs to represent the representations. called context-to-query attention. The idea is for each context word, can we find the most relevant words from the question for the query words. And then the second type of attention is called the query to context attention. So here the idea is to choose some context words that are most relevant to one of the queryWords. And this is also why this model is called a bidirectional attention flow because there's a context- to- query attention and there is also a query-to.-context attention. similarity score for every pair of the contextualized vector ci and then for everypair of the question with qj. So this is actually the output from an encoding layer. So the way they do this is basically just taking these metrics, the similarities for sij, for each row. Each row basically correspond to one context word. So here, i actually enumerates over all the context words. And this can give us another attention score of beta i, which captures how important this context word is relevant to this question. Is there a reason why you use both query-to-context and context-to the query attention? Is it sometimes advantageous or OK to use just one? Difficult question. Yeah. So I'm going to show us some operations from this figure, so way we just find both directions can really help. So there'll be some operation studies. So by using one set is useful, but it's sometimes advantageous to use both sets. I hope this answers your question, yeah. It's a good question, yes. just not with us using the both directions. In the bottom right, we sum over i, so why does the i remain in bi? Is that correct or is that a typo there? This is another typo. So the output of gi will actually range from the 1 to N, which is the number of the context words. There are lots of questions about this. What is the rationale for the expression of the gi? How does one come up with such an expression? OK, OK, I'm sorry.  query-to-context attention is trying to measure the importance of these context words with respect to some question words. So by taking the max for each row in this matrix, so it's basically trying to see, OK, which question word is actually most relevant to this context word? And then you can just apply your softmax. And then this will give you a probability that OK, what is the probability of this condition i, would be based on the start position of the final answer string. the dot product between w end and this vector, and this can produce all the probability over all the conditions which predict how likely this position will be the end the position of the answer. So by passing the mi to another bedirectional LSTM, their reasoning is that they're trying to capture some kind of dependence between the choice of the start and end. OK. I'm done with this part, describing the BiDAF model. Any quick questions I can answer? I think you can actually go on. BiDAF model achieved a 77.3 F1 score on SQuAD data set. They found that both attentions in two directions are actually important. If you remove the one direction, the performance will actually drop quite a bit. And the whole model can be just trained in an end to end way from the encoding layer to attention layer to modeling layer and to output layer. And basically all of the models that account at that time between 2016 and 2018 are BiDAF models. the models are actually a very similar ballpark. So numbers range from the highest number here, 79.8 until after the ELMo was introduced, the numbers have actually improved quite a bit. Each model actually improved the previous model by one point or two points. And now here is our attention visualization to show that how this smorgasbord of attention actually can capture the similarity between the question words and the context words. So it show the actual question word here. And each column's matrix basically indicates the attention score, the similarity score that has been learned by this model. BERT is a deep bidirectional transformer encoder pre-trained on large amounts of text. It is trained on the two training objectives, including masked language modeling and the next sentence prediction. The BERTbase has 110 million parameters and the BERT-large model has 330 million parameters. If you just take this BERT model, and by just optimizing all the parameters together, it can give you a very high performance. And even if you use a stronger pre-training models, they can even lead to better performance on SQuAD. pre-training has been so important. Next I will quickly talk about-- OK, a question here is that can we actually even design better pre-training objectives for reading comprehension or question answering? And the answer is actually yes. So this is actually a work I did with Mandar Joshi and other folks one year ago called SpanBERT. So think about this. So for SQuAD and other a lot of extractable reading comprehension datasets, the goal is trying to predict the answer span from the passage. And our BERT is actually just the-- is actually our re-implementation of the BERT model using the same data where we have been trying to train this model for slightly longer. So SpanBERT actually greatly outperformed Google BERT and other BERT basically across all of the datasets. This number has already exceeded even the human performance on SQuAD. Does this means that reading comprehension is already solved? The answer is of course not. So in the recent last couple of years, there's been a lot of work on reading comprehension. a lot of evidence showing that the current systems still perform poorly on adversarial examples or the examples from out of domain distributions. So here is a very classical example proposed by Robin Jia and Percy Liang in 2017. They're trying to just insert a random sentence to the end of the paragraph. And this sentence actually has some overlap with the question. It's actually very similar to this question, but actually the numbers have been changed. And they found that these kind of adversarial example are actually very easy to fool the current system and makes the system to predict the answer to be Jeff Dean. is another paper that actually just came out in 2020. So there has to be a lot of evidence showing the similar things. So today we compute a very good reading comprehension data set on the individual data sets. But these systems trained on one dataset basically cannot really generalize to other datasets. And all the other numbers in this table basically shows that if you train one system on one datasets and then evaluate on another dataset, the performance will drop quite a lot. So it basically really cannot generalize from one dataset to another dataset. Open-domain question answering is a problem that-- so it's different from reading comprehension that we don't assume a given passage. So here, we use the assumptions that we only have access to. And they found that a BERTlarge model cannot solve and basically failed these type of test cases 100% of the time. So I have 10 minutes left. Chris, is there any question I should answer at this point here? I think you can go on. OK. So in the last 10 minutes, I'm going to give you a very, very brief introduction of what is open- domain question answering and what we have been trying to do in the past couple of years. a large collection of documents. So one example is just taking the whole Wikipedia, which has five million articles. And we're going to return the answer for any open-domain questions. So this problem, there isn't any single passage, so we have to answer questions against a very largeCollection of documents or even the whole web documents. This is actually a much more challenging and also more practical problem. So if you look at the example of Google example I showed at the beginning, so these techniques will be very useful in the practical applications. This model kind of works really well, and it can largely outperform the traditional IR retrieval models. So here is actually a really nice demo. So again, the database ferries the whole Wikipedia. And you can see that if you ask a question of who tells Harry Potter that he is a wizard in the Harry Potter series. And the system had really found out the correct article should be Harry Potter films series, and then finally gave you the correct answer. OK. So by looking at all these different curves basically using a different number of training examples, so it actually largely greatly outperforms thetraditional IR models. answer, which is exactly what you have seen here from the Google example here. So the answer would be the Rubeus Hagrid. So this is actually the perfect answer to this question. OK, I'm going to skip this slide. And then finally, very quick. Some researchers have demonstrated that maybe you don't even need this retrieval stage. If you just use a very large language model, you can also just use all open-domain questions answering. So instead we can just record all the phrases in Wikipedia using some kind of dense vectors. Today, because she doesn't have a Stanford login, we're going to do questions inside Zoom. So if you'd like to ask a question, if you use the raise hand button, we can promote you. And if you hang around and don't leave the Zoom for more than a few minutes, maybe we'll just promote everybody who's still there into people in the regular Zoom for some bits of discussion. There are now four people who've been promoted. OK. Should I read those questions? Should I look at the chat or? No. Out: How can we train the reading comprehension model using only a small number of training examples? Out: If we can leverage a very large and very powerful pre-trained language model, there is a possibility that we can actually do the question answering well. Out: And also there are some other promising directions, including some other models that could be used in the future. OK. So thank you so much for the lecture today.OUT: Maybe he could start by asking a question, and then the other people that we've promoted. OUT: How small can your training dataset be for you to get reasonable results? unsupervised question answering so by using some kind of approach like some form of unsupervised machine translation, this kind of idea. That can be borrowed-- can borrow the idea from that and can also work pretty well, reasonably well in unsuper supervised question answering. Yeah, also I have seen a lot of works like [INAUDIBLE] showing that synthetic Pure-DSS can also help a lot in boosting the performance if you don't have enough supervised examples. So my question is I guess it's kind of interesting that there's not really that strong of a transfer effect between data sets that are kind of ostensibly similar. So I actually truly believe that most existing question answering datasets or reading comprehension datasets have been collected from Mechanical Turk. in the training set that is not really generalization, right? Yeah, but this is more on the open-domain setting not in the really [INAUDIBLE] here. Do you want to ask a question? Yes. So you mentioned in the last part of the presentation that the reader model may not be necessary and you presented the DensePhrases which also work well on CPUs. So do we know how well it performs on the question and answering datasets compared to other models including BERT and those on computer of course. The goal of this project is trying to ingest all the phrases in the Wikipedia. So these conversations are built using the training set of the question answering datasets. So if we use say a different data set that does not present the information using the structure presented in Wikipedias, this model may not work as well as. what do you mean by structure represent? So say if we lean more towards structures like the passages we see in standardized tests where the answers to the question may not be in close proximity to where the information was first introduced. while asking a question if you want. So next person is [AUDIO OUT]. All right. Thank you for taking the time to teach this. My question is kind of quick. So you mentioned work, they brought up a set of relatively simple questions that show how brittle or poor the current models can be, right? I'm curious if that-- yeah, exactly. Did that kind of change the community to improve how to evaluate the models? Because they're actually doing pretty poorly on some of those. thank you for bringing this one up. It's really interesting. Next is-- Hi, thanks for taking the time. In what extent can in context learning help models to be more robust with respect to different domains? Can you tell me what you mean by in context? So like basically you provide the template generated by BERT. And then instead of directly predicting the classes of text classifications, you just use some word to represent that class or predict the wordings there. OK. Thanks. Do you think that in order to solve NLP in the sense that you can perform on par with humans on all NLP tasks it's sufficient to only interact with text data? Or do you think we'll eventually need the sort of experiences and common sense. that you get only from seeing and viewing the world and having a set of interactions that we as humans have? Yeah. I mean, common sense is a very difficult-- even in the context question answering, commonsense is aVery important topic that I think still remains unresolved. solve the easy problems. So all these things need to be resolved. Do you think that the current sort of benchmark data sets are maybe a little bit too easy for- [INTERPOSING VOICES] Or just like that. Yeah. One final thought is that having a lot of transversely trying to have a lot. of humans in the loop of the frameworks to evaluate these kind of systems. Just try to break the current system, come up with some harder questions. OK. Are you still game for a couple more questions? Sure. encountered this paper called Learnable Quantizers, which essentially learns baseless representation for the quantizers jointly with the leads of the network. And while this would be extremely effective if you were to just like, say, train from scratch, I was just sort of curious, do you think there is some way to do this say a pre-trained BERT model or something like that? I had a few ideas with like beam search for instance, but I don't see a very clear way of doing that. Next question is from Danqi, who was one of the co-organizers of the EfficientQA task. Danqi: How concerned should we be about potential encoding sort of biases into these record labels or how we evaluate them, or is that just more of a concern for more open ended questions? John: I'm not sure I have a good answer to that. Some people do a de-biasing of the pre-trained language models, all these things are very important. yeah, I guess I'm just a little worried about who comes up with the test cases? Who determines what the right answer is? I mean, we will have more discussion of toxicity and bias coming up very soon, including actually Thursday's lecture as well as a later lecture, not specifically about QA though. OK. Next person is-- Thank you for the lecture. Yeah, my question is also related to the open domain question answering. So there is some very specific designs like domain server alignments and efficient level disentanglement techniques that has shown some interesting performance on other tasks. people also leveraged similar things for question answering. So I was just wondering to what extent these kind of techniques can work on one group of tasks, not just limited to question answering, but mainly question Answer. I have seem some work sort of trying to learn some kind of disentangled representations that can better generalize to the different domains on adversarial examples. Yeah, I'm not sure. I think we have to try that. But it's a little bit more specific for-- so there's a paper called domain. definitely an interesting point. At least for the work that I have seen so far, it all applied or operated at a very simple sentence classification task. I feel like QA is a more structured task and also handles longer bar sequences. Yeah, so I don't know if it works unless people have tried that. OK then we've got-- and maybe we should call this the last question. Hi, I'm just wondering what is the intrinsic difference between solving question answering with generative models like T5 versus encoders like BERT. So if the retrieval returns like, say, 100 passages, so they have to extract the answer from each of the passages and then finally figure out which one has the highest score. But for the generative model, essentially they are trying to aggregate all the 100 passages and the dense representations together and do the generation jointly. So essentially, you're taking the 100 representations together through the joint generation. So I think that is actually the key difference. So that's why thisGenerative model can do really well compared to the extractive models. These numbers are a little bit confusing. So it's actually basically really on par. Their base perform similarity. So the key difference between the generative model and the extractive model is that for generative models, you can actually leverage more input passage together and do the generation. Is that clear or not? Yes. Thanks. Yeah, otherwise, you should just check out this paper here. So this paper actually explains it pretty well why this model works better than the previousGenerative model. The model is very large, like 11 billion parameters. So the parameters are basically trying to memorize a lot of information that has been.information. So by just taking this input, it has to just rely on the parameters to infer this answer. So it's actually very hard to-- yeah, it's a definite balance between memory and the generalization from it, yeah. All right, thanks. Do you want to call it a night or do you want one more question? It's up to you. There is a lot of interest in extending these question answering techniques or just encoding techniques, embedding techniques to recommender systems. The first question is whether these techniques can be generalized to other languages. If we have, actually, I think that the techniques could be generally applied to other language. There has been a lot. of work trying to do cross-lingual question answering and stuff like that. But there has been some constraints that a. lot of models or systems that I described here actually require very strong pre-trained language model. and also requires lots of training examples for the Pure-DSS.

ROUGE-1: 45.06, ROUGE-2: 43.74, ROUGE-L: 42.26
BERTScore: 68.57

==============================================
==================== [41/100] ====================
Summary:
 homework two is out now. We're gonna be having some more background on deep learning this weekend. You're not expected to become, or, or to be a deep learning expert to be in this class, but we, you only need to have some basic skills in order to do homework two, um, be able to use function approximation with a deep neural network. Um, we're also gonna be reaching, uh, releasing by the end of tomorrow. Uh, but the sessions will be a good chance to catch up on that material. [NOISE] Um, just a quick humble, which of you have used TensorFlow or PyTorch before? The assignments, [inaudible] are they limited to TensorFlow? asked the question. I'm pretty sure that everything relies that, er, you're using Tensor Flow. Um, I'll believe you guys also should have access to the Azure credit. If you have any questions about getting setup without feel free to use the Piazza channel. We also released a tutorial for how to just sort of set up your machine last week. So, if you're having any questions with that, that's a great place to get started. Deep Q Learning is a form of reinforcement learning. It uses deep neural networks to learn to make complex decisions. We'll be covering the basics of Deep Q Learning in this tutorial. You can look at the tutorial, or you can reach out to us on Piazza with any other questions. We hope to see you in the next class on November 14th and 15th, at 10:30am and 11:00am. Back to the page you came from. Click here for more information about the class. when we thought about doing this, we're gonna focus on function approximations that are differentiable. Um, and the nice thing about differentiable rep-representations is that we can use our data, and we can estimate our parameters, and then we can take use gradient descent to try to fit our function. And that information now could be [NOISE] in the form of episodes or it could be individual tuples. When I say a tuple, I generally mean a state-action reward next state tuple. is the same as the full gradient update. Our objective function is again the mean squared error. And the key hard thing was that we don't know what this is. So, this is the true value of a policy. But the problem is we don’t know what the trueValue of a Policy is, and so we can't get a value for a policy that we think is the real value of the policy. And so, we have to change the way we think about a policy to get a true value. otherwise we wouldn't have to be doing all of this learning. And so, the two ways we talked about last time was inspired by a work on Monte Carlo, or on TD learning is we could either plug-in the return from the full episode. Or we could put in a bootstrapped return. So, now we're doing bootstrapping. Where we look at the reward, the next state, and the value of our next state. And in this case we're using a linear value function approximators for everything. all for linear value function approximation, but there are some limitations to use the linear valuefunction approximation, even though this has been probably the most well-studied. So, if you have the right set of features, and historically there was a lot of work on figuring out what those rights set offeatures are. They often worked really well. And in fact when we get into, I think I mentioned briefly before. When we start to talk about deep neural networks you can think of, a deep neural network is just a really complicated way to get out features. and how easy is it for us to converge to that. So, one alternative that we didn't talk so much about last time is to use sort of a really, really rich function approximator class. Um, where we don't have to, have to have a direct representation of the features. Er, and some of those are Kernel based approaches. These actually have a lot stronger convergence results compared compared to other approaches. The problem is, um, that the number of data points you need tends to scale with the dimension. The intuition is that if you want to have sort of an accurate representation of your value function, um, and you're representing it by say, uh, local points around it. For example, with the k-nearest neighbor approach. then the number of points you need to have everything be close like in an epsilon ball scales with the- the dimensionality. So, basically you're just gridding the space. Um, and everyone just [inaudible] name first please to stop me. a square, you're gonna need four points so that everything can be somewhat close to one of the points. Generally, the number of points you need this going to scale exponentially with the dimension. A really cool thing about averagers is sort of by their name. They're guaranteed to be a non-expansion, which means that when you combine them with a bellman backup it's guaranteed it'd still be a contraction. So, that means these sort of approximators are guaranteed to converge compared to a lot of other ones. These for things like, um, health care applications and how do you sort of generalized from related patients. So, they can be useful but they generally don't scale so well. What we're gonna talk about today is thinking about deep neural networks which also have very flexible representations but we hope we'll be able to scale a lot better. Um, now, in general we're going to have almost no theoretical guarantees for the rest of the day, and- but in practice they often work really really well. In this example, we're going to use a loss function called j which is like our Q. Then we're gonna push that into another function, and throw in some more weights. I'm gonna do that a whole bunch of times, and then at the very end of that you can output some y. Then, we can output that to some loss function j. These are- happen a lot in unsupervised learning like predicting whether or not something is a cat or not or, you know, an image of a particular object. functions, um, you could represent really complicated functions by adding and subtracting and taking polynomials and all sorts of things you could do by just composing functions together. But the nice reason to write it down like this is that you can do the chain rule to try to do stochastic gradient descent. So, we really want, you know, dj with respect to all these different parameters. We can write down dj of hn and dhn of dwn and we can do- do this kind of everywhere. your weights. When I first learned about deep neural networks, you have to do this by hand. But I think one of the major major innovations that's happened over there, you know, roughly what? Like last 5 to 8 years is that there's auto differentiation. So, that now, um, you don't have to derive all of these, uh, gradients by hand instead, you can just write down your network parameters and then you have software like TensorFlow to do all of the differentiation for you. and as usual we need a loss function at the end. Typically, we use mean squared error. You could also use log likelihood but we need something that- that we can differentiate how close we are achieving that target in order to update our weights. [NOISE] Yeah? Name first. So, this ReLU function is not differentiable, right? It is differentiable. It's ended up being a lot more popular than sigmoid recently, though I feel like it [OVERLAPPING]. Yes. But I don't see how gradient [inaudible] is gonna work on the part where it's flat. Convolutional neural networks are used extensively in computer vision. They can represent any function with the deep neural network. If you have at least one hidden layer, um, if you have a sufficient number of nodes. You can learn the parameters using stochastic gradient descent. All right. So, that's pretty much that, you know, deep neural networks in like five seconds. Now, we're now gonna talk a little bit about convolutional Neural Networks. We'll talk- we'll talk some about that in sessions. Convolutional neural networks try to have a particular form of deep neural network that tries to think about the properties of images. So, in particular, images often have structure, um, in the way that our- our brain promises images also has structure and this sort of distinctive features in space and frequency. Having so operators again here are like our functions, h1 and hn, which I said before could either be linear or nonlinear and then convolutional Neural Network learn a particular structures for those. Deep learning is a new way of looking at images. It uses layers of data that are applied to different parts of the image. The layers are called a filter and a receptive field. They are then used to extract different features from the image, such as whether or not there's an edge in a particular patch. The results can then be used to create different types of depth maps, which can be used in other ways, like facial recognition or other types of image analysis. Back to the page you came from. then you could apply these different filters on top of it, which you can think of as trying to detect different features. Um, the other really important thing in CNNs, is what are known as pooling layers. They are often used as a way to sort of down-sample the image. So you can do things like max pooling to detect whether or not a particular feature is present, um, or take averages or other ways to kind of just down, ah, and compress the, the information that you got it in. for really high dimensional input and kind of average and slow down until we can get to, um, a low dimensional output. So, the final layer is typically fully connected. We're kind of computing this new feature representation of the image, and at the very end, we can take some fully connected layer, where it's like doing linear regression, and use that to output predictions or scalars. So these type of representations, both Deep Neural Networks and Convolutional Neural Networks, are both used extensively in deep reinforcement learning. How we could use these type of approximations for Atari. So why was the surprising? I just sort of wandering back. In around 1994, personally in 1994, we had TD backgammon which used Deep Neural Networks. Well, they used neural networks. I think there was someone that deep, and I think out like a world-class backgammond player out of that. So, that was pretty early on. And then we had the results that were kind of happening around like 1995 to maybe like 1998, which said that, "Function approximation plus offline off policy control, plus bootstrapping can be bad, can fail to converge" success and then there were these results in sort of the middle of the nineties that indicated that things could be very bad, and the risk was some of the- In addition to the theoretical results, there were sort of these simple test cases, that, you know, these simple cases that went wrong. So, it wasn't just sort of in principle this could happen, uh, but there were cases which failed. And so I think for a long time after that, the, the community was sort of backed away from Deep Neural Networks for a while. DeepMind, DeepMind combined them and had some really amazing successes with Atari. And so I think it sort of really changed the story of how people are perceiving using, um, this sort of complicated function approximation, meters, and RL, and that yes, it can fail to converge. But it is also possible of them that despite that- you know, the fact that we don't always fully understand why they always work, that often in practice, we can still get pretty good policies out. the mid '90s? Or, is it just that kind of through increases in computational power and the ability to gather a lot of data, that when it failed, it kinda doesn't matter, and we can try some different, like we- you know, try it again and kinda put it together and just keep trying until it works? I guess my question is, did we actually overcome any of the problems that arose in the late ' 90s, or is itjust that we're just kinda powered through? The question is how we sort of fundamentally resolve some of the issues of the late my '90's, or, um, we kind of brute forcing it. I think there's also a couple algorithmic ideas that we're gonna see later in this lecture, that help the performance kind of avoid some of those convergence problems. So with the Atari case specifically, did you- did you avoid that problem? Well, sort of, that if you tried it by having on policy control? I just don't know. Um, and it's a great question for me. We'll see how it works here. Anyone else? Okay, cool. So, we'll- we'll see an example for breakout shortly, um, of what they did. are the important things that they, um, did in their paper, this is a nature paper from 2015, is they use the same architecture and hyperparameters across all games. Now just to be clear, they're gonna then learn different Q functions and different policies for each game. But their point was that they didn't have to use totally different architectures, do totally different hyperparameter tuning for every single game separately. It really was the sort of general architecture and setup was sufficient for them to be able to learn to make good decisions for all of the games. approximators act. And the nice thing is that, I think this is actually required by nature. They, they released the source code as well. So you can play around with this. So how did they do it? Well, they're gonna do value function approximators. They're going to minimize the mean squared lost by stochastic gradient descent. Uh, but we know that this can diverge with value function approximation. And what are the two of the problems for this? Well one is that there is this or the correlation between samples which means that if you have s, a, r, s prime, aprime, a prime, r prime, double prime. lot of correlations. Um, and also this issue with non-stationary targets. What does that mean? It means that when you're trying to do your supervised learning and train your value function predictor, um, it's not like you always have the same v pi oracle that's telling you what the true value is. That's changing over time because you are doing Q-learning to try to estimate what that is and your policies changing. So you don't have a stationary target when you are even just trying to fit your function. data instead of just using each data point once, you can reuse it and that can be helpful. So, even though we're treating the target as a scalar, the weights will get updated the next round which means our target value changes. This is like saying that periodically I- like let's say I went s1 a1 r1 s2 and then I keep going on and now I'm at like s3 a3 r3 s4. That's really where the data is going. I am in the world, I'm now in state four. It's like I suddenly pretend that I'm back in s1, took a1, got r1, and went to s2 and I'm gonna update my weights again. The reason that that update will be different than before is because I've now updated using my second update and my third update. So, it'll cause a different weight update. In general, one thing we talked about a long time ago is that if you, um, uh, do TD learning to converge it, which means that you go over your data mu- like, like, an infinite amount of time. learn to model, a dynamics model, and then the planning for that which is pretty cool. But we don't wanna do that all the time because there's a computation trade-off and particularly here because we're in games. There's a directtrade-off between computation and getting more experience. Can we use something similar to like exploitation versus exploration. Um, essentially like with random probability just decide to re-flag [inaudible]. The question is about how would we choose between getting new data and how much to replay et cetera. based on the experience replay versus getting, um, putting new samples into there. So, generally right now is really heuristic trade-off. Could certainly imagine trying to optimally figure this out but that also requires computation. This gets us into the really interesting question of metacomputation and metacognition. Um, but if, you know, your agent thinking about how to prioritize its own computation which is a super cool problem. Which is what we solve all the time. use in that value of S prime for several rounds. So, instead of always update- taking whatever the most recent one is, we're just gonna fix it for awhile and that's basically like making this more stable. Because this, in general, is an approximation of the oracle of V star. What this is saying is, don't do that, keep the weights fixed that used to compute VS prime for a little while. Um, one is gonna be this weight and the other is this weight. minus. I'll call it minus because, um, well there might be other conventions but in particular it's the older set of weights, the ones we're not updating right now. Those are the ones that we're using them as target calculation. So, when we compute our target value we, again, can sample and experience tuple from the dataset from our experience replay buffer, compute the target value using our w minus, and then we use stochastic gradient descent to update the network weights. help, um, in terms of stability? In terms of Stability, it helps because you're basically reducing the noise in your target. If you kept your target fixed forever, you would learn the weights that- that minimize the error to a constant function. That would then be stable because you always have the same target value that you're always trying to predict. And eventually you'd learn that, and that would eventually be stable. And that's what we're trying to do with GT. This is just reducing the noise and the target that we're trying to sort of, um, if you think of this as a supervised learning problem, we have an input x and output y. The challenge in RL is that our y is changing. If you make it that you're- so your y is not changing, it's much easier to fit. Uh, assuming we want to do [inaudible] approximator. Is there something that's specific to the deep neural networks? This is really just about stability and that's- that's true for the experience replay too. Experience replay is just kinda propagate information more- more effectively and, um, this is just gonna make it more stable. Do you every update the- Minus at all, or is that [inaudible]. Great question. Dian. Dian's question is whether or not we ever update w minus, yes we do. We pu- can periodically update wminus as well. In a fixed schedule, say every 50 or, you know, every n episodes or every n steps, you would set w minus dw. information fester, um, and possibly being less stable. If n is infinity, that means you've never updated it. There's a- there's a smooth continuum there. We notice, like, for w, there are better initializations than just like zero, uh, something, if you take into account, I guess like the mean and variance. Uh, would you initialize w minus just two w or is there like an even better initialization for w minus? Yeah, his questions is about, you know, the- the impact of how we, um,. uh, initialize w ca- can matter. It stores the transition in this sort of replay buffer, a replay memory, um, use sample random mini-batches from D. So, normally sample in mini-batch instead of a single one. You do your gradient descent given those. Um, you compute Q learning using these old targets and you optimize the mean squared error between the Q network and Q learning targets, use stochastic gradient descent, and something I did not mention on here is that we're typically doing E-greedy exploration. of what the agent is doing. So, remember the agent's just learning from pixels here how to do this. Um, and one of the interesting things about it is that as you'd hope, as it gets more and more data, it learns to make better decisions. So this is really cool that sort of it could discover things that maybe are strategies that people take a little while to learn when they're first learning the game as well. Yeah, so, um, you might see, uh, I think she is talking- she is referring to the fact that the paddle was moving a lot. clearly sort of an inexperienced player to do that. That would be a strange thing but from the agent's perspective, that's completely reasonable. Um, and it does not give him positive or negative reward from that. So, it can't distinguish between, you know, stay in stationary versus going left or right. If you put it in a cost for movement that could help. This might become a little bit of [inaudible] but is there a reason to introduce a pulling layer? Puling layer? There might be one in there. uh, they're not talking about how long it took them or their agent to learn and as you guys will find out for homework two, it can be a lot of experience. So, they did very well on some domains. Some domains, they doing very poorly. Um, I think that it's clear that the really important feature is replay. We'll probably talk- uh, we'll talk a lot more about exploration later on in the course. so, what was critical? So, I- I like the, uh, there's a lot  lovely things about this paper and one of the really nice things is that they did a nice ablation study.  replay is hugely important and it just gives us a much better way to use the data. Using that fixed Q here means you seem like a fixed target. You do replay and suddenly you're at 241. Okay, so throwing away each data point what- after you use it once is not a very good thing to do. Um, and then if you combine replay and fixed Q you do get an improvement over that but, uh, it's really that you get this huge increase, um, at least in break out in some of the other games. So, the question is like, "Well, maybe we could use, like, linear-" also I guess I should be clear. So, we've done some work, um, using a Bayesian last layer, using like Bayesian linear regression which is useful for uncertainty. But you could certainly imagine trying linear plus replay and it seems like you might do very well here, it might depend on which features you're using. There's some cool work over the last few years looking also at, uh, whether you can combine these two. a talk about reinforcement learning, and like 40 people would show up, but most of them you knew, and, um, and then, uh, then it started really changing. I think I was maybe in 2016, when, er, ICML, I was in New York and like suddenly there were 400 people in the room for reinforcement learning talks. And then, this year at NLP's which is one of the major machine-learning conferences, it's sold out in like eight minutes. So, there's been a huge amount of excitement based on this work. double DQN is kind of like double Q learning, which we covered very briefly at the end of a couple of classes ago. The thing that we discussed there was this sort of maximization bias, is that, um, the max of estimated state action values can be a biased estimator of the true max. This is to try to separate how we pick our action versus our estimate of the value of that action. It turns out that it gives you a huge benefit in many, many cases for the Atari games. back to the Mars Rover example. Um, er, so, in Mars Rover we had this really small domain, we are talking about tabular setting through just seven states, um, and we're talking about a policy that just always took action a1 which turned out to mostly go left. So, it was this. And the first visit Monte Carlo estimate of v for every state was 1110000, and the TD estimate with alpha equal one is this. That was when we talked about the fact that TD only uses each data point once and it didn't propagate the information back. Vote if you think it matters which ones you pick, in terms of the value function you get out. Back-propagate from the information you're already [NOISE] have on step one to step two. So, if you pick backup three, so what's backup three? It is, S2, A1, 0, S1. So if you do the backup, that's, zero, plus gamma V of S prime. And this is one. So that means now you're gonna get to backup and so now your V of. S2 is gonna be equal to one. you get to backup that information. So, um, if you wanted to get all the way to the Monte Carlo estimate. What you would wanna do here, is you'd wanna do S3, a1, 0, S2 which would allow your V of S3 to be updated to one. So it definitely matters. It matters the order in which you did, do it. And that's the same as the last time I [inaudible] That's right. Yes. The number, of, um, updates you need to do until your value function converges to the right thing can be exponentially smaller. If you update carefully and you, you could have an oracle tells you exactly what to do. But you can't do that. You're not gonna spend all this. It- it's very computationally, expensive or impossible in some cases to figure out exactly what that. oracle ordering should be. But it does illustrate that we might wanna be careful about the order that we do it. In the old ways and uh, example we're just going through, after you like propagated the one back once, you wouldn't be able to do anymore because your value's totally zero. So there's gonna be this tension between, when you fix, um, uh, your w minus, then, if you were looking at our case that we had before, then you would be able. to continue propagating that back, because you wouldn’t update yet, yet, that's exactly right. things versus her propagating information back. So why does it, what does ordering matter, that if you're fixing, and so you are not changing, uh, like, then it wouldn't matter what order we sampled those previous ones, right? Uh, okay. So basically, ordering matter at all, in that case. It still matters because we're still gonna be doing replay, o- over. So that buffer could be like, million and you might re-update your weights like every 50 steps or something like that. among the existing tuples? So out- so Pi is our, uh, sort of basically our DQN error. If we set Alpha equal to zero, you know, it's right. Yeah. So, so this sort of trades off between uniform, no prioritization to completely picking the one that, um, like if alpha's infinity then that's gonna be picked the one with the highest DQn error. So it's a trade-off. Most, the time prioritize replay is better and there's some hyper parameters here to play with. Duoing.do is an architectural choice and learning a recombine these for the Q. The idea is that, if you want to, make decisions in the world, they're working some states that are better or worse, um, and they're just gonna have higher value or lower value. What you really wanna be able to do is, figure out what the right action is to do, in a particular state. So, what they do to do this is that in contrast to DQN, where you output all of the Q's. It could be super tempting to try to start, by like implementing Q learning directly on the ATARI. Highly encourage you to first go through, sort of the order of the assignment and like, do the linear case, make sure your Q learning is totally working. Even with the smaller games, like Pong which we're working on, um, it is enormously time consuming. It's way better to make sure that you know your Q Learning method is working, before you wait, 12 hours to see. whether or not, oh it didn't learn anything on Pogge. So, that, that- there's a reason for why we, sort of build up, the way we do in the assignment. Um, another practical, to a few other practical tips, feel free to, to look at those, um, and then we were on Thursday. Thanks. Back to Mail Online home.back to the page you came from. Back from the page where you come from. back to MailOnline home.

ROUGE-1: 48.43, ROUGE-2: 46.03, ROUGE-L: 45.36
BERTScore: 73.50

==============================================
==================== [42/100] ====================
Summary:
 salt makes up a tiny part of any bread though which has a huge effect on it and most bread is made with salt nowadays. salt has only been used in bread making for the last couple of hundred years which i can't believe surely someone would have thought to add salt to bread. Earlier bread has been around for thousands of years but regardless of what the truth is salt is an essential ingredient in breadmaking. We're going to make three breads one without salt so here's what we're Going to do today. This is not a recipe video so i'm not going to talk you through the steps here i'm making 3 breads they contain all the same amount of ingredients except the salt. Instead of talking about these breads i'll talk about how to use salt in ahsoka. This is a method of adding seeds and grains to your bread though and i will make a whole separate video covering this topic in detail right so we'll start with the three breads.just flour yeast and water the second one made with a standard two percent salt and the final one will be made with way too much salt at 10 percent these are of course extreme examples and only the tubes and dough is the correct one. Salt is a tiny part of any bread though this small percentage has a great effect on flavor texture and fermentation salt has a tightening effect on the gluten it strengthens the dough and makes it more cohesive as yeast consumes the sugars in the dough it expels carbon dioxide it is the carbon dioxide gas that makes our dough rise and it's not able to hold that gas very effectively. bread made without salt is bland and has no character salt doesn't just make bread salty it accentuates the flavor of the flour and any other ingredients contained in the Dough. Ahsoka would be made with hot or boiling water leaving it to soak at room temperature and keeping it warm for a long time would run the risk of it going off and spoiling salt inhibits enzymatic activity. adding just two percent of salt to your soaker will ensure that it doesn't get any funky flavors. You should account for the amount of seeds and grains and for the flour in the recipe when you're calculating the total amount of salt. If you don't add enough salt you'll end up with a bland tasting loaf. starter or yeast you would mix your flour water yeast or starter and then leave to ferment for several hours ahead of time before making the final dough pre-ferments add a great deal of flavor improve the texture and the keeping quality of your bread. Normally brief mints don't contain any salt that's why in hot kitchens or hot climates they can ferment too rapidly. There are ways of controlling this you can lower the temperature of the briefment you can place it in a cooler area or even lower the hydration of it by adding salt. it's rising more slowly whilst the one on the left is already collapsing. the one in the right is still pushing on. what did you think of this experiment did you learn something new let me know down in the comments see more videos like this one click right here that's all i have for you today thank you for watching i'll see you in the next one. i'll be back with a new video in a week or so. I'll let you know what it's about.

ROUGE-1: 44.97, ROUGE-2: 42.55, ROUGE-L: 37.45
BERTScore: 74.95

==============================================
==================== [43/100] ====================
Summary:
In this section, we're going to talk about the relativistic Doppler effect. We make good use of our space-time diagrams, which we discussed earlier. The question is how is this being observed by an observer which is moving with a relative velocity v with respect to the source? So the question is not how this observed-- how this is seen by the source but how it is being viewed by the observer. We have to apply Lorentz transformation to the data. that the period now is given by 1 plus beta over 1 minus beta square root of that times tau. And the frequency is the inverse. So we just calculated relativistically how the period and the frequency of a wave is Lorentz transformed. We'll have 1 minus Beta over 1 plus Beta squareroot of that [? times ?] the frequency. That's how we get the period of the wave and the rate of its movement. The period is the same as the frequency, but the rate is the opposite.

ROUGE-1: 49.45, ROUGE-2: 42.07, ROUGE-L: 40.06
BERTScore: 71.88

==============================================
==================== [44/100] ====================
Summary:
KOMO goes behind the scenes of a new racecraft that's fast and designed to Perfection. The all new E1 racing series aims to prove the potential of electric power in the Marine industry. The boats can reach 50 knots that's around 93 km per hour so how do they reach those speeds? The key bit here is getting up on the thin bits of the foil and staying above the water to have the speed that's right. It's a challenge being a pilot in the race bird with the boat back on dry land. drawing too much power while and while they're lift and that lifts them up onto the foils. While they're on the foil we can then obviously play around with the lift which is on the left hand side of the of the wheel. The trim on the right hand side and it's we're just altering that by a few points depending on wave conditions. This sport is still in the very early stages the nine teams have the same boat but they're working out how to push the tech. E1 is a brand new racing concept using foiling boats with an electric motor in a format that's never been done before. Every team has a male and a female pilot and it's up to the team to decide which pilot will go first. The most challenging part is the starts getting those right can really affect the race. The course is a very simple Loop but those green boys mark an extra special part of the track and the teams have to choose very wisely when you take that turn you have to take the Long Lap. as we go there's no set plan and it completely depends on where we are during the race and yeah it can change in a matter of minutes [Music] at the end of the day you know the teams really have to work together both Pilots have to be consistent you know One Pilot can be really fast if the other one is slower then it may come down to the wire. Having two very consistent Pilots that can work together is how you're really going to win let's po that champagne [Applause] hope it continues for many years to come. We are proud to be a part of the history of the city. We hope to see it continue for many more years. Thank you for all your support and good wishes. We will continue to support the city in any way we can over the next few years. Back to Mail Online home.Back to the page you came from. Back To the pageyou came from, click here for more information on this story and to read the rest of the article.

ROUGE-1: 41.45, ROUGE-2: 35.42, ROUGE-L: 36.40
BERTScore: 61.82

==============================================
==================== [45/100] ====================
Summary:
Marginal rate of substitution of good 1 with respect to good 2 is infinity. When we do not say when we say just MRS, we are not using any particular term, you can use both way. We will always use this, yes here is 0 and MRS here is infinity, but in both the examples MRS of cola is Infinity. So, just be careful what we are talking about. This is you know a point of confusion many people just change the axis when they talk about it. getting x you get 1 by x, and why? Let us see what do we mean by marginal rate of substitution mathematically. We will let us change it little bit, let us put it here 3.25 just for example, because what is the marginal rates of substitution here, MRS by the definition that we have used is minus 0.75. Just wait I will come to that, why what is happening, increase in x is, why we are getting minus sign, because of course, when we have convexity what we will get. To get 1 good you will have to give up the other good, both what we are assuming that both these items are good, means they give certain satisfaction or certain you know utility to the person, and what we want. So, of course, when we are increasing the amount of 1 good to bring what will happen using this, if we use the monotonicity what will happening. If more of 1Good what is happening let us see. From here you are moving here in this direction, here at the screen, its increasing from 2 its going to 3. accompanied by decrease in the other good, if both are the goods. So, here we have in denominator we have good 1 and changes 1 unit. How much change do we need in the second good, 4 minus 3.25 and of course, I should put a minus sign here, and this is you get 0.75. Marginal rate of substitution is nothing, but the slope of this indifference curve. It would be mathematically more sound to talk about very small unit of good 1, and with respect to get very little amount of good. good 1, how much the other person is willing to give up, the another good, but we have to measure in terms of per unit of good 1. So, that is why in that case MRS is going to be, let us say in other word, 'MRS' MRS. 1 is the original bundle is x y, and let us. say what is happening from x y what we are having, change is x plus delta. x and y plus delta y, what would be the slope. see, that MRS is given as a positive number, that only means that the author has introduced a negative sign here to convert the MRS into apositive number. So, it does not matter. Is it clear? Do you know the answer to this question? If so, please email us at jennifer.smith@mailonline.co.uk. If you don't, we would like to hear from you. Please send us a photo of your MRS and we will send it to you.

ROUGE-1: 58.30, ROUGE-2: 53.31, ROUGE-L: 54.71
BERTScore: 70.84

==============================================
==================== [46/100] ====================
Summary:
in this video we're going to discuss what externalities are in economics so an externality is when you do something that affects the well-being or the good of another person or a company but you're neither harmed or rewarded for what you did to that person. The externalities can be positive they can be negative a negative externability is whenyou've harmed someone you've done something to somehow impose a cost on someone or some some company or something and you haven't reimbursed that person you haven’t paid them any money or or done anything to compensate forwhat you did. at 3: a.m. and you said okay you know what I'll deal with this but I need you to give me an extra 50 bucks a month toward my rent and then you work out an agreement that's different but we're assuming here they haven't done anything to reimburse you they're not paying you. Now a positive externality is where you are doing something that doesn't harm someone it actually benefits that other person you're doing something good that just as a side test like it's as a tangent it's actually helping some other person or people and so but those people aren't turning around and compensating you for it right. your lawn and you mow your lawn and stuff but you don't really spend a l a lot of time making your house look pretty now if your neighbor is trying to sell their house they have a for sale sign up they might appreciate if you went out and really did a great job maintaining your home they would really just love that because then when people come to see their house which is for sale that would increase the value of their home right if the neighboring properties like yours look really really nice then that would help them sell their home. where you have a negative externality like pollution or something like that it would be overs supplied relative to what is socially efficient or optimal. Where you have an over-supply of something like pollution, for example, you would have it over supplied in a way that would be socially efficient and optimal. For example, if you have pollution, it would have to be over supplied to avoid it becoming a problem. This would be a way to reduce the amount of pollution or other negative externalities in the environment.

ROUGE-1: 52.84, ROUGE-2: 47.41, ROUGE-L: 46.57
BERTScore: 70.20

==============================================
==================== [47/100] ====================
Summary:
Professor Steven Smith: Let me start today by asking the question, "what is political philosophy?" In one sense, you could say political philosophy is simply a branch or what we call a subfield of the field of political science. Yet in another sense, political philosophy seems to be the oldest and most fundamental part of politicalScience. Its purpose is to lay bare the fundamental problems, the fundamental concepts and categories which frame the study of politics. In this respect it seems to me much less like just a branch of political Science than the foundation of the entire discipline. Political philosophy is the oldest of the social sciences. It can boast a wealth of heavy hitters from Plato and Aristotle to Machiavelli, Hobbes, Hegel, Tocqueville, Nietzsche, and so on. The study of the great books or great thinkers of the past can easily degenerate into a kind of antiquarianism, into a sort of pedantry. These works provide us with the most basic questions that continue to guide our field, says Yale's John Maynard Keynes. This course will be devoted to the study of those "academic scribblers" who have written books that continue to impress and create the forms of authority with which we are familiar. But one thing we should not do, right, is to approach these works as if they provide, somehow, answers to the problems of today. Rather, the great works provide us, so to speak, with a repository of fundamental or permanent questions that political scientists still continue to rely on in their work. Again, we still think in.influences, are usually the slave of some defunct economist. terms of the basic concepts and categories that were created for us long ago. In political philosophy, it is never a sufficient answer to answer a question with a statement "because Plato says so," or "because Nietzsche says so" There are no final authorities in that respect in philosophy because even the greatest thinkers disagree profoundly with one another over their answers. We are called upon first to read and listen, and then to judge "who's right?" "how do we know?" The only way to decide is not to defer to authority, whoever's authority, but to rely on our own powers of reason and judgment. What is justice? What are the goals of a decent society? How should a citizen be educated? Why should I obey the law, and what are the limits, if any, to my obligation? And of course, the all important question, even though political philosophers and political scientists rarely pronounce it, namely, quid sit deus, what is God? Does he exist? And what does that imply for our obligations as human beings and citizens? Those are some of the most basic and fundamental problems of the study of politics, but you might say, where does one enter this debate? The concept of the regime is perhaps the oldest and most fundamental of political ideas. Broadly speaking, a regime indicates a form of government, whether it is ruled by the one, a few, the many, or as more common, some mixture of these three ruling powers. Regimes are necessarily partisan, that is to say they instill certain loyalties and passions in the same way that one may feel partisanship to the New York Yankees or the Boston Red Sox, or to Yale. Fierce loyalty, partisanship: it is inseparable from the character of regime politics. Henry Adams once cynically reflected that politics is simply the "organization of hatreds" This raises the question whether it is possible to transform politics, to replace enmity and factional conflict with friendship. Is such a thing possible? It can't be ruled out, but such a world, I would note--let's just say a world administered by international courts of law, by judges and judicial officials. tribunals--would no longer be a political world. The study of regime politics is in part a study of the distinctive national character types that constitutes a citizen body. You can't understand a regime unless you understand, so to speak, what it stands for, what a people stand for and what they look up to. This raises a further set of questions that we will consider over the term. How are regimes founded, the founding of regimes? What brings them into being and sustains them over time? In its oldest sense, political science simply was a science of statecraft. What are the qualities necessary for sound statesmanship? How does statecraft differ from other kinds of activities? Must a good statesman be a philosopher versed in poetry, mathematics, and metaphysics? Or is statesmanship a purely practical skill requiring judgment based on deliberation and experience? Is a streak of cruelty and a willingness to act immorally necessary for statecraft, as Machiavelli infamously argued? Political philosophy is an imminently practical discipline, a practical field. Its purpose is not simply contemplation alone: it is advice giving. None of the people we will study this semester were cloistered scholars detached from the world. Plato undertook three long and dangerous voyages to Sicily in order to advise the King Dionysius. Machiavelli spent a large part of his career in the foreign service of his native Florence, and wrote as an advisor to the Medici. Hobbes was the tutor to a royal household who followed the King into exile during the English Civil War. The study of regime politics either implicitly or explicitly raises a question that goes beyond the boundary of any given society. A regime constitutes a people's way of life, what they believe makes their life worth living. What has or ought to have a claim on our loyalty and rational consent? What function does the best regime play in political science? How does it guide our actions here and now? The best regime will always favor a certain kind of human being with a certain set of character traits, whether common man or warrior. Aristotle says the good citizen is not the same as the good human being. The philosopher can never be truly loyal to anyone or anything but what is best, he says. The study of political philosophy may be the highest tribute we pay to love, he adds. The best regime embodies a supreme paradox, it would seem, he writes. It is superior in some ways to all actual regimes, but it has no concrete existence anywhere, he argues. The quest for knowledge of the best regime must necessarily be accompanied by eros, or love. see you back, and have a very good but thoughtful September 11^(th). See you back on 9/11/11. I'll see you back in a week or so. Thanks for your support and good wishes. I love you all, and see you on 11/11 /11. Back to Mail Online home. back to the page you came from. See you in a month or so, and I'll be back to see you in the U.S.

ROUGE-1: 41.98, ROUGE-2: 38.30, ROUGE-L: 38.44
BERTScore: 70.24

==============================================
==================== [48/100] ====================
Summary:
Ahern: So the exams are not graded. The TAs have exams of their own and I have told the TAs that, fingers crossed, I would like to have exams back sometime on Friday. That may not be until afternoon, I don't know at this point. But the aim is to get things back by Friday. When exams are available, what I will do is I will send an email out to the class announcing that they're available and announcing where to pick them up. exam. Ahern: I have never had an exam where I had fewer questions. There were maybe 10 questions I got on the exam and that was for a class of this side, really unusual. "I find most students are honest. I've only had a handful of situations where in this class, where I've had dishonesty as an issue," Ahern says. "There's just too many eyes here and not enough of our eyes," he says of his class. "So that's why I videotape those" Ahern: How many amino acids can form zwitterion? None. That's not trick. There are no amino acids, everything, so think about it. Ahern: What did you have in mind for the last question? The one about the Kcat? Oh,Yeah, yeah, yeah. okay. So the question, and by the way, I will post the key outside my door after we give the exams back. I don't post those now because students get all anxious until they see their exam. Ahern: How can you have two apparent Kcats? and the answer is it depends on how you calculate the concentration of the enzyme. If you take Vmax and divide it by the total concentration of enzyme, you will see a reduced Kcat compared to the uninhibited enzyme. Why? Because much of that concentration of. enzyme is not active, it's inhibited. However, if you take the inhibited out of it and you take. Vmax to divide it, you'll see exactly the same Kcat as if you have an uninhibited. enzyme. where time is sometimes a factor, and so I was going to have 3 of the longer answer questions and I decided not to do that and I made them shorter. So I had 2. There's trade offs in all these as I've told other classes. So one of the things that happens is the fewer the questions I have, the more points each question is worth. And so I have to try to strike a balance. And this balance, I think works fairly well. I'm glad to hear there weren't too many at least who indicated time problems. give an exam where I ask you to sign their name and people would say they didn't have enough time. But literally, I rarely have much of an issue with the other two exams. And usually I'll tell you. When I ask that question to this class, I would say I've seen as many as 2/3 of the hands go, 'I didn'thave enough time' So I was very careful to try to make sure I didn't ask you too many things. It meant I had to have 20 point problems because we have to have a 100 point exam. same manner that the enzyme is binding a substrate. And so the parallels of those with respect to concentration and so forth, that's really the reason you see those two curves being essentially the same. Everybody's all [Ahern makes groaning noises]. Alright, I hope everybody got how I start my lecture. Right? Student: No. Ahern: No!? Student: I said if you said something about starting the exam, we would give credit. Or starting the class, we'd give credit, yeah? S1 proteases are a class of enzymes that are called S1. They're called serine proteases because they all use serine in the active site. So they all have the catalytic triad. But there are some related proteases that have things like that that I want to spend some time on. And I'm going to talk about some of those today. But before I do that,I want to talk a little bit more about S1 proteased because so far all I've told you about them is that they are aclass of enzymes. a few minutes talking about today. Using genetic techniques today, it's very easy to alter the genetic code for any of these proteases and change which amino acid is presence at any given place. Researchers have changed, for example, a serine residue of 221, which is the serine, gives it its name, to an alanine. Or changing the histidine position 64 to anAlanine or changing all 3 to analine. And when they do that, and they compare the activity, so this is the log of Kcat. So Kcat of course is a good measure of velocity. the water as if it didn't have a proton that could be pulled off in the first place. So these are important. When we look at removing the aspartic acid, we still see about 5 or 4 or 5 orders of magnitude lower. That tells us it's not absolutely essential for its catalysis although it does play some importance in that. But this tells us that that as partic acid residue is not as important as the other two. The other 2 are much more important. Ahern: It's all possible, of course, but my production would be, in this case, that it would not be, because we're thinking about very precise orientations inside of that active site. Student: Why is it just as ineffective when you replace as three as when you take off one them? Ahern: Very good question. Any one of these mutations alone is enough to knock the enzyme out essentially. You might say well why do you have any activity at all? And that's also a question. good question but remember we have a very little activity and we have the rest of the structure of the enzyme intact. We have the binding site, we have an environment in there that maybe, in addition to the specific amino acid we see in an environment there that's favoring to some extent these activation and breaking of peptide bonds. So that's an interesting observation. What I want to do now is show you some related proteases. Subtilisin is a protease, it's an S1 prote enzyme, but there are other proteases that aren't S1 that behave very much like S1. a cysteine residue adjacent to a histidine. Ahern: The nitrogen on histidine withdraws the electron from the sulfhydryl group on cystine, which is then nucleophilic and attacks the substrate. Another class of proteases that is slightly different but interesting are called the aspartyl proteases. An example which is are renin. The nucleophile bond falls apart and part of the polypeptide chain is broken. The covalent bond between the water and the residue starts to flip. The 3rd class of proteases are called metalloproteases. These enzymes derive their name by virtue of the fact that they use a metal ion as their way of holding on to a water molecule. The most common ion that's used is zinc. The zinc, you'll notice, is positively charged. The positive charge of the zinc is attracted to the negative charge, partial charge, on the oxygen of the water. That interaction helps to hold water at the right place. And then, and this is going to vary from one enzyme to another, there is a side chain that will help to remove a proton. The basic mechanisms are the same. We created a nucleophile, the nucleophile attacks the carbonyl group, the peptide bond breaks, and the pieces go their way. Well this business of creating nucleophiles is not unique to proteases. There are other enzymes that use nucleophile and generation of nucleophile in their catalytic mechanisms. One of these is an enzyme we've been talking about some already, that's the carbonic anhydrase and that's right here. You guys look very tired. of a sudden realizes, "Whoa! What's that?" He grabs it, you know. Wipes the dust off of it. Of course in the process polishes this thing. And out pops this magic genie. And he says, "oh master, thank you, I will grant you 3 wishes." and the guy says, 'oh, this is really great' he says,. "I guess I want a billion dollars "so that I can be a very rich man." and poof, a certificate appears in his hands and it says he has a billion. dollars in a Swiss bank account. Carbonic anhydrase can catalyze the conversion of a million molecules of substrate into product per second, per enzyme. Most enzymes have a fairly narrow pH range where they work that's ideal. But this guy tops out at about pH 9, where we get up to a million per second. Why is its Kcat so high at such a high pH that it really doesn't encounter in the body? And so that's what I want to show you next. It's going to relate to the things I've been talking about. The rate limiting step in the catalytic action of this enzyme like that of the proteases that you saw before, is the rate of formation of the nucleophile. At pH 9, the enzyme is still holding its shape enough that it's actually able to continue catalysis. When we get above that, we're going to see the ending drop off precipitously. There is a lot of interest in manipulating enzymes to infact increase their activity and increase their efficiency. If the enzyme structure is stable at pH 10, the enzymes will be way better at 10 than it is at 7. their efficiency. In the case of carbonic anhydrase, though, remember what's limiting them is actually defusing it into the active site. It's probably not going to get much better than that million even if we were to improve that. But for a metalloproteases, it may very well be useful because now we can stabilize the enzyme with disulfite bonds, we can use it at a higher pH, that might very may be a strategy. We're slithering along through this. Let's take a, spend the last 5 or 6 minutes talking about restriction enzymes. We'll see some similarities we saw before. They use water to break the bond. And that should give you some hint about the mechanism that they use. One of the things we see in restriction enzymes is that they all require magnesium for their action. magnesium, like zinc, is a divalent KCat ion. It does help to position the water so that it can lose a proton and make an attack on, in this case, a phosphodiester bond. We're not breaking peptide bonds, obviously. But we're breaking phosphodiesters because those are the bonds between the adjacent nucleotides in a DNA molecule. A restriction enzyme is a protein. That protein grabs a hold of DNA. EcoRV recognizes the structure, the sequence GATATC and it cuts right in the middle of it. Now I want to explain to you just physically how a restriction enzyme works and then I'll show you very briefly a little bit of mechanism. DNA is a very complex substance. It's very difficult to understand. It has a lot of different functions. It can be used to help people understand how DNA works. is a negatively charged molecule, we would expect that to grab a hold of DNA, perhaps positive or neutral, we certainly wouldn't expect the protein to be negatively charged because it wouldn't interact very well with DNA. Most of the time it's going down that trip down the DNA molecule, it does not encounter the sequence GATATC. In fact that sequence will occur randomly, only about once every 4,000 residues. In the case of the serine proteases, that shape change resulted in the creation of the enzyme. alkoxide ion. In the case of the restriction endonucleases, that shape change is more dramatic. What it does is it actually causes a bend to occur in the DNA. So we think of the DNA molecules of being straight and linear, but when the enzyme is bound to that proper site, the enzyme goes "oh, whoa!" and it bends. The DNA molecule is physically bent at that point. It's physically bent. Now that bending turns out to be critical for the catalytic action. like we saw with the peptide bond and everybody's happy. I will very briefly go over that next time and I will see you on Friday. Thank you for listening to our show on CNN.com. We will be back on Friday at 10 a.m. ET for a new episode of CNN Live in the U.S. and 2 p.M. ET in the UK. For more, visit CNN.co.uk/live and follow us on Twitter @cnnlive and @CNNLive.

ROUGE-1: 43.78, ROUGE-2: 41.21, ROUGE-L: 40.35
BERTScore: 71.95

==============================================
==================== [49/100] ====================
Summary:
AA and I are going to show you how to make vanilla extract so easy so yummy so good for all the things that you would use it for cakes whatever really really good isn't it so let's go [Music] simple now all you want for this is about 1 oz or roughly 30 G of vanilla beans so they'll be you know long Dobby whacker things and just cut them up into I don't know a couple of cenm you may maybe maybe qu an inch half an inch or so. cup of vodka that's it all you do is put on the lid and just give this a shake and you just have to shake this once a day for at least a month preferably 2 to 3 months cuz you'll get more flavor it will ferment and it'll be a nice strong flavor just store this in a dry cool place and just as I said just shake once aday as you can see it's nice and dark I've been shaking this every day for about 2 months now a month will be enough but the longer you leave it the more flavor you'll have. like this no no you don't want to try it oh it smells so good do I smell this no you sure no it's really good can I smell it no oh let's give this a little little taste hold on oh yummmy do you want totry no no I'll see you next time for my next [Music] meal. Like this noNo, you won't even try it. No, you're not going to even smell it. You're not even going to taste it.

ROUGE-1: 72.43, ROUGE-2: 68.28, ROUGE-L: 68.11
BERTScore: 78.76

==============================================
==================== [50/100] ====================
Summary:
RAFAEL JARAMILLO: All right, let's talk about intermediate phases and line compounds. So I want you to recall intermediate phase in a three-phase system. And I'm going to recall it visually, and we're going to remember what the free-energy composition diagram looked like in such a case. And it looked-- let's say an alpha phase and the beta phase. We had some intermediate phase. So the common tangents are to look like this with a common tangency there. If n is fixed, it's a little bit more like a molecule than a solution. So the solution model becomes very narrowly shaped, like a pin. All possible common tangents are going to converge at the same point. That point is x of B equals n. That's that one composition that we find in nature. So I no longer need a solution model. All I need is one point, that one point is one free energy point and one composition. So this kind of, to me, looks like a. The magnesium nickel system has a number of different phases. At high temperature, this Laves phase develops some width. But when you drop down to low temperature, both of these intermediate phases appear as line compounds. These Laves phases are of interest for people that study magnetism because they have these triangular sheets which are interesting for spin liquids and spin ices-- and then this FCC nickel. But this is the point I want to make here is that these are very distinct structures, and they're only occurring at very distinct compositions. like this. Magnesium nickel-- actually, magnesium nickel system, right? So, for instance, at some low. temperature, we have here this is going to be x nickel. And my taut rope construction, or my common tangent construction, ends up being just a series of straight lines. This is magnesium nickel 2 nickel. All right. So now let's talk about the size of these vertical segments. And it's often written as delta form. It is the free energy change for formation of 1 mole. of compound from the elements in their reference states. So, for example, I might have 2 moles of magnesium in. its alpha phase plus alpha-- let's say HTP-- plus a mole of nickel in its alpha. FCC phase. And these can react to form magnesium 2 nickel. This formation energy is per mole of compound. When we draw free energy composition diagrams, we assume 1 mole total of the components. So there's a normalization that you need to apply in order to use formation free energies. Modeling we have a model for how the free energy changes when you combine a total fixed amount of atoms in different composition ratios. This measure is 1/3 times delta form magnesium 2 nickel. So that is kind of a a solution. But this is different in the formation energy, right? This is a delta formation free energy on a free energy composition plot. So 2/3 a mole of magnesium, 1/2 of nickel combined to form this magnesium 2 Nickel 1 phase. That green arrow is the change of free energy. algebraically-simple point, but it's a conceptual point that it's easy to mess up. So you have to apply that normalization if you need to draw such plots. All right, I want to give you some examples of line compounds in nature and in technology. And then we'll come back to discuss the thermodynamics a little more. Before I move on to some examples, are there questions about this algebra, this arithmetic, the concept of formation energy, the mouse-face plot, anything, anything of that nature? have some examples here. So you can see that you can get a fair amount of silicon into copper. That's this kind of purple region. There are silicon bronzes and silicon brasses-- that is, bronze and brass alloyed with silicon. Those are ternary systems. But silicon tends to be a pretty useful additive for copper-based alloys. I used a silicon bronze when I was in grad school and we were designing high-pressure cells that needed to be actuated at low temperature, below 1 Kelvin. agencies around the world have developed in the last century. There's no real lubricant that you can use. And so there are certain silicon-based bronzes that have been developed for that application. And I didn't know anything about all that, really, when I was in grad school. But I needed something that would work for my high-pressure experiments. So we ended up with that. So let's see. There're a couple of other solid solution phases. But how many line compounds are there? Trick question. That's why it's a trick question. Silicon's not an intermediate phase, but it is a line compound. The solid silicon phase appears to have no equilibrium solubility of copper. In reality, you always have some finite solubilities of a solute in a solvent. So in the case of silicon, the solubilty of metals is very, very low. The solubileil limit is typically parts per billion. But in principle, there is a purple region extending along this y-axis of solubiliy of copper into silicon. Doping semiconductors is why we're able to talk to each other over Zoom. Doping some metals into silicon is as important as it gets. The solubility limits can be in the parts per billion. But they're rarely above parts perbillion. There's always a solution to doping semiconductor devices, says Dr. Richard Branson, founder of Branson Semiconductors, a company that specialises in semiconducting materials. The company's products include the gallium arsenide line compound and gallium arsenic system. gallium arsenide. Where silicon isn't fast enough are the transmitters and receivers of your phones, gigahertz RF networks. Another place you're going to find it is anywhere you need light. And so gallium arsenicide and alloys, thereof-- which we don't show here-- are the basis for all optoelectronics and photonic technology. So right now, we're Zooming. But likely, some part of the data between me and you is carried by fiber optic. Silicon carbide is a refractory-- some people will say it's a ceramic. Some people say no because it doesn't contain oxygen. It's of enormous industrial importance. It also is an emerging semiconductor material for high-power electronics. In 50 years from now, if the idea of a power substation is a thing of the past, it will be due to silicon carbide and similar high- power electronics that are being developed today. And this last one, this is the titanium-sulfur system. This is a neat system because, first of all, it has everything in it. third of the Nobel Prize work that was recognized recently in 2019 with the chemistry Nobel Prize was for work on titanium-sulfide-based cathode. It's a layered material, so you can shove a lot of lithium in it. So these are-- for example, systems that have line compounds and other things. Do we have any questions on reading these, interpreting these, using these? AUDIENCE: Yeah, I have a quick question. So on the bottom left one and the top right one, do they both contain three line compounds? doesn't have to be that way. Here's a case of a line and an element that actually does have a pretty wide, solid solution, great range. At low temperature-- actually, similarly to gallium arsenide at low temperature, it's going to be a really boring free-energy composition diagram. Let's draw what that looks like. So would anyone like to take a stab at how I would draw a free- energy composition diagram for the silicon-carbon system at low temperatures? the free-energy composition diagram. That's what I meant to say. OK, then we move back to the board. I'll just make a couple of conceptual points and then we'll finish up. Comparing solutions at equilibrium to line compounds at equilibrium. So this is going to be two solutions. Let's imagine an alpha phase and a liquid phase. And I'm going to draw just a representative phase diagram just to have something in mind. So here's alpha. It is liquid. Here's x. we have these composition variables. We're familiar with that. The equilibrium condition, the equilibrium condition dG equals 0 satisfied by common tangents. Chemical potentials are the same in both phases so that the coefficients are 0. That's ensured by the common tangent construction. So this is just recalling, right? Now let's imagine two line compounds. B3A2 and B4A3. How did I come up with that? Well, I sketched an imaginary phase diagram, and then I had to follow through on my sketch. 1/7 of the Gibbs free energy of the IV-III phase. And these phase factions are determined by lever law. This is really the point. When you have line compounds in coexistence in equilibrium, there are no internal composition variables. Whereas when you have solution phases in equilibrium,. the internal compositions are variable. And that's what's led to everything we've been enjoying over the last month and a half. And now we have these cases where the compositions are not there [INAUDIBLE] anymore. Z is determined by charge balance. Oxygen is always O2 minus in compounds. Metals have various oxidation states. Some metals have more than one oxidation state. Z is in its reference state. That could be solid, liquid, or even gas-- although, we don't really encounter that so often. Oxidation of metals at low temperature, the metals are solid unless it's gallium or mercury. Oxides are line compounds. That z is not a variable. That's what that's supposed to mean. z is an integer or a rational fraction, and it's fixed-- SiO2, magnesium oxide, Al2O3, so forth. So when we return on Wednesday, we're going to talk about the thermodynamics of this reaction. We'll use this property of being line compounds, and we're also going to use a bunch of other things as well. Back to the page you came from. Follow us on Twitter @CNNOpinion and @cnnopin.

ROUGE-1: 49.83, ROUGE-2: 47.28, ROUGE-L: 47.39
BERTScore: 70.79

==============================================
==================== [51/100] ====================
Summary:
A random variable can take different numerical values depending on the outcome of the experiment. Some outcomes are more likely than others, and similarly some of the possible numerical values of a random variable will be more likely. We restrict ourselves to discrete random variables, and we will describe these relative likelihoods in terms of the so-called probability mass function, or PMF. The PMF is also sometimes called the probability law or the probability distribution of a discrete random variable. The probability of this event is equal to 1/2. with a probability, and we indicate it using this particular notation. More formally, the probability that we're dealing with is the probability, the total probability, of all outcomes for which the numerical value of our random variable is this particular number, x. We use a subscript, X, to indicate which random variable we're talking about. This will be useful if we have several random variables involved. For example, if We have another random variable on the same sample space, Y, then it would have its own probability mass function. The argument of the PMF, which is x, ranges over the possible values of the random variable. The probability mass function is a function of an argument x. For any x, it specifies the probability that the random variable takes on this particular value. Since the total probability of all outcomes is equal to 1, the probabilities of the different possible values of the random variables should also add to 1. The probability massfunction is always non-negative, since we're talking about probabilities and probabilities are alwaysNon-negative. In terms of our picture, the event that x isequal to 3, which is this subset of the sample space. In order to do any probability calculations, we also need the probability law. Let us assume that every possible outcome, there's 16 of them, has the same probability. We will concentrate on a particular random variable defined to be the sum of the random variables, X and Y. What we want to do now is to calculate the PMF of this random variable. We need to find this value for all choices of z, that is for all possible values in the range of our random variables. the form of the answers. And it's always convenient to also provide a plot with the answers that we have. The answers come in the form of a plot. The plot comes in the shape of a map. The map is a map of the world as seen from the top of a mountain. The top of the mountain is a mountain with a waterfall at the top. The waterfall is a waterfall as well as a river. The river is a river that runs through the middle of the village. The rivers run through the village and the valley.

ROUGE-1: 46.28, ROUGE-2: 40.81, ROUGE-L: 41.19
BERTScore: 75.44

==============================================
==================== [52/100] ====================
Summary:
Protein three-dimensional structure is an important part of proteomics. Structure has implications for the binding of small molecules such as drugs. We will in short order get to the scary pumpkin-like molecule. We'll connect it to last week's through the vehicle of focusing on motifs that are involved in protein interactions with the two nucleic acid macromolecules. We're going to be covering, just as we introduced RNA omics with RNA structure, we'll spend this entire class talking about protein three-Degree Structure. of the proteins and the three dimensional structure of the nucleic acid and these symmetry elements would align. Now in order to introduce these symmetry element and the possibility of having codes that you can at least program, even if they may have been tinkered about during an evolution, the question is to what extent can we get our hands on these kind of protein and nucleic Acid motifs that interact. In order to get at this issue of where there is a code-- and I just take this as one of the ways of dealing with the incredible complexity of proteins is to give this a theme. all kept within the helix with a repeat of 3.6 residues per turn. In the beta sheet, they tend to have a longer, straighter chains where there are unpaired hydrogen bonds. The arrows typically point from the n terminus to the c terminus just as in nucleic acids is from five prime to three prime. OK, now how can we use these basic motifs? These are the smallest meaningful units of protein three dimensional structure. How can we used these to recognize other macromolecules, other proteins and nucleic acid? We have these motifs that we could find, weight matrices for them by aligning lots of sequences. Now instead of aligning sequences, let's see what we can do by mutating both the protein part and the nucleic acid part. This is a way. of getting a really good empirical data set, which in principle, you can combine it with similar functions on the flanking ones, and you can dial up sequence of a protein interaction, at least with this class of proteins. you can get the binding at a lower concentration, which means a stronger binding. How you relate that to the binding constant we had in the previous slide is the subject of this slide number eight. Now we call this the apparent equilibrium association constant because these experiments, just like many binding in living cells is not at equilibrium. It's a dynamic process in the cell and in vitro. So that one over the association constant is directly related to the fraction of DNA molecules with protein bound, which is directly proportional to the signal intensity and fluorescence. groove of the DNA. And the reason the textbook is wrong, first of all, it emphasizes the non-helical part of the zinc finger. You can barely see the helix with the background there. And also the way it loops through the DNA, if you look at this carefully in your textbook, this is actually the [? Mount ?] book, it actually interdigitates with a phosphodiester bond, basically going through the base pairs, which is not at all what happens. of the protein maintaining almost perpendicular to the DNA axis. But again, so on the left is the three tandem repeats, and on the right is a dyad axis. These are the two major symmetry classes, and it's amazing how many nucleic acid protein interactions fall into one of these two classes. Can we extend this to RNA? This is a much more complicated situation with RNA because you don't have these long perfect double helices anymore. You have these very short RNA helices that I found. showed in the last couple of classes. This is transfer RNA, one of our favorite molecules here, with the anticodon at the bottom of each of the pink structures. And the amino acid acceptor three prime end of that 70-some nucleotide-- 70 to 80 nucleotide nucleic acid. So the pinks are all the tRNAs, and there are at least 20 different types of amino acid and has 20 types of transfer RNAs and 20 type of proteins that add amino acid onto the three prime ends of the transfer RNA. If you wanted to create a new code, as these authors have, you'd have to find homology among the proteins or graph domains of recognition between each one. You can arrange to make a new amino acid by carving the pocket the amino acid recognizes and grafting on the appropriate nucleotides. OK, you've had some programming experience that hopefully will prepare you for the real world of interacting with input and output from various devices. The topic today is proteins, and this really is the main contact between the exquisite regulatory mechanisms. that you can basically program the almost digital nucleic acid world inside the cell but via clearly analog inputs and outputs. We also-- I've listed some of the scariest proteins that I could think of. And we're going to talk about three of them. One of them in the slide, which is the proteins that are actually involved in causing the symptoms that come from when you're worried about anthrax. And then we'll talk about HIV yet again, this time, polymerase mutants that cause drug resistance. not inside the cell. But the whole complex gets internalized. Still, topologically, it's as if it were outside the cell when it's inside this little vesicle. So you can see that when we're talking about protein three-dimensional structure, whether we're predicting it or solving it, protein is not a static object. Here, it associates with one factor. It associates seven of itself. It interacts with lethal factor. You need to think of these as dynamic systems with many different states. minus 9th seconds. That's atomic motion. Transcription that we talked about, all of the regulatory mechanisms of transcription last time, the rate of the constant for that process is around 50 nucleotides per second. Not entirely coincidentally, that's about the rate at which it is translated into protein. That could be used as a timer in a circuit of these longer time frames, like cell cycle, circadian rhythm, very long time frames in ecological systems with bamboo and various pests. then development and aging, which can be on the order of hundreds of years, at least for humans, turtles, and whales. So what we think proteins are good for depends on the accuracy. And the accuracy depend on the method. At the very bottom right, we have a very appealing approach, which is de novo, a priori, or ab initio prediction of secondary-- of protein three-dimensional structure from the sequence alone. But unfortunately, accuracy so far-- and we'll delve into this in more detail in a moment-- is on the orders of six angstroms of difference between the predicted structure and what it actually is. your accuracy, as you can get from NMR and X-ray crystallography, you now are in a position to study catalytic mechanism and design and improve ligands, such as drugs. This is really where we want to be. There may be a day where we can do this all from ab initio prediction or modeling at very great distances. But for now, modeling atVery short, say, 80% to 90% amino acid similarity, is important. Remember, there's a variety of different protein structures. And ways that you can discover the small molecules by a clever use of parts of it that you know bind. HIV is one of the most sequenced molecules on Earth. It's been sequenced many times because as a patient takes the drugs, their population of the AIDS virus changes. And that causes a drug resistance in the HIV, with unfortunate consequences for the patient. We can take-- now, making mutations in polymerases is not entirely of negative consequences. And I'm going to show you a really beautiful example where a DNA polymerase, you want to change it so that it can now handle what would normally be an inhibitor. space to the position on a phenylalanine or a tyrosine, position 762 of this polymerase. If you now put in a dideoxy inhibitor, you now have too much space in there, and you start trying to fill that space with other bulky molecules, like water. And basically, the binding constant, it becomes much less favorable binding when you're lacking both oxygens. So this presented an opportunity to engineer some polymerases which had a phenylicalanine there to become more accepting of the dideoxys. This has an 8,000-fold effect on the specificity of this polymerase. Now, that's how we program a particular atom to achieve an important goal. Point mutants are not the only way to generate conditional mutants. Many of them historically were. But there are ways that you can program, and conditional, meaning you can regulate under what conditions. It's the ultimate where we go in and if the protein is already present, we can change that particular nucleotide in situ in the correct place so it's properly regulated and everything. the protein is expressed or not or active or not with an entire domain, or with single nucleotide polymorphisms. Now, so this is one way. This is the nucleic acid way. Another way is by modulating the activity of the proteins from the outside with drugs or drug-like molecules and chemical kinetics. And under the subheadings for that, you can make these by combinatorial synthesis-- and we'll show an example of that. But combinatorially synthesis can be based on design principles, not just completely random. that we didn't discuss before. But in previous classes. But it's related to what we've been talking about. In the case of the zinc finger, we made an altered specificity. We made new zinc fingers with bind to completely new trinucleotides. With the DNA polymerase, by changing one amino acid, we could make it now accept almost four logs better an inhibitor is very useful. And here, many different-- many of these are enzymes, where you can not just knock out the enzyme, but actually make it recognize a new substrate. ApoE refers to its involvement in cholesterol metabolism and transport. ApoE3 is present in about 80%, and is far more common in human populations. The ancestral form of this, for example, found in chimpanzees at nearly 100%, is this arginine 112, instead of what's now common inhuman populations was cysteine 112. We now eat a lot more fatty things. We live long enough to get Alzheimer's. And so maybe this was something that was-- this bad allele was good in chimpanzees that have different diets or lifespans. strand, to fall back and interact. And you can see that one of the nearest amino acids to this arginine 112, which is the main difference between ApoE4 andApoE3. Arginine 61 is the same on the two alleles. But you think of this as one haplotype, and in chimpanzees the haplotype is now threonine 61. So it's like this compensating, complementary mutation, just like we had in the oxygens in the polymerase a couple of slides ago. think of these things in terms of proteins. You can have-- a disulfide is a very important thing to lose. They tend to be highly conserved. If you introduce a proline into what would normally be an alpha helix, this is something where knowledge of the three-dimensional structure would say, oh, that proline, this a priori, without any knowledge of conservation, could be a huge change. And then these multi-sequence profiles are a good way of looking at the conservation. That's a way of prioritizing single-nucleotide polymorphisms that might have impact on pharmacogenomics or disease. The idea of chemical diversity, in a way I hope nicely connects to where we've been with RNA arrays. RNA arrays, and the double-stranded RNA array that we used earlier in class today, can be generated in a commentorial sense. You can make an exhaustive set. Or you can make them as a mixture of solid phase particles and then separate the [INAUDIBLE] phase particles out in some manner. Solid phase comes up again and again in arrays. It's very obvious why you have a solid phase. You want to be able to address it by its positions in x and y on the array. purification of your products simply by washing rather than doing complicated purification procedures. And it allows you to, in the case of beads, there now-- you can think of it as an ultimate and flexible array. You can move the beads around and put them in new arrays, and identify them later. Anyway, so we're going to introduce the general way of making either-- complex chemicals, whether they're linear polymers like proteins or nucleic acids, or much more tighter and small molecules.  Synthetic way of getting short peptides, either by directly synthesizing the peptides or synthesizing nucleic acid that encodes that peptide. And you can think of these as drug-like molecules. These are naturally related-- they can be analogs of nucleic acids and proteins, not just straight ones. And we'll talk about opportunities for making these analogs. And the process is cyclic in the sense that each cycle, you return, and the polymer gets a little bit longer. You start with one monomer. on a solid phase, shown by these little hexagons on the far right side of the slide. And you add-- you remove the protecting group on the immobilized polymer, one protecting group. And then you bring in this reactive group, otherwise protected. And there's really one major product that you expect. You wash off all of the excess. You now have one longer. You deprotect. This DMT group is removed. There may be additional steps, such as oxidation, which will stabilize the new bond. I said there's an opportunity here for modifying the nucleotides or oligopeptides or other chemicals to make them so that they're related to, but not identical in every property, to normal constituents of your body or of a bacterial cell that you're aiming at. And why would you want to make derivatives? Why not make the exact thing? And examples are, in the previous slide, you can make modified bases. And in slide 29 here you can change the backbone itself. which you can make small molecule diversity which are less cyclic than processes we just talked about. These are more a set of ordered reactions that has a conceptual repeat, but in a sense, you can think of it as a linear program that you go from the beginning to the end. And that's to make these polyketides, which are shown on the right-hand side of the slide. A large class of pharmaceuticals, including most of the antibiotics, are made by a fairly small set of organisms, such as streptomyces in certain plants. Drug-like molecules are small, so they diffuse quickly and get to their site. Because they're small, they have less surface area to bind to their binding pocket. They have to be highly cross-linked in order to maintain the rigidity. And the third source of biological diversity is one you're probably more familiar with, which is the immune receptors, B and T cell receptors, the antibodies, and cell-mediated immunity. And these use recombination machinery to program various combinations of nucleic acid motifs. to a template-independent polymerase, [? thermotransferase, ?] which will extend a few nucleotides of completely random nucleic acid sequence. This is one of the examples in biology where you generate sequence de novo. The proteins themselves, these little arrow-shaped things with boxes in them along the top, labeled Module 1 through 6, those proteins are, of course, made on ribosomes. But then they act kind of like the solid phase synthesis. where the acyl carrier protein, ACP in the box, binds to the first monomer, and it starts transferring it from protein to protein along this multi-domain huge protein. And there's actually three proteins in a row here. And each of the steps are taken in order along the protein. But you can see each of these has a substrate specificity. And by changing the order of substrate specificities, you can build up a huge combinatorial collection here in microbial communities, and also in the laboratory. known protein might be, [INAUDIBLE],, which binds to DNA, and B42, which activates transcription of something for which you have a good visual assay, like [? URO3, ?] life and death. And so this is a so-called two-hybrid assay and variations on it. And you get this information about-- you can either collect a big data set of proteins that interact from a proteomic scale experiment, or from molecules that inhibit one or more of them. We have hundreds of proteins for which we have three-dimensional structures. From some of them, we have information on what ligands they bind. And typically, we want to select targets for binding drugs, or for solving the structures of proteins. And how can we do this? How can we decide which targets are high on our list to go for next? This is an example of a strategy where you use a little bit of prior knowledge, which can be empirical or it could be purely computational, about how to limit your library. would like to have-- you've got your target. You've gotyour genome sequence-- gene sequence for that target. How, then, do you get the three-dimensional structure that helps you design drugs or improve the drugs that you have? Well, one very attractive approach, given a protein sequence which might get from their deluge of genome sequences, the practical approach might be to start with this gene sequence. And try to predict the three dimensional structure of the protein and its ligand specificity. Once you have a regulated gene, getting the protein sequence is easy. Getting from the sequence to secondary structure is easy in the context of some of these other things. But still, the accuracy is only around 77% for secondary structure and about 25% for ab initio three-dimensional structure. We'll pick up this thread right after a break and carry on to actually how we get the three- dimensional structure, whether it's predictive or experimental, and the computational tasks there. Take a break.

ROUGE-1: 51.91, ROUGE-2: 50.44, ROUGE-L: 50.08
BERTScore: 71.31

==============================================
==================== [53/100] ====================
Summary:
 AI is replacing human tasks faster than you might think according to a CNN business article more than half of large US firms plan to use AI within the next year. The New York Times reports that generative AI could automate activities equivalent to 300 million full-time jobs around the world. open ai's chief executive that's Sam mman says governments will need to assume the bulk of responsibility in supporting workers AI labor market disruptions and the question will employees just end up training AI systems only to them be replaced by them. last decade you know over a trillion customer insights are built on our platform every single week and now here we are in the generative AI Revolution um when it comes to the employee experience some of the AI deployments are things like uh you know a lot of our employees were spending time looking at disperate systems to find knowledge articles access to benefits who to speak to on the first day how to onboard and ramp. Now with AI applications that we've deployed they don't have to go to multiple systems anymore. One quarter of employees saved a combined 50,000 hours. At.at what that's allowed you to do I mean as you said free up time allow those staff to do other things. I mean how does that work how do we square that Circle well I think like you know any other uh benefits of becoming more efficient or more productive it is now spending more time on higher value impact work in your job those are the core benefits that we've seen from our teams instead of spending you know 10% of your time looking for information. Cisco CEO: We have to train the Next Generation in both these Advanced AI skills but also some of the fundamental essential digital skills that we need. We've got to do both uh to help Society yeah and so that's a sort of skills Gap isn't it and Stephanie I wonder whether firms are ready because I'm looking at numbers here 97% say they are.get us that extra day off or a 3-day 4 day working week that we might all want um chintan talk to me about skills as well. of companies say that yes they know they need to do this but I think what 14% say they're actually ready to do it that's quite the Gap yeah. Who is we talking about overhauling the education curriculum from what age 5 to 18 and then into the universities who's funding that and who has the skills to even do it yeah yeah and that is a big question and Stephanie you're always our guide on this program aren't you through all things Ai and I know you've got questions uh for our panel we've got two big players here um what do you want. Natalie: How do we make it so that AI is valuable for everybody and not just the usual people who profit from technology. Chintan: At Salesforce we receive over 2 million applications every single year here at Salesforce and we want to make sure that we're not leaving any talent unhidden and AI is helping us optimize that so I do see the advancements of democratizing uh access to AI through those efforts as well but it's something we think about all of the time related to trust.  AI decoded looks at the impact of AI in the world workplace. The tech may be able to speed up and automate all sorts of monotonous or repetitive roles but there's also now a concern that Tech like intelligent chatbots could replace roles that have traditionally relied on a more human touch things like customer service or call center helplines. We're going to speak to one reporter who's been researching the threat posed to workers and how some are now fighting back around the world and across the UK. some workers are feeling the effects of that already and they're starting to ask who is going to protect us you know what entities are stepping in to take responsibility for retraining or providing opportunities for workers whose jobs might be entirely eliminated by AI technology. I think that would be incredibly demoralizing for anybody who's asked to do that so I think employers really are going to have to think about the messaging but also the after plan so once you've trained up an AI to do your supposedly Bol tasks what are employers offering are the higher value more creative more interesting. Emma asked if we would actually see an increase in Union membership for private sector workers in the United States. She said a lot of workers want to feel that their voices are part of the process in deciding how AI is going to be used. She argued that actually the people making all the decisions about the AI are not the ones who will be affected by that change it's workers further down the food chain that will find their job disappears before the ones sat in in the boardroom. EM: The role that I'm seeing unions play is just reminding employers that they should be bringing workers to the table to help make and shape decisions. frustrated because she felt that she was being asked to train her replacement whenever she used an AI tool because the AI was watching her do her job. What she was asking asking from her Union was just the ability to be at the table making decisions about AI along with company Executives and Emma this made me think of the difference between what it's like to work in the United States where Union representation is so low and often in opposition with management to models we see in places like France or even Germany. I almost feel like the model for unions needs to be updated for the 21st century too how do you see that playing out? were most at risk because of automation. People are realizing you have to throw out the door any ideas you had about who is really at risk and say every job is going to be changed. We just hope that the workers whose jobs are changing have a voice in saying how yeah it's turkeyy is not going to vote for Christmas are they if those are the ones that could find their jobs being replaced. There's uh there's so much in there and Stephanie just a final thought from you in all of this about briefly if you will. I think we also have to be realistic you're not just going to suddenly go get an engineering degree in two weeks right learn cyber security overnight um these are these are highly complex skills that require usually years of training so this will involve I think a sort of again look at the Danish model of the government and companies working together to sponsor re-education and retraining for workers. This is a total pivot of our economy uh Stephanie really good to have you with us again guing us through all of this and now Emma thank you so much.

ROUGE-1: 46.46, ROUGE-2: 44.41, ROUGE-L: 42.51
BERTScore: 63.68

==============================================
==================== [54/100] ====================
Summary:
foreign I'm really excited especially for this lecture which is a very special lecture on robust and trustworthy deep learning by one of our sponsors of this amazing course themus AI. Theyus AI is a startup actually locally based here in Cambridge our mission is to design advance and deploy the future of AI and trustworthy AI specifically. I'm especially excited about today's lecture because I co-founded Themis right here at MIT right here in this very building in fact this all stemmed from really the incredible scientific innovation and advances that we created right here. Sadhana sadhana is a machine learning scientist at Themis Ai. She's also the lead TA of this course intro to deep learning at MIT. Her research focuses specifically on how we can build very modular and flexible methods for AI and building what we call a safe and trustworthy Ai. Sadhana will be teaching us more about specifically the bias and the uncertainty of AI algorithms which are really two key or critical components towards achieving this Mission. She'll be talking to you all about robust and trustworthy deep learning on. behalf of Themis so over the past decade we've seen some tremendous growth in artificial intelligence across safety critical domains in the Spheres of autonomy and Robotics. We now have models that can make critical decisions about things like self-driving at a second's notice and these are Paving the way for fully autonomous vehicles and robots. That's not where this stops in theSpheres of medicine and Healthcare robots are now equipped to conduct life-saving surgery. We have algorithms that generate predictions for critical drugs that may cure diseases that we previously thought were incurable. rooms is this these are some headlines about the failures of AI from the last few years alone in addition to these incredible advances we've also seen catastrophic failures. Every single one of the safety critical domains I just mentioned these problems range from crashing autonomous vehicles to healthcare algorithms that don't actually work for everyone even though they're deployed out in the real world. At a first glance this seems really demoralizing if these are all of the things wrong with artificial intelligence how are we ever going to achieve that vision of having our AI integrated into the fabric of our daily lives. A lot of the problems in modern day AI are the result of a combination of unmitigated bias and uncertainty. In this lecture we're going to focus on investigating the root causes of all of these problems these two big challenges to robust deep learning. We'll also talk about solutions for them that can improve the robustness and safety of these algorithms for everyone. Themis is innovating in these areas in order to bring new algorithms in this space to Industries around the world and we'll talk about the ramifications for this for real world AI. a lot of clinical data sets where they often contain fewer examples of diseased patients than healthy patients because it's much easier to acquire data for healthy patients than their disease counterparts. We also have selection bias at the data portion of the AI lifecycle think about Apple's series voice recognition algorithm this model is trained largely on Flawless American English but it's deployed across the real world to be able to recognize voices with accents from all over the world. These biases can be propagated towards models training Cycles themselves which is what we'll focus on in the second half of this lecture. I have a model that I trained on the past 20 years of data and then I deploy it into the real world in 2023 this model will probably do fine because the data input distribution is quite similar to data in the training distribution. What would happen to this model in 2033 it's it probably would not work as well because the distribution that the data is coming from would shift significantly across this decade. If we don't continue to update our models with this input stream of data we're going to have Obsolete and incorrect predictions. Commercial facial detection systems are everywhere you actually played around with some of them in lab two when you trained your vae on a facial detection data set. The biases in these models were only uncovered once an independent study actually constructed a data set that is specifically designed to uncover these sorts of biases by balancing across race and gender. There are other ways that data sets can be biased that we haven't yet talked about so so far we've assumed a pretty key assumption in our data set which is that the number of faces in ourData is the exact same as theNumber of non-faces in our Data set. accurate class boundary between the two classes so how can we mitigate this this is a really big problem and it's very common across a lot of different types of machine learning tasks and data sets. The first way that we can try to mitigate class imbalance is using sample re-weighting which is when instead of uniformly sampling from our data set we instead sample at a rate that is inversely proportional to the incidence of a class in the data set. The second way we can mitigate class and balance is through loss re-weightsing. to dbias a model so what we want is a way to learn the features of this data set and then automatically determine that samples with the highest feature bias and the samples with lowest feature bias we've already learned a method of doing this in the generative modeling lecture. Now we'll walk through step by step a de-biasing algorithm that automatically uses the latent features learned by a variational autoencoder to under sample and oversample from regions in our data set um before I start I want to point out that this debiasing model is actually the foundation of themis's work this work comes out of a paper that we published a few years ago. good representation of what a face actually is so now that we have our latent structure we can use it to calculate a distribution of the inputs across every latent variable and we can estimate a probability distribution depending on that's based on the features of every item in this data set. This allows us to train in a fair and unbiased manner to dig in a little bit more into the math behind how this resampling works this approach basically approximates the latent space via a joint histogram over the individual latent variables. data point x will be based on the latent space of X such that it is the inverse of the joint approximated distribution. As Alpha increases this probability will tend to the uniform distribution and if Alpha decreases we tend to de-bias more strongly. This gives us the final weight of the sample in our data set that we can calculate on the Fly and use it to adaptively resample while training. Once we apply these this debiasing we have pretty remarkable results. Keep this algorithm in mind because you're going to need it for the lab 3 competition which I'll talk more about towards the end of this. lecture so so far we've been focusing mainly on facial recognition systems and a couple of other systems as canonical examples of bias however bias is actually far more widespread in machine learning consider the example of autonomous driving many data sets are comprised mainly of cars driving down straight and sunny roads in really good weather conditions with very high visibility. In some specific cases you're going to face adverse weather bad um bad visibility near Collision scenarios and these are actually the samples that are the most important for the model to learn. an extremely famous paper a couple years ago showed that if you put terms that imply female or women into a large language model powered job search engine you're going to get roles such as artists or things in the humanities. If you help input similar things but of the male counterpart you'll end up with roles for scientists and engineers so this type of bias also occurs regardless of the task at hand for a specific model. Finally let's talk about Healthcare recommendation algorithms these recommendation algorithms tend to amplify racial biases. uses that UL will also be developing today and for the next part of the lecture we'll focus on uncertainty or when a model does not know the answer. We'll talk about why uncertainty is important and how we can estimate it and also the applications of uncertainty estimation. To start with what is uncertainty and why is it necessary to compute let's look at the following example this is a binary classifier that is trained on images of cats and dogs for every single input it will output a probability distribution over these two classes. Uncertainty estimation is useful for scenarios like this this is an example of a Tesla car driving behind a horse-drawn buggy which are very common in some parts of the United States. The exact same problem that resulted in that video has also resulted in numerous autonomous car crashes so let's go through why something like this might have happened. There are multiple different types of uncertainty in neural networks which may cause incidents like the ones that we just saw we'll go through a simple example that illustrates the two main type of uncertainty that we'll focus on. of a regression task the input here x is some real number and we want it to Output f of x which is should be ideally X cubed so right away you might notice that there are some issues in this data set assume the red points in this image are your training samples so the boxed area of this image shows data points in our data set where we have really high noise. If we queried the model for a prediction in this part of in this region of the data set we should not really expect to see an accurate result. names to the types of uncertainty that we just talked about the blue area or the area of high data uncertainty is known as aliatoric uncertainty. The green areas of this just the green boxes that we talked about which were Model uncertainty are known as epistemic uncertainty. This cannot be learned directly from the data however it can be reduced by adding more data into our systems into these regions okay so first let's go through alliatoric uncertainty so the goal of out estimating alliatorIC uncertainty is to learn a set of variances that correspond to the input. model we have the same output size that predicts a variance for every output so the reason why we do this is that we expect that areas in our data set with high data and certainty are going to have higher variance. The crucial thing to remember here is that this variance is not constant it depends on the value of x so now that we have this model we have an extra layer attached to it in addition to predicting y hat we also predict a sigma squared how do we train this model our current loss function does not take into account variance at any point. a data set called cityscapes and the inputs are RGB images of scenes the labels are pixel wise annotations of this entire image of which label every pixel belongs to and the outputs try to mimic the labels they're also predicted pixel wise masks. Why would we expect that this data set has high natural alliatoric uncertainty and which parts of this dataSet do you think would have aliatoric uncertainty? And that's exactly what we see if you train a model to predict aliatoic uncertainty. Even if your pixels are like one row off or one column off that introduces noise into the model the model can still learn in the face of this noise. very little variance in the um the logits or the outputs that we're predicting. However if a model has never seen a specific input before or that input is very hard to learn all of these models should predict slightly different answers and the variance of them should be higher than if they were predicting a similar input so creating an ensemble of networks is quite similar it's quite simple you start out with defining the number of ensembles you want and then you fit them all on the same training data and training data. epistemic uncertainty so both of the methods we talked about just now involve sampling and sampling is expensive ensembling is very expensive but even if you have a pretty large model um having or introducing Dropout layers and calling 24 word passes might also be something that's pretty infeasible. At Themis we're dedicated to developing Innovative methods of estimating epistemic uncertainty that don't rely on things like sampling so that they're more generalizable and they're usable by more Industries and people. training The Ensemble and calling multiple ensembles on the same input we received multiple predictions and we calculated that variance. We've gone through two major challenges for robust steep learning we've talked about bias which is what happens when models are skewed by sensitive feature inputs and uncertainty which is when we can measure a level of confidence of a certain model. We'll talk about how themus uses these Concepts to build products that transform models to make them more risk aware and how we're changing the AI landscape in terms of safe and trustworthy AI. i's product called capsa which is a model agnostic framework for risk estimation so capsa is an open source Library you all will actually use it in your lab today. It transforms models so that they're risk aware so this is a typical training pipeline you've seen this many times in the course by now we have our data we have the model and it's fed into the training algorithm and we get a trained model at the end that outputs a prediction for every input. With capsa what we can do is by adding a single line into any training workflow we can turn this model into a risk-aware variant that essentially calculates biases uncertainty and label noise. then further analyze and so this is the one line that I've been talking about um after you build your model you can just create a wrapper or you can call a wrapper that capsa has a an extensive library of. Capsa wraps models for every uncertainty metric that we want to estimate we can apply and create the minimal model modifications as necessary while preserving the initial architecture and predictive capabilities. This could be adding a new layer in the case of a variational autoencoder this could be creating and training the decoder and calculating the Reconstruction loss on the Fly. Themis is unlocking the key to deploy deep learning models safely across fields. We can now answer a lot of the questions that the headlines were raising earlier which is when should a human take control of an autonomous vehicle. What types of data are underrepresented in commercial autonomous driving pipelines. We now have educated answers to these questions due to products that Themis is developing and in spheres such as medicine and health care we can now answers questions such as when is a model uncertain about a life-threatening diagnosis. compete in the competition which the details are described in the lab but basically it's about analyzing this data set creating risk-aware models that mitigate bias and uncertainty in the specific training pipeline. At Themis our goal is to design advance and deploy a trustworthy AI across Industries and around the world. We're hiring for the upcoming summer and for full-time roles so if you're interested please send an email to careers themesai.io or apply by submitting your resume to the Deep learning resume drop and we'll see those resumes and get back to you.

ROUGE-1: 46.24, ROUGE-2: 44.96, ROUGE-L: 46.09
BERTScore: 67.10

==============================================
==================== [55/100] ====================
Summary:
HONG LIU: So at the end of last lecture, so we discussed this LSZ theorem, which tells you how to obtain scattering amplitude from correlation functions. OK, so if you want to compute, say, some scattering. amplitude from alpha to beta-- so alpha's some initial state and beta's some final state. Say alpha consists of momentum p1 and PN-- or pm, and beta, say momentum p m plus 1 and pn. And then you can get this scattering amplitude just by taking your momentum-space correlation function for the n points. HONG LIU: So for each external momentum-- so here there's a propagator, and just as if that-- when you get-- so this scattering amplitude was corresponding to this one with all external propagators stripped. OK, so that's why you consider the truncated diagram not including the external propagator. And you take it on shell.correlation functions, OK, and then you sum over-- youSum over, say, the truncate-- so you see the relation between these correlation functions and the scattering amplitudes. So they differ by this product. I will explain a few things. OK, so remember this Gn, so let's go back to the definition of this Gn. These momentum-space correlation functions. So this is obtained by doing a Fourier transform. Say-- I think it would be minus sign. So then you want those phi corresponding to the initial state to act on the right. And so this, if you just record the mode expansion, can be written as the following: phi x1 andphi xn. for phi and the phi contains a and a dagger-- and the a pieces acting on the zero will just give you zero, so only a dagger piece will survive. So when phi x acting on zero, you keep the part which is corresponding to the a dagger, and then you get a piece proportional like this. And then when you do the Fourier transform, then here it gives p equal to k. OK, so that's why in the final state, you just have pequal to k and then p0 is equal to just omega k. HONG LIU: To derive that theorem, the time-order matters. OK, you can do this for the full interacting theory. Yeah, just use the free scalar as the-- yeah, because when you go to plus or minus infinity,you can just reduce to the free particles. OK. Other questions? OK, good. So this is the first comment. The second comment, each side, we need to here-- from here, weneed to truncate the external propagator. propagators, so that means you also throw away diagrams like this. You can consider arbitrary, complicated diagram, OK, as far as that only happens-- yeah. So such kind of diagrams, they only change the external propagator, but since we truncate the external propagateator, and then they don't matter at all, OK? So the reason is the following. All this diagram do is just modify the properties of the external. propagator. And the only way all these diagrams can modify the. external propagators is to give you an overall constant. truncated them, and so you don't need to worry about them. So Z also has an expansion, just 1 plus order Lambda, et cetera, so the leading order, so Z does not contribute. OK, you can just set it to 1, and when you go to the higher order, then the Z can make a contribution. OK. So you just need to separately take into account the Z, and there's no need to contribute-- to calculate those things separately. HONG LIU: Z is the same for different processes, but it's different for different particles. Z is a constant for all of them, yeah. If it depended on momentum, then it would be kind of useless, right? So we will not go into details of the Z. And that is what is called the "Z" principle. It is the principle that all such things don't change the momentum. OK, the momentum don't changed. Yeah.things, they-- yeah, all these things, essentially, they just modify the-- give you the correction to the external propagator and include it in that constant Z. HONG LIU: This is the self-interact-- yeah, just when the-- when you have an interacting theory, so the particle can interact with itself. It just all comes from this kind of diagram. You can have single particle, and you can have such a diagram like this and all these diagrams. Correspondingly, you have a particle propagating, but that particle can interacts with the virtual particle, its own virtual particle. OK, and so that, this is the rule corresponding to the particle loop. kind of interaction, will affect the property of the propagation but can have the most effect by prefactor, but actually can change the mass, too. But for the-- oh, it can correct for the mass-- and also, that's the subject of the QFT2. I think at most canchange the overall factor by z. Other questions? Good. If you don't have other questions, so let's conclude our discussion of chapter 3 on interacting theories. OK, and now let's discuss how to describe fermions. The Dirac equation is one of the most beautiful equations in mathematical physics. It's actually describing electrons, so it's not only beautiful, but it's actually useful. The Dirac theory is a prime example of how people make great discoveries often for the wrong motivations. But the key is that if you are good enough, you will find something new and that something new will be useful. We'll talk about fermions in the next section of the lecture. We're going to talk about the Dirac equations and its covariance. go to a different frame. OK, yeah, that's what we mean by-- just when you go to a. different Lorentz frame, the equation, the form of the equation looks the same. Just different observers in different laboratory, they see the same equation. OK. So for this to be LorentZ covariant, remember, Lorentzi transformation transform t to x, so immediately, you conclude that H must be first-order in spatial derivatives. So the only-- then the most general way you can write it is alpha minus i, and then you can at most add the constant. purely imaginative, OK, just nothing like this before. Like when Einstein wrote down his theory, et cetera, you can still trace-- there some clues, OK. But when Dirac-- this one just really-- [LAUGHTER] --like music, just came out from his mind, OK? It just-- and then he reasoned, OK,. OK, if this is constant which does not work, and then let's make alpha and beta to be matrices. Take them-- OK, so let's say they are n-by-n matrices, then in order for that equation to make sense, then psi has to be a n- component vector. They're just some constant Hermitian matrices. And then, so then he reasoned that for this equation, if we want this equation to be Lorentz covariant, then at least it should have the relativistic plane wave as its solution. If it does not even have that type of solution, then you, yeah, of course cannot be covariant. OK, so the minimal requirement-- so before we really try to see how can we make this into a covariant equation, we say let's consider minimal requirement. The Klein-Gordon equation has the following form. So when we square this star, we just act twice, so essentially, you have-- so you have partial partial t square psi equal to H square psi. OK, and then we try to make this of this Klein- Gordon form. If that works, then we're guaranteed to have a plane-wave solution of such a dispersion relation because this equation has such solutions. OK? So this will be satisfied-- can be satisfied if square of star, OK, satisfies reduced to the Klein-Graham equation. with that kind of dispersion relation. So now we just compare the both sides, so for this to be true, so we just need to have-- so let's compare the second-order derivative term. And then we need alpha i. So we need-- first, when i not equal to j, the off-diagonal terms, they all should vanish, OK, because here there's only diagonal terms. So that means that the alpha i alpha j plus alpha j alpha i should equal to 0. We said the alpha and the beta, they must be Hermitian, so that means that the alpha i dagger is equal to alpha i and thebeta dagger equal to beta. So if we satisfy all these four conditions, and then we will guarantee that that equation star should have the plane-wave solution. And so now you just try to find matrices, satisfy those conditions. OK, you actually find the infinite number of solutions. So you see that to satisfy them needs at least a 4-by-4 matrix, so n has to be 4. HONG LIU: Alpha is a 4-by-4 matrix. Alpha acts on different components of psi, and this just acts on-- the derivative acts on all components of psi. Each element of alpha is a matrix, and each component is aMatrix. HONG LIu: Just, if you have alpha 1, alpha 2, alpha 3, so here you see explicitly, alpha 1 is equal to sigma 1, sigma 2, 1, 0, minus sigma i. you'd get an equation like this. So now I will denote-- introduce a new notation so that it looks nicer. I'll denote the gamma 0 equal to i beta and then the gamma iequal to i times beta alpha i. And then let's all pull it to the same side, and then this becomes the following equation, then the equation has the following form, gamma mu partial mu minus m psi equal to 0. OK, so this is a little bit intricate equation, but once you get used to it, it's not that difficult. not symmetric, so it's easier to put one upstairs, one downstairs. Yeah, these two indices are not symmetric. So yeah, it takes a little bit time to get used to it, OK, and I know some people develop psychological fears for fermions because you have to deal with those gamma matrices. For a long while, actually, I have this psychological fear myself. [LAUGHTER] When I look at fermion, I want to be away from it because I don't want toDeal with those Gamma Matrices. HONG LIU: All the gamma matrices, so you can check yourself, OK, all these are given by just this. And so this equation, when the later mathematicians, of course, studied this, a mathematician would say this is a beautiful object. So this object is called Clifford algebra. From those solutions of beta and alpha, we can write down different solutions of gamma. So for example, for 1, you're corresponding to gamma 0 equal to minus i. So now this is minus i times a 2-by-2 matrix, OK. HONG LIU: So this is a new space, and so that's called-- this is called spinor space, yeah. Yes? AUDIENCE: How do we know that-- are these the only two representations? HONG LIu: There are infinite number of them. We will talk about that. OK? Good? So now let me make some remarks. Yeah, so first, if you consider the case m equal to 0, and then this is, like, for massless, so when mequal to zero, then when you reduce to this Klein-Gordon equation. same story just here, you just forget about beta. OK, the same story, you forget the beta, and then you only need alpha i alpha j the commutator to be 0 for i not equal to j, essentially just that equation 1 there. And then also, you'd want the alpha i square equal to 1, OK, so for any i. So now these are the conditions for the alphas, and now you can actually satisfy by 2-by-2 matrices. they are all just complex. So this actually tells you that actually the massive particle have more degrees of freedom than the massless particle. And then the second thing is what Dirac essentially was-- Dirac's original motivation. So from Dirac equation, you can show you can derive a current. Just as you can do for the Schrodinger equation. You can derive an equation like this for some j mu and with j 0, with the 0-th component of this thing, positive definite. the meaning of all these different solutions for alpha and beta or for gammas, OK? So as I mentioned, you can have infinite number of solutions. What's the meaning of them? So first, let's imagine when we look at this equation-- so as I said, this is a matrix equation. In this matrix equation, then you have this psi which is a four- component vector. So now if we make a basis change in this four-component vector, OK, so imagine, just say, consider making a basischange in psi. actually in the-- opposite regime, it's convenient for the ultrarelativistic regime. OK, so it depends on which regime, sometimes you use different gamma matrices. So now having introduced the Dirac equation and then the structure of theDirac equation, but still we haven't showed that the DirAC equation is covariant. So we, of course, won't have time to do that today, but let me just remind you how this Lorentz covariance works for the scalar case. Consider such a Lorentz transformation, OK, so and then phi transforms as following, phi prime x prime phiprime. New phi evaluated at the new position should be the same as phi evaluation at the old position. So the phi-- yeah, just equal to phi lambda minus 1 x. So now if you look at the Klein-Gordon equation, let's see how this is covariant, OK? OK, it's the same in any frame. to show, OK, so now we want to show that the Dirac equation has the same property, OK. OK, that's much more nontrivial. Again, it's really ingenious, ingenious, yeah, but we see, actually, it works.OK, so we will do it next time. Next time, we will show you how to do the same thing in a different way. We will do that in a few minutes. We are going to take a break. We're going to have a drink.

ROUGE-1: 42.54, ROUGE-2: 40.67, ROUGE-L: 39.47
BERTScore: 74.18

==============================================
==================== [56/100] ====================
Summary:
There's no age, education, profession, or even native-born citizenship requirement. Most presidents nominate individuals who broadly share their ideological view. So far, six justices have been foreign-born. At least one never graduated from high school, and another was only 32 years old when he joined the bench. For example, when President Eisenhower, a Republican, nominated Earl Warren for Chief Justice, Eisenhower expected him to make conservative decisions. Instead, he chose to appoint him to the Supreme Court. After the president interviews the candidate and makes a formal nomination announcement, the Senate leadership traditionally turns the nomination over to hearings. Depending on the contentiousness of the choice, that can stretch over many days. The Judiciary Committee votes to send the nomination to the full Senate with a positive or negative recommendation, often reflective of political leanings. Most rejections have happened when the Senate majority has been a different political party than the president. When the Senate does vote on the nomination, it usually takes 60 days. approve, it's by a simple majority vote, with ties broken by the vice president. With the Senate's consent, the president issues a written appointment, allowing the nominee to complete the final steps to take the constitutional and judicial oaths. In doing so, they solemnly swear to administer justice without respect to persons and do equal right to the poor and the rich. This job is for life, barring resignation, retirement, or removal from the court by impeachment. Of the 112 justices who have held the position, not one has yet been removed from office as a result of an impeachment. to be debated and dissected by the ultimate judges, time and history. To be debated, dissected and debated, we need to look to the past, present and future. We need to see how far we have come and what we can learn from the past. We also need to learn from our mistakes and learn from each other. We want to be the best we can be, and we want to do it in a way that honors the past and the present. We hope you will join us in this quest.

ROUGE-1: 64.37, ROUGE-2: 53.55, ROUGE-L: 52.83
BERTScore: 70.18

==============================================
==================== [57/100] ====================
Summary:
Jake Xia: This is the second time we are having this class. We had it last year in a smaller version. That was for six units of a credit, and we had it once a week. And mostly practitioners from the industry, from Morgan Stanley, talking about examples how math is applied in modern finance. And so we got some good response last year. So, with the support of the math department, we decided to expand this class to be 12 units of credit and have twice a week, as you know. WebEx.is has added math lectures focusing on linear algebra, probability to statistics, and some stochastic calculus. The purpose of this course is to give you a sampling menu to see how mathematics is applied in modern finance. Last year when we finished the class, we had a few students coming to work in the industry. Some work at Morgan Stanley, some work at elsewhere. So it's open door. You're very welcome to attend the classes here. And at the same time, obviously, you will further solidify your math knowledge and learn new content. and the Sloan school here. So anyway, thanks for that. We will be doing a bit more polling along the way, mainly to get feedback of how you feel about the class. Last year we had it online, so if you feel the class is going too fast, or the math part is. going too slow or the finance part is a bit confusing, the easiest way is really just to send us. emails, which you will find from the class website. So Anyway, I will start today's lecture with a story, and a quiz at the end. Don't worry, it's not a real quiz. Just going to ask you some questions you can raise your hand and give your answer. my personal story. I want to tell you why I tell the story later. But the story actually was in the mid '90s. I just left Salomon Brothers -- that was my first financial industry job -- to go to Morgan Stanley in New York. So the first day, I sat down, I opened the trading book, I found something was missing. So, I turned around, I asked my desk quant. I said, where is the vega report? So, let me show you. Volatility is a measurement about a book or portfolio or position's sensitivity to volatility. At Morgan Stanley this is not called vega, it's called kappa. Kappa is actually a Greek letter. So the footnote about why it's kappa is on the same page as the explanation of what volatility is. That's all you need to know right now. I'm not going to ask you questions later. So, what is volatility? Which again, you will learn more in rigorous terms how it's defined in mathematics. called kappa at Morgan Stanley. Kappa is also called vega by some uneducated traders at the Salomon Brothers. They have mistaken vega as a Greek letter after gambling at Vegas. So obviously, I learned how to call kappa very quickly. And I called it kappa in the last 17 years, but you will hear people calling it vega. But anyway, so that's my first day atMorgan Stanley. But why did I tell you the story? What point I try to make? So this story is actually-- when you think about it, mathematical or quantitative finance is a rather new field. from mostly under-educated traders. Some of them typically joined the firms in the mail room and became trader later on. That's typical career path. And to nowadays, if you walk on the trading floor, you talk to the traders, most of them have advanced degrees. So what has changed over the last 20 or 30 years? I myself, personally, was probably one of the data point experiencing this change. And I certainly didn't expect I would be doing this when I was at MIT, but I did that in last 20 years. everything are changing very rapidly. Even nowadays, they're still changing. So with that, I will give you some background on how the financial markets actually started, and that's really the history part of this industry. In early days people need to exchange goods, so there's exchanges. Then it becomes centralized. There are stock exchanges, futures exchanges all over the world where these products will be listed as securities. That's one way of trading, which is centralized. Obviously, in the last 10, 15 years, now we have ECNs, electronic platforms. Trade over-- you know, even larger volume of those trades. has money to lend out, someone needs to borrow money. Loan is really a private agreement between two counterparties or multiple counterparties. Commodities, actually, you know. Metal, energy, agriculture products are traded, mostly in the futures format. When you actually buying and sell, you build a warehouse to take them. You ship a tank to store above the ocean. And the real estate, you're buying and selling houses. And when you look at bonds, every government will issue large sovereign debt. Before 2008 financial crisis, large amount of CMBS-- basically, it's a commercial real estate backed securities, mortgage securities, and the residential, as well. And further of all of these, you heard probably a lot about the derivative products. So, that started with swaps, options. And the structure of the products, it become more tailor-made for either investors or borrowers to structure the products in a way to suit their needs. And some of the complexity of those structured products become quite high and the mathematics involved in pricing them and the risk management become rather challenging. After 1933 Glass-Steagall legislation, there were two main types of banks. Commercial bank is supposedly, you're taking deposits and lend out the money. Investment bank supposed to focus on the capital markets, raising capital, trading, and asset management. So that's how banks are organized. Outside banks, other players, basically, the asset managers, are obviously a very big force in the financial markets. So the really bank.type of player is really the investment bank. The investment bank is the player that is really bank-like. question a lot of people ask is, is this a zero sum game? I'm sure you've heard this many times. A lot of times, it depends on the specific products you trade, the market you're in. But why do we need financial markets? This comes back to what I described before. There's a need for it. It's really the need to bridge between the lenders and the borrowers. So, investors who have money need to have better yield or better return, better interest. Banks and so-called dealers play the role of market making. What is market making? So, when you or some end user wants to buy or sell, typically, if there's no market, you don't really find the match. And so the trade between lenders and the borrowers, is again, essentially the main driver of the financial markets. The dealers step in the middle, make you a price. Say, this stock, I make you price. $0.99, and that's my bid. brokers. So, brokers don't really take principal risks. Mutual funds, who actually manage public investors' money, typically in the long-only format. Insurance companies has large asset. They need to generate a return, generate cash flow to meet their liability needs. And the pension funds, same thing. As inflation goes higher, they need to pay out more to the retirees, so where do you get the return? Sovereign wealth fund, similarly, endowment funds-- they all have this same situation, have capital and needs to deploy. have some exposure. Let's say you borrow money, you bought a house, so you have mortgage payments. Or your corporate has a large income coming from Europe. So, you have euros coming in, but you're not sure if euro would trade stronger to the US dollar in the future, or trade weaker. If you think it will be stronger, you just leave it. But if it will trade weaker, you may want to hedge it. And so that's the hedging type. The second type, as I mentioned, is a market maker. In the new regulation, obviously, proprietary trading is banned, right? And so the third type is really the proprietary trader, the risk taker. These are the hedge funds or some portfolio managers. They need to focus on generating return and control the risk. So, that's where the beta and alpha, the concept comes in. matched the S&P 500 index fund, R(b). That's a return of that index. So you can find a correlation between those two time series. say, this actually-- somehow it came out. It's supposed to be alpha and beta, but it turned out to be the letters. So, in a short description, beta is really-- just think as correlated move with the other asset. Alpha is really the difference in the return. You want to beat S&P 500, so you want to basically have certain tracking of this index, but you Want to return more on top of that. So let me just go in bit of details of how each type of trade actually occurs. So, you invest in the Australia Ozzie, Australian dollar. The Australian dollar may become weaker to the yen. You may lose all your profit, or even more. And further, if everybody plays the same game, then when you try to exit, you have the adverse impact of your trade. So, let's say you think that's the right time to do it, but then at one time, you wake up, you said, huh, I think too many people are doing this. I want to hedge myself. Even if you are not a finance guy, you work in a corporate, you just do you import, export, or building a factory, you have to know, actually, what the exposure is. Risk management, nowadays, becomes pretty widespread responsibility. It's not just the corporate treasury's responsibility. So, that's on the hedging side. If you're entering in a merger deal, and one company is buying another, you need to hedge your potential currency exposure and your interest rate exposure. stock, I think a lot of people know pretty much where it is. But if it's not transparent, so what do you do? So, if instead of asking you where Apple is, probably you're going to tell me $495 today. So you're probably less transparent. So that market maker comes in to provide that liquidity, and then takes the risk. They manage the book by balancing those Greeks, which I mentioned earlier. That's called delta. Gamma is really the change of the portfolio. Take the derivative to the delta, or to the underlying spot. "VaR" concept is also, obviously, a very important concept. And we talk about the volatility exposure was vega. And on top of that, what are the tail risks? What are the events that can actually get you into big trouble? So people use value at risk. Then capital. How much capital are you using? It becomes a veryimportant issue nowadays. And balance sheet. You have asset, you have liability. How do you leverage? How much leverage you have? Before the crisis, for example, lot of the banks leverage up 40 times. Trading is about finding relationships between prices, and trying to profit from those relationship mispricing. Not many people focus on arbitrage, because lot of people are gut traders. If you trade gold in the States, the gold price happen in Asia and in Europe matters, right, because you're trading the same thing. And that's just a simple example. But a spot price versus forward price, that's a deterministic relationship. It's a mathematical relationship. If that relationship breaks down, you can also profit. So there are many examples mathematical relationship which gives you the arbitrage opportunity. Math is very effective, because when you, your bank, your corporate, you want to buy some financial instruments, you have to know where is the price. So, pricing model, which Vasily and many of his colleagues can tell you more. Risk management itself is very challenging. It's not a purely mathematical question, but yet, math plays a very important role to quantify how much exposure you have. Then, I think a lot of people with math background, or in general, people are looking for the so-called holy grail trading strategies. You just turn it on. It makes money by itself. come back, you'll have more in your bank account. Obviously, that's not going to happen. The robotrader, a robotic trader, is a dream. It has its place or its use, but it's a fast evolving market. You have to constantly either upgrade your research and adjust your strategies. There's no such thing you can build and leave it alone. But I just want to mention that because maybe towards the end of the term you will feel, hmm, I came up with this brilliant trading strategy. I think it's going to make money forever. facing two choices, choice A and a choice B. Choice A being you have 80 chance to lose $500. You have 20% chance to win $500, right? That's choice A. Or choice B, you basically just lock in you have 100% chance of losing $280. Let me ask you, for whoever likes to choose choice A, please raise your hand. One, two, three, four. About six out of say, let's call it 50. So, can I ask you why you think choice A makes sense? When the stock goes up, makes bit of money, the natural tendency -- for especially someone is new to the market -- is to let's take profit. Trading is really all about how do you risk manage, have the discipline, and how to manage your losses. The natural tendency of a lot of people is, well, I think there's a 20% chance to come back, and I'm going to make $500 more. Why do I want to lock in to stop myself out at 280? So even if you have the Discipline to get out, that's great. though the expected value-- I think lot of people said, you lose expected value, which is $300 in choice A, but you would still not to choose choice B, because you don't want to lock in the $280 loss. So, that's really the common behavior, which mathematically may not make sense, but lot ofPeople still would like to do. And also, really, when you think about it, depends on your situation. And let's say, you think the market-- I'm giving you the stock example again. If you just think the fundamental picture has changed. You really don't think the stock should go up anymore. A lot of people don't really want to choose choice B, because they don't want to lock in the loss. The answer, I think it can go you either way, as you said. I mean, the last day of the class, hopefully we'll have much deeper discussion on this. It's not unique. I think we can talk a bit more along in the class. Yup. Well, let me just leave it here. Anyone want to give me a reason for choice B? AUDIENCE: Higher Sharpe. your bank account balance is-- let's say you are a freshman student. Your choice will be very different from someone has $100,000 in his bank account. And also, your risk tolerance, how much you can tolerate. I'm not going to give you say, this is right or wrong. But with that, let me move on and give you some homework. So, before I give you the homework, I want to make a few more comments. Do people always learn from their experiences? In science, we collect evidence, we build models. try to trade on those, how do you really build models? Is the market really efficient? What part is efficient? How do you apply those theories in your day-to-day risk management or trading activities? And sometimes, people tend to oversimplify. So learn the math, learn the finance first, but keep those questions along the way when you are learning during this class. So suggested homework, optional. Go to the course website, read what we have put up for the financial glossary. we got maybe-- how about this? We still got about 15 minutes or 12 minutes left, so I'll pass it to Vasily, then maybe we can leave five minutes for some questions. VASILY STRELA: [INAUDIBLE] mentioned that, Apple trades, that now it's $494.4 Yeah, just a couple of [INAudIBLE]. Well, first of all, no offense to people who were [INA UDIBLE], but I just wanted to give an example. every time. So, if you want to differentiate this functions and get a derivative, then this derivative will be quite noisy. And so, instead of getting the true derivative, you might obtain something quite different from true derivative just because there is a confidence interval around any point. So obviously, there is somewhere balance, and the question was, is there an optimal shift size to get the derivative? And that's what-- uh oh, the slide got corrupted. There was an answer. optimal size, that would be your numerical derivative of this blue function. While if you use an optimal shift size, which [INAUDIBLE] computed, it would be much smoother and much better. So, that's one of example, and that's what he did. And we actually are implementing it in our systems and plan to use it in practice. Another project was actually quite different. And it was about electronic trading and basically how to better predict prices of currencies and exchange rate. We put syllabus there, a short list of literature. We will be posting a lot of materials there. Probably most lectures will be published there. Jake's slides are there already. So, any questions? We like to get your emails so we can put you on the website for further announcements. But it's probably easier if you put your email on the sign up sheet, so that we can [INAUDIBLE]. VASILY STRELA: Yeah, but please visit and sign up here, because there will be announcements to the class.

ROUGE-1: 56.26, ROUGE-2: 53.99, ROUGE-L: 53.24
BERTScore: 68.71

==============================================
==================== [58/100] ====================
Summary:
Scientists are warning we are on course for devastating changes to our climate. Researchers are now starting to understand that it's also already affecting our mental health. In the UK one in four adults and one in 10 children experience mental illness. The UK Met Office has issued its first ever red warning for extreme heat after the 2022 heat wave in the UK Charles and a team of researchers set out to study how the extreme heat affected people's well-being. Over half of the the people they spoke to experienced negative impacts on their mental health due to the heat. Clayton has interviewed numerous doctors and scientists who are looking at how the changing environment is affecting our minds brains and bodies. You don't even need to be alive to experience some of these effects a study of expecting mothers who experienced Hurricane Sandy in 2012 the huge storm that hit New York showed that in unborn children who did experience that storm girls as early as preschool were 20 times as likely to experience anxiety and boys were 60 times more likely to express some kind of ADHD. Charles's research also saw the heat affecting men and women differently often due to societal factors such as traditional gender roles. people in that storm showed that about half of these folks had some kind of post-traumatic stress and that's relative to 5% of the general population. Direct effects of climate change on people's mental health there's also knock on effects like loss of income and Rising prices which inevitably have implications for people's well-being. Although the impact of a changing climate on our mental health can be profound both Clayton and Charles's Rec search has shown that there are things you can do to support your wellbeing engaging with nature so spending more time in Green Space. people use that as a way to cope with stress so this is very beneficial social connection is a really big one as well. We are not separate from our environment we are connected not just to the world around us but of course to one another and it and it is only in working with one another that we're going to be able to move forward [Music]"It's a very exciting time for us. We're looking forward to it," says singer-songwriter. "It's going to give us a lot of energy. It's a really exciting time"

ROUGE-1: 54.33, ROUGE-2: 50.33, ROUGE-L: 50.52
BERTScore: 65.39

==============================================
==================== [59/100] ====================
Summary:
Adam Martin: How do you go from something you're interested in learning about an organism to actually identifying genes and mechanisms that are important for that? At the end, I'm going to tell you how you can try to figure out the genes and mechanism that are involved in determining the behavior of an organism. And on my title slide here, I have three fruit fly mutant phenotypes that you can see, and each of them is a different type of gene. And each one has a different effect on the behavior. of these mutants defined genes that were subsequently found to be present-- or homologous genes were present in humans and were shown to play important roles in human biology. So later on in the lecture, hall kind of explain what each of these phenotypes is. But first, I want to just highlight the importance of model organisms and their use in biology. You've been seeing them already. I've talked a bit about flies, we talked about Mendel's pea plants. I just now have a compendium of model organism that I'm going to throw up to tell you about. The roundworm, Caenorhabditis elegans, and the fruit fly, Drosophila melanogaster, are the heroes of today's lecture. The mouse is our lab mascot, but it's also an important genetic model. Human cell lines are important, but you have to understand that they're sort of an in-vitro system, and they're not functioning in the context of an entire organism. So it's really unethical for us to do a lot of different types of experiments on humans. Genetic approaches are as fundamental to biology as math is to physics, says Drosophila genetics professor. "Geneticists are going to break genes and then look at the result and see if it gives the phenotype we're interested in," he says. "In a forward genetic screen, you're looking for a phenotype that you would expect if you affected a certain process, if you disrupt a process," he adds. "So the goal in genetics is to identify a mutation that alters a gene function that gives you a phenotype" induce mutations. So we're looking for mutations. And these mutations could be spontaneous mutations, meaning you didn't do anything to induce it, but they just appear as a variant in the population. In the way we can induce mutations is by using some type of mutagen. For example, you could have some sort of chemical mutagen that increases the error rate in DNA replication. Or you could use radiation to induce DNA damage, and that essentially accelerates the frequency of mutations that occur in the genome of an organism. In model organisms, we can actually find these types of mutations. There's a specific class of mutant that was called "wingless"-- where the flies have fewer than two wings. This particular mutant defines an entire signaling pathway, which is important in stem-cell biology and is also over activated in cancer. But obviously, we don't have wings, so this gene didn't get discovered in humans. It was discovered in flies, and then only later on, it was inferred-- or it was discovered that there was a gene for wingless. is a related gene in humans. One of the other phenotypes I showed you is called "notch" Normally, a fly wing has a nice, smooth margin. notch mutants have wings that have this chunk taken out of them at the end. But again, there's a human notch, and human notch is involved in human diseases, such as cancer.. How can you have a concerted effort to identify genes that have that function in a given process? I'm going to tell you about work done by Eric Wieschaus and Christiane Nusslein-Volhard. treated the males with a mutagen to induce mutations in the gametes these male flies would then be passed to subsequent generations. They mated the mutagenized males to females, and then they went on to look at-- to isolate individual F1 progeny. In order to look for organisms that have incorrect body patterning, you need to get a situation where each of the mutated chromosomes is homozygous recessive, and to do that, you have to do more crosses. Drosophila larvae looks like. And you can see it has a segmental pattern here. But you see there are these segments that alternate between smooth cuticle and hairy cuticle. And because there's a lot of hairlike projections here, it reminded the researchers of a hedgehog, and so this mutant became known as "hedgehog" And the hedgehog gene was the founding member of an entire signaling pathway. That plays important roles in human development and also, human cancer. the sonic-hedgehog gene is important in cancer. And actually, there are now a number of drugs that are being developed to target the hedgehog pathway. One was approved back in 2012 for use in treating basal-cell carcinoma. There's currently another drug that's in phase-II clinical trials for treating some forms of leukemia. So this is a story that goes from identifying this weird fly mutant all the way to clinical trials, developing drugs, whose purpose is to inhibit this signaling pathway. whether or not a cell lives or dies during development. One fate that Horvitz, Sulston, and Brenner saw is that sometimes, cells-- their fate was to just die. And this was defined as "programmed cell death" Because it followed a very stereotypic pattern, where the same cell, each time, would undergo cell death, so it seems like there's a program for it. This also is called "apoptosis." So what really enabled this work is the biology of C. elegans. Robert Horvitz's lab identified a pathway of genes that were involved in cell death. They identified a mutation that affected cell death that specifically blocked this engulfment process. They then mutagenized these ced-1 mutants. And what you see in this worm are these bubble-like structures that are cells that are dead but haven't been engulfed. So these dead cells, because they're not engulfed, are visible in the adult worm. And so they identified a mutant, and thus, a gene that causes "3," which is basically a double mutant. would lose these sort of bubble-like structures? What else could be happening? When you do a screen like this, and when you do science in general, you have to think through all the different types of possibilities. How would you differentiate between these two? Any ideas? Should this have an extra cell? No. Stevens says no. There should be no extra cell here. But if this is a bona-fide cell-death mutant, then you should have extra cells. And it turns out the ced-3 mutant blocks all 131 of these cell deaths. So there's an active mechanism involved in the cell death. Adam Martin: circadian rhythm is a behavior. We are awake during certain parts of the day and are asleep at night. If you're hidden from the light-dark cycle, you continue this cycle for some amount of time. Martin: There's something intrinsic in our system such that we want to exist on this 24-hour wake-sleep cycle. He says a genetic screen can identify genes that are important for circadian rhythm. The Nobel Prize-winning work was done by Konopka and Benzer. you need an X chromosome and you can't have three X chromosomes. But your females are all attached XY. So the females actually get their X chromosomes from their mom, which is the opposite of the way it normally works. And males getting their X chromosome from dad because the attached X strain has a Y chromosome. So it's a little bit of a genetic trick that, in this case, served the researchers a generation on their screen. But to establish a line of flies that have this mutation, they then took these. F1 mutated males, and crossed them, again, to attached X flies. So now, you have multiple males, all of which are mutant. The mutants that the Benzer Lab identified had altered period of the sleep-wake cycle, and therefore, the gene was named "period" So this screen identified a gene called "period." This is a gene. And the gene in humans is associated with familial advanced sleep-phase syndrome. So defects in the genes that were identified in Drosophila are relevant to human sleep disorders.

ROUGE-1: 38.03, ROUGE-2: 36.12, ROUGE-L: 35.84
BERTScore: 72.35

==============================================
==================== [60/100] ====================
Summary:
In this chapter we will discuss two applications, one price control and second taxation, so right. Sir, does this slope of this graph denote anything price demand upon, some price upon some quantity? So, wait little later we will talk about that that topic, right now we are just talking about movement and shifts, the direction of movement. We are not talking about the slope. So, what is price control what do we mean by price control? Price control is how we can regulate the prices of the goods in the market. In India we have pagadi system and it is more prevalent in Bombay because in Bombay, we have more we have stringent rent control laws. Pagadi is something that security deposit that land the house owner or the apartment owners they take from the person who would like to rent their house. So, to compensate they charge pagadi in name of security fee and this is in a way when they say that it is a security fee it is not illegal. Now, we can also think about the black market, the rise of black market or in other word illegal trade at prohibited prices. Yes, sir we do have agents like who supply. I am not trying to say that they do they provide us they of course, provide us a service. The idea here is not to defend them, but to explain why it is happening and then what we have is some kind of tie-in deals. Then tie in deals is many people would like to have gas connection. And that is also quite common. You are not interested in buying gas burner at really at the price which is much higher. than the price that you will you have to pay in the market for a gas burner. So, this is the tie in deals, it is not that you are buying the gas burner here. Similarly, when you go for apartments in Bombay, the apartment owner may say rent is this much. You have to take the furniture that I have put in the house, you also have to rent the refrigerator. These are tie-in deals that is what you get. I am not defending their position that they do a right or legal thing. Let us look at what happens when we have a price floor. Of course, you will have excess supply and also you'll have non-market rationing. Can you give me one example of non- market rationing mechanism in case of excess supply of wheat because of price floor? Sir, like the payment is not done at the time of buy, it is done after year or after few months. That can be one, again it is very difficult to discern it because of some other reason. And one more thing we have to pay a minimum wage to the laborers. That is stretching too far. very very, they wait long period to sell their product or when they go to the government unit to sale their product there is a long queue. So, long waiting period is there for offloading their products. What else, illegal market; you will have to pay bribe, illegal trade instead of writing market illegal trade to offload your wheat at government units. We do not have a proper distribution system by which we can distribute like some people with like below poverty line people, they are dying because of hunger, and we are throwing a lot of grains as surplus.

ROUGE-1: 31.33, ROUGE-2: 30.07, ROUGE-L: 30.54
BERTScore: 68.22

==============================================
==================== [61/100] ====================
Summary:
In order to make proteins like hemoglobin and antibodies-- these are made up of amino acids-- we need large entities. And so the things that will feature today are the transfer RNAs and the ribosome. And I want you to look at the size of this molecular machine. This is we're getting pretty large now. We're needing to use large machines to make the smaller catalysts that are essential to making proteins and other molecules that we use every day. And we are going here now from the smallest carbon atom. The ribosome organelle is a large entity in the cell. And, when you do look at electron micrographs of cells, you can see these dark dots, which represent ribosomes. They're big enough to see, whereas the proteins themselves are not. So that's what you're destined for today. The structure of the mature messenger RNA just for a minute because, in the last class, we talked about a lot of manipulations of that pre-messenger RNA. And now I just want to remind you that the messenger RNA is the fresh thing out of transcription. messenger is single-stranded RNA, obviously. It has a 5 prime cap, which has got this funky 5 prime, 5 prime bridge that's resistant to exonucleases. Somewhere in that sequence is a start codon. It's something that says this is the bit I want to translate. Often, there's a lot of stuff here that you don't translate. Part of what's known as the ribosome binding site. And there are many features in this part of the sequence that are very important for translation. The genetic code, which forms the basis of this entire concept, has some features to it where it does have some degeneracy. But we'll go through the degeneracy, and we'll take a look at the genetic code because it will tell us exactly how the three letter-- the words made of three bases encode everything we need for translation, all right? So let's just go back and take a looks at this. So we've looked at the messenger. I've told you a little bit about the tRNAs and. Once the structure of double-stranded DNA was deduced, everyone was moving on to trying to understand how that converted to the translation to proteins. Crick and Brenner realized it was three bases to code for one amino acid, but Khorana, Nirenberg, and Holley defined that genetic code and got all of the details. So that's the work thatKhorana and others did. And that was awarded them a Nobel Prize for that work. And then, later on, things started to get-- you know, these are decades of work I want to point out to you. decade later, the sort of details of the structure, but not the structure itself. And it was really exciting in the 2000s when Ramakrishnan, Steitz, and Yonath solved the structure of the prokaryotic ribosome. So each of these things has taken a decade to happen, but they are fundamental, major, important things that we can act on and move forward to understand more. All right, so let's move to the transfer RNAs. And I've flashed up this slide a couple of times, but I actually now have the movie of theructure of a transfer RNA. The ribosome is an important structure in the mechanisms of protein translation and synthesis. The 3 prime hydroxyl group of the last ribose within this ribosomal sequence is where the amino acid that's going to be loaded into your protein is attached. One of the loops has a special name. It's called the anticodon loop. It comprises three nucleotides that are complementary to the nucleotide in your messenger sequence. So this really is a decoder because, at one end, it's carrying an amino acid, but it's also carrying the aminoacid that corresponds to the code that's in the messenger via that anticodon loops. We're starting to understand the tRNAs. What we need to move on to now is really taking a look at the genetic code. This is the absolute-- the sort of Rosetta Stone for translating messenger RNA to amino acid sequence using codons. So this sort of-- whoa. Getting a little-- I love translation. I'm getting a little bit excited about translation. OK, so there are a few features of this genetic code that are very important. Number one, you won't have to remember it. is how we designate the triplet of nucleotides. The way you read this table is you read the first letter. So, if I'm going here, here, it's going to be starting UU. Then, within each block, there are the four alternatives for the other four bases. And then the third one, basically, just designates those. So you can read, for each amino acid, what three-letter codon would correspond to it. Some people quite like-- oops. I got rid of it too fast. stop codons. The stop codons tend to be used variously. Some are more predominant in some organisms than other. Some organisms might prefer two or three of the degenerate codons, and others may prefer a couple of the others. The last thing I want to do is, basically, explain to you one more time, when you're looking to read what your amino acids that get put in may be, you're going to look at the codon. And it will tell you exactly the amino acid. synthetases for different amino acids that show you that there's a recognition not just for the amino acid that's being loaded, but, rather, for the entire transfer RNA. So some of these look quite different. The isoleucine one interacts in one way. The valine one is a little different. And the glutamine one is different again. So they vary in the way they interact with the transfer RNAs. That's how you get the specificity. Does that address your question from earlier? Hello? small and large subunits. In orange-- well, that's kind of a burnt orange-- is a sneaky little bit of the messenger. In yellow are the transfer RNAs. And there's one more unit on here that I won't describe too much. It's a protein factor that helps all the processes occur. And, in each step, you're bringing in a tRNA that's loaded with an amino acid where the anticodon of the amino acid is complementary to the codon that's within the messenger RNA. When proteins are made on the ribosome, they have a bit of a choice. They can get made and fold beautifully into active proteins. Those proteins could be modified. They could go to different places in the cell. Occasionally, proteins misfold. Maybe the rate of synthesis is too fast, or the environment isn't right. So there will need to be mechanisms whereby proteins get degraded if they're not folded properly. It's not always perfect, but what is known now is that they're starting to fold almost immediately from that N-terminus. writing 5 prime to 3 prime, except when we have double-stranded because we have to put the bottom strand in a different order. So this would be a situation where you have a wild-type enzyme. Everything is transcribed and translated properly. Occasionally, though, there are errors that will introduce defects into the ultimate protein. The first type of error is a nonsense mutation, which might be leaving out a base pair, inserting one, substituting one. And this would, ultimately, cause an error in the DNA that then causes an error in your messenger RNA. A missense mutation is where you put in the wrong amino acids. Nonsense mutations are not so bad because you probably just truncate the protein. The last ones are the ones where we start to encounter errors in DNA that result in errors in proteins that may cause genetically inherited diseases. "I am going to tell you that I'm handing over the baton to my colleague, Professor Martin. He'll take over on Monday. He's keen on genetics, yeah?" "I think this field is fascinating. Once you get used to the mechanics of it, it's really cool to think of how you go from DNA to RNA to folded proteins," he says. "Don't forget my office hours on Monday if you need them," he adds. "I'll be in the lab all day, every day, if you want to talk to me about it." "I've got a lot of questions for you," she says, "but I'll be happy to answer them."

ROUGE-1: 34.60, ROUGE-2: 32.94, ROUGE-L: 32.15
BERTScore: 72.58

==============================================
==================== [62/100] ====================
Summary:
Professor Donald Kagan: We have been looking at the question of the rise of the polis. He says the concepts and the kind of characteristics I've been describing appear to spread all over the place. One of the ways in which we can date the pol is has to do with the Greek traditions about the establishment of colonies throughout the Mediterranean, he says. Kagan says the idea of the farmer hoplite citizen is a critical element in shaping a polis and for my money that's what the poli is about to start with. are a clue is because every time we see a colony, learn anything at all about it, it appears to exist in the form of a polis. That powerfully suggests that that was the typical characteristic style of life that had already been established for Greeks before they sent out the colonies. The earliest date according to Greek tradition, if my memory is correct, was something like 773 where the Greeks date the foundation of what they thought was the earliest colony they ever established. That's the very first place where there is a tradition of a Greek colony having been planted. the natural thing to do given the character of life, which was based upon farming, if you leave you lose your farm, and based upon the difficulty of transportation. In the Greek world we know--I think I quoted something from Hesiod that confirmed it. The Greeks were, even though they went to sea plenty, they were terrified of the sea for very good reason. Their ships, their boats were not very seaworthy; storms come up in the Mediterranean very suddenly and terribly. So then there's the whole idea--we've already given you some sense that the Greeks were ancestor worshippers. four, how do you provide for the extra two? Well, sometimes you divide up the land equally, but if that land continues to get smaller and smaller, it will not sustain an additional person, not to mention additional family. So that clearly is a problem and the notion that land hunger is a key explanation, I think, is supported by the fact that wherever we find a polis, whatever other characteristics it has, and they vary, some of them are located at wonderful places on the sea. place for trade. They would have had to be damn fools to have settled there without that being in their minds. Some of the places where they settled leave us puzzled, and have left the ancients puzzled. One of my favorite examples is the colony on the south shore of the Bosporus, which is called Chalcedon. It's right opposite Constantinople--that doesn't exist, Istanbul. Winston Churchill never, never conceded that it was Istanbul; he called it Constantinople till the day he died. In any group of people there is a small minority, I want to emphasize small, who just love to do risky things. They just love adventure; they're never happy if they're safe, and so off they go seeking adventure and seeking to make a fortune however they're going to do it. So, for these reasons and probably for hundred of years, they've been colonizing. And now that we do have something, namely, this wave of colonization, they join that as well. Colony is a Latin word ultimately for colonia and the Roman colonies were, first of all, garrisons that they planted in land they had conquered. The Greek word for this is, apoikia, and most literally it would mean a home away, an away home and that's what they're making. They are establishing for themselves a household, a home someplace away from where they started. They were the antecedents of the Serfs, which we will see later on in medieval history in Europe. Delphi is halfway up Mount Parnassus and it was thought by the Greeks to be the omphalos, the navel of the universe, the center in every way. There the god Apollo had established an oracle. Gases would escape through this gap in the earth and there were priests who worshipped Apollo there. They would place a young woman there who would sit as these gases came up and she would after a while begin to speak in tongues, which is to say she would rattle off a lot of language which nobody could understand. John Hale of the Yale Class of 1973 is now an archaeologist at the University of Louisville. He discovered evidence that totally confirmed the Greek story. They tell you precisely what the gases were, what the characteristics of those gases were. It squared beautifully with all details that we heard about the Delphic Oracle. So, here's just one more case where Yale helped to straighten out the world, but you notice it wasn't done by a Yale faculty member, we engage in confusing the world but our alumni do a much better job. Greeks and barbarians came to Delphi to consult the Delphic Oracle. Most of the things they asked were questions that really had a yes or no answer. The oracle probably gained its fame for being very good precisely at answering this question. These people knew more than anybody else about these things, and so consulting that oracle was a very act of rational thought, says John MacIntosh, professor of ancient history at the University of California, Los Angeles, and author of the book, "The Lost City of Syracuse" will decide whether it's a good idea for him or not. Recruiting is tremendously important because you need to have a certain number of settlers to make the settlement viable. So however many that is, that is what you try to recruit and you recruit typically at a time when it's easy to get people together so you can tell them the story. There are festivals held in each city just for its own citizens and my guess is that when you could do that, when you felt that you could recruit a full colony from your fellow citizens in Corinth, let us say, that's what you did. were not enough Corinthians who were ready to go with you on your expedition. So, you would try to take your message to one of the Pan-Hellenic festivals which were getting organized about this time. So now you have everything in place, you've recruited your settlement, you get on your ships and sail, in this case out to the west central Mediterranean. You find your way to Sicily, work your way into the harbor at Syracuse and things work out, and now we have this apoikia called Syracuse. The city of Corinth sent out a lot of colonies, which is why we know something about their arrangements. When Potidaea got into trouble with Athens, and found itself besieged, Corinth sent a real army to go in there and fight. At the other end of the spectrum it's again Corinth and they have a colony up in the northwest called Corcyra. The first relationship between them is a navel battle, and thereafter we hear of them quarrelling and fighting with each other just about at least once a century right on down. more time, that the overwhelming normal situation is the first one I described, friendly relations. These guys that have gone out, let us say to Syracuse, they are your people, they have relatives back home. They have friends back home, it is natural--oh by the way, they're accustomed to worship the gods in the same way that the Corinthians do. We do know, again, Thucydides is our source, that it was customary for colonies to send representatives back to the mother city for the religious observations that were common to them all. shop, but you can't get now, so you would want to buy what the Corinthians sell. Guess what? You've got great grain fields out there in Syracuse. Hard to believe today, but Sicily was one of the major granaries of the Mediterranean world at that time. Corinth always needs that kind of stuff, so we sell you our wheat, you sell us your pottery. You sell good wine that we can't grow yet and maybe never will be able to grow in our neighborhood. So you can see why it would be very natural for all sorts of ties to unite these colony and mother city. Kagan: Nobody was compelled to do anything. The British practicing mercantilism passed navigation acts, saying what ships could carry what and so on--nothing like that in the Greek world. Everybody--all of this is voluntary on both sides of every agreement. Okay, now where are these colonies? Let me give you a little run down. Before we get to that, I should say that the Greeks have already, before this period of the period, had colonies. In the back, yeah? Student: What extent was the primitive form of [inaudible]Professor Donald Kagan: Primitive form of what? By the tenth century B.C., we see Greek cities lining the coast of Asia Minor on the west, and even around on the bottom and to some degree on the north, and on the islands in the Aegean. So, there has been a Greek--what's the word I want? There is an expansion of the Greek world already by the 10th century. I might point out that the way the Greeks did their immigration into Asia Minor had a pattern so that you can go from north to south and you will find some consistency. The Black Sea is not a Greek lake, but there are Greek cities that are spotted along the coast. When the mythical mission of Jason and his Argonauts go sailing out to that territory, he is out there in Tarzan country. As far as the Greeks were concerned, it was just the wild out in that territory and remember he marries and brings home a wife, Media, and she, of course, is like no Greek woman who ever lived. She can perform magic and she can do monstrous things that you can't imagine a Greek woman doing. there, Palestine, there are no Greek cities there and that is because during the period we're talking about those regions were occupied by civilized powerful people. Nobody would even dream of trying to take them on and building cities that would challenge their control of that area. So that is not territory that you can build colonies; you've got powerful empires to deal with. There is one exception. In the sixth century, I think it's around--imagine around 550 or something like that, the Greeks settle a single colony in the Delta. Greece colonized most of the Mediterranean in the 7th century B.C. Greek cities are all over the place, including Nice, Marseille, and Creta. The Greeks are shut out of the Italian Riviera because of the Etruscans, who control their own area. When the Romans dominate most of Italy, they refer to the southern portion of that peninsula as Magna Graecia, great Greece because they're all Greeks down there. There were two important cities in the northern part of that island, Calkis and Eretria. what can we speculate is the meaning of that? What we find is that the states who are doing most of the colonizing are located where most ofThe trade was going on at this point in history. When I say manufacturing, you understand everything is done by hand, but you see things like shops that contain a number of slaves working for a master. In some cases, especially the later on you go, some shops that have quite a few slaves that worked to produce these things. Well, these places are the ones that have the trade, the industry, and also engage in colonization. is easy to see that where there is that kind of conflict and trouble, there would be people who would want to flee that and to go elsewhere. It might well be that the people who won those wars, internal wars, would have been glad to send them away rather than to have these discontented people and these folks who were their enemies hanging around town and making trouble. It is only speculation, but it seems to make sense and we know we don't hear of such troubles within Athens and Thebes, and Sparta. Greece's impact was greater in the west and the north than it was in the east and the south. The Greeks lived among people who were more civilized than they. They had very little to teach or to impose upon those people rather than vice versa. philosophy is going to be invented in Miletus probably in this sixth century B.C. Well, MileTus was on the main routes to all of the places where advanced knowledge could be found, Mesopotamia, Egypt. It is inconceivable the Greeks could have developed a civilization that they did without contact with these eastern civilizations. who have interests rather different from those of the most primitive polis you could imagine. Some scholars early on in the century, moved by Marxist theories, suggested that you had a capitalist class growing up, there's just no evidence of that; it's just wrong. My guess is that the earliest traders of any scope were probably noblemen who also had land and estates back home, but who had the opportunity, the know-how, the connections to make it possible to make a lot of living in trade. is going on. More and more farmers are becoming independent, self-sustaining, hoplite farmers of the kind that I've described. They're not going to feel the same way about it, there's going to be pressure from them for a better participation in the decisions that are made in the state. And also there will be some rich people, very rich people,. rich in a different way from the way people used to be rich; rich meant the best land. There will be people who will have wealth in the form of precious things and I would use the word money. come to mean weights of silver or gold. So now you have a change in fundamental economic things. Well, all of this is tied up with this colonial story I've been telling you. Finally, I think, it works in both directions at the same time in terms of the impact all of these changes have on the political situation. On the one hand the changes, that is (A) the rise of the hoplite class; (B) the development of lots of commerce and industry and wealth in a new kind. especially, some scholars have pointed out, I think persuasively, also for some considerable time provided an answer to that problem in the form of an escape valve. Americans didn't have the kind of terrible class warfare and the terrible warfare within cities that the Europeans had experienced throughout most of their history. Really unhappy and angry people could always go west, get new places. I mean, fundamentally, Kansas is a colony in a certain Greek sense, all of these places are. So, that's part of the story of why America had the very lucky early history that it had. that colonization provided something analogous to that for the Greek people. So now, here we are somewhere in the seventh century, most of these places I've been talking about have been settled, the currents that I have been describing are flowing and the kinds of problems they have give rise to what will be felt in most of the towns. That is the proper introduction to the next topic, which I'll discuss next year. No not--it seems like a year, but it's next Tuesday actually.

ROUGE-1: 42.04, ROUGE-2: 40.05, ROUGE-L: 40.14
BERTScore: 68.77

==============================================
==================== [63/100] ====================
Summary:
Instructor: We are asked, which of the following correctly identifies the areas of consumer surplus, producer surplus, tax revenue, and deadweight loss in this market after the tax? So pause this video, have a go at it. Even if you struggle with it it will make your brain more attuned to when we work through it together. All right, now let's work through this together. And I just want to sort of understand what's going on here before I even try to answer their questions.

ROUGE-1: 16.31, ROUGE-2: 16.15, ROUGE-L: 16.31
BERTScore: 70.34

==============================================
==================== [64/100] ====================
Summary:
King Arthur was thrown a party at Camelot for Christmas. A towering knight riding an emerald steed burst into the room. He proposed a game. The bravest warrior present would attack him with his own axe. If they could strike him down, they would win his powerful weapon. However, the knight would be allowed to return that blow in one year and one day. No man could survive such a strike. Arthur’s nephew, Sir Gawain, took the weapon instead. And with one swift strike, he beheaded the grinning knight. Gawain was told to seek the Green Chapel by the castle's lord and lady. In exchange for their hospitality, the lord made a strange request. Over the next three days, he would go hunting and share his spoils every night. In return, Gawain must give him whatever he’d gained during his day at the castle. On the third day, the lady offered more than just three kisses. She presented a magical sash that would protect Gawain from the Green Knight’s blade. He bowed his head for the deadly blow, and with a massive swing, the Green Knights cut Gawain’S neck.

ROUGE-1: 43.67, ROUGE-2: 39.46, ROUGE-L: 42.08
BERTScore: 73.78

==============================================
==================== [65/100] ====================
Summary:
well welcome back everybody to uh the last lecture 162. this is kind of a a special lecture um i did get some requests for more information about distributed storage and quantum computing and so i think we're going to do that. i want to make sure that we talk through the chord algorithm since that's a i think relatively simple thing to understand and is very cool and applied pretty much everywhere so if you remember one of the things we talked about last week was basically this cap theorem which was really a conjecture that eric brewer put forth back in the early 2000s. is a good way to understand global storage systems as a result now um at the very end of uh last lecture we were talking about key value stores. Key value stores are very simple in interface excuse me so basically uh you can have an arbitrary key although that's usually a hash over some value. You can have a value associated with it and if you do put a key comma value that goes somewhere into the ether and then when you do get of the key you get back the value that you started with.  node except that in reality what happens is this gets distributed over a whole bunch of nodes and so the question is really many parts to this question one is how do we actually do that distributing another is when some client does a get how does it figure out which node to go through. So far we haven't really talked about how to even make that work okay. So today i want to tell you about the cord uh algorithm which has been turned into storage systems of many sorts including those used by amazon et cetera okay facebook. here's an example of a recursive lookup which is like routing so basically if i say i want to get uh whatever key 14 has got it goes to the master directory and then that directory forwards it on it routes it to the particular node that's got the results and then the the node returns to the directory which returns back to the original client that's recursively routing its way through. An iterative approach is one in which the client basically talks to the directories then they talk to the individual nodes and um we're not routing queries through anywhere every individual client is.  consistent hashing is a way to take your keys and figure out a clean way to distribute them throughout the system without having to know pretty much all of the nodes that are participating. The chord algorithm lets you get by with only knowing essentially a logarithmic number of nodes in the total system and you can still do this well so we're going to associate each one of those storage nodes is going to get a unique id okay and that unique id will be in the hash space. This is basically going to be a mechanism to divide our space up and we'll talk about that in the next slide. So imagine you take their i don't know their ip address and their owner and whatever you concatenate all those things together and you hash them and you get a single 256-bit id out of that now we're going to talk more about secure hashes a little bit later in the lecture. Every node has an id and it's going to be in this ring space this unit dimensional space from 0 to 2 to the m minus 1 where m is big okay and so let me just show you the picture here. said in practice m is really something more like 256 and so uh this ring is really big and um these nodes are much more sparsely distributed around the ring okay questions we only have a very small class today so you guys are likely to get your questions answered anybody okay no questions all right should we move on now is a system that was developed uh with a group of researchers at mit and at berkeley um and you can think of it as a distributed lookup service uh and it's in my view i like to teach about it because it's the simplest and cleanest algorithm for distributed storage that i have seen. product there's cademlia there's a lot of interesting ones several designs here at berkeley and so this problem of how to look up a key value pair got a lots of study in the early 2000s okay and let's look about the way to think about chords lookup mechanism is once again routing so it's going to be we're going to describe this in a recursive fashion to start with and then of course you can do this in an iterative way as well i think the recursive version is a lot easier to thinkabout so every node in the system is going to know who its successor node is. correct so how did we find the first one again that's a great question so the answer is that any clients that talk to the storage server need to know at least one node in the system. The client which i haven't shown separately out here happened to know about node four and node four serves as a gateway into the ring all right did that answer that question now you can see that this doesn't seem very ideal because if i've got a thousand nodes that are storage nodes i may have to take many hops to find out what i want here. Just its successor then we can always find the server we're looking for okay now what does this really mean okay so here's this ring and here's you know key 14 stored on node 15 let's say what it really means is something more like this right so these nodes since we we're doing hashes over their ip addresses and some metadata it means that they could be anywhere in the world and then we're connecting them together based on their hash name so fort talks to eight eight talks to 15 and so on so that for instance key 14 happens to be stored here on the east coast node 4 is up in alaska. means that no particular part in the in the world here might be a hot spot it means unfortunately though that we don't have the most uh local of look up because if we start at node four it'd be nice if we could just go down to 15 and back okay now this is a really good question here about redundancy how do we get redundancy out of this for the moment uh suspend that question for just a second certainly we could put raid servers or what you know raid storage on each of these nodes and that would be great if the disks fail but uh we would like something even more powerful. beachfront property in nevada and then has a plan to basically cause uh california to fall into the ocean and therefore have really expensive properties fortunately superman uh saves the day and it doesn't happen so um okay so if we move um forward with this by the way i'm showing you these clients now to make this a little more clear the clients need to know one gateway into the system in order to talk to the system okay so that's going to be part of the initial lookup. wrong with who's connected to whom and then if it finds a problem it can run notify to help reconnect the ring okay so let's uh these are the kind of things that are a lot easier to see with um animations and so what i want to show you here for instance is here's a new a new node or it's a node that crashes coming back then suppose that what iwant is to join the ring so what do i do well just like we've been talking with clients presumably what i know is i know one of the nodes in the system. about this algorithm is all that the ring is going to do is it's going to figure out who is responsible for storing key 50 as if this was just a regular key value lookup okay. 50 starts by updating its successor 58 so now it's technically connected somewhat to node 58 but you know 44 is also connected to 58 so we now have a kind of a weird partially connected ring okay and let's look through what happened. At that point 44 will change its successor to 50 and then finally 50 will notify 50 about itself at which point 50 knows its predecessor and when all said and done we have the the node 50 has joined. If you lose two nodes in a row then what i've just described to you is no longer going to work so there is a way to completely break the ring such that the stabilized procedure won't reconnect it can anybody think about what the right thing to do there is in that scenario how do we make sure that two failed nodes can't prevent the ring from re reattaching itself? So far we still have this pretty expensive lookup process which is order n now we have figured out how to make this stable so first of all as long as we have a fully connected ring we can always find the storage uh for this for the data. now um and what you should do is you should take a look uh take aLook at that paper because they describe this in more detail but basically what you want is a stabilization procedure that can work even when nodes uh several nodes in a row are failing. What you'll see is that that there's a way to do that as long as you have multiple links and what we're going to do right now for performance is going to make that even harder to destroy the connectivity okay so if you look here the question is sort of how do we make sure that we have better than order n? be 96 what node would store 82 well that would also be 96 what nodes would store 84 that'd be 96 at some point we get to what node will store 80 plus 32 so 112. okay and we're going to keep track of a logarithmic number of these pointers. The power the powerful thing about this is once i've got all these nodes now i can do a really fast routing process to figure out how to find which node is going to store the key i'm interested in. first routing hop is going to say well if i'm at 80 and i want to get somewhere over on the ring i'm going to connect i'mGoing to correct the bit i've got in this case it would be a 1 in the high point. Then i'll turn it to 0 by taking a long hop, then i'll take a less long hop and so on. i end up with a logarithmic number of hops to get me to my destination and you can view that like i'm correcting the bits from my starting point. first of all we're going to have um more than one forward and backward link called the leaf set. In the predecessor reply message node a can send its k minus one successors and so on and so you can see what's going to happen. During these heartbeat process of looking things up you know asking well hey my successor who's your predecessor during that process the stabilized process we'll get back multiple nodes. This is going to help us get a forest of connection connectivity forward and backwards and that's gonna allow us to keep our leaf set as as correct as possible. The finger table look uh lookup process that just keeps renewing these pointers over and over again. As new nodes come in the finger table adjusts as new nodes leave or as old nodes leave. So that we end up with really high probability even if half of the nodes fail so you can find data with the right number of leaf nodes. That's kind of what's proved in that chord paper and that's not that many because it's a logarithmic number okay so uh before i.me okay and so that that's a very good way to start. key 14s stored on node 15. If node 15 weren't there key 14 would be stored on 20. If 15 dies or goes away we don't have the data. So it's fine that the consistent hashing tells us where it should be stored. But we can't store it there because we've lost our data so we got to do something else here okay. We're going to take the forward leaf set or you can do both forward and backwards up up.go on to uh storage fault tolerance for the data does anybody have any questions on this we good okay. depends on the algorithm. We're going to store 14 on the successive nodes that we know about because of the leaf set so we'll store it on 20 and 32 and now what's good about this is if node 15 fails which is the point that's supposed to store it we've already got a copy on node 20 and node 20 can notice oh 15 went down therefore node 20 will start the process of making sure that 35 gets a replica. okay questions and the ring is going to stay connected because of our connectivity. algorithm and so what's good about this is like i said you store the data in the cord ring and it it's very hard to destroy okay why are they called leaf sets that's a good question the reason they're called Leaf sets is because in some sense you can view the uh if you take any given starting node like 58 and you view the set of fingers that’s a tree and so eventually you get to the leaf set and so it's like a tree with leaves so that's where the leaf is coming from. i guess you could call them branches if we don't want to mix metaphors too much and the leaves and none of those quite have what i want so i'll follow one of these branches it's a little shorter and then eventually i'll get to a node that's this one where that node knows because of the leaf set which node is the one i'm looking for which is going to be the one that's just bigger counterclockwise or excuse me clockwise from the id i's looking at okay. So this leaf set not only serves to help us with our replication but it also serves as uh as part of the last couple of hops we can use it to basically find who's supposed to have our data. randomness is helping us to avoid correlated failures where yeah we have a bunch of copies but they're all in the same machine room and the building got struck by lightning so that doesn't happen in a chord algorithm. The downside of course is performance might hurt if you happen to be too far away from a copy um and so i will tell you that there are subsequent versions of cord which uh when you're doing this routing and you have a lot of options here see how we have many places we could go. Think of this like a dns built out of cord and so what the client does is the client doesn't know where the data they're interested in is they ask the cord ring. The cord ring tells them who to talk to and then they can talk directly to them and exchange data over the shortest path possible using tcpip or whatever. So you can now get the best of both worlds and that you have very hard to destroy lookup process and then you can choose to replicate that data on close to the client. what we did with the the tapestry lookup process back for ocean store okay so i did want to point out that what i've just described to you this chord ring is actually used in lots of uh cloud services these days the idea at least. For instance dynamodb and i have a paper for that up on the reading from last time uses the chord rings and you can look down here but it uses them rather than spreading them around the planet. It uses them within their machine rooms as a way to distribute load. have a service guarantee that says we'll get a response within 300 milliseconds uh for say 99.9 percent of the requests okay. This is very in contrast essentially to what we've been talking about a lot of the rest of the term uh which is focusing on mean response time. Instead we want to have guaranteed performance okay and this is again thinking i want you to think back to when we were talking about real time scheduling and what was important there was keeping the predictability of the scheduling time low. it adapts automatically which is pretty good okay so what i wanted to do next uh i'm going to leave that there a little bit i want to talk a littlebit about security and then um talk through a couple of things and then i wants to uh try to get to quantum computing as well so we can i know there was some of you asked some questions about that so i'mgoing to leave this topic unless there's more questions okay so i's going to talk through  things that i'm pretty sure i'm assuming everybody kind of knows but i want  to make sure we all have the same terminology so um you know security is an interesting thing it's basically computing in the presence of an adversary. Security is basically using those mechanisms to prevent misuse of resources so for instance virtual memory is a mechanism that can be used for protection security policy would be making sure that when we use virtual memory we don't let malicious processes or different processes owned by different people use the same memory and have a potential for screwing each other up. "It's a it's a constant arms race uh preventing people from breaking into things you care about by using new techniques and the distinction between protection and security i think is an important one" security policy built with our protection mechanisms okay so i wanted to point out something interesting i don't know if you've ever seen this before but here is a car in the ditch. Back in july of 2015 there's a team of researchers that took complete control of a cheap suv remotely exploited a firmware attack over the sprint cellular network. They basically caused the car to speed up and slow down and and veer off the road and uh totally wirelessly so this is a little scary uh to think about now fortunately no humans were harmed. Firmware in this car was accepted as authentic even though it came from a malicious third party. One of the questions that's important is do you know where your data came from that's a provenance question. Do you know whether it's been ordered or changed or altered in any way that's an integrity question. This is a question of the rise of fake data which is kind of much worse than fake news which is about corrupting the data and making the system behave very badly.  confidentiality is making sure that the data is read only by authorized users. Non-repudiation is a surprisingly important thing that people don't often talk about. cryptography is one of the central points of many of these mechanisms. You just have to use it correctly and this is communication that's in the presence of adversaries. It's been studied for thousands of years there's actually something called the code book which you should look up which talks about you know Thousands of years of cryptography and cryptography. The central goal has always been confidentiality about encoding information so an adversary can't extract it the general premise is that there you know there's a key and if you have the key you can decode things if you don't have thekey it's impossible. Public key cryptography where there's really two associated keys and you encode with one and decode with the other really leads to all sorts of really interesting authentication problems okay so basic cryptography which you've probably heard about is you have a secret key and you take the plain text and you encrypt it with the secret key. single symmetric key encryption work which symmetric because the same secrets used at both sides is to prevent a adversary from holding on to an old message and sending it later is you have to start adding what are called nonces which are things like timestamps and so on so that every time you send this it's unique and if somebody sends an old version you can detect it. The idea of a secure hash function is one where you take data and you run it through a hash function and get a bunch of bits out of it. we can take a plain text something like a contract and we can run it through a hash function where we take that key and an append m and that's called a digest now we can send that across and the data and at the other side we can verify by re uh computing that hmac okay and if they match the one that was sent across versus the one you computed yourself then you can know that the message is not corrupted otherwise it's corrupted. So we can use hashes to prove later that you know after the transmission has happened that the data is authentic okay so hashing is pretty powerful. it wasn't uh you know if the integrity wasn't high you know it was basically didn't match then we could know that that firmware is probably bogus and we shouldn't be using it okay now the downside of everything we've talked about is both sides share the same key and so if you leak the key then you got problems okay and furthermore you have to somehow share the key. So that requires you to go in a dark alley and you know hand the key over and so this seems like only part of the solution. it's private key and that private key is something that i hold uh secret but the public key i broadcast and so this is basically uh this is the the basis for all sorts of modern algorithms okay among other things if i were to encrypt uh the hash over data and then encrypt it with a public key then i can know for a fact that that data has made it through and only could have come from somebody okay so that's part of uh how we actually sign things all right so for instance here's alice and bob let me show you a fun algorithm here bob sends his public key out in to the wild to alice. Now alice can encrypt messages and send to bob and only bob can decrypt him. Alice can send her public key and now bob can send things to her. is a valid public key requires public key infrastructure but that's another story so now i'm i'm going i went through this very quickly how many people have never seen anybody uh never seen this kind of thing before or is this all pretty familiar okay good oh great this is in cs70 great so let's talk about a project that i've been working on so again you could view security as trying to protect things with a firewall or you could View security as it's all about the data and if you can protect the data then you can protection everything okay. A virtual machine that's in modern hardware that allows you to set up a secure channel and do some secure encryption in a way that not even the local operating system can see the data. If we have these secure enclaves stored everywhere and secure encrypted data then perhaps we can do some interesting things okay and we canDo them securely and so um let me see i'm running low on time here i wanted to say something a little bit interesting here about why data breaches which we've heard a lot about in the last four years are so prevalent okay. and now we suddenly have this issue that physical devices that are trusting on this security suddenly start performing things they're not supposed to okay so the real reason we get these data breaches everywhere is because people think that they can put these boundaries up in a way that don't um can't be breached and of course we know that's not true. The problem really is not only are things breached but the integrity and the provenance of that data is not known so what do we do the data centric vision which is one that i've adopted in uh my research group is one in which we think about shipping containers full of data. One person said well why don't we just make things that are all the same size and shape and then all of a sudden we've got ships trains cranes all of the the the infrastructure for handling these things are the same across the planet. Now i can ship something from my house in lafayette to beijing the outskirts of beijing just by calling the right trucks to come pick up a shipping container which gets taken to the port of oakland put on a ship and then it goes across the ocean and it's unloaded and and so on. a data capsule and inside the data capsule is a bunch of transactions that are hashed so remember those hashes we talked about and signed where we uh we use a private key to sign a hash over something and as a result we trust that this really came from the person who said it did because only they could have the private key. As a result of these data capsules this gives us a cryptographically secure way of moving data around to the edge to the cloud and back again in a way that nobody can fake out okay another way to look at this is this is like almost a blockchain in a box okay. handle this standardized metadata and what is the standardized metadata well it's a hash over an owner key and some other metadata about who created this and that forms a unique address that you can route to in our system unlike um not unlike an ip address. The data becomes a first-class entity so your data basically can float pretty much anywhere so you could put a data a data capsule server in your house and all of a sudden your local data capsules could be stored there or if you're doing some communication with somebody else you could get a copy of their data. data capsules and again because it's like a blockchain in a box it's not possible for somebody to fake data that doesn't belong in there okay and so think back to that firmware issue with the car in the ditch okay and the other thing is that metadata we're looking at actually has details about what the network should and should not enforce. So this vision if this uh is ultimately complete is one where you instead of paying for ip service you'd pay for data capsule service and um you'd be able to store your data in a way that was secure okay and could be used anywhere you want and you'd own your data. how we want to be dealing with data all right sorry if that's a lot of information but i wanted to see if there's any questions there before i switch over to some quantum computing all righty give me a second i'll be right back. So first question is how do we know the data is secured so um just like with a blockchain let me just back up to the picture here which i think is a is a good one to be talking about um what we know is the following. bundles of data and if somebody tries to put garbage in there a legitimate person who's trying to look at this can just throw the garbage out because there's no way that that garbage could have been put in there uh in a way that meets the integrity constraints of the data okay. So it's not forgeable um it's uh it maintains its integrity the the transactions can't be swapped or whatever and so it's a unique umly uh high integrity kind of bundle of data. The vision here really is of pretty much everybody using data capsules everywhere okay and if you can get that to happen then you could potentially have a very interesting scenario here. Part of what we're doing is we're working with roboticists and machine learning folks to put their data and their models for grasping and so on inside of data capsules and as a result they can reside securely in the edge in say your robots or whatever in a way that can't be breached okay. This is really targeted at secure edge infrastructure in addition to the cloud so these data capsules can move back and forth. unforgeable all right good so let me say a little bit about using quantum mechanics to compute and since there's only a few of you tonight if you're uh willing to hear me out i can talk for a little longer just to get through a couple of other things on quantum computing. It's basically using weird but kind of useful properties of quantum mechanics two of them quantization and superposition and that quantization really gives us the ability to talk about something like a one or a zero. Superposition is having a bit which is both a zero and a one in certain fraction of uh between the two and that's where things get interesting okay it's like it's fifty percent zero fifty percent one or something in between that's called superposition. Most digital abstractions that you might learn about in 151 or pick your 141 some of those uh various vlsi classes is you're spend a lot of time trying to get rid of the quantum effects. However if you're willing to allow things to not be always a one or a zero that's a different story. always a zero what you can do is you can just start doing quantum computing and that's basically using quantization and superposition to compute. Some interesting results just to tell you uh quickly here is for instance shore's factoring algorithm factors large numbers in polynomial time even though the best known classical ones are sub-exponential in the number of bits. If you could get a shores algorithm running on a quantum computer pretty much all rsa cryptography would be broken because you could factor okay. a time that's a square root in n rather than half of n okay that's pretty interesting right um the other uh so uh 191 is mentioned in the chat. That's a good class to take if you're interested in quantum computing. Another one that's my favorite i think best application of quantum computing is what i like to call material simulation. This was kind of the original uh the original application ofquantum computing that was uh thought of and basically the idea there is if i want to design a brand new element or brand new material to build things out of. Google and ibm are building quantum computers. The goal is to prove that quantum computers could be faster than classical ones. The machines are currently running at four degrees kelvin or something really cold. There are other types of technologies including ion traps that potentially are pretty interesting that there have been some thoughts over the years might be able to run at something closer to room temperature not there yet the current goal of google and ibM is to do something which they call quantum supremacy which is basically to prove quantum supremacy. Quantum supremacy is the ability of a quantum computer to do something better than a classical machine. This is a demonstration of quantization which is a way of looking at the spin of certain particles like protons and electrons and neutrons. These are particles that have this intrinsic spin and so now i got one and zero or up and down okay and a representation called the heisenberg representation looks at this messy physical situation like this which is either a zero or a one in these brackets and that represents spin up and spin down. something people were looking at okay but the temperature here was less than one kelvin which is really cool okay but let's suppose now here's where the quantum computiness gets pretty tricky okay and and uh bear with me just a little bit i know i'm going a tiny bit over here but um if you think of the zero and the one thing okay this is actually a wave function if you take quantum mechanics representing spin up and spin down and what's interesting is the wave function in quantum mechanics is a complex function. here is actually sort of in one state andsort of in another okay and those are those are two options and it turned out that there was there's a set of famous bell uh inequality experiments that were done that showed that reality is actually the second choice so in fact as weird as it is uh that proton is is a combination of zero and one at the beginning. It's only when we look carefully and force it to be one or the other when we actually try to measure it then it gets forced into a state okay. codes believe it or not which can protect this quantum information from being measured by accident by the environment. As a result really we can we can hold these quantum states for a long enough period of time to actually do something interesting with them. Let me show you this simple two-bit state okay this is called an epr pair for einstein pradonsky rosen it was produced by einstein and pedonsky and rosen as a thought experiment and the idea is i've got two bits but i don't have all four options i only have a zero zero or a one one. you do a bunch of computing on it such that the probabilities are kept and you measure okay and the way it looks is that you take uh let's say you put an input with all possible combinations of the input input of the inputs being equal values all possible probabilities it looks like you're doing computation on all possible values at once but then when you measure you pick up exactly one and that's the answer you get okay. If you don't do anything very interesting here this is going to look like you randomly picked some input and computed on it so basically what we're talking about here looks like a random computation. high probability some answer that was hard to find that's what we would like okay and so if you look here um you know if the two n inputs are equally probable there could be two to the n outputs that are equally likely. What we'd like is the probability of the outputs to be piled up high on the answer we want and it turns out that something like fourier transform does the trick okay so if we can do a fourier transforms on some input we can actually get an interesting output. quantum computer can do it polynomial time and let me show you how here's how it is in a nutshell you pick a random x between 0 and n that's easy you say if the gcd the greatest common divisor between x and n is not 1 you just found a factor you win. We find the smallest integer r such that x raised to the r is is congruent to one mod n okay so that uh you know basically is doing modulo multiply that's really hard to do well. With a quantum computer what we can do and unfortunately i guess i don't have time to do this because we're running out of time but i can set up a situation where my input to my algorithm is all the possible k's uh if i take a bunch of values and i compute uh the the value x to that value and i add them all together as a superposition and i do a fourier transform what i'll find is that x to the r congruent to one as i have r go through all its possible values. actually investigated if you were to build uh that factoring algorithm and you could do it as quantum circuits that could run on a quantum computer what would that look like. We actually investigated ways of optimizing that and we could actually look at performance of different options for the shortest factoring algorithms. So we built a cad tool to do that so um i i don't know i think it's a pretty interesting area right now and there's a lot of interest in it all right so um sorry i kept you guys way over but this is the last lecture i figured if anybody was interested. i think it's it's pretty exciting project we got working on it if anybody's interested in that and then we told you a little bit about quantum computing and uh feel free to come ask me or also look at 151 or 191 excuse me um which is an interesting class on quantum computing all right well thank you everybody sorry for going way over today thank you for those of you that stuck around and uh i hope you have a good uh finalizing of project three andThose of you listening in cyberspace later as well you are all great.

ROUGE-1: 56.64, ROUGE-2: 54.85, ROUGE-L: 55.42
BERTScore: 76.22

==============================================
==================== [66/100] ====================
Summary:
see then it will go right but some extra amount of plasma or plasma fluid most of it enters into space or DC and then goes back but some which remains extra which is no drain back into sinusoids that will drain into the periphery and that will convert into length right so lymph is moving from the center to the periphery now in between the hepatocytes the parasites are draining on this side secreting on the other side what does what is the substance bile and bile is moving to the center. Early astrologists did not recognize the lymphatics so they thought there are only three system there is a branch of portal or this branch of puerto bean. At the outer corners of the hexagonal lobules we have portal areas in every portal area. Blood from both system drain into a paddock sinusoids which is moving from the periphery to the center then it collect into central vein central vein come out and they drain into sub level or wane and eventually into a hepatic vein.

ROUGE-1: 26.81, ROUGE-2: 25.64, ROUGE-L: 26.51
BERTScore: 72.96

==============================================
==================== [67/100] ====================
Summary:
Causality says that the policy at time t prime can't affect the reward at another time step t if t is less than t prime. This is another way of saying that what you do now is not going to change the reward that you've got in the past now. In the next portion of today's lecture we're going to talk about how we can modify the policy gradient uh calculation to reduce its variance and in this way obtain a version of the policy gradients that can be used as a practical reinforcement learning algorithm. always true for any process where time flows forward the only way this would not be true is if you had time travel and you could take an action or travel back into the past and change your action but we're not allowed to do that all right. i'm going to claim that the policy gradient that i've derived so far does not actually make use of this assumption and that it can be modified to utilize this assumption. i've simply rewritten it and what i've done here is i use the distributive property to distribute the sum over rewards into thesum over grad log pies. over time steps from 1 to capital t of grad log pi at that time step multiplied by another sum over another variable t prime. At every time step i multiply the grand log probability of the action by the sum of rewards over all time steps in the past present and future. If we generate enough samples eventually we should see that all the rewards at time steps t prime less than t will average out to a multiplier of zero and they will not affect the log probability at this time step in fact we can prove that this is true. the proof is somewhat involved so i won't go through it here but once we show that this is true then we can simply change the summation of rewards. Instead of summing from t prime equals one to capital t simply sum from t Prime equals t to capitalt basically discard all the rewards in the past because we know the current policy can't affect them now. For a finite sample size removing all those rewards from the past will actually change your estimator but it will still be unbiased so this is the only change that we made. that is it's the rewards from now until the end of time which means that it refers to the rewards that you have yet to collect basically all the rewards except for the ones in the past or the reward to go. We will get much more into this in the next lecture when we talk about extra critical algorithms but for now we'll just use a similar symbol with a hat on top to note that it's a single sample estimate all right now the causality trick that i described before you can always use it you'll use it in homework two. think back to this cartoon that we had where we collect some trajectories and we evaluate the rewards and then we try to make the good ones more likely and the bad ones less likely that seemed like a very straightforward elegant way to formalize trial and error learning as a grain ascend procedure but is this actually what policy gradients do well intuitively? We can show that subtracting a constant b from your rewards in policy gradient will not actually change the gradient in expectation although it will change its variance meaning that for any b doing this trick will keep your grading estimator unbiased. this is equal to b times the gradient with respect to theta of one but the grading withrespect to thea of one is zero because one doesn't depend on theta. For a finite number of samples it's not equal to zero so what this means is that subtracting b will remain will keep our policy gradient unbiased but it will actually alter its variance so subtracting a by a baseline is unbiased in expectation the average reward which is what i'm using here turns out to not actually be the best baseline but it's actually pretty good. baseline to optimally minimize variance so to start with we're going to write down variance. The variance of the policy gradient is equal to the expected value of the quantity inside the bracket squared minus the whole expected value squared. The first term in the variance doesn't depend on b but the first term does so then in order to find the optimal b i'm going towrite down the derivative d var db and solve for the best b. The baseline actually depends on the gradient which means that if the gradient is a vector with multiple dimensions if you have multiple parameters you like to have a different baseline for every entry in the gradient. different policy parameters you'll have one value of the baseline for parameter one a different value for parameter two. In practice we often don't use the optimal variance we just uh sorry we typically just use the expected reward but if you want the optimal baseline this is how you would get it all right so to review what we've covered so far we talked about the high variance of policy gradients algorithms. We talked about how we can lower that variance by exploiting the fact that present actions don't affect past rewards and we can use baselines which are also unbiased.

ROUGE-1: 52.37, ROUGE-2: 50.91, ROUGE-L: 50.11
BERTScore: 75.61

==============================================
==================== [68/100] ====================
Summary:
Today we're gonna talk about learning in the setting of games. So what does learning mean? How do we learn those evaluation functions that we talked about? And then, er, towards the end of the lecture, we wanna talk a little [NOISE] bit about variations of the game- the games we have talked about. So, uh, how about if you have- how about the cases where we have simultaneous games or non-zero-sum games? So that's the, that's the plan for today. So I'm gonna start with a question that you're actually going to talk about it towards the end of the lecture, but it's a good motivation. So, uh, think [NOISE] about a setting where we have a simultaneous two-player zero-sum game. And an example of that is rock, paper, scissors. So can you still be optimal if you reveal your strategy? So lets say you're playing with someone. If you tell them what your strategy is, can youstill be optimal? That's the question. In the game of chase- che- and chess, you have this evaluation function that can depend on the number of pieces you have, the mobility of your pieces. Maybe the safety of your king, central control, all these various things that you might care about. So the idea of using an evaluation function was to speed things up. And, and potentially, a designer can come in and say, "Well, I care about nine times more about how many pawns I have." So the hand-designer can actually hand- design these things and write down these weights. "I care about the number of kings and queens and these sort of things that I have, but I don't know how much I care about them. And I actually wanna learn that evaluation function. Like what the weights should be." "So to do that, I can write my evaluation function, eval of S, as, as this V as a function of state parameterized by, by weights Ws" "And, and my goal is to figure out what these Ws, what these weights are. And ideally I wanna learning that from some data" In the first part of the lecture, we're going to look at backgammon. And then towards the end of the class, we will talk about simultaneous games and non-zero-sum games. And, and that kind of introduces to this, this, um, temporal difference learning which we're gonna discuss in a second. It's very similar to Q-learning. Okay. So let's think about an example and I'm going to focus on the linear classifier way of looking at this just for simplicity. can actually, like, roll two dice and based on the outcome of your dice, you move your pieces various, various amounts to, to various columns. So your goal is to get all your pieces off the board. But if you have only one piece and your opponent gets on top of you, they can push you to the bar and you have to start again. Um, there are a bunch of rules about it. Read it, read about it on Wikipedia if you're interested. But you are going to look at a simplified version of it. maybe like the location of the X's and O's. The number of them. Maybe fraction of X's or O's that are removed, whose turn it is. These features, kind of, explain what the sport looks like or how good this board is. And what we wanna do is we wanna figure out what, what are the weights that we should put for each one of these features and how much we should care about, uh, each one. So, so that is the goal of learning here. somewhere. So, so one idea that we can use here is we can try to generate data based on our current policy pi agent or pi opponent, which is based onOur current estimate of what V is. Right. So currently, I might have some idea of what this V function is. It might be a very bad idea ofwhat V is, but that's okay. I can just start with that and starting with, with that V function that I currently have, what I can do is I can, I can call arg max of V over successors of s and a to get a policy for my agent. "We generate episodes and then from these episodes, we want to learn. These episodes look like state action reward states and then they keep going until we get a full episode" "The reward is going to be 0 throughout the episode until the very end of- end of the game. Until we end the episode and we might get some reward at that point or we might not" "We go over them to make things better and better. So that's, kind of, the key idea" So s, take an action, you get a reward. You go to some s prime from that and you have some prediction. Your prediction is your current, like, your current V function. And then we had a target that you're trying to get to. And my target, which is kind- kind of acts as a label, is going to be equal to my reward, the reward that I'm getting. So I'm gonna treat my target as just like a value, I'm not writing it as a function of w, okay? is simple, right? 2 reduced, 2 gets canceled. Gradient is just this guy, prediction of w, minus target, times the gradient of this inner expression. So the objective function is prediction minus target squared. And then the update is this, this particular update where we move in the negative direction of the gradient. This is, this is what you guys have seen already, okay. All right. So so far so good. Um, so this is the algorithm we're going to use. is the TD learning algorithm. This is all it does. So temporal difference learning, what it does is it picks like these pieces of experience; s, a, r, s prime, and then based on that, it just updates w based on this gradient descent update, difference between prediction and target times the gradient of V, okay? So what if my V of sw is just equal to w dot phi of s, yeah phiof s. So what happens to my update? Minus Eta. between the two? Yeah, so this is very similar to Q learning. There are very minor differences that you'll talk about actually at the end of this section, comparing it to Qlearning. All right. So, so I wanna go over an example, it's kind of like a tedious example but I think it helps going over that and kind of seeing why it works. Especially in the case that the reward is just equal to 0 like throughout an episode. So I want to just go over like one example of this. If you use like, uh, initialize rates do not be zeros which you update throughout instead of just to the end. Yeah. Okay and section two, so S4 and S9 are the same future of activities but you said S4 is S9 [OVERLAPPING]. Uh, this is a made up example, [LAUGHTER] so don't think about this example too much though. Well, is it that possible to have, an end state and not end state have the same feature vector, or no? As one, uh, entry that's always isn't [inaudible] like instead of 1, 2, we have 1, 0 leading to the, the final weight then the weight corresponding to that. Is going to- [OVERLAPPING] Yeah. It will never converge. And that kind of tells you that that entry in your feature vector, you don't care about that. If it is always 0, it doesn't matter what the weight of that entry is. So in general, you wanna have features that are differentiating and, and you're using it in some way. on the relationship between the features and the weights. Uh, they always have to be the same dimension, and what should we be thinking about that would make a good feature for updating the weights specifically, like- So, uh, okay so first off, yes, they need to be always in the same- in dimension cause you are doing this, um, dot-product between them. And then it's usually like hand designed, right. So, so i- i- it, it's not necessarily- you shouldn't think of it as how is it helping my weights. of 10, uh, if you're using the same feature extraction for both, how does that affect the generalized ability of the model, the agent? Yeah, so, so you might choose two, two different features and one of them might be more like so. So there is kind of a trade-off, right? You might get a feature that actually differentiates between different states very well, but then that makes learning longer, that makes it not as generalizable, and then at the end- on the other hand, you might get one that's pretty generalizable but then it might not do these specific things. to 0.25 and 0.75 then it kind of stays there, and you are happy. All right so, so this was just an example of TD learning but this is the update that you have kind of already seen. And then a lot of you have pointed out that this is, this is similar to Q-learning already, right? This is actually pretty similar to update, um, it's very similar, like we have these gradients, and, and the same weight that we have in Q- learning. The idea of learning in games is old. People have been using it. In the case of Backgammon, um, this was around '90s when Tesauro came up with, with an algorithm to solve the game. And he was able to reach human expert play. And then more recently we have been looking at the game of Go. So in 2016, we had AlphaGo, uh, which was using a lot of expert knowledge in addition to ideas from a Monte Carlo tree search and then, in 2017, we have AlphaGo Zero, which wasn't using even expert knowledge. Minimax sca- strategy seemed to be pretty okay when it comes to solving these turn-based games. But not all games are turn- based, right? Like an example of it is rock-paper-scissors. You're all playing at the same time, everyone is playing simultaneously. The question is, how do we go about solving simultaneously, okay? So let's start with, um, a game that is a simplified version of rock- Paper-Scissors. This is called a two-finger Morra game. Game is a one-step game too, so like you're just playing and then you see what you get. So we have pure strategy which is almost like the same thing as, uh, as deterministic. And again the reason I only like talk about one way is we are still in the setting of zero-sum games. So, so I'm trying to like get good things for A. In this case it's not at the end [inaudible] ? Uh, yeah. policies. So a pure strategy is just a single action that you decide to take. We have also this other thing that's called mixed strategy which is equivalent to, to stochastic policies. And what a mixed strategy is is a probability distribution that tells you what's the probability of you choosing A. So, so pure strategies are just actions a's. And then you can have things that are called mixed strategies and they are probabilities of, of choosing action a, okay? All right. game. So, so for this particular case of Two-finger Morra game, let's say someone comes in and says I'm gonna tell you what Pi A is. Policy of agent A is just to always show one. And policy of agent B is this, this mixed strategy which is half the strategy. Pi A chooses action A, Pi B chooses action B times value of choice A and B, summing over all possible a and bs. Okay, so let's look at an actual example for this. time show one, half the time show, show two. And then the question is, what is the value of, of these two policies? How do we compute that? [NOISE] Well, I'm gonna use my payoff matrix, right? So, so 1 times 1 over 2 times the value that we get at 1, 1, which is equal to 2. Ah, so you might be interested in looking at what happens in repeated games. In this class right now we're just talking about this, one step one play. We're playing like zero-sum game um, but we's playing like we'll say, rock-paper-scissors and you just play once. Someone tells me it's pi A and pi B, I can evaluate it. I can know how good pi A is, from the perspective of agent A. But with the challenge here is we are playing simultaneously, so we can't really use the minimax tree. So what should we do? So I'm going to assume we can play sequentially. So that's what I wanna do for now. So right now I'm gonna focus only on pure strategies. I will just consider a setting- very limited setting and see what happens. In a more general case, I'm gonna make a lot of generalizations in this lecture. So I'll show you one example I generalize it, but if you're interested in details of it, like, we can talk about it offline. So, so, so setting is for any fixed mixed strategy Pi A. What I should do as Agent B is I should minimize that value. I should pick Pi B in a way that minimizes that value, and that can be attained by pure strategy. to 7 over 12 here, like these two values end up being equal. Equal, right? [inaudible]. [OVERLAPPING] Uh, none of them are actually equal. The reason that they end up be equal is you are trying to minimize the thing that this guy is trying to maximize. So no matter what your opponent does, like you're gonna get the best thing that you can do. So, so that's kind of the idea. All right. So let let's say I would pick a p that doesn't make these things equal. The key idea here is revealing your optimal mixed strategy does not hurt you which is kind of a cool idea. The proof of that is interesting. If you're interested in looking at the notes, you can use linear programming here. So, so let's summarize what we have talked about so far. Next 10 minutes, I want to spend a little bit of time talking about non-zero-sum games. In real life, you're kind of somewhere in between that, and, and I Want to motivate that by an example. dilemma? Okay. So, uh, so you have two players A or B. Each one of you have an option. You can either testify or you can refuse to testify. So you can- B can testify and A can refusal to testify, and I am going to create this payoff matrix. This payoff matrix is going to have two entries now in each one of these, these cells. And, and why is that? Because we have a non-zero-sum game. Because this was for player A, player B would just get negative of that. different players. So the von Neumann's minimax theorem doesn't really apply here because we don't have the zero-sum game. But do you actually get something a little bit weaker, and that's the idea of Nash equilibrium. So a Nash equilibrium is setup policies Pi star A and Pi star B so that no player has an incentive to change their strategy. So, so what that, that means is if you look at the, the value function from perspective of player A. There's a theorem which is, er, Nash's existence theorem. If you have any finite player game with a finite number of actions, then there exists at least one Nash equilibrium. In a collaborative Two-finger Morra game, it's not a zero-sum game anymore and, and you have two Nash equilibria. And then Prisoner's dilemma is the case where both of them testify. So we just actually solve that using the minimax- von Neumann's minimax theorem. There's a huge literature around different types of games, uh, in game theory and economics. Uh, but we have multi- we also have multiple game values from- depending on whose perspective you are looking at. If you're interested in that, take classes. And yeah, there are other type of games still like Security Games and or resource allocation games that have some characteristics that are similar to things we've talked about. And with that, I'll see you guys next time.equilibria.com.

ROUGE-1: 31.86, ROUGE-2: 31.00, ROUGE-L: 30.39
BERTScore: 73.07

==============================================
==================== [69/100] ====================
Summary:
The famous example was posed by Comte de Buffon back in the 18th century. It marks the beginning of a subject that is known as the subject of geometric probability. The problem is pretty simple. We take a needle that has a certain length-- l-- and we throw it at random on the plane. The needle might fall this way, so that it doesn't cross any line, or it might fall that way, and it ends up crossing one of the lines. If the needle is long enough, it might actually end up crossing two of the Lines. much more streamlined. There's not going to be any choices. We just need to consider the event of interest, express it in terms of the random variables that we have in our hands, and then use the probability model to calculate the probability of this particular event. When will the needle intersect the nearest line? This will depend on the following. We have an intersection if and only if the vertical extent-- which is this vertical green segment-- is larger than the distance x. Or equivalently, if x is less than the vertical amount of the needle. our case is four over pi d-- and integrate it over the set of x's and theta's for which the PDF is non-zero. So what are these pairs? This event can occur with any choice of theta. So theta is free to vary from 0 up to pi over 2. How about x? For this event to occur, x can be anything that isNon-negative as long as it is less than or equal to this number. And all we need to do now is to evaluate this double integral. is this 4 with this 2 give us a 2. We have 2l over pi d. And then the integral from 0 to pi over 2 of sine theta. Now the integral of sin theta is minus cosine theTA. And we need to evaluate this at 0 andpi over 2. This turns out to be equal to 1. And this is the final answer to the problem that we have been considering. And now, a curious thought. How can you figure out the number pi? Take your needle, throw it at random a million times, and count the frequency with which the needle ends up crossing the line. So it gives you a good estimate of this particular number. unit cube. So you throw points. Some fault inside. Some fall outside. You count the frequency with which the points happen to be inside your set. And as long as you're throwing the points uniformly over the cube, then the probability of your complicated set is going to be the volume of that set. You estimate the probability by counting the frequencies with which you get points in that set, and so, by using these observed frequencies, you can estimate the volume. It turns out that these days, physicists and many engineers use methods of this kind quite often and in many important applications.

ROUGE-1: 38.25, ROUGE-2: 36.85, ROUGE-L: 38.10
BERTScore: 68.36

==============================================
==================== [70/100] ====================
Summary:
Professor: We had formulated an exact approach using the time evolution operators and diagrams. And well, I think we understood what it means when atoms in the ground state emit photons which are virtually absorbed. So we figured out what is really inside this formalism and what are the processes. What we want to continue discussing today is one problem which you often have such approaches. And this is the problem of resonance. And that means if you write down the perturbative expansion, you have a 0 in the denominator. You have a divergence. I reminded you that in a phenomenological way, you've seen that this problem can be "fixed" by adding an imaginary part to the energy level. I want to show you what are the tools to treat those infinity source divergences in a consistent and a systematic way. And one hint how we have to do it comes by simply taking this energy denominator and expanding it in gamma, simply a Taylor expansion in gamma. And then, we realize gamma is often calculated in second order Fermi's golden rule. That tells us that doing something here probably means infinite orders in a perturbation series. means to sum up an infinite number of diagrams. It's a very elegant way to combine equations with graphical manipulations. So that's our agenda for at least the first part of today. And OK, we want to understand the time evolution of this system. Our tool is a time evolution operator. And at the end of the class on Monday, I told you, well, let's simplify things. Let's get rid of those temporal integrations and multiple integrals by simply doing a Fourier transform. now the starting point for our discussion today. We want to calculate the Fourier transform of the time evolution operator to infinite orders. So unfortunately, [INAUDIBLE]. We should copy this equation. Because we need it. And now we want to iterate it. So the resolving G in 0's order is G0. Now plug G0 into the right hand side of the equation, and you get the first order, G0VG0. I think you've got the idea. It's almost like a geometric series. terms, which are 1 over Z minus Eb. Sometimes, scattering and evolution equations are better formulated when you do it in the complex plane. Just remember, Z is the energy. And it is the initial energy. The initial energy is if it's a ground state and a resonant photon, we have a problem. Because the denominator is 0. So in other words, for resonant excitation, we are interested in the case that Z is on the order of this close to Eb. easy part, which has no divergence, we can make any kind of approximation we want without altering the physics. But the resonant part, this needs special attention. Because if I treat it literally in those expressions, they don't make sense mathematically. Because they cause infinities. But because I think it's just beautiful method, I want to look at this equation and write it down in symbols. So we want to arrive at a diagrammatic representation for this matrix element of the resolvent Gbb. Quantum mechanics is an algebraic equation. We want to figure out which of those expressions include this problematic term exactly twice or three times or four times. So we regroup the terms, and then we see what we can do. Now, I've picked the matrix element Gbb. So that means over here and over here we start out in the state b. So if I write down all terms which contain this resonant term twice, well, we start with a resonance term. And we have to end with a resonantterm, because we have the matrix elements Gbb, which I'm focusing now on. We can go through two vertices. But it can only include dashed lines in between. So we start with that state. We end with a state b. But in between, we can sort of once, twice, three times go through other intermediate states. But we never are allowed to create another divergence. And this infinite sum over all other states-- I don't know how to calculate it yet. But I'll just call it a square box. The square box is the circle plus all terms like this. equations. We call this the function Rb of Z. And it's clear how to go to higher terms. So we've just defined this function R by focusing on two occurrences of the straight line. Well, let's look at higher order terms. What happens when Z minus Eb, the divergent term, comes to the power n? Well, we just dealt with n equals 2. Let's now look at n equals 3. And what I've shown in diagrams above is nothing else than the circle Vbb, the matrix element of the interaction. Professor: R has a real and imaginary part. One is a self energy, and the other one is a decay rate. The real part will be the self energy. Yes, we connect a lot of passwords you may have heard here and there. But the nice thing is no. Because n equals 3, we don't have to find more and more symbols for more complicated sums. We just have to use the same symbols as we have always used. We don't need to change our passwords. means we have to start in state b. We can go through state b one time in the time evolution. And now, between that, we can go from here to there with any combination of states you want. But one thing is not allowed-- to involve the state b because we are focusing on three occurrences of the state B. And everything else other than the stateb has already a symbol. It is the square symbol. So this is the exact representation for n equals 3. non-trivial expression, the function of the kernel, has no divergences. And therefore, because there is no critical part to it, rather simple approximations can be made and lead to physically meaningful results. That's an idea you may see often in physics. You have a theory whether it's something complicated, non-perturbative divergence. But you just rewrite the theory, transform the equations in such a way that structure of the equations now accounts for the physics behind it. then, the perturbative expansion involves no divergent terms and can be performed. So therefore, we are now in a position to make approximations to the function R. And the simplest approximation which we can do is we can just try to see if we can get away with very low order. And let me call this now the triangle. So that would mean the following, that the exact formulation involved-- let me get black-- had a propagator. The state b has to go through multiple squares. This is how it propagates. And an approximate result is now that the squares are replaced by triangles. light scattering. I just go now and apply to an excited atomic state. So the state we are interested in is the atomic state b and no photons. And the property of the atomic. state is obtained when we know the function Gb of Z. And this is the matrix element between state B0B0 and the time. evolution operator. So we are calculating, of course, the Fourier transform of the time evolution of the state b by the. Fourier. transform through the resolvent G. Fermi's golden rule where we-- well, with a little twist-- have the initial state. The dipole interaction or the [? p.a ?] interaction takes us to an intermediate state with a photon with [INAUDIBLE] and polarization epsilon. We propagate in the intermediate state Ea. And now we have to go back with the same matrix element. So therefore the matrix element is squared. And we have a double sum. We sum over all possible states of the photon. The time evolution operator has poles in omega. So we can't just Fourier transform. But what we can do is we can add an imaginary part plus or minus eta. And we can just go around the poles. And then, it becomes mathematically meaningful. And what we're doing here is-- but I'm not really explaining it mathematically-- we have played those tricks here. But I hope it becomes clear if I say what the real and imaginary parts are. So the real part is this matrix element squared, but the imaginary part is also squared. double sum. But what we use is the principle part of it, which is well defined in the theory of complex functions. And it's divergent, but you take a certain symmetric limiting procedure. So the imaginary part gets us Fermi's golden rule. And the real part has a 1 over [INAUDIBLE] dependence. So this is actually nothing else than the AC Stark shift not due to a laser beam, but due to one photon per mode. Because we started with an atom in an excited state. It can emit a photon in any mode. Now creating an AC Stark shift. And this is mathematically the expression. And such AC Stark shifts which appear as self energies, as energy shifts created by the state, this is nothing else than the famous Lamb shift. So that's what we get out here. I have already-- do I in this sum? What we have here is we have this function R in the real and imaginary part, which depends on the energy E. But remember, we worked so hard with diagrams to make sure that the triangle-- first the square, and then the triangle, and this is what we calculate here-- has no resonant structure at the energy Eb. So this replace, neglect E and set, or replace the dependence by E, by taking the value at Eb, this corresponds to the Markov approximation. And by neglecting the energy dependence, we are now saying everything is constant as a function of energy. And that means in the temporal domain that we have a delta function. And we obtained, as promised, the Fourier transform of the time evolution operator, which initially had a divergence at energy b. But by now, calculating the function R, we had a correction, which is a radiative shift, which comes from the real part. imaginary part, which we can approximate by Fermi's golden rule. If we now Fourier transform back and obtain the time evolution of this state, it no longer evolves with the energy Eb. It has a shifted energy by this self energy. But in addition, because of the imaginary part, it has now an exponential decay. But there are two things you should learn. The first thing is that the exponential decay would be different if we had not made the Markov approximation. spectrum of energies. And it's obvious that the properties of this expression where you sum over all states, something will happen when you go past the normal excitation energy or the ionization energy of the atom. So what you can immediately read form here is that exponential decay is a simple approximation. But at very early times, it will break down. Because then, the energy dependence matters. But the longer you wait-- if you wait a few nanoseconds, the relevant part of the Fourier transform is only a small energy or frequency interval around the resonance energy. And then, this approximation is excellent. infinite summation of diagrams, if we had done a perturbative expansion, we would have never obtained exponential decay. We would have obtained some polynominal decay. If you do lowest order perturbation theory, instead of getting an exponential decay, you would just get a linear slope. And if you fix it, I think you get quadratic terms. So it's not really profound what I'm saying. It's pretty much an exponential function is non-perturbative. we have an atom in the ground state, and a photon comes along, and it takes the atom to the excited state b. Then we go back to the same state-- could be also another state-- by emitting a photon k prime epsilon prime. And the relevant matrix element of the time evolution operator, which is the T-matrix, involves now the matrix element, the initial energy minus the intermediate energy. It transfers exactly to the light scattering problem, that we have to include now radiative shifts. to infinite order. If you're off-resonant, you don't have a problem. This extra term delta and gamma, the radiative shift and the line widths only matter when the black term is close to 0. So everything we have done by correcting the naked propagation of the state b by the correct propagation with this infinite emission and reabsorption of virtual photons, this is only needed if the denominator is 0. And then, we have to figure out what else happens.  chapter of diagrams. Until maybe 10, 15 years ago here at MIT, we were not teaching that. And I felt often in discussion with students that a little bit more of a complete picture behind atom photon processes is needed. What I summarized could of course cover a whole semester course in QED and how to do calculation. And if you're interested in mathematical rigor, the green book, Atom-Photon Interactions, is pretty rigorous and still very physical. But on the other hand, many of you experimentalists, I think you should have sort of this picture behind it. many modes. It emits photons and reabsorbs them. And you can often neglect that in the simple description of your experiment. But if you take certain expressions seriously, they would have divergences. And that's what we discussed without this infinite number of processes which happen. Of course, yes, the whole other regime which I should mention is when you can completely neglect the coupling to many modes. If you do Rabi oscillation with resonant interaction, you don't need all that. Because then, you're really looking at discrete states.  chapter-- to give you sort of the fundamental story, the profound story behind the optical Bloch equations. We want to describe a quantum system. But the quantum system is coupled to the environment. And that means we have dissipation. And this is something which is not easily dealt with in simple quantum physics. And so in this section, what I want to address at the most fundamental limit is, what is the step where we go from reversible equation, unitary time evolution, to something called relaxation, which is dissipative. A small system which I just described by Schrodinger's equation, now follows the density matrix equation, has relaxation, the entropy increases, and such. So in other words, we have coupling to the environment. And in this cause in part one, we've dealt with it and looked at vacuum Robi oscillation and a few really neat things. But what happens is that the system is an open quantum system. You can have spontaneous emission. And if your mirrors are not 100.00% reflectivity, some light leaks out. So this is our system. In general, if you write down the total Hamiltonian and do the time evolution, something will come out which, in general, is very complicated, very entangled. So you have to know, to keep track of all the photons, which have been scattered in the lifetime of an atom. So often, what we do is we simply put the photons in a trash can. We trash them. We're not interested in what the photons are doing. The vacuum chamber has taken care of them. So all that we are interested in is how do we describe the atomic system? emitted. But those million photons which have been emitted into the environment, they change, of course. They change this density matrix of the atom. And if you find a description, the master equation is including with extra terms what those photons have done. Maybe this sounds very abstract. But in the end, you will find that maybe photons which emitted produce some damping. Or if you put atoms in molasses, the atomic motion comes to a standstill. So that's the idea. it causes stimulated emission. And it causes absorption described by the Einstein b coefficient. And you have a similar equation for the excited state. So this is clearly the semi-classical limit of what we want to accomplish. We want to know more. We really want to find the full quantum time evolution. We have to be careful. The time evolution as a Hamiltonian, if you now bring in the environment, cannot be simply included by adding an imaginary term. This here violates the unitary time Evolution. Consistent with the loss of quantum physics. If you find an equation which describes the atomic system, it will be a requirement that a density matrix turns into a densityMatrix. And that is actually extremely restrictive. This is actually something which is the frontier of our field. We have some evolution of an atomic system by coupling it to the environment. But can you engineer the environment in such a way that it does something really fancy to your system? Well, you can dream of it. But you dreams are restricted by the mathematical structure of all possible master equations in the world. I will be telling you is also sort of relevant to understand this sort of frontier in our field which is called environment engineering. OK, density matrix-- good, five more minutes. So what we have is we have a system. And we have this environment. And what we are exchanging with the environment is both energy, but also entropy. And so when we transfer energy or heat, there is a corresponding change in energy. And it's a general property of all quantum systems. It's a consequence of the fluctuation dissipation principle. display that, that we do not get any form of damping without at least the fundamental quantum noise. So what we need is we need a description of the quantum noise, which comes from coupling to the environment. The tool which we use for that is the density matrix. The density matrix can be written as a probabilistic sum over states. This will actually play a major role. We will make certain models for damping. And it's really beautiful. On Monday, I will give you the beam splitter model for the optical Bloch equation. have certain quantum states k, and we just add them up probabilistically, this kind of microscopic interpretation of the density matrix is called unravelling. It's sort of writing it as a specific diagonal sum over states. But those unravellings are not unique. They describe one possibility. But there are other possibilities. And you can see by inspection that this will do the trick. So we'll talk a lot about unravelled of thedensity matrix. That's why I want to say up front, that the same density matrix can be thought of as being created by different processes. But this actually makes it even more powerful. processes. OK, any last questions? Well then, let's enjoy the open house with incoming graduate students, and I'll see you on Monday. I'll be back on Monday to talk to you about the classes we'll be teaching next year. Back to Mail Online home. back to the page you came from. Click here to read the full transcript of this interview. Back To the pageyou came from, click here to see the full Transcript of this Interview. Back in the page, please share your questions and comments.

ROUGE-1: 55.35, ROUGE-2: 53.34, ROUGE-L: 53.46
BERTScore: 73.39

==============================================
==================== [71/100] ====================
Summary:
David KAISER: In the last few class sessions, we were looking at some changes in high energy particle theory. And then in our most recent class session, we looked at some of the shifts within the fields of study. And today, we're going to focus on a kind of example of that new subfield, a relatively new sub field that's known as inflationary cosmology or simply cosmic inflation. So it's a framework for trying to understand the evolution of our universe over a huge expanse of time, increasingly using tools at the interface. lecture notes on the Canvas site which go into a little bit more detail of some of these parts from the lecture. Again, strictly for your own interest as your interest and time allows. There's some more material there. And again, I'd be glad to chat more about this if questions come up beyond that. OK. So oftentimes, astronomers will describe the most salient features of our universe in terms of what they call large scale structure. It's really quite remarkable. And this [CLEARS THROAT] picture's been emerging really over a century, for 100 years or even more. or our own Milky Way galaxy. Or if we zoom in even closer to home with the solar system or even really in human terms, there are concentrations of enormous matter and energy and activity separated by huge voids. It turns out that ordinary gravity-- even Newtonian gravity, let alone Einstein's fancier version that we looked at in class, general theory of relativity-- that these gravitational frameworks are sufficient to help us make sense of this hierarchy of scales, of structure across large distance scales. Astronomers have been trying to make Einstein's theory of gravity more precise and more quantitative. The other main ingredient has been some prevailing understanding of matter, especially matter at very high energies and temperatures. So with those two ingredients, the goal has been, again, for many decades to account for the observational features of our universe even on very large scales. The goal is to build a toy model of an entire universe that might satisfy or might be governed by Einstein's field equations. It would depend on the amount of stuff, depending on the distribution of matter and energy, then depending on whether there was more than some critical value. a critical value that came from the equations themselves above that, an overdense region, space itself would warp back onto itself like a closed sphere. If you had less stuff per volume, if the universe were underdense compared to that critical value, then, in fact, the universe would open up away from itself. You'd have a hyperbolic solution or an open geometry with negative curvature. Only if the amount of stuff perVolume were exactly equal to the critical value would the sections of space be flat. Einstein thought that was horrible. He had a very strong aesthetic and philosophical preference for a universe that had no beginning that was simply static. But some of his colleagues who began pursuing these cosmological solutions began to realize that the universe could not only have a shape at a given moment in time, but the shape could change over time. You could have expanding or collapsing solutions, also strictly consistent with Einstein's equations. And they could apply not only to local physics like the warping of spacetime outside a massive object like the sun. for an infinite expanse of time. But other colleagues showed at least it was consistent with his own equations to have universes that would change over time, that could either expand or contract. That was actually a prediction made by some of these colleagues even before some empirical evidence began to come in starting in the late 1920s. Hubble found this remarkable trend that the further away from us a given galaxy was, the faster it tended to be moving away from me further still. So you can actually then work backwards and say for how long has our observable universe been stretching? When did this stretching or expanding phase begin? Georges Lemaitre was at the forefront of this work, starting in the 1920s and throughout the 1930s. He was an ordained Catholic priest and an MIT trained PhD astrophysicist. He studied briefly in Cambridge, England with one of the first converge to general relativity, Arthur Eddington. And then he came to MIT to finish his PhD and then was finding many of these solutions to Einstein's field equations even before Einstein did. And it's consistent with the beginning of that expansion being not quite 14 billion years ago, billions of years ago. relevant in the light of data like Edwin Hubble's about the expanding universe. Lemaitre was one of the first to start thinking about playing that filmstrip backwards to say if things are moving further apart from each other on average today, and if the universe in general is expanding today, then was it, in fact, smaller at earlier times? And what if you ride that all the way back? Was there a primeval moment, was there a single moment when all the matter of the universe, at least all of the matter that we can see, was actually on top of each other? After the Second World War, new groups began coming back to these somewhat old questions. Some of the newer groups had experience with things like the Manhattan Project and in general were much better versed in things like nuclear physics than had been known even in Lemaitre's day. One of the most active groups soon after the war was based at the advanced-- excuse me-- the Applied Physics Laboratory. Here's a famous composite photograph. They're making a not so subtle gesture to the fact that Gamow was widely rumored to enjoy his drink. So his head is emerging from the vapors of Cointreau, of a liqueur. The Big Bang model suggests that the universe was very hot and dense at early times. The conditions in which these elementary particles would find themselves should be quite different than what we find commonly around ourselves today. Temperature, after all, is just a measure of kinetic energy of motion. So you have a very high temperature. It could've been, for example, higher than the binding energy of stable hydrogen atoms. So if that were the case, then every time some positively charged nuclear particle like even just a single proton would approach or be in proximity to a negatively charged electron, they might begin to form a stable electrically neutral hydrogen atom. At early times in cosmic history, the universe should've been opaque. You literally wouldn't have been able to see anything because the mean free path of any given photon would be very, very short. The photons would each be trapped, kicked like soccer balls between all these loose electric charges. Light can't propagate in a charged plasma because it's always bouncing between these very nearby free electric charge. So they could calculate how to make a proton. Proton would then piece all this together. When would that effect go away? Well, when the average or ambient temperature fell below the average binding energy of a single hydrogen atom-- and that would happen at a distinct moment in cosmic history. So as the volume of space stretches, as you have an expanding universe, the average temperature of all the stuff inside it should fall. It should fall in a quantitatively calculable way, again, using Einstein's equations. So again, they put numbers to that and say, well, at a particular moment in time, now using the modern values-- they had the right idea. years, after the start of that stretch after that primeval atom begins to expand, the ambient or average temperature of all the junk inside that universe should've fallen below this Coulomb attractive energy for neutral hydrogen. At that moment, the average energy per photon or per elementary particle would fall. So only at that time, a new phase in the universe would begin to unfold. The universe would be filled with neutral atoms of hydrogen. And now you have a mean free path for light that's arbitrarily long. energy continues to redshift. They lose energy as the universe continues to expand. So the energy of those photons would've started at the equivalent of around 10,000 degrees Kelvin and now today would be much, much,much lower than that. The universe has been expanding and draining that average energy per particle over time [CLEARS THROAT] so that today the universe should be filled with this remnant glow. This is all work that they predict around 1948, '49, '50, Gamov, Herman, and Alpher. out I don't attend dance parties very often. This is what the internet tells me they look like. If you just Google "dance party" and throw away the bad pictures-- anyway. So at early times, the DJ's playing some raucous house music, and everyone's just jostling around. The average energy per dancer is very high. That's like the charged particles where the mean free path is effectively zero. No one could cross that dance floor. And then at a calculable moment, if the DJ knows what she's doing, she'll put on some slow music. And you start having couples form like in Harry Potter at the Yule Ball. Gamov, Alpher, and Herman were putting real numbers to to try to make sense of these different phases of the very early universe. They predicted as early as 1948 that there should be this remnant glow from the Big Bang. And the question was, where is it? Well, almost 20 years later, two radial physicists working at Bell Labs, Robert Wilson and Arno Penzias, were using a new horn antenna sensitive to radial microwave and radial band frequencies. This was basically left over from the early telecommunications age. actually given time on this telescope not only to fine tune the corporate program for telephonics, but also to conduct actual radial astronomy. This should've been among the most precise instruments available on the planet for that band of the spectrum. And they couldn't get rid of a residual hum. At one point, they climbed inside that huge horn antenna on their hands and knees to scrub out what they graciously called special dielectric materials from pigeons who had made a nest in there. in Southern Jersey. They were close to Princeton. They all got together. They said, oh, what you found is actually the remnant glow from the Big Bang. This residual hum in your receiver consistent with an energy of about three degrees above zero, three degrees Kelvin. The average energy per photon had fallen steadily since the time when they were first released in that early dance party. Soon afterwards, they were very soon afterwards awarded the Nobel Prize for actually detecting evidence of the Big. Bang. The idea was the whole universe is filled in the early times with very high energy particles that are at early, early times too high energy to form stable, electrically neutral atoms. And so from every part of space, from every single direction in the sky, those photons began to move freely at this single moment in time. So basically, the universe should've been filled with light, originally avery high energy. And then actually the energy of that light should be falling as the container expands, so as the average energy inside that balloon goes down. a galaxy there, a quasar, a particular bright star in our neighborhood. The photons were everywhere. And it's like sitting in a bathtub full of these photons. And they're just losing their energy as the overall size of space continues to grow. The idea was that there should be-- so it's not just that they should have a particular temperature. They should be everywhere in the sky was the idea, a uniform pattern. So if they could point that radial telescope in any direction, and they should find more or less the same signal, which is indeed what they were finding. everywhere. So every part of space that we could see today once had been at the Big Bang, so to speak. The Big Bang happened there. It happened at x equals 0, and x equals 1, equals 2. But I say all that as if that's obvious. It's not obvious. I'd be glad to chat more about it. But that's the kind of reckoning that people like Lemaitre got very comfortable with starting in the '20s and '30s. This day or let's just say earnest disagreement over what's called the cosmic distance ladder. We can get the velocity from these very fancy spectroscopic-- I say we. The people who do it are actually astronomers. They kindly share their information. I don't know how to do it well. But one can do it very, very well. What's hard to do is to calibrate. How far away is that object right now, let alone how quickly is it continuing to move away? Astronomer Hubble measured a much quicker average rate of expansion than what we have mostly settled on today. The picture was enough to get a small number of people to pay attention to Georges Lemaitre's otherwise quite obscure mathematical solutions. This is actually called conformal time, which might remind you of our beloved friends, the 19th century Cambridge Wranglers. We're really doing a very similar thing here, to adopt coordinates for the rate at which time takes into account changing rates over time. Robert Dicke was an expert in microwave electronics, a radar Rad Lab veteran. He went back to Princeton and became very interested in general relativity and cosmology. In 1961, he published this alternate to Einstein's own theory of gravity, the Brans-Dicke theory ofgravity. He introduced this conundrum in 1969, so soon after the discovery of the cosmic microwave background radiation when people began to take the Big Bang model more and more seriously, including Robert Dicske. stuff per volume, the actual density of matter and energy per volume. If omega is larger than 1, you have more stuff for volume. You expect it's open or hyperbolic geometry. So far so good. Then Dicke plugged this quantity into Einstein's own equations. A universe should generically become more and more different from flat over time. And yet a measurement of anywhere near 1 today suggested that it had to have been exponentially close to 1 at early times. And that seems like this very strange or unexplained fine tuning. years later, Dicke and Peebles introduced the second big conundrum. And this one's called the horizon problem. So now let's go back to this very convenient, conformal diagram. I'm mapping the history of the universe using comoving distances. So I've taken into account that universal stretching of space and that variable clock rate, that conformal time. According to this, we should be receiving these microwave photons today from literally every direction in the sky. This goes back to Steven's question. Imagine you have a three dimensional version of this. Einstein's theory says light travels at a fixed speed at least according to Einstein's theory. So if the universe has only been around for so long, then light could only have traveled so far. That's called the horizon distance. What's the furthest possible distance that a light beam could've traveled traveling at that constant speed of light for as long as it was able to? So even though an actual physical light beam couldn't have traveled because the universe was optically opaque, any information, any physical signal, any force, anything that is limited by Einstein's speed limit should only be able to travel up to and limited by the speed oflight. When the microwave background photons began their journey when they first began to free stream, the universe was still so young that the furthest possible distance that any causal influence should've been able to travel was a tiny fraction of the distance across which we measure remarkably uniform signals on the sky today. That became known as the horizon problem. And this was heightened as more and more data came in. It became clear that signal really is uniform to one part in 100,000. It was at 1,000th of 1%. That signal is uniform across every direction we look in the sky. The Big Bang model has still had to assume by fiat with no real explanation that there was some initial lumpiness, there's some inhomogeneity that over time could then grow to become this cascading hierarchy of scales. So we'd have super clusters of galaxies separated by huge voids and all the rest. That's the point of this series of ping pong balls distributed through space. And that's what it's like to have these causally disjoint regions emitting these photons with the exact same energy. the Big Bang model had some amazing successes but some pretty stubborn quandaries as well. So I'll pause there again and ask the questions about that. Any questions on the shortcomings of the Big Bang as people began articulating them throughout the '60s and '70s? Feel free to jump in or use the chat or either way. And again, there's more on the quantitative details of that in that optional primer you can find on the Canvas site. So Fisher asks, is it useful to think of the universe as spherical still? Yeah. These pictures get pretty hard. like circa 1980. Here's a very young smiling Alan approximately 40 years ago. He was wondering about these questions as well as we'll see in a moment. But he was, however, coming at this having been trained at MIT in particle theory. He wasn't trained in relativity or cosmology. And he was much more the same generation as Tony Zee, whose work we talked about briefly in the previous lecture. When Alan was in graduate school, he was studying high energy physics. He wound up doing a series of postdoctoral studies. but he was haphazardly encountering some of those questions, again, very much like Tony Zee around the same time. What Alan was interested in was in things like spontaneous symmetry breaking and the Higgs mechanism. And he was wondering about shapes for the potential energy function of that Higgs field that might have a extra structure. There might be a kind of dimple to that energy function. We could imagine theHiggs field getting temporarily stuck at some metastable state at the origin of its own potential energyfunction. Einstein's notebook is now on display in the Adler Planetarium in Chicago. He realized that this kind of feature could actually lead to a cosmologically distinct kind of evolution. If the energy density, the stuff per volume, remains constant, then very counterintuitively, you have a runaway growth in the size of space. That stretch function, the scale factor going back just to Einstein's equations, will grow exponentially quickly, will have a period of accelerated expansion during which universe won't just get bigger. even as the volume grows exponentially. That could happen. Alan began wondering if you have this weird state of matter that was at least hypothetical and of right interest to particle physicists. Alex, I'm going to skip the monopolar problem, but it comes from this discussion as well. And I'd be delighted to chat more about that if you'd like afterwards. But in the interest of time, Alan was worried about some exotic features from these Higgs fields that can get twisted up in some topological shape. But he was really just wondering what happens if the universe gets stuck even temporarily. equations exactly in the form that he began learning from Bob Dicke from that series of lectures, then you have these very different solutions for the average size of space. It grows exponentially quickly. And as Alan and others were quick to confirm, this happens very naturally, or at least it's a kind of feature that one stumbles upon readily, if when studying these exotic Higgs-like fields from particle physics. And then again, realizing that if you study the dynamics, the behavior of these exotic quantum fields like a Higgs field. in a stretching space time, if you take that stretching of space seriously, then you don't even need to cook up those exotic Higgs-like potentials that Alan was first thinking about. Quite generically, you'll have a damped oscillator behavior. This comes from the fact that space itself is stretching. And that alone it turns out is enough to find these self-consistent solutions in which the field moves very slowly. You can imagine it rolling down this hill, rolling down-- sorry-- rolling down slowly as a function of time. The latest measurement from the Planck collaboration using a satellite is that this parameter in our actual universe today is 1 to better than a percent level accuracy. In grad school, it looked very much like omega was 0.3. And if you squinted at it, you could maybe make it 0.35. It was not 1 according to the best. In more quantitative detail in the primer, we'll go into more detail about the new measurement in a few minutes. We'll be back next week with a look at some of the other things we've learned about the universe this week. If inflation happened, there should've been a very brief period before what had previously been called the Big Bang. So we're adding more real estate along our time axis. We're unfurling a little bit extra time that hadn't been taken into account in the standard Big Bang model. So therefore, you could have the horizon distance, the maximum causal distance, becomes much larger than the smoothness scale that we measure. In fact, it could be much, much larger, exponentially larger. first papers on inflation. By 1982, '83, pretty early on, people realized that not only would you have a gross feature of the evolution of those exotic particle physics-like fields. They should also have quantum wiggles because how could they not because they should be subject to the uncertainty principle. These are quantum fields evolving in a dynamical spacetime. But you can actually take into account that frictional damping, the stretching of space, and the reaction of that jittering trampoline. moment, that field would be subject to slight, slight quantum fluctuations in the distribution of energy across space. That starts to yield this tiny little fluctuation in why there's slightly more matter and energy in this region of space than the other one. So now those very tiny quantum scale fluctuations get stretched as the whole universe stretches. As the scale factor grows exponentially, you have the average length between the distance between crests of those tiny wiggles get stretched to galactic and even super galactic scales all within that blink of an eye. higher energy photons in the CMB and slightly lower energy photons. The regions of the sky from which these photons were emitted are telling us about the very, very tiny unevenness in the distribution of matter and energy. There's a tiny, tiny little excess gravitational potential. So the photons we receive today had to spend less energy gravitationally to overcome that. They should have slightly more energy on average today than the average. We should receive it today as being a little less energy than average, very slightly less. ground based measurements as well. And each of these came out 10 years apart with an increase of about a factor of 30 in the angular resolution of the sky. They were the first ones to measure these tiny, tiny fluctuations on the order of about one part in 100,000 but over huge scales. It was like they had very poor eyeglasses. The first of these released their data in September 1992. I was a senior that year. And the [INAUDIBLE] team led actually in part by our own Rai Weiss. solid green line is the generic prediction from the simplest models of inflation, what's the pattern of bumps and wiggles on the sky you should see today. The red dots are the actual observations from Planck team. And in many cases, the error bars are expanded so we can see them with our naked eye. So now not only do we know do we live in a universe that is indistinguishable from flat as inflation suggests we should, but the actual pattern of those wiggled matches predictions to, again, better than a percent level accuracy. should be slightly more or less energetic depending on the quantum fluctuations of that Higgs-like field. There should be primordial gravitational waves as well. This is now much like the waves that Rai and his huge team found locally from the collision of, say, black holes. Inflation says similar kinds of things should've been happening in the earliest moments everywhere in space through this very violent, rapid stretching of space. So a version of these were found by the LIGO collaboration and announced early in 2016. These are not primordial. While atoms are forming, gravity waves would be rippling through them. That should yield a characteristic twisting or curl pattern of polarization in that cosmic microwave background radiation. In March of 2014, a team using the BICEP satellite at the South Pole announced they had actually measured exactly that corkscrew pattern. Unfortunately, pretty soon after that, it turned out the BiceP team had measured data consistent with local noise. This is from their now famous or infamous paper. We had a celebration here at MIT. Many of my friends on the BICEP team managed to find out the Milky Way galaxy is dusty, which we knew. So basically, the signal they had hoped to measure was actually swamped by foregrounds they had not yet been able to control. And this was found by a number of very sophisticated analyzes soon afterwards. So it remains an open question to this day whether these primordial curling, twisting patterns really can be detected. Maybe there's such small magnitude, it'll evade our detection. We don't know. makes specific predictions for what we should see on the sky today, including very minute statistical predictions for things like the cosmic microwave background radiation. The simplest models fit to unbelievable accuracy despite what my mean dormmates used to say in the mid '90s. So why is the universe lumpy? Why is this cascade of scales? Because space time is wiggly, and matter is jiggly. Now, there's an alternate hypothesis, my final set of slides. I mentioned this last time. And I just want to make it clear. why the universe is so messy is actually because Alan's been generating the mess in his own office, and it's expanded to cosmic scales. So if you want to study that part of today's lecture, it's probably the most important lesson, you'll ever take away. And I'll be glad to stay a bit longer if people have questions. Again, I'm sorry for running late. Feel free to drop off if you need. Any questions on that? The photos in Alan's office are on Canvas.

ROUGE-1: 48.35, ROUGE-2: 46.48, ROUGE-L: 45.68
BERTScore: 66.11

==============================================
==================== [72/100] ====================
Summary:
The Peloponnesian War was fought in 431 BC. After the war, Spartan power had grown to an unprecedented degree. For the first time there were lots of Spartans, who had lots of money. The Spartans had choices that they could take. They could either stay in the Pelop onnesus, or they could contest it in their power to control the entire Greek world in the east. Or they could have some control of the Aegean and the Hellespont. Lysander was at the height of his power and influence, and I guess it's fair to say, he reached heights that no mortal ever had reached in the Greek world. He placed a Spartan garrison, or at least a Peloponnesian garrison in that city led by a Spartan commander called a harmost. This newly founded Spartan Empire was different from the Athenian Empire in a variety of ways. On the one hand, this new empire under Lysander had no purpose and it was not voluntary in any shape, manner or form. Law of Epitadeus allowed people to buy influence and power in Sparta. Money, of course, allowed for corruption. There was jealousy and resentment and fear at Sparta that something bad was going to happen to the Spartan way of life. Pausanias and his tradionalists bided their time for the opportunity to put a spike into this development. There were other things that were flowing from what I've already described that were threatening the traditional character of Spartan life. I'd like to shift the scene to Athens, which had been the empire that the Greeks had ever seen. the great rhetorician and sophist Gorgias and he was also in the circle of Socrates, along with Plato and Xenophon and various other bright young men of the upper classes in Athens. Also, he was a poet, an orator himself, a philosopher and so on and some of his fragments remain for us to look at. But one thing that he was by 404 was a bitter enemy of the democracy. He had been exiled or had voluntarily taken exile, in order to get away from the democracy, and was determined now that there should be no democracy in Greece. kind of idiotic idea that a democracy would come up with so that democracy itself was seen to be inherently wicked. Lest you think there's something special about that, that's such a characteristic of the human race. So, that was the basic widespread view of what was natural in the Greek world. Now, you add to that that they've just lost this terrible war and you could point to what seemed to you to be both a wickedness and foolishness. How in the world could anybody think democracy was a good thing after that? had to do with the rightness or the wrongness of wisdom of the foolishness of the kinds of arrangements that you had. Critias, in any case, was determined that Athens in the future would not be a democracy. In fact, it looks like he was very much taken with the virtues of Sparta, because Sparta had won the war. So, it's easy to say the characteristics that the Spartan state had must be good ones, because they can do the most critical thing that a state can do, win in competition with the other. The Thirty ruled between September of 404 and May of 403, just a matter of months as it turned out. They established a council of 500--well, that's the same number as the Athenian council, but it was quite different. It was made up of extreme oligarchs; they were given judicial powers. Men who were identified as sycophants, and the Greek use of that term, was widely unpopular. They were very unpopular and the Thirty began with an act that was not only unpopular, but also limited to a certain portion of the population. The Thirty limited citizenship, active participation in the government of any kind to only 3,000 Athenians out of what would have been at least 21,000 and probably more. Only these had citizen rights. The rest of the Athenians did not. Theramenes didn't like that. This was far too narrow and far too troubling for the future for Theramene. And so that's why Krentz suggests that this is not an accident; that it's a conscious effort to model the future Athenian state upon the great successful, admirable, Spartan state. people to death just because they were rich, so that they could take their money away and this of course increased the amount of resistance on unhappiness. A small, I want to emphasize small, very small group of Athenians fled the city and went into exile to neighboring cities. The cities that were most receptive to these anti-Thirty, anti-oligarchical,Anti-Spartan people were Corinth, Megara, and Thebes. They are both angry at the Spartans and I think fearful that the Sparta that is arising now will be a menace to their autonomy. and Attica, a placed called Phyle, and built a fort there to which they hoped other discontented Athenians would flee and join them in the resistance. To my mind, it is helpful to think about France in June of 1940 after the Germans had defeated France and occupied part of it and left the other part unoccupied, but absolutely beholden to the Nazi Regime. It was a terrifying prospect to tackle this regime, which looked like it was unbeatable. Remember, they had been put in place by the Spartans. The Spartans ruled the world. What could anybody expect to change that situation? as much as they could in collaborating with the Germans just to make their--the fate of the Frenchman less hard and to help France in the future in that way. That's the way it was with most Athenians; most Frenchman and most Athenian didn't do either of those things. They kept their heads down and tried to live their lives as best they could. I think what you need to understand is happening and this all puts what Thrasybulus and Anytus, and their friends did in a very special kind of a light. went to fight. Others, like Lysias the orator, used his money to hire mercenary soldiers to fight for the Thrasybulus democrats as well. Well, the first test came in the month of January. There were these seventy guys or so up in the fortress on Phyle. By now the Thirty were worried enough about this nascent army to send an army of their own, much bigger, to try to get them. And really the British--the English fleet didn't do anywhere near as much damage to the Spanish fleet as did the winds. More and more Athenians were becoming hostile to the regime that they had fallen under. When the forces of the Thirty came after Thrasybulus, they just couldn't get there; they were fought off and they had to retreat. As they retreated the seventy came down after them and chased them, and killed them as they fled. They were forced to flee to Eleusis on the northwestern frontier of Attica, and the democrats were in position to take control of the city again. settlement. A moderate group of ten would be chosen in Athens and Pausanias and a commission sent from Sparta to sit with these Athenians and worked out a reconciliation for the future. There would be an amnesty for anybody, no matter what, except for the Thirty themselves. Even the town of Eleusis which they had seized for their own protection as things were going badly, they were allowed to stay there after the settlement. That newly restored democracy behaved with remarkable moderation. A Roman historian of the first century B.C. wrote the following about Thrasybulus: "If excellence were to be weighed by itself, apart from luck, I believe I would rank this man first of all" A few years before 180 A.D., Pausanias the great travel writer of antiquity, wrote his guide to the famous and historic places of ancient Greece. "His is the first grave and after it comes that of Pericles," he says, "in every way the greatest of all famous Athenians"

ROUGE-1: 25.13, ROUGE-2: 23.83, ROUGE-L: 23.62
BERTScore: 58.01

==============================================
==================== [73/100] ====================
Summary:
The coherent state has a simple definition, simple but subtle. It's an eigenstate of the annihilation operator, and it has a complex eigenvalue alpha. The person who popularized those states was Glauber, and he got amply rewarded for that. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu. today is that the coherent state is a complex number. The coherent state has a time evolution. It moves in a circle. And this is really the phasor of the electric field associated with it. So coherent state, the alpha value is directly related to an electric field. That's why this state is closely related to the classical limit of the electromagnetic field. We looked at the fluctuations and showed that it's a Poissonian statistic. And then we use now-- once you define something, you can use it as a tool. We are now using the coherent states to look at any other quantum state. look at a number state-- Well, you often know in quantum mechanics, number and phase are complimentary. If the number of photons is fixed, you know nothing about the phase. And indeed the quasi-probability of a numberState is a ring. It has no phase. It's completely random phase over the 2 pi circle. The energy is sharp of aNumberState, since the energy is e squared. But what you get is also something blurred on the order of unity. In the analogy with the harmonic oscillator, the electric field was a minus a dagger. In those quasi-probabilities-- and we will see more about it-- something which is sharp in momentum is a sliver parallel to the x-axis. So therefore, since momentum is electric field, you always get the electric fields by projecting onto the vertical axis. And if this quasi- Probability starts to rotate due to the time evolution, we get an oscillating electromagnetic field. fuzziness. For instance, if you would say the phase is determined by the 0 crossing, you don't know exactly when the0 crossing happened, and that corresponds to an uncertainty in the phase. So this fuzziness here is the intrinsic uncertainty of quantum physics. So that's what we want to discuss today. But then we will immediately start with non-classical states. And that is, well, if this area is determined. by Heisenberg's uncertainty relation, what can be maybe deform the circle into an ellipse, and these are three states of light. In quantum mechanics, you cannot measure x and p simultaneously. These are non-commuting variables. So therefore, what happens is, if you now define a phase space function, which is done in quantum mechanics textbooks, you can actually do it in three different ways. And the three different way are Q, P, and W. The definition of those functions involves the operator definition, a and a dagger. If you define something in units of X and p or a and the dagger, you could actually do something in three ways. have a product which is fully symmetric i in the ordering of x p, which is anti-normal or normal. The reason why I picked for the course Q of alpha is that it's a real probability, it's always positive. The other guys, P of alpha, can be positive or negative. And also, W of alpha can be negative or positive. But the fact is all three have their advantages and disadvantages. So they all have pluses and minuses. And as a result, it can be written like this. the coherent state is now not this Gaussian. It doesn't have thisGaussian distribution as a course of probability. The probability of the coherent state alpha has a delta function peak at alpha, which is sort of nice. And the number state is not a ring of a finite radius. You would naively expect the energy is sharp. The square root of the energy's electric field, shouldn't it be sharp? And indeed, it issharp. It's actually worse than aDelta function. W stands for Wigner distribution, which is something you actually find in most quantum mechanics textbooks. The Q and P distribution are more common in quantum optics. All the three distributions are the same. It's more sort of on the level of whether something is a delta function or has widths unity. So on the small scale, it matters. But if you map out something on a bigger scale, they are all related to each other. And for the rest off today and the next class, when I project onto the vertical axis to get the electric field, I'm not completely rigorous which of the three functions I've really chosen. want to understand in more depth the fluctuations. And in particular, I want to show you that coherent states are minimum uncertainty states. So by identifying the vertical axis with p, the horizontal axis with x, we immediately expect that we find a result related to the Heisenberg uncertainty principle. And we can then immediately, by just using elementary commutator, calculate what are the expectation values in a coherent state for P, P squared, Q, and Q squared. For P, it is-- the P operator is a dagger minus a. If we act with a on alpha, we get alpha, because alpha-- the coherent state-- is an eigenstate of alpha. The fluctuations of the intensity are usually expressed by the second order temporal coherence function. The classical description is you measure the intensity of light. And then you'll see what is the difference between quantum states of light and classical light. But I always feel that if you want to really appreciate the quantum character, you have to know the classic description first. It is simple. It's quantum mechanical. It’s exact. That's what we want to introduce now. Yes, this is theSecond order temporal correlation or coherencefunction. If tau equals 0, it's nothing else than intensity squared average divided by the average of the intensity squared. So this is the classical definition, g2 of tau. But quantum mechanically, we will see that the g2 function is not necessarily larger than 1, it can be smaller than 1. And that's actually an interesting-- you can see-- litmus test for the quantumness of a state. If you generate states of the electromagnetic field-- Fock states, photon number states-- we see that in a moment. In classical physics, you can determine an ensemble average by taking an ergotic system and observing it at many, many times. The idea is that one system as time goes by will sample all possible states. So in other words, you would actually think, if you switch on a light bulb with a stable power supply, that the light emitted by the light bulb will go through all possible quantum states as time evolves. So how do we generalize that to quantum mechanics? Well, one possibility would be that-- OK. of tau is we measure the intensity now and a little bit later. But measuring the intensity really means absorbing photons. So what is more closely related to an experiment how you measure the correlation function is you want to look at the probability of absorbing 2 photons. This suggests that experiments where we look at two subsequent clicks of a photomultiplier where we determine the photon correlation, that this is measuring a correlation function, which, for quantum states of light, should be defined as the expectation value of a dagger. Professor: As long as we limit ourselves to a single mode of the electromagnetic field, things are independent of tau. He says if g2 of t Tau changes, it comes because you have several modes. But if you have one mode, there is no coherence time, he says. Professor: In your homework, you will show immediately that the g2 function is related to number fluctuations. It's related to an average and an n-squared average, and it's independent of time. number state, the number of photons is an eigenvalue. Therefore, n squared average is n average squared. The Fano factor is minus 1. Sub-Poissonian distribution. And the g2 function, which classically cannot go below 1, is now n minus 1 over n. It is smaller than 1. And you see immediately that the biggest violation for g2 is to go to minus 1 for the case of a single photon state. Any questions? AUDIENCE: Shouldn't it be 0 for [INAUDIBLE]?? PROFESSOR: The g2function? No, if you put in-- wait. Gosh. I'll double-check. Light is not a continuous stream of energy, it comes quantized in photons. The granularity of light due to the photon character is, of course, most pronounced for a single photon. If you've only one photon, you find one photon and for the next photon, there is no photon to be detected. So the probability of detecting two photons is 0. And that only happens when you go down to similar photons. So this is when certain fluctuations are most pronounced, because the energy is dependant on a singular photon. me first address one misconception. Coherent states, as I've just shown you, are very classical. They've always a g2 function of 1. And attenuation is not changing it. So a coherent state with an expectation value of 1 photon is not a single photon. But of course, there are ways how you can get single photons. And this is, well, you start with single atoms. If you have a single atom in the excited state, it can emit only one photon. So that's a way how we can create non-classical light. states of light. So we obtain the quasi-probability distribution by taking the single photon state and projecting it on a coherent state. The ring immediately tells us that there is no phase defined. All the phases are equally probable. And that also means, if you don't have a phase, the average value of the electric field this 0.1. The equation of single photons is essential for studying non-classical light, but also since it's a very active frontier of our field. it's about-- it involves single atoms. But it's a little bit more demanding like that. So you want to take 1 atom home or 1 ion. But the problem is if the atom or ion emits a light, it can emit the light into all directions. And therefore, you have a single photon afterwards. But you have many, many different spacial modes. And in any given mode, it will not have a. single photon. So therefore, what you have to add to the single atom or single ion is-- you. have to put it in a cavity. The Hanbury Brown Twiss experiment was a landmark experiment done in the 1950s. It was the first experiment which really looked at g2 functions correlations, which one could say was the beginning of quantum optics and modern experiments with light. In principle, you can now find 2 photons which are only a few picoseconds apart, because the first photon is observed by the first detector, and the second photon is detected by the second detector. In the classic limit, you don't have to worry about it. say photon, I should actually say intensity. The intensity splits equally. And if you do the measurement with the coincidence detector, you find the difference between the g2 function, which I discussed earlier. That's actually the only way how you can distinguish a light bulb from a laser beam. But it is the correlation experimental which shows you that you started with a thermal source. It has a g2function of 2, and you can never get rid of it, whereas the laser beam has ag2 function of 1. especially when we have a single photon, the photon can go to only one detector. And that means, for this extreme case of a single photons, the g2 function is 0. Anyway, you will look at those situations in more detail in you homework assignment. Yes? AUDIENCE: Sir, if you know that different for tau non-zero, then even the single mode in the function would have a final g2 [INAUDIBLE],, because there would be some probability. The experiment how it is done is often done as in an open system, where you couple the system to a light source, which is always replenishing your experiment. I think, in essence, the experiment would be done with a single photon light source. But the single photons have a high repetition rate. You have an heralded single photon. You know the term heralded photon. I showed you how to generate single photons. But in other words, what we have focused in the simple description is that we have a quantum state which is prepared-- it's a closed system. And now we do our detection. single photon comes now. You do the experiment, and then you repeat it again. And then you find indeed, that during that temporal window, you will never find a second photon. So this may happen in a few nanoseconds. Then you wait a microsecond, and the next photon arrives. But this is then related to the repetition rate of a single photon and not to the single photon itself. I think you've got the taste. Your homework is a really simple. You just deal with a closed system. The only property which distinguishes a laser from the thermal light source-- we're not taking advantage of it. You cannot create an intense enough single mode light source unless you use stimulated emission into a single mode. There are LEDs or semiconductor devices, which provide photons with interesting statistical properties. The correlation function for, for example, an LED light-- that's not really a thermal source. It's not described by a Maxwell-Boltzmann distribution. It would be closer to something for a laser, even though there is no cavity.

ROUGE-1: 38.01, ROUGE-2: 36.45, ROUGE-L: 35.20
BERTScore: 66.77

==============================================
==================== [74/100] ====================
Summary:
This lesson will first dive into some signal Theory and then move on into things that we're more familiar with things like deconvolutions and using Transformers for next note prediction. The first thing we want to talk about is how can we sample and quantize a continuous time signal. We'll then go into some geometric signal theory and with Transformers and finally how how we can kind of generate sounds using these. The lesson will end with a soft introduction to digital signals and then we'll move on to the next lesson. not very easy for a computer to do given that every operation needs to be in on a continuous time signal. The way that we we can fix that is through the process of discretization or to to make a an analog signal a digital signal for us to be able to process. The two kind of main ways that we can make our signal easier to process is one by taking samples at certain time periods and two by quantizing our level so instead of dealing with A continuous scale we can quantize at certain levels for example a frequency of like 2 4 6 8 Hertz. signal to an analog output we can kind of start by talking about the ADC circuit. This uses something called the SARS ADC algorithm essentially what this is is a binary search to figure out what is my best digital approximation of my analog signal right so I have a continuous signal pass it through my sample and hold circuit. From here we take in our our input and our output is based on the amount of bits of precision that we want to have so depending on whether we want a two-bit approximation a three bit approximation. here we use a low pass filter which is also covered in courses like 16b um the motivation behind this is that we we maintain a signal that's the pass band. We allow every signal to pass when we hit certain cutoff frequency we Wane our signal by a certain factor and that factor dictates the slope of this line. Our signal will continuously Wane after that cutoff frequency is hit on the right is kind of the picture of the approximation where we can approximate a different quantization levels different bit parodies based on the Stars ADC algorithm. voice and Pitch it up very fast right what quantization level do we do we want there. Can we do a lossy pitch up with a uh with by filling in the the blanks in some intelligent way through prediction or kind of note fitting which is an interesting consideration I think given the fact that audio is a continuous time signal um the digitization process and the choices you make matter a lot and because of that this field is so interesting and there's a lot of really didactic work around how we can take these continuous signals. with a whole bunch of things in digital signal processing. If the sampling frequency is less than double of the highest frequency present aliasing will happen. This asserts that you need at least two samples per period. The aliasing phenomenon is incredibly interesting this happens both visually and um auditorily um and aliasing is an entire um topic just based on itself. As you you can see here your approximation gets very different as your your sampling rate increases and decreases if your assembling rate is 0.3 Hertz. also increases we're at one Hertz you're almost perfectly fitting the polynomial on the the points um something interesting to consider is that at a sampling rate of of 0.3 you are fitting a polynictional right because you're you're creating apolynomial through the points that you have. However this polynomal is very not indicative of the actual signal that you're trying to process right while we we can see that this this does kind of capture the trends of our data and that it falls when our data has fallen.  aliasing is the byproduct of poor sampling. A lower wave resolution will result in a modified output signal as compared to the original input that we're trying to process. frequencies that are higher than one half of the sampling rate will be automatically transformed to lower frequency sees that's where information loss stems from. There's a lot of literature about um aliasing effects um including spatial illnessing right um you see that uh there's there's a lots of different ways that aliasing takes place. we we take certain points along this you can see that the image changes we get kind of the gist of this um but this is a a compressed image it contains similar information it allows us to kind of see what's happening but it contains this in a very compressed format super sampling is where um you know this this image is uh take in this this 4x4 uh image and we're kind of running a kind of stride over top where uh we're losing some information in the background as you cansee it really Blends together but in the foreground. um this is is kind of uh and and add add-on um to this presentation it uh doesn't uh really contribute exactly to what we're talking about but I thought this was incredibly cool. With one line in C you're able to to generate Melodies um which is incredibly cool um yeah so please check it out if you if you guys have a chance. The next thing we're going to talk about briefly is geometric signal Theory and how that can tie in to reconstructing signals. A vector can be reconstructed with a linear combination from its projections onto another set of vectors if and only if the set used is a basis. A basis is a Subspace that's covered by all linear combinations of vectors. Given that a basis is required the vectors used must be orthogonal to one another and this is very important as it ensures that that we're maximizing the amount of information gained right by having two vectors that are orthogona to one other. We can say s 0 to SN is called the span which is a representation of all the vectors that can contribute to a a certain Vector combination. The idea behind the the last two sections here was to give you motivation for for how signals work and how kind of classical reconstruction can occur using math that we're all familiar with. This really covers any Vector in R2 um e0 uh we can Define as one zero so a horizontal Vector E1 is zero one a vertical Vector if we look at where we we're trying to project some Vector X onto uh the the e0 space right we can kind of see how the math works out here. familiar with perhaps in terms of how we can use those to reconstruct signals and ultimately how we could use them to generate audio right predict the best uh kind of next node um so looking at the next the next step here we want to use deep learning for reconstruction right where we are are reconstructing a low quality audio to high resolution audio right um and this is this is the kind of uh model framework um that we can used for this um you might notice it really closely resembles a unit which is something that we talked about during image segmentation. to uh kind of increase uh the uh the resolution of a certain low quality image form so as you can see if this is our initial wave our our final wave is is much more populated right we're able to gain information through this unit process. At each layer the number of filter Banks is doubled so that while the the mention along the waveform is is halved the filter Bank Dimension is increased by two. We're reducing the size of our uh of our image but we're increasing the dimension the dimensionality of it. we're developing a representation of these these audio signals so as we pass through the bottleneck layer which is constructed identically to a down sampling block right these connect eight up sampling blocks which have residual connections to the down sampling blocks. What this allows you to do is it allows you. to preserve features and share features that are learned from the low resolution representation of the image into our higher resolution output. The final convolutional layer um has a restacking operation and it does the reordering operation following our our sub pixel deconvolution. after this restacking step um and the the loss function used throughout this process specifically was was kind of a mean squared error loss function so by playing around with different kinds of of loss functions you might be able to yield better performance. These kinds of techniques are used in a variety of ways to reproduce music from bands um in the 1900s um the late 1900s mid 1900s whose recordings may not have been preserved in full quality um so by you know through the remastering process they're able to to kind of do things like this. waveform and the reconstructed waveform. We want to convert our data into usable tokens which in the music realm does provide a different issue than it did for our other two representations. The first step takes the form of converting data which is music files into a token sequence which is individual notes. We can tokenize this into a series of tokens that all correspond to our vocabulary which is very very easy to map by a dictionary to certain Keys. We're adding color to our our downsampled waveform to to ultimately get something that hopefully resembles our true waveform better. intuitive what we can do for uh for music is We can approximate this which is a series of notes in a piano roll right or a graph that has our offsets and our pitches right so our pitches span you know a certain uh pitch set. We want our our information to be captured in multiple Dimensions right we want the the pitch of the note as well as the length of thenote for example these two notes at the bottom right they correspond to to e and A2. We're trying to form multiple notes can be played at a single point in time. n62 which is this actual note representation on piano. A single song can be transformed into 12 songs of different Keys which can help increase our sample of training data and generalize key scales and beats throughout a data set. Data augmentation provides an amazing data sub multiplier to to Simply get more data. The more data you have the more data that can be used to improve training data. We're able to capture information in a a very sequential and very structured way so putting this all together you can get your initial translation right where you have a um our our initial translation. the better your model will be and the more generalizability you have in your Transformer the better it'll perform right we talked about Occam's razor. A generalized Transformer a generalized solution can fit the Goldilocks of what we want in a model. It's easier for machines to predict keys without flats and Sharps um which has you know similar to what humans do it's easier to focus on the regular keys on piano um so this specific example was trained on on those um however the glass andSharps with specific augmentations and specific training processes can also be added to our vocabulary. example um this specifically I believe this uses like a music 21 framework but it's able to you know tokenize a certain item and then you're able to transpose this to a certain amount of notes or a certain key. Just by transposing you'reable to increase your your training sample size which is very cool and can improve model performance by a ton. The next thing to consider is positional beat encoding right we want to include some metadata to feed into our model to give it a better sense of musical timing because the position of the token in our our tokenized representation it doesn't correspond to its actual position in time. The attention mask is a way to keep the model from peaking and essentially leaking information at the next token it's supposed to predict. By applying an another mask a window of size 2 you're essentially enforcing a window size of two where you're only updating the information you see every two time steps right at the very end you can't see the final two bits of information and that lack of information is very important to a Transformer as it allows you to predict several steps ahead and will ideally produce a more generalized model. hidden state memory Transformer memory specifically to this model enables very fast inference for music prediction right we've done a lot of things to optimize for for our prediction we're including a beat embedding so that's not something it has to learn. We're able to get a sense of of relative position with Transformer XL whereas vanilla Transformers will use Absolution absolute position only. It's important for music models to know the position of each token relative to one another because positionality matters right the order that you're playing the notes really is is what matters the most. our positional beat encoding which we're including for the the model to have um so I'd kind of like to end with a little demo generated by by somebody who who use this model to kind of predict the end of Canon in in D Major by by Pachelbel so here'sPachelbel's Canon I'm kind of in the spirit of Christmas coming up as well um yeah so as you can see there um this is the original pocket balls Canon and this is what's predicted. So yeah there's a a lot to do in this field um a lot of really cool things happening um. things a try yourself uh yeah thank you guys for tuning in have a good one. Things you might want to try yourself. Things that you may want to give a try. uh yeah. things you might be interested in trying yourself. things that you might like to give yourself. uhYeah. things a try yourselves. uh Yeah. Things a try themselves. Things your might like yourself.things you may like to do yourself. thanks you guys. for tuning into this week's episode of The Daily Discussion.

ROUGE-1: 48.09, ROUGE-2: 45.35, ROUGE-L: 43.91
BERTScore: 70.53

==============================================
==================== [75/100] ====================
Summary:
The amygdala is closely connected to the basal forebrain. The amygdala primarily projects to the more caudal one here. The abnormal brain connections that we know occur, at least many types of schizophrenia. The types that don't include the abnormal connections appear to have abnormalities, though, in the receptors, affecting the same system we're talking about. It's a hypothesis of and early lesion explanation of some forms of schizophrenia back in the '70s, based on work in the olfactory system. and visual system that I and other people had done. It was inspired by a study of people with temporal lobe epilepsy that had been operated on in order to get the tissue generating seizures removed. And they found that the patients could be grouped into two types. And I've summarized there at the bottom the real basis for this idea, other than the fact of early lesions. And that is that the earlier the lesion in these other systems, at least, the greater the plasticity, that is, more sprouting, more chances of regeneration. of the catecholamines, the monoamine, serotonin, and some acetylcholine axons as well. I knew at the time I drew up this hypothesis that there were dopamine abnormalities in the prefrontal cortex in schizophrenics in many of them. And I would predict this kind of sprouting. For one thing, by removing this structure we've eliminated these projections to basic forebrain and prefrontal cortexes. But we've also pruned these axons, making it likely that they will show compensatory sprouting in other areas. and early damage? The fact is, a number of schizophrenics, particularly the ones that are the hardest to treat, have enlarged brain ventricles. Now, of course, with more drugs to treat them, more of them are not in the mental hospitals. But this just shows schizophrenian monozygotic twins, where you have one twin with schizophrenia. The other doesn't have it. And as they often find in these cases, the affected twin has larger ventricle. And we know that larger ventricularles can result from early damage. of them do have this temporal lobe damage. Of course, there's always a lot of variability in the studies like this. But-- yes? AUDIENCE: [INAUDIBLE] in like epilepsy in schizophrenics? PROFESSOR: That's a good question. You'd like to know if in studies of schizophrenics, how many of them have epilepsy. Usually they're kept separate, but I don't know of studies that have just looked broadly at schizophrenics. It'd be worthwhile checking. are a little more widespread according to recent studies than they were in the earlier studies, where they were seen mainly in the cortex. Now we know they are also in the more caudal areas, but just less dense. But also we know the basal nucleus projections are shown here. They could be affected too. And in every case these four systems of widespread projections all go to the amygdala as well as to other parts of the brain. All right? And this is just to show you binding to receptors for these different transmitters of the various anti-psychotic drugs. that we know if you bind the receptor you'll reduce the effects of the [? rejections. ?] If the prefrontal cortex is functioning abnormally because of sprouting of these axons, also the basal forebrain, then binding to the receptors will move it more towards the normal. And that could be a reason. Just saying that it does [INAUDIBLE].. Let's talk about the other part of the basal ganglia, the larger part, the corpus striatum. In mammals and other amniotes, the birds and reptiles, the skates and the rays-- sharks, skates, and rays comes from the ventral tegmental area. And we know that, especially if you look in fish, that a major input to the hypothalamus in those animals is from the taste [? cyst. ?] In mammals it's never been emphasized, but we know taste can be very rewarding and influences the te segmental area cells. The studies of rats have indicated yes, there are some projections, even in mammals, from that system. to the VA of the thalamus, which then projects to motor cortex. The one with the colliculus goes directly from the dorsal striatum to the nigra. And then you need to know what we mean by doubled inhibition. Notice excitatory input from cortex. Inhibits the globus pallidus and inhibits the Nigra. So you're inhibiting an inhibitory pathway. Important for understanding the pathologyies when something goes wrong with these structures, as in Parkinson's disease. The subthalamic nucleus excites both segments of the globus pallidus and the nigra. So it's unique in that way. And it's critical for the balance of this system. So anything that goes wrong with it can cause major problems with movement. For people to see how knowing these connections explains some of the disorders. So we'll leave it here. But just note, if there's just a subthalamic nucleus-- here's the Nigra down here. So these are the two main satellites of the corpus striatum.

ROUGE-1: 27.62, ROUGE-2: 26.52, ROUGE-L: 26.31
BERTScore: 58.45

==============================================
==================== [76/100] ====================
Summary:
Learn how the solar cell device converts sunlight, the input energy, to some usable output energy, which is in the form of electricity, typically, from a solar panel. Learn how to minimize the amount of light reflected or not absorbed into maximizing amount of life that's actually absorbed. Learn about the duality of light, or how to think about light as a particle, or alternatively, as a quantified particle. Use the weekly Newsquiz to test your knowledge of stories you saw on MIT OpenCourseWare. you can have, for example, in the visible range, a decreasing depth of penetration of the light with increasing energy, whereas with x-rays, it's the exact opposite. It's because you're dealing with different types of electrons and the material. The real component of the refractive index is material-specific property. So if I have silicon or if I've silicon nitride, it'll have a particular type of glass. It'll have different refractive indices for different materials. a particular refractive index. It's comprised of a real component which indicates the phase velocity inside of the material and an imaginary component, which can be thought of as an extinction coefficient. And it is related to the attenuation of the light intensity as it travels through that material. And we use that information to calculate engineering relevant parameters such as reflectance of light off of a surface. And the reason that's important is because we want to minimize reflection off of surfaces. So I've come up with the first equation right here. which is describing the reflectance from air to a solid, in this case, from air where the refractive index is 1. The amount reflected can be described by this equation right here. It could also be thought of very loosely as the ability of an electromagnetic wave coming into material to slosh those electrons around. So I would advise taking this analogy as far as it will go until it breaks down. And you'll see at some point it actually does, but it's a useful place to start. if you have a tinted window, why can't you see inside? What would you imagine is going on? If I add a coating, for instance, to a window that increases the reflectivity, then the amount of light that is able to escape from the inside to my eyes decreases. If I have a bigger n, I would get bigger reflectance. Is that right? r goes up? Well, you'd have to plot it out, I guess. The light on the outside is much, much greater than it is on the inside. If I took that glass and just flipped it, would it change it? What about the symmetry argument, that the amount of light is reflected, the r reflectance, is the same from both sides? TONIO BUONASSISI: Yeah, so I would advise you to actually walk through that calculation. And what you'll find is it winds up being the same. And it's because you have to take all reflectances off of all these interfaces into account. We're just assuming that all of these layers are well above the wavelength of the light. These linear equations, are valid. So we're happy to walk through that perhaps during recitation. OK, so what we're going to do now is we've talked about reflectance off of surfaces. What I'd like to do is talk about a light absorption inside of a material. And for that, we apply a very simple formulation inside of this class, which is called Beer-Lambert's Law. And now the light that's incident on the material is actually going to go inside and get absorbed by the material inside. very simple yet very powerful formulation that describes not only the interaction of light with the solar cell material but also light through the atmosphere, light the water, many other forms of optical absorption. And for that, I'd like to call Joe up for a quick demo that will allow us to actually plot out Beer-Lambert's Law. And so I'm going to come up with a hypothesis. What we're going to be doing is taking many sheets of material. This is just some polyethylene material, a little bit discolored. And we'regoing to shine a laser down on to this photodiode. of what's going to happen. I'm going to say that if we double the thickness of the polyethylene that we're going to halve the amount of light going through. And let's see if the hypothesis is correct. It's not. And it's a logical thing you might assume. And then we'll walk through a derivation that will correct our missed logic. So go ahead, Joe. Take it away. JOE: Sure, so if you guys want to play along, that's fine too. Right now we're getting about 1.32 milliamps. Then as we keep increasing and put one layer of polyethylene, that drops to 0.75. There's kind of this sense that it should be exponential. What don't we add some more filter in front, and we'll see what exactly this comes out to be. It's actually starting to go in a straight line. We're going to see what it's like, what the power of our-- yeah. to curve down. Exponential. It looks like one at least. And we can test whether or not the hypothesis is correct by an exponential fit, which happens to match pretty well. JOE: Now one other quick thing you notice is that if you look at the fit, the first point's a little bit higher than that fit. Anyone have an idea of why that might be the case? What are we ignoring in this experiment? AUDIENCE: The reflection is [INAUDIBLE]. Joe: The reflections, yeah. TONIO BUONASSISI: OK, so we notice that we have some exponential character to be decay of the intensity of the transmitted light through a medium. And the amount that's absorbed is following another trend, which is just 1 minus that. So it's the amount of light that'sabsorbed is following a curve looks something like that. OK, let's look through the formalism of Beer-Lambert Law and try to understand why it is that we come up with that exponential function right here. by some sort of scattering intensity within the medium-- and this sigma here can refer to a variety of processes. The sigma is independent of thickness throughout. And then as you integrate through, you wind up with that beautiful exponential function at the end, the sigma l times n. That alpha is an absorption coefficient. The l is the total length or the total thickness of this medium right here. So if we increase the total. thickness, we're going to decrease the total amount of light coming through via that exponential function. a geometric parameter. It's an intrinsic material parameter. This alpha will vary as a function of wavelength inside of a material. And so from an engineering point of view, we don't really-- to first order, it doesn't really matter what sort of scattering or absorption process is happening in a material for us to calculate the amount of transmitted light. We just need to know the alpha. We need to known the optical absorption coefficient. We can measure, experimentally just like we did right there, our alphas for materials. states within the material, that light, depends on the energy of the light. So there's a wavelength dependence. And that general equation is the same one that drives the reduction of light intensity as it travels through the atmosphere. So if we increase the atmospheric path length, we'll be reducing the amount of light that actually reaches the surface of the earth. That's at air mass two or air mass three, there's less solar flux coming down than at air Mass one or air Mass zero. The only geometric parameter that is of essence is really our l.variable, Tonio Buonassisi says. Oftentimes we're operating in a wavelength regime of light wherein free charge is excited. But we can also keep increasing that the wavelength of light, say, out to 10 microns, very long wavelength light, very low energy light. That can excite free carriers within the material-- carriers that are already excited, essentially excited them further, without generating any new free carriers inside of our material. Alpha is a function of the wavelength of light and the property of the medium. We're talking about an energy range quite broad here, from about 6.2 eV to 0.62 eV. The visible wavelengths range would be somewhere in this regime right here, so a very limited band. And the infrared out here, ultraviolet over here, and we can see for a variety of different types of materials what the absorption coefficient is. The red would be crystalline silicon, gallium arsenide, indium phosphide, and amorphous silicon. The thickness of gallium arsenide is necessary to absorb 90% of the incoming light at 550 nanometers. To make sure people are setting this up right, i divided by i0 is 0.1, 1 minus 0.9. If we're absorbing 90% the light, it means only 10% is going out the other side. That means their i is going to be 1/10 of i0. And then we would take the log of both sides, typically, typically. and solve for our l based on the alphas that we have here. Again, units of alpha would be in inverse centimeters. Did anybody manage to walk all the way through that calculation? Did anybody get any other numbers for gallium arsenide? How about the silicon? Is it larger or smaller? For silicon, crystalline silicon that is, with an optical absorption coefficient and order of magnitude less than gallium arsenicide, is the thickness needed to absorb the same amount of light going to be greater or smaller. Most solar cells that you see of crystalline silicon are on the order of 100 microns. The record efficiency of gallium arsenide solar cell is a few hundred nanometers thick. If you absorb 90% of the light on the first pass, you'll absorb 99% of it on two bounces, right? Or in one bounce, rather, and two trips, two optical path links through the material. And over the next few slides, we're going to learn how we engineer that. electrons instead of the system is changing from one medium to another. The light path will obey what is called Snell's Law, which is the product of the refractive index and sine of that angle, the angle relative to the surface normal. So there are two benefits to texturizing your front surface. One is you have an additional pass, additional bounce, an additional encounter with the material. And the second benefit is that you're able to increase the optical path length by the delta in refractive indices. most often, depending on the angle. You have what is called total internal reflection, which is this case right over here. You might change the nature of the anti-reflection coating on the glass. Even if the panel looks black, there are some really aesthetically pleasing solar panels out there that look completely black. They may still have white back skin, but the glass is just very good at absorbing that light and preventing it from escaping. To engineer front and back surface reflectances, you really have to carefully select your refractive indices. In one of these two images, the refractive index of the medium inside the pool is not 1.3. It's 0.9. And in another one of this two, we'll call it a negative refractiveIndex material, a negative index material. Think about what would happen to the reflectivity of that front surface of the water. And think about the angle that the light travels, or the angle of refraction of bending, shall you say, as the light goes from one medium to another. The back skins of our solar modules can quite often be Lambertian scatters. And we have a certain amount of light that comes off at some angle here that will get trapped by a total internal reflection inside of a modules. And so the notion of a Lambertian scatter is important on our solar panels. It's those waves, those rays that are bouncing off at those large angles that are causing the totalinternal reflection event. It is not sub-wavelength, but smaller features such as texturization on the back skin right here. the backsides of solar cell devices. We would obviously wants to even change the scattering profile. We wouldn't want necessarily specular reflectance. We might want to maximize the amount of light reflected off at particular angles. And there is, of course, research being done to figure out how to make light do that. And you don't only have to texture your back skin. You can also texture the bus bars. The bus bars are these little metal wires right. Let's ignore front surface texturing for now. Let't just focus on the backside. here that are collecting the charge from each of the solar cells. They're connecting essentially the front side of one cell to the backside of the next. And this metal right here is just really shiny, and it's reflecting light right back out into space. What if we instead were to texture that metal so that when laser light shined on it a certain amount would be reflected off at an angle and then caught by total internal reflection? That's exactly what you're seeing right here. There is a limit to how much we can trap light simply by modifying or corrugating the surfaces. A gentleman by the name of Eli Yablonovitch, who's now a professor in Berkeley calculated these parameters I think back in 1982. He came up with an upper limit to the optical path length. That's a pretty good litmus test for the ability of a material to trap light. If you have silicon, for instance, with a refractive index of, let's say, in the infrared some around 3.6, your Yabonovitch limit is around 50. we have a grading of refractive indices going from air, our anti-reflection coating, to silicon. And right over here we have a certain thickness, d1. And over here, d2, over there, over here. So what is happening in these two images? Let me show you with another, a little bit more clear figure, coming from our beloved Wikipedia, and then go back to that other image right there. What's happening is we have an incoming wave that for some reason is ignoring Snell's Law. In most solar cells, we want to suppress reflection. We go to great lengths to make sure that this thickness as well as the refractive index of the material is optimized for a particular system. You can constructively interfere if you like and enhance the amount of reflected light as a result of this interference effect. The anti-reflection coding is enabling the solar cell underneath it to be absorbing the light to be suppressing the reflectance. This is really briefly-- I'll show you some slides to drive that point home. Recall that equation that described the amount of reflectance, there was that-- what was it-- n1 minus n2 quantity squared, right? The bigger the delta between the ends, the bigger the difference in refractive indices between material one and material two, the more the reflectance is going to be off that interface. So you can begin reducing reflectance off of a stack of light going both ways by grading the refractive index of the material. And so you get a reduction in the total amount of reflected light when you put silicon under glass. front surface of your sample by using an intelligent combination of the very first equation that we're exposed to in the class today, which was the reflected light as a function of refractive index. And secondly, by engineering by engineering an anti-reflective coating, which oftentimes in the lingo of solar cell science we call it an ARC. And those two things combined give us very low reflection off of the front surface. Probably 5% of our R&D cells that we make at MIT use these sorts of technologies, which are pretty standard in the industry. expressions that we just walked through. It's really important to understand the fundamentals behind any simulation software because you will get out of it what you put into it. You will not be able to pick up on obvious things that you might of-- for example, double clicked on this little material here and find the real component of the refractive index completely wrong. And you might not notice it if you don't have some good intuition which is grounded in the fundamentals. And so it's important that you understand what we've presented today. The absorber is the material, our photovoltaic material, the ones absorbing the sunlight and ultimately going to be generating the charge. So we want to ensure good light trapping inside it. There are fancier ways of light management as well that don't involve light trapping necessarily but light manipulation or even semiconductor manipulation. If we can eliminate the longer wavelength stuff out here, which is heat, performance of most solar cell suffers when they get hot. And we'll learn why that is about five or 10 lectures from now. a coating on the back to reflect the light back so that it gets a second bounce through the material. I've engineered the front surface, texturized it so that we have not only the benefit of two bounces, double the chance of light going in, but also the Snell's Law working in our favor. And so all told, the one reason why this boost is so big right here is because I'm increasing the optical path length. And as a result, I'm getting a much larger current output. I'm absorbing much more light inside of my material. surface of a material, let's say right here, then you can cause each node, each point within your material, to lag by an increasing amount, so that your wave front now bends. And that will cause the light, essentially, if you trace through the points of maximum intensity, say the pink, you'll see that the light is bent. And so it's really exciting. There's stuff coming up every day. This is the point. We can, in principle, if this is hot off the press-- and then of course there's a whole flurry of researchers out there trying to figure out how to use this to our advantage. on light trapping and light management. Mostly it's for photonic devices, but they can be transferred over into solar cells as well. And another example of the photon up/down converters, there's recent reports in SPIE, a lot of interest in the optics community. There was a TR35 award given to a person who studying this topic. So it is, as well, a very exciting and up and coming field. Again, the opportunities there of manipulating light are large, are vast.

ROUGE-1: 40.63, ROUGE-2: 38.86, ROUGE-L: 38.25
BERTScore: 60.88

==============================================
==================== [77/100] ====================
Summary:
Professor Steven Smith: I want to look at two sets of issues. One is Locke's theory of the constitutional state, particularly focusing on the role of the executive, vis-a-vis the legislative branch of government. The other is thinking about Locke and the American regime and the current state of political philosophy, modern contemporary American political philosophy. Smith: Locke doesn't endorse necessarily one particular form of government from any other. He is an advocate of what we have come to call limited government, of constitutional government. a domestic, not an international issue, which is to say, in the case of a fire in a city it is sometimes necessary, he says, in his day for the fire department to tear down the house of an innocent person. This is acting for the public good of the community, even while in some ways it's clearly a violation of rights of property and so on. In fact, the example is not so far fetched. Think today for example about arguments we have today. Even in Connecticut, there's a big argument going on about the right of what's called "eminent domain" Locke asks what are the limits of this prerogative power. What check, if any, is there on this power to prevent their abuse? This is beginning to sound more and more in respects like Machiavelli than the advocate of, again, limited government. This power comes into play, he says, especially during times of national crisis or emergency when it is necessary to act for the public safety. And again, this seems to have special resonance for us today as we face issues like states of emergency and states of exception. utilize when ordinary constitutional operations, like the rule of law, prove to be inadequate. Consider Lincoln's famous suspension of habeas corpus during the Civil War. Lincoln argued quite forcefully that this sort of prerogative power is already deeply embedded within the structure of constitutional government. The Constitution seems to embody within itself, our constitution that is, this Lockean power ofprerogative that comes into effect or can be legitimately exercised in times of rebellion or invasion. Are we living in that kind of age now, not rebellion perhaps? LZ Granderson: John Locke gave the modern constitutional state its definitive form of expression. He says Locke's doctrine of consent and legislative supremacy should make him a hero to Democrats, to radical Democrats. LZ: Locke's conception of natural law, rights, government by consent, the right to revolution and all are all part of the cornerstone of our founding. Lz: A judgment on America is very much a judgment on the philosophy of Locke, if anyone is to be considered to be America's philosopher-king. a more or less kind of random or arbitrary genetic lottery or social lottery of which I or you happen to be the unique beneficiaries. Fortune, luck, Machiavellian fortuna, in that way, is utterly arbitrary and therefore, Rawls concludes, I should not be regarded as the possessor but merely the recipient of what talents, capacities and abilities that I may, again, purely arbitrarily happen to possess. So what does that mean in terms of social policy or theory of government? The result of Rawls' difference principle and its fundamental difference with that of John Locke could not be more striking. John Rawls and Jean-Jacques Rousseau offer radically different visions of the liberal state. Rousseau is a passionate critic of inequality; Rawls is attentive to the moralills of inequality. The question for you is which of these two views is more valid or which of the two strikes you as more powerful or plausible? I think my own view is far closer to American theory, to Locke's theory, which I think--than Rawls' Rawls'. The Declaration of Independence, the charter of American liberty, states that each individual is endowed with unalienable rights. A return to Locke such as it is, even if such a return were possible, is by no means a panacea to what ails us. Locke's effort to build a kind of modern republican government on the low but solid foundations of self-interest and self-ownership could not help but generate its own forms of dissatisfaction. America, as a former teacher of mine once said, is the land where the many facets, the many faces of modernity are working themselves out. We are but a moment in the kind of comprehensive self-dissatisfaction that is modernity.

ROUGE-1: 23.12, ROUGE-2: 21.60, ROUGE-L: 22.18
BERTScore: 64.64

==============================================
==================== [78/100] ====================
Summary:
JACK HARE: Let's do a little recap on electron cyclotron emission, and then we will go on to a few other things. We didn't actually derive the emissivity of it, but we gave ourselves a hand-wavy reason why there may be multiple peaks here. And these peaks are going to be occurring at frequencies-- I'm going to switch into angular frequency units, omega m. And we can say this is m equals 1,. m equals 2, m equals 3. And they're evenly spaced. "We agreed that these peaks would, in general, be broadened in some asymmetric fashion. But the exact shape will depend on exactly how big these two terms are with respect to each other" "And we said the neat thing about this is that these frequencies depend only on the magnetic field. And so, if you see some emission at some certain frequency, then you know that it's been emitted by a region of plasma which has this magnetic field" "That was particularly useful when we considered a tokamak because, if we have some magnetic field that goes 1 upon R" different because the magnetic field is dropping off nice and monotonically throughout our device here. So we said that, for example, we might have three different regions, which we could label positions R1, R2, and R3. And each of these then have different magnetic fields, B1, B2 and B3. Each of these magnetic fields will then produce a spectra of lines at these different harmonics here. And at each ofThese points, if we measure the intensity, we then know straight away what the temperature is corresponding to the black body spectrum. temperature as a function of frequency. Then we can say, well, that frequency corresponds to a certain magnetic field. And then we can says that magnetic field corresponds to. a certain spatial coordinate. And so, this is a technique which will give us, by looking at the spectrum for lowish frequencies, the first or maybe the second harmonics of this cyclotron emission, we can work out what the temperature is as a. function of space. This is correlation ECE, often called CECE. what we want to do is measure very small temperature fluctuations. We want to measure temperature fluctuations within the plasma that are maybe on the order of 1% of the baseline temperature. If the mean temperature is just Te, and we have some fluctuation around 1%, this intensity will also fluctuate by about 1%. And that 1% is actually extremely hard to measure. And this is because the noise is just too high on these systems. There are lots of different contributions to the noise. But, in general, they all add up to make it very hard toMeasure these very small fluctuations. want to understand in plasmas so that we can build an economically viable fusion reactor. Now, the fact that the noise is too high does seem like a big limitation. But there are some clever tricks that we play where we use correlations. And I'll talk now about what exactly these correlations are and how they provide us with information that allows us to get a signal out despite the overwhelming [INAUDIBLE]. So our setup here is borrowed from ASDEX Upgrade. And, in effect, I referred to Alex Creely's PhD thesis, which you can find online if you want more information. can get very detailed. So in ASDEX Upgrade, we don't really have a circular cross-section plasma, but I'm just drawing it like that, be a nice D-shaped plasma, got our plasma inside here. And our system, at first glance, looks an awful lot like the system that we sketched out up here. We're going to have some sort of special lens. It turns out, you can make lenses for microwaves. And that lens is going to collect light from a region like this. some sort of top hat. It's centered around the frequency where most of the electron cyclotron emission is. And this has a bandwidth of 10 gigahertz. So we've cut out an awful lot of the radiation in bands that we're not interested in. We are no longer going to study those, any bremsstrahlung, any higher order things. This is going to capture all of the information in, say, the first harmonic within some relatively small window. frequency range. Once we've got our bandpass filtered signal here, 110 kilohertz is still too fast for us to digitize. This would be an extremely expensive digitizer. So, what we actually do is we downmix it with the signal at 100 gigahertz. And so, then we get out our beat signal, which we can digitize, which is at 10 gig ahertz here. So this is-- actually, I will write this as 0 to 10 giga hertz. This is the sort of signal that we can actually digitize now. bins is 125 megahertz. It's important that these bins do not overlap in frequency space. They are each sampling a separate discrete part of the plasma inside here. So each of these represents a measure of the power that's being emitted by a very small region. And you can tell that these regions are very small because we're dealing with 100 mega hertz bandwidth. And we originally started with 110 gigahertz here. And so, you see we've gone down by a factor of 1,000. downsampled these is that digitized is now much less expensive. We're doing it something like 4 mega samples a second. And that is quite an affordable digitizer compared to the ones you would need to digitize this signal. So I have not yet told you anything about how correlation ECE works. I'm just giving you an outline of exactly how these measurements are made with an example from ASDEX Upgrade. But there are other similar devices on other tokamaks. many oscillations. And so, it will average out to-- well, because it's power, it'll average out out to 1 or something like that. So it's some DC offset that we can subtract off after. So all this is doing here is mixing the signal down so it gets to a regime that we could effectively digitize. Yeah, another question. [INAUDIBLE] JACK HARE: So if we were doing geometric optics, which we're not, then you would have a lens like this. That lens could collimate your beam. The idea here is that there was some region over which, in the transverse direction perpendicular to your collection volume, you have a very narrow scale. You can actually collect from a very small region on the order of 100 microns. Anyone know how micro splitters work? Looking at you? STUDENT: RF. JACK HARE: The answer I got is that you can buy something from DigiKey or something like that that will do it for you. It depends on your size of your lens and the wavelength of light. was RF, which I don't think is much more satisfying than my answer. So, yeah, there are circuits which will split microwaves. What they were actually doing with this system is all of these were very tunable. And so, if they wanted to look at turbulence in the edge or turbulence near the center, they could actually tune all their bandpass filters to do that. But this is getting way beyond what I was hoping to talk about on this. So let's get on to correlation ECE see what that does. we're going to write this little tilde here to remind us that this signal is some oscillating quantity or time varying quantity. And that signal has two components to it. It's got some fluctuation, which is due to temperature fluctuation. And then, it's also got some noise. This is the thing that we don't want to measure here. And so, the signal, as a function of time, is going to look like, again, our temperature signal, which might be some nice and smooth function like this corresponding to some turbulent eddy. of extracting this temperature from the noise here. And what we do is we pick two adjacent channels. These channels are adjacent in frequency space, which means that they are measuring from adjacent parcels of plasma in real space or inside the tokamak. So we say, our term is greater than delta R. Which means that, if there's a temperature fluctuation associated with this little vortex, it is the same temperature fluctuations in S1 as in S2. And, again-- oh, I don't need this to be much greater than. I just need it to be greater than or less than. on the order of 100 microns or so apart. We are going to correlate these two signals. And we're going to find that the noise is uncorrelated at random. These two signals will correlate together, and we'll be able to measure it. And, again, these are really, really closely spaced, 100 micron or so away. But, the nice thing is now that theseTwo signals are carrying the same components that we're trying to measure. And this is where the correlation comes in. is an example of nominative determinism. Someone called Watts goes around making power measurements. Yeah, and this technique is incredibly powerful because it's enabled people to measure, again, delta Te upon Te on the order of 1%. And they've done this at 13-- on ASDEX Upgrade-- 13 radial locations. So 13 positions they can measure these temperature fluctuations. And they have done this with a time step of 100 kilohertz. So 100,000 times a second they've been able to measure these temperatures. we have positioned these two volumes, which are producing frequencies omega 1 and omega 2. And we think that that distance is smaller than the size of our turbulent eddy. The temperature should be the same going up and down. And if you do this correlation and you get out nothing, that probably means your volumes are too far apart because there is-- this T correlation would just go T1 T2. And there's no good reason to believe those temperature fluctuations are correlated, because they'll be part of a different turbulent Eddy. situation where, at some point, your eddy has moved across, and these two are no longer correlated because the next two are correlated. So it-- yeah. I think we're reaching the limits of my knowledge. Yeah. Now we're going to go to bremsstrahlung. Some people these days just call this breaking radiation, which is just the translation from the German, and that's a perfectly reasonable term to use. And so, what we're dealing with is heavy ions, and all ions are heavy compared to electrons. And we've got some electron whizzing by. from its trajectory. Now, this electron isn't then just going to sail off and never see an ion again. In fact, it's going to see one very, very soon. And so, effectively, our entire plasma is full of electrons which are gently being deflected and breaking and emitting these photons. So the main thing we can say in a classical treatment is that the bremsstrahlung is going to be isotropic. That's actually quite different from electron cyclotron emission, even though we didn't really look at that in any detail. here with the ions and electrons as point particles. There's a semi-classical approach where you start bringing in some quantum physics and treat, I think, the electron as a wave. And then there's a full quantum approach. What's remarkable about all of these approaches is they all give the same answer with just a very slightly different coefficient. So we get a small change in coefficient. The scalings are the same. So, in some sense, although it's important to get the exact coefficient, it doesn't matter exactly which one of these techniques you use. from the point of view of this course, it makes no difference. Yeah, I think it's kind of remarkable that it doesn't make any difference. So, again, if you want the full treatment, go have a look in Hutchinson. And there's also a long treatment in Jackson of this same problem. I'm just going to quote some results. I kind of already spoiled it now. It's here. For the Maxwellian average, because we can have all sorts of different distribution functions, but our plasma tends towards a Maxwellian. This, therefore, has units of watts per hertz per meter cubed. And these constants are things like e, the electron charge, and the electron mass, and epsilon 0, and h bar, and c, all arranged in some way to make all the dimensions work. And you'll also find this Gaunt factor varies very weakly with the temperature of the plasma here. So this is a pretty weakly varying function. We can change it by two orders of magnitude in this parameter here, but this only changes by one order of. magnitude. And so, in general, it's reasonable to just treat G as being a constant and then, for this calculations we're doing, where we're going to drop the absolute intensity, we can just drop G with all the other constants as well. So we can drop [INAUDIBLE]. But if you want to go back and do this properly for some measurement that you'redoing, then you'd have to include this. And that is all you need to do Problem Set 3. at all frequencies, like a black body kind of spectrum here. That goes down to very low frequencies and goes up to very high frequencies. We're going to talk about lots of other effects which produce emissivity which is higher than the bremsstrahlung. But, often, when we're doing power balance calculations for a tokamak, we will just use this, and that represents our most optimistic take. So, I guess, you always need to worry about this, even if you managed to clear out all the impurities. something like that. But this bremsstrahlung may be quite small. But even if it's not quite small, it is constant because it varies only slowly as a function of a frequency. So for a small frequency window, it looks constant. And then you can just subtract off some background intensity and look at the actual signal you're interested in, like you see there. Yeah. So, yeah, we haven't really talked about that. From this j, you can now calculate alpha, the opacity, because we had j upon alpha is equal. In reality, for some plasma, we might have a spectrum that looks like this. So it goes back to being optically thin here for the high energy photons. But the low energy photons will get absorbed as well. There's actually another effect, which is in Hutchinson's book, which I haven't covered here. And so, the spectrum will be even further modified because that wave will be evanescent. But we're skipping over that this year. But it's in there if you're interested. at synchrotron, yes. Jack HARE: I think someone told me that maybe for a high field tokamaks synch rotron could start being significant. But I actually have no idea how big a deal it is. And I don't know if people are using it as a diagnostic. I've not heard of someone using it. But it's interesting in its own right. It's a source of X-rays for diagnosing many other things. It depends on what you're trying to diagnose. mostly on the magnetic field and the radius. And those are two things in a tokamak you already know. But maybe there's a really clever diagnostic you can do, like fast particles or something like that. So worth thinking about. STUDENT: [INAUDIBLE] JACK HARE: Right, but I'm not interested in [INAudIBLE]. This is a diagnostics course. Any questions online while we pause? So this is bremsstrahlung radiation, and often people call this free-free. That entire acceleration yields one photon, one energy. And so, initially, we have a kinetic energy, a 1/2 mv squared. Then, afterwards, we're going to have an energy 1/ 2 mv prime squared minus h nu. Now, if h nu is less than the initial kinetic energy here, then we still have some kinetic energy left. So v prime is greater than 0, our particle is still free, and it can continue. But, of course, there's another case where this photon takes away so much energy that this starts, I guess it becomes imaginary. where we have a range of different discrete energy levels that the electrons can occupy. These energy levels are labeled by the principal quantum number n. n equals 1, 2, 3, 4, and so on. And, up here, infinity, this is ionization. If your electron gets this much energy, it becomes free again. And the energies of these levels are given by this unit, Ry, which is the Rydberg z squared of our ion over n squared. And that's the thing that we're going to see with our spectrometer. The spectrum, therefore, looks like we had something like this for bremsstrahlung before, and now we have a spectrum that contains a series of edges, like this. And this lowest edge here-- I should draw this as a straight line-- this is n equals 1, 2, 3, 4, and all the way back up here, where, again, this is our brems result, and this isOur recombination.n of jn here. So if you're asking, what happens if you can't fulfill that, it just doesn't happen. Quantum mechanically, that would be a forbidden transition. I understand. So I was just wondering, because it's not the condition that there are photons that are released with greater than 12 mv squared the kinetic energy. It's the photon energy that's-- yeah, maybe we're doing this backwards in some sense. STUDENT: I see. So if you see a photon being emitted with more than 1/2mv squared, then the electron has over-emitted. And the only way it could have done that is if it fell down into one of these principles. we just did it in reverse. So this long tail here is due to the fact that we have electrons not just with v equal 0 but much more than that. Now, are they actually sharp or is it that we want f of distribution of v squared? I'll have a look into that. Any other questions? Yeah. I understand. JACK HARE: Yeah, I think maybe I motivated this the wrong way around. Yeah. Other questions? yeah. STUDENT: [INAUDIBLE] Jack Hare: Yes, exactly. related to the overlap integral between those with a dipole operator, the dipole operators being the thing that emits the photon in between them. So, yeah, it depends on the ion charge. If you've got some helium with 2 times ionized helium, and you'veGot some hydrogen, then it will have different recombination lines here. And that's because, fundamentally, the energy levels are in different places inside here. The energy levels shift by the ion charges here. Any other questions? time, that absorbs some [INAUDIBLE]. JACK HARE: Ooh. Wouldn't this balance out, electricity going in and out of ions? There's a very good question. We're going to get to that and the idea of detailed balance and thermodynamic equilibrium and things of that ilk. One use of this is a diagnostic called bolometry. It cares not at all about the detailed spectrum of what the emission is. It just wants to know how much power is being radiated by the plasma. This is balanced by conduction losses and what we, at the time, we assumed were bremsstrahlung losses, but in general could be any sort of radiative losses here. And so, bolometry is focused on measuring the total power that's being emitted. So we take our beautiful spectrum like this, and we integrate over all of this. We lose all of the detail. But, of course, the detail matters when we're doing the integral because you can see the recombination increases the amount of emission. So there'll be more emission here. divider just drawn in a complicated way. The reason why this is interesting is that, in general, M is going to change with T. We're going to have some resistivity as a function of temperature. And so, as this resistor heats up from absorbing the radiation, its resistance is going. to change. So if we're measuring the resistance M, we can then use some table of rho of T to get out the temperature. We'll talk a little bit more about how to do that in the next step. be digitizing this as a function of time. And so, this is also a function. of time and temperature. And all of this is time some heat capacity. And, in general, this resistor is going to be connected. It has its own heat capacity c, but it's also going to. be connected to some heat sink, which is unavoidable. And that heat sink will have some thermal transport time tau. So there's two different ways that the resistor is connected. There's actually a second term here, which was delta tau delta T upon tau, like that. radiation can affect this. And so, by measuring delta T up here, the change in temperature in our resistance, we can invert this equation and we can back out the radiation power. So this is just a really simple way of using a resistor to measure the power coming out of the plasma. And bolometry was one of the first diagnostics that we had on many MCF devices. It does not work because it is very susceptible to noise. So we have to, as always, come up with a clever system, which is noise resistant. resistors. So there's a resistor here, another resistor here. And we connect these resistors up. And the clever thing, in a bolometer, is we allow two of the resistors to see the plasma. And these are the ones we call the measurement resistors M1 and M2. So these measurement. resistors, they see the radiated power P rad, and their. temperature is equal to the temperature of the reference resistors plus a change in. temperature due to radiation. setup is your entire bolometer is going to heat up. And so, what you want to know is not just how hot they are, but howHot they are relative to the vacuum vessel. So, this is why we have this system where we're trying to measure a very small change between R1 and R2, which would be identical, and M1 and M2. And it's this small quantity here, delta T, that's due to the radiated power that we're really trying toMeasure. At the Wheatstone bridge, we also use a phase locked loop measurement, which is a form of heterodyning again, my favorite technique. And so, we actually have V0 is oscillating at around 50 kilohertz or so. So, we can see that our signal, delta T, or the change in temperature as a function of time, is a slowly varying signal which is embedded on top of this 50 kph signal. And then, using heterodyting techniques,we can measure it very cleanly without noise. This is often made out of gold. Gold is chosen because it absorbs all wavelengths relatively evenly. So you don't need to worry too much about the spectral response of this. This thin layer of gold has been deposited on top of a substrate. And it's on the back of the substrate that you have your resistor. And your resistor is literally a little zig zag of gold deposited on theBack side of this, so this is M or R. And depending on whether it is M. or R, you either have this open to the plasma or you have a thick block some distance in front of it so it can't see the plasma. heating down from direct heating and then also a time lag phenomena delta T on tau. And, effectively, this tau here sets the timescale at which we can measure. So the larger tau is the slower our measurement of the radiated power is going to be. If tau gets very large, because we've got a very thick substrate here, or it doesn't have very good heat transport, then we're going to have a very poor time resolution of our radiation power. difference between those. neutron damage leads us to use much thicker substrates, which gives us a longer time response and so, therefore, a worse bolometer. So, ironically, the bolometers that will be used on [INAUDIBLE] are significantly worse than the bolometer used on existing devices. And I'm sure that [? Spark ?] will have exactly the same problem. Almost everyone in the world uses this design of bolometer that they pioneered on ASDEX Upgrade in the '80s. No one has come up with a better system yet.

ROUGE-1: 54.37, ROUGE-2: 52.74, ROUGE-L: 52.90
BERTScore: 73.95

==============================================
==================== [79/100] ====================
Summary:
Reinforcement learning involves the idea of a model, a value, and a policy. A policy is a mapping from the state you're in to what is the action, um, to take. A model is a representation of the world and how that changes in response to agent's accident. A value is the expected discounted sum of rewards from being in a state and/or an action, and then following a particular policy. Markov Decision Processes is where we think about an agent interacting with the world. The Markov Process is to say that the state that the agent is using to make their decisions is a Markov state. The Markov process involves taking actions that affect the state of the world in some way, and then the agent receives back a state and a reward. Today, we're going to think of an agent, just focusing on the current state, um, so the most recent observation, like, you know, whether or not the robots laser range finders saying, that there are walls, to the left or right of it. A Markov Chain is a sequence of random states, where the transition dynamics satisfies this Markov property. So if you have a finite set of states, you can just write this down as a matrix. What's the probability distribution over next states that you could reach? So if we go back to the Mars Rover example, we thought of a Mars Rover landing on Mars and there might be different sorts of landing sites. And then, it can go to the left or right, um, er, under different actions or we could just think of those actions as being a_1 or a_2. what are the probabilities computed of, like the rewards, I guess, the probability, based on the reward of going from state 1 to 2 [NOISE] or? Great question. So we're assuming right now, this is, um, the, this Markov process is a state of the world that you were, there is some the, the environment you're in is just described as a Markov Process, and this describes the dynamics of that process. We're not talking about how you would estimate those. So, what would this look like if you wanted to think of what might happen to the agent over time in this case or what the process might look like? So, let's say that your initial starting state is S four, and then you could say, well, I can write that as a one-hot vector. I multiply it by my probability. And that gives me some probability distribution over the next states that I might be in and the world will sample one of those. So, it's like the world you know what the dynamics, the dynamics is of the world and then nature is gonna pick one ofThose outcomes. It's like sampling from sort of a probability distribution. rewards for the Markov Decision Process can either be a function of the state, the state in action, or state action next state. Right now we're still in Markov Reward Processes so there's no action. So, in this case, the ways you could define rewards would either be over the immediate state or state and next state, for example. Once we start to think about there being rewards, we can then think about returns and expected returns. We talked about those briefly last time, but it often we think about the case where, um, an agent might be acting forever. long time. The definition of a return is just the discounted sum of rewards you get from the current time step to a horizon and that horizon could be infinite. If the process is deterministic, these two things will be identical. But in general if theprocess is stochastic, they will be different. So, what I mean by deterministic is that if you always go to the same next state, no matter which if you start at a state if there's only a single next state you can go to, uh, then the expectation is equivalent to a single return. General case, we are gonna be interested in these stochastic decision processes which means averages will be different than particularly runs. So, for an example of that well, let me first just talk about discount factor and then I'll give an example. Discount factors are a little bit tricky. They're both sort of somewhat motivated and somewhat used for mathematical convenience. We'll see later one of the benefits of mathematic, uh, benefits of discount factors mathematically is that we can be sure that the value function sort of expected discounted sum of returns is bounded. There's often a bounded number of time you know bounded length of course in many many cases that the horizon is naturally bounded. So, in this case you know what might happen in this scenario we start off in s_4. Um, and then on time-step s_7 we get a reward of 10. But that has to be weighed down by the discount factor which here is 1/2. And so the sample return for this particular episode is just 1.25. And of course we could define this for any particular, um, episode. The Markov structure allows us to decompose the value function of a Markov Reward Process. The value function is simply the immediate reward the agent gets from the current state it's in plus the discounted sum of future rewards weighed by the discount factor times the- and where we express that discounted sum is we can just express it with V, V(s'). So, we sort of say well whatever state you're in right now, you're going to get your immediate word and then you'reGoing to transition. And you could just do this many many many times. And then average. And that would asymptotically converge to what the valuefunction is. to some state s' Um, and then you're going to get the value of whatever state you ended up in discounted by our discount factor. So, if we're in a finite state MRP we can express this using matrix notation. Um, we can say that the value function which is a vector is equal to the reward plus gamma times the transition model times V. And the nice thing is that once we've done that we can just analytically solve for thevalue function. The question was was if it's possible to have self-loops? Um, could it be that this is sort of circulator defined [NOISE] in this case? So, if one of the transitions can be back to itself, um wouldn't it be become a circular to try to express V in terms of V(s)? And if you have N states, it's fine if some of the states that you might transition back to the same state there's no problem. You do need that this matrix is well-defined. so let's say you have N states there's generally on the order of somewhere between N squared and N cubed depending on which matrix inversion you're using. Is it ever actually possible for, uh, that matrix not to have an inverse or does like the property that like column sum to one or something make it not possible? Question was is it ever possible for this not to has an inverse? Um, it's a it'sA good question. I'm trying to think whether or not that can be violated in some cases. Markov Decision Processes are the same as the Markov Reward Process except for now we have actions. So, the agent is in a state they take an action, they get immediate reward, and then they transition to the next state. And as was asked before by Camilla I think, the reward can either be a function of the immediate state, the state and action to the state action and next state for most of the rest of today we'll be using that it's the function of both theState and action. in a state in K action, why is it deterministic what the next state is? Question is same like well why is this- why are there stochastic processes I think. Um, there are a lot of cases where we don't have perfect models of the environment. May be if we had better models then things would be deterministic. And so, we're going to approximate our uncertainty over those models with Stochasticity. So, maybe you have a robot that's a little bit faulty and so sometimes it gets stuck on carpet and then sometimes it goes forward. A Markov Decision Process policy specifies what action to take in each state. And the policies themselves can be deterministic or stochastic, meaning that you could either have a distribution over in the next action you might take given the state you're in or you could have a deterministic mapping. So, if you have an MDP plus a policy then that immediately specifies a Markov Reward Process. And similarly you can define your transition model by averaging across your transition models according to the weight at which you would take those different actions. expected discounted sum of rewards. Now you might ask, okay well they- are they ever guaranteed to stop changing? And we'll get to that part later. We're going to get to the fact that this whole process is guaranteed to be a contraction so it's not going to go on forever. So the distance between the value functions is going to be shrinking. And that's one of the benefits of the discount factor. So if people don't have any more immediate questions, I suggest we all take a minute and then just compare with your neighbor of what number you get when you do this computation. to be pi up there. Yes it was, thanks for catching. All right, so now we can start to talk about Markov Decision Process control. Control here is going to be the fact that ultimately we don't care about just evaluating policies, typically we want our agent actually be learning policies. And so in this case we're not going to talks about learning policies, we're just going to talking about computing optimal policies. So the important thing is that there exists a unique optimal value function. before we do this let's think about how many policies there might be. So there are seven discrete states. In this case it's the locations that the robot. There are two actions. I won't call them left and right, I'm just going to call them a_1 and a_2. Then the question is how many deterministic policies are there and is the optimal policy for MDP always unique? So kind of right we just take like one minute or say one or two minutes feel free to talk to a neighbor. The optimal policy for an MDP and a finite horizon problem where the agent acts forever is stationary. It's stationary which means it doesn't depend on the time-step. If you would always do action a_1 from state s_7 now, um then if you encounter it again in 50 time-steps you still have an infinite amount of time to go from there. So, if you have a lot of compute, you might just want to and this might be better if you really care about wall clock and you have many many many processors. Policy improvement is the next step in the Markov Reward Process. The next critical question is how you bring you function and you function. Is this going to be like finding a local maximum goal then its kind of gets stuck there and [inaudible] for actions. So, we're guaranteed to converge to the global optima and we'll see why for a second. Okay. So this is how it works. You do this policy evaluation and then compute the Q function and then you compute the new policy that takes an arg max of Q. that quantity for each state. But the strange thing is that we're not gonna follow the old policy from then onwards. We are going to follow this new policy for all time. So, it should be at least a little unclear that this is a good thing to do [LAUGHTER]. Should be like, okay, so you're saying that if I were to take this one different action and then follow my old policy, then I know that my value would be better than before. But what you really want is that this new Policy is just better overall. strict inequality if the old policy was suboptimal. So, why does this work? So, it works for the following reasons. Let's go ahead and just like walk through the proof briefly. Okay. This is- what we've said here is that, um, V^pi_i(s), that's our old value of our policy. Has to be less than or equal to max a of Q#pi. Is equal to R(s, pi_i+1(s) If the policy at pi, so the question here was to say, if pi of i+1 is equal to pi i for all states, could it ever change again? Somebody wanna share a guess of whether or not that is true? And the second question is, um, is there a maximum number of policy iterations? Yeah. There's no- you can't have more iterations than there are policies. There- We know that there is at most a to the s policies. You cannot repeat a policy ever. And so, there's no policy improvements to be, yeah, to change. work? The algorithm can be summarized as follows. You start off, you can initialize your value function to zero for all states. And then you loop until you converge, um, or if you're doing a finite horizon, which we might not have time to get to today. And basically, for each state, you do this Bellman backup operator. So you'd say, my value at k plus one time steps for that state is if I get to pick the best immediate action plus the discounted sum of future rewards. on sort of the contraction operator. So, for any operator, um, let's let O be an operator and x denote a norm of x. So x could be a vector like a value function and then we could look at like an L2 norm or an L1 norm or L infinity norm. If an operator is a contraction it means that if you apply it to two different things, you can think of these as value functions. So just to, um- actually, I'll save examples for later. But this is the formal definition of what it means to be a contraction. doesn't get bigger and can shrink after you apply this operator. So, the key question of whether or not value iteration will converge is because the Bellman backup is a contraction operator as long as gamma is less than one. So how do we prove this? Um, we prove it- for interest of time I'll show you the proof. Again, I'm happy to go through it, um, I- or we can going through it in office hours et cetera. Okay. between the two value functions can't be larger after you apply the Bellman operator than it was before. There has to be a unique solution. It's also good to think about whether the initialization and values impacts anything if you only care about the result after it's converged. All right. Class is basically over. There's a little bit more in the slides to talk about, um, the finite horizon case, and feel free to reach out to us on Piazza with any questions.

ROUGE-1: 32.63, ROUGE-2: 31.58, ROUGE-L: 31.30
BERTScore: 66.31

==============================================
==================== [80/100] ====================
Summary:
 angular momentum is a set of operators that provide observables, things we can measure. They are important for systems in which you have central potentials. Potentials that depend just on the magnitude of the radial variable are relevant to cases where you have two bodies interacting through a potential that just depends on the distance between the particles. We found there was another object we could measure, which was the square of the total angular momentum. l squared is, by definition, lx times lx, plus ly times ly, plus lz times lz. This is this operator. And we showed that any component of angular momentum, be it lx, ly, or lz, commutes with l squared. Given that they commute, it's a general theorem that two operators that commute, you can find simultaneous eigenstates of those two operators. And therefore, we set up for the search of those wave functions that are simultaneous eigestates of one of the three components of angular Momentum. Everybody chooses lz and l squared, lz being proportional to angular momentum has an h bar m. for it. All these things were taken care of by l squared. The differential equation for l squared ended up being of this form. For the case of m equals 0 it simplifies very much so that it becomes an equation for what were eventually called Legenre polynomials. We looked at that differential equation with m equals0. We called it pl 0. So we don't write the zeros. Everybody writes pl for those polynmials. And looking at the differential equation one finds that they have divergences at theta equals 0. are the Legendre polynomials. Solve this equation for m equals 0. Are there any questions? Anything about the definitions or? Yes? AUDIENCE: Why do we care about simultaneous eigenstates? PROFESSOR: Well, the question is why do we want to figure out what are the properties of the states? In general, you will be led in any physical problem to look for the maximal set of commuting operators. The most number of operators that you could possibly measure. for every allowed energy, except for 0 energy, but two energy eigenstates. And you would be baffled. You'd say, why do I have two? There must be some difference between these two states. And in that case the answer was simple. It was the momentum. You have a particle with some momentum in one direction, or in the reverse direction. So in general, it's a most important question to try to enlarge the set of commuting observables. Leading finally to what is initially called a complete set of commutes. and an electron we can reduce this system to as if we had one particle in a central potential. So that will be also very important physically. And here there is a simple observation that one can make. Is that the differential equation for p l m depends on m squared. We expect to need values of m that are positive and negative. You have wave functions here, of this form. The complex conjugate ones should be thought as having m negative. So we expect positive andnegative m's to be allowed. definition solves the differential equation star. This takes a little work to check. It's probably something you can find the calculation in some books. But it's not all that important. The important thing to note here is the following. That this provides solutions. And there's no great honor in finding zero solution of this equation. These are no solutions. So this produces solutions for an, absolute value of m, less than l. And therefore m in between l and minus l. It is a theorem that there are no more solutions. No additional regular solutions. that don't diverge. So this is very important. It shows that there is one more constraint on your quantum numbers. This formula you may forget, but you should never forget this one. This one says that if you choose some l which corresponds to choosing the magnitude of the angular momentum, l is the eigenvalue. You will have several possibilities for m. There will be several states that have the same l, but m different. So for example you'll have l equal 0, in which case m must be equal to 0. The spherical harmonicas are going to be those wave functions. And they have a normalization, n l m, an exponention, and all that. So let me write, just for the record, what a y l m looks like with all the constants. The only one I really remember is that y 0 0 is a constant. It's 1 over 4 pi. That's simple enough. No dependents. Here is another one. y1 plus minus 1 is minus plus square root of 3 over 8 pi e to the plus minus i phi sine theta.

ROUGE-1: 58.27, ROUGE-2: 56.09, ROUGE-L: 58.05
BERTScore: 74.34

==============================================
==================== [81/100] ====================
Summary:
In order to do that, I basically have to do the integral. So here it is. We have psi of x and t. It's integral dk phi of k e to the ikx minus omega of kt. If you want to see the distortion, you have to keep that [INAUDIBLE]. We'll do that in a week from now. And then, you say, look. There's lots of things making it look like a difficult integral, but it's not as difficult as it looks.

ROUGE-1: 15.65, ROUGE-2: 15.13, ROUGE-L: 15.65
BERTScore: 62.97

==============================================
==================== [82/100] ====================
Summary:
There are three common uses of a rotation matrix. The first is to represent an orientation. The second is to change the frame of reference of a vector. And the third is to rotate a vector or frame. To demonstrate these, I will use these three coordinate frames, representing the same space with different orientations. To help you visualize these frames in 3 dimensions, I’ll use my handy tinkertoy frame. This is the z-axis, this is the x-axis and the y-axis. we will learn how to represent the angular velocity of a frame. We will also learn about how to use the frame to represent a frame's angular velocity. We'll also look at how the frame is used to represent an object's speed. We hope you will join us for the next few weeks of classes on how to work with a frame in this class. The next class will be on the physics of the frame in which we are working. The final class will take place in the next week or so.

ROUGE-1: 35.22, ROUGE-2: 26.36, ROUGE-L: 29.92
BERTScore: 66.09

==============================================
==================== [83/100] ====================
Summary:
 RAMESH RASKAR: So this is a position, and this is superposition. And that concept of a position or superposition applies to all three types, shadows- or refraction- or reflection-based techniques. So we saw this last time, and we'll see how-- we already have some projects that are inspired by biological vision. You know, Matt is trying the chicken. And I think it's going to be-- [LAUGHTER] It is going to. Coded imaging is a co-design between how you capture the image and how you process the image. In a typical film camera, or even it is digital camera, you take the picture, and that's basically the end of the story. Here, you're trying to do something clever about how the picture is taken. You can either take a really short exposure photo. But that's going to be very dark. If you take a high ISO, you can recover some information. Or you can just take a long-exposure photo by keeping the shutter open. Photographer RamESH RASKAR: When you try to recover this information, you start getting this banding artifacts. And we'll see it in the next slide, why that happens. If you keep the shutter open for even longer, it'll blur correspondingly longer. So you can basically represent that as a sharp photo, where there is a convolution of the sharp photo with some kind of a Convolution filter. But then you will get a blurry photo, which is well exposed, but a lot of high-frequency details are lost. have basically a 1D convolution that's converting this image into this image. But the Fourier transform has some zeros, so you cannot divide those frequencies by 0 and recover an image. So the culprit here is really this low pass filter where some of the even lower frequencies are also being nullified. And there's nothing you can do to recover those frequencies because in the Fouriers domain, all you have to do is take the Fouries of this and divide by this. And it will give you the image. box function, which is equivalent to-- when you release the shutter, opening the-- release your shutter button-- opening the shutter and keeping it open for exposure duration and closing it. Instead of keeping the shutter open for the entire duration, you open and close it in a carefully chosen binary sequence. So at the end, you still get just one photo. But now something magical has happened because first of all, if you look at this number one, you'll see that it's not the same as before. It has-- it seems to have these replicas. frequencies-- they're all preserved. Of course, they're attenuated. It's not as high as-- it's not 1.0.0, it's reduced. Maybe it's 0.1 or so. There is still some hope to recover this photo back from this because, in the denominator, we will not have seen. this because of the shutter. So of course, if you try to implement this mechanically, where you open the shutter and then mechanically try to close the shutter, that will be problematic. The idea is very simple. Instead of keeping the shutter open for the entire duration and getting a well-exposed photo, the shutter is open for only half of the time. The support for the representation of the Fourier domain of that function that you describe there is infinite, right? So you actually truncate this in order to-- RAMESH RASKAR: It's not infinite because you still have some width. AUDIENCE: Right, but you have infinite high frequencies there by the sharp conditions. I mean, you can think of this one goes to infinity. But there's hardly any energy left. So although it went to infinity, there is not much energy left in the process. When you get to invert the process then, that's why you're still not getting the perfect images to-- RAMESH RASKAR: In this case as well. You still lost some high frequency, right? You haven't seen the results yet for this. But it's a very controlled experiment in a laboratory. but not 0. If you invert the process-- RAMESH RASKAR: From here, this is what you get. It cuts off and corresponding to the width. The width of this post was very short than yesterday were very far away. And that's this loss of these frequencies also shows up as these artifacts at regular frequencies, at regular intervals. So, again, this one-- this doesn't go to infinity all the way. It's open for two milliseconds, open for four milliseconds. filter from space? RAMESH RASKAR: It corresponds automatically to filter in space. So your 52 vector is going to stretch or shrink based on how fast the object is moving. And you mostly have to think about image space motion because the speed in the real world and-- the distance are they get-- you divide to normalize by the distance. If you're in a dark room, you can just strobe the light, rather than opening and closing the shutter. So you only have to worry about the image space distance. mobile demo of that scene. You need to know the motion or the direction of the motion. If we did 100 milliseconds, it picks up speed. Some parts will go faster and slower. It's acceleration in the measurement, but in the real world, it's still constant speed. You can either go to object space or you can come back to image space to make sure there is no acceleration. It is all linear. So you get a reasonable result. But going back, what are the limitations of this method? Yes. have multiple cars, for example, and they're all independent, then it's fine. As long as it's moving in a straight line at a constant speed, you're OK. But if the two cars overlap, what happens? Our model fails again. If two cars are partially overlapping during the exposure, it's possible, but it's more challenging because you don't know exactly how fast the two car are moving. So it's just like-- AUDIENCE: OK, but that's just so you can get more light. When I take a picture, the camera automatically decides what the exposure time should be. Similarly, you should look at the speed of how things are moving maybe with an ultrasound Doppler or whatever. You need to know how much the blur is. Another major disadvantage is let's say I want to take this bottle. And if I just rotate it and motion blur that, it will not work. For any point in the front that you're looking at it, it'll work. But the point that was in the back, that all of the 52 sequence-- maybe for the first 10, it was occluded. And the remaining 42, it's seen. during that 52 window. In general, the technique works well when things are moving naturally. But if somebody wants to do this kind of an experiment, or move things behind an occluder and move out, those are very challenging scenarios. Can you combine both horizontal and vertical [INAUDIBLE] masks? RAMESH RASKAR: Vertical, horizontal is fine. You can-- it doesn't matter. It could be moving vertically. Basically, your point spread function-- the blur function will be vertical rather than horizontal. of that object moves in a straight line, OK. It doesn't matter which direction and what speed. So the problem here really is the point spread function or the blurred function is very critical. And this is what we want to study about half of the class. And the concept is very, very,Very interesting because light is linear. So eventually, it's very linear. What happens to a point happens to the rest of the object. So if I have a car that's moving, and I tell you how exactly one point of the car is behaving in the image, I can tell you automatically how the other points are behaving. All of it is going to have the same behavior. same spread image. So you can either-- for experiments, you can just put an LED on the car and see how that LED moves. And that tells you everything. There's also an impulse response. And when you're trying to find a speed of a car, [INAUDIBLE],, a very small impulse. And it answers and comes back. It does. The point spread function for your time of flight. So that's the same concept here. You just want to call leading the world, take a picture, andsee how it works. to engineer activity of the camera. So in this particular case, a point that was moving created a blur like this. And by engineering the time point spread function, it stops looking a bit like that. And then it just turns out that this one is easier to deal with than this one. So that's the basic concept, engineering or actively changing the point spreadfunction. So this is very counterintuitive because you would say, let me just build the best lens and the best exposure time. And so that kind of mimics the human eye. hope, there is some computational technique, that will allow you to go from here to here. As far as I know, animals don't have deconvolution circuitry or deep-learning circuitry. I can look at a blurry image and kind of figure out. I mean, this was a challenge for you, right? Right. So we have pretty sophisticated eyes, but we're still not able to deep learn what this is. If you have some prior knowledge of how the Volkswagen logo looks like, maybe you can say, OK, maybe that was this. But on the other hand, you're immediately willing to believe that this photo is a blurred version of this photo. to recover some information. The goal of coded imaging is to come up with clever mechanisms so that we can capture light. The circuit is very, very simple. You just take the hot shoe of the flash, and it triggers. When you lose the shutter, it triggers the circuit. And then you just cycle through the code that you care about. What can we do for defocus blur that is for motion blur? What can you do fordefocus blur? We, again, want to engineer the point spread function. would you apply spatial coding? AUDIENCE: Coded aperture? RAMESH RASKAR: C coded aperture. So this is coded exposure, coded aperture-- very easy. And all you're going to do is put some kind of a code in the aperture of the lens. And this is how, actually, it started in the days of-- in scientific imaging, especially in astronomy, coded apertures are very well known. So I've been following this for a long, long time. And I thought, it must be useful for something in photography. system. It took almost two years to realize that to put this coded aperture in a camera, there are only a few places where you can put it to get good results. So out of that came this particular experiment. And that was just a graph paper. And then we said, OK, let's come back and think about this. What's going on? Why don't we get good Results? So it took nearly two years. To see the full interview, go to CNN iReport.com. This is a standard film lens, which, of course, can also be used with a digital camera. It's 100-millimeter focal length lens. When you focus with this, it works in very interesting ways. It has to deal with chromatic aberration, geometric aberrations, such as radial distortion. So it has to move all these lenses with corresponding ratios, OK? So I'll pass this around, and you'll see that there are these notches on this lens that are in a parabolic fashion. When you think about a visual camera, you make this very simplistic assumption. That is a pinhole, and there's a sensor. When you put a lens, we assume that the center of the lens is the central projection. So when you change your f-stop and decrease it and increase it, it's all happening in theCenter of projection. For professional lenses, that's not true. But for normal cameras, you have theCentral projection. But again, conceptually assume that all the rays are going through that point. Ramesh Raskar: If you put the sensor all the way here, you'll see the whole code. If you start moving away, the code will shrink. When it's auto focus, we just see the code, all right? By the way, this is the same idea behind another project, which is [INAUDIBLE]. So the idea came around at the same time of how to make this happen. And eventually, when you put it here, we get another code. That's exactly what's happening here. I'm in a different mode. If I look at this picture, you will see that-- so this is a sharp photo. It's blurred with disc. And it's blurred With that function. You can already see that it seems to preserve slightly more information. But it's still-- you won't be able to with your naked eye. You'll not be able. to figure out what underlying patterns are. After the blurring, you can. do these simple tricks, where the person you're interested in is out of focus. But then you can refocus digitally. So this is the input photo and the stock photos, all right? its Fourier transform is 52 long. So there are 52 entries here, and almost all of them are the same. If I just take a square aperture, a traditional one, and take asquare transform, it will look something like this. So a Fourier transforms of 7 by 7 will have a peak in the middle. But the rest of the time, it's more distributed instead of just all being near the center. It's more like a crossword-puzzle-shaped item, should be easy. In communication theory, everything is [INAUDIBLE].. We think about carrier frequencies of radio stations in frequencies. And convolution, deconvolution-- much easier to think in frequency domain. Although all the analysis in the frequency domain, at the end, the solution is very easy-- just flutter the shutter or just put. the values will be constant. And that's the magic of a broadband code. So if we're placing a broadband. code, certainly we have an opportunity to recover all the information. a coded aperture. Extremely simple solution to achieve that. It's very similar to the [INAUDIBLE].. AUDIENCE: Half the light. Very good. RAMESH RASKAR: Are there disadvantages? Or challenges? Not really disadvantage. Remember, in the. in the photo, at a distance, take our false photo. They will all look like this. At a distance,. At adistance, takeOur false photo, they will allLook like this, or you could put hearts in it, or, like-- motion case, we had to know how much the motion is. But the size of the blur is dependent on what? AUDIENCE: Belt. RAMESH RASKAR: The belt. But not just depth-- depth from the plane of focus, right? So that's an extra parameter you would estimate somehow. Maybe you can use a rangefinder or something like that, or just a software. There are methods you can employ. That's what you would do, like, in a light field, when we did the refocusing. the depth. When it comes into sharp focus, my edges, that must be the right depth. Unfortunately, it doesn't work out in this case. The main reason is that, because it's coded aperture, no matter where you refocus, it still looks like it has very high frequencies. So that makes it challenging. Yes. And we won't go into the detail, but the main reason for that is that it's a coded aperture. So you need to find this 7-by-7 pattern or even the previous case, the 52 pattern. And you take a random sequence. I said, by the time I come tomorrow morning, I'll find a really good code. And I came back next morning. Nothing had happened. I waited all day. It was still running. And it never came out of that. So 2 the 52 is pretty challenging. But even if you use a cluster, it's still a pretty big number. And there are all these theories about how to create different codes for different applications. So you can start with some code and do a gradient descent and so on. good solutions for 2D. But for 1D, there are some really good solutions to come up with that. For 2D, for certain dimensions, they call it one more 4 or three more 4. Basically, when you divide by 4, the remainder can be 1 or 3. And there are certain sequences that are beautiful mathematical properties, of which sequences could have broadband properties and which may not. So it turns out you cannot-- there's a little bit of cheating going on here. filter to the beginning of the signal. This particular filter is actually not circular, but it's linear. So when you apply the filter here, when you start applying the filter at the end of the image, you don't go back to the front. For circular convolution, the match is very clean and beautiful and smoother course work. Or for linear convolution,. there is no good mechanism. So we came up with our own code called RAT code, R-A-T, which is after three quarters. convolution-- I mean the linear convolution is basically circular convolution with a lot of padding of 0s. Finding a code that's 1,000 long is nearly impossible. So, yeah, so it seems like can just choose a random sequence and get a similar property. But actually, it doesn't work. The chances of arandom sequence doing the right thing for you is very, very low. Instead of [INAUDIBLE].. [LAUGHTER] AUDIENCE: Are astronomy people are already using-- In astronomy, you have circular convolution because they use either two mirror tiles and one sensor or one mirror tile and two sensors. If you tile aperture, you'll get really horrible frequency response, unfortunately, because if you put two tiles, that means certain frequencies are lost. But that's because our eyes are not very good at thinking about what the original image could be, given either this one or the previous one. So given this, I can challenge you that you're not able to predict that it has all this structure, right? yet. There is no medium filtering or smoothing or anything. It's just pure x equals b, x equals a backslash b. What's amazing about coded imaging is that the math is elegant and beautiful and sometimes complicated, but the implementation is very easy. At the end, all I had to do is put this code or shutter it, and very easy to explain. All right, so let's move on. OK, let me finish this one. We only saw two ways of engineering the point spread function. question. RAMESH RASKAR: Yes, go ahead. AUDIENCE: What if the mask was not quite? If you have some information by the board so that you could set up approximate [INAUDIBLE].. RAMESHRASKar: So what would you have? RASkar: In case of aperture, yes. It doesn't have to be opaque or transparent. It could be a continuous value. It turns out that, for any continuous code, there is a corresponding binary code that will do an equally good job. so far. And that's because in a binary code, you get to play with the phase function. Mike? AUDIENCE: Has anyone tried to combine the coded aperture and the coded [INAUDIBLE]? RAMESH RASKAR: That's a great idea. People talk about it, but nobody has done it. It's like we are sick of it, so we don't want to do it. But I think it's worth trying. And because those are orthogonal motion blur. Can you use both at the same time and record? There are orthogonal technologies, basically. RAMESH RASKAR: Exactly. So it's amazing because motion is time, and the focus is space. They're completely Orthogonal. So you can play with it. It's very interesting. Eventually, it's going to have a 2D projection. Yeah, eventually, it'll be able to do that. It'll be very interesting to see how it'll work in 2D. It will be very different from what we've seen before. at the top-- I'm sorry, at the bottom. The bottom one goes at the top. And when you think about the cross-section of all the straws, it's kind of cylindrical, when they all come together. So no matter where you are, the image is out of focus but by the same amount. It turns out that from that, you can recover images. Like, so this is open aperture. We discussed it in the class, so I hope you remember that. saw this right in the very first class, by the way. And the benefit of that, it turns out, is that it preserves the spatial frequencies, and it has the benefit that, no matter which steps you are at, you have the same defocus blur. So the disadvantage of coded aperture was that you need to know what the depth was to be able to deblur. But now, because it's independent of depth, you can just apply the same deconvolution and get back a sharper image. adding small matchsticks on top of the main lens-- or the way they do it is they actually put one single sheet that looks like that, an additional layer of support, a face mask. A face mask basically means you are changing the face of incoming light. That's why, as we learned about at the beginning, if you have something very far away, this slows down a little bit. This is the Syrian optic solution or the [INAUDIBLE],, which is actually bought as another company. the name. The solution is very similar. I'm sure they're fighting out in court right now. Same solution. Instead of putting this particular guy, that's just going to add some extra glass, but mostly in a minor form. It's just [INAUDIBLE] on that one. So basically the same solution but creating different focal length for different [? partners. ?] AUDIENCE: Yeah. Although you said, I mean, there's this portion there, where if you have another blur [INAudIBLE],, right? RAMESH RASKAR: Right. blur is only about 10 pixels, no matter where you [INAUDIBLE]. So maybe that was the matter. If you have a point of access, it's still going to create an image that's blurred 10 pixels. This is, again, very counterintuitive, where you go to make the image intentionally blurred. It's just that it's blurred everywhere. And then we also saw this one very early on, where the point spread function-- typically when something goes in and out of focus, it looks like a point. some point, they'll stay the same. RAMESH RASKAR: The xy still remains traditional microscope 1 micron, 1/2 micron. But the z-dimension is 10 nanometers. They are still working on a lot of these concepts. OK? So let's very briefly look at compressed sensing because it's something you should be familiar with. It's a very cool idea, by the way. As a scientist, I really like it. But when somebody like Technology Review or Wired Magazine says, Top 50, Top 10, of course, I wish I'm listed among them. Raskar: Single-pixel camera was listed as one of the big things in 2005 by Technology Review. The idea is, instead of taking one single photo, what you're going to do is-- let's say that's your scene. You're go to turn on-- you go to take a single photodetector and aim it at a set of micrometers. And one at a time, if you go through this million pixels, you will get a million megapixel image, right? you had this photo as a JPEG. In a composite, it might take up only about tens of thousands of bytes. So if I can represent the image with 10,000 bytes, and I'm going to. take a photo and compress it down to 10,00 bytes, I can't just directly measure only 10.000 values in the scene so that I save on everything, OK? So I can take this picture effectively with just 10, 000 pixels but recreate a million-pixel image. That's where the concept of compressive sensing or compressed imaging comes up. can transform the image and measure in [? your ?] measurements. In general, this scheme doesn't work. But you will continue to see people who come to you and say, you know, I have this magical thing I just heard or compressive image something, and that will just solve a problem. There are certain images, like cartoons, that can be represented with very few samples because they have flat regions, sharp boundaries, and fluctuations. But a natural image, unfortunately, cannot be transformed that easily. Danish photographer RamESH RASKAR: Compressive sensing allows you to build a camera with a single sensor. But do we really want it just to do compressed sensing? He says if somebody can build this and show that you can take fewer measurements and recover the image, that's a breakthrough. He says the secret of success for film, of film photography, is that if somebody had given you this problem before the invention of film, that there is a scene-- and I want to give you a sensation of the same scene. Photography is a record of visual experience, which is great for humans, but not so great for computers. What computers care about are all these high-level features. That's why we're going back to the drawing board and saying, let's build cameras that are not mimicking human eye but actually extracting more information, like [? apertures ?] that we remove the flash camera, or additional information with light-field cameras or multi-spectral cameras and so on. of-- so Brett was asking, why would you want to do [? precisely? ?] When do you have to reduce the number of measurements? And I think one of the problem [INAUDIBLE].. I don't know. The debate about whether it's really better or not is photography. RAMESH RASKAR: Tomography, yeah. Tomography is a very high-dimensional signal. There are only a few places. If you think about taking a CAT scan of your body, there are only four or five types of materials. Compressive sensing allows you to take less measurements. But the problem is you need to actually have more information about the scene before you take the measurement, which is another measurement. Compressive sensing is not used in anything commercially currently, but a lot of people are getting grants. It's a high-dimensional signal, 2D camera and 2D projector, but what you're trying to recover is two dimensional. So tomography is the same, it's 4D capture for 3D representation. which is how to write a paper and wishlist for photography. Which isHow to Write a Paper and Wishlist for Photography: How to Write A Paper and Write A Wishlist For The Camera. For more information on writing a paper or wishlist, go to: http://www.cnn.com/2013/01/30/photography/how-to-write-a-paper-and-wishlist-for-photography-how- to- Write-A-Paper-And-Wishlist.html.

ROUGE-1: 50.33, ROUGE-2: 47.81, ROUGE-L: 46.71
BERTScore: 71.52

==============================================
==================== [84/100] ====================
Summary:
Prof: You know why I am dressed up? When I do this course and when I do the first half of the French course I do a lecture on the bourgeoisie, the middle classes. Middle class was a form of self-identity that was constructed in the way being a worker was constructed, or being a noble. When you look at me dressed like this, please try to think, knowing me a little bit as you do, why it was that it meant a lot to dress like this in the nineteenth century. of class identity for ordinary people, for working people, the bourgeoisie had as strong a sense of self-identity as any social class you could imagine. It was, as I'll make the point in a minute, difficult to get into that class if you weren't born into it. The fear of falling out of it was something that helps motivate lots of political things in the nineteenth century. Once we've got an increase in the wealth of the middle classes, then you wanted the political power. You wanted access to information through the press and print culture. The French Revolution opened the way by removing legal blocks in very many places to the career open to talents. Napoleon used to say tediously that in each soldier's backpack there was a marshal's baton, or staff that you could get promoted with good work, hard work, if you didn't get your head blown off in one of these battles. The bourgeoisie did anything but that. Work was part of how they believed to get ahead, and getting ahead is what they wanted to do. It was always in the nineteenth century sort of classic to poke fun at bourgeois culture, and in some cases the lack of it. One employer wrote in the 1830s that, relative to his workers--is that the worker, I couldn't invent this, "should be constantly harassed by need, for then he will not set his children on the right path" It was a classic to ascribe to the middle classes philistine habits in which making money was really the only thing that counted. a bad example and his poverty will be the guarantee of good behavior." Of course, this is a caricature of middle class self-absorption, of narcissism, of this inveterate cruelty to the classes below them. On the other hand, the more we study the middle classes, we see certainly that no matter where you look one of the things the middle class people did was form voluntary associations. The middle class formed voluntary associations, and many of these were for extremely charitable purposes, particularly in Britain. There's always this tension between families who needed children's income, however small that was. The Society for the Protection of Cruelty to Animals is one of the classic examples of bourgeois voluntary associations doing good things. For all the bad press that the middle class has had, there is also this good side that should be evoked as well. In terms of organized religion, the middleclass goes to church more than ordinary people, than workers, for sure. In the case of peasants it depends on where. Religion was a fundamental part of the British middle class's view of itself. The percentage of people who went to church could be exaggerated. There's a massive kind of church building campaign that has its counterpart in almost every country as well. After the Paris Commune of 1871 they start building churches in France, and in other countries as well, including the U.S. and Germany. The church movement in France is well studied, but you still had this de-Christianization. in the working class districts perched on the edge of cities. More about that in another lecture. Religion for the middle classes has a greater role in their lives than in working class cities. In the case of the peasants, there weren't any peasants left in England. I'll talk about that and it will be fun to talk about in one of these lectures. Anyway, there we go. How many people would have considered themselves middle-class? How do we know? How would you know who is middle class? the 1970s on what they used to call the new urban history, which is counting people up and deciding who might well have considered themselves middle-class. Inevitably I have to talk some about Paris because the work is so rich there. A woman called Adeline Daumard wrote a dissertation that was subsequently published called Les Bourgeois de Paris. She determined that somewhere between seventeen and nineteen percent of the Parisian population in the first half of the nineteenth century would have been considered bourgeois. Hamburg, Bremen, and Lübeck, and Hamburg above all, have a very enormous bourgeoisie. Barcelona is a really natural economy based upon important economic relations between its hinterland and Barcelona. Naples is one of the biggest cities in Europe right through the early-modern period. In Poland, Warsaw had a large--I was just at a history museum, a fascinating one at Warsaw Museum a couple months ago. In Russia, the estimates are about two percent of the population were middle class. of Istanbul, but Istanbul isn't in the Balkans, but with an important middle class. At the very top there are the great bourgeoisie, the big bourgeoisie. These are people who are big financiers. The nineteenth century bankers will become much more important for perfectly obvious reasons. They are big wholesale merchants who are making bundles shipping things from here to there. You won't yet find lawyers and people like that. What also makes them the high bourgeoisie, a small percentage, is that they have access to money. There's a revolution in France in 1830, yet another one that you can read about. Arguably--Marx says this and in a way it's sort of true--what it does is it brings to power in France the big bourgeoisie. They have the ear of the king, Louis-Philippe, who calls himself the Citizen King. He would rule from 1830 to 1848. He was noble. But in the official government he was not any bourgeois. That's what he calls himself. He's still the king. paintings of him you see people dressed like me who are coming into the throne room. They have power. He wants them in the painting with him. That's terribly revealing. So, these are people,. these are big bankers, high financiers at the top. Then you've got other layers of bourgeoisie. You can kind of fill in the gap. Here we have smaller bankers, not in size but in money, industrialists, merchants, these kinds of people. Lawyers rise up rapidly in popular esteem and usefulness. The middle class likes to see themselves as useful. Notaries know all of the secrets of people with money, he says. Notaries are important in all these countries, et cetera. Then at the bottom you have the petty bourgeoisie, and everybody's making fun of the petty bourgeois, but they too had a self-identity. Can you imagine going to a professional history conference where they all had their little nametags? All they do is they start up your body and look at your nameteags, and see if it's worth looking at your face. Pathetic. Can you imagine going to a conference like the World Congress of the Petty Bourgeoisie? "Hi, my name is Albert." But they had a self-identity. Who are in the petty bourgeoisie? Lots of these classically new nineteenth-century professions--schoolteachers. Schoolteachers were a way of social mobility for peasant families. Out of the working class or out of the peasantry female schoolteachers become increasingly more important. Master artisans own the tools that their journeymen work with. They rent or own their shops. times, as you know, in the French Revolution--;the French revolutions, and in the revolutions of 1848. They're always there. These folks are here, too. People are always dumping all over them needlessly. I will give you some example. If you've ever read the great French novelist--;he was paid by the word, but Balzac is really the novelist of the bourgeoisie. When he describes Paris and the seventeen to nineteen percent of the population who are increasingly living in the western part of Paris, he describes it as a jungle. as a jungle. In several hundred brushstrokes, Daumier captures the look of panic on his face because he's going to go home without his hat. He's got to buy one, and they've got to put the money together so he is not going to fall off the ladder in this jungle. Then you have to imagine this as a ladder, like this. In order to really give an image of what it was like, he's got this one magnificent print called the "Street of the Four Winds" mobility is the goal. You want to have enough money to leave to your 2.2 children. Then you'd have to grease this pole through bad economic times. What happens down below here? Holy cow! That's the big sea. I saw this wretched movie called the Poseidon Adventure once. It had an image where the water is kind of coming up below and it's going to finally get to the top and there's no more room to breathe. This is how the people on the bottom part of this ladder viewed the demands of the working class. Daumier is the greatest caricaturist in the nineteenth century and arguably ever, to make an extreme assertion, but it really is pretty true. This is what he captures, the prevailing mood in much of Europe in that money, more than blood if you were going to exclude places like Hungary, Poland, Spain, and Prussia. What is the.down here? This is ordinary people. The chances are that in these bad years you're going to fall down. But yet lots of people get up and the ranks of the middle class increases everywhere. man doing? He's counting his money. That's a very nineteenth-century profession, as it is for every subject. This guy, if you have extraordinary eyes and can read upside down, you will be able to see that he is reading a newspaper on the price of colonial goods, imports. He's one of these people that's at the very top of my triangle there. Look, this guy's got his coat, too. This is early in the century. You can tell. Some of these images, this is really not very interesting art, but that's not the point. The bourgeoisie didn't kiss and hug a lot. They still had arranged marriages. Love could count for something, but marriages were still essentially, less so for the middle classes than for ordinary people. That's what they were. They were economic relationships, wrangling over the dowry and that kind of thing. Look at our guy on the left. He's working very hard there. He had probably not secondary education. Most people didn't go to high school, secondary, lycée in France or gymnasium in France. in Germany, et cetera, and et ceta. It represents this world. By the way, we also know that this takes place in the center of Paris, right behind a big department store, subsequently the Hotel de Ville, but right near the town hall. This is very common. You see this in the book you're reading, I think. These things can be represented spatially very easily. One of the themes of the long run is the emergence of prosperous western Paris, prosperous western London, prosperous center Vienna and other places. minute. In Zola's great novel, L'Assommoir, Gervaise dies like a dog on a bed of straw, because there was no more mattress. She must be at the very top. Now these rooms then became in the twentieth century student rooms and then were transformed into enormously expensive lofts. But this is a way of visualizing the special concomitance of what I'm talking about. The more you go up there, you're still within the middle class. People were aware of what these symbols meant. This is your classic Hamburg financier's apartment. Ordinary people did not wear slippers. Domestic servants cost almost nothing. It was considered to be a way of moving up the ladder to say that you had four domestic servants instead of three. You've got brass or copper here on the heater. That's a good sign. You're on one of the lower floors. Why? Because you see the trees outside the window. And you've got a domesticated animal. Pianos were expensive, but the middle class has pianos. The piano replaces the harpsichord. The middle class wants privacy. They want their own rooms. There's the kitchen. This is the domestic with her children, who are part of the team who has been hired to help run this. There is more than one room. You'll see in a minute there's even more than two rooms. It's all obvious stuff. There are lots of rooms. These are very good chairs, sort of Louis-Philippe chairs. The middle class arguably helps create the notion of childhood. What the middle class wants, besides social mobility and access to political power, is they want space. Nobles did not send their children to public schools or even to private schools. They were educated, to some extent at least, by private tutors. Working people, their children went to work right away, as soon as they could make anything. If they were poor and didn't have jobs, then they were sent out to beg. hour, when you're supposed to come out when there were guests and run through your extraordinarily modest bag of tricks for the guests. How about birth control? How about not having ten or eleven children? We have friends, one of whom unfortunately just died, very older friends who were born in the early 1930s in the south of France. One had thirteen brothers and sisters, and the other eleven. They grew up in absolute misery. The whole salon, the idea of going to see art shows. It really starts in the eighteenth century. birthday, papa." You didn't take time out to celebrate a birthday if you were an ordinary person having to get to the fields at 4:00 in the morning in the summer, or going to work during the day. There's a whole notion, and here again this would probably fit rather awkwardly into the birth control description, but there's this whole sense of being prepared that emerges with the middle class. It was the idea of protecting that one suit. We didn't carry umbrellas, because it rained all the time anyway and I'd just lose it. The bourgeoisie, the middle classes, and this is particularly true of Germany and France, and of England, too, and other places--they want the right to bear arms. They want to be in the national guard. The national guard might hypothetically be there in case there was an invasion of France or Germany by, I don't know, some distant place, the Fins or something most unlikely. But the main reason they wanted to join the national Guard--and you had to own property to be a national guard--was to be able to vote. You had to be defined as a property-owning citizen to have the right. until you have universal male suffrage, by how much taxes you paid and how much property you own. They didn't want to pay a lot of taxes, but property reflects one's belief in one's own social worth. No longer was it the worth of blood. So, they formed these national guards, particularly after revolutions and after 1848, or after 1830. But these are mainly there to protect them against the workers. Should one day all of these people try to rise up, climb up this ladder, you'll be down there to stomp on their fingers or to shoot them down. H.D. Daumier's light lines, and this is the last one, disappear in this painting, which is called the Rue Transnonain, April 15, 1934-don't write it down, in Paris. It's a street that no longer exists. It disappeared when Haussmann built the boulevards in the 1850s and 1860s. It was selected to disappear because it recalled an event in the early 1830s when these bourgeois panicked and started going into a house full of very ordinary people and simply shooting them. Transnonain, where this happened in the center of Paris, simply disappeared. It didn't quite disappear from the collective memory of people thinking about Parisian things. In conclusion, the middle classes extremely vary. They have a common material culture. They share a belief in achieved status, as measured by the amount of property that you had. They want a collective voice in decisions. Have a good weekend. See you on Monday. Back to Mail Online home. back to the page you came from.

ROUGE-1: 52.64, ROUGE-2: 50.26, ROUGE-L: 47.59
BERTScore: 62.84

==============================================
==================== [85/100] ====================
Summary:
Researchers have confirmed a second smaller space Rock smashed into the sea off the coast of West Africa creating a large crater during the same era. Scientists say it would have caused a tsunami at least 800 M High to tear across the Atlantic Ocean. The asteroid that's believed to have wiped them out 66 million years ago was not the only one researchers have confirmed. The discovery is exciting that it happens to be potentially close to the same time as the chicku event known to be the the main cause of the extinction event that killed the dinosaurs.

ROUGE-1: 38.76, ROUGE-2: 35.80, ROUGE-L: 31.78
BERTScore: 63.39

==============================================
==================== [86/100] ====================
Summary:
Dynamics plays a very important part in automotive design. There's a trade-off between how comfortable the ride is and how tightly the car handles. The subject that we're studying applications homeworks and exams I know that I mean beyond that followingYeah trajectories so missiles stuff like that anything to kill people you need Dynamics what else build a what building a car okay that's good good and what for that's actually that's right but what for well actually in automotiveDesign. MIT opencourseware at ocw.mit.edu. in Dynamics there two sides to it one is here's the system what is its trajectory going to be in other words how will its various degrees of freedom behave over time if you you know stretch it and let it go and it goes twang you know boing right and you want to figure out how it goes in time that that's analysis. H actually suspensions of cars tend to be passive although some suspensions are active but actually in a car cruise control right cruise control is called C control. going to uh go in a certain way right but then cruise control puts in this you know this artificial foot essentially on the throttle and it tries to maintain the speed at a constant level right so we're doing Dynamics end of the course we're going to solve the dynamical equations dou4 is controls where you actually try and put in extra things like cruise control so to make the uh system behave in a way you want it to behave so if you have a rocket open loop right it's called open loop and open loop system is a system that doesn't close the loop. The thrust is only for the first few minutes of its um journey and then it's ballistic ballistic means trajectory it's all Dynamics after that you control it initially to make sure it's pointing in the right direction compensates for wind Etc. A lot of missiles there's a little bit of fuel left so in the end you can do some adjustment right but a bistic missile most of its journey is ballistic okay okay. In the last class we did um I should also warn you I'm a little woozy today uh I had some serious drugs this morning prescription drugs and the result is that I might I think Sam. was saying if I might start babbling but you won't notice because I Babble anyway right so all right Sam didn't say that I said that I bet but anyway s was very respectful okay so uh in the last class we did uh uh we did a problem essentially the whole Pro class was we looked at you know the skier situation and there's a handout AJ's published right on the web where we do the energy formulation and we solve the problem. So today we're going to kind of flow the accelerator a little bit we've been slow and steady we've kind of pounded the concepts in.  angular momentum concept is our stepping stone into Dynamics of rigid bodies because then you can start looking at two and three particles more easily so we'll start with that. Any questions about the last class comments ridicule jokes nothing okay all right so so today we're going to do angular momentums we're still in points Point masses but this is the stepping stone the link to rigid bodies then we'll do a problem we're very problem oriented in this class and then we're Going to do yet another problem but we'reGoing to do multi- particle okay now just a couple of announcements uh one is that pet is that dog. 4 was due uh is due on Wednesday the 10th and the reason is there's no class next Monday and um we posted the solution to that problem from class uh just one last thing I won't have officers today only because you don't want to hear me Babel I'm really sick um but I'm also going to change my officers um several people suggest so the timing isn't right um so we'll talk about the end of class but I I might go to like a Monday off M um like later on a Monday or maybe Wednesday later or something like that. Just hang out like at 3:00 p.m. on a Saturday is that something that you you folks would find useful okay we'll do that okay um so here's what we going to look at what no okay we're going to see our first angular momentums and torqus today. So consider a frame consider a point fixed in frame and this is an inertial frame and a pointfixed in that frame o okay now let's consider a particle P by the way when I say particle a point mass or in context point I'm referring to the same thing essentially I'm refer to something with no Dimensions but with a finite Mass. The MIT way is to do it exactly right using all the mechanisms we've used and guess what you're going to find a stray correction term which you can only ignore in some cases. torque is not always equal to rate of change of angular momentum there's a correction term there are conditions under which it's a rate of angular rate ofChange of angular Momentum but not always you understand because you know it's an analogy so it all kind of makes sense. So let's uh write it out so um we have defined a uh so let's take the derivative of. derivative do I need to say which frame I'm taking the derivative in yes and this thing is going to be I need I'll put it out big let say scaler does that make sense I got to take the deriva to the right side there two pieces to it I need the uh chain Rule and yeah nothing special right everything is completely reasonable according to the laws of math and physics that we've learned so far now. What is this folks what is this this this thing acceleration right so this isGoing to come out to be M or in fact I can re you know I can just kind of write the terms simply like this. Rqp is an ugly term right what do you do with this guy here's what we're going to do. I'm leading it on a path which you would think I mean I'm not doing anything wrong why I'm doing that will be obvious in a second okay everybody Lauren everyone yeah okay so this I can write as this this thing a d by DT of r o minus r oq cross M A VP you understand I haven't done anything wrong I'm just going down. be clear this whole thing is this term and this is thisterm now let's let's write this The Next Step what is this what this m a acceleration of P or acceleration of p with respect to a hm H it's the force on particle P right cross product rqp yes now so I'm just going to put a dotted line so you know that that's what this is is this I don't think you'll disagree let me just write some draw some lines I'm trying to save space as I said. it just looks a little nicer make sense and now I'm going to write the final step what is the cross product of something so what what will this so we have to Let's expand this right associative. What is mavp is a linear momentum right so it's the momentum of particle p with respect to a right plus what is this guy look here what is it okay so so far I've done things that might be like why is he doing that but you you can't disagree with what I did now let me show you why I did that all that. of all engineering graduates who take a car class in Dynamics Berkeley Stanford Princeton might not even see this there is this term and you need to know about it okay it just so happens the term vanishes in many situations but it's key that you know see for Force f is equal to D by DT of P momentum completely coer Crystal Clear when you come to angular momentum it's say artifice yeah there's this funky term which vanishes let's identify the conditions but youneed to know it exists when do you think this vanishes so what is this? it's not Kosher can't do it if I do I need to include that term right and you you've got a figure that a simple thing like my a robot is a very typical Dynamics application okay common mistake okay now that we've done this let's try and figure out why angular momentum is useful let's solve a problem any questions about this any questions bottom line if you're taking angle momenta about moving points be careful bottom line many conditions it'll be okay we'll elucidate we'll Express we'll we'll nail this conditions. A lot of MIT grads old friends work all over the world very important positions around the world for example the foreign minister of the new British government is an MIT grad. One of my friends Works in a congressional he she helps Congressional analyze things from a physics point of view so you know when Katrina occurred someone asked if it would be possible to change the temperature in the when when a hurricane approaches to dissipate the temperature. She did some analysis and showed that you need something like a nuclear weapon but like you know the most the largest the largest. nuclear weapon ever conceived to even you know impact it by like 2% because the energy in a in a hurricane all right I told you I'd Babble all right let's do a problem here's a problem so imagine a um a table right you notice I've drawn it in perspective you know what perspective is right it's very cool it wasn't intentional but looks good I see everything in perspective right now okay I have a hole on this table right so this is a table and and um it's frictionless hockey puck basically a point map attached by a string and the string comes through the hole. call this Theta the initial length is L one and the initial velocity is we'll call it a scalar because this is how I'm defining the problem of V1 when we actually solve it we might have to define a vector okay. As the thing's going around this person is going to pull the string down and as it kind of goes around it's going to spiral in and end up it's a new length L2 and the question is what is V2 going to be okay so I'll let you uh let resolve this for a second. that stuff let's let's examine it from a uh from a basic you know intuition point of view from what we studied so far first of all when is linear momentum conserved forget this in general linear momentum is conserved when what condition occurs no external Force right so let's study this guy this particle as it moves around does it feel an external Force. As the particle moves around kind of intuitively which direction is it accelerating in kind of cental right so it's has an acceleration in this direction what else is happening maybe there's a potentially a tangential acceleration kind of an Oiler acceleration as well potentially right kind of thing. is so where does force get applied on this the string so the string is applying a tension force on this right are there any other forces gravity is not an issue here are thereAny other forces no so the only Direction it can really accelerate in in fact is what towards this in this direction right so there is a force onthis so is momentum conserved in any direction linear momentum how about tangentially yeah yeah yeah tangentially it is conserved right it is Conserved tangential it's just not conserved towards the center but the problem with the tangential momentum is when it's here the tangentials momentum is conserving this way but then when it comes here it's the directions change so direction is always changing right right.  linear momentum conservation is a vector equation which is the vector linear momentum is conserved right. If if it's not conserved in One Direction but there's no force in the other it's still conserve in the the other direction understand so.that's basically what it is you understand so let's so is angular momentum conserved let's think about it is there any talk on this particle yep go ahead well there are no forces in the tangential Direction on this are there right isn't the velocity changes ah but the velocity. There is no torque on this particle at any point in time it's just a very long way to say listen things going in circles and the only force is radial if we take a cross product it's going to vanish. In a lot of situations that pesky correction term doesn't make a difference you just need to be careful that it exists. The angular momentum is conserved because this goes to zero which means d by DT of ah p q is equal Z and what that tells you is understood. would have to do one of two things I would have had to either calculate this term or calculate or make you know make my frame attach it to the truck. The whole point is to show you they could be surprises but be careful any questions about this all right snap quiz in the next 3 minutes I want you to calculate for me the final velocity literally 3 minutes because I have toDo the dumbbell problem now you know the irony is this problem you could have done before you took this class. momentum at length L2 V2 equate the two and get V2 in terms of V1, L1 and L2 it's very simple just for bless you all of you you too no the fing how I do this I'm going to change here actually if have you done it how many of you have done it well you did it okay so good I'm actually going to to uh having asked you to do it that's good turn it in but I'll change it a little bit just to make it more interesting.  angular momentum is a vector out of plane in 2D you see that okay is energy conserved for this particle why not well think about it you wor yeah work it out has the energy gone up or gone down. The energy kinetic energy is gone up by the square a velocity right and um so energy is not conserved so where did the energy come come from yeah that's because you were doing work by pulling it right potential energy is constant so the can energies because you can also do this with energy by the way right. momentum formulation actually came precisely from FAL to ma. I just gave you a canned way to do it instead of doing it you know each time you have a question I meant ABP I think yeah it was meant to be AVP thanks for catching that I told you I'm on drugs okay and there's a master missing as well there you go and the mm will cancel out okay go ahead yeah it could have a velocity inwards yeah because it's a good question but I'm taking the question. and state it very clearly and I said it fast when I talking about energy so great question if the particle has an inward velocity when I look at that V2 State the L2 State then I missed some terms if however I State you which I I did not state I screwed up I made a mistake if I state to you that listen you start at length L1 is just going in a circle right and then I pull it in and thenI bring it to an length L2 and I stop pulling. is equal to ma there's nothing all this is f is equal ma right so far we've done nothing Beyond it energy comes from f isequal to ma these are all just tricks okay okay so with that now let me solve a multi-particle system so this is a stepping stone into uh into uh rigid body Dynamics in the fullest Glory so what we're going to analyze now is this system this is all think of this in the horizontal plane right like a skating rink um and this is an inertial frame. they always point in in the horizontal Direction in the on the Whiteboard right so they little Gyros they you point that way or maybe they're magnets and there's a big magnet at that end so it's only being pulled in that direction okay and the question I ask now is how does this thing behave so let's examine this first of all how do I parameter or to use the more technical term what nonstandard coordinates do I need to describe the configuration of this dumbbell let me make a proposal to you. p and particle Q is that reasonable it's perfectly reasonable but do I have a kinematic constraint and what would the kinematics constraint be H yeah it's a they connected by a rigid body so they can do whatever they want as long as the length between the two of them remains constant right by the way if instead of a rigid bar if I had a string connecting them what would  the kinematic constraint be? H is equal to R to R so it's equal to to R all right. time dependent and non-time dependent constraints right I mean imagine in the Str with changing length right over time right and by the way that does show up for example temperature something strings you know that doesShow up but don't worry about all that the point is if I went with four non-standard coordinates X and Y of this X andY of that I would have four non,standard coordinates and one kinematic constraint right is there a better coordinate system General a non- standard coordinate system you can think about anybody clao are we assuming that the same mass doesn't make any much it doesn't makes a difference the problem just makes our lives easier later yep claudo if they had been different would you have placed them the point in the center of mass for reasons that are not clear yet if the masses have been. different you'll find out later I would have picked the center of mass which would not have been the geometric Center Center okay but you don't know why so I can't tell you why. A lot of terms cancel out that's the only difference I could still have by the way I could have picked a point on that line anywhere. There would still be reasonable generaliz coordinates there wouldStill be three just the math is easier that's it okay so I don't have to pick theCenter of mass but I pick thecenter of mass. understand the uh um right totally understand the reasoning behind kinematic constraints I'm going to call this point c r o That's when one vector now this angle of this thing is Theta and I'm defining um because this thing I've rotate a lot right uh I just you know it's a little confusing but let me just draw it for you like this if I had if if the way I had drawn it I hadn't rotated that dumbbell so much if I drawn it like this it'll make more sense. this R OC which is some component this way plus some components this way and an angle that we know the configuration of this dumbbell at any point in time. We're going to figure out how it behaves what it trajectory is going to be over time we won't solve it we write the differential equations to solve it right. You'll see that they come out to be very beautiful and you'll see out of the primordial soup you'll recognize the shape say hey that's a moment of inertia we'll do that. from a free body diagram point of view I'm not going to do it right now but very simply there are each bar applies a force on the part on the particle. I'll do it later on because I want to the kinematics first so I'm breaking my own rule I'll doing the free body diagrams later on. I can actually just use the ultra super cool magic formula here directly I need you need have done that but we can do it brute force and just figure it out so um actually let's justuse the um the uh super cool formula and what we will get is the acceleration of particle p is equal to. Point got it so we figured out the accelerations of these particles it's very cool in principle now we should be able to equate those ex multiply them by m and equate them to the forces do a free body diagram we should we done right nothing really special here any questions about this anybody okay so I'll just write it out now I won't do it because we have only about 2 minutes left but let me do this this side this white board sorry now let's do the free body diagrams on each particle. stick if I have something at the end of a stick can I apply like a you know does it only have to be a force inwards right. Next week we'll pick up on this and essentially what I'll do is I'll take components and write F equal to ma right I'll write f is equal toMa in two directions here. I'll get four equations one of those equations will turn out to be the same so we get three equations three unknowns we'll solve it and we'll end up with essentially what what what. we'll show is that the acceleration of the center of mass is uh related to the total force and the angular acceleration of. the whole rigid body is related to torque and we'll show it okay and then we'll generalize it. Define angular acceleration and moment of inertia and a more General sense okay so let's stop here because we are over time. We're going to take a break. We'll be back in a few minutes. We've got a lot to talk about.

ROUGE-1: 55.43, ROUGE-2: 54.12, ROUGE-L: 54.09
BERTScore: 72.09

==============================================
==================== [87/100] ====================
Summary:
In this module, I'm going to briefly introduce the idea of differentiable programming. Differentiable programming is closely related to deep learning. I've adopted the former term as an attempt to be more precise in terms of highlighting the mechanics of writing models as you would code. So let's begin with our familiar example, a simple neural network. And this is the programming part of differentable programming which allows you to build up an increasingly more sophisticated model without losing track of what's going on. In a three layer neural network, we start with our feature vector. In this case, it's a six dimensional vector. And we left multiply by a matrix. I've drawn some lines here to help us interpret this matrix as a set of rows where each row corresponds to a hidden unit. And I'm going to take the dot product of each row with the input vector to produce a hidden vector of dimension 4. I'm Going to add a bias term and then I'mGoing to apply an activation function. Now I have a vector and now I can do the same thing again. we're going to see a lot of these box diagrams which are going to represent functions that we can reuse and have a nice interpretation. So the FeedForward function takes in an input vector x and produces an output vector which could be of a different dimensionality. And the way to interpret what people are doing is performing one step of processing. In particular what that processing is, is taking this input vector, multiplying it by a matrix, adding a bias term and applying an activation function. So this is a very compact way of writing something that would otherwise be quite complicated. The FeedForward function that we just introduced, takes a vector as input and we can represent an image as a long vector by, for example, adding all the rows. But then we would have this huge matrix that we would need to be able to transform this vector resulting in a lot of parameters which may make life difficult. To fix this problem, we introduce convolutional neural networks which is a refinement of a fully connected neural network. So here is an example of ConvNet in action. It goes through a number of layers and over time it computes increasingly abstract representations of the image. ConvNets have two basic building blocks. You can take CS231 if you want to learn all about ConvNets. But instead I'm going to focus on the interface and show how these modules compare. And so Conv takes an image and the image is going to be represented as a volume which is a collection of matrices, one for each channel, red, green, blue. Each matrix has the same dimensionality as the image, height by width. And what the Conv is. going to do is it's going to compute another volume of a slightly different size, usually the height and width of this volume is going. to be equal. Conv is going to compute this volume is via a sequence of filters, and intuitively what it's going to do is try to detect local patterns with [AUDIO OUT] So here is one filter and how it works is I'm going to slide this filter across the image. And then for the second filter, I am going to use to fill up the second output channel. The second operation is MaxPool which again takes an input volume and then it produces a smaller output volume. going to slide a little max operation over every 2x2 or 3x3 region. So the max over these four numbers is going to be used to build this [INAUDIBLE] and so on. That's all I'm going to say about MaxPool. If you want to go into the details, you can check out this demo or you can learn more in 231. But again, I want to highlight that there's these two modules. One for detecting patterns and one for aggregating, to kind of reduce the dimensionality. be learned. The second thing is I also haven't specified the hyperparameters which is the number of channels, the filter sizes, and so on, which are actually pretty important for getting a good performance. But I just wanted to highlight the overarching structure and the idea that you can compose in a fairly effortless way. So now let's turn our attention to natural language processing. So here is a motivating example. Suppose we want to build a question answering system. We have a paragraph. It's from Wikipedia and we have a question. We want to select the answer from that passage, from the paragraph. somehow related to product. And also the fact that some words are ambiguous, like product can be-- multiplication or output. So there's a lot of processing that needs to happen and it's hard to kind of specify in advance. So we're going to define an EmbedToken function that takes a word or a token x and maps it into a vector. And all this function is going to do is it's going to look up vector in a dictionary that has a static set of vectors associated with particular tokens. is something that has an interface but not an implementation. A SequenceModel is going to be something that takes a sequence of input vectors and produces a corresponding sequence of output vectors. So in other words, I want to contextualize these vectors using the sequence models. I'm going to talk about two implementations of the Sequence models. One is recurrent neural networks and one is transformers. The SequenceModel can be thought of as reading a sentence left to right. So we have a word which gets mapped into a vector that produces some hidden state. And then we're going to read a second input vector, and I'm Going to update this hidden state along with this hiddenState. A simple RNN works by taking a hidden state, multiply by a matrix, take the input and multiply by the matrix. And then I add these two and I apply an activation function. So at the end of the day, I have the sequence model because that maps input sequence into an output sequence. And I notice that each vector here now depends on not just the input vector but [INAUDIBLE] So if you look at h3, h3 depends on x3, x2, and x1 following this computation map. Collapse takes a sequence of vectors and returns a single vector. There's three common things you can do. If you're doing text classification, you probably want to pick the average to not privilege any individual word. But as we'll see later if you're trying to do language modeling, you want to take the last. The score for, let's say, binary classification is going to be equal to taking the input sequence of tokens. You embed all the tokens into a sequence and now you can apply a sequence model, for example, a sequence RNN. The attention mechanism takes in a collection of input vectors and a query vector and it outputs a single vector. So mathematically what this is doing is you start with the query vector. I'm going to multiply a matrix to reduce its dimensionality, in this case from 6 to 3. And the attention is going to process y by comparing it to each of these x's. OK. So these types of functions where the input and output have the same type signature are really handy because then you can compose them with each other and get multiple steps of computation. Here is one of the input vectors. x1, x2, x3, x4. I'm going to reduce its dimensionality to also 3 dimensions. And now I can take the dot product between these x's and y's. So that's going to give me a four-dimensional vector of dot products intuitively measuring the similarity between the x and the y. So now I have a distribution over the input Vector x1. I can use those probabilities, those weights, when I multiply by x to take away the combination of the columns of x. multifaceted thing. So one thing that the transformer does is it allows us to use multiple attention heads. The transformer uses something called self attention, which means that the query vector is actually going to be the input vectors. So I'm selecting out the input vector and I multiply it by a matrix to reduce the dimensionality. I've done this twice, but in general you can do this any, 4 or 16. So now I concatenate these vectors. I have a four-dimensional vector from this computation. themselves. So if self attention takes a sequence of input vectors and then it's going to output the same sequence of output vectors where the first vector is, I'm going to stick x1 into the query vector for y and compute the attention, and then x2 and x3 and x4. So each of these vectors is comparing a particular input vector with the rest of the input vector and doing some processing. So in contrast with the RNN, you have representations that have to kind of proceed step by step. And the number of steps is the length of a sequence which causes these long chains. be done once the parameters are learned from data. You can think about this as a sequence model that just takes input sequence and contextualizes the input vectors into output vectors. There's two other pieces I need to talk about before I can fully define the transformer. Layer normalization and residual connections. These are really kind of technical devices to make the final neural network easier to train. I'm going to package them up into something called AddNorm and it also has a type signature of a sequences model. processing each xi in context. Now we have enough that we can actually build up to BERT which was this complicated thing that I mentioned at the beginning. So BERT is this large unsupervised pretrained model which came out in 2018 which has really kind of transformed NLP. And the basic building block for generation is, I'm going to call it GenerateToken. And you take a vector x and you generate token y. And this is kind of the reverse of EmbedToken which takes a token and produces a vector. Translated sentence, given the input sentence or a document summarization or semantic parsing. Each of these sequence can be framed as sequence-to-sequence tasks based on, usually these days, basically BERT and Transformers. So we started with-- Now in hindsight, it seems kind of very simple, FeedForward networks. And we looked at images and looked at convolutional neural networks which were built on Conv layers and MaxPool layers and also FeedForward. So the nice thing about packaging this in a module is that now this is used in transformers and different places as well. encourage you to consult the original source if you want kind of the actual, the full gory details. Another thing I haven't talked about is learning any of these models. It's going to be using some variant of stochastic gradient descent, but there's often various tricks that are needed to get it to work. But maybe the final thing I'll leave you with is the idea that all of differentiable programming is built out of modules. Even if you kind of don't understand or I didn't explain the details, I think it's really important to pay attention to the type signature of these functions.

ROUGE-1: 55.88, ROUGE-2: 54.42, ROUGE-L: 53.05
BERTScore: 75.03

==============================================
==================== [88/100] ====================
Summary:
Professor Amy Hungerford: Today it is my very great privilege and pleasure to introduce Andrew Goldstone, a TF in this course. Andrew is a fourth-year student in the Ph.D. program in English, and he is writing a dissertation on the autonomy of the work of art in modernism. In preparation for that, for next week I'd like you to finish the novel and then read his essay, "On a Novel Entitled Lolita." It should be bound at the back of your book. we had three main themes that were used to introduce this novel to you. First is the idea that the novel invites ethical questions but also holds them off through parody. We looked at Humbert's techniques of rhetorical seduction and related that to a kind of intellectual problem that Nabokov sets himself of trying to make you identify with this villainous character. And that leads to the third big question we looked at, which is the place of Nabokovsky in this novel amidst the many layers. T.S. Eliot's "Gerontion" is a spoof of Nabokov's "Humbert" Eliot says poems should be autotelic, that means they should be an end unto themselves. Eliot in some ways comes very close to the kind of ideas about art that Nabokovsky holds. Eight of the eight features of literary modernism that are all important to Nabokova are: obsession with art's autonomy, the idea that art is its own law, that it has no other purpose than its own. sense that civilization itself is being overturned. Third, the idea that the paradigm of experience is artistic experience. Fourth--and this goes along with that--a rejection of convention, especially sexual convention, sexual morality. Sixth, this is a term from the critic Joseph Frank: spatial form. In place of a linear narrative you have a system of cross-references and repeated motifs that give the structure of works. And then, this anticipates my last points: Modernism is self-consciously international. For Nabokov, the highest value is originality. He says this in his last Russian novel, The Gift. "Any genuinely new trend in art is a knight's move, a change of shadows, a shift that shift that all. for all" "I had a teacher who used to compare Lolita to Huck Finn. They are two novels about traveling across America and an unconventional couple. Right? So, anyway. Okay. But now, that modernist tradition is something that Nabokova owes a lot to, but he always tries to distinguish himself from it" The strategy of the knight's move is to frustrate your expectations, to leap over the apparently important events into something else characterized by a kind of aesthetic play. Nabokov, in 1966 he said this: "The greatest masterpieces of twentieth-century prose" are, in this order: Joyce's Ulysses, Kafka's Transformation"--that is, "Kafka's Transformation," "Ulysses" and "Lolita" The parentheses are a real icon of that. A critic has counted 450 sets of them in this novel. is, The Metamorphosis--"Bely's St. Petersburg," a pretty obscure Russian avant-garde novel. Proust is himself gay. One of his big subjects is homosexuality, and Nabokov's reaction to this is really homophobic. It's about a relationship to predecessors who are seen as too similar. This should cue you to think about the theme of doubling in this novel, to think of the possibility of desire between men here, says David Bianculli. he's attractive to all women, about his supposed virility. And it should just make you wonder whether pedophilia is in itself a kind of knight's move from homosexuality. In other words, is there another form of perverted desire hiding behind the one that's in front of us? Just a suggestion: look on page 20, still in Humbert's early life, near the bottom. It happened for instance that from my balcony I would notice a lighted window across the street and what looked like a nymphet in the act of undressing before a co-operative mirror. Nabokov's relationship to this modernist past is not just the burlesque that he visits on Eliot. An element of admiration is also present, and that's really part of his relationship to Joyce. On page 221 there is a reference to a writer named Vivian Darkbloom plagiarizing from Joyce. And the thing that's being plagiarized, I've actually given you on the handout, is a little piece of Finnegans Wake, which is Joyce's work in which almost every word is a pun. Eliot's poem describes the hero, Stephen Dedalus, as a young boy trying to write a poem. And eventually in the novel he will succeed in writing a poem, but here he doesn't manage to. And so, this is a kind of forecast of what will happen later on. The further complication is that here he's writing a poems and then he remembers an earlier attempt; that layering of memory, and that kind of layering, is actually a prototype for the layering in Lolita. in the collected poems of Lord Byron. When he had written this title and drawn an ornamental line underneath, he fell into a daydream and began to draw diagrams on the cover of the book. The version of this that comes up in the novel is in the midst of Humbert's diary. And I've given you a piece of that diary to look at on your own on the handout. But this is the moment that directly alludes to Portrait, and it's really very important for understanding Nabokov's technique. Young People's Encyclopedia I found a map of the States that a child's pencil had started copying out on a sheet of lightweight paper. On the other side of the map was a mimeographed list of names referring, evidently, to her class at the Ramsdale School. A poem, a poem forsooth! So strange and sweet was it to discover this Haze Dolores: she, in its special bower of names with its bodyguard of roses, a fairy princess between her two maids of honor. ordinary materials of life become the basis for a kind of artistic achievement. However, obviously this is not like the Joyce, where there is a realistic depiction of a young boy trying to write, getting bored and failing. There is that bower of roses. That refers to Mary Rose Hamilton; Haze, Dolores; Hanek, Rosaline. And then there's Emile Rosado and Carmine Rose--a red rose--Angel, Grace-- really--Stella Fantasia. Lolita is a kind of artificial, processed, bland, easily consumable version of fate. You might think of it as having the same relation to real fate as Chicken McNuggets do to chicken. There is a short circuit between the Joycean idea of taking ordinary life and transforming it into an aesthetic order. In other words, chance is already fated. The ordinary is already aesthetic in the book. The randomness. of life is the same as chance.randomness.of life. thing that stands for randomness in this book, the thing that looks like ordinary detail, has already been arranged to give you artistic pleasure. So, the artificial has taken the place of the real here, and this novel really reminds you of that all the time. This is the, kind of, hand of Nabokov, taking a narrative of real events and twisting it into something that makes a kind of sense, taking fate and making it McFate. And I want to show you one more example of that, in the scene where Humbert and Lolita have reached the hotel, the Enchanted Hunter. 118 near the bottom. "In the slow, clear hand of crime, I wrote 'Dr. Edgar H. Humbert and daughter, 342 Lawn Street, Ramsdale' A key, 342, was half shown to me, magician showing object he is about to palm and hand it over to Uncle Tom." The coincidence--normally, in real life, it would be a delightful coincidence to go to a hotel room that has the same number as your street address. Here it's a kind of too-easy icon of the correspondence between the place where HumberT meets Lolita and the placewhere he rapes her. foreign country, lives in a kind of denaturalized world, a world where, instead of everything making instant sense everything has to be decoded. In that afterword to this book, Nabokov says he had to invent America. That's because he didn't know it already; it wasn't given to him. In a way this is a terrible state, a state of discontinuity with the world you exist in. But it has a payoff, kind of, a payoff which is the possibility precisely of inventing. because Humbert is a foreigner--into something you can laugh at, something youCan enjoy, something that you can apply the knight's move to. Gaston Godin says about the school that Lolita's going to go to, the girls are taught "not to spell very well, but to smell very well" The foreigner's love for this kind of move is a response to this denaturalized world of the exile. It's important, in this connection, to remember that the Knight's move as a way of avoiding obstacles keeps skipping over forms of violence. turn of the staircase was glazed with ruby, and that raw wound among the unstained rectangles and its asymmetrical position--a knight's move from the top--always extremely disturbed me. Nabokov will say that his private tragedy is that, let's see: [His] private tragedy, which cannot, and indeed should not, be anybody's concern, is that I had to abandon my natural idiom, my untrammeled, rich, and infinitely docile Russian tongue for a second-rate brand of English. the fear that it's too like what he wants to do. But the main point here to think about is that feeling of damage. On page 152, Nabokov's wife, Vera, drove him on thousands of miles of trips around the country while he was writing this novel and hunting butterflies. These techniques are really I think the source of the most appealing writing in this book, and so let's look now at one of those evocations of the American landscape which I just think maybe are the closest the book comes just to pure beauty. evocation of the landscape. "By a paradox of pictorial thought, the average lowland North American countryside had at first seemed to me something I accepted with a shock of amused recognition" Nabokov: "beyond the tilled plain, there would be a slow suffusion of inutile loveliness, a low sun in a platinum haze with a warm, peeled-peach tinge pervading the upper edge of a two-dimensional, dove-gray cloud fusing with the distant amorous mist" Humbert says the novel has as its only purpose to provide aesthetic bliss. So, a European artist actually appears again there, with Claude Lorrain, but kind of made strange: given that knight's move, given a new twist. So--instead of familiar, incorporated into this profoundly strange, vast landscape that gets Humbert's most appealing rhetoric--the rhetoric of an exile. But, I don't want you to think that this just means everything's okay. Of course, everything is not okay. Humbert Humbert: "We had been everywhere. We had really seen nothing" "I catch myself thinking today that our long journey had only defiled with a sinuous trail of slime the lovely, trustful, dreamy, enormous country" "We have to pair that with that other evocation of the landscape to see this alternate idea, that actually this distanced criss-crossing of the landscapes could be damaging" "There's another version, yet another, that relates back to that funny figure of Gaston Godin" There he was, in priggish New England, crooned over by the old and caressed by the young, oh, having a grand time and fooling everybody, and here was I. And the contrast here is between someone who has remained tied to that European past, remained comfortably alienated--and by that very means been able to fit into society. And in fact it's more than that: he translated Lolita back in to Russian later on, and he added a second afterword where he said this: That wondrous Russian tongue that, it seemed to me, was waiting for me somewhere. in safekeeping for so many years, proved to be nonexistent. And there is nothing behind the gate but charred stumps and a hopeless autumnal distance, and the key in my hand is more like a skeleton key. So, there's a kind of lost paradise of European culture which he can't get back, even with this spectacular effort in English. That suggests that it's not all to the good; it hasn't been saved by taking up these knight's move techniques, the defamiliarizing techniques; there's still a record of damage. element of violence that keeps coming back, the trail of slime across this dream of transforming reality, in this Joycean way, into something saved. Could it be that all of this modernist technique that Humbert succeeds in putting to his own ends is not an unambiguous good, but a record of a kind of damage? On Monday you're going to hear about this novel's confrontation with the idea that art could be saving, that it could somehow be redemptive, but here I think is a hint that it's something that the novel simply laughs at hollowly. the admirable way foreigners, or at least naturalized Americans, use our rich language. In other words, that the aesthetic discovery of English is something that just kind of fits comfortably into this prejudice of the dull suburban American. So, I'll just end there with this thought, this doubt, about Nabokov's own use of modernist technique in this novel. Whether it could be--not just that triumph of the imagination that Humbert sees in the list of the names--but a mark of a wound that can't be healed.

ROUGE-1: 52.57, ROUGE-2: 50.11, ROUGE-L: 49.40
BERTScore: 69.79

==============================================
==================== [89/100] ====================
Summary:
NORVIN RICHARDS: Today is phonetics, which means that today we begin making funny sounds at each other. Let's see. I'm trying to remember if there's anything that I ought to announce. You remember, maybe, that problem set 1, which confusingly is your second problem set, is due on Thursday. Normally, it would be due on Tuesday. But because I am technologically challenged, it's due Thursday. I just figured out how to get the projector to project over there instead of in the middle. When we speak, if we're speaking an oral language, what we are typically doing is producing a flow of air. And it gets obstructed in various ways in the vocal tract. One way of categorizing the various things that your vocal tract does to the airflow is by what's called place of articulation. So for example, there are what are called bilabial sounds. These are sounds which are made with both lips. And that's what we're going to do. This picture over here on the right is the old technique. And we'll go back to the old days. Linguists have a system for writing sounds down so that we'll all know what kind of sound we're talking about. A lot of the symbols of the International Phonetic Alphabet resemble letters of the English alphabet. The symbol for the sound at the beginning of "paint" is the letter p. There are also what are called labiodental sounds, which involve your top teeth and your lower lip. We'll talk about other kinds of articulation that English doesn't use, but I think that one just doesn't exist. Interdental sounds are linguistically not hugely common. We have them in English. There are various dialects of Arabic that have them. But they're not all that common. These are the sounds of the beginnings of words like "thistle" and "this" The symbol for the sound of the beginning of "face" is an f, and the symbol for "vase" is a v. The International Phonetic Alphabet is there so that we can unambiguously talk about what we're talking about. There are two different IPA symbols for them. The Greek letter theta is used for the sound at the beginning of "thistle" And that second letter is an old English letter, still used in Icelandic. It's sometimes called "edh," and it stands for thesound at the start of "this" Then there are what are called alveolar sounds. If you put your tongue at the top of your mouth and drag it-- so put it first against your front teeth and then drag it backwards along the top. another new symbol. That's the symbol for the sound of the beginning of a "ship," and another new symbol that's the sound in the middle of "azure," the "zh" sound. Both of those are postalveolar sounds. A little further back, there are what are called palatal sounds. These are either even further behind the alveolar ridge, back where the roof of your mouth gets as high as it's going to get. And the one palatal sound that we have in English is the "y" sound at the start of "year" The IPA symbol for that sound is a "j" Continuing our tour of the mouth, there are what are called velar sounds. In the velar sound, the body of your tongue is up against what's called the velum. The velum is responsible for partitioning your mouth from your nose through your oral cavity. And then further down, further down in your throat, you've got the vocal cords, the glottis, this space that's down there inyour throat around your larynx, and your vocal folds. English doesn't make a huge amount of use of the glottal stop. But it's what shows up at the beginnings of words like "uh-uh" You can also hold them close together and let the air whistle past. That's how you make an "h," right? As in, what's my word up there-- "help,"Yeah. OK. There are questions about any of that? So that was just a quick tour through the vocal tract. Yeah? Where's, like, "chuh"? "Puh" is not an English word for me. There are dialects of English in which that's something you would say, right? "Puh." There are places in English where things that we write as other kinds of sounds actually are, in fact, glottal stops, at least in my English. "Can't" is really just "can" plus aglottal stop. I'm not saying "can't," usually, unless I'm being very emphatic. in mind? STUDENT: No. So we haven't gotten yet to "r." We'll get to " r," eventually. But actually, people discovered at a certain point-- so people investigate this kind of thing in all kinds of ways. These days, people do a lot of MRIs. I'm going to put on the website a couple of websites that have charts of all of the sounds that we're going to talk about plus many more together with MRIs of the insides of people's mouths making these sounds. "r" is one of the kinds of sounds that people classically have trouble with. If you've been around small children, for example, it's standard for them to not quite get "r" right and to say something that sounds more like a "w" at a certain stage. So a place of articulation is obviously not the whole story. Here's another part of the story. It's what's called voicing. So if you think about an "s" and a "z," those are both alveolar sounds. Your tongue is reaching toward the alveolars. NORVIN RICHARDS: What's the difference between a cat and a dog? "Cat" and "dog" end in sounds that differ in voicing. "z" is voiced and that "s" is voiceless, so it's a distinction in voicing, right? Yes? STUDENT: Just the fact that [INAUDIBLE]?? NORVin RICHards: Yeah, so the differenceBetween "cats" and 'dogs"-- yeah. So then is it possible to whisper "z," "g"s? Are they-- f, v, f, f,. v, v. f, v,. v. Does anybody feel a difference between "f" and "v"? Not here, right? Yeah? STUDENT: I guess the "v" is more-- there's more air [INAUDIBLE] NORVIN RICHARDS: So yes? STUDent: Also, my mouth is opening slower, I think. NORVin RICHards: Ah, there might be a difference in the aperture of your mouth. Student: I actually have the opposite of your feeling. what it means is that your vocal cords are vibrating. But I think maybe what we're learning is that you do some other things, too, to optimize the flow of air so that you will get a good vibration going. There's experimental work on this. This is the kind of thing people try to figure out. Yeah, really good question. OK. So when you whisper, you're not engaging your vocal cord, but you're doing all of the other stuff. And that's what you're using to hear the difference. Polish has words that end in "k" and words that ended in "g" underlyingly. Polish also has a rule that changes "g," to "k," at the ends of words. Voiced "b" becomes the voiceless version, which is "p," in Polish. "z" and "d" are voiced, and "t" is voiceless, but both are alveolar, so they're both different from "to" And it's a cross-linguistically quite common phenomenon. English doesn't allow words to begin with velar nasals. But there are languages that do. Tagalog is one. Cantonese is one, and there's a bunch of others. English, for example, has bilabial stops, "p" and "b" But it doesn't have a labial fricative, which sounds like a candle, just like blowing out. Are there questions about any of this? Is anybody looking at this and saying, whoa, this table has grown out of my ability to keep up? English has interdental fricatives-- thuh and thuh. There are languages out there that have what are called dental stops. Part of your job, if you're learning Tagalog, for example, is to learn to make dental "t"s instead of alveolar "t," because that's what they've got. If you're studying another language, this is the kind of thing to think about because sometimes, your teacher will not be thinking about this. But you should. There are even languages out there that have both dental "t"s and alveolar "t's. So the Dravidian languages of India are famous for having those. And a lot of the Aboriginal languages of Australia are really rich in places of articulation. These are all languages that have lots and lots of places to make sounds. But they often don't make the languages of Australian, for example. So they have stops, but they don't distinguish voiced from voiceless. So there are places in the vocal tract that English uses. Sometimes, it doesn't use them for the same things as other languages do. English just does not use. what are called retroflex sounds. Instead of a tuh, you're making a cuh-- [NON-ENGLISH]. So your tongue is curled back a little bit further than it would be for a "t" And it's making a closure, if you're make a stop, right there. Retroflex sounds are very popular in India, and Australia, and Indonesia. They're all over the place. There are also pharyngeals. Pharyngeal fricatives involve constriction near the pharynges. uvulars, retroflexes. And for some reason, the dental stops are still red. I don't know why. Have to fix that. OK. Now people keep asking me about sounds that I've been carefully avoiding, so let's talk about them. There are what are called approximants. Approximants are not stops, and they're not fricatives. They're not nasals. They involve your articulators vaguely gesturing towards each other in some part of your vocal tract. A "w" is like an "oo" sped up. A "y" sound, yuh, is a sped-up version of an "e" as opposed to an "r" or an "l," which are just something else. Eventually, we're going to start talking about sequences of sounds. And so it's going to be useful, at that point, to be able to distinguish, for example, consonants from vowels. "That's the prima facie reason for distinguishing them," he says. said is the right way to think about this or not. What people do is say, yeah, there's this package deal, an affricate. When you're trying to figure out what sequences of sounds are allowed in a syllable in a given language, sometimes it's useful to be able to say this is a language that doesn't ever, ever allow, say, a stop followed by a fricative. Oh, but it's OK for it to end with chuh. That's the move people make, yeah. There are glides like wuh and yuh. There are some other glides there which I can try to read to you. What would a labiodental glide sound like? Vuh, right? Like a "v" sound. English doesn't have those. I believe Hindi does. Similarly, there are velar glides, [NON-ENGLISH],, where your tongue is just vaguely gesturing in the direction of your velum. It looks like something out of Tolkien. English has a very large number of vowels and a not-very-good system for writing them. One way of classifying vowels is in terms of height. For "ee," your tongue is tense. And then for "ooh," where does it go? It moves, right? So you aren't just rounding your lips and leaving your tongue where it was. In fact, that's why when you take photographs of people, you have them say something with an "ee" vowel in it, like "cheese" English is supposed to have five vowels. It does not have five. It has 14. Why do we only have five letters for vowels? Who gave us this alphabet? The Romans, right? Yeah. And in Latin, there in fact are five vowel, which can be either long or short. And so we've ended up with 12, 14 vowels, different dialects of English are different. And we have 5 letters to spell them with. And this is why we have spelling bees. yeah-- one of the reasons. OK, so I've written six of our five vowels here on this chart. And then we have more. So think about "ooh" and "uh," in "who'd" and 'hood," or "ee," and 'ih" in 'heed' and 'hid," or 'ay' and'eh' in 'raid' and "red" or 'oh' and '' in 'coat,' 'caught' There are various ways of talking about this distinction. We say that there's a distinction between what are called tense vowels. English doesn't have words that end in "ih," "uh," or "eh," with the possible exception of "meh" English monosyllables can't end in lax vowels that are either front or high. Not all speakers of English distinguish schwa from wedge. Not every dialect of English has all of these vowels or has them all in the same places. There are people who pronounce "caught" and "cot" the same. For me, those are two different vowels. this exercise next time. As we go along, I'm going to be asking you to read things in IPA. So I'll start putting IPA on the slides more and more. So start trying to familiarize yourself with it and get to where you're familiar with at least the symbols for sounds that we use in English. Do you want me to read the rest of them? I'll do some more IPA. OK, so what's the second one? STUDENT: "Sue says he's a bad egg."

ROUGE-1: 33.03, ROUGE-2: 31.17, ROUGE-L: 30.89
BERTScore: 68.82

==============================================
==================== [90/100] ====================
Summary:
So we're imagining n independent flips of a coin with bias p. So the coins might not be fair. The probability of heads is p. It would be biased in favor of heads if p is greater than 1/2. And we want to know how many heads are expected. This is a basic question that will come up again and again when we look at random variables and probability theory. So what's the expected number of heads? Well, we already know-- we've examined the binomial distribution B n,p. of getting k heads, which we've worked out previously. n choose k times p to the k, 1 minus p toThe n minus k. Well, let's introduce an abbreviation, a standard abbreviation. Let's replace 1minus p by q, where-- so p plus q equals 1, and they're both not negative and between 0 and 1. And when I express the expectation this way, it starts to look like something a little bit familiar. So what I'm going to wind up with is that n is equal to 1/p times the expectation of B n,p.

ROUGE-1: 39.22, ROUGE-2: 38.28, ROUGE-L: 39.22
BERTScore: 80.13

==============================================
==================== [91/100] ====================
Summary:
Aristotle was born 384,15 years after the trial of Socrates. He was sent by his father to go to college. Unlike most of you, Aristotle did not spend four years at the Platonic Academy. He remained attached to it for the next 20, until the death of Plato. Unlike his intellectual godfather, Socrates, who wrote nothing but conversed endlessly, Aristotle wrote disciplined and thematic treatises on virtually every topic, from biology to ethics to metaphysics to literary criticism and politics. Aristotle appears from the beginning to look more like what we would think of as a political scientist. He collected constitutions, 158 of them in all, from throughout the ancient world. He was the first to give some kind of conceptual rigor to the vocabulary of political life. Yet, for a man as notoriously secretive and reluctant as Aristotle, his works acquired over the centuries virtual canonical status. For centuries, Aristotle's authority seemed to go virtually unchallenged. But the authority of Aristotle obviously no longer has quite the power that it once did. animal. "That man" he says "is much more a political animal than any kind of bee or herd animal is clear" Why is it clear? "For we assert," he says, "nature does nothing in vain and man alone among the animals has speech" In other words, he seems to be saying that it is speech or reason, logos, that is able to both distinguish and create certain moral categories, such as the advantageous, the harmful, the just and unjust, and things of this kind. Aristotle says man is political not because we have some biological impulse or instinct that drives us to participate in politics, but because we are possessed of the power of speech. It is a reason or speech, not instinct, that makes us political, he says. To say it's natural for us to do so is not to say we engage in political life spontaneously and avidly, as you might say spiders spin webs or ants build anthills, he writes. The power to know is our ability to recognize, by sight, members of the same polis or city. condensed in very deep ways, carry a great deal of freight. There's a lot in there that needs to be unpacked. We need to avoid the temptation, in many ways understandable as it might be, to airbrush or sanitize Aristotle, to make him seem more politically correct for modern readers. The question is what did Aristotle mean by slavery? Who or what did he think was the slave by nature? Until we understand what he meant, we have no reason to either accept or reject his argument. kind of egalitarianism, so to speak, built in to the conception of rational animal and political animal? Yet, at the same time, Aristotle seems to regard education as the preserve of the few. The kind of discipline and self-restraint necessary for an educated mind appears, for him, to be unequally divided among human beings. It follows, I think, that the regime according to nature, that is to say the best regime, would be what we might think of as an aristocracy of the educated. the preserve of the few, of a minority capable of sharing in the administration of justice and in the offices of a city. Would you agree? Unappealing to us, perhaps, for that reason, very contrary to our intuitions and the way we have been brought up. But before we dismiss Aristotle's account as insufferably inegalitarian and elitist, we have to ask a difficult question. What else is Yale, but an elite institution intended to educate, morally and intellectually, potential members of a leadership class? Think about that. Aristotle might, as a natural aristocracy? I leave you with this question to think about. Before we reject Aristotle as an antidemocratic elitist, take a look at yourselves. So are you, or you wouldn't be sitting here today. Think about that and I'll see you next week. Back to Mail Online home. back to the page you came from. Follow us on Twitter @dailymailonline and @jennifer_newton. Back To The Daily Mail home.

ROUGE-1: 23.43, ROUGE-2: 22.10, ROUGE-L: 22.02
BERTScore: 56.29

==============================================
==================== [92/100] ====================
Summary:
Mathematically, a consumer is trying to maximize his utility. And this utility maximization has to be done with respect to some constraint and the constraint the budget constraint we take P 1 x 1; P 2 x 2 should be less than or equal to I. In real life, it is possible that a person derives some satisfaction from having some money left in his pocket, but the way this problem has been framed here the person’s satisfaction depends only on his level of consumption of good 1, and good 2. Student: So, what we have here is such that P 1 x 1 plus P 2 x 2 is equal to I.equal to u naught. Now let us look at these 2 problems; what is happening is so what we can do here? Student: We are varying the budget line in the other word expenditure line, budget line is also an expenditure line. So, basically, these two are dual of one another. If we solve these two, we reach to the end of the problem. same consumption bundle; it is clear. So, if we solve it what do we get? Here let us say for x 1 instead of using star let me use term M I will explain what does this M, this is x 1 m. What are the parameters P 1 P 2 and I so x 1 the optimal level of consumption of good 1 should be given as a function of parameters in this system and the parameters are P 1, P2 and I is it clear? Similarly, let me write here x 1 H again, I will explains what is H. I is P 1 x 1 plus P 2 x 2. What is e? E is nothing. We are checking we have set up the problem such that this I is equal to this u naught and what we have learned is that x 1 m P 1, P 2 I is. equal to x 1 h P 1 P 2 uNaught. This is an identity. not just equal to. this is always true. I can write it further if you pay attention to this that x1 m P1 comma P 2 and I is e of P 1 comma P2.

ROUGE-1: 32.05, ROUGE-2: 30.45, ROUGE-L: 31.45
BERTScore: 67.37

==============================================
==================== [93/100] ====================
Summary:
The definition is a cylindrical container containing a date covered with a [? basic ?] substance that can be deployed in order to attract and capture insects. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu.The following content is provided under a Creative Commons license. For more information about MIT Open CourseWare, visit opencourseWare.org. i3. A transportation system responsible for moving people and products with an enclosed metal frame equipped with various safety devices using electrically-powered control and locomotion subsystems. A concept for an all-electric vehicle. The i3 and EPFL? Anybody do the i3? Nobody. Anybody else here? Yeah, Veronica. Thank you. There's a lot there. OLIVIER DE WECK: OK. That's pretty good. I would throw a question. Justice. defined could almost apply to a Tramway as well. If this was like a streetcar, don't you think it would apply to that as well? So I think the fact that it's a personal vehicle, I think it's important. So the key in this is, describe the concept using few words precisely, but to set it apart from neighboring concepts. What about Rolex Center? It's a single-layer building with multiple straw used as a library for people to meet and study. bank, a cafeteria, student services. But you could encompass it in a meeting area. You meet and you do some stuff like eating, going to the bank. So in that sense, it's pretty similar. But I think the Rolex Center is such an iconic building that it also serve a kind of a prestige function, to put the institution on the map in terms of it's a statement. Whereas, I would argue our MIT student center, it has very similar functions to theRolex Center, but I wouldn't call it an iconicBuilding. built. So we could spend a lot of time on these, but really crisply refining and thinking about the concept is very, very important. So let me very quickly go through the refrigerator case study to show how do we transition from concept to design. So the first thing you do is understand where is the value-- the stakeholders and the stakeholder analysis and the requirements definition. And then you interpret and incorporate some of the needs into goals, which become requirements. And so the goals then are an instrument of the primary delivery value delivering process. deliver that value you need to design the product, the product system and the product object. And there is a recipe for doing this. So first you start examining the operand associated with value. What's really the thing that generates the value that the user, the beneficiaries care about? Next you say, this is the attribute link. And so the attribute-transforming process is where the value is generated. So the refrigerator effectively becomes a food spoilage rate reduction device. and I. In order to chill, we need a chiller, and there are different types of chillers, like a cooler or refrigerator. The key idea is start thinking in this abstract way, and all of a sudden all these other possibilities become possible. Once we have that, we can start managing complexity, decomposing function and form. And then our system object, you can decompose it into different elements, supporting systems, the operand, the operator, and so forth. It's the combination of this specific way you're going to operate the system. for something very simple like a cooler. One question and then we'll talk about the refrigerator and how it's different in a minute. So architecture selects the concept, the decomposition, mapping of function to form. Design, then, given that, selects the actual values for those design variables, and then you can optimize. So when you look at the example of the cooler here, we have our cooler with the box in the bottom and then the ice, and we can decompose the attributes of that. Swiss refrigerators are much smaller than those in the U.S. The form function mapping in the refrigerator is actually much simpler than the cooler. But the real complexity comes in when you look at the form form mapping. This is then the decomposition of the refrigerator in terms of all the elements of form and then how they relate to each other. In the refrigerator, each of these elements supports, essentially, one of the primary sub-functions. But in the cooler, they have much more of a one-to-one mapping. is concept generation. So take the requirements and think creatively about how these requirements could be fulfilled. That's concept generation, finding systems that do the right thing. And then once you have several concepts, you've got to select among them, which we'll talk about next week. Do you do you see the difference? What do you think? Share your thoughts in the comments below or post a video on our Facebook and Twitter pages. Follow us on Twitter @CNNOpinion and @CNBCOpinions. The goodness of an architecture is really a pretty complex concept where we have multiple objectives to satisfy, including performance, resource utilization, cost, operability, safety, capacity, and so forth. So architecture requires consideration of both function and form related through concept. It's about starting with the operand. What is the thing that the beneficiary, the stakeholder cares about, and how do we transform that? Concept then elaborate these into architectures that have form function and structural complexity. So the NASA approach is basically described in the system engineering handbook in the SE engine as step 3 called logical decomposition. System design and management program is a full-year program. It's essentially focused on decomposition, which is an important part of architecting. So let me talk about methods and tools for concept generation. So what are different ways of stimulating or organizing creativity? And what I'm showing you here is-- that's essentially a mind map of how to think about the creativity space. And then we have this whole area here, which I'm going to mention, but we're not going to do as part of the class. industry almost. There's an ideal group size, and it says 5 to 10 here, but I should probably revise this to be-- what do you think? 7 plus minus 2. If you try to do brainstorming session with 30 people in the room, it's not going to be that productive. What's important is that you have a clear idea of why you're doing the brainstorming sessions. And then there's this killer sentences you should never say during a brainstorming. take turns expressing thoughts, suggestions, ideas. You should take notes. These big whiteboards are great for that, with idea paint, the whole wall. Or you can do flip charts. You can do different ways of capturing these ideas. And then the idea there is produce a large amount and diversity of ideas. It's called the principle of delayed judgment. So you're not allowed to criticize or particularly praise. Even though it's praise, it actually implicitly is criticism of the other ideas. Leonardo sketching is more important than writing. He didn't build a lot of his ideas. But he was a head of his time in many ways. So he's really been identified as an exceptional individual. Here's a book called How to Think Like Leonardo, Seven Steps to Genius. And what's been extracted from this is the seven da Vincian principles of creativity. And they're here in Italian. And I'm just going to go through them. I'm not a big fan of these popular books, but this one is pretty interesting. very quickly. So curiosita, lifelong quest for learning. Dimostratzione, testing your knowledge through experience, trying things out. Sensazione, continual refinement of the senses. Mastering ambiguity, paradox, uncertainty. Arte/Scienza is the whole brain thinking, left-right brain. Corporalita, balance of body and mind, so a healthy mind and a healthy body. Connessione is interesting. That gets close to system architecture, which is the appreciation of patterns, relationships, connections, and systems. All right. Let's move to some of the structured processes for creativity. or an architecture. So the key decisions are the rows. There are factors in the rows, and then for each row you think about what are the number of possible alternatives for doing this. And then you enumerate all possible combinations. And the big challenge with this, of course, is if you have many factors, you could generate many infeasible architectures. Not all these combinations are actually feasible. So that's architecture enumeration, and there's different ways of doing this at different layers of abstraction. like 12 different tail geometries here. At that higher abstraction layer, it's just a single tail. So how do you combine these using compositional rules? That's architecture enumeration. So here's also an example from [? Narek's ?] work. So at an engine, a turbo prop engine at a high level of abstraction, that's basically a propeller, an intake, a core, and a core nozzle. And then to break that concept in further detail, the core itself gets shown at a lower level of detail. of this can be done in Excel, for example, where you essentially list your components. This is your library of components. And then on a different sheet, you define all the different rules that allow you to combine different number of instances of these components into architectures. And we'll post some information on this if you want to try this out for your concepts. So let me summarize. So system architecture is definitely very abstract, but it's also, potentially, the most influential activity that we do in system architecting. A3 assignment A3 asks students to come up with new ways of brainstorming. Students must use mind maps, morphological matrices, and architecture enumeration. The assignment is due in two weeks and will be graded on a scale of 1-10. The final assignment will be given to students at the end of the month and the results will be published in the next few days. For more information on the assignment, visit the assignment website. It is open to students from all over the world and can be downloaded from the assignment site.

ROUGE-1: 40.16, ROUGE-2: 36.92, ROUGE-L: 34.82
BERTScore: 67.70

==============================================
==================== [94/100] ====================
Summary:
then we are going to continue with the second part of the lecture today which focuses on the problem what actually happens if the gaussian assumption that i have about my constraints doesn't hold you can have multiple reasons why this doesn't holding. As you will see in some small examples having this outliers in your optimization problem is something which hurts dramatically which actually screw up your solution so already a few outliers can lead to a environment model which is completely unusable for doing any navigation task. Where the geometry of what you computed doesn't fit to the real world geometry anymore and one of the questions actually how to handle that. a corner so either my my laser beam hits one of those walls over there or goes out through the glass pane to the next building so i'm either measuring here two meters or measuring 200 meters it would be nice if i could say to the system as either 1 meter or 2 meter or 200 meter i simply don't know take into account a distribution which is not a gaussian with a single mode but why not taking account a multi-modal distribution. If we would have the possibility to integrate aMulti-Modal distribution here that would actually be a nice beneficiary and what i want to talk about here today is um ways for oops okay ways for doing that. they look very very similar it may be very hard for a robot to distinguish that we are here whatever in room 18 and all in room 16. Other things is if you have structures in the environment and there's a lot of clutter in the scene the clutter even if it has a repetitive pattern may lead to a multimodal belief about what the relative transformation between two poses let's say or you walk along whatever a corridor with very little feature every few features you only have say some pillars. can we actually take that into account it's not always easy to get this information out of your gps because typically it runs the kalman filter internally or most of the gps devices do that so they get a gaussian belief is screwed up. If you get the raw measurements you may be able to do better by allowing for multimodal distributions in here. There's one small example so there's a small robot which moved through the 3d board and this is what was similar to this repetitive structure that i was talking before. have also experienced and if you look to those poses over here in the poses down here how those individual structures match um if you just apply let's say scan alignment you may say this may match so maybe someone has opened the door which was closed before or here is a door now closed which was open all the other scans map actually quite well the same holds here. Even as a humanism you say okay there is definitely a misalignment between the skin so they don't fit perfectly but that's something which actually can result from small changes in the environment. over here so this is a single constraint you can already see that you don't have a straight wall over here anymore so it's kind of bended a little bit like this due to the single constraint which obviously has a really really large error so the least square error minimization at the error is squared error term tries actually to minimize that. If we add two three four five i think there were 10 constraints 10 wrong constraints the map actually gets so distorted that is unusable for navigation at least down here here you still may be able to navigate within. will actually end up in dramatic mapping errors so the system is unusable so having good data cessations is really important so already screwing up a small number of places is something which can hurt your optimization if you don't take that into account. How can we deal with the problem that we have places which look identical we have cluttered scenes uh we have may have gps multi-pass problems so the signal gets reflected for example at tall buildings and in this case screwed up the measurement how can we incorporate that into the graph based slam approach? the first attempt to to solve this problem this would be our probability distribution what is the problem with this probability distribution so i say okay some of my constraints are these multiple multimodal constraints i will simply go ahead and implement that. What's the problem that you're going to experience if you make this is some so this is we know how to solve that right this is what you know howto solve that that's what we did so far. If you do it exactly that way you start coding your stuff at some point i say hmm something doesn't work here what's what is that. don't have a single constraint we have a number of constraints right hundred thousand millions of constraints how do we combine those constraints if we minimize the squared error what are we actually doing? If we go to the log like negative log likelihood we're going to optimize here this term here minus a constant and here we can't go further than that that's a problem. There's where it fails do you see what is the dirtiest way for you to fix this let's say you started implementing that you have your implementation is. done you know he said oh damn i can't do that what would be the ugliest trick that you can do in order to make that work even worse no that's not quite what you're going to do i mean the sum is kind of the the the bad thing what can i do with the sum instead of the sum i can i can get rid of thesum in some nice way sorry oh the integral of some to the integral actually makes our life typically worth um so that's that's going to fly. The key trick is to simply say uh i just say where am right now is this actually the approximation error is actually kind of small if the gaussians are quite separated from each other. If one mode would be 2 meters and the other one 2 meter 5 then this may not be a good approximation but what we're going to do is we say okay just select the cave mode which is currently the best one so it's a maximization operation again. The idea of this max mixture approach to actually change the optimization from a sum of gaussian to a max of gaussedians. sum anymore we don't have we only have the mux in here and so then the the log if you go for for the log term i can move the log inside so when you see i just have this constant factor which i had before as well or negative log like i'm minimizing negative log likelihood this is exactly my expression so i stick with exactly the same operation here. The only thing i need to do whenever i compute the error function ineed to pick the mode of the gaussian which gives me the best performance. exactly the same in my code the nice thing is that actually between iterations you can the system can swap between different modes and therefore although the optimization in one iteration takes into account only one mode of the gaussian as you can switch the modes it is you still have the ability to deal with multimodal constraints if i do that that's what the result looks like so this was the original stuff you have seen before one wrong constraint 10 and 100 if i go for max mixtures let's say either it's a perfect fit or it'sa very very very flat gaussian this can be in layer or outlier. kind of in the system swaps to this other one if it is an outlier there's a very high likelihood this will swap to that. If you have a bad initial guess and the bad initial guessing is in line with the outlier then you may run into problems. Those are constraints which simply swap to the other mode and don't harm the optimization much. The solution may be still a little bit different than the one which is done completely without constraints because you still have this very very tiny error but it's actually kind of within the noise. individual constraints so when you evaluate the error the evaluation of the error is somewhat more expensive because every constraint can have can be multimodal or bimodal in this case. There's not no big difference in the operation of those systems when you um if you use the red or the. or the or the blue plot this is exactly the trick that is used um so if you just want to deal with outliers so the the red one is kind of the inlier and the blue function is the one which is the outlier. robot and the ground is muddy the wheels may slip before you get grip and the and the robot starts starts driving if this is the case although you're executing command you're standing and then you start moving so you may get this kind of distribution. In most cases actually the vehicle executes what you tell the vehicle to do but in some cases simply doesn't move. This max mixture idea is actually a pretty easy idea pretty simple idea just reply funny no one has done that in robotics until recently a few years ago. that's actually a nice thing so um another thing is it can handle both things at the same time data station errors as well as multimodal constraints. So the combination of outlier rejection and dealing with wrong data associations is actually kind of nice we also can do this obviously in 3d so this is again this data set with the sphere that we have seen before robot moving in a virtual sphere with constraints. This is gauss newton and this is the max mixture gaussnewton and um so you can see here there's a non-perfect alignment in here because you don't see the regular structure. if he increases to 100 outliers this is just whatever a big mess whereas this one still is able to solve those things quite nicely. The key idea the intuition behind that is if i have a constraint which has a large error so where the um the current configuration is far away from what the constraint tells me just reduce the uh or increase the uncertainty that is associated to that so decrease um the the information matrix so scale down the information Matrix. The question is still how do we get to that point. actually compute these so the main changes we go to this formulation we have the scaling factor over here and we need a good way to compute the scaling Factor so how can we actually do that and there's actually closed form you can derive that under certain properties. So what you do is you compute the original error then you compute this sij and just multiply your information matrix with this this leads to the case that constraints which are far away from what we expect have a smaller influence on the optimization so we can actually visualize this. in this area kind of the the core center of attraction both both perform equally well because there's no scaling involved. The further you move out the more the red curve gets scaled so it gets kind of fatter andfatter and better. If the error increases if you're further away from the mode this is what your error function looks like so the further away the more you down weight the influence of this constraint because you increase the uncertainty of the constraint through the gaussian distribution you can generate a flatter error function. and flatter and flatter gaussian distribution the further the point is actually away there's also one technique which you can find which is also quite easy to implement because you just need to compute the scaling factor and multiply that with your information matrix for every constraint. The tails of this gaussian distributions contain too few probability mass they're too close to zero that's very unlikely that you are really far away from the mode and therefore if you have one outlier which is really far from the current estimate the whole mole is tracked in this direction. now you get different properties in the optimization so if you use um if r is just the quadratic function then we exactly have the original problem that's what we minimized x of minus uh squared error so if we have this one we have we examine exactly in the gaussian world and now there are different techniques how we can actually address that one thing is we could take simply the absolute value so we don't square it just take theabsolute value of the error that's not the parabola that we have but the absolute function. Max mixture is kind of the max mixture for a bimodal distribution for dealing with outliers. The system optimized according to a different cost function but this allows you to take into account for example these these heavier tails so that outliers still are not weighted that dramatically and impact your solution so much because they completely disagree with the solution that you actually have before the solution. For dynamic covariance scaling just as a node this is similar to a robot stem estimator of these families that we have seen it's actually an equivalent. here that by changing this function you can't get much better behaviors kind of deciding which function to use for the underlying optimization problem is not on it's not always an easy and easy choice so this requires some expert knowledge some good intuition on coming up with the way with one of those functions. Next week which is the last week of the term i will briefly talk about front ends and give kind of a short summary on what typical front ends exist obviously we're not going to all the details as we did that here. setup to another sensor setup can be quite tricky on but the back end itself which sits here doesn't really change that much therefore the focus in this course which was much more on the backEnd. At least i would tell you a little bit about what typical front desk exists and how you could realize a front end if you want to build a slam system. Well that's something we are going to do next week that's it from my side thank you very much and hope to see all of you next week.

ROUGE-1: 56.67, ROUGE-2: 55.38, ROUGE-L: 56.47
BERTScore: 71.09

==============================================
==================== [95/100] ====================
Summary:
John Stuart Mill was the principle expositor of neoclassical utilitarianism. The rights-utility synthesis signals that we're looking for an attempt to put together both a commitment to utilitarian efficiency that's grounded in science on the one hand, and respect for individual rights on the other. We're not going to actually get to the rights-UTility synthesis as it's expressed in politics by John Stuart Mill until next Monday. What instead I'm going to do today is explain how the transition for classical to neoclassicals utilitarianism really went on in all fields of thinking about the human sciences. in philosophy that are going to be my principle focus in today's lecture. What you're also going to get is everything you ever needed to know about neoclassical economics in 45 minutes. At the same time, more or less, there were very important developments in moral philosophy that I just want to alert you to, that we're going to return to later when we come to consider Alasdair MacIntyre's book, After Virtue. And this movement that I'm mentioning here is the doctrine that would come to be called emotivism. It was associated with a man by the name of Stevenson who wrote several books advocating the emotivist doctrine when he was an untenured professor in the Yale Philosophy Department. His doctrine was that when we make claims like murder is wrong, we're making claims that express our emotions, our emotive reactions to propositions. All we're doing is expressing our tastes, our emotional reactions and that there is nothing more to say about ethics than that, he says. He says it's an endpoint in a philosophical evolution that really begins in the seventeenth century. Hume's famous for the idea that an ought cannot be derived from an is; that there's a fact-value problem. But he thought, nonetheless, people are pretty much the same, and so if you can figure out what makes one of them tick, you can find what makes all of themtick. And that was most emphatically Jeremy Bentham's view. It's presupposed in everything we discussed last time. If you think about the idea of doing interpersonal comparisons of utility, and making the judgment that taking that dollar from Donald Trump and giving it to me would be better, that's what Bentham would have said. it to the bag lady increases her utility more than it decrease his, you're assuming that they basically all have the same kinds of utility functions. Stevenson questioned that idea radically. He said, "We don't actually know. We should take Hobbes much more seriously in his critique of Aristotle than he was willing to take himself" And so that was thought to be a radically relativist doctrine because it seemed to undermine the possibility of making ethical judgments of any sort across people. That is a doctrine to which we will return, as I said, when we get to the anti-Enlightenment and, in particular, Alasdair MacIntyre's book, After Virtue. But today we're going to focus for the rest of our time on the economics of the transition from classical to neoclassical utilitarianism. And I'm going to ask you to suspend disbelief for the whole of today's lecture and just trust me, because what I'mgoing to do is go into this backwards. And it's not until you get to. the end of this narrative that you'll start to see why the transition in economics was essential for the transition. in political theory, and indeed in moral philosophy. lot of wine to get a second loaf of bread. If, on the other hand, you were choking on your six loaves of bread and dying of thirst the reverse would be true. And these are what are called indifference curves in neoclassical economics. And indifference curves basically imply exactly as the name suggests that you would be indifferent among the mixes of Bread and Wine anywhere on this curve. And this curve is always shaped that way, concave toward the origin. Anybody want to tell us why? What is it reflecting?  neoclassical economists wanted to understand the behavior of markets. They wanted to be able to more precisely to predict what prices were going to be in markets. Pareto, Marshall, and Edgeworth, and others who were in their circle, thought you could do this just with ordinal utility. So moving from cardinal to Ordinal utility is going to turn out to have huge ideological consequences, which I'm going to unpack for you towards the end of today's lecture. All All we would know about this person A, as I said, is that they prefer four to three, three to two, two to one, one to zero. But we can't say anything about how much they prefer those things because these distances don't actually mean anything. All we get is an ordered ranking. One other thing we can say is, that this is a no-no. These indifference curves cannot cross. Can anybody tell us why? Why can't they cross? Wait for the mic. you get it that way. But so now we have a diagram with two people on it, okay? So this is person A, and this isperson B. And these axes, the X-axis, here, is A's utility function. We don't know that A's happier than B from what I just said, right? These distances don't mean anything,right? So it looks like A's happiest than B, but that's misleading. If the different distances are taken to imply in your mind, disabuse yourself of that thought right away. he said, "Let's draw a line north-south through the status quo," okay? And we'll imagine that there's a finite source of utility. One thing we can say is if you can anywhere into the northeast quadrant both of them are better off, right? So if we go from X to Y we know A's utility has gone up. We don't know by how much, but we know it's gone up so they're both better off. On the other hand, if we went anywhere in here, this quadrant, southwest as it were, obviously they's both worse off. use, yeah, let's use J. If I put a point here, J, we would say that A's gone down and B's gone up. Now, to make this a bit more real imagine in here this is the sphere of market transactions. This is where A and B will go voluntarily, right? So A will say to B, "Well, I have all this wine, and you have all that bread, how about I swap you a bottle of wine for a loaf of bread?" And you say, "Okay." The Pareto principle out of which the whole of neoclassical economic theory was constructed depends on this idea of indifference curves. A is trying to get up on those indifference curves, and B is wanting to get along on them. And we can't say that B's gain is greater than A's loss because we don't allow interpersonal comparisons of utility. There's no scientific way to do it. We can't assume that everybody's basically the same. Perhaps they are, perhaps they aren't, but we just don't know, okay? A proposes to B swapping a loaf of bread for a bottle of wine and B agrees. They go to Y, and then A says, "Well, I'll give you another loaf of Bread for a Bottle of Wine" And B says, 'Forget it," and then they go to Z. When no transaction occurs, you know they've hit that frontier. So, the Pareto principle says that in a market system they'll move toward the frontier and when they get there, they'll stop. of course, they may have gotten there some way else. They might have gone from X to G over here, and then they would have done a new one. And that would just reflect shrewdness in bargaining, or how much people cared lower down their indifference curves. But once they wind up anywhere on this indifference curve they're not going to move off of it because now there is no way of improving one person's utility without diminishing the next person's. That's it. That is neoclassical economic theory in a nutshell. diagrammatically, and then if anybody doesn't get it we'll wait up and I'll go through it more slowly. But think about the diagram we just did, okay? Think about A is here in the corner,Okay? But basically now we're putting the two previous diagrams together. We're putting this diagram, where we have two commodities and one person, and this diagram where we've got two people and just utility. And so you'll see why this is helpful once we get to the end of it. John Rawls: The trouble with utilitarianism is that it doesn't take seriously differences among persons. He says classical utilitarianism says, "Well, if taking all of your utility increases overall net utility then we should do that, because we don't care who has the greatest number of the greatest happiness" John Rawls' argument is half-right, he says, because the truth is that's the classical utilitarianists' doctrine. John Rawl's Theory of Justice: The Case for Justice, the Case for Liberty, and Other Essays, is published by Oxford University Press, priced £16.99. which the radical fangs of classical utilitarianism have been ripped out and it is now a doctrine that is very friendly to whatever status quo happens to be generated in a market system. So it ceases to be this radically redistributive doctrine, and in the process imports into utilitarianism a very robust, some would say, hyper-robust doctrine of individual rights. We'll see how that played out in political theory when we come to look at John Stuart Mills' harm principle next Monday.

ROUGE-1: 41.72, ROUGE-2: 39.70, ROUGE-L: 39.64
BERTScore: 71.88

==============================================
==================== [96/100] ====================
Summary:
HONG LIU: So, first, we talk about chiral fermions. So, previously, we showed that the Dirac equation requires, actually, psi to have four components. And the answer turns out to be, no, you can reduce it, OK? And so there are two ways to reduce it. One is called the Majorana fermion. So we first talk about the chiralfermion and one way to do it. And then, we will look at the specific representation of gamma matrices. i 0, 0 sigma i-- again, the small sigmai is always the Pauli matrices. And then you can also work out the sigma Ij. Then you find the is given by minus 1/2, epsilon ijk, then sigma k. So do you see something? Yes? AUDIENCE: They're block diagonal. HONG LIU: Yes, they are. So if sigma is block diagonal, then that means this S is also block. So that means, if I write psi x into two component vector, HONG LIU: You don't need four components to be able to transform under Lorentz transformation. At least two components can already transform. So this tells you, in a sense, that the LorentZ covariance only requires two component spinors. So we have to do a little bit of work to do much work if you actually find the right trick to do this for any choice of gamma matrices. So you can check yourself that the gamma 5 is actually Hermitian. You need i for this to be true, OK? You can also take the product of all the gamma matrix together and then with a factor of i, OK?" HONG LIU: gamma 5 squared, squared to 1, is Hermitian, which means its eigenvalues are all real. He says if gamma 5 commutes with sigma mu, nu, then gamma 5 will commute with Sigma S. So gamma 5 acting on psi then just equal to psi L, and the gamma 5 psi R is equal to minus psi R, he says. HONG LIu: So you can easily see, by definition, that gamma 5 acts on psi L and psi R. HONG LIU: I will use that language when I talk about Majorana spinor. OK, so let's go back to this chiral representation and write the Dirac equation into it. And then you find that the cross term vanish. You can write it as psi dagger partial sub 0, plus i sigma i, partial i, psi L. And, indeed, the gamma 5-- gamma 5 in the other representation are related to this one just by a similar transformation, too. Without the chiral symmetries, there's no pion. Symmetry is only present in the classical level but not in the quantum level. And, again, that plays a very important role in particle physics, actually. It's also important in many condensed matter systems, like liquid helium, et cetera. Will not go into detail. The pions-- they essentially come from the Chiral symmeetries. And actually understanding how the pions come from them was a Nobel Prize to Nambu. HONG LIU: If tilde is just some other constant, then you multiply gamma 5. So, here, we can rewrite a little bit differently. We can consider rewrite this alpha L and alpha R in terms of the following. Let's consider the two transformation-- one transformation, psi L, and psi R transform the same. And the other transformation is that they transform oppositely. They transform in the opposite phase, OK? So I write the alpha-- and this writing is like that. HONG LIU: In physics, actually, the massless case actually gives you very much richer structure, normally, than the massive particle. Mathematically, it's because the representation of the Lorentz group is very different from the massive case. In Euclidean space, you continue gamma 0 to gamma 4. And then you reserve gamma 4 for that. Then the gamma 5 is the next one you take.this? Yes. Other questions? Yes, I'm happy to answer. HONG LIU: In the Dirac spinor, which we have talked about so far, is four components. In the chiral spinor we talked about, you have two complex components. The next one I'm going to talk about is the Majorana, in which case, I would argue, we have 4 times 1 real component. And, now, let's talk about the last case-- this case, which is-- you have four real components, OK? So what do you do? Again, we follow the similar strategy to see whether it's possible to have fourreal components. HONG LIU: The Majorana spinor was discovered by Majorana in 1937. Majorana is, like, half electron. Heuristically half electron, it has very stable topological properties, which a single electron does not have. He says if you can engineer in your condensed matter systems, Majoranaspinor then became a Holy Grail. HONG LIu: People say they have engineered Majorana Spinor in the lab, which I think has never been fully confirmed. complex conjugate of this equation because gamma mu m is real. So that means that, since gammamu m equal to gamma Mu m star, but if we take complex conjugates of that equation, means that the C star gamma mu, C minus 1 star is equal to C gamma mu. So, now, we see that B-- this actually makes sense. This is actually the matrix we take gamma mu to gamma mu star. So B is the matrix to take star, OK? Good. Any questions on this? But, in principle, you don't have to choose them to be unitary. OK, so, now, let's double check. So let's check that star star-- so we show that, here, in this representation, this is compatible with Lorentz transformation, OK? So we still need to check star, star is compatible. So it means that the psi prime star should be equal to the same as B psi prime. So that means this iscompatible with LoreNTz transformation. B when you act on sigma mu B minus 1. So that gives you minus sigmaMu, nu, star, OK? So this is obvious because sigmamu, nu has i there. So the minus sign comes from the i. And, otherwise, the B takes each gamma matrices there into star. And then that means that the S star, lambda, which is given by exponential 1/2 omega mu, nu. Now this is equal to-- yeah, you can just plug this in. we get a very nice relation that, under Lorentz transformation, is generated by this B, related to this B matrix. When you have the psi prime equal to that, let's just take the star of this equation, OK? So psi prime star just equal to S star, Lambda psi star, equal to B S. B minus 1 and B S-- B psi. So that means that the psi star should be equal to gamma 2 psi. That's the Majorana condition here. psi, and there should be another one, right? So is that one? HONG LIU: I don't quite understand your question. Say it again-- what? AUDIENCE: OK, [INAUDIBLE]. HONGLIU:OK, OK. Other questions? Good. OK, good. So let's now go to the next topic. We only have a few minutes, so we can only just make some general comments. So so far, mostly, we have been talking about continuous symmetries. But there are also discrete symmetry, OK? we have-- so this real scalar theory-- we can see that before. So this theory has a discrete symmetry because this is invariant under phi. It goes to minus phi, OK? And so this is-- if you do it twice, you go back to itself. And there are also spacetime discrete symmetries. So you can have so-called time reversal, which corresponding to your t. Then you revert all the spatial direction. So comment that you can ask why we actually reverse all three directions. How about if I just reverse one direction or reverse two directions? you take that phase to be pi-- say, exponential i pi-- and then you take to be minus phi. And so, in that case, this is part of the continuous symmetry. But, here, there's, nevertheless, another discrete symmetry. Can you see what is the other independent discrete symmetry here? Yes? Good. You can exchange phi to phi star, OK? It's a complex conjugation. And this is often called charge conjugated.

ROUGE-1: 27.92, ROUGE-2: 26.39, ROUGE-L: 25.76
BERTScore: 72.17

==============================================
==================== [97/100] ====================
Summary:
The best-case scenario for expansionary fiscal policy is when there are lots of underemployed resources in the economy. By increasing spending, the federal government can try to counteract falling aggregate demand. In one scenario, government spending doesn't have to be as large as the fall in "C," or consumption, to counteract the recession. That's because of the multiplier effect. But, as always, shifting lines on a graph is much more important than the long-run effects. easier than shifting around real resources in a multi-trillion dollar economy. Fiscal policy has many implementation challenges, and we'll turn to these next. You're on your way to mastering economics. Make sure this video sticks by taking a few practice questions. Or, if you're ready for more macroeconomics, click for the next video. Check out Marginal Revolution University's other popular videos, including the one about the U.S. debt ceiling and the next one on the debt ceiling.

ROUGE-1: 47.04, ROUGE-2: 42.19, ROUGE-L: 42.99
BERTScore: 63.85

==============================================
==================== [98/100] ====================
Summary:
Sarah thread sterner shows you how to wear and take off a mask. She explains how to determine which part of the mask is the front versus the back. She also shows how to mold the nose piece of the face mask with the finger tips of both hands. Finally, she shows you the best way to remove the mask by placing it over your ears and pulling it under your chin when removing the mask it's important to remember that the front is considered contaminated so remove it with the fingertip and then perform hand hygiene.

ROUGE-1: 29.04, ROUGE-2: 20.29, ROUGE-L: 23.82
BERTScore: 64.55

==============================================
==================== [99/100] ====================
Summary:
Adam Martin: In this video, researchers are shining light into a mouse's brain to activate specific neurons in order to test whether they function in arousal. In today's lecture, we're going to work towards understanding how this experiment works. We're also going to talk about how neurons function and how researchers are able to control that function to modify behavior-- in this case, the arousal of this mouse. And here, you see the mouse is going to wake up. There it goes. It's awake now. The sciatic nerve extends from the base of your spine all the way down into your foot, OK? So that's an extremely long distance to transmit information along a single cell. And so we're going to go from thinking about how signals are transmitted in single cells, and this will evolve electrical signaling. Then we'll talk about synapses and how synapses function to help us understand the function of a single neuron, and how they communicate with each other, and so on and so forth. Communicate between neurons. And this is going to involve also sort of understanding how certain antidepressants, like Prozac, work. And then we'll end by talking about how researchers did this experiment to wake up the mouse. And it all starts with something that I told you about at the beginning of the semester, which is that the plasma membrane separates distinct compartments the outside of the cell from the cytoplasm. And there are distinct ion concentrations on either side of this boundary. So we're starting now talking about a single neuron cell. This is thermodynamically not favored, right? These ions would prefer, by diffusion, to be equal concentrations on both sides of this plasma membrane. So the cell to shift this from equilibrium has to expend energy to set up this situation. And it pumps potassium ions into the cytoplasm such that there's a higher concentration of potassium ions in the cy toplasm. So these neurons expend a huge-- a quarter of their ATP is used by pumping ions like this. This voltage difference is known as a membrane. potential. So this is a membrane potential. And it's an electrical potential across the membrane. If the cell is not getting stimulated by something like a neurotransmitter, the resting potential is negative 70 millivolts. So the resting state of the side is there's a polarized-- it's polarized. However, the cell can lose this polarity and not have a charge differential, or it can flip and be positive on the side that has the negative inside potential. The cell can also be polarized and have a positive inside potential, or a negative outside potential. Inside a cell, if there's either zero or positive inside potential, this is referred to as depolarized. Anyone have an idea as to how the cell would flip the potential? What would have to happen in the plasma membrane to flip this potential and depolarize the cell? Yes, Stephen? AUDIENCE: You could open the ion channels. ADAM MARTIN: So Stephen suggested opening ion channels, which ion channels would you open? The sodium channels. Because remember, sodium is high on the outside, out here. And so if you open these channels, positive ions are going to flow in. activity of a neuron is not determined by the size of this action potential. This action potential is an all-or-nothing event. It either happens or it doesn't. And when it happens, it depolarizes to the same level. You can think of it as a binary signal. So now we're going to unpack how it is a nerve cell fires an action potential and how it propagates along the entire cell length. In the case of the sciatic nerve, this has to happen across an entire meter, OK? That's a very long distance to propagate this change in electrical signal, at least for a cell. How is it that this nerve cell is told to start depolarizing at the dendrites? Because there's going to be another neuron here, which is going to communicate to this neuron over here. It does this at the location known as the synapse. And the way this process is initiated is similar to the type of signaling that you saw in the past few lectures, where you have a ligand and a receptor. And these receptors are what are known as ligand-gated ion channels. In this case, it's a sodium channel. Whether or not it's open depends on the presence of the ligand. The depolarization is going to be high where the sodium channels are only entering. And then following that, you would have potassium ions getting pumped out and basically repolarizing the cell. So here, you have a spike, and you complete the cycle. It can even get hyperpolarized, where it gets even more negative than it normally does. It eventually gets back to this resting potential of around negative 60 or negative 70 millivolts. And I want to tell you about one process or property of neurons and another helpful cell that enables this to go extremely fast. tape for neurons, OK? So they are these-- there's electrical insulation around the axons of these neurons. And this is provided by another specialized cell type called a glial cell. And that insulates the plasma membrane of the axon such that-- so here is an axon. You have glial cells that are wrapped around, and it sort of forms like beads on a string. And so there are these gaps between the myelin sheath that are known as the nodes of Ranvier. ones, localize to these nodes. And when the action potential is traveling along the axon, because. these regions where the myelin sheath is are electrically insulated, the. axon potential doesn't just move continuously, but jumps from node to node. And if you damage this electrical insulation, you greatly slow down these action potentials, and that has a significant impact on nerve impulses in the brain and throughout the entire body. And that's why multiple sclerosis is such a devastating disease. but you might have another neuron sending a signal to a synapse on this part of the cell. And you could have another signal coming in here. And so this neuron will then have to decide whether or not to fire an action potential down its axon. So there's a signal integration process. And what's important for signal integration in a neuron is whether the cell body-- whether the voltage increases above a certain threshold potential. If the voltage increase above the threshold potential, then it fires the action potential and signals to a downstream neuron or muscle. The synapse is the gap between the axon terminal of one neuron and the dendrites of a postsynaptic neuron. The way that multiple neurons communicate with each other are through a type of signal known as a neurotransmitter. Neurons are totally prepared to send signals to each other. They have everything ready to go when they get word from upstream, and they're ready to sent signals to the next cell. The fusion should be triggered by the action potential. In order to fuse, there needs to be some signal inside the cytoplasm to tell the vesicles to fuse. the plasma membrane of the cell, thus releasing the neurotransmitter into the synaptic cleft. So this is what starts the signal. Now, you probably know that these neurons are not active or on all the time. So something has to terminate the signal, usually quite rapidly. So now I want to talk about that. So like all signaling pathways, signaling is useless if you can just turn it on. You have to be able to toggle it on and off in order for biological systems to function properly. And that's the case with neurons. Prozac, Zoloft, these are a class of drugs that are known as selective serotonin reuptake inhibitors. This is abbreviated SSRIs. But the way they function is to leave the neurotransmitter in the synaptic cleft for longer so that you enhance signaling, even if you have low levels of the neurotransmitters. All the machinery on this vesicle is recycled by endocytosis such that it can be reused again, OK? So cells are really good at recycling stuff. If this is sort of the membrane, youendocytose and then you can use it again later on.  optogenetics is an approach to control the activity of a cell with light. In this case, we're going to have light inducing depolarization. And the way this is done is there's a protein discovered from photosynthetic algae that's responsive to light. And this protein is called channelrhodopsin, specifically ChR2. And if that's expressed specifically in the neurons that you're trying to test, you can then shine a light into the brain of the organism and activate this type of neuron. you to test the function of the neuron in the behavior of an organism. So, in this case, this mouse, the light is shined into its brain, and they're testing a specific type of neuron that is involved in arousal of the mouse. And it's going to wake up right now. There it goes. It woke up. You see now its muscle activity is going, OK? So you can test thefunction of specific nerve cells using this approach, and it's because you have a light-sensitive sodium channel.

ROUGE-1: 39.82, ROUGE-2: 38.22, ROUGE-L: 38.26
BERTScore: 74.05

==============================================
==================== [100/100] ====================
Summary:
In this problem, we're going to be dealing with a variation of the usual coin-flipping problem. But in this case, the bias itself of the coin is going toBe random. And we're told that the expectation of this bias is mu and that the variance of the bias is some sigma squared. So how do we go about calculating what this is? Well, the problem gives us a int. It tells us to try using the law of iterated expectations, but in order to use it, you need to figure out what you need the condition on. The problem also defines the random variable x. X is the total number of heads within the n tosses. Or you can think of it as a sum of all these individual xi Bernoulli random variables. We can remember that linearity of expectations allows us to split up this sum. And so each of these expectations of xi should be the same, no matter what xi is. Each one of them is mu. We already calculated that earlier. And there's 10 of them, so the answer would be n times mu. The law of total variance will tell us that we can write the variance of x as a sum of two different parts. The first is variance of the expectation of the variance. And the second is the conditional expectation of x given Q. The final answer is just a combination of these two terms. This one and this one. And now, let's try doing it another way. And we can actually use a formula involving the covariances of x. And that is actually a covariance of sigma squared. An art that you learn through more practice. But one good rule of thumb is, when you have kind of a hierarchy or layers of randomness, it's useful to condition on the layer above where that is, in this case, the random bias of the coin itself. Once you condition on that layer above, that makes the next level much simpler. Because you kind of assume that you know what all the previous levels ofrandomness are, and that helps you calculate what the expectation for this current level.

ROUGE-1: 21.47, ROUGE-2: 20.20, ROUGE-L: 20.83
BERTScore: 71.63

==============================================
