This lesson will first dive into some signal Theory and then move on into things that we're more familiar with things like deconvolutions and using Transformers for next note prediction. The first thing we want to talk about is how can we sample and quantize a continuous time signal. We then go into some geometric signal Theory with Transformers and finally how how we can kind of generate sounds using these. The next thing we're going to kind oftalk about is changing forms. We'll talk about the SARS ADC algorithm and how it's used to convert digital signals to analog. is less than double of the highest frequency present aliasing will happen. This asserts that you need at least two samples per period. aliasing is the byproduct of poor sampling. A lower wave resolution will result in a modified output signal as compared to the original input that we're trying to process. There's a lot of literature about um aliasing effects including spatial illnessing. The aliasing phenomenon is incredibly interesting this happens both visually and auditorily. It's a very prevalent problem in any problem. that can tie in to reconstructing signals right um we we are also going to talk about um using deconvolutions. We talked about the unit architecture very thoroughly used for image segmentation we talked about it in our survey of uh computer vision techniques. This is something that uh that is kind of going to come back in terms of how we can reconstruct signals so the inner product and projections are an application of inner products where one vector can be projected onto another Vector and you can you can kind of see what the projection is based on. is that as our our basis differs as long as these are orthogonal vectors and they span the complete basis of a certain Vector we're able to reconstruct this Vector. The idea behind the the last two sections here was to give you motivation for for how signals work and how kind of classical reconstruction can occur using math that we're all familiar with. The next step here we want to use deep learning for reconstruction right where we are are reconstructing a low quality audio to high resolution audio. are the original Pachelbel's Canon um as you can see this does deviate a bit but honestly it sounds pretty good. The Transformer model is able to do this next note next sequence prediction pretty pretty well. So yeah there's a a lot to do in this field um a lot of really cool things happening um and yeah I hope you guys learned something about uh about generative audio today and are inspired to kind of give some of these things a try yourself. thank you guys for tuning in have a good one.