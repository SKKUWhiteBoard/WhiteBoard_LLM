This lesson will first dive into some signal Theory and then move on into things that we're more familiar with things like deconvolutions and using Transformers for next note prediction. The first thing we want to talk about is how can we sample and quantize a continuous time signal. We then go into some geometric signal Theory with Transformers and finally how how we can kind of generate sounds using these. The next thing we're going to kind oftalk about is changing forms. We'll talk about the SARS ADC algorithm and how it's used to convert digital signals to analog. voice and Pitch it up very fast right what quantization level do we do we want there. Can we do a lossy pitch up with a uh with by filling in the the blanks in some intelligent way through prediction or kind of note fitting which is an interesting consideration I think given the fact that audio is a continuous time signal um the digitization process and the choices you make matter a lot and because of that this field is so interesting and there's a lot of really didactic work around how we can take these continuous signals. also increases we're at one Hertz you're almost perfectly fitting the polynomial on the the points. aliasing is the byproduct of poor sampling right so a lower wave resolution will result in a modified output signal as compared to the original input that we're trying to process. Different frequencies approximate our input wave differently right this wave you wouldn't really think is indicative of uh the original signal that you're tryingto process. This is an example of where aliasing would be present at the Nyquist trade so exactly at um double the highest frequency you can see we have an approximation. actual wave is the byproduct of a lot of of aliasing right where we have a curve that is not representative of our our sample at all because we're sampling at a rate that is uh is not adhering to our our aliasing uh the law. frequencies that are higher than one half of the sampling rate will be automatically transformed to lower frequency sees that's where information loss stems from. There's a lots of literature about um aliasing effects including spatial illnessing right um so I'd highly recommend checking out some of these links. um this is is kind of uh and and add add-on um to this presentation it uh doesn't really contribute exactly to what we're talking about but I thought this was incredibly cool um with one line in C you're able to to generate Melodies um which is incredibly coolUm yeah so please check it out if you if you guys have a chance uh the next thing we're going to talk about briefly is geometric signal Theory. Um and specifically you know what a projection is how it can be used to reconstruct signals and finally how that can tie in to reconstructing signals. familiar with perhaps in terms of how we can use those to reconstruct signals and ultimately how we Can use Those to generate audio right predict the best uh kind of next node um so looking at the next the next step here we want to use deep learning for reconstruction right where we are are reconstructing a low quality audio to high resolution audio right um and this is this is the kind of uh model framework um that we can used for this um you might notice it really closely resembles a unit which is something that we talked about during image segmentation. Transformers can help increase our sample of training data and generalize key scales and beats throughout a data set. A single song can be transformed into 12 songs of different Keys. The more data you have the better your model will be and the more generalizability you have in your Transformer the better it'll perform. Transformers will far outperform classical methods of of both computer vision and natural language processing. It's easier for machines to predict keys without flats and Sharps which has you know similar to what humans do. hidden state memory Transformer memory enables very fast inference for music prediction right we've done a lot of things to optimize for for our prediction we're including a beat embedding so that's not something it has to learn. We're able to get a sense of of relative position with Transformer XL whereas vanilla Transformers will use Absolution absolute position only. It's important for music models to know the position of each token relative to one another because positionality matters right the order that you're playing the notes really is is what matters the most and this is an additional to our positional beat encoding. things a try yourself uh yeah thank you guys for tuning in have a good one. Things you might want to try yourself. Things that you may want to give a try. uh yeah. things you might be interested in trying yourself. things that you might like to give yourself. uhYeah. things a try yourselves. uh Yeah. Things a try themselves. Things your might like yourself.things you may like to do yourself. thanks you guys. for tuning into this week's episode of The Daily Discussion.