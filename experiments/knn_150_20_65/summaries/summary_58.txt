Last time, we covered Fourier series and the Fourier transform. Today, we're going to talk about the convolution theorem, noise and filtering Shannon-Nyquist sampling theorem as a function of time. All right, so that was just a brief review of what we covered last time. Now, let's take a look at another function that we've been talking about, a square wave. In this which is 2 bels, which is 20 decibels, we can see a series of peaks because it's a periodic signal. and spectral estimation. And next time, we're going to move on to spectrograms and an important idea of windowing and tapering, time bandwidth product, and some more advanced filtering methods. And we'll end up on the Shannon-Nyquist theorem and zero padding. And there may be, if there's time at the end, I'll talk about a little trick for removing the line noise from signals. All right, let me point out why spectral estimation is very powerful. So remember, we talked about how you can see, if you have noise, the power spectrum of the original signal. we plot power in log base 10. A difference of an order of magnitude in two peaks corresponds to a unit called a bel, b-e-l. Deci just means a tenth of, right? Remember those units? A factor of 10 in signal is a factor of 100 in power, in the middle. It's just imagine that you have a sine wave that gets smaller as you go away from the origin by an amount 1 over f. That's all it is. Fourier transform just stretches out. If you make the square pulse smaller, the sinc function gets broader. If I make that Gaussian pulses in time narrower, then the Gaussian in frequency gets wider. And inversely, if I make the pulse in time wider, than the Gaussian in frequency space gets narrower. This is where the Heisenberg uncertainty principle comes from, because wave functions are just-- you can think of wave functions as just functions in time. All right, so it's a very important theorem. Basically anybody's acquiring to know the Shannon-Nyquist theorem. Convolution theorem says Fourier transform of y is product of Fourier transforms of g and x. We're going to talk now about how you do filtering in the frequency domain. The kernel for a low-pass filter is a delta function that reproduces the function of a high-pass filtered version of the signal. And then we'll talk about how to filter a signal with a linear kernel in the high-frequency domain. We'll end the show with a question-and-answer segment. wanted to show you what the autocorrelation function of this looks like. So if you look at the distribution of all the samples, it just gives you a distribution that it has the shape of a Gaussian. And the standard deviation of that Gaussian is 1. Now, what if you plot the correlation between the value of value of this function at time t and time t plus 1? So they're completely uncorrelated with each other. So there's zero correlations between neighboring samples. into short pieces. extracting that little piece of signal from this longer signal is essentially the same as multiplying that long signal by a square pulse. So that process of taking a long signal and extracting out one piece of it has a name. It's called windowing. And you compute the power spectrum in each one of those windows. And again, you average them together. So using these methods, you can pull tiny signals out of noise at a very bad signal to noise ratio, where the signal is really buried in the noise. Filtering in the frequency domain means multiplying the power spectrum of your signal by a function that's low at high frequencies and big at low frequencies. So convolving our original blue signal with this green Gaussian kernel smooths the signal. It gets rid of high frequencies. Any questions about that? Well, yes-- AUDIENCE: So why is it that like-- you need to like-- of I guess when you filter a signal, either high pass or of that Gaussian? It's just another Gaussian. Gaussian, you're not adding some of the signal here that were over here. Convolving with a sinc function kind of mixes things in time. So normally you would smooth by functions that are kind of local in time, local in frequency, but not having sharp edges. So we're going to talk about how to smooth things in frequency with signals with kernels that are optimal for that job. That's Thursday. What would a high-pass filter look like in the frequency domain? signal has some bandwidth B that in order to sample that signal properly, your sampling rate needs to be greater than twice that bandwidth, 1, 2. There was recently a paper where somebody claimed to be able to get around this limit. And they were mercilessly treated in the responses to that paper. Now that's an amazing claim. Right? You have a [AUDIO OUT] time. All right, it's wiggling around. What this is saying is that I can completely ignore what's happening between those samples and make it a longer vector.