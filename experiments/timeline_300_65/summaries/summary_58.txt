Last time, we covered Fourier series and the Fourier transform. Today, we're going to talk about the convolution theorem, noise and filtering Shannon-Nyquist sampling theorem and spectral estimation. Next, we'll move on to spectrograms and an important idea of windowing and tapering, time bandwidth product, and some more advanced filtering methods. The series of three lectures will continue on Thursday and Friday in New York and Washington, D.C. and on Friday in Los Angeles. as a function of time. At some frequency, here, 20 hertz. We compute the Fourier transform of that and plot that. So that's what this looks like. Here is a cosine at 20Hertz. And you can see that what you see is the real part as a. function of frequency. It has two peaks, one at plus 20Herz. And the imaginary part is 0. So any questions about that? Feel like I didn't say that quite as clearly as I could have? OK. we plot power in log base 10. A difference of an order of magnitude in two peaks corresponds to a unit called a bel, b-e-l. More commonly used unit is called decibels, which are 10 decibel per bel. So decibles are given by 10 times the logbase 10 of the power of the square magnitude of the Fourier transform. Does that make sense? Good question. All right, any questions about this and what the meaning of decibela is? The faster something moves in time, the more stretched out the frequencies are. We're going to talk about the Fourier transform a Gaussian noise and this power spectrum of Gaussian Noise. We'll talk about how to do spectral estimation and we'll end up on the Shannon-Nyquist theorem and zero padding. And there may be, if there's time at the end, a little trick for removing the line noise from signals. OK? All right, so that was just a brief review of what we covered last time. that particle can be computed as the Fourier transform of the wave function. So if the particle is more lo-- [AUDIO OUT] in space, then if you compute the Fouriers transform of that wave function, it's more dispersed in momentum. OK, so the uncertainty in momentum is larger. So this concept of time bandwidth product in the physical world is what gives us the Heisenberg uncertainty principle. It's very cool. Actually, before I go on, you can see that in this case, the Fouriester transform of this function is the same function. a convolution. The convolution theorem tells us that the Fourier transform of y is just the product of the Fouriers transform of g and the Fouriester transform of x. Michael FEE: I'm going to walk you through how you derive that. The derivation is kind of cute, and I enjoyed it. But it's also really powerful. OK, so let me show you what you can do with that. We're going to calculate transform of a Gaussian, some window centered around 0 in time-- this is a function of time. The Fourier transform of a Gaussian is the product of a sine wave and a cosine function. You can figure it out very simply, because you know the Fourier transforms of aGaussian. There are many, many examples of interesting and useful functions in the time domain that you can intuitively understand just by having this idea. It's very powerful. All right, let's talk about Gaussian noise and the power spectrum of noise. And we're going to eventually bring all these things back together. wanted to show you what the autocorrelation function of this looks like, which I think we saw before. So if you look at the distribution of all the samples, it just gives you a distribution that it has the shape of a Gaussian. And the standard deviation of that Gaussian is 1. Now, what if you plot the correlation between the value of value of this function at time t and time t plus 1? So they're completely uncorrelated with each other. On average, if you take many different signals, many copies of this, and calculate the power spectrum and average them all altogether, it's going to be flat. But for any given piece of noisy signal, the power Spectrum is very noisy. We're going to spend a lot of time addressing how you solve that problem in a principled way. In the next lecture, we'll talk about how to make a good estimate of the spectrum of a signal by breaking it up into little pieces. a noisy signal that has a little bit of underlying sine wave in it, we talked about in class, if you take the autocorrelation of that function, you get a delta function and then some little wiggles. So there are ways of pulling periodic signals, periodic structure out of noisy signals. But it turns out that this method of spectral estimation did the most powerful way to do it. So using these methods, you can pull tiny signals out of noise at a very bad signal to noise ratio. So it's a very powerful method. of noise. In order to estimate what the spectrum of noise looks like, you have to take many examples of that and average them together. And when you do that, what you find is that the power spectrum of Gaussian noise is a constant. It's flat. The power spectrum, really, you should think about it properly as a power spectral density. So there is a certain amount of power at different frequencies in this signal. And forGaussian noise, that power spectraldensity is flat. Itâ€™s constant as a function of frequency. low pass, by convolving a signal with a kernel. The kernel for a high-pass filter is a delta function that reproduces the function. filtering in the frequency domain is multiplying the Fourier transform of a [AUDIO OUT] times the Fouriers transform of the kernel. Power spectrum of the filtered signal is just the power spectrum of your original signal times the power Spectrum of the kernels. So convolving our original blue signal with this green Gaussian kernel smooths 0 at high frequencies of blue signal and 1 at low frequencies. with each other? If we look at for the red signal, y of i and y ofi plus 1, what does that look like? They become correlated with each other, right? Because each value of the smooth signal is some sum over the blue points. So if you look at the autocorrelation of the original Gaussian noise, it has a delta function at zero. And the width to that autoc orrelation function tells you the time [AUDIO OUT] this signal was smoothed. Any signal that has discrete components and frequencies is periodic in time. Discretely sampled in time means that the Fourier transform is periodic. If the sampling rate is less than twice the bandwidth, what happens? That means delta t is too big. These copies of the spectrum are too close to [AUDIO OUT] and they overlap. That overlap is called aliasing-- a-l-i-a-s-I-n-g. You can perfectly reconstruct the signal, even though I didn't look there. Matlab has built into it the ability to do zero-padding right in the FFT function. You can also sample the signal in the time domain and then add a bunch of zeros to it before you Fourier transform. And that gives you finer samples in the frequency domain. And I'll show you in more detail how to do this after we talk about tapering. See something at the wrong frequency? That's an example of aliasing. OK? OK, let's actually just stop there. I feel like we covered a lot of stuff today.