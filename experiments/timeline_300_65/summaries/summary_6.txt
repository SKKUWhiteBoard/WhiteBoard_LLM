foreign and I should turn off the zoom background blur Ry options like this oh it does show up uh yeah there's like speaker notes on your screen but there's be careful because I accidentally just put something else in the first longer okay. I apologize that was kind of a rough introduction that was uh that was me making a couple of last minute edits that probably hurt more than they helped so I want to just apologize. I just think I was just too ready to go I usually uh yeah as our slides were they and put which is the product describing to replace the names. review um convolutions and and the architecture of a CNN to make this more clear and put it put it into perspective how it relates to um just standard um dense neural networks I think it's fine um so we talked I think I think most people felt okay about um the actual mechanics of doing a convolution. When you have images and a CNN you can simply just do convolutions instead of your normal matrix multiplication. You have pooling layers if you want to decrease the size of this volume because it can get quite unwieldy. but it's still ideally still sort of captures all the main information that was in that uh that feature volume um yeah it's it's more just used so we can get our feature volume down to a reasonable size so it doesn't take forever to run convolutions on it just makes it a lot quicker yeah no well so we're going to talk about um segmentation which is where you have like an image like a person in it and you need to Output another image except each pixel has basically been like labeled with like there's a person inside of like here and then everything else is background so in that case your output is the same size as your input which gets a little bit weird. different activation Maps one from each filter that we obtained so your your Channel's Dimension uh would be 10 Deep um yeah it just corresponds to like if if if this filter is corresponds to horizontal edges and this filter corresponds to edges like this. You can just sort of look along the channel and see like okay like was there an edge that went this way was there a feature that went that way. If there are any more questions then I will hand it over to Rohan who's going to talk about more advanced CNN architectures. a little timeline here starting from uh alexnet and moving forward. laneet is something that was created quite a while ago. Alexnet in 2012 was a a big groundbreaking feat in that it proposed stacking layers of convolutions Max poolings following it up by fully connected layers. This really sets the stage for uh the the future of advancement in this field so yeah convolutional Nets were proposed in 1990 by Yen lacun and he kind of pioneered that pattern for today he's currently head of AI at Facebook AI research so furthering the metaverse. because you're not negating the problem this is highly dependent on what system you're using to compute these as well as where the model is eventually running so yeah um yeah dude that was an example of a very long uh residual net adding skip connections makes the identity easier to learn because you're quite literally adding a previous identity to the resultant of a transformation. If you add if you put a million layers on a dense neural network it's going to just learn like garbage like it's not going to work at all but like that's kind of weird because we should just trivially be able to add more layers. shouldn't produce accuracy when in reality like if this is scaled it can yeah awesome group wise uh your Dimensions so yeah this is a really good point um so if your layer is a convolution um the dimension can change which is why often this is result like kind of viewed as f of x plus W of X where W is a transformation that you do on X two to make it the same Dimension exactly. Global average pooling is designed to replace fully connected layers in cnns. The typical dense layer that you previously had that's facilitating these connections does not enforce correspondences between feature maps and categories. As you go through the three dense layers at the end of the network there's no parameter to optimizing global average as well which saves overfitting time. As we get deeper the number of channels can get large which leads to a lot of parameters. What if we process each Channel separately and then intelligently combine those at theend how can we still retain data from each Channel while reducing the computations that you're doing? number of uh computations that we need to do the answer is depth wise separable convolutions so this is a a pretty decent visualization of how that works. If you have like a three channel uh like some X by X image you're applying a uh like a feature map to it and then you're left with one product by one channel. Instead of that what if we took each Channel individually we applied a smaller or a lower Dimension feature map and created three depthwise layers and then combine those with a convolution. those so you can think about it instead of doing one step that results in one map and multiplying that by the number of filters you have you're not doing one. You're applying this one step to every channel and then your next step is applying a different sized convolution to do your filter multiplication. Instead of one step you have two steps that are being combined um which reduces complexity quite a bit alrighty I guess we can quickly go over like squeezing anxiety networks basically uh you squeeze you apply this through a couple of dense layers and then you rescale. CNN.swap out if you're very well CNN building plus um you know yeah I think understanding like the the base of how optimizations are held and the problems that certain optimizations face and others don't really sets the stage for like future networks like the efficient net in 2020. There will also be a quiz at least is there a homework position closer or not [Music] um and do next Friday [ music] thank you for sure. Thank you guys for coming thank you Guys for coming.