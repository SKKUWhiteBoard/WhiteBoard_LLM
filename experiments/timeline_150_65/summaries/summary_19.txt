Professor: We're just start with a short review problem on rugged landscapes. And then we'll get into the core topic of the class, which is evolutionary game theory. And we'll discuss why it is that you don't need to invoke any notion of rationality. Then we'll try to understand this difference to human decision making, professor says. The course is part of MIT OpenCourseWare. To make a donation or view additional materials from hundreds of MIT courses, visit MIT Open courseWare at ocw.mit.edu. know what a Nash equilibrium is in the context of game theory versus an evolutionary stable strategy in this context. And we'll say something about the evolution of cooperation and experiments that one can do with microbial populations in the laboratory. Are there any questions before I get started? All right, so just on this question of evolutionary paths, on Tuesday we discussed the Weinreich paper where he talked about sort of different models that you might use to try to make estimates of the path that evolution might take. Each time that an individual divides, it has a 1 in a million probability of mutating. And that's a per base pair mutation rate. Originally when we discussed this, we were talking about just mutations, maybe A's and B's. But now, what we're going to have is just a genotype. And I'll show you what I mean by that. I'm going to give you some fitness values just so that we can be clear about why it is that there might be different paths. short genome that's string length 2. So we're assuming that this is relative fitness as compared to the 0, 0 state. And the question is, what's going to happen eventually? And in particular, what path will be taken on this landscape here? You can start thinking about it while I write out some possibilities that we can vote for, and I'll give you a minute to think about it. So don't-- Are there any questions about what I'm trying to ask here? If we wait long enough, the population will get there, and the 1, 1 genotype will fix in the population. We can talk a bit later about how long it's going to take to get there. We'll also discuss whether it somehow is very likely is going to kind of have to go through one or two mutations. But for now, if you'd like, we can say that this is even just mu sub b, the beneficial mutation rate per base pair, assuming that the 0's can only turn into 1s. the other of them. The probability of getting both mutations in one generation is going to be 10 to the minus 12. And then there's another question, which is, will 0, 1 actually fix in the population before you later fix this population? And actually, I think the answers to all these questions are in principal already on the board. And really, this is in some ways a very simple problem. But in another way, you have to keep track of lots of different things, and which regime we're in. a minute. But if you don't understand what's going on, it'll take you an hour. Yes? No? Maybe? Well, I'll give you another 20 seconds. Hopefully, you've been thinking about it while we've been talking. All right, do you need more time? Why don't we go ahead and vote? I think it's very likely that we will not be at the kind of 100% mark, in which case you'll have a chance to talk about it and think about it some more. a group of D's and a group of B's here, which means that everybody-- AUDIENCE: Let's fight. PROFESSOR: All right, so everybody thinks that everybody agrees with them, but you just need to look a little bit more long distance. So turn to a pseudo-neighbor. You should be able to find somebody there. It's roughly even here, so you should be can't find someone. So I don't see much in the way of vibrant discussion and argument. a group, so don't be too disappointed if you don't get finished there. But I do want to see kind of where we are. Ready? Three, two, one. OK, so it still is, maybe, split roughly equally between D and maybe a B-ish and some C's. All right, does somebody want to volunteer their explanation? Yes. And you're saying, all right, maybe because of the extra, that 1, 0 is somehow more fit than 0, 1. some relative rates or ratios for which reason? Audience: Well, I took 0.02 and then 0.1, which is 1/5. And then I decided that that should be around what it is, but slightly less, because there's also a chance that [INAUDIBLE]. PROFESSOR: OK, yes. I think the arguments there-- there's a lot of truth to the arguments that you're saying. Yeah, it's a little-- right. from 0, 0 to 0, 1. I first checked S, N and it's non-neutral. So probably [INAUDIBLE] S. So the probability for that first path would be the S for 0,1, so it's 0.02, which is 1/50, multiplied by the probability that the other 1, 0 would die out. And I think that's the calculation that you're describing, where you say, OK, well, in order for this individual to fix, he has to survive stochastic extinction. if we ask, we're going to start with an entire population at 0, 0, and now these mutations will be occurring randomly at some rate. And we're trying to figure out the relative probability that it's going to take kind of one path or another. Do you see the difference between these two questions? So indeed, this is the correct answer to a different question. And so it'sgoing to end up being D. And now we want to try to figureout how to get there. Because I think it is a bit tricky. all, we have to remember that we start out with everybody, all 1,000 individuals in the 0, 0 state. So there are initially no mutants in the population. But they're just replicating at some rate. And every now and then, mutation's going to occur. Now one thing we need to answer is whether these are nearly neutral mutations. Verbally yes or no? Ready? Three, two, one. AUDIENCE: No. PROFESSOR: No, right. But in both cases, S times N is much larger than 1. point is that the number needed to become established is equal to the population. If they both appear in the population, and they both survive stochastic extinction, then this mutant loses to this mutant. That's the clonal interference. So remember, this was comparing the two time scales. The time between successive establishment events, which went as 1 over mu N S. And the other time scale was 1 over Mu N S, which is 1 over 1,000 years, which was the time between establishment events. One is the time between the time to fix, which went as 1 over S log of NS, right? So we can ignore clonal interference if this is much larger than that. No clonal interfered corresponds to mu N log NS much less than 1. Is that right? Did I do it right? OK. So and once again, there are multiple S's, and it's easy to get kind of upset about this. But you can just use whichever S would be-- which S would you want to use to be kind of-- to the minus 6, 10 to the 3, and then this is the log of maybe 100, which is, like, 4 or 5. This is indeed much less than 1. So indeed, we don't have to worry about clonal interference. What it's saying is that the population is dividing. Every now and then, a mutation occurs in the population. It could be either the 0, 1 or the 1, 0. But in either case, the fate of that mutation is resolved before the next mutation occurs. of those two steps-- going to 0, 1 or 1, 0. And in particular, this is like a chemical reaction, where we have some chemical state here. And what we know is we know the ratio of those rates. And that's everything we need to know to calculate the relative probabilities of taking those states. So this is how we get 1/6 instead of 1/5. Because this thing is1/5 of that. So it's like 1, and then 1, 5. And this is actually, in principle, not quite answering the question that I asked. talking about the relative probability of the first state, the first mutant to fix. In principle, it is possible that from there, there's some rate of coming back. Or they might not necessarily move forward on up that hill. But in this case do we have to worry about going backwards? No. And why not? It's very unlikely. And in particular, you could think now that you're here you can talk about the rate of going to the 1, 1 state. And those are going to be exponentially different. So the probability of fixing it in the back direction is not 0, but it's exponentially suppressed. In practice, it doesn't actually matter, because this acts as a ratchet. Because all these mutations are non-neutral, once you fix this state or this one, you can't go back. So the population will move forward once it gets to one of those two states. Now I mean, it would be a very interesting question to ask if we instead did a different arrangement. What would the rate of evolution be, and so forth? Yeah, but what you're saying is certainly true, that if this took up all of the benefit going here, then it may not actually be somehow an optimal path. or something like that. I'll think about that when designing. Problems. In this system, 0, 0 eventually becomes 1, 1. So we are guaranteed that we will eventually evolve to this peak in the fitness landscape. And of course, there are non-zero probabilities of going backwards. It's just that they are reduced. Over long time scales, there's going to be an equilibrium that distribution over all. And actually, you can prove, for those of you who are interested in such things, that over long time Scale. these states, where the probability of being in a particular state will-- it goes as the fitness. It scales as the relative fitness to the Nth power. So we talk about these fitness landscapes as energy landscapes. And indeed, in this regime where you have small mutation rates, then it's going to be a detailed balance. And it's actually a thermodynamic system. So then in that case, you can make a correspondence between everything that we normally talk about, where fitness is like energy and population size is like temperature. cohered at this peak in the finished landscape. And so what we have is we have r is relative fitness 1 and 1.02. The rate of going forward, well, we sample mutations at a rate mu. And this is mu only, because we don't have to worry about going up the landscape. We just have the 0, 0 and the0, 1 states, just so we don’t have to worrying about going down the landscape, for example. So if you want to calculate a problem going from 0, 1 to0, 0, then [INAUDIBLE] that would just be-- I guess I'm not sure. for this one state, because pretend that we're not going to mutate this other one. So rate mu N, you have mutations appearing. And times this s, 0.02, is the probability that it'll actually fix in the forward direction. And now what we want to know is the rate of coming back. So which of these terms is going to be dominant? This thing gets up to be some really really really interesting stuff. And the probability of fixation is-- there was this thing X1, which was 1 minus-- now this is r. big number is our problem. So we should be able to figure this out, though. Because this new r is 1/1.02. OK, so there's less than a 1% probability of it fixing. Is this believable? AUDIENCE: It's about right. PROFESSOR: Yes, sorry, I was just saying this doesn't-- so this is why I'm saying you always check to make sure that your calculation makes any sense at all. So it's not this. But it's tiny, right? fixation of a neutral mutation. This is a deleterious mutation. It's not even nearly neutral. So it has to be much less than 1 over N, right? So this whole thing is 10 to the minus 10, or something like that? All right, any other questions about how to think about these sorts of evolutionary dynamics with presence of mutation, fixation, everything? Yeah. Can we handle a situation where [INAUDIBLE] interference is important at this point? PROFESSOR: Yeah, so this is what you do in your problem set with simulations. In the limit, as you get more and more mutations, when clonal interference is really significant, then you're pretty much just guaranteed to take the 1, 0 path. Once you have multiple mutations that have established, then it's likely that one of them is going to be this. And if it's established, it's going to win. But, like, with basic-- I guess I was thinking about it and you could probably imagine that [INAUDIBLE] calculate the probability that 1,0 doesn't arise first. rate, you don't even do successive fixations. So it may be that neither state ever actually fixes, because it could be that the 1, 0 state is growing exponentially, but is a minority of the population. And it has a lot of the same behaviors, in the sense of exponential suppression of probabilities as a function of the depth and the width of the valley you're trying to traverse. And there's some very nice papers, if you're interested in looking at this stuff. syllabus that I mentioned. I think the most important thing to stress when thinking about evolutionary game theory is just that this point that we don't need to assume anything about rationality. Instead, you simply have mutations that sample different strategies. And then you have differences in fitness that just lead to evolution towards the same solutions of the game. So it's evolution to the game solutions, so the Nash equilibrium, for example. And the more fit individuals spread in the population. And somehow, you evolve to the same or similar solutions. we have a 0, 0 state that has some fitness. 0, 1 has a higher fitness, and so forth. But in general, these fitness values may depend upon what the population composition is. And in that situation, then you want to use evolutionary game theory. For example, you can have situations where the population evolves to lower fitness. So it's just important. If the fitnesses depend on composition-- this is the population compositions-- then you cannot even define a fitness landscape. Just knowing the fitness of a pure population is not actually enough information to know that it's going to be selected for. It's still possible that in a mixed population, the genome 0 may actually have higher fitness than the genome 1.1. And once you kind of study these things, it's kind of clear that once you study them, you can't really tell what the fitness is of a population. The key is to look at the whole population, not just one or two, and try to find out what it's like to live in that population. it can happen. But then it's easy to then go back to the lab and forget that it's true. I think that the more formal evolutionary game theory thing-- these two-player games that you guys just read about-- I think they're important because they tell you what are the possible outcomes of measurements or of systems, even in the most simple situation where everything's linear. Now, when things are not linear, of course you can get even richer dynamics. But in this case, we'll see how this plays out. practice, you basically get the categories of outcomes that we saw there. So it's what you would get if you just had some two-player game like they study in game theory, but in a population of 1,000 or whatnot. You just made a bunch of random pairwise interactions. And then you had them do that again over time. And it's really importing the kind of approach, or the nomenclature, from conventional game theory and then immediately applying it to populations where you just assume that all the individuals have equal probability of interacting. The payouts that you read about in Chapter Four are kind of what would happen in that sort of situation, where everybody's interacting with everybody else with equal probability. Depending upon the strategy that these guys are following, you get different payouts. And this is telling us about the payout that the A individual gets depending on what he does, and depending upon what his opponent does. Now, we're not explicitly saying what the payout to the B individual is, but we're assuming that this is a symmetric game, so you could figure it out by looking at the opposite entry. a fitness, whereas B also gets little a fitness, because it's a symmetric game. So the case it's different is when we're in the diagonals. And from this framework, you can see that there are going to be already a bunch of kind of non-trivial things that can happen, even in this regime where everything's linear. And the probably best well-known of these is this Prisoner's Dilemma, which is the standard model of cooperation in the field of game theory. be in trouble, et cetera. So the idea of the prisoner's dilemma is that if you set up these jail sentences in the right way, then it could be the case that each individual has the incentive to confess. And you can come up with some reasonable payout structure that has that property. And we'll call this-- so this is for individual one, say and individual two. So there are different strategies you can follow. And do you guys remember from the reading slash my explanation how to read these charts? Professor: Nash equilibrium is to do strategy D that we're saying here. If both players had followed this strategy C for cooperate, D for defect, then both individuals would be getting fitness 3, or payout 3. But the problem is that that's not evolutionarily stable. So if you're in this state, what you have a choice of is to switch to the cooperate strategy, which would be D. The question is whether you as an individual would have the incentive to change strategy? And the answer is no. to go up here. So you have a choice to move up to this 0 payout, but that's not to your advantage. Now, it's true that your opponent would get payout 5. So that's saying that the strategy D is noninvadable. We can also think about what happens if we're a population of cooperators. Now everybody has high fitness-- fitness 3. Question is, What happens if there's a mutation that leads to one individual following the D strategy? Is he selected four or not? General, in terms of game theory, we like it when the mean of these two is smaller than this one. That's why you're asking, right? Exactly, because that's right. So yeah, so that's a slightly more complicated situation, because in that situation, then, if you had two rational agents, say, playing this game, then you could alternate cooperation and defection. And that would actually be the ultimate form of cooperation in such a game, because you could actually get a higher payout by alternating. cooperator and for the defector. For example, I'm going to draw a solid line for the cooperator, dashed line for a defector, do you understand? So what should these things look like? I'd like to encourage you to-- I'll give you 30 seconds to try to draw what this should look like. So this is the payout or the expected payout. So we're assuming that you're going to interact randomly with the other members of the population as a function of the fraction cooperator. Do you understand what I'm trying to ask you to do? are lines. But you can imagine that the only thing that's important are how these lines cross each other. So for example, there are only a few different things that can happen. You can have one strategy that dominates, which is what occurred here. And surprisingly, that does not mean that that strategy is higher fitness, in the sense that you may evolve to a state of low fitness. That's what's weird. So I'll give you another example of this. So now we're just going to have two strategies. The strategies-- we'll just call them A and B. And the question is, what is the Nash equilibrium? terms of these lines if we draw them? So this is payout as a function of the fraction that is playing the A strategy. Should the lines cross? Yes or no? Ready, three, two, one. AUDIENCE: Yes. PROFESSOR: Yes, and indeed, in principle, the math that we do in all these situations is kind of super simple. Yet it's easy to get confused about what's going on in all of these situations, says the professor. and then that leads to coexistence. Now, in some ways coexistence is the most subtle of the situations. And that's for an interesting reason. And maybe I shouldn't have covered this up, so you're not influenced, in case you actually did do the reading. Then I don't want to. But I'm saying that these things can cross in the other orientation. Let me put a matrix out there, and then-- so this is something that, for example, is what's known as a Hawk/Dove game. you to be influenced by this. So think about it for 30 seconds. Do you need more time? Let's go see where we are. Ready, three, two, one. All right, so most of the group is agreeing in this case, neither are the Nash equilibrium. Does that mean that this game has no Nash equilibrium? Yes or no, verbally-- ready, 3, 2, 1. AUDIENCE: No. PROFESSOR: No, it does not mean that. This game has a Nash equilibrium and indeed, all games like this have Nash equilibria. saying, otherwise we'd be in trouble, all of us. So what he proved is that such games, even with more players, more options, and so forth, they always have such a solution in this sense. There exists some strategy such as if everybody were playing in, nobody would have the incentive to change strategy. But you have to include so-called probabilistic or mixed strategies. And we can draw what this thing is. So just like always, so everyone else is following A, then A starts here at 3, and then it goes to 1. Whereas the B individuals start at 5, and they go to 0. In a population, if you have genetic A's and genetic B's that are each giving birth to their own type, then you evolve to some coexistence of genotypes. Whereas in this situation over here, we have coexistence. Does not matter where you start. So long as you have some members of both A and B in the population, you'll always evolve to the same equilibrium. Whereas the mixed Nash equilibrium is a situation where you have, in principle, genetic homogeneity. So this is a single genotype that is implementing phenotypic heterogeneity. In many cases, isogenic populations of microbes can exhibit a diversity of phenotypes as a result of stochastic gene expression and bi-stability. Another question is, what is the evolution explanation for why that behavior might have evolved? Now in general, we cannot prove why something evolved, but we can make educated guesses that make experimentally testable hypotheses. And for example, in the experiment that we've been doing, we're looking at bi-modality in expression of the galactose genes in yeast. you make the mutants that always turn on or always don't turn on these genes, then they're actually playing game where you get this exact thing. So that's saying that maybe the wild type that follows this stochastic, mixed strategy may be implementing the solution of some game. There are other possible explanations to this. In the coming weeks, we'll talk about this idea of bet hedging-- that given uncertain or fluctuating environments, it may be advantageous for clonal populations to have a variety of different strategies to cope with that uncertainty. Nash equilibrium mixed strategy plays A with probability-- so it's p should be equal to f a star. But the funny thing is, what that means is, it doesn't matter what you do at the equilibrium. What's interesting is that any individual in the population following any strategy has the same fitness. It's either coexistence of genotypes following different strategies, or it could be one genotype implementing both. It could be a mixture of those, actually. The heterogeneity there can be implemented either way. If your at the equilibrium, or if the population or the opponent is playing this Nash equilibrium in these games, then it just does not matter what you do. You can do A, actually, in any fraction. So since A and B have the same fitness, you can choose between them at any frequency you want. And indeed, in this there are nice conditions for what makes it this Nash equilibration. And I'm going to just highlight that you should make sense of why it means what it is. equal to this guy. So that's what I just said-- that it doesn't matter what you do. If everyone else is doing p star, you have the same fitness. That's saying it's a Nash equilibrium. Whereas there's another interesting kind of statement here, that you can't unilaterally increase your fitness by switching. That you don't have the incentive to change strategy. It's true that you're not dis-incentivized. So it's not a strict Nash equilibrium, but it's an equality. not the definition of that. But this thing is true, which means that it's a Nash equilibrium. And if you have questions about this, I'm happy to answer it. It's explained in the book as well. We are out of time, so I should let you go. But good luck on the exam next Thursday. If you have Questions and you want to meet with me, I am available on Tuesday. So please let me know. I'll be happy to talk to you.