{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-23T12:55:12.112332Z",
     "iopub.status.busy": "2024-11-23T12:55:12.112049Z",
     "iopub.status.idle": "2024-11-23T12:55:20.790954Z",
     "shell.execute_reply": "2024-11-23T12:55:20.790073Z",
     "shell.execute_reply.started": "2024-11-23T12:55:12.112306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transforms in /opt/conda/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.3)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.15.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install transforms datasets torch wandb huggingface_hub peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:55:39.431526Z",
     "iopub.status.busy": "2024-11-23T12:55:39.431039Z",
     "iopub.status.idle": "2024-11-23T12:55:39.437649Z",
     "shell.execute_reply": "2024-11-23T12:55:39.436789Z",
     "shell.execute_reply.started": "2024-11-23T12:55:39.431483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, \n",
    "    Trainer, TrainingArguments, DataCollatorForSeq2Seq, \n",
    "    Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import huggingface_hub\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from bitsandbytes.optim import PagedAdamW8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:55:39.438965Z",
     "iopub.status.busy": "2024-11-23T12:55:39.438730Z",
     "iopub.status.idle": "2024-11-23T12:55:39.450775Z",
     "shell.execute_reply": "2024-11-23T12:55:39.449871Z",
     "shell.execute_reply.started": "2024-11-23T12:55:39.438942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"hugginface_token\": \"\",\n",
    "  \"wandb_key\": \"\",\n",
    "  \"model_path\": \"meta-llama/Llama-3.2-1B\", #  google/gemma-2-2b-it\n",
    "  \"save_model_name\": \"pretrain_open_source\",\n",
    "  # \"use_lora\": True,\n",
    "  # \"lora_r\": 16,\n",
    "  # \"lora_alpha\": 32,\n",
    "  \"lr\": 3e-5,\n",
    "  \"epoch\": 1,\n",
    "  \"batch_size\": 1,\n",
    "  \"max_seq_len\": 512, # max token seq, change with gpu memory\n",
    "  \"checkpoint_path\": \"./checkpoints\",\n",
    "  \"OpenSource_data_path\": \"FiscalNote/billsum\", #  ccdv/govreport-summarization \n",
    "  \"OpenSource_version\": \"\",\n",
    "  \"Youtube_data_path\": \"ht324/WhiteBoard_LLM_Data_response\" # \"ht324/WhiteBoard_LLM_Data_response\"\n",
    "}\n",
    "\n",
    "hugginface_token = config[\"hugginface_token\"]\n",
    "wandb_key = config[\"wandb_key\"]\n",
    "\n",
    "model_path = config[\"model_path\"]\n",
    "save_model_name = config[\"save_model_name\"]\n",
    "\n",
    "# use_lora = config[\"use_lora\"]\n",
    "# lora_r = config[\"lora_r\"]\n",
    "# lora_alpha = config[\"lora_alpha\"]\n",
    "\n",
    "lr = config[\"lr\"]\n",
    "epoch = config[\"epoch\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "max_seq_len = config[\"max_seq_len\"]\n",
    "\n",
    "# checkpoint_path = config[\"checkpoint_path\"]\n",
    "OpenSource_data_path = config[\"OpenSource_data_path\"]\n",
    "OpenSource_version = config[\"OpenSource_version\"]\n",
    "Youtube_data_path = config[\"Youtube_data_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:55:39.452007Z",
     "iopub.status.busy": "2024-11-23T12:55:39.451770Z",
     "iopub.status.idle": "2024-11-23T12:55:41.969081Z",
     "shell.execute_reply": "2024-11-23T12:55:41.968320Z",
     "shell.execute_reply.started": "2024-11-23T12:55:39.451983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:oxixl2ht) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda157c4f7a34a398ee94ce8316f3eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pretrain_open_source</strong> at: <a href='https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM/runs/oxixl2ht' target=\"_blank\">https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM/runs/oxixl2ht</a><br/> View project at: <a href='https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM' target=\"_blank\">https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241123_125528-oxixl2ht/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:oxixl2ht). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241123_125539-zqypda2t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM/runs/zqypda2t' target=\"_blank\">pretrain_open_source</a></strong> to <a href='https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM' target=\"_blank\">https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM/runs/zqypda2t' target=\"_blank\">https://wandb.ai/namul2wnb-sungkyunkwan-university/WhiteBoard_LLM/runs/zqypda2t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# login to huggingface and wandb\n",
    "\n",
    "huggingface_hub.login(token=hugginface_token)\n",
    "if wandb_key:\n",
    "    wandb.login(key=wandb_key)\n",
    "    wandb.init(\n",
    "        project=\"WhiteBoard_LLM\",\n",
    "        config={\n",
    "            \"model_name\": save_model_name,\n",
    "            \"lr\": lr,\n",
    "            \"epoch\": epoch,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"max_seq_len\": max_seq_len,\n",
    "            # \"use_lora\": use_lora,\n",
    "            # \"lora_r\": lora_r,\n",
    "            # \"lora_alpha\": lora_alpha,\n",
    "        },\n",
    "        name=save_model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:55:41.970314Z",
     "iopub.status.busy": "2024-11-23T12:55:41.970066Z",
     "iopub.status.idle": "2024-11-23T12:55:50.437996Z",
     "shell.execute_reply": "2024-11-23T12:55:50.436932Z",
     "shell.execute_reply.started": "2024-11-23T12:55:41.970290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# for llama tokenzier\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:55:50.443062Z",
     "iopub.status.busy": "2024-11-23T12:55:50.442748Z",
     "iopub.status.idle": "2024-11-23T12:55:53.286153Z",
     "shell.execute_reply": "2024-11-23T12:55:53.285224Z",
     "shell.execute_reply.started": "2024-11-23T12:55:50.443034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load data opensource dataset have to check column name\n",
    "if OpenSource_data_path:\n",
    "    if OpenSource_version:\n",
    "        open_source_data = load_dataset(OpenSource_data_path, OpenSource_version)\n",
    "    else:\n",
    "        open_source_data = load_dataset(OpenSource_data_path)\n",
    "\n",
    "if Youtube_data_path:\n",
    "    youtube_data = load_dataset(Youtube_data_path)\n",
    "    youtube_data[\"train\"] = youtube_data[\"train\"].rename_column('content','text')\n",
    "    youtube_data[\"train\"] = youtube_data[\"train\"].rename_column('response','summary')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:55:53.287589Z",
     "iopub.status.busy": "2024-11-23T12:55:53.287302Z",
     "iopub.status.idle": "2024-11-23T12:55:53.293738Z",
     "shell.execute_reply": "2024-11-23T12:55:53.292840Z",
     "shell.execute_reply.started": "2024-11-23T12:55:53.287562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    # 입력 텍스트 토큰화\n",
    "    inputs = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        max_length=max_seq_len,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"  # 모든 시퀀스를 max_length로 맞춤\n",
    "    )\n",
    "    # 출력 텍스트 토큰화\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"summary\"],\n",
    "            max_length=max_seq_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "    # 모델 입력 데이터 반환\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "def fix_dataset_format(example):\n",
    "    example[\"text\"] = \" \".join(example[\"text\"]) if isinstance(example[\"text\"], list) else example[\"text\"]\n",
    "    example[\"summary\"] = \" \".join(example[\"summary\"]) if isinstance(example[\"summary\"], list) else example[\"summary\"]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:55:53.295089Z",
     "iopub.status.busy": "2024-11-23T12:55:53.294805Z",
     "iopub.status.idle": "2024-11-23T12:55:53.306542Z",
     "shell.execute_reply": "2024-11-23T12:55:53.305728Z",
     "shell.execute_reply.started": "2024-11-23T12:55:53.295064Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['custom_id', 'role', 'text', 'summary'],\n",
       "        num_rows: 4840\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open_source_data\n",
    "youtube_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:56:12.380299Z",
     "iopub.status.busy": "2024-11-23T12:56:12.379933Z",
     "iopub.status.idle": "2024-11-23T12:56:15.357096Z",
     "shell.execute_reply": "2024-11-23T12:56:15.356322Z",
     "shell.execute_reply.started": "2024-11-23T12:56:12.380266Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff46a20537674d26a4cd7d54ee7d15b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbd97b719754872be85696199e44f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'summary'],\n",
       "    num_rows: 4840\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = youtube_data[\"train\"]\n",
    "# train_data = open_source_data[\"train\"]\n",
    "# test_data = open_source_data[\"test\"]\n",
    "\n",
    "train_data = train_data.map(fix_dataset_format)\n",
    "# test_data = test_data.map(fix_dataset_format)\n",
    "\n",
    "# remove useless columns\n",
    "train_data = train_data.map(\n",
    "    lambda example: {\"text\": example[\"text\"], \"summary\": example[\"summary\"]},\n",
    "    remove_columns=train_data.column_names,\n",
    ")\n",
    "\n",
    "\n",
    "# test_data = test_data.map(\n",
    "#     lambda example: {\"text\": example[\"text\"], \"summary\": example[\"summary\"]},\n",
    "#     remove_columns=train_data.column_names,\n",
    "# )\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_data.map(preprocess_function, batched=True)\n",
    "# tokenized_test_dataset = test_data.map(preprocess_function, batched=True)\n",
    "\n",
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns(train_data.column_names)\n",
    "# tokenized_test_dataset = tokenized_test_dataset.remove_columns(test_data.column_names)\n",
    "\n",
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    # eval_strategy=\"steps\",\n",
    "    eval_strategy=\"no\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    logging_steps=20,\n",
    "    save_total_limit=2,\n",
    "    per_device_train_batch_size=batch_size, # change with gpu \n",
    "    per_device_eval_batch_size=batch_size,  # change with gpu\n",
    "    gradient_accumulation_steps=8,          # change with gpu\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    num_train_epochs=epoch,\n",
    "    learning_rate=lr,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"wandb\",\n",
    "    fp16=True, # mixed precision training\n",
    "    hub_model_id=\"ht324/WhiteBoard_LLM_Models\"\n",
    "    push_to_hub=True, # huggingface hub model upload\n",
    "    run_name=\"pretrain with opensource\",\n",
    "    remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    # eval_dataset=tokenized_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # peft_config=lora_config,               \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동 huggingface hub 업로드\n",
    "# trainer.push_to_hub(repo_id=\"ht324/WhiteBoard_LLM_Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "# save_dir = f\"./checkpoints/{save_model_name}\"\n",
    "# model.save_pretrained(save_dir)\n",
    "# tokenizer.save_pretrained(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
