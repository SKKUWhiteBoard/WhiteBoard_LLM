then we are going to continue with the second part of the lecture today which focuses on the problem what actually happens if the gaussian assumption that i have about my constraints doesn't hold. One of the questions actually how to handle that so as we said what we are doing here we are minimizing the sum of the squared errors terms and as we have seen so far this is the same or strongly related depending on how you formulate that. If we would have the possibility to integrate a multi-modal distribution here that would actually be a nice beneficiary. If you have structures in the environment and there's a lot of clutter in the scene the clutter even if it has a repetitive pattern may lead to a multimodal belief about what the relative transformation between two poses let's say. Other things is gps can even be problematic if you have this called gps multi-pass problems you have reflections of the gps signal based on larger buildings. You may get beliefs or you may get outlier measurements and the question is how can we actually take that into account. have also experienced and if you look to those poses over here in the poses down here how those individual structures match um if you just apply let's say scan alignment you may say this may match so maybe someone has opened the door which was closed before or here is a door now closed which was open all the other scans map actually quite well the same holds here. Even as a humanism you say okay there is definitely a misalignment between the skin so they don't fit perfectly but that's something which actually can result from small changes in the environment. The original number of constraints i don't know how large it was but i think it's around three thousand something like this along those lines. If you put already ten wrong ones in there it's quite likely to screw up it was one hundred which is still a very small number compared to 3000 or just a small fraction. It will actually end up in dramatic mapping errors so the system is unusable so having good data cessations is really important so already screwing up a small number of places is something which can hurt your optimization. the first attempt to to solve this problem this would be our probability distribution what is the problem with this probability distribution so i say okay some of my constraints are these multiple multimodal constraints i will simply go ahead and implement that. What's the problem that you're going to experience if you make this is some so this is we know how to solve that right this is what you know howto solve that that's what we did so far so the thing is we have a waiting term down here so we make sure that it sums up to one so we assume we have normalized this. robot and the ground is muddy the wheels may slip before you get grip and the and the robot starts starts driving if this is the case although you're executing command you're standing and then you start moving so you may get this kind of distribution. In most cases actually the vehicle executes what you tell the vehicle to do but in some cases simply doesn't move. This max mixture idea is actually a pretty easy idea pretty simple idea just reply funny no one has done that in robotics until recently a few years ago. that's actually a nice thing so um another thing is it can handle both things at the same time data station errors as well as multimodal constraints. So the combination of outlier rejection and dealing with wrong data associations is actually kind of nice we also can do this obviously in 3d so this is again this data set with the sphere that we have seen before robot moving in a virtual sphere with constraints. This is gauss newton and this is the max mixture gaussnewton and um so you can see here there's a non-perfect alignment in here because you don't see the regular structure. if he increases to 100 outliers this is just whatever a big mess whereas this one still is able to solve those things quite nicely. The key idea the intuition behind that is if i have a constraint which has a large error so where the current configuration is far away from what the constraint tells me just reduce the uncertainty that is associated to that so decrease um the the information matrix so scale down the information Matrix so they can just a small change by saying the question is still how do we actually compute these so the main changes we go to this formulation. and flatter and flatter gaussian distribution the further the point is actually away there's also one technique which you can find which is also quite easy to implement because you just need to compute the scaling factor and multiply that with your information matrix for every constraint also something you can do quite efficiently. If you have constraint which introduce large errors these are these outliers this can actually screw up the optimization when computing the minimal error configuration. There are different ways of uh kind of row function that we can actually in there and then we're then trying to minimize. setup to another sensor setup can be quite tricky on but the back end itself which sits here doesn't really change that much therefore the focus in this course which was much more on the backEnd. At least i would tell you a little bit about what typical front desk exists and how you could realize a front end if you want to build a slam system. Well that's something we are going to do next week that's it from my side thank you very much and hope to see all of you next week.