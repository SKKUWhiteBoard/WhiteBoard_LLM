PhilipPE RIGOLLET: I want to have a small bias, hopefully a 0 bias. If this thing is 0, then we see that the estimator is unbiased. So am I planning-- yeah. So if I do, for example, X1, Xn, there are iid Bernoulli. And I'm going to write it theta so that we keep the same notation. Then theta hat is the average of Xi's. So what is the bias of this guy? Well, to know the bias, I just have to remove theta from the expectation. that we are going to be looking for in an estimator, trying to find them to be unbiased. But we'll see that it's actually maybe not enough. So unbiasedness should not be something you lose your sleep over. Something that's slightly better is the risk, really the quadratics risk, which is expectation of theta. And so for example, if the quadratic risk goes to 0, then that means that theta hat converges to theta in the L2 sense. for sum of independent random variables, now it's time to wake up. So we have the variance of something that looks like 1 over n, the sum from i equal 1 to n of Xi. So it's of the form variance of a constant times a random variable. We would like somehow to say that this is the sum of the variances. And in general, we are not allowed to say this, but we are because my Xi's are actually independent. And that's by independence, so this is basic probability. Rigollet: When you have an unbiased estimator, it's simple. It's just telling you it's the variance, because the theta that you have over there is really-- so in the definition so there's this weird notation. You want 1 minus alpha to be very close to 1, because it's really telling you that whatever random variable I'm giving you, my error bars are actually covering the right theta. And I want this to hold true for all possible values of the parameters that nature may have come up with. a vector of parameters, a multivariate parameter, the bias increases when you're trying to pull more information across the different components to actually have a lower variance. So the more you average, the lower the variance. As n increases, the variance decreases, like 1 over n or theta, 1 minus theta over n. And so this is how it happens in general. In this class, it's mostly one-dimensional parameter estimation, so it's going to be a little harder to illustrate that. what a confidence interval is. And so we fixed a statistical model for n observations, X1 to Xn. The parameter theta here is one-dimensional. Theta is a subset of the real line, and that's why I talk about intervals. An interval is just a one- dimensional conference region. And it has to be an interval as well. A confidence interval of level 1 minus alpha is actually called it's level. The closer to 1 it is, the better the confidence interval. One of the properties that we wanted. Strongly consistent means that as n goes to infinity, it converges almost surely to the true parameter. It is consistent also, because it's strongly consistent, so it also converges in probability, which makes it consistent. We've actually computed its quadratic risk. And now what I have is that if I look at-- thanks to the central limit theorem, we actually did this. We built a confidence interval at level 1 minus alpha. two ways of getting rid of this. Since we only need this thing-- so this thing, as we said, is really equal. Every time I'm going to make this guy smaller and this guy larger, I'm only going to increase the probability. And so what we do is we actually just take the largest possible value for p1 minus p, which makes the interval as large as possible. And by Slutsky, we know that this is actually converging not Slutky, right? as much from your data as you can. So it depends on how comfortable and how critical it is for you to put valid error bars. If they're valid in the asymptotics, then maybe you're actually going to go with Slutsky so it actually gives you slightly narrower confidence intervals. Now, if you really need to be super-conservative, then you'reactually going to going with the P1 minus P. So that's what the function here-- the function you're interested in is 1 over square root of X1 minus X. Its derivative really is what matters. The goal is to estimate a true theta star, the one that generated some data, X1 to Xn, in an iid fashion. If I tell you the KL divergence is 0.01, it's not clear what it means. The goal of knowing theta stars is so that you can actually know what P theta. Otherwise, it has-- well, sometimes we said it has some meaning itself, but really you want to know what the distribution is. The proof is just one step Jensen's inequality, which we will not go into details. When you compute probabilities on one distribution, you should have the same probability on the other distribution pretty much. So what we can do is say, well, now I have two candidate distributions. And so that means that we have this actual total variation distance between probability distributions. But here, I still cannot compute it, because I have this P theta star that shows up. And if you've heard of KL, you've probably heard of entropy. And that's a quantity that just depends on theta. are you to compute this maximum over all possible events? I mean, it's just crazy, right? There's an infinite number of them. And so there's actually a way to compress it by just looking at the basically function distance or vector distance between probability mass functions or probability density functions. So throughout this chapter, I will make the difference between discrete random variables and continuous random variables. It really doesn't matter. All it means is that when I talk about discrete,. I will talk about probability mass function. And when I talks about continuous, I'll talk about probabilities density. But they're all the same thing. to some event A. The probability of X falling to some subset of the real line A is simply the integral of the density on this set. Since for each possible value, the probability at X-- so I hope you remember that stuff. But essentially, we know that the probability that X is equal to little x is 0 for a continuous random variable. There's just none of them that actually gets weight. So what we have to do is to describe the fact that it's in some little region. 1/2 really doesn't matter. It's just if I want to have an actual correspondence between the maximum and the other guy, I have to do this. So this is what it looks like. And so we have a couple of properties that come into this. The first one is that it's symmetric. TV of P theta and P thea prime is the same as the TV between P thena prime and PThena. I just flip those two, I get the same number. Those things are completely symmetric in theta. You can just flip them. The total variation equal to 0 implies that P theta is equal to P theTA prime. If this thing being small implied that P. theta could be all over the place, that would not help very much. The problem is that this will still not satisfy the triangle inequality. But the divergence is doing a pretty good thing for us. And this is what will allow us to estimate it and basically overcome what we could not do with the total variation. The fact that you need two definitions of the [INAUDIBLE],, is it something obvious or is it complete? I'll do it for you now. Philip Pirollet: The integral of f is equal to 1 and the integral of g isequal to 1. Pirollett: If I take any other A in this integral than this guy A star, it's actually got to decrease its value. Piollet: This A star is the one that actually maximizes the integral over the set of X's such that delta of X is non-negative. It's actually exactly the same area above and below that's actually equal to 0. RIGOLLET: It is. Just look at this board. So this is definitely at most the maximum over A of Pf of A minus Pg of A. Right? We agree with this? Because this is just for one specific A, and I'm bounding it by themaximum over all possible A. So that's clearly true. So now I have to show you that the max is actually this guy, A star. So why would that be true? Well, let's just inspect this. when I take A to be the set where it's positive. Just need to make sure that there is someplace where it is, but that's about it. So it's a distance. It's symmetric, non-negative, equal to 0, if and only if the two arguments are equal, then it satisfies the triangle compared to the convex function of the expectation of a random variable. If it's not satisfying this thing, it's called pseudo-distance or quasi- distance or just metric or nothing at all. estimator is. And I'm going to try to minimize this estimator now. And if the two things are close, then the minima should be close. That's a pretty good estimation strategy. The problem is that it's very unclear how you would build this. estimator of TV, of the Total Variation. But for this guy, we will be able to build an estimate for it, because it's actually going to be of the form expectation of something. And this constant, I don't know. It depends on P theta star. it is. And that's now where the log plays a role. If you actually pay attention, I said you can use Jensen to prove all this stuff. You could actually replace the log by any concave function. That would be f divergent. That's called an f divergence. But the log itself is a very, very specific property, which allows us to say that the log of the ratio is the ratio of the log. If I change theta, this thing is never going to change. It depends only on theta. this constant is 0 for my purposes, or 25 if you prefer. All right. So we'll just keep going on this property next time. And we'll see how from here we can move on to-- the likelihood is actually going to come out of this formula. Thanks. Back to Mail Online home. back to the page you came from. Back from the page where you came From. Click here to go to the show page where we'll be talking about the probability of winning the lottery.