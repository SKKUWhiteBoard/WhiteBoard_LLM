In the second half, we'll talk about multisequence alignment. This is a generalization of the two-dimensional array that we had before. Let's go beyond triple, but to a very simple dinucleotide alignment. And we will say that this is the optimal multiple alignment. We want to generalize the kind of algorithms we've been using. And again, this is again, the MIT OpenCourseWare team's work. We hope to see you in the next half of the course. will be a recursive algorithm where the score of a two-character string is defined in terms of the maximum of various shorter strings. The number of different cases we have here-- before, it was 3 for a global alignment, which was k, being the number of sequences, was 2. Now k is3 for a three-way comparison. And all possible subsets is 2 to the k minus 1, in this case, so it's 7. You can see the first one is no insertions or deletions. The next three are two insertion or deletion in the three different ways that can happen. The time complexity is have to do 2 to the k comparisons per node. The larger k is, the more you can explore. If you know where the band should start and how wide it should be, you can essentially prune off many of the nodes without really losing any optimality. There are very good reasons for inferring structure or function without experiments, just from sequence. And the two that we'll illustrate are not guaranteed to be optimal, but on the other hand, they don't necessarily require arbitrary pruning. in the next couple of slides is a tree alignment, as illustrated by ClustalW. By the way, pruning is illustrated by a program called MSA, which is short for multisequence alignment. And we'll show a star alignment. Later on into the transcriptome part of the course, we will talk about the Gibbs algorithm. So let's walk through ClustAlW, and then a star algorithm. Here's progressive multiple alignment. So here, we have five sequences instead of four, but it's the same thing. You do all pairwise similarities. And so you can construct a tree. give a score. These scores are the scores that would have come out at the end of that traceback in the pairwise alignments. And so we'll use S1 as the focus of the star geometry. And we'll get to the Gibbs sampling later. But in general when you have a hard problem, where you can't comprehensively go through the entire space, what you do is sample it. You say, let's try a few things, and try to randomly sample it, and maybe even develop locally. by having this storing, this pairwise or multi sequence in a matrix-- so that's actually you've done a trade-off where you've taken up computer memory in order to save time. If you're willing to sacrifice a little accuracy or a little comprehensiveness, then you can save even more time or memory. Now we want to use motifs, which is the sort of thing that you get out of local alignments, to find genes. And we're going to use the motifs and the finding genes as a way of introducing a particular motif. cell type and the rare [INAUDIBLE],, rare messenger RNA within a cell type. GEORGE CHURCH: Let's talk about the sizes of proteins. How is it that it precipitously drops off at 100 amino acids? Why are there so few proteins that are short? And there are slightly more short proteins in Mycoplasma? Any guesses why they're so few? Why does it drop off at 10,000 of amino acids for the largest proteins? When we get to proteomics, we'll talk about ways that you can empirically, by mass spectrometry and so forth, find those small proteins. The 23 sRNA encodes this pentapeptide, which confers erythromycin resistance at low levels in wild type. It is not a mutant kind of peptide. It's the normal pentapepticide. This has to be sensing the translation process itself, asking whether the transfer RNAs are charged up with amino acids enough that you're getting efficient translation. If you want to know whether you need to make tryptophan, phenylalanine, or histidine, you ask whether there's enough of it around to do translation. you're not, then you'll pause here. That ribosome will hesitate, waiting for the right transfer RNA. And as it hesitates, this RNA changes. It's folding. And a series of events results in-- if it's hesitating, then it wants to make the biosynthetic genes downstream to make more of the amino acids. So the tRNA has to be charged up. So you get this nice, little feedback loop that the hesitation causes a change in RNA, which causes change of transcription. be A, C, G, or T. These are four different sequences, real start sites, that we've aligned, either manually or by computer. This is dead easy to do the alignment, but the interpretation here is the position upstream of the start codon doesn't matter. And so this is the weight matrix or position-sensitive substitution matrix. But it's not the most precise way of representing this. It's position sensitive, but we've lost the higher order correlations between positions. And you can find these motifs that have great biological significance. Bayes' theorem says that the probability that the model given the sequence is equal to the probability of the sequence given the model. We're going to be doing-- of the various applications, we had recognition discrimination and database search. And we're talking about a particular sequence, where we can have randomness at the mononucleotide level rather than the level of the Markov chain. And I want to give you some biological rationale for why you can have nonrandomness at every order of a chain. Gs with them. Many organisms repair-- well a T near a T in the presence of ultraviolet light will get mutated to something else. And so you'll lose that particular dinucleotide out of the 16 possible dinucleotides. Every place you've got a methyl CG turns into a TG, and you tend to lose the CGs, unless they're not methylated. And similarly, you can have rare codons. And hence, these turn into rare triplets. And we'll get to that. The triplet bias, documented here that this 10 times lower frequency of ATG than of some of the other arginine codons. We've said that CGs are underrepresented in the genome as a whole, and they're over-represented in promoters. This particular transition of what's the probability of getting a G given a C in the 5-prime position-- this is one of those conditional probabilities. This is a Bayesian that we had set up a couple of slides back. And so this particular arrow going from a C to a G is represented by this probability. There's 16 possible transitions, including four homopolymers, AA, TT, CC, GG, and 12 transitions of the other dinucleotides. We've got CG islands where the CGs have been protected from methylation, and hence, protected from mutations. And then outside are the ocean, which are not protected. And you want to know where the island begins and ends because that helps you know where regulatory factors are. And so this Markov model that you have has to be different for whether you're in an island or not.