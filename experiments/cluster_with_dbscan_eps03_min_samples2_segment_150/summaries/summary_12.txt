to your friends is that you just blab of something, and I understand what you're saying, and, um, what goes on beyond that, is sort of not really accessible to consciousness. But well, to be able to have machines that interpret language correctly, we sort of need to understand the structure of these sentences. Unless we know what words are arguments and modifiers of other words, we can't actually work out what sentences mean. And I'll show some examples of that as to how things go wrong immediately, because a lot of the time there are different possible interpretations you can have. The idea of tree banks is to get human beings to sit around and put grammatical structures over sentences. People started thinking about grammars of languages even in modern times in the fifties, and people started building parses for languages in the 19, early 1960s. So, there was decades of work in the 60s, 70s, 80s, and no one had tree banks. Of course, you can get in touch if you want to talk about tree banks with me. Final issue is whether we want to allow dependencies to cross or not. Most of the time, um, dependencies don't cross each other. But sometimes they do, and this example here is actually an instance for that. So, we actually have another dependency here that crosses that dependency. And that's sort of rare, that doesn't happen a ton in English, but it happens sometimes in some structures like that. You could've said, I'll give a talk on bootstrapping tomorrow, and then a [inaudible] have a projective parse, but if you want to, you can kind of delay that extra modifier. And then the parse becomes non-projective. Parsing the sentence "I ate fish" involves three actions. The first is to shift things onto the stack or to do the equivalent of a Reduce where I build dependencies. The second is to treat the second from top thing on the stack as a dependent of the thing that's on top of the stack. The third is to leave the head on the Stack ate, but I sort of add this dependencies as other dependencies I've built. The finished condition of successfully parsing the sentence is my buffer is empty and I just have root left on my stack. The conventional way to do this is to say well, we want to have features. And well, the kind of features you wanted was so the usually some kind of conjunction or multiple things. And the problems with that, was these features were very sparse. Each of these features matches very few things. Um, they match some configurations but not others so the features tend to be incomplete. And that's not very good if you want to parse the whole web, whereas if you have something that's linear time, that's really getting you places. like this. And so these are the correct arcs and to evaluate our dependency parser, we're simply gonna say, uh, which arcs are correct. So here in my example, my dependency paths, I've got most of the arcs right but it got this one wrong. So I say my unlabeled attachment score is 80 percent or we can also look at the labels and then my parser wasn't very good at getting the labels rights, so I'm only getting 40 percent. And that's in our accuracy. even though at the end of the day, it was sort of looking at weights that went into a support vector machine. So that was kind of cool. And so the secret was we're gonna make use of distributed representations like we've already seen for words. So for each word, we're going to represent it as a word embedding. And in particular, um, we are gonna use word vectors and use them as the represent- the starting representations of words in our Parser. But well, if we're interested in distributed representations, it seem to us like maybe you should only have distributed representation of words. "We trained up our parser, um, and it was then able to predict the sentences" "This work has kind of, you know, deep learning people like to optimize" "It led to ah sort of a new era of sort of better parsers" "We're getting close to 95 percent unlabeled accuracy score from these models" "These models are sort of getting a bit higher again. But, youknow, so this work has continued along in the intervening two years" neural transition based dependency parsers. We sort of have gone down that we've halve that error-error rate. And we're now down to sort of about a five percent error rate. Yeah. I'm basically out of time now but there is further work including, you know, at Stanford. It's more accurate than 95 percent, right? So we- we're still going on but I think I'd better stop here today, um, and that's neural dependency parsing. [NOISE]. This week in week three, we're actually going to have some human language, and so this lecture has no partial derivative signs in it. In assignment three, what you're doing is building a neural dependency parser. And so we hope that you can put together what you learned about neural networks last week and the content of today, and jump straight right in to building the neural dependency parsers. And since I missed my office hours yesterday, I'm gonna have a shortened office hour tomorrow from 1:00 to 2:20.