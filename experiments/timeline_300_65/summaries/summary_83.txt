Lecture eight is about deep learning software. This is a super exciting topic because it changes a lot every year. As usual, a couple administrative notes before we dive into the material. Project proposals for your course projects were due on Tuesday. Another reminder is that assignment two has been out for a while. That's going to be due next week, a week from today, Thursday. And again, when working on assignment two, remember to stop your Google Cloud instances when you're not working to try to preserve your credits. The midterm will be in class on Tuesday, five nine. It'll be sort of pen and paper working through different kinds of, slightly more theoretical questions to check your understanding of the material that we've covered so far. Last time we talked about fancier optimization algorithms for deep learning models including SGD Momentum, Nesterov, RMSProp and Adam. And we saw that these relatively small tweaks on top of vanilla SGD, are relatively easy to implement but can make your networks converge a bit faster. We also talked about regularization, especially dropout. Deep learning uses GPUs, but we weren't really too explicit up to this point about what exactly these things are and why one might be better than another for different tasks. Today we're going to shift gears a little bit and talk about some of the nuts and bolts about writing software and how the hardware works. And we'll talk about several of the major deep learning frameworks that are out there in use these days. We'll also talk about what the software looks like that you actually use to train these things in practice. how it works and what are the basic ideas even if you're not writing it yourself. So if you want to look at kind of CPU GPU performance in practice, I did some benchmarks last summer comparing a decent Intel CPU against a bunch of different GPUs that were sort of near top of the line at that time. For things like VGG 16 and 19, ResNets, various ResNet, then you typically see something like a 65 to 75 times speed up when running the exact same computation on a top-of-the-line GPU. overview of these things. So, remember that in the last several lectures we've hammered this idea of computational graphs in sort of over and over. That whenever you're doing deep learning, you want to think about building some computational graph that computes whatever function. Remember that these graph structures can get pretty complex in the case of a big neural net, now there's many different layers, many different activations. Many different weights spread all around in a pretty complex graph. And as you move to things like neural turing machines then you can get these really crazy computational graphs that you can't even really draw because they're so big and messy. TensorFlow and PyTorch let you write code in the forward pass that looks very similar to Numpy, but lets you run it on the GPU and lets you automatically compute gradients. The other nice thing about TensorFlow is you can really just, like with one line you can switch all this computation between CPU and GPU. And then again, you can just usePyTorch to compute gradient, all your gradients, with just one line. So if you just look at these three examples, these three code snippets, the Numpy side, the Tensor Flow side, and the Pytorch side, all of these kind of just kind of dive in and talk a little bit about what's going on. TensorFlow gives you a bunch of convenience functions that compute these common neural network things for you. So in this case we can use. tf.losses.mean_squared_error and it just does the L2 loss for us so we don't have to compute it ourself in. terms of basic tensor operations. Once you get to like convolutions and batch normalizations and other types of layers this kind of basic way of working could be a little bit unwieldy. TensorFlow is an open-sourceensorFlow framework. It's used by Google to train neural networks. The code example shows how to use TensorFlow to train a neural network. It uses the xavier initializer object to set up an initialization strategy for the data and labels. It also sets up variables for those with the right shapes that are kind of inside the graph but a little bit hidden from us. And in fact if you run this code, it converges much faster than the previous one because the initialization is better. There's like a lot of different higher level libraries that people build on top of TensorFlow. When we're working with neural networks we have this concept of layers and weights and some layers have weights associated with them, and we typically think at a slightly higher level of abstraction than this raw computational graph. So that's what these various packages are trying to help you out and let you work at this higher layer of abstraction. Another very popular package that you may have seen before is Keras. There's another framework also from Google, but not shipping with Tensor Flow called Pretty Tensor that does the same sort of thing. different where we're actually building up this new computational graph, this new fresh thing on every forward pass. That's called a dynamic computational graph. For kind of simple cases, with kind of feed forward neural networks, it doesn't really make a huge difference, the code ends up kind of similarly. But I do want to talk a bit about some of the implications of static versus dynamic. And what are the tradeoffs of those two? So one kind of nice idea with static graphs is that because we're kind of building up one computational graph once, and then reusing it many times, the framework might have the opportunity to go in and do optimizations on that graph. In PyTorch because we're using dynamic graphs, it's super simple. Your code kind of looks exactly like you would expect, exactly what you would do in Numpy. Now in TensorFlow the situations is a little bit more complicated because we build the graph once. So that means that any kind of control flow operators that you want to have need to be not Python controlFlow operators, you need to use some kind of magic, special tensor flow operations to do control flow. So one option is recurrent networks. So you can see that for image captioning we use a recurrent network which operates over sequences of different lengths. Caffe 2 is the successor to Caffe which is from Facebook. It uses static graphs kind of similar to TensorFlow. Caffe has a Python interface but it's not super well documented. Google's kind of trying to build one framework to rule them all that maybe works for every possible scenario for deep learning. If you want dynamic graphs, you're maybe out of luck with PyTorch and Caffe 2. Tensorflow is a pretty safe bet for just about any project that you want to start new.