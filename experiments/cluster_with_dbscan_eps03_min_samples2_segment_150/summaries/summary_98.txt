age right over here we have a neural network that whose goal is to sort of predict something about a car. As you go deeper down the network is trying to become more and more abstract. depth refines representations you start with course information like edges and you go all the way down to like find information like this mental model of a car so I know that this was a good exercise for me. I guess the thing I wants you I want you to take away from this is that depthRefines representations. simple computer vision task like a cat versus dog classification or some sort of object detection and again no worries if a convolution is sort of familiar we'll cover convolutions and CNN's in much greater depth very soon. So for example um each of these models should be able to for example capture how low-level features as Arya mentioned such as the general shape the edges the patterns and the colors in the lower layer so the more earlier layers of our neural network. Then once we've moved on and we've gone towards the later layers they should be can to capture some higher level features like the abstractions of the cats versus the dogs people's faces or some of the major objects. So in other words like how do we actually transfer or do transfer learning um does anyone have any ideas perhaps of how we might want to keep certain information from a previous pre-trained model and transfer that knowledge yeah that's basically the right idea what about you you're just copy the weights Maybe yeah so very similar um one of the more common ideas is that well basically our neural networks are just stacks of layers so the idea is can we keep certain layers and basically use that on our next model so there's an idea called freezing. and that will have a homework so if you ever need to review uh the topics from this lecture so to work on that homework this slide deck should be up on the website again if you feel free to do that. That is it for today a second pause. Back to the page you came from. The slide deck for this lecture is now available on our website again. Click through the slide deck to see the rest of the lecture. The lecture will be available again on the site later this week. Aryan: I'm gonna go somewhat into detail into what representation learning is and I think this should sort of cap out the last few weeks of deep learning. Aryan: The quiz for this week will probably go live tomorrow but I'm not quite sure yet but you'll try to get it up as soon as possible so I guess like without further Ado let's Jump Right In. I'm Aryan, one of the facilitators for this decal and I'm going to be presenting today's lecture on pre-training with Verona today.