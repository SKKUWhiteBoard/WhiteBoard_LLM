well welcome back everybody to uh the last lecture 162. this is kind of a a special lecture um i did get some requests for more information about distributed storage and quantum computing and so i think we're going to do that. i want to make sure that we talk through the chord algorithm since that's a i think relatively simple thing to understand and is very cool and applied pretty much everywhere so if you remember one of the things we talked about last week was basically this cap theorem which was really a conjecture that eric brewer put forth back in the early 2000s. the value that you started with and so this interface is extremely simple it's certainly an interface uh many of you have used in languages on a single machine. If you use this in a global storage system it turns out that the interface is simple enough that you can have some pretty interesting um implementations. So today i want to tell you about the cord uh algorithm which uh has been turned into storage systems of many sorts including those used by amazon et cetera okay facebook so um before we get there i wanted to remind you of this notion of recursive versus iterative lookups so um. The challenge of that central directory is really that it's got many entries that are sort of key value pairs or at least key node mappings and you could have billions of entries in the system and so um i would say that anything that thinks of a directory here like a single server is bound to be a bad server. Here's an example of a recursive lookup which is like routing so basically if i say i want to get uh whatever key 14 has got it goes to the master directory and then that directory forwards it on it routes it to the particular node. idea okay because it's just not going to scale the billions of entries very well all right and back in the early 2000s myself and a bunch of other researchers started looking at how do you deal with peer-to-peer technologies as a way to solve this problem. One solution here is consistent hashing which i'm going to tell you about um we did tellYou about it last time but i want to reemphasize what it is. The chord algorithm lets you get by with only knowing essentially a logarithmic number of nodes in the total system. So imagine you take their i don't know their ip address and their owner and whatever you concatenate all those things together and you hash them and you get a single 256-bit id out of that now we're going to talk more about secure hashes a little bit later in the lecture. Every node has an id and it's going to be in this ring space this unit dimensional space from 0 to 2 to the m minus 1 where m is big okay and so let me just show you the picture here. said in practice m is really something more like 256 and so uh this ring is really big and um these nodes are much more sparsely distributed around the ring okay questions we only have a very small class today so you guys are likely to get your questions answered anybody okay no questions all right should we move on now is a system that was developed uh with a group of researchers at mit and at berkeley um and you can think of it as a distributed look-up service. In my view i like to teach about it because it's the simplest and cleanest algorithm for distributed storage that i have seen. all these nodes but we're looking down from above and you can clearly see that no lookup for a t37 is going to want to get back node 44 because that's what's going to store key 37. so how does this happen well 4 says well i don't know what it is so it routes to 8. it says i don’t knowwhat it is that's 15 rounds to 20 32 35 this point 35 knows that it's uh successor is 44 and so it just responds back and says hey i happen to know that node 44 is responsible for key 37 and at that point uh node4 can talk back to the client and the client now knows just to talk to 44. got a thousand nodes that are storage nodes i may have to take many hops to find out uh what i want here um it turns out that the worst case lookup here is order n so that's probably bad but we're going to show you how to get login in a little bit it's going to be a dynamic performance optimization and so on that'sGoing to be pretty interesting now what I want you to see though is from a correctness standpoint as long as every node knows who its predecessor is and successor then we can always find the server we're looking for. means that no particular part in the in the world here might be a hot spot it means unfortunately though that we don't have the most uh local of look up because if we start at node four it'd be nice if we could just go down to 15 and back okay now this is a really good question here about redundancy how do we get redundancy out of this for the moment uh suspend that question for just a second certainly we could put raid servers or what you know raid storage on each of these nodes and that would be great if the disks fail but uh we would like something even more powerful because i don't know if there's a big earthquake and california falls off into the ocean it'dbe nice to know that key 14 survived somehow. with dns you need to know how to talk to local at least one dns server somewhere before you can start resolving names okay so the first thing i want to talk about is how can we make sure this this ring stays connected even though nodes are failing and coming back okay. How we can make sure it's connected is we're going to have this dynamic stabilization procedure so every node can run stabilize. If it finds a problem it can run notify to help reconnect the ring okay so let's uh these are the kind of things that are a lot easier to see with animations. about this algorithm is all that the ring is going to do is it's going to figure out who is responsible for storing key 50 as if this was just a regular key value lookup. So just by asking the ring where key 50 belongs it now has some information about nodes that it can talk to. If you lose two nodes in a row then what i've just described to you is no longer going to work so there is a way to completely break the ring such that the stabilized procedure won't reconnect. There's a way to do that as long as you have multiple links and what we're going to do right now for performance is going to make that even harder to destroy the connectivity okay. Rather than just keeping track of nodes forward and backward what we'll do is we'll keep track of uh our current position plus uh 1 plus 2 plus 4 plus 8 plus 16 and so on. The question would be what node would store 81 well that would be here at node 80. And if you have a leaf set with more than one node by the way though okay now. Think about this as bit correction. We're going to keep track of a logarithmic number of these pointers. We just query the ring and ask it oh i want to store each of these keys. What will come back from the ring is which node is responsible the power the powerful thing about this is once i've got all these nodes now i can do a really fast routing process to figure out how to find which nodes are responsible for the key i'm interested in. The power of the finger table is that you can view that like i'm correcting the bits from my starting point to my destination. my ending point i'm correcting them one at a time by taking these various hops okay and that's how we end up with logarithmic routing time. This forest of additional pointers plus the extra pointers from the leaf set together make it really hard to be uh unable to reconnect the ring okay and so if you read that chord paper it talks about how you make use of all the information you've got to keep the ring connected okay questions okay we're good now let's think a little bit more about data. The only place for key 14 to be stored as on node 15. If node 15 weren't there key 14 would be stored on 20 right that's just the next node up from 14 since the only copy of key 14 it's currently stored on 15 if 15 dies or goes away we don't have the data. So we can't store it there because we've lost our data so we got to do something else here okay. We're going to store 14 on the successive nodes that we know about because of the leaf set so we'll store it on 20 and 32. algorithm and so what's good about this is like i said you store the data in the cord ring and it it's very hard to destroy okay why are they called leaf sets that's a good question the reason they're called Leaf sets is because in some sense you can view the uh if you take any given um starting node like 58 and you view the set of fingers that’s a tree and so eventually you get to the leaf set and so it's like a tree with leaves so that's where the leaf is coming from and here's an example of that. with our replication but it also serves as uh as part of the last couple of hops we can use the leaf set to basically find who's supposed to have our data all right um now so let's look at replication from a physical standpoint right so if you look again at this ring i showed you a little while ago that ring is mapped physically to things that are spread widely. Now we can see another big advantage of the randomness introduced in chord and that advantage is that these copies are actually stored in geographically separate places. Think of this like a dns built out of cord and so what the client does is the client doesn't know where the data they're interested in is they ask the cord ring. The cord ring tells them who to talk to and then they can talk directly to them and exchange data over the shortest path possible. So you can now get the best of both worlds and that you have very hard to destroy lookup process and then you can choose to replicate that data on close to the client. The cord ring is really about making sure that they can get their performance within a small number of nines okay and so the availability is an important aspect here. You have a service guarantee that says we'll get a response within 300 milliseconds uh for say 99.9 percent of the requests okay. This is very in contrast essentially to what we've been talking about a lot of the rest of the term uh which is focusing on mean response time instead we want to have guaranteed performance okay and this is again thinking i want you to think back to when we were talking about real time scheduling. it adapts automatically which is pretty good okay so what i wanted to do next uh i'm going to talk a little bit about security and then um talk through a couple of things and then i want to uh try to get to quantum computing as well so we can i know there was some of you asked some questions about that so i'mgoing to leave this topic unless there's more questions okay. Security is kind of dealing with actions of a knowledgeable attacker who's really trying to cause harm and we want to make sure that uh they can't really screw us up. about by using new techniques and the distinction between protection and security i think is an important one because protection is the set of mechanisms that we talk about in this class security is basically using those mechanisms to prevent misuse of resources so for instance virtual memory is a mechanism that can be used for protection security policy would be making sure that when we use virtual memory we don't let malicious processes or different processes owned by different people use the same memory and have a potential for screwing each other up so that would be a security policy built with our protection mechanisms. The rise of fake data which is kind of much worse than fake news which is about corrupting the data and making the system behave very badly. We have several security requirements that people talk about so authentication is making sure that a user who's making changes to the system is really who they claim to be data integrity is makes sure that the data hasn't changed okay so that's important confidentiality is make sure the data is read only by authorized users. Non-repudiation is a surprisingly important thing that people don't often talk about which is that if one sender makes a statement and they uh send a message or whatever they can't later claim that well i didn't really send out somebody malicious did. making sure that you can't repudiate things that you've previously said and so i'm hoping that if you haven't taken 161 it's on your list because there's a very interesting set of things that people can talk about. cryptography is one of the central points of many of these mechanisms you just have to use it correctly. This is communication that's in the presence of adversaries uh it's been studied for thousands of years there's actually something called the code book which you should look up. single symmetric key encryption work which symmetric because the same secrets used at both sides is to prevent a adversary from holding on to an old message and sending it later. You have to start adding what are called nonces which are things like timestamps and so on so that every time you send this it's unique and if somebody sends an old version you can detect it. The idea of a secure hash function is one where you take data and you run it through a hash function and you get a bunch of bits. to come up with two different items that you come upwith yourself that have the same hash function okay and so that's why we can kind of use hashes as a proxy for the data itself. So for instance in that firmware problem with the car we could have a key that only came from the manufacturer in a secret way and we could check the integrity of that firmware against the manufacturer and if it was not corrupted then it wasn't corrupted. So we can use hashes to prove later that you know after the transmission has happened that the data is authentic okay so hashing is pretty powerful. it wasn't uh you know if the integrity wasn't high you know it was basically didn't match then we could know that that firmware is probably bogus and we shouldn't be using it okay now the downside of course of everything we've talked about is both sides share the same key and so if you leak the key then you got problems okay and furthermore you have to somehow share the key so that requires you to go in a dark alley and you know hand the key over and so this seems like only part of the solution and um the interesting thing about that is this idea of public private key pairs. A virtual machine that's in modern hardware that allows you to set up a secure channel and do some secure encryption in a way that not even the local operating system can see the data. This is what i like to call as border security rather than data security and so if you think well i'm going to put some firewalls and now i can say look this is a trusted computing base that's secure this is one as well there's one around the cloud and then you know the only thing left is cell phones which i make secure tunnels with. have any breaches inside the trusted computing base then all of a sudden not only is the data breached but somebody who is inside that firewall can produce data that looks authentic uh even though it's not. The real reason we get these data breaches everywhere is because people think that they can put these boundaries up in a way that don't um can't be breached and of course we know that's not true. The problem really is not only are things breached but the integrity and the provenance of that data is not known so what do we do the data centric vision. there'd be people there that would unpack them and then you'd have to figure out how to put them on trucks and so on and it was a mess and basically one person that said well why don't we just make things that are all the same size and shape and then all of a sudden we've got ships trains cranes all of the the infrastructure for handling these things are the same across the planet. Now i can ship something from my house in lafayette to beijing the outskirts of beijing just by calling the right trucks to come pick up a shipping container. Underneath the network is like the ships and trains and cranes and planes that handle this standardized metadata and what is the standardized metadata well it's a hash over an owner key and some other metadata about who created this and that forms a unique address that you can route to in our system. Standardization makes it possible for the infrastructure to be put everywhere and it benefits everyone federation you can actually build a market of service providers the data becomes a first-class entity so your data basically can float pretty much anywhere. is one where you instead of paying for ip service you'd pay for data capsule service and um you'd be able to store your data in a way that was secure okay and could be used anywhere you want and you'd own your data okay so physical view just one last little slide here and then i'll move on to to the uh quantum computing so i want to make sure we cover that but if you think about ip the way we talked about it briefly in a couple of weeks prior if you look at the physical view of ip there's a bunch of routing clouds and there's also transit providers. how we want to be dealing with data all right sorry if that's a lot of information but i wanted to see if there's any questions there before i switch over to some quantum computing all righty give me a second i'll be right back and then we'll see ifthere are any questions that came up one moment okay so good so we have some good questions here so first question is how do we know the data is secured so um just like with a blockchain let me just back up to the picture here which i think is a is a good one to be talking about. The data capsules are cryptographically hardened bundles of data. They are not forgeable and can't be swapped or swapped or whatever. If somebody tries to put garbage in there a legitimate person who's trying to look at this can just throw the garbage out because there's no way that that garbage could have been put in there. If you have a signature only at the end of a chain of data you can essentially check the rest of the chain by checking the hash pointers so these are all of the things you get out of a blockchain by the way. The vision here really is of pretty much everybody using data capsules everywhere okay and if you can get that to happen then you potentially have a very interesting scenario here. If any of you want to come work on this project come talk to me uh separately we have plenty of uh places we can talk to you okay now i'm gonna i promised you some quantum computing i did wanna show you one other interesting slide here potentially which shows you kind of an idea of how we can build things up um here. put their data and their models for grasping and so on inside of data capsules and as a result they can reside securely in uh in the edge in say your robots or whatever in a way that can't be breached okay. This is really targeted at secure edge infrastructure in addition to the cloud so these data capsules can move back and forth but certainly you need something like this on the edge because these pieces of hardware are easily breached and you want to make sure your data is is uh secured and unforgeable all right good.  quantum computing is basically using quantization and superposition to compute. If you could get a shores algorithm running on a quantum computer pretty much all rsa cryptography would be broken because you could factor. material simulation was kind of the original uh the original application of quantum computing that was thought of. If i'm really interested in designing exotic new materials to build interesting things i probably want a quantum computers. There are many other algorithms out there now these days they've been slowly working on them but these are some pretty good ones that give you an idea why this might be interesting.  quantum computing technology is not going to be in your laptop at least not in any laptop i'd want to put on my lap but there are other types of technologies including ion traps that potentially are pretty interesting. These computers by being built by google and ibm have you know maybe have order 100 bits maximum it's very hard to do anything interesting with 100 bits but they're focusing on demonstrations that show that with those 100 bits they could potentially do something a lot better than a classical machine so that's called quantum supremacy. spin one-half particles are particles that can only spin with the axis pointing up or down nowhere in between. A representation called the heisenberg representation looks at this messy physical situation like this which is either a zero or a one in these brackets and that represents spin up and spin down okay or vice versa depending on how you want to look at it. One proposal for building quantum computers from way back when was called the cane proposal and those spins were actually what you got when you embedded phosphorus impurity atoms into silicon. something people were looking at okay but the temperature here was less than one kelvin which is really cool okay but let's suppose now here's where the quantum computiness gets pretty tricky okay. If you think of the zero and the one thing okay this is actually a wave function if you take quantum mechanics representing spin up and spin down. What you see here okay with this psi function isactually a superposition of zeroness and oneness together okay now you know i realize this looks a little weird we don't normally get a wavefunction notation in 162. The way we build a computer is we take a complex state like i just showed you and then we put it through a bunch of adders whatever you want to call it which are really all unitary transformations. If we measure one of them like let's suppose we measure and find that there's a zero back on earth we know instantaneously that we got a zero on the other side okay. So that looks like we had faster than light travel in fact instantaneous travel of information from the earth out to that far planet einstein really didn't like this he called it spooky action at a distance okay. you do a bunch of computing on it such that the probabilities are kept and you measure okay and the way it looks is that you take uh let's say you put an input with all possible combinations of the input input of the inputs being equal values all possible probabilities it looks like you're doing computation on all possible values at once but then when you measure you pick up exactly one and that's the answer you get okay. So basically what we're talking about here looks like a random computation like you get in cs70 or 170 where you randomly pick an input you compute on it you look at the result so that's not very interesting right. The difficulty of factoring rsa is figuring out how to take a large number which is publicly known and factor it into two large factors that are primes. If you can do that you break the cryptography so classically this is an exponential time algorithm and so as long as these are big enough nobody's going to break it quantum computer can do it polynomial time and let me show you how here's how it is in a nutshell you pick a random x between 0 and n that's easy. This out what r makes this equiv equation satisfied and we could do that quickly then um we win and that's something that uh you can't do easily classically but with a quantum computer what we can do. i can set up a situation where my input to my algorithm is all the possible k's uh if i take a bunch of values and i compute uh the the value x to that value and i add them all together as a superposition and i do a fourier transform what i'll find is that x to the r congruent to one as i have r go through all its possible values. question is is this something to worry about the answer is well so far no but it's looking like um it's getting closer and closer okay. We actually investigated ways of optimizing that and we could actually look at performance of different options for the shortest factoring algorithm as quantum circuits. We built a cad tool to do that so um i i don't know i think it's a pretty interesting area right now and there's a lot of interest in it all right so um sorry i kept you guys way over but this is the last lecture i figured if anybody was interested. i think it's it's pretty exciting project we got working on it if anybody's interested in that and then we told you a little bit about quantum computing and uh feel free to come ask me or also look at 151 or 191 excuse me um which is an interesting class on quantum computing all right well thank you everybody sorry for going way over today thank you for those of you that stuck around and uh i hope you have a good uh finalizing of project three andThose of you listening in cyberspace later as well you are all great.